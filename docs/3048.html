<html>
<head>
<title>Diagnose your Linear Regression Model — With Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python诊断您的线性回归模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/diagnose-your-linear-regression-model-with-python-428b7334f81c?source=collection_archive---------6-----------------------#2021-05-31">https://medium.com/analytics-vidhya/diagnose-your-linear-regression-model-with-python-428b7334f81c?source=collection_archive---------6-----------------------#2021-05-31</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="3013" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">回归诊断是实现有意义回归模型的关键步骤。</p><p id="8efe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jc translated"><span class="l jd je jf bm jg jh ji jj jk di"> O </span>统计学家和数据科学家的主要兴趣之一是检查一个称为目标或响应的单个变量与另一组称为预测因素的变量之间的关联，以便进行预测或分析。实现这一目标的常见步骤包括但不限于:</p><ul class=""><li id="5cd3" class="jl jm hh ig b ih ii il im ip jn it jo ix jp jb jq jr js jt bi translated">预处理数据</li><li id="9705" class="jl jm hh ig b ih ju il jv ip jw it jx ix jy jb jq jr js jt bi translated">检查数据</li><li id="885b" class="jl jm hh ig b ih ju il jv ip jw it jx ix jy jb jq jr js jt bi translated">型号选择</li><li id="1363" class="jl jm hh ig b ih ju il jv ip jw it jx ix jy jb jq jr js jt bi translated">训练模型</li><li id="2ac8" class="jl jm hh ig b ih ju il jv ip jw it jx ix jy jb jq jr js jt bi translated">模型诊断</li></ul><p id="c4b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">机器学习领域的大多数文章都涵盖了前四个步骤，但不太强调最后一个步骤，这可能是决策过程中最重要的步骤。诊断模型包括许多逻辑的和可重复的过程，通过与真实值比较来监控和评估模型的输出。显然，我们应该在这个过程中使用的度量是残差，它被定义为真实值和预测值之间的差异。使用残差来帮助指导回归拟合的概念是建模过程中的一个基本步骤。在本文中，我们简要介绍了线性回归诊断，以提高我们对模型的理解，并最终改进它。</p><figure class="ka kb kc kd fd ke er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es jz"><img src="../Images/99fad6f7fc96bba543f344649f76c39e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yACx2SkWvDCfYm0Eoppt_A.jpeg"/></div></div><figcaption class="kl km et er es kn ko bd b be z dx translated"><a class="ae kp" href="http://One of the main interests of" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="1a69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了展示所提出方法的实用性，我们将使用python语言来实现。为此，我们使用数据集"<em class="kq">医疗费用个人数据集"。</em>你可以从Kaggle网站找到数据集，<a class="ae kp" href="https://www.kaggle.com/mirichoi0218/insurance" rel="noopener ugc nofollow" target="_blank">这里</a>。为了解释数据集，它由六个不同的预测值和一个名为<code class="du kr ks kt ku b">charges</code>的目标结果组成。这是每个人需要支付的医疗保险金额。每一行都包含贡献者端的数据。<code class="du kr ks kt ku b">age</code>、<code class="du kr ks kt ku b">sex</code>和<code class="du kr ks kt ku b">bmi</code>(身体质量函数)不言自明。<code class="du kr ks kt ku b">children</code>是每个贡献者所拥有的家属人数。最后，<code class="du kr ks kt ku b">smoker</code>和<code class="du kr ks kt ku b">region</code>分别表示吸烟状态和居住地点。</p><p id="3fde" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将大部分讨论分配给诊断过程，因为模型的训练已经在<a class="ae kp" href="https://vnaghshin.medium.com/linear-regression-for-data-science-with-python-eeb3407abf9d" rel="noopener">中讨论过。完整的python代码可以在</a><a class="ae kp" href="https://www.kaggle.com/vahidnaghshin/linear-regression" rel="noopener ugc nofollow" target="_blank">这里</a>找到。因此，我们从训练好的模型开始:</p><pre class="ka kb kc kd fd kv ku kw kx aw ky bi"><span id="b10f" class="kz la hh ku b fi lb lc l ld le">df = pd.read_csv('insurance.csv')</span><span id="94cb" class="kz la hh ku b fi lf lc l ld le">predictors = ['age', 'sex', 'bmi', <br/>              'children', 'smoker', 'region']<br/>outcome = 'charges'</span><span id="f7b6" class="kz la hh ku b fi lf lc l ld le">df_encoded = pd.get_dummies(df[predictors], drop_first=True)<br/>df_lm_factor = LinearRegression()<br/>df_lm_factor.fit(df_encoded, df[outcome])<br/>print(f'Intercept: {df_lm_factor.intercept_:.3f}') <br/>print('Coefficients:')<br/>for name, coef in zip(X.columns, df_lm_factor.coef_):<br/>    print(f' {name}: {coef}')</span></pre><p id="bff6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出将是:</p><pre class="ka kb kc kd fd kv ku kw kx aw ky bi"><span id="e92a" class="kz la hh ku b fi lb lc l ld le">[output]:<br/>Intercept: -11938.539<br/>Coefficients:<br/> age: 256.85635253734864<br/> bmi: 339.1934536108373<br/> children: 475.5005451491269<br/> sex_male: -131.3143593951132<br/> smoker_yes: 23848.534541912835<br/> region_northwest: -352.9638994246546<br/> region_southeast: -1035.0220493878253<br/> region_southwest: -960.0509913008365</span></pre><p id="dd04" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型的截距和系数如下所示。因为，在我们的模型中，一些预测因子是通过虚拟变量编码的，解释这个模型有点棘手。有关处理离散预测值的更多详情，请参考此处的<a class="ae kp" href="https://vnaghshin.medium.com/linear-regression-for-data-science-with-python-eeb3407abf9d" rel="noopener"/>。</p><h1 id="c13f" class="lg la hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated"><strong class="ak">解释回归模型</strong></h1><p id="a3ec" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">数据科学中最重要的任务是预测变量。然而，解释线性回归模型主要是作为概要分析或基于数据的解释的一部分。通过查看模型的系数，我们可以看到，对于<code class="du kr ks kt ku b">age, bmi, children, </code>和<code class="du kr ks kt ku b">smoker_yes</code>，它是正的，表明这些变量中任何一个的增加都会导致<code class="du kr ks kt ku b">charges</code>的增加。例如，对于数值预测器，<code class="du kr ks kt ku b">bmi</code>，我们可以说<code class="du kr ks kt ku b">bmi</code>增加一个单位将导致<code class="du kr ks kt ku b">charges</code>增加大约340个单位。对于其他非数值变量，注意<code class="du kr ks kt ku b">smoker_yes</code>是一个因子变量，它通过虚拟变量转换成数值，用于回归模型。因此，应该参照<code class="du kr ks kt ku b">smoker = no. </code>来解释。因此，通过查看<code class="du kr ks kt ku b">smoker_yes</code>的系数，我们可以看到这个数字是23848，这意味着与不吸烟的人相比，吸烟者的费用增加了23848。这种解释可以推广到负系数模型中的同因子变量。</p><h2 id="0776" class="kz la hh bd lh mi mj mk ll ml mm mn lp ip mo mp lt it mq mr lx ix ms mt mb mu bi translated">相关预测值</h2><p id="54a2" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">在多元线性回归中，如果有一个以上的预测因子，那么不同的预测因子之间可能存在相关性。作为一个例子，考虑一个吸烟的人，<code class="du kr ks kt ku b">smoker=yes</code>可能有更高的<code class="du kr ks kt ku b">bmi</code>，这表明通过知道一个人吸烟，我们可以(以更高的确定性)推断这个人也吸烟。在线性回归模型中，高度相关的预测值可能会导致不良建模。这是要记住的关键点，因为它不能通过交叉验证或其他通常被认为是模型改进者的指标来缓解。在这种模型中，高相关系数可以通过更广泛的上下文理解(如领域知识)来识别。<strong class="ig hi">如果你发现正系数或负系数在模型中没有意义，请怀疑相关变量。</strong></p><h2 id="1b77" class="kz la hh bd lh mi mj mk ll ml mm mn lp ip mo mp lt it mq mr lx ix ms mt mb mu bi translated">多重共线性</h2><p id="0187" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">相关预测值导致了模型验证中的一个重要概念，称为多重共线性。多重共线性仅仅意味着模型中存在冗余变量。消除其中一个可以极大地改善模型。必须解决回归中的多重共线性，应移除变量，直到多重共线性消失[1]。存在完全多重共线性时，回归没有明确定义的解。包括<em class="kq"> R </em>和<em class="kq"> Python </em>在内的很多软件包都会自动处理某些类型的多重共线性。例如，如果<code class="du kr ks kt ku b">age</code>在数据回归中包含两次，结果与<code class="du kr ks kt ku b">df_lm_factor</code>模型相同。</p><h2 id="f9f2" class="kz la hh bd lh mi mj mk ll ml mm mn lp ip mo mp lt it mq mr lx ix ms mt mb mu bi translated">混淆变量</h2><p id="f5bb" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">混杂变量是多重共线性的对应变量。在多重共线性中，我们做出了足够多的承诺，而在混淆中，我们的模型受到必要变量排除的影响。例如，在我们的模型中，<code class="du kr ks kt ku b">bmi</code>的增加可能导致更高的<code class="du kr ks kt ku b">charges.</code>，然而，这可能是代谢减少导致更高的<code class="du kr ks kt ku b">bmi</code>，从而导致<code class="du kr ks kt ku b">charges</code>。混淆变量不是一个简单的问题，在每个数据库决策过程中，在推导伤亡时都应该考虑。有时，通过从现有变量生成一些变量，可以使用<em class="kq">特征工程</em>解决混淆变量。然而，在大多数情况下，混淆变量要求知识领域，并考虑问题发生的背景。</p><h1 id="8671" class="lg la hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">测试假设</h1><p id="86a4" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">大多数线性回归都是基于一些关键的假设。这些假设中的大多数可以通过查看残差来验证。在下文中，我们将介绍一些用于诊断线性回归模型的指标和概念。</p><h2 id="77ea" class="kz la hh bd lh mi mj mk ll ml mm mn lp ip mo mp lt it mq mr lx ix ms mt mb mu bi translated">极端值</h2><p id="2dc0" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">异常值通常是远离大多数其他观察值的样本。根据应用程序的不同，异常值可能会很有趣。例如，在欺诈检测中，异常值是交易中的欺诈迹象，可以触发许多结果操作。在线性回归上下文中，异常值是预测值和真实值之间高度不匹配的记录。距离可以通过<em class="kq">标准化残差来量化，标准化残差是残差除以残差的标准误差。</em>标准化残差可以解释为“远离回归线的标准误差数”。基于标准化残差的异常值检测的python代码如下所示:</p><pre class="ka kb kc kd fd kv ku kw kx aw ky bi"><span id="1e37" class="kz la hh ku b fi lb lc l ld le">res = df[outcome] - df_lm_factor.predict(df_encoded)<br/>sres = np.abs(res / res.std())</span><span id="f8a7" class="kz la hh ku b fi lf lc l ld le">idx_sres, max_sres = sresiduals.idxmax(), sresiduals.max()</span><span id="5d6f" class="kz la hh ku b fi lf lc l ld le">df.iloc[idx_sres]</span></pre><p id="6ed0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">运行上述代码可识别具有最高标准化残差/误差的样本，如下所示:</p><pre class="ka kb kc kd fd kv ku kw kx aw ky bi"><span id="85d9" class="kz la hh ku b fi lb lc l ld le">[Output]:<br/>age                  45<br/>sex                male<br/>bmi               30.36<br/>children              0<br/>smoker              yes<br/>region        southeast<br/>charges     62592.87309<br/>Name: 1300, dtype: object</span></pre><p id="2f24" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">移除此样本可能会提高模型的准确性，因为它离回归线的距离增加了四倍。<strong class="ig hi">请注意，这种异常值检测方法假设残差遵循正态分布。</strong></p><h2 id="b9fb" class="kz la hh bd lh mi mj mk ll ml mm mn lp ip mo mp lt it mq mr lx ix ms mt mb mu bi translated">有影响力的价值观</h2><p id="dbbc" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">影响值是对线性回归模型有显著影响的值。例如，排除有影响的样本会导致直线斜率和总体残差的显著变化。这个样本叫做有影响的观察。该值不一定是异常值，因为它可能具有较小的标准化误差(接近回归线)。据说这个数据对回归有很高的<em class="kq">杠杆</em>。</p><p id="39cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">记录在结果空间或预测空间中可以是不同的。前者叫做<em class="kq">离群值</em>，后者叫做<em class="kq">杠杆</em>。换句话说，给定记录的预测值可以不同于其他记录，或者目标结果可以不同于其他记录。识别数据的这些特征有助于解释结果和验证获得的模型。<strong class="ig hi">要成为有影响力的值，样本需要在预测值和结果空间都不同。</strong></p><figure class="ka kb kc kd fd ke er es paragraph-image"><div class="er es mv"><img src="../Images/5f57dcf454e4b3abbc4d00dd668fcc0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*ERvJCrGcIaChEK2Tu7y0PA.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated"><a class="ae kp" href="https://tillbe.github.io/outlier-influence-identification.html" rel="noopener ugc nofollow" target="_blank">影响点</a></figcaption></figure><p id="14d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上图中，点8在预测空间和结果空间中都远离这些点。所以，这是一个有影响力的观点。</p><p id="d627" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">统计学家开发了几个度量标准来确定单个记录对回归的影响。杠杆的一个常见衡量标准是<em class="kq">帽子价值。</em>高于2 <em class="kq"> P </em> + 1 / <em class="kq"> n </em>的值表示高杠杆数据值[1]。这里，<em class="kq"> P </em>是预测数，<em class="kq"> n </em>是记录总数。hat值只是预测空间中给定样本的距离的标准化版本。Hat值介于1/n和1之间，1表示最高杠杆(与均值的最大距离)。</p><p id="2dc9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">检查影响点的一种常见方法是查看影响图或气泡图。气泡图显示了<em class="kq">学生化残差</em>对S. hat值。学生化残差是基于残差和标准误差计算的，不考虑可能的影响样本。它也使用相应的帽子值。另一个指标是<em class="kq">库克距离</em>，它将影响力定义为杠杆年龄和剩余大小的组合。一个经验法则是，如果库克的距离超过4/<em class="kq">n</em>P1[1】，则观察具有很高的影响。</p><p id="3ec0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们数据集的气泡图可以使用<code class="du kr ks kt ku b">statsmodel</code>包来实现。代码如下:</p><pre class="ka kb kc kd fd kv ku kw kx aw ky bi"><span id="39b5" class="kz la hh ku b fi lb lc l ld le"># in order to include intercept, const=1<br/>df_outlier = sm.OLS(df[outcome], df_encoded.assign(const=1)) <br/>result = df_outlier.fit()<br/>influence = OLSInfluence(result)</span><span id="7c22" class="kz la hh ku b fi lf lc l ld le">fig, ax = plt.subplots(figsize=(5, 5))<br/>ax.axhline(-1.96, linestyle='--', color='C1')<br/>ax.axhline(1.96, linestyle='--', color='C1')<br/>ax.scatter(influence.hat_matrix_diag, influence.resid_studentized_internal, <br/>           s=1000 * np.sqrt(influence.cooks_distance[0]),<br/>           alpha=0.5)</span><span id="805d" class="kz la hh ku b fi lf lc l ld le">ax.set_xlabel('hat values')<br/>ax.set_ylabel('studentized residuals')</span><span id="c4e6" class="kz la hh ku b fi lf lc l ld le">plt.tight_layout()<br/>plt.show()</span></pre><figure class="ka kb kc kd fd ke er es paragraph-image"><div class="er es mw"><img src="../Images/bc603f1378e4198e85de26419292ac09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*vvAtoi8ZdE5rx7uUJvZvPQ.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">气泡图</figcaption></figure><p id="cd39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">较高的hat值代表较高的杠杆作用，而学生化残差表明可能存在异常值。如果我们对学生误差使用95%的置信区间，任何不在[-1.96，1.96]内的点都是潜在的异常值。其他可能性是，具有较高学生化残差的点需要更复杂的预测模型。</p><h2 id="35b0" class="kz la hh bd lh mi mj mk ll ml mm mn lp ip mo mp lt it mq mr lx ix ms mt mb mu bi translated">异方差</h2><p id="668d" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">异方差一般是指残差的方差。对于一个好的模型，期望残差是正态分布的，样本之间没有相关性(样本可以是正态分布的，但仍然代表一些相关性)。此外，预计残差在不同的预测范围内具有恒定的方差。异方差是残差中缺少恒定方差。换句话说，数据的某些部分比其他部分具有更高的残差。这在评估假设检验或预测区间时更为关键。异方差表明预测值的不同范围的预测误差不同，并可能表明模型不完整[1]。</p><p id="7ff6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于我们的数据，我们可以绘制预测值与残差的关系图，以研究可能的异方差性。以下代码将绘制残差绝对值与预测值的关系。</p><pre class="ka kb kc kd fd kv ku kw kx aw ky bi"><span id="2f4e" class="kz la hh ku b fi lb lc l ld le">fig, ax = plt.subplots(figsize=(8, 5)) <br/>sns.regplot(x=result.fittedvalues, y=np.abs(result.resid),<br/>scatter_kws={'alpha': 0.25}, line_kws={'color': 'C1'}, lowess=True, ax=ax, ci=95)</span></pre><figure class="ka kb kc kd fd ke er es paragraph-image"><div class="er es mx"><img src="../Images/a0c42bd3df0d4707900fe8708ad963ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1232/format:webp/1*iX_slWwO-zU1siKz0gHiUQ.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">绝对残差与预测</figcaption></figure><p id="1716" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可以看出，对于宽范围的预测值，回归线周围的残差变化几乎是恒定的。这表明我们开发的模型没有异方差。残差的正态性可以通过直接观察残差的分布来验证。下面的代码用于推导学生化误差的正态分布。</p><pre class="ka kb kc kd fd kv ku kw kx aw ky bi"><span id="0c42" class="kz la hh ku b fi lb lc l ld le">fig, ax = plt.subplots(figsize=(4, 4))</span><span id="d85b" class="kz la hh ku b fi lf lc l ld le">pd.Series(influence.resid_studentized_internal).hist(ax=ax)</span><span id="4071" class="kz la hh ku b fi lf lc l ld le">ax.set_xlabel('std. residual')<br/>ax.set_ylabel('Frequency')<br/>plt.tight_layout()<br/>plt.show()</span></pre><figure class="ka kb kc kd fd ke er es paragraph-image"><div class="er es mv"><img src="../Images/3e58fed5747bf57a01002d1a200bebfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*Gm7xubgOJWZOXdzrzhxSsg.png"/></div><figcaption class="kl km et er es kn ko bd b be z dx translated">学生化剩余的历史</figcaption></figure><p id="3323" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从上图可以看出，随着残差拉伸为正值，学生化误差的直方图呈正偏斜。在确定预测间隔时，应该考虑到这一点。</p><h2 id="ceac" class="kz la hh bd lh mi mj mk ll ml mm mn lp ip mo mp lt it mq mr lx ix ms mt mb mu bi translated">部分残差图</h2><p id="e4b1" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">我们如何检查结果和预测因子之间的非线性关系？部分残差图为这一调查提供了很好的洞察力。<em class="kq">部分残差图</em>是一种直观显示估计拟合度如何解释预测值和结果之间关系的方法。部分残差图的基本思想是隔离预测变量和反应之间的关系，<em class="kq">考虑所有其他预测变量[1] </em>。换句话说，部分残差图可用于定性评估每个回归项的拟合度，可能会导致替代模型规范。</p><p id="0612" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果预测值与任何其他独立变量高度相关，则应小心谨慎。如果是这种情况，图中明显的方差将是对真实方差的低估。</p><p id="1f4b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用<code class="du kr ks kt ku b">statsmodel </code>软件包，可以获得<code class="du kr ks kt ku b">bmi </code>和<code class="du kr ks kt ku b">age</code>的部分残差图，如下所示:</p><figure class="ka kb kc kd fd ke er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es my"><img src="../Images/5d4b180b9fc2864ac96c28e54560b46c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bSd8nRMCqPYzohvSaFlI7Q.png"/></div></div><figcaption class="kl km et er es kn ko bd b be z dx translated">“年龄”和“体重指数”的局部图</figcaption></figure><p id="7b6a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的图表明<code class="du kr ks kt ku b">age</code>比<code class="du kr ks kt ku b">bmi</code>与结果有更高的相关性。</p><h1 id="479d" class="lg la hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">总结</h1><p id="2295" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">在本文中，我们简要地介绍了线性回归中的诊断方法，用以分析和评价所得模型。</p><h1 id="f13a" class="lg la hh bd lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc bi translated">参考</h1><p id="4933" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">[1]布鲁斯、彼得、安德鲁·布鲁斯和彼得·格德克。<em class="kq">数据科学家实用统计:使用R和Python的50多个基本概念</em>。奥莱利媒体，2020。</p></div></div>    
</body>
</html>