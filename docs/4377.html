<html>
<head>
<title>Tokenizers — Your first step into NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">记号赋予者——你进入NLP的第一步</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tokenizers-your-first-step-into-nlp-837c2ddae60a?source=collection_archive---------2-----------------------#2021-10-02">https://medium.com/analytics-vidhya/tokenizers-your-first-step-into-nlp-837c2ddae60a?source=collection_archive---------2-----------------------#2021-10-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="e19c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">解释了NLP管道的起点之一</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/70518e52a7784328971f096f6e681833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wp5yaXfQfPd2Bml-"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">由<a class="ae js" href="https://unsplash.com/@ikukevk?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">凯文·Ku</a>在<a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="9518" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">简介:机器与人类——我们如何阅读？</h1><p id="76b1" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">对我们来说，语言是微不足道的。我们从出生的那天起就听到了。我们理解:</p><ol class=""><li id="e4c4" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated">语音学:讲话的声音帮助我们理解它的意思。</li><li id="eeab" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">句法:组成句子的单词和短语的组合。</li><li id="a4d4" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">语义:每个单词、短语和句子的意思</li></ol><p id="57ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，一旦你给计算机看一个句子，它不知道这个句子的结构和意思。不管怎样，我们必须在单词、短语和句子的层次上对意思进行编码。</p><p id="d465" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们能编码规则吗？我们可以说，“名词必须与动词一致，这意味着单数名词需要单数动词，复数名词需要复数动词”等等吗？嗯，那将需要一长串的规则，并使我们的工作更加困难。随着ML和深度学习的出现，事实证明，模型可以自己找出这些规则和意义。</p><h2 id="64ec" class="lk ju hh bd jv ll lm ln jz lo lp lq kd ip lr ls kh it lt lu kl ix lv lw kp lx bi translated"><strong class="ak">基于单词的标记化</strong></h2><p id="3fd4" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">第一步是将文本分解成“块”并用数字编码。然后这个数字表示会有一个向量表示(<strong class="ig hi"> <em class="ly">单词嵌入</em> </strong>，<a class="ae js" rel="noopener" href="/analytics-vidhya/word-embeddings-aaef8c6bd04a">你可以查看我写的关于那个</a>的整篇文章)，模型会学习这个向量表示。</p><p id="13ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">空白标记化:</strong></p><p id="c938" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最简单的形式是，我们在空白区将整个文本分开。这会把它分解成单词。</p><p id="cafb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们以《哈利·波特》小说中的词汇为例。我们的模型知道的所有单词都来自这段文本。</p><p id="24da" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里有一个缩写。</p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="bdfb" class="lk ju hh ma b fi me mf l mg mh">/ \n\n\n\n\nTHE BOY WHO LIVED \n\nMr. and Mrs. Dursley, of number four, Privet Drive, \nwere proud to say that they were perfectly normal, \nthank you very much. They were the last people you’d \nexpect to be involved in anything strange or \nmysterious, because they just didn’t hold with such \nnonsense. \n\nMr. Dursley was the director of a firm called \nGrunnings, which made drills. He was a big, beefy \nman with hardly any neck, although he did have a \nvery large mustache...</span></pre><p id="a1d3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这一点上，为了简单起见，我们想要去掉标点符号和<code class="du mi mj mk ma b">\n</code>来逐词清理文本。</p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="2035" class="lk ju hh ma b fi me mf l mg mh"><strong class="ma hi">Regex to match any non alphanumeric character or whitespace, ie punctuation and replacing with empty ''</strong></span><span id="2095" class="lk ju hh ma b fi ml mf l mg mh">punc = re.sub('[^\w\s]', '', string)</span><span id="4a8f" class="lk ju hh ma b fi ml mf l mg mh"><strong class="ma hi">Removing newlines \n and applying lowercase.</strong></span><span id="2fac" class="lk ju hh ma b fi ml mf l mg mh">newlines=re.sub('[\n+]','',punc).lower()    </span></pre><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mm mn l"/></div></figure><p id="609a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的代码将段落转换成类似这样的形式。</p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="696c" class="lk ju hh ma b fi me mf l mg mh">c=Corpus(path) <br/>c.tokenize()</span><span id="a972" class="lk ju hh ma b fi ml mf l mg mh"><strong class="ma hi">2D vector where each element is a sentence. [0,1,2,3] corresponds to "the boy who lived"</strong></span><span id="cbbf" class="lk ju hh ma b fi ml mf l mg mh">--------------------------------------------------------------------</span><span id="bfa3" class="lk ju hh ma b fi ml mf l mg mh">[[], [], [], [], [], [0, 1, 2, 3], [], [4, 5, 6, 7, 8, 9, 10, 11, 12], [13, 14, 15, 16, 17, 18, 13, 19, 20], [21, 22, 23, 24, 18, 13, 0, 25, 26, 27], [28, 15, 29, 30, 31, 32, 33, 34], [35, ...</span></pre><p id="1f31" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每个数字将对应于某个<strong class="ig hi"> d维向量</strong>，模型将学习它的表示。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mo"><img src="../Images/0fffe0c35839944a5d9186ee994bc1ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*lyy8ED9SDqCS3Du9gkjYWA.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">嵌入维数为3的示例</figcaption></figure><p id="4362" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是问题来了</p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="e58e" class="lk ju hh ma b fi me mf l mg mh">df[df.word.str.startswith('brave')]</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mp"><img src="../Images/98661d6e8b5598390553f254af498d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*MuVunFiWuq1O6fioBLc6Kw.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">基础词勇敢</figcaption></figure><p id="5028" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于像<code class="du mi mj mk ma b">brave,bravery,bravely,braver</code>这样的单词，模型假设了独立的嵌入，这可能是对空间的浪费。此外，如果我们的词汇中使用每一个独特的单词，它可能会变得过于庞大。</p><p id="5873" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">还有我避免的标点符号的复杂性。理想情况下，您会希望保留一些标点符号来增加句子的含义。像<code class="du mi mj mk ma b">? </code>这样的字符可以被单独剥离和标记。</p><p id="05be" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">像<code class="du mi mj mk ma b">nltk </code>这样有内置标记器的库处理标点符号的方式如下。</p><p id="9219" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">基于规则的标记化:</strong></p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="1f60" class="lk ju hh ma b fi me mf l mg mh">from nltk.tokenize import word_tokenize<br/>word_tokenize("Do you like this? I don't")</span><span id="c2c6" class="lk ju hh ma b fi ml mf l mg mh">--------------------------------------------------------------</span><span id="c26c" class="lk ju hh ma b fi ml mf l mg mh">['Do', 'you', 'like', 'this', '?', 'I', 'do', "n't"]</span></pre><p id="3412" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意到了吗？是一个单独的令牌。而“不”又分裂为“做”和“不做”。这是由于“不”来源于“不做”。这种分裂通常被称为<code class="du mi mj mk ma b"><strong class="ig hi">rule-based tokenization.</strong></code></p><p id="0caa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">基于标点符号化</strong></p><p id="a753" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果用标点符号分隔，<code class="du mi mj mk ma b">dont</code>将被拆分为<code class="du mi mj mk ma b">don</code>和<code class="du mi mj mk ma b">t</code>，标点符号<code class="du mi mj mk ma b">'</code>将是一个单独的符号。</p><p id="8eb7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所有这些基于单词的分词器都面临着大词汇量的基本问题。如果你加入规则来缩短你的词汇量，比如只取常用词——在测试/生成的时候，你就面临着对<strong class="ig hi">未知词</strong>使用<code class="du mi mj mk ma b">unk</code>标记的问题。</p><blockquote class="mq mr ms"><p id="3ab0" class="ie if ly ig b ih ii ij ik il im in io mt iq ir is mu iu iv iw mv iy iz ja jb ha bi translated">但是有一个简单的解决方法，对吗？人物！至少对于英语来说，字符比单词要少得多。</p></blockquote><h2 id="a838" class="lk ju hh bd jv ll lm ln jz lo lp lq kd ip lr ls kh it lt lu kl ix lv lw kp lx bi translated"><strong class="ak">基于字符的标记化:</strong></h2><p id="147e" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我在这篇文章中已经谈到了一点这个<a class="ae js" rel="noopener" href="/analytics-vidhya/character-awareness-for-language-models-using-cnns-6b1c1a331042">。但是这个想法只是映射到每个字符(或特殊字符&amp;标点符号)并学习每个字符的嵌入。</a></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mw"><img src="../Images/105a101205b895b5ea0f808e10e91254.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JrHEqjeIbFMIiRUW.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">图片来源:【https://blog.floydhub.com/tokenization-nlp/ T21】</figcaption></figure><p id="e3a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如上例所示，模型将分别学习每个角色<code class="du mi mj mk ma b">I s n t.. </code>的表示。这将解决我们最初的两个问题。</p><ol class=""><li id="a77d" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated"><strong class="ig hi"> Vocab size </strong>:我们需要考虑的字符只有几个。我们可以把它们混合起来组成任何单词。</li><li id="a056" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated"><strong class="ig hi">未收录单词</strong>:在纯基于单词的标记化中，有可能在测试时，我们会遇到以前没有见过的单词。例如，如果我们在测试集中有一个像<code class="du mi mj mk ma b">Gobbledygook</code>这样的罕见单词，而不是给它分配<code class="du mi mj mk ma b">unk</code>标记，它会组合所有的单个字符并形成它的一个表示。</li></ol><p id="a465" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是很明显，有问题。就单词而言，每一个代表都有一个意义。单个字符的向量表示真正意味着什么？</p><p id="3d40" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，我们的序列变得不必要的长。对于7个单词的单句，我们的基于单词的记号赋予器将产生7个记号。对于相同的序列，基于字符的记号赋予器将根据单词的大小产生大约35-40个记号。(对于顺序模型，这可能是一个更大的问题，因为我们的输入需要一个接一个地处理。但是现在我们有了变压器，输入被并行处理。)</p><p id="8c20" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我们继续前进到最佳点<code class="du mi mj mk ma b">subword-based tokenization</code>，在这里我们(有点)结合了基于字符和单词级别的标记。</p><h2 id="38b6" class="lk ju hh bd jv ll lm ln jz lo lp lq kd ip lr ls kh it lt lu kl ix lv lw kp lx bi translated"><strong class="ak">基于子词的标记化:</strong></h2><p id="fcdb" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">这里的主要思想是，较罕见的词将被分解成子词，其他的保持原样。例如，语料库中的一个普通单词如<code class="du mi mj mk ma b">Harry</code>将保持原样。像<code class="du mi mj mk ma b">gryffindor</code>这样罕见的词会被分解成子词，比如<code class="du mi mj mk ma b">gr,y,ffin,dor</code></p><p id="914f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你注意到后缀<code class="du mi mj mk ma b">y,r,ly,est,er</code>加在其他单词上可能意味着什么吗？例如，最高/最强有一个共同的后缀est，使其成为最高级。因此，也许学习<code class="du mi mj mk ma b">est</code>的表示法会对我们有所帮助。</p><p id="0d3f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">字节对编码:</strong></p><p id="5a03" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">字节对编码</strong>是一种数据压缩形式，其中数据中最常见的<strong class="ig hi">对连续字节</strong>被替换为该数据中不存在的字节。</p><p id="188d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，如果我们有像<code class="du mi mj mk ma b">bbdcdcae</code>这样的字节</p><ol class=""><li id="b885" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated">看这一对<code class="du mi mj mk ma b">dc repeated twice</code></li><li id="2873" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">我们用X代替cd，所以我们有<code class="du mi mj mk ma b">bbXXae</code></li><li id="c741" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">接下来，我们有一对<code class="du mi mj mk ma b">bb</code>，我们可以用Y、<code class="du mi mj mk ma b">YXXae</code>来代替它</li><li id="5915" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">现在没有对存在，我们可以停止。</li></ol><p id="64dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于使用BPE的标记化，我们应用一个非常相似的算法。</p><ol class=""><li id="da84" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated">从人物词汇开始。</li></ol><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="b24c" class="lk ju hh ma b fi me mf l mg mh">All tokens: dict_keys(['/', '&lt;/w&gt;', 'T', 'H', 'E', 'B', 'O', 'Y', 'W', 'L', 'I', 'V', 'D', 'M', 'r', '.', 'a', 'n', 'd', 's', 'u', 'l', 'e', 'y', ',', 'o', 'f', 'm', 'b', 'P', 'i', 'v', 't', 'w', 'p', 'h', 'c', 'k', '’', 'x', 'g', 'j', 'G', '|', '2', 'S', '-', 'J', 'K', 'R', ';', 'N', 'A', '“', '”', '—', 'F', 'z', '?', '3', '!', 'q', '4', 'C', '5', '6', '(', ')', ':', '7', '8', '9', '1', '0', 'U', '"', '\\', '‘', '•', 'Z', 'Q', '■', "'"])</span><span id="49c7" class="lk ju hh ma b fi ml mf l mg mh">No. of tokens : 83</span></pre><p id="9abe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">计算每个令牌出现的频率。</p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="a330" class="lk ju hh ma b fi me mf l mg mh">....</span><span id="2bb9" class="lk ju hh ma b fi ml mf l mg mh">'c': 6372,            <br/>'d': 16279,              <br/>'e': 41351,              <br/>'f': 6429,</span><span id="b83b" class="lk ju hh ma b fi ml mf l mg mh">....</span></pre><p id="5321" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.根据基本词汇拆分所有单词(目前都是字符)，用标记标记每个单词的结尾(这样后缀和前缀就可以分开，例如，用Real 和algebra 标记。如果al 是标记，那么它一定来自Real )。</p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="fc7f" class="lk ju hh ma b fi me mf l mg mh">T H E &lt;/w&gt; : 17 <br/>B O Y &lt;/w&gt; : 1<br/>W H O &lt;/w&gt; : 1 <br/>L I V E D &lt;/w&gt; : 1<br/>M r . &lt;/w&gt; : 79 <br/>a n d &lt;/w&gt; : 2139 <br/>M r s . &lt;/w&gt; : 44 <br/>D u r s l e y , &lt;/w&gt; : 6 <br/>o f &lt;/w&gt; : 1233 <br/>n u m b e r &lt;/w&gt; : 14<br/>...</span></pre><p id="fadb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.根据当前vocab计算当前单词的<code class="du mi mj mk ma b">pairwise-frequency</code>。</p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="6de0" class="lk ju hh ma b fi me mf l mg mh">('/', '&lt;/w&gt;') : 4 <br/>('T', 'H') : 28 <br/>('H', 'E') : 21 <br/>('E', '&lt;/w&gt;') : 33 <br/>('B', 'O') : 4 <br/>('O', 'Y') : 1 <br/>('Y', '&lt;/w&gt;') : 8 <br/>('W', 'H') : 6 <br/>('H', 'O') : 7 <br/>('O', '&lt;/w&gt;') : 6 <br/>('L', 'I') : 3 <br/>('I', 'V') : 2 <br/>('V', 'E') : 6 <br/>('E', 'D') : 9 <br/>('D', '&lt;/w&gt;')<br/>...</span></pre><p id="dd22" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这两个字母中的每一个都以右边提到的频率重复出现。</p><p id="8f6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.计算具有最大频率的对并合并。将此添加到当前vocab。</p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="e7df" class="lk ju hh ma b fi me mf l mg mh">('e', '&lt;/w&gt;'): 13356 # these will be merged in this case</span><span id="620d" class="lk ju hh ma b fi ml mf l mg mh">All tokens: dict_keys(['/', '&lt;/w&gt;', 'T', 'H', 'E', 'B', 'O', 'Y', 'W', 'L', 'I', 'V', 'D', 'M', 'r', '.', 'a', 'n', 'd', 's', 'u', 'l', 'e', 'y', ',', 'o', 'f', 'm', 'b', 'P', 'i', 'v', 't', 'w', <strong class="ma hi">'e&lt;/w&gt;'</strong>, 'p', 'h', 'c', ...</span><span id="e2df" class="lk ju hh ma b fi ml mf l mg mh">No of tokens: 84</span><span id="f119" class="lk ju hh ma b fi ml mf l mg mh"><strong class="ma hi">Current list of words</strong></span><span id="4792" class="lk ju hh ma b fi ml mf l mg mh">'T h e y &lt;/w&gt;': 155,  <br/>'t h <strong class="ma hi">e&lt;/w&gt;</strong>': 3654,  <br/>'l a s t &lt;/w&gt;': 61,</span></pre><p id="3d6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们可以将e 与其他字符组合成下一对字符。我们还需要重新计算令牌频率</p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="84a9" class="lk ju hh ma b fi me mf l mg mh">...</span><span id="42e8" class="lk ju hh ma b fi ml mf l mg mh">'c': 6372,         <br/>'d': 16279,    <br/>'e': 27995,         <br/>'e&lt;/w&gt;': 13356,     <br/></span><span id="103a" class="lk ju hh ma b fi ml mf l mg mh">...  </span></pre><p id="02eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意<code class="du mi mj mk ma b">e</code>的频率是如何变化的。</p><p id="56e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.重复一遍。选择合并的数量作为一个适合你的超级参数。通过这种方式，经过多次合并后，常用词和子词会保持不变，然后子词可以组合起来形成未知词。</p><p id="f111" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦你有了记号列表，对于一个未知单词，我们可以组合在这个过程中找到的子单词来形成表示。</p><p id="f4c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">词块:</strong></p><p id="a4f9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦你了解了BPE，只需要做一些小小的调整就可以学习WordPiece了。这是最近最成功的NLP论文之一BERT中使用的标记化方法。</p><p id="b437" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">主要的区别在于合并令牌的想法。在BPE，我们只取最频繁的一对&amp;合并它。</p><p id="1288" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相比之下，wordpiece只有在增加训练数据的可能性时才会合并。例如，如果“er”比e &amp; r更可能出现，则它们被合并。你可以在这里阅读更多关于这个<a class="ae js" href="https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/37842.pdf" rel="noopener ugc nofollow" target="_blank">的内容。</a></p><pre class="jd je jf jg fd lz ma mb mc aw md bi"><span id="3588" class="lk ju hh ma b fi me mf l mg mh">from transformers import BertTokenizer<br/>tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")<br/>tokenizer.tokenize("Slytherin is the best house ever!")</span><span id="387c" class="lk ju hh ma b fi ml mf l mg mh">Output:<br/>['sly', '##ther', '##in', 'is', 'the', 'best', 'house', 'ever', '!']</span></pre><p id="8112" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du mi mj mk ma b">##</code>表示单词不是以<code class="du mi mj mk ma b">ther</code>开头的。“Syltherin”在伯特的字典里是一个陌生的词。但是它有对应于#ther，##in &amp; sly的令牌。因此，它用它知道的记号来分解这个词。</p><p id="fe72" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">资源:</strong></p><ol class=""><li id="c5bb" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated"><a class="ae js" href="https://huggingface.co/transformers/tokenizer_summary.html" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/transformers/tokenizer_summary.html</a></li><li id="ad73" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated"><a class="ae js" href="https://blog.floydhub.com/tokenization-nlp/" rel="noopener ugc nofollow" target="_blank">https://blog.floydhub.com/tokenization-nlp/</a></li><li id="af32" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated"><a class="ae js" href="https://leimao.github.io/blog/Byte-Pair-Encoding/" rel="noopener ugc nofollow" target="_blank">https://leimao.github.io/blog/Byte-Pair-Encoding/</a></li></ol></div></div>    
</body>
</html>