<html>
<head>
<title>Unsupervised Learning — A Complete Overview</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无监督学习——全面概述</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/unsupervised-learning-a-complete-overview-b433267e1c2a?source=collection_archive---------9-----------------------#2021-03-28">https://medium.com/analytics-vidhya/unsupervised-learning-a-complete-overview-b433267e1c2a?source=collection_archive---------9-----------------------#2021-03-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h2 id="76bf" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">无监督机器学习的完整概述</h2><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es jj"><img src="../Images/6e318f37cfa4f5d514fd72ea5a71cb0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EdumQQiYH_gU5Z8uaUz1yQ.jpeg"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated"><a class="ae jz" href="http://www.linkedin.com/in/ronil08" rel="noopener ugc nofollow" target="_blank">作者</a></figcaption></figure><h1 id="aa75" class="ka im hh bd in kb kc kd ir ke kf kg iv kh ki kj iz kk kl km jd kn ko kp jh kq bi translated">介绍</h1><blockquote class="kr ks kt"><p id="917f" class="ku kv kw kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls ha bi translated">这是一种机器学习技术，其中模型本身从数据中找到隐藏的模式和见解，而不是从训练数据集学习(如在监督学习中)。它基于一些相似性创建组，甚至不知道每个组代表什么。在这篇文章中，我不会简单地解释每一件事情，我只会给出一个关于不同类型的无监督学习的简短概述。大多数时候人们问我什么是无监督学习，有多少种类型，我谷歌了一下，但没有得到这个问题的完美答案，这只是我写这篇文章的座右铭。</p><p id="281c" class="ku kv kw kx b ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr ls ha bi translated"><strong class="kx hi">例如:</strong>假设我们有一组学生属于不同的大学，我们必须根据一些特征对他们进行分组，现在我们将这一职责交给无监督算法。现在我们不知道无监督学习算法到时会如何分组。它可能会根据他们的制服、身高或发型对他们进行分组。以同样的方式，无监督算法寻找隐藏的模式或相似性，并将它们分组。</p></blockquote><h2 id="e058" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">无监督学习的类型:</h2><ul class=""><li id="b67d" class="lt lu hh kx b ky lv lc lw iw lx ja ly je lz ls ma mb mc md bi translated"><strong class="kx hi">聚类</strong></li><li id="43a2" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">关联</strong></li><li id="75a4" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">降维</strong></li></ul><p id="0642" class="pw-post-body-paragraph ku kv hh kx b ky kz la lb lc ld le lf iw lh li lj ja ll lm ln je lp lq lr ls ha bi translated">现在让我们看一下它的概况。</p><ol class=""><li id="e39f" class="lt lu hh kx b ky kz lc ld iw mj ja mk je ml ls mm mb mc md bi translated"><strong class="kx hi">聚类:</strong>在这种类型的无监督学习中，使用不同的算法，我们可以根据数据中存在的一些相似性或隐藏模式将数据分组为聚类。一些聚类算法是:</li></ol><ul class=""><li id="e50d" class="lt lu hh kx b ky kz lc ld iw mj ja mk je ml ls ma mb mc md bi translated"><strong class="kx hi"> K均值聚类</strong></li><li id="6959" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">数据库扫描</strong></li><li id="383e" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">层次聚类</strong></li><li id="7716" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">桦树</strong></li><li id="a9a9" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">亲和繁殖</strong></li><li id="56b6" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">凝聚聚类</strong></li><li id="f0a5" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">小批量K均值</strong></li><li id="3aaf" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">光学</strong></li><li id="9a09" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">均值漂移</strong></li><li id="2475" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">光谱聚类</strong></li><li id="7a4d" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">高斯混合</strong></li></ul><p id="aba1" class="pw-post-body-paragraph ku kv hh kx b ky kz la lb lc ld le lf iw lh li lj ja ll lm ln je lp lq lr ls ha bi translated">2.<strong class="kx hi">关联:</strong>它是机器学习的一个重要概念，也是另一种类型的无监督学习，在这种学习中，它发现我们数据中的特征或变量之间的关系，或者我们可以说，它检查我们数据中一个特征对另一个特征的依赖性。它主要用于购物篮数据分析、交叉营销、Web使用挖掘和入侵检测等。一些关联算法是:</p><ul class=""><li id="82fd" class="lt lu hh kx b ky kz lc ld iw mj ja mk je ml ls ma mb mc md bi translated"><strong class="kx hi"> Apriori算法</strong></li><li id="4fa6" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi"> F-P增长算法</strong></li><li id="ba19" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi"> Eclat算法</strong></li></ul><p id="8588" class="pw-post-body-paragraph ku kv hh kx b ky kz la lb lc ld le lf iw lh li lj ja ll lm ln je lp lq lr ls ha bi translated">3.维度缩减:这是另一种无监督学习，我们的任务是简化我们的数据，用更少的特征来描述它，同时又不失一般性。这是一个非常有用的预处理步骤，我们可以在应用不同的算法之前应用它来简化我们的数据，从而提高我们模型的精度。<strong class="kx hi"> </strong>降维技术在不损失太多信息的情况下移除冗余和不相关的特征，因为更多的输入特征使得我们的模型的预测任务更具挑战性，这导致大规模过拟合的风险。降维有两个组成部分:</p><ol class=""><li id="0fdc" class="lt lu hh kx b ky kz lc ld iw mj ja mk je ml ls mm mb mc md bi translated"><strong class="kx hi">功能选择</strong></li><li id="5e25" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls mm mb mc md bi translated"><strong class="kx hi">特征提取</strong></li></ol><p id="2e20" class="pw-post-body-paragraph ku kv hh kx b ky kz la lb lc ld le lf iw lh li lj ja ll lm ln je lp lq lr ls ha bi translated">一些<strong class="kx hi">特征选择方法</strong>(不同的技术在该方法下分类)是:</p><ul class=""><li id="30c1" class="lt lu hh kx b ky kz lc ld iw mj ja mk je ml ls ma mb mc md bi translated"><strong class="kx hi">过滤方法</strong></li><li id="dd12" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">包装方法</strong></li><li id="9cbc" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">混合方法</strong></li><li id="7d31" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">嵌入方法</strong></li></ul><p id="3590" class="pw-post-body-paragraph ku kv hh kx b ky kz la lb lc ld le lf iw lh li lj ja ll lm ln je lp lq lr ls ha bi translated"><strong class="kx hi"> <em class="kw">特征选择方法中可用的不同技术:</em> </strong></p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es mn"><img src="../Images/541c2b27a367452dd3550bbb646cac95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YhyfP23JrGtiXqfabsl8jw.jpeg"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">特征选择方法</figcaption></figure><p id="d2e9" class="pw-post-body-paragraph ku kv hh kx b ky kz la lb lc ld le lf iw lh li lj ja ll lm ln je lp lq lr ls ha bi translated">一些<strong class="kx hi">特征提取方法</strong>有:</p><ul class=""><li id="bbdf" class="lt lu hh kx b ky kz lc ld iw mj ja mk je ml ls ma mb mc md bi translated"><strong class="kx hi">主成分分析</strong></li><li id="7a77" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">线性判别分析</strong></li><li id="6fb8" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">广义判别分析</strong></li><li id="a710" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">随机投影</strong></li><li id="de90" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">独立成分分析</strong></li><li id="40f8" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi">局部线性嵌入(LLE) </strong></li><li id="be29" class="lt lu hh kx b ky me lc mf iw mg ja mh je mi ls ma mb mc md bi translated"><strong class="kx hi"> t分布随机邻居嵌入(t-SNE) </strong></li></ul><h1 id="6fac" class="ka im hh bd in kb kc kd ir ke kf kg iv kh ki kj iz kk kl km jd kn ko kp jh kq bi translated">摘要</h1><p id="c140" class="pw-post-body-paragraph ku kv hh kx b ky lv la lb lc lw le lf iw mo li lj ja mp lm ln je mq lq lr ls ha bi translated">在本文中，我们讨论了不同类型的无监督学习及其类型。假设你想学习无监督学习的概念，那么这篇文章肯定会帮助你以循序渐进的方式涵盖无监督学习的概念。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="d4c5" class="pw-post-body-paragraph ku kv hh kx b ky kz la lb lc ld le lf iw lh li lj ja ll lm ln je lp lq lr ls ha bi translated">感谢您的阅读！如果您有任何建议或问题，请不要犹豫，在下面评论或在LinkedIn上ping我。请在LinkedIn 上联系我，如果您有任何疑问，请随时提问。</p></div></div>    
</body>
</html>