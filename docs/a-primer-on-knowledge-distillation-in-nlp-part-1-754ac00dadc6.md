# 自然语言处理中的知识蒸馏入门——第一部分

> 原文：<https://medium.com/analytics-vidhya/a-primer-on-knowledge-distillation-in-nlp-part-1-754ac00dadc6?source=collection_archive---------0----------------------->

近年来，深度神经网络在各种自然语言处理(NLP)任务上取得了令人印象深刻的性能，然而，高计算和存储要求对其在现实世界应用中的部署提出了巨大的挑战，特别是在资源有限的设备上，如手机。为此，已经开发了各种模型压缩和加速技术。一种这样的技术是知识提炼，它可以有效地从一个大的**老师**模型中学习一个小的**学生**模型。在这一系列文章中，我们将首先研究…