<html>
<head>
<title>Text to Numerical Vector Conversion Techniques</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本到数字矢量转换技术</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/text-to-numerical-vector-conversion-techniques-f2b97ab9b895?source=collection_archive---------5-----------------------#2021-06-28">https://medium.com/analytics-vidhya/text-to-numerical-vector-conversion-techniques-f2b97ab9b895?source=collection_archive---------5-----------------------#2021-06-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="fd48" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个现代计算的时代，今天有海量的数据可用，并且通过各种方式每秒钟都在增加，如“脸书评论”、“推特上的推文”、“WhatsApp聊天”、“电子邮件”、“博客”、“谷歌搜索”以及你能想到的许多其他方式。</p><p id="0a8e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在机器学习中，数据起着至关重要的作用。我们需要在大量数据的基础上训练一个模型，然后对看不见的数据进行评估。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/4a721fbd0eb0b73c4eb562d397a1583c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*17-GgNl8Ty7Uw2uJLxy-dg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated"><a class="ae js" href="https://www.thetalkingmachines.com/sites/default/files/styles/widescreen_large/public/2019-05/34_binary_space_data.jpg?itok=fYxXjksG" rel="noopener ugc nofollow" target="_blank">图像来源</a></figcaption></figure></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="a69e" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">目录</h1><ol class=""><li id="6cf0" class="ky kz hh ig b ih la il lb ip lc it ld ix le jb lf lg lh li bi translated"><a class="ae js" href="#9389" rel="noopener ugc nofollow">先决条件</a></li><li id="5291" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#5ba2" rel="noopener ugc nofollow">不同形式的数据</a></li><li id="9225" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#26bc" rel="noopener ugc nofollow">不同类型的数据</a></li><li id="89dd" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#a3d9" rel="noopener ugc nofollow">需要将数据转换为数字数据/矢量</a></li><li id="0203" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#96f0" rel="noopener ugc nofollow">将数据转换为数值数据/向量的嵌入技术</a> <br/>一.<a class="ae js" href="#0fb4" rel="noopener ugc nofollow">文字包(BoWs) </a> <br/>二、<a class="ae js" href="#c411" rel="noopener ugc nofollow">词频-倒排文档频率(TF-IDF) </a> <br/> iii。<a class="ae js" href="#e207" rel="noopener ugc nofollow"> Word2Vec </a> <br/> iv。<a class="ae js" href="#3771" rel="noopener ugc nofollow"> Doc2Vec </a></li><li id="a254" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#bb44" rel="noopener ugc nofollow">总结</a></li><li id="81e6" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#376d" rel="noopener ugc nofollow">参考文献</a></li></ol></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="9389" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">先决条件</h1><ol class=""><li id="740c" class="ky kz hh ig b ih la il lb ip lc it ld ix le jb lf lg lh li bi translated">基础数学</li><li id="a03f" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">机器学习中特征的基础知识。</li></ol></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="5ba2" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">不同形式的数据</h1><p id="9f0c" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">数据可以以任何形式存在。、文本、音频、视频和图像。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lr"><img src="../Images/0cc46421e5d53c0a075adbea44e1be0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8LzecyVHLx8Oq27fvjMzdQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated"><a class="ae js" href="https://techblogwriter.co.uk/wp-content/uploads/2016/01/text-video-audio-and-images..png" rel="noopener ugc nofollow" target="_blank">图像来源</a></figcaption></figure></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="26bc" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">不同类型的数据</h1><p id="8b00" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">上述任何形式的数据都可以大致分为四种主要类型，任何机器学习模型都可以依赖这四种类型。这些类型是:</p><ol class=""><li id="ce63" class="ky kz hh ig b ih ii il im ip ls it lt ix lu jb lf lg lh li bi translated"><strong class="ig hi">数值数据</strong></li><li id="0acf" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi">分类数据</strong></li><li id="dcad" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi">时间序列数据</strong></li><li id="7ccf" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi">文本数据。</strong></li></ol><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lv"><img src="../Images/2b740b64c0d1e935a61764977b272918.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bgsaKzWUeReVqtgE17NAGg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">广泛的数据类别</figcaption></figure><p id="822d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我简单介绍一下这些数据类型:</p><ol class=""><li id="ff28" class="ky kz hh ig b ih ii il im ip ls it lt ix lu jb lf lg lh li bi translated"><strong class="ig hi">数字数据</strong>或<strong class="ig hi">定量数据</strong>:任何形式的可测量数据，如你的身高、体重或手机价格。<br/>一、<strong class="ig hi">连续</strong>:可以取身高、体重、温度等范围内任意值的数值型数据。<br/>二。<strong class="ig hi">离散</strong>:只能取不同值的数字数据，如员工/学生人数、售出单位等。</li><li id="f0b5" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi">分类数据</strong>:可以统计的任何种类，如性别、城市、州、国家等。<br/>一、<strong class="ig hi">名义上的</strong>:可计数但不可排序的分类数据，如性别、发色、手机品牌等。<br/>二。<strong class="ig hi">序数</strong>:可以计数也可以排序的分类数据，比如IMDB电影评分(1-10)、酒店星级等。</li><li id="f704" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi">时间序列数据</strong>:由特定时间点索引的数据点组成的任何数据，如股票价格、<a class="ae js" href="https://en.wikipedia.org/wiki/Electrocardiography" rel="noopener ugc nofollow" target="_blank">心电图</a>、天气状况等。</li><li id="e503" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi">文本数据</strong>:文本数据是简单的单词、句子或段落，可以提供一些见解，如产品评论、脸书评论等。</li></ol></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="a3d9" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">需要将数据转换为数字数据/矢量</h1><p id="059d" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">许多机器模型要求数据以数字格式呈现。</p><p id="16af" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你想知道吗？"<em class="lw">为什么我们需要在将任何数据输入到机器学习模型之前将其转换为数字数据？</em></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lx"><img src="../Images/f5977996346caf270328892b2bc1f9be.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*8r5pYRf3DI4BUXtupyqaag.png"/></div></figure><p id="f067" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">嗯，机器学习模型包括在引擎盖下执行各种数学运算。就像人类需要氧气，数学需要数字。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ly"><img src="../Images/ae50a27c9359fd7f3c3d5f24d017b843.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*uuGtQGjoLXHy_uMcXrHWRQ.png"/></div></figure><p id="5a4c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数字数据已经有数字，不需要任何转换。<br/>在本文中，我们将主要关注将文本数据转换成数字向量。</p><h2 id="00b8" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated"><strong class="ak">嵌入</strong></h2><p id="f134" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">文本数据转换成矢量的过程称为<strong class="ig hi">嵌入</strong>。</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><p id="8029" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们研究将文本转换成数字向量的各种技术之前，让我们先了解一些术语:</p><ol class=""><li id="3f6f" class="ky kz hh ig b ih ii il im ip ls it lt ix lu jb lf lg lh li bi translated"><a class="ae js" href="#347d" rel="noopener ugc nofollow"> <strong class="ig hi">矢量</strong> </a></li><li id="7432" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#54ce" rel="noopener ugc nofollow"> <strong class="ig hi">文件</strong> </a></li><li id="a833" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#95cf" rel="noopener ugc nofollow"> <strong class="ig hi">文集</strong> </a></li><li id="03be" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#f45f" rel="noopener ugc nofollow"> <strong class="ig hi">令牌</strong> </a></li><li id="a0b9" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#9dc1" rel="noopener ugc nofollow"> <strong class="ig hi">词汇</strong> </a></li></ol><h2 id="347d" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">矢量</h2><p id="79b6" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">在物理学中，矢量是一个有大小和方向的实体。例如，汽车的速度。</p><p id="2819" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在计算机科学中，向量只不过是一个或多个数字的集合。向量中的每个数字代表向量在特定维度上的大小。<br/>例如，三维空间中的向量可以由三个数字表示为v = [2，1，3]:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mn"><img src="../Images/f72213d4625d0194ef156b186ed3c226.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*b4z2dLcLA-APVOGUGWr-xg.png"/></div></figure><h2 id="54ce" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">文件</h2><p id="d23a" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">文档是代表特定事实或实体的句子的集合。文档的例子包括产品评论、博客、推文或软件生成的日志文件。</p><h2 id="95cf" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">文集</h2><p id="3ecd" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">语料库是文档的集合。语料库中的文档是相互关联的。例如，语料库可以包括一个月内给定产品的所有评论、IMDB平台中所有电影的评论或者脸书用户的所有脸书评论。</p><p id="3790" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">仅供参考:语料库的复数形式称为<strong class="ig hi">语料库</strong>。</p><h2 id="f45f" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">代币</h2><p id="6ab9" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">标记是自然语言的组成部分。它指的是文本被分成的单元。获得令牌的过程称为<strong class="ig hi">令牌化</strong>。</p><p id="399c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有不同类型的标记化:</p><ol class=""><li id="9109" class="ky kz hh ig b ih ii il im ip ls it lt ix lu jb lf lg lh li bi translated"><strong class="ig hi">单词标记化</strong>:根据文本中的单词分割文本的标记化。</li><li id="c364" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi">字符标记化</strong>:根据文本中的字符分割文本的标记化。<br/>在本文中，我们不会深入探讨字符标记化的细节。</li><li id="ff0f" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi"> n-gram记号化</strong>:记号化是通过基于文本中的n个连续单词来分割文本来完成的。</li></ol><h2 id="9dc1" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">词汇</h2><p id="3237" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">词汇表是语料库中所有独特单词/标记的集合。</p><p id="4882" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看下图来理解上述术语:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mo"><img src="../Images/d7e51a94d777664e910aca92295ca1dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jeKMXYsTtKlC2mzHIf17fQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">文档、语料库、标记和词汇</figcaption></figure><p id="39ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">请注意，我们将使用上述文档的示例来理解不同的文本嵌入技术。</strong></p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="96f0" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">将数据转换成数字数据/向量的嵌入技术</h1><p id="f681" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">让我们看看如何将文本转换成数字向量。我们将讨论一些将文本转换成数字向量的标准技术。</p><p id="b0a0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是一些文本嵌入技术:</p><ol class=""><li id="6224" class="ky kz hh ig b ih ii il im ip ls it lt ix lu jb lf lg lh li bi translated"><a class="ae js" href="#0fb4" rel="noopener ugc nofollow"> <strong class="ig hi">包字(弓)</strong> </a> <strong class="ig hi"> <br/>一、单克弓<br/>二。双克弓<br/>三世。三克弓<br/>四。n字弓</strong></li><li id="4306" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#c411" rel="noopener ugc nofollow"> <strong class="ig hi">词频-倒排文档频率(TF-IDF) </strong> </a></li><li id="9d4c" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#e207" rel="noopener ugc nofollow"><strong class="ig hi">word 2 vec</strong></a><strong class="ig hi"><br/>一、</strong> <a class="ae js" href="#f1d9" rel="noopener ugc nofollow"> <strong class="ig hi">平均Word2Vec </strong> </a> <strong class="ig hi"> <br/>二。</strong><a class="ae js" href="#a9e1" rel="noopener ugc nofollow"><strong class="ig hi">TF-IDF word 2 vec</strong></a></li><li id="6510" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><a class="ae js" href="#3771" rel="noopener ugc nofollow"> <strong class="ig hi"> Doc2Vec </strong> </a></li></ol><h1 id="0fb4" class="ka kb hh bd kc kd mp kf kg kh mq kj kk kl mr kn ko kp ms kr ks kt mt kv kw kx bi translated">单词袋(蝴蝶结)</h1><p id="4435" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">单词袋模型，简称BoW，是一种非常简单而灵活的将文本表示为数字向量的技术。<br/>这涉及到两件事:</p><ol class=""><li id="9c6c" class="ky kz hh ig b ih ii il im ip ls it lt ix lu jb lf lg lh li bi translated">已知单词的词汇表。</li><li id="649a" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">已知单词存在的度量。</li></ol><p id="7b51" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">想象一个袋子，里面有9个不同的球，每个球都被标记为词汇表中的独特单词。正如我们前面看到的，对于我们的语料库，词汇表中有一组9个独特的单词。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mu"><img src="../Images/7dee71ffac15e225d6ce933836e2b7d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X5qVzeNFzhkjdbKtMGSoeQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">弓概念的插图</figcaption></figure><p id="ec82" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这9个独特的球代表了可以表示数字向量的所有维度。</p><p id="b569" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">要将文档表示为一个向量，我们需要根据词汇表标记文档中每个单词的出现次数(频率),如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mv"><img src="../Images/01ce50e8ec79575b9f4b80827e646e7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L7B_vZnzYI-bU43V2w0tbQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">BoWs表为所有四个文件</figcaption></figure><p id="43d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从上表中，我们可以通过将数字集合(按行)写成:<br/>文档1的向量:[1，0，0，0，0，1，0，1，1，1] <br/>文档2的向量:[0，0，0，0，1，1，1，0，2] <br/>文档3的向量:[1，1，0，1，0，1，0] <br/>文档4的向量:[1，0，1，0，0，0，0，0，0</p><h2 id="286a" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">二进制单词包</h2><p id="0bd2" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">除了使用出现次数，我们还可以使用1或0来表示该单词是否出现在文档中。<br/>如果我们使用1或0来检查单词是否出现，BoWs的这种实现被称为<strong class="ig hi">二进制单词包</strong>。</p><h2 id="a97f" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">一袋n-克</h2><p id="ef26" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">一袋n-grams是一袋单词的延伸。在n-gram BoWs中，我们将n个连续的单词作为令牌。我们在上面的例子中看到的是单克弓。</p><ol class=""><li id="b402" class="ky kz hh ig b ih ii il im ip ls it lt ix lu jb lf lg lh li bi translated"><strong class="ig hi">单克或1克弓</strong>:令牌由单个单词组成。我们上面讨论的例子是单字弓。</li><li id="4de7" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi">双克或双克弓</strong>:代币由两个连续的单词组成。例如，对于文档1(你创造了你的生活)，令牌将是{“你创造了”，“创造了你的”，“你的生活”}。<br/>类似地，语料库将包含具有不同的两个连续单词的记号。</li><li id="05c6" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi">三克或三克弓</strong>:代币由三个连续的单词组成。<br/>同样，这个概念可以扩展到生成n-grams弓。</li></ol><p id="3f1b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看看使用二元弓的数字向量:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mw"><img src="../Images/84c4da42b049811187bdd0f88072fc7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JldAiqecWWoOBGwdIwL-yA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">二元语法标记化</figcaption></figure><p id="0098" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了将文本表示为向量，我们可以将两个连续单词的出现次数写在相应的标记上:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mx"><img src="../Images/784eec78fadca4c95142c63f5ba09bc9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*24MfLn7-VKYiniPp92G4Ow.png"/></div></div></figure><p id="b432" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于上表，我们可以通过将数字集合(按行)写成如下形式将文档表示为向量:<br/>文档1的向量:[1，1，1，0，0，0，0，0，0，0] <br/>文档2的向量:[0，0，1，1，1，1，1，0，0] <br/>文档3的向量:[1，0，0，0，0，0，0，0，1，1，0] <br/>文档4的向量:[1，1</p><p id="9666" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样，我们可以做三元弓和二元弓。</p><p id="1573" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一袋n-grams可能比一袋unigrams信息量更大，因为它们捕捉了每个单词周围的更多上下文(例如，“创造你的生活”比“生活”信息量更大)。</p><p id="86dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">BoWs可用于<strong class="ig hi">分类</strong>和<strong class="ig hi">文本</strong>数据。</p><h2 id="320c" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">使用词汇袋的缺点</h2><ol class=""><li id="6ffa" class="ky kz hh ig b ih la il lb ip lc it ld ix le jb lf lg lh li bi translated">BoWs依赖于字数统计，并且丢弃了文档的语义。</li><li id="47fa" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">词汇表的大小会随着新文档的加入而增加。</li><li id="0f85" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">对于一个文档来说，向量将包含太多的零，导致矩阵稀疏。因此，它用更少的信息消耗更多的内存。</li><li id="802b" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">不保留关于文档语法或文本中单词顺序的信息。</li></ol><h1 id="c411" class="ka kb hh bd kc kd mp kf kg kh mq kj kk kl mr kn ko kp ms kr ks kt mt kv kw kx bi translated">术语频率-逆文档频率(TF-IDF)</h1><p id="5f08" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">TF-IDF是Term Frequency-Inverse Document Frequency的缩写，在<a class="ae js" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"> Wikipedia </a>中定义为“旨在反映一个词对集合或语料库中的文档有多重要的数字统计”。</p><p id="a081" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是另一种将文本转换成数字向量的技术。</p><p id="1e52" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们了解TF-IDF如何工作之前，让我们先分别了解一下TF和IDF这两个单独的术语。</p><h2 id="d0ce" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">术语频率(TF)</h2><p id="4794" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">单词的词频是单词在文档中的频率的度量。<br/> TF由下式定义:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es my"><img src="../Images/7cc682b4a9c8ec02dcf18ac351edd6a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*QNajp_DGkKL-5VjGbUI4uQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">词频公式</figcaption></figure><p id="8a3a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于词频介于0和1之间，因此可以解释为概率。<br/>因此，TF也可以定义为:<br/> i .在文档中找到一个单词的概率。<br/>二。单词在文档中出现的频率。</p><h2 id="e188" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">反向文档频率(IDF)</h2><p id="a142" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">IDF是衡量一个词有多重要的指标。<br/> IDF由以下公式定义:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mz"><img src="../Images/134aee5a203d577aed44ed5bebef567d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*3PUtJEz6KioVCVU_8T2-FQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">逆文档频率公式</figcaption></figure><p id="c655" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于对数函数是<a class="ae js" href="https://en.wikipedia.org/wiki/Monotonic_function" rel="noopener ugc nofollow" target="_blank">单调递增函数</a>，所以单词的IDF值与具有给定单词的文档数量成反比。<br/>因此，如果一个词在语料库中出现的频率越低，它的IDF值就越大。在BoWs中，我们通过用单词出现的次数填充维度来创建向量。<br/>在TF-IDF中，我们通过将单词的术语频率和逆文档频率相乘来创建向量。请参见下表中使用TF-IDF值的单词:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es na"><img src="../Images/00d38f46e3759a83a8a514137b57ee58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8MUjxhly8t7FQ95bq7B-aw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">TF-IDF计算</figcaption></figure><p id="46fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从上表中，我们可以通过将单词的TF-IDF值(按行)写成如下来将文档表示为向量:<br/>文档1的向量:[0.03，0.00，0.00，0.00，0.00，0.03，0.00，0.03，0.03] <br/>文档2的向量:[0.00，0.00，0.00，0.00，0.00，0.12，0.02，0</p><p id="ca6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在TF-IDF中，对文档中频繁出现的词以及语料库中罕见的词给予更多的重视。<br/>我们甚至可以仅使用逆文档频率单独生成取决于问题的向量。</p><h2 id="34dc" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">TF-IDF的优势</h2><p id="6fbf" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">它包含了更重要的单词和不太重要的单词的信息。</p><h2 id="d516" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">TF-IDF的缺点</h2><p id="bbdb" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">像BoWs一样，TFIDF不考虑语义。</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="e207" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">Word2Vec</h1><p id="d1b5" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">Word2Vec或<strong class="ig hi"> Word to Vector </strong>，也表示为<strong class="ig hi"> W2V </strong>，是一种最先进的(SOTA)技术，通过考虑单词的语义来将单词转换为向量，不同于BoWs和TF-IDF。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es nb"><img src="../Images/8a696e0584da33eeef2125f86006cde6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*1xavsXIqsHdjOLuftniK0w.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">Word2Vec模型:输入和输出</figcaption></figure><p id="ba3a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Work2Vec使用神经网络模型从大型文本语料库中学习单词关联。<br/>我们不会详细讨论Word2Vec是如何实现的，因为它需要一套不同于深度学习的高级概念，并且会偏离本文的意图。<br/>为了简单起见，我们将它视为本文的黑盒。</p><p id="628d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用Word2Vec，一个单词被转换成一个数字密集向量(不是在BoW和TF-IDF中检索的稀疏向量), d维通常为50、100、200、300等。<br/>如果两个词语义相似，那么这些词的向量在几何上更接近。例如，如果我们有三个词:美味、可口和棒球。在Word2Vec转换之后，单词的向量即、“好吃”和“好吃”在d维空间会比较近，而“棒球”这个词的向量会比较远。</p><h2 id="c8ba" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">Word2Vec要点</h2><p id="e904" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">如果两个单词语义相似，那么它们的向量会更接近。<br/> W2V保留/满足国王::王后、男人::女人、国家::首都等词之间的关系。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es nc"><img src="../Images/286b4738a3818d5eb341fab329efffd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h0m2VIiG_LxcEPMOEZnbtw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">Word2Vec中的语义关系</figcaption></figure><p id="6fbc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以直接使用任何预先训练好的Word2Vec模型。例如，我们可以使用谷歌在谷歌新闻数据上训练的Word2Vec模型，该模型包含1000亿个单词的300维向量。<br/>预先训练好的模型无非是一个包含记号及其相关词向量的文件。</p><p id="37d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我们看到的，Word2Vec将单词转换成向量，而不是将文档(句子)转换成向量。文档是单词/句子的集合。我们需要将文档转换成向量。<br/>我们可以通过两种方式将文档转换为矢量:</p><ol class=""><li id="f1d9" class="ky kz hh ig b ih ii il im ip ls it lt ix lu jb lf lg lh li bi translated"><strong class="ig hi">平均Word2Vec </strong> : <br/>在平均Word2Vec中，我们取文档中所有单词的平均Word2Vec值来得到文档的向量。<br/>利用Word2Vec概念构建文本向量是一种简单的方法。平均Word2Vec工作得相当好，但并不完美。</li><li id="a9e1" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated"><strong class="ig hi">TF-IDF Word2Vec</strong>:<br/>TF-IDF加权word 2 vec是基于TF-IDF值的单词的加权平均值。</li></ol><p id="b257" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">平均加权Word2Vec和TF-IDF加权Word2Vec的公式如下:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es nd"><img src="../Images/336c4c2fbf9cd016dfc8f5afb76add00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*OygCfTj34o0SMBH9uwTtzQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">平均Word2Vec和TF-IDF Word2Vec的公式</figcaption></figure><h2 id="9725" class="lz kb hh bd kc ma mb mc kg md me mf kk ip mg mh ko it mi mj ks ix mk ml kw mm bi translated">平均Word2Vec的缺点</h2><p id="4f03" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">由于我们的目的是将文本转换成数字向量，对Word2Vec的单词进行平均是捕捉句子信息的一种非常幼稚的方法。</p><p id="ca93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">TF-IDF加权Word2Vec优于简单平均Word2Vec，因为它根据单词的重要性进行加权。</p><p id="f00e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">尽管如此，这两种技术并不是将文本转换成向量的最佳方式，因为当我们平均时，我们固有地丢失了信息。</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="3771" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">Doc2Vec</h1><p id="0cc2" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">我们大概可以根据它的名字猜出这个技术。Doc2Vec代表<strong class="ig hi">文档到矢量</strong>。<br/>这种技术不是为每个单词创建一个向量，然后取平均值来找到文本的向量表示，而是为每个文档或文本集合创建一个向量。</p><p id="6aea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">目标和Word2Vec一样。<br/>正如Word2Vec预训练模型一样，我们也有在维基百科或谷歌新闻等非常大的文本语料库上训练的预训练Doc2Vec模型。</p><p id="28fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Doc2Vec模型的美妙之处在于它减少了Word2Vec模型中的整合步骤。<br/>我们可以直接将文档传递给Doc2Vec模型，并获得它的向量表示。</p><p id="f9de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一个比Word2Vec更容易用于机器学习的过程。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ne"><img src="../Images/2e18d5e060b81a70ede5458f0aff352c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*mPjfWl8NPyGeuLJ4SW7qWQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">Doc2Vec模型:输入和输出</figcaption></figure></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="bb44" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">摘要</h1><p id="8fce" class="pw-post-body-paragraph ie if hh ig b ih la ij ik il lb in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">这些是将文本转换成数字向量的一些基本技术，可以用作机器学习中的特征化技术。</p><p id="c668" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">人们还可以探索一些高级嵌入技术，如<a class="ae js" href="https://arxiv.org/abs/1803.11175" rel="noopener ugc nofollow" target="_blank">通用语句编码器</a>、<a class="ae js" href="https://keras.io/api/layers/core_layers/embedding/" rel="noopener ugc nofollow" target="_blank">神经网络中的嵌入层</a>、<a class="ae js" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> BERT </a>等。</p><p id="50fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我总结一下通过思维导图学到的不同技巧:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es nf"><img src="../Images/fd83efda9fb38208b875ec7e31d96c87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u_TnSMxld2pYGwclt_bx1Q.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">本文中涉及的不同嵌入技术的思维导图</figcaption></figure></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="376d" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">参考</h1><ul class=""><li id="9379" class="ky kz hh ig b ih la il lb ip lc it ld ix le jb ng lg lh li bi translated">https://algorithm ia . com/blog/the-importance-of-machine-learning-data</li><li id="aa2f" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb ng lg lh li bi translated"><a class="ae js" href="https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2020/02/quick-introduction-bag-of-words-bow-TF-IDF</a></li><li id="a282" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb ng lg lh li bi translated"><a class="ae js" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Word2vec</a></li><li id="1e2c" class="ky kz hh ig b ih lj il lk ip ll it lm ix ln jb ng lg lh li bi translated"><a class="ae js" href="https://en.wikipedia.org/wiki/Main_Page" rel="noopener ugc nofollow" target="_blank">维基百科</a></li></ul></div></div>    
</body>
</html>