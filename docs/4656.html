<html>
<head>
<title>Understanding Dimensional Reduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解维度缩减</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-dimensional-reduction-321d4f1f770d?source=collection_archive---------2-----------------------#2021-12-14">https://medium.com/analytics-vidhya/understanding-dimensional-reduction-321d4f1f770d?source=collection_archive---------2-----------------------#2021-12-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="618a" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">什么是降维？</strong></h1><ol class=""><li id="8efc" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">降维指的是减少数据集中输入变量/特征数量的技术。</li><li id="9d65" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">将数据集的要素数量从D更改为D '，使得D &gt;= D '</li></ol><h1 id="f723" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">我们为什么需要降维？</strong></h1><ol class=""><li id="3955" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated"><strong class="je hi">维度的诅咒</strong></li></ol><ul class=""><li id="a37a" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">将表示N维特征空间上的维度的数据列和数据行视为该空间中的点。在特征空间中具有多个维度会导致空间的体积异常大，反过来，我们在该空间中的点(数据行)代表一个小的且不具有代表性的样本。这可能会影响机器学习算法的性能&amp;被称为“维数灾难”。</li><li id="a4b5" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">具有太多自由度/特征/变量的模型可能会过度拟合训练数据集，因此可能无法很好地处理新数据。</li><li id="f223" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">它指的是处理高维数据时出现的所有问题，这些问题在低维中并不存在。</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es kf"><img src="../Images/18c5215da4facb0d1d6a42af7e9dab51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*JNBaXq-NbmoSmmrrevhohA.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">图1:在一个临界点之后，随着特征数量的增加，模型的性能下降(图片由作者提供)</figcaption></figure><p id="53a1" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi"> 2。数据可视化</strong></p><ul class=""><li id="6107" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">降维技术通常用于数据可视化</li><li id="97fb" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">例如，在MNIST数据集中，我们总共有784列，但是通过dim reduction，它减少到只有2列，这有助于可视化数据集。</li></ul><h1 id="1dd8" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">尺寸缩减的类型</strong></h1><h2 id="42a0" class="lg if hh bd ig lh li lj ik lk ll lm io jj ln lo is jl lp lq iw jn lr ls ja lt bi translated"><strong class="ak">特征选择方法:</strong></h2><ul class=""><li id="c2f2" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp ke jr js jt bi translated">使用评分或统计方法来选择要保留的特征和要删除的特征，例如:</li><li id="667f" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated"><strong class="je hi">包装器方法</strong>:它采用输入特征的不同子集，并选择产生最佳模型性能的子集。RFE是包装特征选择方法的一个例子。</li><li id="2c78" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated"><strong class="je hi">过滤方法</strong>:使用评分方法，如特征和目标变量之间的相关性，选择最具预测性的输入特征子集。例子包括皮尔逊相关和卡方检验。</li></ul><h2 id="db6d" class="lg if hh bd ig lh li lj ik lk ll lm io jj ln lo is jl lp lq iw jn lr ls ja lt bi translated"><strong class="ak">矩阵分解</strong></h2><ul class=""><li id="aa6c" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp ke jr js jt bi translated">线性代数的技术可以用于降维。</li><li id="1c4f" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">最常见的成分排序方法是<strong class="je hi">主成分分析或简称PCA </strong>。</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lu"><img src="../Images/541fb9e0caf60a2401c0bbe502663d7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*Va2MduWR8SiyC4Q5t8Nj5g.jpeg"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">(图片来自谷歌)</figcaption></figure><h2 id="5445" class="lg if hh bd ig lh li lj ik lk ll lm io jj ln lo is jl lp lq iw jn lr ls ja lt bi translated"><strong class="ak">流形学习:</strong></h2><ul class=""><li id="fab2" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp ke jr js jt bi translated">这些技术用于创建高维数据的低维投影，通常用于数据可视化的目的。</li><li id="38b1" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">例如，<strong class="je hi">t-分布式随机邻居嵌入(t-SNE)。</strong></li></ul><h2 id="4592" class="lg if hh bd ig lh li lj ik lk ll lm io jj ln lo is jl lp lq iw jn lr ls ja lt bi translated"><strong class="ak">其他方法:</strong></h2><ul class=""><li id="0b2a" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp ke jr js jt bi translated">删除缺失值高或方差低的列</li><li id="01ca" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">删除相互之间高度相关的列。</li><li id="b38c" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">决策树和随机森林的使用</li><li id="336d" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">反向特征消除和正向特征构造</li></ul><h1 id="7efa" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">什么是主成分分析(PCA)？</strong></h1><p id="3bf4" class="pw-post-body-paragraph kr ks hh je b jf jg kt ku jh ji kv kw jj lv ky kz jl lw lb lc jn lx le lf jp ha bi translated">PCA通常用于连续数据的降维，它沿着方差增加的方向旋转和投影数据。方差最大的特征是主成分。</p><p id="4836" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">PCA背后的几何直觉</strong></p><p id="ad00" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">例1 </strong></p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es ly"><img src="../Images/cd2c78b853dfaba8f6b56aa3aa6711a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*GBZE80pYjtQaFPxiDqIauA.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">图2:(作者图片)</figcaption></figure><p id="3e35" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">在数据集中，我们有两个特征，比如F1(代表头发的长度)和F2(代表头发的黑度)，现在我们被迫只有一个特征(即降维)。现在有一个问题，我们应该选择哪些特性&amp;为什么？</p><p id="59c2" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">与F2相比，F1具有较大的分布或方差，或者与F2相比，F1具有更多关于数据集的信息</p><p id="2698" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">因此，我们可以删除F2，现在我们的数据集只包含一个特征，即F1。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es md"><img src="../Images/7b79e05896e5438ad08002ba9d536bac.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*GY4Ju7SuTG82rU5Ewx2Zuw.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">图3:(作者图片)</figcaption></figure><p id="9a64" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">例2 </strong></p><ul class=""><li id="538a" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">我们有另一个两列的数据集，比如F1，F2 &amp;它们的分布在pic/graph中给出。</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es me"><img src="../Images/a0576a1c2302f80b4b270f796d60eccc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*6YCtuaFAN0L4fnMSE8gMqg.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">图4:作者图片</figcaption></figure><ul class=""><li id="eccd" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">同样，我们希望dim减少，即将2维减少到1维，但这里两个特征的分布很重要，我们不能忽略任何一个特征。因此，在这种情况下，我们将通过旋转轴创建我们自己的新特征(轴)</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es mf"><img src="../Images/82e24e66e5f7d4fa74075a4a631bc3e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*92LEqVgg_txqgoCQeHMuaQ.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">图5:橙色的轴是数据集的新轴(图片由作者提供)</figcaption></figure><ul class=""><li id="52d1" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">现在我们有了新的特征，F1' &amp; F2' ( F1' &amp; F2 '，应该是相互垂直的，加上一个特征的展开应该是&gt;&gt;然后是另一个)，就像前面的例子。</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mg"><img src="../Images/eb15df361e2d7472f9f7a6e04ce8786f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tmyi_M70n0ph0b41jef-HA.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">图6:作者图片</figcaption></figure><p id="cca6" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">但是下一个问题来了，如何选择新特性(F1' &amp; F2 ')？</p><h1 id="5244" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">PCA背后的数学</strong></h1><ul class=""><li id="48e9" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp ke jr js jt bi translated">对于具有最大分布/方差的新特性，我们需要理解它们背后的数学原理。</li><li id="cd1a" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">对于给定的数据集<strong class="je hi"> D </strong> (n*d)(具有n行和D列)</li><li id="fe07" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">对数据集<strong class="je hi"> D </strong>执行列规范化或标准化</li><li id="0f26" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">找到数据集D的协方差矩阵<strong class="je hi"> S </strong> (d*d ),即</li></ul><p id="b039" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">S = D . T * D</strong>(D . T = D转置)</p><ul class=""><li id="eb6f" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">找出<strong class="je hi"> S </strong> (d*d)的特征值和相应的特征向量</li></ul><p id="fa91" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">λ1 &gt; λ2 &gt; λ3 …….λd(特征值)</p><p id="4efa" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">F1 '，F2 '，F3' …。特征向量</p><ul class=""><li id="f3a0" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">特征向量(F1' F2' …)。)是我们的新功能或者轴。</li></ul><h1 id="9851" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">常设仲裁法院的限制</strong></h1><ul class=""><li id="7fb2" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp ke jr js jt bi translated">在某些情况下，PCA无法捕捉最大方差，导致大量信息丢失，例如:</li></ul><div class="kg kh ki kj fd ab cb"><figure class="mh kk mi mj mk ml mm paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><img src="../Images/6aa91956a33257164cdebdb5c96194a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/format:webp/1*TqwE0rq7TJrIBk2NWKrcrg.png"/></div></figure><figure class="mh kk mn mj mk ml mm paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><img src="../Images/8547f3ef52061e4975fe78dffe83bdca.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*nSP13mmpvoiwzK_Hj1eceg.png"/></div></figure><figure class="mh kk mo mj mk ml mm paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><img src="../Images/96f0ac2869bfa4dcd807343337db71cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*lS3enruBSfgBUyPfmirSBg.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx mp di mq mr translated">T-sne失败的情况(图片由作者提供)</figcaption></figure></div><h1 id="098f" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">什么是T-sne？</strong></h1><ul class=""><li id="b216" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp ke jr js jt bi translated">它发音为tesnee，代表t分布随机邻域嵌入。</li><li id="6696" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">可视化的最佳降维技术</li><li id="41d9" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">PCA是一种古老而基本的技术，它保持全局结构(只是试图最大化方差，它看不到簇内距离)，而t-sne是一种新的先进的数学技术，它保持局部结构。</li></ul><p id="1309" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">t、s、n的含义&amp; e </strong></p><ul class=""><li id="fc31" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">N:  N代表邻居</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ms"><img src="../Images/f53772881fbbefdd04daeedc7f2749bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:342/format:webp/1*Pv6w0k66ic4MNqYe4syGnQ.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">对于橙色的十字，圆内的所有点都在邻域内</figcaption></figure><ul class=""><li id="5ddb" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated"><strong class="je hi"> E: </strong> E代表嵌入，对于高维空间中的每一个点，如果我们在低维空间中找到这个点，这叫做嵌入。</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es mt"><img src="../Images/c79c462e0039d46e7ccc28bce5661647.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*iolztbSik90u85fRbCOtmQ.png"/></div></figure><ul class=""><li id="d43d" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated"><strong class="je hi">随机:</strong>表示随机概率分布或模式，即tsne是一种概率算法</li><li id="67b1" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">T代表学生t分布，这有助于克服拥挤问题。</li></ul><p id="9c0b" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">T-SNE的几何直觉</strong></p><p id="9933" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">T-sne在邻域中保持距离在示例中，对于x1，点x2和x3在邻域中，但是它不保持其他点(x1相对于x4，x5)的距离，因为x4，x5不属于邻域N(x1)。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es mu"><img src="../Images/5aea055b19fd47dfbca40438568c3323.png" data-original-src="https://miro.medium.com/v2/resize:fit:1330/format:webp/1*p1LZkI9vaehKDjx9Va7xbw.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">左边的点是二维的，右边的点是二维的</figcaption></figure><p id="8f86" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">t-SNE的重要参数</strong></p><ul class=""><li id="15a4" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated"><strong class="je hi">步骤:</strong>迭代次数</li><li id="72ba" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated"><strong class="je hi">困惑:</strong>我们想要保留其距离的邻域中的点数。</li><li id="d343" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated"><strong class="je hi"> Epsilon: </strong>优化的速度有多快。</li></ul><p id="33d9" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">T-SNE的不同情况</strong></p><p id="ee72" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">通常，T-sne用于可视化，即将“D”维数据集可视化为2dim，但这里我们采用各种2d数据集，并对其应用T-sne，以了解我们是否获得原始2d数据集。</p><ul class=""><li id="448c" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated"><strong class="je hi">超参数真的很重要</strong></li></ul><p id="2a49" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">让我们从SNE霸王龙的“hello world”开始:一个由两个相距甚远的集群组成的数据集。为了使事情尽可能简单，我们将考虑2D平面中的星团，如左图所示。(为了清楚起见，这两个集群是用颜色编码的。)右图显示了五种不同困惑值的t-SNE图。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mv"><img src="../Images/d06bfb2c0c71495c7602d51a91268e27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KFE4gfNKZruffTQH-DgmsQ.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">步骤不变，困惑在变</figcaption></figure><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mw"><img src="../Images/36f7dcff354ef3bd772d1aae6de9a385.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xmGkTDWRz08yU9x_Px0XxA.png"/></div></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">脚步在变，困惑不变</figcaption></figure><ul class=""><li id="a4e9" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated"><strong class="je hi">t-SNE图中的簇大小没有任何意义</strong></li></ul><p id="e4bc" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">在下面的图片中，在最左边，我们有两个不同密度的集群。让我们看看如果我们对它应用T-sne会发生什么。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mx"><img src="../Images/010d0448a7daca8d3ebafbb09c80b57f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YGZ7uxEk69ypzH_sZ0MjHA.png"/></div></div></figure><p id="d6cd" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">在t-SNE图中，对于更高的困惑值，这两个集群看起来大小相同。t-SNE算法使其“距离”概念适应数据集中的区域密度变化。因此，它会自然地扩大密集的星系团，收缩稀疏的星系团，使星系团大小均匀。</p><ul class=""><li id="6376" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated"><strong class="je hi">星团之间的距离可能没有任何意义</strong></li></ul><p id="bbed" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">在最左边，我们有三个集群，每个集群都有50个点，但是绿色集群离其他两个集群很远，让我们看看T-sne能否记住这些集群之间的距离</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es my"><img src="../Images/5a9d5869a086eff9f869aa5e3b2ac0c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S3dNIiDlY1cl__u0MszfAA.png"/></div></div></figure><p id="b44e" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">从上面的图像看起来，对于更高的困惑，tsne可以记住距离，让我们检查更多的点。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mz"><img src="../Images/99bf35fa8b68dfa017988c571229c9b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tgUM8Rs1yNZ9kiUcJu0UmA.png"/></div></div></figure><p id="179a" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">遗憾的是，没有。如果我们给每一个聚类增加更多的点，困惑度必须增加来补偿。这是三个高斯集群的t-SNE图，每个集群有200个点，而不是50个。现在，没有一个试验困惑值给出好的结果。基本信息是，在t-SNE图上，分离良好的星团之间的距离可能没有任何意义。</p><ul class=""><li id="7271" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated"><strong class="je hi">对于拓扑，你可能需要不止一个图</strong></li></ul><p id="b9eb" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">有时你可以从t-sne图上读出拓扑信息，但永远不要只为一个困惑和一步运行t-SNE。考虑在三维空间中追踪一个链环或一个结/trie-knot的一组点。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es na"><img src="../Images/953871f97eee9a1219ea5f1f844bc15f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xPc2-jFCPwKci8l6sa_WYg.png"/></div></div></figure><p id="0e57" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">再一次，查看多个困惑值给出了最完整的图片。低困惑值给出两个独立的循环；高的显示全球连通性。</p><p id="6692" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">MNIST数据集上的T-SNE&amp;PCA</strong></p><p id="2c50" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">MNIST是60，000个28×28像素的小正方形灰度图像的数据集，这些图像是手写的0到9之间的单个数字。如果我们将28×28像素转换成大小为784的数组，那么我们的数据集被转换成60000×784，即60000个图像，每个图像具有784个值或特征或列。</p><p id="f058" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">之后，我们将对MNIST数据集(60，000 x 784到60，000 x 2)应用降维，首先应用PCA，然后应用T-sne。</p><p id="0e36" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated">我的<a class="ae nb" href="https://github.com/harshyadav1508/medium_article_code/blob/main/PCA_Tsne.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub档案中的实际代码。</a></p><ul class=""><li id="4570" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated"><strong class="je hi">MNIST数据集上的主成分分析</strong></li></ul><figure class="kg kh ki kj fd kk"><div class="bz dy l di"><div class="nc nd l"/></div></figure><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ne"><img src="../Images/b523dfc53a05a89b5209ddb3cd263b9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/format:webp/1*XAb2igTsP1Gxu1I0gwvxlg.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">(图片由作者提供)</figcaption></figure><ul class=""><li id="297e" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated"><strong class="je hi">MNIST数据集上的T-SNE</strong></li></ul><figure class="kg kh ki kj fd kk"><div class="bz dy l di"><div class="nc nd l"/></div></figure><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es nf"><img src="../Images/12c70a3fb66b900ddf72f1b82e904796.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*-38CkaVyeXNbEtR-NT9KPg.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">(图片由作者提供)</figcaption></figure><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ng"><img src="../Images/ba7be60c87ae7091b899b487f1ae94ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/1*pE5a9EvCPo7Eirtra4vHgQ.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">图片来自发表的论文</figcaption></figure><p id="9d72" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">不同btw T-sne和PCA </strong></p><pre class="kg kh ki kj fd nh ni nj nk aw nl bi"><span id="e344" class="lg if hh ni b fi nm nn l no np">+---------------------------+---------------------------+<br/>|   PCA                     |      T-sne                |   <br/>+---------------------------+---------------------------+<br/>| Linear method             | Non-Linear method         |<br/>| Deterministic             | Stochasticity             | <br/>|Preserve global proportion | Preserve local proportion | <br/>+-------------------------------------------------------+</span></pre><p id="5e2e" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">降维的优势</strong></p><ul class=""><li id="bc32" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">降维有助于数据压缩，从而减少存储空间和计算时间。</li><li id="1b55" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">移除多余的特征(如果有的话)。</li><li id="c7d2" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">有助于数据可视化</li><li id="9f69" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">治愈维数灾难</li></ul><p id="e4f0" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">降维的缺点</strong></p><ul class=""><li id="7f6f" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">这可能会导致一些数据丢失。</li><li id="6be9" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp ke jr js jt bi translated">有损压缩</li></ul><p id="2ead" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><strong class="je hi">提示</strong></p><ul class=""><li id="a58c" class="jc jd hh je b jf jz jh ka jj kb jl kc jn kd jp ke jr js jt bi translated">如果输入变量具有不同的比例或单位，那么在使用这些方法之前对数据进行归一化或标准化是一种很好的做法。</li></ul><h1 id="e864" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">参考资料:</h1><div class="nq nr ez fb ns nt"><a href="https://distill.pub/2016/misread-tsne/" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab dw"><div class="nv ab nw cl cj nx"><h2 class="bd hi fi z dy ny ea eb nz ed ef hg bi translated">如何有效地使用t-SNE</h2><div class="oa l"><h3 class="bd b fi z dy ny ea eb nz ed ef dx translated">一种流行的探索高维数据的方法叫做t-SNE，是由范德马滕和辛顿提出的…</h3></div><div class="ob l"><p class="bd b fp z dy ny ea eb nz ed ef dx translated">蒸馏. pub</p></div></div><div class="oc l"><div class="od l oe of og oc oh kl nt"/></div></div></a></div><div class="nq nr ez fb ns nt"><a href="https://colah.github.io/posts/2014-10-Visualizing-MNIST/" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab dw"><div class="nv ab nw cl cj nx"><h2 class="bd hi fi z dy ny ea eb nz ed ef hg bi translated">可视化MNIST:降维探索</h2><div class="oa l"><h3 class="bd b fi z dy ny ea eb nz ed ef dx translated">在一些基本层面上，没有人理解机器学习。这不是事情太复杂的问题…</h3></div><div class="ob l"><p class="bd b fp z dy ny ea eb nz ed ef dx translated">colah.github.io</p></div></div><div class="oc l"><div class="oi l oe of og oc oh kl nt"/></div></div></a></div><p id="327d" class="pw-post-body-paragraph kr ks hh je b jf jz kt ku jh ka kv kw jj kx ky kz jl la lb lc jn ld le lf jp ha bi translated"><a class="ae nb" href="https://github.com/harshyadav1508/medium_article_code" rel="noopener ugc nofollow" target="_blank">https://github.com/harshyadav1508/medium_article_code</a></p></div></div>    
</body>
</html>