<html>
<head>
<title>Speaker Diarisation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">说话者日记化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/speaker-diarisation-89c963fa4fe8?source=collection_archive---------1-----------------------#2021-05-19">https://medium.com/analytics-vidhya/speaker-diarisation-89c963fa4fe8?source=collection_archive---------1-----------------------#2021-05-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="a644" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">在只有两个说话者的音频文件中，找出“谁在什么时候说话”的一种无人监管的方法。</p></blockquote><p id="322d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">语音处理可以分为两大类:<br/> 1 .<strong class="il hj">语音</strong>识别:检测语音音频内容<br/> 2。说话者识别:识别对话中的说话者</p><p id="e261" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">说话人日记属于第二类。说话人日记化是识别音频文件中说话人的开始和结束时间的任务。</p><h1 id="2af7" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">1.先决条件</h1><p id="9de9" class="pw-post-body-paragraph ii ij hi il b im ki io ip iq kj is it jh kk iw ix ji kl ja jb jj km je jf jg hb bi translated">对于这个帖子，我们需要<a class="ae kn" href="https://www.python.org/downloads/release/python-360/" rel="noopener ugc nofollow" target="_blank"> Python </a>，Librosa，Scipy。</p><h1 id="b1f8" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">2.数据集描述</h1><p id="c188" class="pw-post-body-paragraph ii ij hi il b im ki io ip iq kj is it jh kk iw ix ji kl ja jb jj km je jf jg hb bi translated">这里使用的数据集来自<br/><a class="ae kn" href="https://media.talkbank.org/ca/CallHome/eng/6313.mp3" rel="noopener ugc nofollow" target="_blank">https://media.talkbank.org/ca/CallHome/eng</a><br/>，我已经将<a class="ae kn" href="https://media.talkbank.org/ca/CallHome/eng/6313.mp3" rel="noopener ugc nofollow" target="_blank">https://media.talkbank.org/ca/CallHome/eng/4547.mp3</a>的音频文件进行了扬声器细分并执行了下采样。</p><h1 id="7301" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">3.导入所需的库，缩减采样并将mp3转换为wav格式</h1><p id="134e" class="pw-post-body-paragraph ii ij hi il b im ki io ip iq kj is it jh kk iw ix ji kl ja jb jj km je jf jg hb bi translated">要对信号进行下采样，您需要在数据之间进行插值。对于下采样和转换，使用下面的代码。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><h1 id="d619" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">4.框图</h1><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kv"><img src="../Images/706e89ef207d850401a9e62070c158c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Yui1YnvFpZUBJwHlg6-gA.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated"><strong class="bd jm">扬声器变音系统简图</strong></figcaption></figure><h2 id="9c5a" class="lg jl hi bd jm lh li lj jq lk ll lm ju jh ln lo jy ji lp lq kc jj lr ls kg lt bi translated">扬声器日记系统由3个主要模块组成</h2><p id="e8fe" class="pw-post-body-paragraph ii ij hi il b im ki io ip iq kj is it jh kk iw ix ji kl ja jb jj km je jf jg hb bi translated"><br/>语音活动检测模块<br/>特征提取模块【聚类和分段分帧】</p><h1 id="2c85" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak"> 5。提议的方法</strong></h1><p id="11f5" class="pw-post-body-paragraph ii ij hi il b im ki io ip iq kj is it jh kk iw ix ji kl ja jb jj km je jf jg hb bi translated"><strong class="il hj"> a)分段(使用VAD): </strong>通过使用librosa.feature.rms，我们计算短期能量。VAD模块是混合的基于能量的检测器和基于模型的解码器。在第一步中，基于能量的检测器找到所有低能量的段，同时应用最小段持续时间。自动设置能量阈值以获得足够的非语音段。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><p id="1bf2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj"> b)特征向量提取和GMM训练:</strong>通过使用librosa.feature.mfcc，我们计算Mel频率倒谱系数(mfcc)及其一阶和二阶导数，并将它们组合如下:</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es lu"><img src="../Images/953006ba0bc295af1a11ecaa0d159ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g6-Pdm-gzNmjj6vIFgaZyQ.png"/></div></div></figure><p id="e97b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj"> GMM训练</strong>:</p><p id="53c1" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">高斯混合模型(GMM)使用期望最大化方法，定性地做以下事情:</p><ol class=""><li id="2056" class="lv lw hi il b im in iq ir jh lx ji ly jj lz jg ma mb mc md bi translated">选择位置和形状的开始猜测</li><li id="4286" class="lv lw hi il b im me iq mf jh mg ji mh jj mi jg ma mb mc md bi translated">重复直到收敛:<br/><strong class="il hj"><em class="ik">E-步骤</em> : </strong>对于每个点，找到编码每个聚类中的隶属概率的权重<br/><strong class="il hj"><em class="ik">M-步骤</em> : </strong>对于每个聚类，更新其位置，基于<em class="ik">所有</em>数据点，利用权重来归一化权重和形状编码</li></ol><p id="4c9b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">这样的结果是，每个集群不是与一个硬边球体相关联，而是与一个平滑的高斯模型相关联。</p><p id="0fe5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">下一步是找出对于给定的用于GMM训练的音频文件，我们需要多少最佳数量的组件。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es mj"><img src="../Images/d3fc9feb6c570c9780f37bdfd8c1edd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cPcPrgE4iYrpJ5EZQN4d9g.png"/></div></div></figure><p id="4b1a" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">最佳聚类数是使AIC或BIC最小的值，这取决于我们想要使用的近似值。因此，AIC和BIC都告诉我们，20或更多的组件将是更好的选择。<br/>请注意，组件数量的选择衡量的是GMM作为 <strong class="il hj"> <em class="ik">密度估计器</em> </strong>的效果如何，而不是作为聚类算法的效果如何<em class="ik">。</em></p><p id="4bdd" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">现在下一步将是为<strong class="il hj"> GMM训练</strong>编写函数</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><p id="f02c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">wavFile:音频文件的完整路径<br/> frameRate:每秒帧数，我每秒拍摄了50帧<br/> segLen:以秒为单位的段长度，我每秒拍摄了3段<br/> vad:帧级别的有声活动决策。<br/> numMix:混合物模型中混合物的数量。通过查看每秒比特率，我将numMix设置为128。</p><p id="8491" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">GMM函数返回基于段的预测概率数组。</p><p id="5664" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj"> C)聚类和分割框架:</strong></p><p id="63da" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">现在，在下一步中，我们将对GMM结果执行<strong class="il hj">聚类分析。<br/>在当前场景中，我们的主要目标是调整<strong class="il hj"> n_cluster </strong>，我们知道我们只有2个扬声器，因此将使用凝聚聚类来调整它。<strong class="il hj">凝聚</strong> <strong class="il hj">聚类</strong>使用“自下而上”的方法，其中每个观察值从其自己的聚类开始，随着一个聚类在层次结构中向上移动，聚类对被合并。<br/>在聚类分析之前，我们执行数据缩放和标准化，以便所有特征变得可比较，并且数据近似遵循高斯分布。</strong></p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><p id="56b1" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">分段:</strong>在执行聚类之后，我们在分段级别获得说话者假设值，现在下一步是将分段转换到帧级别。为此，请使用下面的函数</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><p id="7db5" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">最后一步:谢谢你读到这里！现在，我们使用下面的函数根据开始时间和结束时间标记说话者，并使用pandas dataframe显示日记化结果。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es mk"><img src="../Images/1891bc1021e9cccf090d788ea2f3aa5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*PlK0ZenLIaFw_SuVsB563A.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated"><strong class="bd jm">扬声器日记化输出</strong></figcaption></figure><p id="c82f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">感谢你的阅读，如果你喜欢这个帖子！打拍手！</p><p id="3ea0" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated">演讲者日记完整代码<a class="ae kn" href="https://github.com/rvipandey/SpeakerDiarisation/blob/main/SpeakerDiarization.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="il hj"> Git Hub库</strong> </a></p><p id="60cf" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jh iv iw ix ji iz ja jb jj jd je jf jg hb bi translated"><strong class="il hj">参考文献<br/> </strong> <a class="ae kn" href="https://www.researchgate.net/publication/220655267_Speaker_Diarization_Features_The_UPM_Contribution_to_the_RT09_Evaluation#pf1" rel="noopener ugc nofollow" target="_blank">说话人二值化特征</a> <br/> <a class="ae kn" href="https://link.springer.com/article/10.1186/s13636-019-0167-7" rel="noopener ugc nofollow" target="_blank">用于广播二值化的PLDA模型的无监督适应</a> <br/> <a class="ae kn" href="https://sail.usc.edu/publications/files/haninterspeech2007.pdf" rel="noopener ugc nofollow" target="_blank">说话人二值化系统中的凝聚层次聚类</a> <br/>特别感谢<a class="ae kn" rel="noopener" href="/@ppandey170993"> Priyanka </a>和<a class="ae kn" href="https://towardsdatascience.com/@nikhilsharma129540" rel="noopener" target="_blank"> Nikhil </a>！</p></div></div>    
</body>
</html>