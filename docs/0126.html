<html>
<head>
<title>ELI5: A Simple Framework for Contrastive Learning of Visual Representations</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ELI5:视觉表征对比学习的简单框架</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/eli5-a-simple-framework-for-contrastive-learning-of-visual-representations-20d9509d0a12?source=collection_archive---------9-----------------------#2021-01-05">https://medium.com/analytics-vidhya/eli5-a-simple-framework-for-contrastive-learning-of-visual-representations-20d9509d0a12?source=collection_archive---------9-----------------------#2021-01-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="6fdd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章将是我将带来的一系列ELI5s，以解释导致我在2020年获得一些最佳见解的论文。每篇文章将是一个<five-minute read="" highlighting="" the="" key="" advantages="" and="" drawbacks="" while="" making="" giving="" user="" understanding="" he="" needs="" to="" get="" hacking="" on="" their="" own.=""/></p><p id="5244" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">A Simple Framework for Contrastive Learning of Visual Representations or just SimCLR has arguably been one of the best papers in 2020 for me. The reason? Extreme simplicity and maximum impact. So, let’s dive deeper!</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/02885f166ba1f4eac47403d234221b29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/1*yaEfeSikGCk9sM-N-dDT2w.gif"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">Working of SimCLR. (Source: Google AI)</figcaption></figure><p id="7312" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">This is it. This 10s gif (pronounced gif or gif??) is it! While being this simple, its impact has been EXCEPTIONAL in terms of the performance it could give with a small amount of labeled data.</p><p id="f805" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">So, here’s how it works: What happens in this process is, we are taking <strong class="ig hi">只有图片</strong>(没有标签)的狗，也是一把椅子。然后，我们通过在原始图像上应用随机增强，从每个图像生成两个不同的图像。例如，我随机裁剪出狗的图片，应用颜色抖动和一些随机的颜色扭曲来得到最左边的图像。这些图像然后通过CNN，这是我的编码器模块，这些网络为这些图像中的每一个输出特定的表示。使用MLP投影头，这些大小为2048的表示被进一步映射到128维向量的潜在空间。现在神奇的是，狗的图片的两个变换使用对比损失变得相似，就像它们相互吸引，而狗和椅子的图像被制成相互排斥，因为它们是负面的一对。在这种情况下，对比损失(NT-Xent)只不过是一种美化的交叉熵损失，通过温度缩放来帮助模型学习硬负面特征(帮助区分狗与大象、椅子和宇宙飞船)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jo"><img src="../Images/ffb4cb13a7ffbe2c6cc727b8e2b59971.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*e1jQ3oM0kEwAHF2P96crwQ.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">交叉熵损失与对比损失</figcaption></figure><p id="a074" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">完成这个数据扩充步骤主要是因为我想将我的未标记数据与类似的数据进行比较，还因为通过这样做，我的模型学会了查看我的图像的全局和局部方面，反过来，与我以前的方法相比，它已经证明学会了更好的表示。</p><p id="fc03" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">编码器模块是卷积神经网络，在这里接受训练，在我完成训练后，我可以将它用作我其他任务的特征提取器。与监控的架构相同，唯一不同的是要装载的重量。Ez。</p><p id="2681" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">既然我们已经看完了这篇论文的特点，让我们检查一下它的优点和缺点。</p><h1 id="e8f0" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">优势</strong></h1><ol class=""><li id="b4a4" class="kn ko hh ig b ih kp il kq ip kr it ks ix kt jb ku kv kw kx bi translated">工作过程一直<strong class="ig hi">极其简单</strong>。选择模型、数据、增强，执行预训练，将模型用于监督任务。</li><li id="efa2" class="kn ko hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">这种技术<strong class="ig hi">通过大部分未标记的数据</strong>学习大部分特征。附属阶段不需要任何标签，编码器通过纯粹查看图像来学习表示。</li><li id="fd7f" class="kn ko hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated"><strong class="ig hi">增强</strong>帮助编码器<strong class="ig hi">理解局部和全局特征</strong>。</li><li id="fbbf" class="kn ko hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">这种技术在ResNet-50上使用1%的标记数据进一步训练时获得了高达85.8% 的前5名准确度，使用10%的标记数据进一步训练时获得了92.6% 前5名准确度<strong class="ig hi"> </strong>(准确地说是4倍)。</li><li id="889c" class="kn ko hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">作为一种半监督学习技术，这种<strong class="ig hi">直接与可用于预训练的未标记数据量</strong>成比例。</li></ol><h1 id="499a" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">缺点:</h1><ol class=""><li id="0cd2" class="kn ko hh ig b ih kp il kq ip kr it ks ix kt jb ku kv kw kx bi translated">这里的预训练任务只涉及数据扩充。虽然是有效的，但是增强的选择和增强的程度必须由用户根据数据和他们希望模型学习的表示类型来完成。</li><li id="4e03" class="kn ko hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">它适用于本地化任务吗？这又一次归结到增强的选择上，这有可能使模型变得更加具有局部性。</li><li id="b9d6" class="kn ko hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">极大的批量:论文建议使用8192的批量！嘿，好吧，谷歌谢谢你指出我们破产了。这仍然适用于较小的数据集，但对比损失已被证明适用于较大的批量。</li></ol><p id="0e41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">资源:</strong></p><p id="12b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">既然你已经快速阅读了我的2020年十大杰出论文之一的概述，这里有一些资源可供你更深入地研究和测试:</p><ol class=""><li id="61eb" class="kn ko hh ig b ih ii il im ip ld it le ix lf jb ku kv kw kx bi translated">视觉表征对比学习的简单框架</li><li id="7b3b" class="kn ko hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated"><a class="ae lg" href="https://github.com/google-research/simclr" rel="noopener ugc nofollow" target="_blank">官方Tensorflow实现</a>如果你是认真的承诺。</li><li id="b6cc" class="kn ko hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated"><a class="ae lg" href="https://github.com/sayakpaul/SimCLR-in-TensorFlow-2" rel="noopener ugc nofollow" target="_blank">简化(但同样有效)的Tensorflow实现</a>如果一切都是为了随遇而安。</li><li id="3cb3" class="kn ko hh ig b ih ky il kz ip la it lb ix lc jb ku kv kw kx bi translated">对于那些喜欢采取强硬手段的人(包括我自己)</li></ol></div></div>    
</body>
</html>