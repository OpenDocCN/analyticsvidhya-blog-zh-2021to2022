<html>
<head>
<title>Titanic Survival Project — Pop Culture to Data Science</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">泰坦尼克号生存项目——从流行文化到数据科学</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/titanic-survival-project-pop-culture-to-data-science-55e8721ef0a8?source=collection_archive---------4-----------------------#2021-03-11">https://medium.com/analytics-vidhya/titanic-survival-project-pop-culture-to-data-science-55e8721ef0a8?source=collection_archive---------4-----------------------#2021-03-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/4320962fc63c221913d01a7b0ae39561.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NB7UEm8AzKh6d-jNrJCBhw.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">泰坦尼克号——图片。壁纸耀斑)</figcaption></figure><p id="6d57" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">首航就沉没的不沉之船。有争议的电影。悲惨的泰坦尼克号。通过使用Kaggle上提供的数据，我们作为数据科学家可以将我们的大量知识应用到相对干净的数据集上。数据集对于EDA(探索性数据分析)、数据清理技术和机器学习算法来说已经成熟。数据科学不仅仅局限于博士和学术界。任何人都可以做到这一点，我希望分享我在解决这个kaggle挑战的方法论。泰坦尼克号嵌入了我们的流行文化，所以很容易拿起这个数据集并开始修补。所以让我们开始吧！</p><h1 id="9759" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">数据探索</h1><h2 id="7198" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">导入和基本设置</h2><p id="b6d0" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">因此，首先，我导入了我认为项目需要的包:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="bc49" class="kp js hh ln b fi lr ls l lt lu"><strong class="ln hi">import</strong> <strong class="ln hi">pandas</strong> <strong class="ln hi">as</strong> <strong class="ln hi">pd</strong> <br/><strong class="ln hi">import</strong> <strong class="ln hi">numpy</strong> <strong class="ln hi">as</strong> <strong class="ln hi">np</strong><br/><strong class="ln hi">import</strong> <strong class="ln hi">matplotlib.pyplot</strong> <strong class="ln hi">as</strong> <strong class="ln hi">plt</strong><br/><strong class="ln hi">import</strong> <strong class="ln hi">sklearn</strong> <br/><strong class="ln hi">import</strong> <strong class="ln hi">seaborn</strong> <strong class="ln hi">as</strong> <strong class="ln hi">sns</strong></span></pre><p id="2f18" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我使用pandas &amp; NumPy进行数据准备和变异，而如果我愿意，我会使用Matplotlib和seaborn进行可视化。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="ee07" class="kp js hh ln b fi lr ls l lt lu">train_df = pd.read_csv('train.csv') <br/>test_df = pd.read_csv('test.csv')</span><span id="0ebc" class="kp js hh ln b fi lv ls l lt lu">tempdf = pd.read_csv('gender_submission.csv') <em class="lw">#Might come useful later</em></span></pre><p id="2f06" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我加载了数据，并为测试数据框架的解决方案留出了一个临时数据框架。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="354f" class="kp js hh ln b fi lr ls l lt lu">train_df.head()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lx"><img src="../Images/cb52657e768c53be0b58e381fc657c00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V2gu5sIjd15pCinQaxLN5g.png"/></div></div></figure><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="db1c" class="kp js hh ln b fi lr ls l lt lu">test_df.head()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ly"><img src="../Images/f359ba416a8acf9c81ce11bbe94a37a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pLhMmYFBzg1cPR_0PZ1gnQ.png"/></div></div></figure><p id="7d14" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">立即突出的事实是，在测试数据帧中没有幸存的列。虽然这是可以预料的，因为幸存的那一列才是我们需要预测的。通过使用数据框架中的特征，我们应该能够预测泰坦尼克号悲剧中的幸存者。</p><h2 id="1ce8" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">进一步探索数据</h2><p id="3ab6" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">首先，我从理解数据的内容开始分析数据。查看数据中有多少NaN/null值，以及每列中有多少唯一值，这一点很重要。因此，我开始写道:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="a46a" class="kp js hh ln b fi lr ls l lt lu">train_df.nunique()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/febb2bdbcf82bd8b35058cc6bd87429e.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*WYB_1vvePp6TgBiHPepiDA.png"/></div></figure><p id="03ae" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在我们可以清楚地看到，我们的训练数据集中有891名乘客。正如我们所料，只有2个幸存的独特价值，因为你只能生存或不生存。乘客有3个等级:1、2或3。有2种性别等等。nunique()函数允许我们查看每一列中唯一值的数量。但是，为了查看有多少个nan值，我编写了代码:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="c0e1" class="kp js hh ln b fi lr ls l lt lu">train_df.isnull().sum()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/d9dffe21bb570ea2c4c92777515df6f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*i7Zuk3lx838LIEL2-K7FWA.png"/></div></figure><p id="1f6d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这很有趣，因为座舱柱已经过时了。在891列中，缺少687行。因此，我从数据框中删除了该系列:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="6fe6" class="kp js hh ln b fi lr ls l lt lu">train_df = train_df.drop('Cabin', axis = 1)<br/>train_df.head()</span></pre><p id="2197" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">尽管我承认您可以从其他专栏中推断数据，但我发现与其他特性相比，它通常没有那么大的影响。尽管我们对数据集做了一些最小的清理，但仍有177个“年龄”没有在数据集中找到。</p><h2 id="7be4" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">列车数据清理和准备</h2><p id="3378" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">我开始用平均值填充年龄空值:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="9bcd" class="kp js hh ln b fi lr ls l lt lu">train_df['Age'].fillna(train_df['Age'].mean(), inplace = <strong class="ln hi">True</strong>)</span></pre><p id="25b7" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">通过填充平均值，我们不会破坏数据集的完整性。尽管中值可能会稍微偏移，但平均值将保持不变，并且在理论上，我们将能够在我们的模型中使用该列。为了完成数据的清理，我简单地删除了装载数据中具有空值的行，方法是:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="af09" class="kp js hh ln b fi lr ls l lt lu">train_df = train_df.dropna(subset = ['Embarked'])</span></pre><p id="4353" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">然后，为了确认所有的空值确实都被删除了，我通过运行以下命令进行了检查:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="77cc" class="kp js hh ln b fi lr ls l lt lu">train_df.isnull().sum()</span></pre><p id="43ab" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">瞧:</p><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es ma"><img src="../Images/711b7aaba75f0a78f7aff4db0d3a69b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/1*B8ssw-c8duCsuUzc3-KuTg.png"/></div></figure><p id="212a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在我们已经删除了所有的空值，我们可以继续进行特性工程和优化。</p><h2 id="927f" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">特征工程</h2><p id="039c" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">首先，让我们创建一个名为“独自旅行”的新专栏。目前只有SibSp和Parch专栏，讨论的是兄弟姐妹、配偶、父母和子女。利用这些数据，我们可以推断出独自旅行一栏。使用该列，我们可以看到，如果你是一个人或不是一个人，生存概率是否有任何变化。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="19d6" class="kp js hh ln b fi lr ls l lt lu">train_df['Travelling Alone'] = train_df.apply(<strong class="ln hi">lambda</strong> row: row.SibSp == 0 &amp; row.Parch == 0, axis = 1)<br/><br/>train_df.loc[train_df['Travelling Alone'] == <strong class="ln hi">True</strong>, 'Travelling Alone'] = 1<br/><br/>train_df.loc[train_df['Travelling Alone'] == <strong class="ln hi">False</strong>, 'Travelling Alone'] = 0</span><span id="6acf" class="kp js hh ln b fi lv ls l lt lu">train_df.head()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mb"><img src="../Images/ccc710e0ecf8b5482064e97342dfc399.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e8DKVTjRgoQHEuqirOzb6g.png"/></div></div></figure><p id="73a8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">通过使用lambda函数，我们可以检查条件是否满足，如果满足，那么我们可以将它添加到单独旅行列中。然而，使用lambda会产生一个布尔类型。因此，我们用熊猫。loc[]运算符将数据转换为整数数据类型。尽管您不一定必须执行这一步，但我发现在整个项目中保持类似的约定非常有用。</p><p id="7741" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在这个项目中，我使用了Scikit-Learn，他们的模型不接受字符串。因此，谨慎的做法是删除包含字符串或字符的列。姓名、机票、登机、性别都有字符串或字符在列中。对于Name和Ticket，因为它们在模型中是不需要的，我们可以简单地删除它们。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="1b93" class="kp js hh ln b fi lr ls l lt lu">train_df = train_df.drop(['Ticket', 'Name'], axis = 1)</span><span id="2650" class="kp js hh ln b fi lv ls l lt lu">train_df.head()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mc"><img src="../Images/d965a37eb64d918e1a88c5339d3252b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*ruJYJE0Erqk93_6wfgR6pQ.png"/></div></figure><p id="e27d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们已经有了一种区分乘客的方法，那就是简单地通过使用他们的乘客ID。然而，性和他们从哪里出发是重要的栏目。它们可能对机器学习模型至关重要，因为它们是分类变量。用熊猫的。loc[]，我们可以把性别列从字符串改成整数。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="8201" class="kp js hh ln b fi lr ls l lt lu">train_df.loc[train_df['Sex'] == 'male', 'Sex'] = 1<br/>train_df.loc[train_df['Sex'] == 'female', 'Sex'] = 0</span><span id="d241" class="kp js hh ln b fi lv ls l lt lu">train_df.head()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es md"><img src="../Images/a535f390dd6e498a75b628e95cc206c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1310/format:webp/1*79P_768jmVPQov8kX8P2rw.png"/></div></figure><p id="1aee" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">既然我们已经将男性指定为数字1，将女性指定为数字0，那么我们可以继续讨论已上船列了。上船列包括3个类别。每个港口都是乘客离开的地方。C =瑟堡，Q =皇后镇，S =南安普顿。我把皇后镇设为1，南安普敦设为2，瑟堡设为3。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="4b47" class="kp js hh ln b fi lr ls l lt lu">train_df.loc[train_df['Embarked'] == 'Q', 'Embarked'] = 1<br/><br/>train_df.loc[train_df['Embarked'] == 'S', 'Embarked'] = 2<br/><br/>train_df.loc[train_df['Embarked'] == 'C', 'Embarked'] = 3</span></pre><p id="cbf3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">通过这种方式，所有的数据都是以整数的形式表示的，使用软件包sci-kit learn不会有任何问题。正如我们外推“独自旅行”专栏一样，我们可以以类似的方式创建另一个名为“家庭规模”的特性。通过使用lambda函数，我们可以访问行:SibSp和Parch来创建一个新列。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="53b9" class="kp js hh ln b fi lr ls l lt lu">train_df['Family Size'] = train_df.apply(<strong class="ln hi">lambda</strong> row: row.SibSp + row.Parch, axis = 1)</span><span id="7de2" class="kp js hh ln b fi lv ls l lt lu">train_df.head()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es me"><img src="../Images/d01fa064d969032d2e3a6467a8cbe53f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FWGdVJ97Ok1UsuJMGq2rmw.png"/></div></div></figure><p id="504f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">通过创建一个新的列，我们可以监控家庭规模对存活率的影响趋势。</p><p id="dacd" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">既然我们已经清理了数据并创建了新的列进行分析，我们必须对测试数据框架做同样的事情。我们的测试数据框架和训练数据框架的特征必须相同，以确保在模型的训练和测试阶段不会出现错误。</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="a8f5" class="kp js hh ln b fi lr ls l lt lu">test_df = test_df.drop(['Ticket', 'Name', 'Cabin'], axis = 1)<br/><br/>test_df['Age'].fillna(test_df['Age'].mean(), inplace = <strong class="ln hi">True</strong>)<br/>test_df = test_df.dropna(subset = ['Embarked'])<br/><br/>test_df['Travelling Alone'] = test_df.apply(<strong class="ln hi">lambda</strong> row: row.SibSp == 0 &amp; row.Parch == 0,axis = 1)<br/><br/>test_df.loc[test_df['Travelling Alone'] == <strong class="ln hi">True</strong>, 'Travelling Alone'] = 1<br/><br/>test_df.loc[test_df['Travelling Alone'] == <strong class="ln hi">False</strong>, 'Travelling Alone'] = 0<br/><br/>test_df.loc[test_df['Sex'] == 'male', 'Sex'] = 1<br/><br/>test_df.loc[test_df['Sex'] == 'female', 'Sex'] = 0<br/><br/>test_df['Family Size'] = test_df.apply(<strong class="ln hi">lambda</strong> row: row.SibSp + row.Parch, axis = 1)</span><span id="a287" class="kp js hh ln b fi lv ls l lt lu">test_df.loc[test_df['Embarked'] == 'Q', 'Embarked'] = 1<br/><br/>test_df.loc[test_df['Embarked'] == 'S', 'Embarked'] = 2<br/><br/>test_df.loc[test_df['Embarked'] == 'C', 'Embarked'] = 3</span><span id="b727" class="kp js hh ln b fi lv ls l lt lu">test_df['Fare'].fillna(test_df['Fare'].mean(), inplace = <strong class="ln hi">True</strong>)</span></pre><h1 id="9250" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">机器学习模型</h1><p id="71cc" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">现在，让我们进入正题。由于这是我的第一个真正的数据科学项目，如果你们能在评论中给我反馈来改变和调整我的项目，我将不胜感激！</p><p id="e10f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我从查看我的火车开始，并再次测试数据帧，只是为了看看一切是否同步并准备就绪！</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="01c2" class="kp js hh ln b fi lr ls l lt lu">train_df.head()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es me"><img src="../Images/4ceea6cc7512f521fb6deaae3bfc7760.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N3VTRbO22oIo04vq3CkYzg.png"/></div></div></figure><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="d9ea" class="kp js hh ln b fi lr ls l lt lu">test_df.head()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mf"><img src="../Images/6b14dcd2aa46bc1de0fbc700a006f7c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*xeGMxSLUpAiMlIBwXCthtg.png"/></div></figure><p id="5ffb" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">看起来我们的数据处于最佳状态，如果我们需要编辑任何东西，我们可以随时进行。要开始机器学习过程，我们必须指定我们的功能:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="49cf" class="kp js hh ln b fi lr ls l lt lu">features = ['Sex', 'SibSp', 'Parch', 'Travelling Alone', 'Family Size', 'Embarked', 'Pclass']<br/><br/>Y = train_df['Survived']<br/>X = train_df[features]<br/><br/>X_test = test_df[features]</span></pre><p id="08ac" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我选择的特征是性别、SibSp、Parch、独自旅行、家庭规模、上船和乘客的等级。值得注意的是，我没有包括年龄和费用，因为我在测试时发现这些往往会使我的模型过拟合。这可能是因为891名乘客中有731人只支付了0-50英镑，我用平均值从年龄中清除了nan值。然而，由于这些情况，我选择不使用这些功能。为了确保没有空值，我再次测试了训练和测试数据帧:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="847f" class="kp js hh ln b fi lr ls l lt lu">X_test.isnull().sum()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mg"><img src="../Images/feb3b67be1f42353827f9e1eee56faf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*7sjrqViKjmU-CBkSWOvqWw.png"/></div></figure><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="f83e" class="kp js hh ln b fi lr ls l lt lu">X.isnull().sum()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mg"><img src="../Images/d7078328c057662b225eca1091b09630.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/1*vmMvwZg89TmHDvhd8xKCbg.png"/></div></figure><p id="1ff6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">既然对nan值存在的任何怀疑都已消除，让我们开始建模。</p><h2 id="36d6" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">随机森林分类器</h2><p id="fd95" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">我们列表中的第一个是随机森林分类器。我将使用的所有模型都与sklearn包兼容。我首先调用这个包:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="c308" class="kp js hh ln b fi lr ls l lt lu"><strong class="ln hi">from</strong> <strong class="ln hi">sklearn.ensemble</strong> <strong class="ln hi">import</strong> RandomForestClassifier</span><span id="2349" class="kp js hh ln b fi lv ls l lt lu">rf = RandomForestClassifier(n_estimators = 100,<br/>                           n_jobs = -1,<br/>                           oob_score = <strong class="ln hi">True</strong>,<br/>                           bootstrap = <strong class="ln hi">True</strong>,<br/>                           random_state = 42)</span></pre><p id="9fb1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我将RandomForestClassifier对象赋给一个易于输入的变量，因为正如比尔·盖茨所说:</p><blockquote class="mh mi mj"><p id="67cf" class="it iu lw iv b iw ix iy iz ja jb jc jd mk jf jg jh ml jj jk jl mm jn jo jp jq ha bi translated">“我总是会选择一个懒惰的人来做一件困难的工作，因为一个懒惰的人会找到一个简单的方法来做这件事。”</p></blockquote><p id="96da" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我创建了一个模型变量并“拟合”了模型:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="8269" class="kp js hh ln b fi lr ls l lt lu">rfm = rf.fit(X,Y)</span></pre><p id="e697" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">然后我给模型打分:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="5dfd" class="kp js hh ln b fi lr ls l lt lu">rfm.score(X,Y)</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mn"><img src="../Images/edeff20dfd897fa019db4a599505e9dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*JEtln5X1V-2HPArRfcQG0g.png"/></div></figure><p id="18f5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在训练数据帧中，特征和存活率之间的关系约为84%。但是，基于决策树的算法因过度拟合而闻名，因此该值对于测试数据可能不准确。</p><p id="132a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">因此，我试图用一种更好的技术来准确判断训练值和测试值之间的关系:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="308b" class="kp js hh ln b fi lr ls l lt lu"><strong class="ln hi">from</strong> <strong class="ln hi">sklearn.model_selection</strong> <strong class="ln hi">import</strong> cross_val_score</span><span id="8510" class="kp js hh ln b fi lv ls l lt lu">accuracyRFM = cross_val_score(estimator=rfm, X = X, y = Y, cv=5) accuracyRFM.mean()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/62c341fb9f14c8a4bb481144496feb27.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*HzYWFGTFnLRfeTcfV9Sg_Q.png"/></div></figure><p id="3a79" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们得到78.4%的相关性，这对于预调模型来说似乎更现实。</p><p id="f66b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我继续为预测做一个数组，编码如下:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="7733" class="kp js hh ln b fi lr ls l lt lu">predictions = rfm.predict(X_test)</span><span id="fcd0" class="kp js hh ln b fi lv ls l lt lu">predictions</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mo"><img src="../Images/c3ec969f8a41650e11a817c70c747c47.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*UZHCPxNszxxO1R4xfsY9kg.png"/></div></figure><h2 id="a785" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">支持向量机分类器</h2><p id="071d" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">接下来，让我们通过sci-kit learn尝试SVM分类器！我们将经历相同的步骤:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="c327" class="kp js hh ln b fi lr ls l lt lu"><strong class="ln hi">from</strong> <strong class="ln hi">sklearn</strong> <strong class="ln hi">import</strong> svm<br/>svms = svm.SVC()</span><span id="0a1a" class="kp js hh ln b fi lv ls l lt lu">s = svms.fit(X,Y)</span><span id="8e98" class="kp js hh ln b fi lv ls l lt lu">svms.score(X,Y)</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/a63355dec7d43256310d065b955d923c.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*KFEUIiwo0iHg25HjRlgyLw.png"/></div></figure><p id="3423" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这一次，使用。score()函数，我们得到了81%的粗略估计。现在让我们使用cross_val_score函数:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="abfa" class="kp js hh ln b fi lr ls l lt lu">accuracySVM = cross_val_score(estimator=s, X = X, y = Y, cv=5)<br/>accuracySVM.mean()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/d079b0e8b394dfc3f53ccbc4213274f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*jBLLo8U5f9QCmtJBGgv3BQ.png"/></div></figure><p id="d3fe" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">尽管我们的scikit-learn分数在技术上较低，但我们的交叉验证分数却较高。与基于决策树的模型相比，支持向量机似乎不太容易过度拟合。</p><p id="8107" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">就像上一个模型一样，我创建了一个预测数组:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="70b0" class="kp js hh ln b fi lr ls l lt lu">predictions = svms.predict(X_test)<br/>predictions</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mp"><img src="../Images/c64fae7cf3960851ca175dac9999ae95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*WPqXAjhcfGxYgAHb9jMz9Q.png"/></div></div></figure><h2 id="2a7b" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">逻辑回归</h2><p id="43c7" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">我最后做了几个其他模型:决策树、AdaBoostClassifier、GradientBoostClassifier和KNN，但我发现向您展示相同的过程只会让这篇文章变得更长、更多余。所以我给你看我用的第三个模型:逻辑回归。虽然回归模型通常用于预测类型的问题，但逻辑回归用于基于分类的数据集。就像上次一样:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="9ee7" class="kp js hh ln b fi lr ls l lt lu"><strong class="ln hi">from</strong> <strong class="ln hi">sklearn.linear_model</strong> <strong class="ln hi">import</strong> LogisticRegression</span><span id="bb4c" class="kp js hh ln b fi lv ls l lt lu">lr = LogisticRegression()</span><span id="3be7" class="kp js hh ln b fi lv ls l lt lu">l = lr.fit(X,Y)</span><span id="e2e9" class="kp js hh ln b fi lv ls l lt lu">l.score(X,Y)</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mn"><img src="../Images/d3923a4ee44ceedea6f64f3fc7bfc7f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*Rw13yPzzFkkGN3B7qnXRUg.png"/></div></figure><p id="90c5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们的sci-kit学习分数达到了81分左右，但是，我们知道不能依赖单一的信息来源:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="2ed3" class="kp js hh ln b fi lr ls l lt lu">accuracySVM = cross_val_score(estimator=l, X = X, y = Y, cv=5)<br/>accuracySVM.mean()</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mn"><img src="../Images/8b4fb1f925d85393cc0219f812bb2376.png" data-original-src="https://miro.medium.com/v2/resize:fit:330/format:webp/1*UhOSPGc0HqWCmqmNVoSeqA.png"/></div></figure><p id="61e5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们的交叉验证分数大约为79%。在sklearn分数和交叉验证分数之间只有1%的下降。这告诉我们，逻辑回归也不会像决策树一样被过度拟合所阻碍。就像上两个模型一样，我创建了预测数组:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="9b38" class="kp js hh ln b fi lr ls l lt lu">predictions = l.predict(X_test)</span><span id="ae75" class="kp js hh ln b fi lv ls l lt lu">predictions</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/83e872c6672dca5ae51bfe4aa256ef4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*CQmbLHJFkku1APfHcXHrrQ.png"/></div></figure><h1 id="80b3" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">调整模型</h1><p id="0d7a" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">在上一节中，我们最终使用了基本模型，并且我们对模型本身几乎没有控制。现在，我们将直接访问模型的参数，并修改它们以找到最佳参数和模型。</p><p id="e5f8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们将从导入一些重要的包开始:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="8439" class="kp js hh ln b fi lr ls l lt lu"><strong class="ln hi">from</strong> <strong class="ln hi">pprint</strong> <strong class="ln hi">import</strong> pprint</span><span id="52d4" class="kp js hh ln b fi lv ls l lt lu"><strong class="ln hi">from</strong> <strong class="ln hi">sklearn.model_selection</strong> <strong class="ln hi">import</strong> GridSearchCV, StratifiedKFold<br/><strong class="ln hi">from</strong> <strong class="ln hi">sklearn</strong> <strong class="ln hi">import</strong> linear_model, decomposition<br/><strong class="ln hi">from</strong> <strong class="ln hi">sklearn.preprocessing</strong> <strong class="ln hi">import</strong> StandardScaler</span><span id="8a2b" class="kp js hh ln b fi lv ls l lt lu">kfold = StratifiedKFold(n_splits=10)</span></pre><p id="a062" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们使用GridSearchCV为我们的数据找到可能的最佳模型。</p><h2 id="f9c0" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">随机森林分类器的超参数调整</h2><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="83a0" class="kp js hh ln b fi lr ls l lt lu">rf_param_grid = <br/>{'max_features' : [0.1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_split': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'min_samples_leaf': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 100, 150]}<br/><br/>best_rfc = GridSearchCV(rfc, param_grid = rf_param_grid, cv = kfold, scoring = 'accuracy', n_jobs  = 4, verbose = 2)<br/><br/>best_rfc.fit(X,Y)<br/><br/>pprint(best_rfc.best_score_)<br/><br/>best_rfc = best_rfc.best_estimator_</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mr"><img src="../Images/eafebc4905eb04b1073780e4df54a271.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*32TQxvLfo9P_CtrLIW_jpA.png"/></div></div></figure><p id="ffb5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">首先，我们必须研究模型的超参数是什么。要做到这一点，你可以做一个简单的谷歌搜索，然后到文档<a class="ae ms" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">这里</a>。通过改变最大特征、最小样本分割和叶子，我可以更好地控制我的分类模型。我将我的参数网格插入GridCV函数，并告诉它我希望如何评分。然后，我继续使用GridSearchCV对象来调优随机森林分类模型。我打印的最佳分数为80.1%，比基线模型的78%有了显著的提升。然后，我们将包含最佳参数的最佳估计量分配给变量:best_rfc。</p><h2 id="aed8" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">支持向量机分类的超参数调整</h2><p id="b3dd" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">使用与上一个模型类似的过程，我们编写代码:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="d074" class="kp js hh ln b fi lr ls l lt lu">svmc = SVC(probability = <strong class="ln hi">True</strong>)<br/><br/>svmc_param_grid = {"kernel": ['rbf'], 'gamma': [0.001, 0.01, 0.1, 1, 10], 'C': [0.01, 0.1, 1, 10, 50, 100, 500, 1000, 5000, 10000]}<br/><br/>best_svmc = GridSearchCV(svmc, param_grid = svmc_param_grid, cv = kfold, scoring = 'accuracy', n_jobs = 4, verbose = 2)<br/><br/>best_svmc.fit(X,Y)<br/><br/>pprint(best_svmc.best_score_)<br/><br/>best_svmc = best_svmc.best_estimator_</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mr"><img src="../Images/1e47ef49f7cf41d0ef8643050bbbd3cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*raRupeRepF9BHqdq0XU13w.png"/></div></div></figure><p id="7bd2" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">支持向量机也输出80.1%的最佳得分。与基线模型相比没有显著增加。</p><h2 id="1ab4" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">逻辑回归的超参数调整</h2><p id="3b1b" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">就像模型一样，我不希望它是多余的，所以我将展示另一个超参数调整的例子:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="f784" class="kp js hh ln b fi lr ls l lt lu">lr = LogisticRegression()<br/><br/>lr_param_grid = {'penalty': ['l1','l2'], 'C': [50, 10, 1.0, 0.1, 0.01], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}<br/><br/>best_lr = GridSearchCV(lr, param_grid = lr_param_grid, cv = kfold, scoring = 'accuracy', n_jobs = 4, verbose = 2)<br/><br/>best_lr.fit(X,Y)<br/><br/>pprint(best_lr.best_score_)<br/><br/>best_lr = best_lr.best_estimator_</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mr"><img src="../Images/60568756773cc4226d42b7ab10941062.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fcVfbxn2vskiROtSMsvfzg.png"/></div></div></figure><p id="d65c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">逻辑回归模型输出了80%的最佳得分，比基线模型提高了1%。</p><h1 id="fe76" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">将所有调整后的模型组合成一个集合</h1><p id="057b" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">既然我们已经排除了模型，是时候把它们串起来了。为此，我们将使用位于sklearn的ensemble子包中的投票分类器:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="156b" class="kp js hh ln b fi lr ls l lt lu"><strong class="ln hi">from</strong> <strong class="ln hi">sklearn.ensemble</strong> <strong class="ln hi">import</strong> VotingClassifier</span></pre><p id="c5d6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">然后，我们将继续把调好的模型串在一起:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="3966" class="kp js hh ln b fi lr ls l lt lu">stringClassifier = VotingClassifier(estimators=[('rfc', best_rfc),('svc', best_svmc), ('adac',best_abc),('gbc',best_gbc), ('knn', best_knn), ('lr', best_lr)], voting='soft', n_jobs=4)</span><span id="eb04" class="kp js hh ln b fi lv ls l lt lu">stringClassifier = stringClassifier.fit(X, Y)</span><span id="f4fd" class="kp js hh ln b fi lv ls l lt lu">stringClassifier.score(X,Y)</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/2d0b6a3086d75592493b5876a09c960f.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/1*c1HTCY-Ee5OGQQbviA0CrA.png"/></div></figure><p id="f24a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">使用投票分类器函数，我们可以获得82.5%的预测率。现在我们简单地使用数组函数来创建我们的预测:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="227b" class="kp js hh ln b fi lr ls l lt lu">predictions = votingC.predict(X_test)<br/>predictions</span></pre><figure class="li lj lk ll fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/ab4adc314665ed0e7b7accb2cbcf0580.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*4vPE6fAHHHeD6McNwTwb1g.png"/></div></figure><p id="327a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">最后，我们编写一个CSV，以便提交我们的发现:</p><pre class="li lj lk ll fd lm ln lo lp aw lq bi"><span id="4a88" class="kp js hh ln b fi lr ls l lt lu">Survived = pd.Series(stringClassifier.predict(X_test), name="Survived")<br/><br/>results = pd.concat([IDtest,Survived],axis=1)<br/><br/>results.to_csv("results.csv",index=<strong class="ln hi">False</strong>)</span></pre><h1 id="cfca" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">结论</h1><p id="100e" class="pw-post-body-paragraph it iu hh iv b iw ld iy iz ja le jc jd je lf jg jh ji lg jk jl jm lh jo jp jq ha bi translated">尽管泰坦尼克号数据集可能不能代表真实世界的数据，但通过数据集肯定可以学到很多东西。我非常支持通过实践来学习，为此，我将永远感谢这个数据集。在许多方面，我能够应用我从吴恩达的机器学习课程(强烈推荐)和其他课程中学到的技能。当你在一个课程中，你会得到一些信息，但是在一个项目中，你什么也不会得到。你和数据。就是这样。我希望我能激励你们中的一些人拿起数据集，尝试学习那些原本无人触及的技术。我当然不是机器学习方面的专家，所以我会感谢反馈或任何问题！感谢大家的阅读！</p><h2 id="3a43" class="kp js hh bd jt kq kr ks jx kt ku kv kb je kw kx kf ji ky kz kj jm la lb kn lc bi translated">重要链接</h2><div class="mv mw ez fb mx my"><a href="https://www.kaggle.com/c/titanic" rel="noopener  ugc nofollow" target="_blank"><div class="mz ab dw"><div class="na ab nb cl cj nc"><h2 class="bd hi fi z dy nd ea eb ne ed ef hg bi translated">泰坦尼克号-机器从灾难中学习</h2><div class="nf l"><h3 class="bd b fi z dy nd ea eb ne ed ef dx translated">从这里开始！预测泰坦尼克号上的生存并熟悉ML基础知识</h3></div><div class="ng l"><p class="bd b fp z dy nd ea eb ne ed ef dx translated">www.kaggle.com</p></div></div><div class="nh l"><div class="ni l nj nk nl nh nm in my"/></div></div></a></div><p id="842b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><a class="ae ms" href="https://www.wallpaperflare.com/white-and-black-ship-titanic-vintage-ship-wallpaper-255721" rel="noopener ugc nofollow" target="_blank">https://www . wallpaperflare . com/white-and-black-ship-titanic-vintage-ship-wallpaper-255721</a></p></div></div>    
</body>
</html>