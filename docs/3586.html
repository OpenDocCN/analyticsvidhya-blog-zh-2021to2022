<html>
<head>
<title>Beginners guide to Apache Spark for data analytics — Part 1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Apache Spark数据分析初学者指南—第1部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/learn-basics-in-spark-for-data-analytics-11cee514ac30?source=collection_archive---------8-----------------------#2021-07-11">https://medium.com/analytics-vidhya/learn-basics-in-spark-for-data-analytics-11cee514ac30?source=collection_archive---------8-----------------------#2021-07-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="6e0c" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">学习数据分析中常用的基本spark语法</h2></div></div><div class="ab cl ix iy gp iz" role="separator"><span class="ja bw bk jb jc jd"/><span class="ja bw bk jb jc jd"/><span class="ja bw bk jb jc"/></div><div class="hb hc hd he hf"><p id="908b" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">数据正成为我们生活中不可或缺的一部分。随着获取和存储数据的方式越来越简单、方便和便宜，数据在未来也将扮演重要角色，这已经变得非常必要。数据本身意义不大，除非它可以用来产生一些见解。这就是数据分析发挥作用的地方。</p><p id="ff68" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">作为一名分析人员，我使用过SQL、SAS和python等分析工具。我看到一种转变正在发生，企业正在从付费工具转向免费的软件包。Python提供了一个完美的替代方案，凭借其庞大的库和包，它可以满足多种需求——无论是<strong class="jg hj">探索性数据分析</strong> (sweetviz和pandas profiling)<strong class="jg hj">交互式图表和仪表盘</strong> (seaborn和matplotlib)还是<strong class="jg hj">数据科学</strong> (scikit-learn)。</p><p id="15de" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">下面是一篇我试图介绍基本spark语法的文章。这是这个系列的第一部分，我打算在后面的部分增加更多的功能，这是我多年来学到的。开始需要时间，出于同样的原因，我开始在一个笔记本上记下这些功能，以帮助加快我的项目。大多数情况下，堆栈溢出是我的救命稻草，我会建议读者也这样做。如果您也从事分析工作，您可能使用过上面提到的库，但是您肯定会使用SQL。</p><blockquote class="kb kc kd"><p id="caee" class="je jf ka jg b jh ji ij jj jk jl im jm ke jo jp jq kf js jt ju kg jw jx jy jz hb bi translated">最近，随着大数据的出现，出现了许多更好的工具。其中一个就是阿帕奇Spark。</p></blockquote></div><div class="ab cl ix iy gp iz" role="separator"><span class="ja bw bk jb jc jd"/><span class="ja bw bk jb jc jd"/><span class="ja bw bk jb jc"/></div><div class="hb hc hd he hf"><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es kh"><img src="../Images/9ffbd81c655484a80e9b65e2d470094a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*tDLVicyTLT-jac0cjbnYdg.png"/></div></figure><p id="1340" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><a class="ae kp" href="http://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Apache Spark </a>是一款强大的开源大数据分析工具。这是加州大学伯克利分校的AMP实验室在2009年开发的。Spark在数据管道和机器学习模型开发方面也很受欢迎。</p><p id="ee54" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">让Spark广受欢迎的一些特性包括:</p><ul class=""><li id="56a6" class="kq kr hi jg b jh ji jk jl jn ks jr kt jv ku jz kv kw kx ky bi translated">它有助于在更快的Hadoop集群中运行应用程序</li><li id="c0de" class="kq kr hi jg b jh kz jk la jn lb jr lc jv ld jz kv kw kx ky bi translated">支持复杂的分析</li><li id="ffa8" class="kq kr hi jg b jh kz jk la jn lb jr lc jv ld jz kv kw kx ky bi translated">能够与Hadoop和现有Hadoop数据集成</li><li id="f719" class="kq kr hi jg b jh kz jk la jn lb jr lc jv ld jz kv kw kx ky bi translated">社区与贡献者一起帮助改进软件包</li></ul></div><div class="ab cl ix iy gp iz" role="separator"><span class="ja bw bk jb jc jd"/><span class="ja bw bk jb jc jd"/><span class="ja bw bk jb jc"/></div><div class="hb hc hd he hf"><p id="d52a" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在这一部分，我将介绍创建spark数据帧的不同方法。数据帧是组织成命名列的数据的分布式集合，相当于关系数据库中的表。数据帧可以从各种来源构建，例如:结构化数据文件、Hive中的表、外部数据库或现有的rdd。首先，我们需要初始化spark。我正在使用<a class="ae kp" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> colab </a>作为练习笔记本，并将在下面分享完整的笔记本。</p><p id="809d" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">下面一行代码初始化spark。这将安装Apache Spark 3.0.0、Java 8和Findspark，后者是一个使Python很容易找到Spark的库。安装时，您可能还需要参考正确的版本。这里我用的是3.0.3。库位置的任何更新都可能导致错误，请参考<a class="ae kp" href="https://downloads.apache.org/spark/" rel="noopener ugc nofollow" target="_blank">链接找到稳定的</a>版本。</p><h2 id="5dc5" class="le lf hi bd lg lh li lj lk ll lm ln lo jn lp lq lr jr ls lt lu jv lv lw lx ly bi translated">正在初始化Spark-3.0.3</h2><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lz ma l"/></div><figcaption class="mb mc et er es md me bd b be z dx translated">在colab中初始化Spark</figcaption></figure><p id="2b82" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">要检查初始化是否有效，请运行以下代码。输出应该只是一个在hello列下带有“spark”值的表。</p><pre class="ki kj kk kl fd mf mg mh mi aw mj bi"><span id="f985" class="le lf hi mg b fi mk ml l mm mn">spark.sql('''select 'spark' as hello''').show()</span></pre><h2 id="f67f" class="le lf hi bd lg lh li lj lk ll lm ln lo jn lp lq lr jr ls lt lu jv lv lw lx ly bi translated">库导入</h2><p id="5f5e" class="pw-post-body-paragraph je jf hi jg b jh mo ij jj jk mp im jm jn mq jp jq jr mr jt ju jv ms jx jy jz hb bi translated">如果你能运行上面的代码，你就可以继续了。让我们从在spark中创建数据帧的方法开始。在此之前，我们会先导入有用的库。其中之一是<code class="du mt mu mv mg b">pyspark.sql.function</code>，这将有助于数据分析和描述性分析。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="4e18" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">要查看创建的数据帧，我们可以显示或收集方法。</p><pre class="ki kj kk kl fd mf mg mh mi aw mj bi"><span id="a02d" class="le lf hi mg b fi mk ml l mm mn">df.show()<br/>OR <br/>df.collect()</span></pre><h2 id="db25" class="le lf hi bd lg lh li lj lk ll lm ln lo jn lp lq lr jr ls lt lu jv lv lw lx ly bi translated">创建火花数据帧</h2><ol class=""><li id="cedc" class="kq kr hi jg b jh mo jk mp jn mw jr mx jv my jz mz kw kx ky bi translated"><strong class="jg hj">从列表中创建数据帧</strong></li></ol><p id="440a" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">使用数组创建列表，并使用所需的列名创建数据框架。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lz ma l"/></div><figcaption class="mb mc et er es md me bd b be z dx translated">从列表创建数据框架</figcaption></figure><p id="cc14" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">一旦成功创建了dataframe，我们应该能够看到使用<code class="du mt mu mv mg b">show()</code>方法的输出。对于下面的部分，输出是相同的。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es na"><img src="../Images/61e0b62076f46b5eccbdd6003a9c0361.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/format:webp/1*eAPD_AlkcsbBLG5edpkCOg.png"/></div></figure><p id="aa39" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="jg hj"> 2。从RDD创建数据帧</strong></p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="e5b8" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="jg hj"> 3。从RDD和模式创建数据帧</strong></p><p id="2cd3" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">以下语法中的<code class="du mt mu mv mg b">nullable</code>允许数据帧中有空值。如果设置为<code class="du mt mu mv mg b">False</code>，dataframe将为空值抛出错误</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="7d2d" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="jg hj"> 4。从列表中创建数据框</strong></p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="81c7" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="jg hj"> 5。从熊猫数据框创建数据框</strong></p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="e443" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="jg hj"> 6。从配置单元表</strong>创建数据帧</p><p id="6955" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">当表被存储为hive表时，下面的代码非常有用，hive表为HDFS的数据提供了类似SQL的访问。</p><pre class="ki kj kk kl fd mf mg mh mi aw mj bi"><span id="c2b5" class="le lf hi mg b fi mk ml l mm mn">input_table = &lt;db_name&gt;.&lt;table_name&gt;</span><span id="abf4" class="le lf hi mg b fi nb ml l mm mn">df = spark.sql('''select data_date, months_to_add from {0}'''.format(input_table)</span></pre><p id="5804" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated"><strong class="jg hj"> 7。从CSV或其他文本文件创建数据帧</strong></p><p id="6af1" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我使用的数据是从data.gov免费获得的FDIC失败银行名单。你可以从给定的链接下载相同的内容，或者使用你有的任何文本文件。数据链接:<a class="ae kp" href="https://catalog.data.gov/dataset/fdic-failed-bank-list" rel="noopener ugc nofollow" target="_blank">https://catalog.data.gov/dataset/fdic-failed-bank-list</a>。</p><p id="d9de" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">请注意read函数中的参数。<code class="du mt mu mv mg b">header</code>适用于以第一行为表头提供数据。<code class="du mt mu mv mg b">inferschema</code>只是一种使用最佳数据类型的懒惰方式。<code class="du mt mu mv mg b">delimiter</code>可根据输入文件更改为制表符(\t)或空格(\s)。</p><p id="052d" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">我也上传了同样的文件到github。请随意直接使用该链接。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lz ma l"/></div></figure><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es nc"><img src="../Images/c8f4e6d0bb3be36b7c88c3e0cc34a922.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/1*khCNAkLB-by1XMN8lYqxtw.png"/></div><figcaption class="mb mc et er es md me bd b be z dx translated">查询输出</figcaption></figure><p id="2de4" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">在github上从上传的CSV创建数据帧。下面将创建相同的数据帧并输出相同的信息。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="lz ma l"/></div></figure><p id="9233" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">这部分就这些了。我将很快上传另一个，在那里我们会看到数据操作和其他功能/方法。请随意留下您的评论。</p><p id="8b2a" class="pw-post-body-paragraph je jf hi jg b jh ji ij jj jk jl im jm jn jo jp jq jr js jt ju jv jw jx jy jz hb bi translated">请使用此链接<a class="ae kp" href="https://github.com/akash865/spark_101.git" rel="noopener ugc nofollow" target="_blank">在colab或github上下载完整的笔记本</a>。</p><div class="nd ne ez fb nf ng"><a href="https://colab.research.google.com/drive/1mI_q5LFtTvJaMNCQw6NwUazea9EK8IyB?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">谷歌联合实验室</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">编辑描述</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">colab.research.google.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu kn ng"/></div></div></a></div><div class="nd ne ez fb nf ng"><a href="https://github.com/akash865/spark_101/blob/master/Spark101_CreateDataframe.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">akash865/spark_101</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">火花基本代码。在GitHub上创建一个帐户，为akash865/spark_101开发做出贡献。</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">github.com</p></div></div><div class="np l"><div class="nv l nr ns nt np nu kn ng"/></div></div></a></div></div><div class="ab cl ix iy gp iz" role="separator"><span class="ja bw bk jb jc jd"/><span class="ja bw bk jb jc jd"/><span class="ja bw bk jb jc"/></div><div class="hb hc hd he hf"><h1 id="2c17" class="nw lf hi bd lg nx ny nz lk oa ob oc lo io od ip lr ir oe is lu iu of iv lx og bi translated"><strong class="ak">参考文献</strong></h1><ol class=""><li id="3b07" class="kq kr hi jg b jh mo jk mp jn mw jr mx jv my jz mz kw kx ky bi translated">火花[【http://spark.apache.org/】T4</li><li id="2181" class="kq kr hi jg b jh kz jk la jn lb jr lc jv ld jz mz kw kx ky bi translated">data frame[<a class="ae kp" href="https://databricks.com/blog/2015/02/17/introducing-dataframes-in-spark-for-large-scale-data-science.html" rel="noopener ugc nofollow" target="_blank">https://data bricks . com/blog/2015/02/17/introducing-data frames-in-spark-for-large-scale-data-science . html</a></li><li id="5e5f" class="kq kr hi jg b jh kz jk la jn lb jr lc jv ld jz mz kw kx ky bi translated">科拉布笔记本[<a class="ae kp" href="https://www.youtube.com/watch?v=inN8seMm7UI" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=inN8seMm7UI</a>]</li></ol></div></div>    
</body>
</html>