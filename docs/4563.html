<html>
<head>
<title>Understanding Dropout!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解辍学！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-dropout-abe00504be82?source=collection_archive---------0-----------------------#2021-11-16">https://medium.com/analytics-vidhya/understanding-dropout-abe00504be82?source=collection_archive---------0-----------------------#2021-11-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="db17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">辍学者在培训中的重要性</p><p id="9660" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇博客文章也是机器学习系列文章的一部分。我之前写过关于<a class="ae jd" href="https://ajinkya29.medium.com/regularization-understanding-fb8cd7b7c0e2" rel="noopener"> <strong class="ih hj">正规化</strong> </a>的博文。所以你可以继续读这本书，如果你愿意，也可以看看其他的。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/2303fe795823351bdf1a8955c9705d55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1342/format:webp/1*gCwYbQr67te9LTxWIwSB2A.png"/></div></figure><p id="6ed5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">读者你好，</p><p id="4518" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以，让我们用简单的方式来理解辍学以及它解决了什么问题。所以让我们开始吧！</p><p id="1946" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们必须记住的一点是，每当有深度神经网络时，就会有许多<strong class="ih hj">权重和偏差参数</strong>。因此，这可能会导致模型过度适应特定的用例。因此，我们必须找到避免过度拟合的方法。</p><p id="87ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解决过拟合问题有两种方法:</p><ol class=""><li id="8a4f" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc jr js jt ju bi translated">正规化</li><li id="4a6e" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc jr js jt ju bi translated">拒绝传统社会的人</li></ol><p id="4619" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我们主要关注辍学及其概念理解。</p><p id="6e21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，<strong class="ih hj">最基本的术语</strong>什么是辍学？<br/> →简单来说，在dropout中我们随机忽略或“<em class="ka">dropped”</em>一些层输出称为节点。<em class="ka"> </em>因此这些被忽略的节点不参与训练模型。</p><p id="5295" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为我们已经了解了一些关于辍学的知识，现在让我们进入细节。</p><p id="bc65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">训练</strong> <br/>因此，为了实现一个漏失层，我们必须决定一个漏失率(<strong class="ih hj"> p </strong>)，该漏失率在0和1的范围内，其中1表示没有漏失，0表示该层没有输出。良好的丢失率值介于0.5和0.6之间</p><p id="deac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Dropout是神经网络中正则化的一种方式。</strong></p><p id="21cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">测试</strong> <br/>在测试模型时，我们必须使用所有的节点，并用我们决定的<strong class="ih hj"> p </strong>值(<strong class="ih hj"> w x p </strong>)乘以权重。</p><h2 id="7dc3" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">Keras API辍学</h2><p id="7d4f" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">在Keras中，辍学被表示为<em class="ka">核心层</em> (Keras，未注明日期)之一:</p><pre class="jf jg jh ji fd lb lc ld le aw lf bi"><span id="47ce" class="kb kc hi lc b fi lg lh l li lj">keras.layers.Dropout(rate, noise_shape=None, seed=None)</span></pre><p id="642f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它可以通过<code class="du lk ll lm lc b">model.add</code>添加到Keras深度学习模型中，并包含以下属性:</p><ul class=""><li id="fe8c" class="jm jn hi ih b ii ij im in iq jo iu jp iy jq jc ln js jt ju bi translated"><strong class="ih hj"> Rate </strong>:决定神经元脱落几率的参数p。</li><li id="950b" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc ln js jt ju bi translated"><strong class="ih hj">噪声形状:</strong>如果您希望在(批处理、时间步长、特征)中共享噪声，您可以为此目的设置噪声形状。</li><li id="8d14" class="jm jn hi ih b ii jv im jw iq jx iu jy iy jz jc ln js jt ju bi translated"><strong class="ih hj">种子</strong>:如果您希望固定决定伯努利变量是1还是0的伪随机生成器(例如，排除数字生成器的问题)，那么您可以通过在此指定一个整数值来设置一些种子。</li></ul><h2 id="e903" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated"><strong class="ak">如何使用Dropout </strong></h2><p id="6831" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated">没有退出的CNN可以用如下代码表示:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="er es lo"><img src="../Images/1a93eb3c7687e011bef89e3112254ed8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mcR-axmZ4578YM906utpYA.png"/></div></div></figure><p id="24b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，要添加一个dropout层，我们可以添加这样一行:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="er es lt"><img src="../Images/9b5fc4780ff8eb7f45838e927a0936e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pww2pqxfF5w52A7KHxuUGw.png"/></div></div></figure><p id="5d75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们可以看到dropout参数为0.5，这意味着一半的给定单元将会退出。您可以更改辍学率值来检查其执行情况。</p><h1 id="01f9" class="lu kc hi bd kd lv lw lx kh ly lz ma kl mb mc md ko me mf mg kr mh mi mj ku mk bi translated">终于！</h1><p id="8ef2" class="pw-post-body-paragraph if ig hi ih b ii kw ik il im kx io ip iq ky is it iu kz iw ix iy la ja jb jc hb bi translated"><em class="ka">感谢阅读！</em></p><p id="9554" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你喜欢这个，请投我一票，也建议一些更多的主题。</p><p id="3b66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请随时在<a class="ae jd" href="https://www.linkedin.com/in/ajinkya-mishrikotkar-a6594a144/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> LinkedIn </strong> </a>上联系我</p><p id="0b49" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">欢迎在下面发表评论，并提出你认为我遗漏了什么。谢谢！</p></div></div>    
</body>
</html>