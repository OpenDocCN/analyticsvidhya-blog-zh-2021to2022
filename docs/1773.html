<html>
<head>
<title>Fuzzy String Matching with Spark in Python — Real World Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中使用Spark的模糊字符串匹配——真实世界示例</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/fuzzy-string-matching-with-spark-in-python-7fcd0c422f71?source=collection_archive---------3-----------------------#2021-03-17">https://medium.com/analytics-vidhya/fuzzy-string-matching-with-spark-in-python-7fcd0c422f71?source=collection_archive---------3-----------------------#2021-03-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f003c5d387e5c1fcac95eed1c7649ef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ih37jMlBTxnCAd5_uWg_HQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">它们是相同的，但是不同的。</figcaption></figure><p id="2f74" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi js translated">模糊字符串匹配是数据科学中数据清理过程中经常使用的一种技术。它试图匹配由于各种原因(如人为错误，不同的数据源，...)但实际上指的是同一个东西，比如美国总统上下文中的‘巴拉克·奥巴马’和‘b·奥巴马’。本文将通过必要的步骤(包括代码)来使用Spark的Python API对一个真实示例执行模糊字符串匹配。</p></div><div class="ab cl kb kc gp kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="hb hc hd he hf"><h1 id="aa6a" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">真实世界的例子</h1><p id="3d3d" class="pw-post-body-paragraph iu iv hi iw b ix lg iz ja jb lh jd je jf li jh ji jj lj jl jm jn lk jp jq jr hb bi translated">例如，我们将使用包含电影细节的两个数据集。第一个数据集来自明尼苏达大学的研究实验室GroupLens，包含62423部电影的信息(<a class="ae ll" href="https://grouplens.org/datasets/movielens/latest/" rel="noopener ugc nofollow" target="_blank">数据集</a>)。第二个数据集包含来自IMDB的100部电影(<a class="ae ll" href="https://github.com/mielverkerken/FuzzyStringMatching/blob/master/imdb_sample.csv" rel="noopener ugc nofollow" target="_blank">数据集</a>)。目标是根据电影标题将IMDB电影连接到GroupLens数据集中的相应电影，并显示两个平台的相应评级。开始吧！</p><h2 id="87c9" class="lm kj hi bd kk ln lo lp ko lq lr ls ks jf lt lu kw jj lv lw la jn lx ly le lz bi translated">火花初始化</h2><p id="0255" class="pw-post-body-paragraph iu iv hi iw b ix lg iz ja jb lh jd je jf li jh ji jj lj jl jm jn lk jp jq jr hb bi translated">我们将使用<a class="ae ll" href="https://spark.apache.org/" rel="noopener ugc nofollow" target="_blank"> Spark </a>，一个用于大规模数据处理的统一分析引擎。首先，需要初始化spark上下文。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="4d03" class="lm kj hi mf b fi mj mk l ml mm">import pyspark<br/>from pyspark.sql import SparkSession, functions as F</span><span id="19cd" class="lm kj hi mf b fi mn mk l ml mm">sc = pyspark.SparkContext('local[*]')<br/>spark = SparkSession.builder.getOrCreate()</span></pre><h2 id="649f" class="lm kj hi bd kk ln lo lp ko lq lr ls ks jf lt lu kw jj lv lw la jn lx ly le lz bi translated">数据加载</h2><p id="7aef" class="pw-post-body-paragraph iu iv hi iw b ix lg iz ja jb lh jd je jf li jh ji jj lj jl jm jn lk jp jq jr hb bi translated">在开始处理数据之前，需要将数据加载到分布式数据框架(DDF)中。这使我们能够在spark的弹性分布式数据集(RDD)之上使用高级API。</p><p id="a7d9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">GroupLens数据集不包含具有电影及其相应评级的单个文件，而是包含电影细节的文件和包含2500万用户个人评级的单独文件。我们首先需要计算每部电影的平均评分，并将结果与电影的细节相结合。</p><p id="3201" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们开始加载包含电影细节的文件，同时只保留必要的数据，方法是从标题中去掉发行年份，去掉类型。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="efd2" class="lm kj hi mf b fi mj mk l ml mm">stripYear = F.udf(lambda title: title[:-7])<br/>movies_ddf = (spark.read.csv('movies.csv', header=True, inferSchema=True)<br/>              .drop('genres')<br/>              .withColumn('title', stripYear(F.col('title'))))<br/>movies_ddf.show(5, False)</span><span id="4257" class="lm kj hi mf b fi mn mk l ml mm">+-------+---------------------------+<br/>|movieId|title                      |<br/>+-------+---------------------------+<br/>|1      |Toy Story                  |<br/>|2      |Jumanji                    |<br/>|3      |Grumpier Old Men           |<br/>|4      |Waiting to Exhale          |<br/>|5      |Father of the Bride Part II|<br/>+-------+---------------------------+</span></pre><p id="bfed" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">接下来，我们加载用户评级。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="e019" class="lm kj hi mf b fi mj mk l ml mm">ratings_ddf = (spark.read.csv('ratings.csv', header=True, inferSchema=True)<br/>                .drop('timestamp'))<br/>ratings_ddf.show(5, False)</span><span id="392f" class="lm kj hi mf b fi mn mk l ml mm">+------+-------+------+<br/>|userId|movieId|rating|<br/>+------+-------+------+<br/>|1     |296    |5.0   |<br/>|1     |306    |3.5   |<br/>|1     |307    |5.0   |<br/>|1     |665    |5.0   |<br/>|1     |899    |3.5   |<br/>+------+-------+------+</span></pre><p id="4bd5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然后我们可以计算每部电影的平均收视率，并加入两个DDF的。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="0b2c" class="lm kj hi mf b fi mj mk l ml mm">lens_ddf = (ratings_ddf<br/>  .groupby('movieId')<br/>  .avg('rating')<br/>  .select(F.col('movieId'), F.col('avg(rating)').alias('Rating'))<br/>  .join(movies_ddf, 'movieId'))<br/>lens_ddf.show(5, False)</span><span id="1a5f" class="lm kj hi mf b fi mn mk l ml mm">+-------+------------------+-------------------------+<br/>|movieId|Rating            |Title                    |<br/>+-------+------------------+-------------------------+<br/>|1088   |3.25002094679514  |Dirty Dancing            |<br/>|1580   |3.5817083457378187|Men in Black (a.k.a. MIB)|<br/>|3175   |3.6077836141619484|Galaxy Quest             |<br/>|44022  |3.2593627146699773|Ice Age 2: The Meltdown  |<br/>|175197 |2.754918032786885 |The Dark Tower           |<br/>+-------+------------------+-------------------------+</span></pre><p id="f665" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">100个IMDB电影数据集已经在单个文件中包含了所有需要的数据。轻松点。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="b899" class="lm kj hi mf b fi mj mk l ml mm">imdb_df = (spark.read.csv('imdb_sample.csv', sep=';', header='true')<br/>           .select('Id', 'Title', F.col('ImdbScore').alias('Rating')))<br/>imdb_df.show(5, False)</span><span id="6311" class="lm kj hi mf b fi mn mk l ml mm">+---+------------------------+------+<br/>|Id |Title                   |Rating|<br/>+---+------------------------+------+<br/>|1  |The Shawshank Redemption|9.2   |<br/>|2  |The Godfather           |9.2   |<br/>|3  |The Godfather: Part II  |9     |<br/>|4  |Pulp Fiction            |8.9   |<br/>|5  |Schindler's List        |8.9   |<br/>+---+------------------------+------+</span></pre><h2 id="6013" class="lm kj hi bd kk ln lo lp ko lq lr ls ks jf lt lu kw jj lv lw la jn lx ly le lz bi translated">基线连接</h2><p id="57d0" class="pw-post-body-paragraph iu iv hi iw b ix lg iz ja jb lh jd je jf li jh ji jj lj jl jm jn lk jp jq jr hb bi translated">现在数据被正确加载，我们到达使用<em class="mo">‘模糊字符串匹配’</em>链接GroupLens和IMDB电影的有趣部分。作为基线，通过使用<em class="mo">标题</em>连接两个数据集，在100个匹配中产生64个匹配。不错，但我们肯定可以做得更好！</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="0e5b" class="lm kj hi mf b fi mj mk l ml mm">result = imdb_df.join(lens_ddf, 'Title')<br/>result.count()</span><span id="07e1" class="lm kj hi mf b fi mn mk l ml mm"># 64 matches</span></pre><h2 id="10dc" class="lm kj hi bd kk ln lo lp ko lq lr ls ks jf lt lu kw jj lv lw la jn lx ly le lz bi translated">记录链接</h2><p id="9dc2" class="pw-post-body-paragraph iu iv hi iw b ix lg iz ja jb lh jd je jf li jh ji jj lj jl jm jn lk jp jq jr hb bi translated">为了匹配等效的电影标题，我们需要一个度量来告诉我们两个字符串有多相似。Jaccard距离是两个有限集之间相似性的常用指标。它被定义为1减去交集的大小除以两个集合的并集的大小。</p><blockquote class="mp mq mr"><p id="341c" class="iu iv mo iw b ix iy iz ja jb jc jd je ms jg jh ji mt jk jl jm mu jo jp jq jr hb bi translated"><strong class="iw hj"> <em class="hi"> D(A，B) = 1 - |A∩B|/|A∪B| </em> </strong></p></blockquote><p id="abf5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在我们使用这个距离函数之前，字符串需要被转换成一个集合。常用的两个技巧:<em class="mo">词袋</em>和<em class="mo"> n-Grams </em>。对于这个用例，单词包并不合适，因为拼写错误的单词永远不会与它们的原始单词相匹配。相反，我们将在角色层面使用<em class="mo"> 2个字母</em>。人们可以为n选择另一个值，但是因为<em class="mo">标题</em>相对较短，并且(几乎所有)<em class="mo"> </em> n-grams的概率较小，所以低值是优选的。</p><p id="9f6b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">英语中包含了很多非常常见的单词，叫做<em class="mo">停用词</em>。将这些包含在我们的集合中可能会错误地减少或增加Jaccard距离。根据上下文，删除空格、大写字母或标点符号也是有益的。</p><p id="d25d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这种方法的唯一问题是，为两个数据集中的所有元素成对计算该距离会随着数据集的大小呈指数增长，即<em class="mo"> O(n ) </em>。幸运的是已经存在一种叫做<a class="ae ll" href="https://en.wikipedia.org/wiki/MinHash" rel="noopener ugc nofollow" target="_blank"><em class="mo">MinHash</em></a><em class="mo"/>的技术，以较低的<a class="ae ll" href="http://web.eecs.utk.edu/~jplank/plank/classes/cs494/494/notes/Min-Hash/index.html" rel="noopener ugc nofollow" target="_blank">复杂度</a>来估计这个距离，在Spark中实现。</p><h2 id="fa76" class="lm kj hi bd kk ln lo lp ko lq lr ls ks jf lt lu kw jj lv lw la jn lx ly le lz bi translated">预处理流水线</h2><figure class="ma mb mc md fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/d9ab71b648adf77a2cfb1a97fb90dd48.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*N9hZzjDDRLKC3cmQn_m84g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">预处理管道:“肖申克的救赎”</figcaption></figure><p id="db05" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们看一下整个流程。首先，字符串被转换成小写。然后，小写字符串被连续标记化，最常见的(英语)单词被<code class="du mw mx my mf b"><a class="ae ll" href="https://spark.apache.org/docs/latest/ml-features#stopwordsremover" rel="noopener ugc nofollow" target="_blank">StopWordsRemove</a>r</code>删除。在将这些关键字放入正确的格式后，我们应用<code class="du mw mx my mf b"><a class="ae ll" href="https://spark.apache.org/docs/latest/ml-features#n-gram" rel="noopener ugc nofollow" target="_blank">NGra</a>m</code>，产生成对的字符。在我们用<code class="du mw mx my mf b"><a class="ae ll" href="https://spark.apache.org/docs/latest/ml-features#minhash-for-jaccard-distance" rel="noopener ugc nofollow" target="_blank">MinHashLSH</a></code>估计<em class="mo"> Jaccard距离</em>之前，字符对被矢量化。</p><p id="9b51" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在Spark中实现这一点最简单的方法是使用机器学习管道。此管道包含现有的转换器和用户定义的SQLTransformers。GroupLens和IMDB DDF通过相同的管道进行转换。在包含单个角色的电影的数据集中存在一些异常。这些导致n元文法的空集，因此不能被散列，因此应该被过滤掉。</p><p id="c8a9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">首先，我们在GroupLens数据集上拟合管道并应用转换。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="7768" class="lm kj hi mf b fi mj mk l ml mm">from pyspark.ml import Pipeline<br/>from pyspark.ml.feature import StopWordsRemover, Tokenizer, NGram, HashingTF, MinHashLSH, RegexTokenizer, SQLTransformer</span><span id="d4d4" class="lm kj hi mf b fi mn mk l ml mm">model = Pipeline(stages=[<br/>    SQLTransformer(statement="SELECT *, lower(Title) lower FROM __THIS__"),<br/>    Tokenizer(inputCol="lower", outputCol="token"),<br/>    StopWordsRemover(inputCol="token", outputCol="stop"),<br/>    SQLTransformer(statement="SELECT *, concat_ws(' ', stop) concat FROM __THIS__"),<br/>    RegexTokenizer(pattern="", inputCol="concat", outputCol="char", minTokenLength=1),<br/>    NGram(n=<strong class="mf hj">2</strong>, inputCol="char", outputCol="ngram"),<br/>    HashingTF(inputCol="ngram", outputCol="vector"),<br/>    MinHashLSH(inputCol="vector", outputCol="lsh", numHashTables=<strong class="mf hj">3</strong>)<br/>]).fit(lens_ddf)</span><span id="3d9e" class="lm kj hi mf b fi mn mk l ml mm">result_lens = model.transform(lens_ddf)<br/>result_lens = result_lens.filter(F.size(F.col("ngram")) &gt; 0)</span></pre><p id="ef27" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">然后，我们在IMDB数据集上应用相同的拟合管道。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="53f0" class="lm kj hi mf b fi mj mk l ml mm">result_imdb = model.transform(IMDB_df)<br/>result_imdb = result_imdb.filter(F.size(F.col("ngram")) &gt; 0)</span></pre><h2 id="2747" class="lm kj hi bd kk ln lo lp ko lq lr ls ks jf lt lu kw jj lv lw la jn lx ly le lz bi translated">相似连接</h2><p id="4944" class="pw-post-body-paragraph iu iv hi iw b ix lg iz ja jb lh jd je jf li jh ji jj lj jl jm jn lk jp jq jr hb bi translated">现在两个数据集都准备好了，我们可以通过提供一个最大Jaccard距离将它们连接在一起，从而产生一个匹配。降低该阈值将提供更精确的匹配，从而产生更少的假阳性，但是可能会导致遗漏一些真阳性。如果两个字符串长度相等，Jaccard距离为0.5相当于三分之二的匹配。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="13aa" class="lm kj hi mf b fi mj mk l ml mm">result = model.stages[-1].approxSimilarityJoin(result_imdb, result_lens, 0.5, "jaccardDist")<br/>(result<br/> .select('datasetA.id', 'datasetA.Title', 'datasetB.Title', 'jaccardDist')<br/> .sort(F.col('datasetA.id'))<br/> .show(5))</span><span id="fbe0" class="lm kj hi mf b fi mn mk l ml mm">+---+--------------------+--------------------+-------------------+<br/>| id|               Title|               Title|        jaccardDist|<br/>+---+--------------------+--------------------+-------------------+<br/>|  1|The Shawshank Red...|Shawshank Redempt...|0.05555555555555558|<br/>|  1|The Shawshank Red...|          Redemption|0.47058823529411764|<br/>| 10|          Fight Club|          Fight Club|                0.0|<br/>| 10|          Fight Club|   Female Fight Club|             0.4375|<br/>| 10|          Fight Club|   Zombie Fight Club|             0.4375|<br/>+---+--------------------+--------------------+-------------------+</span></pre><p id="dec7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">不是降低Jaccard距离以获得更少但更正确的匹配，而是以额外的计算成本选择具有最小距离的匹配。这是通过在<em class="mo"> id上聚合来完成的。</em></p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="4a54" class="lm kj hi mf b fi mj mk l ml mm">from pyspark.sql import Window</span><span id="d9a2" class="lm kj hi mf b fi mn mk l ml mm">w = Window.partitionBy('datasetA.id')<br/>result = (result<br/>           .withColumn('minDist', F.min('jaccardDist').over(w))<br/>           .where(F.col('jaccardDist') == F.col('minDist'))<br/>           .drop('minDist'))<br/>(result<br/> .select('datasetA.Title', 'datasetB.Title', 'jaccardDist')<br/> .sort(F.col('datasetA.id'))<br/> .show(5))</span><span id="ec86" class="lm kj hi mf b fi mn mk l ml mm">+--------------------+--------------------+--------------------+<br/>|               Title|               Title|         jaccardDist|<br/>+--------------------+--------------------+--------------------+<br/>|The Shawshank Red...|Shawshank Redempt...| 0.05555555555555558|<br/>|          Fight Club|          Fight Club|                 0.0|<br/>| Inglorious Basterds|Inglourious Basterds| 0.10526315789473684|<br/>|The Lord of the R...|Lord of the Rings...|0.045454545454545414|<br/>|        Forrest Gump|        Forrest Gump|                 0.0|<br/>+--------------------+--------------------+--------------------+</span></pre><p id="6092" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在可以显示包含IMDB和GroupLens评级的最终数据框。</p><pre class="ma mb mc md fd me mf mg mh aw mi bi"><span id="b433" class="lm kj hi mf b fi mj mk l ml mm">result.select('datasetA.Title', 'datasetB.Title', 'datasetA.Rating', 'datasetB.Rating').show(5)</span><span id="c220" class="lm kj hi mf b fi mn mk l ml mm">+--------------------+--------------------+------+-----------------+<br/>|               Title|               Title|Rating|   Rating (stars)|<br/>+--------------------+--------------------+------+-----------------+<br/>|               Alien|               Alien|   8.5|4.055518882196001|<br/>|Star Wars Episode...|Star Wars: Episod...|   8.7|4.144122313069856|<br/>|       The Lion King|       The Lion King|   8.4| 3.14922480620155|<br/>|The Lord of the R...|Lord of the Rings...|   8.8|4.091188818716808|<br/>|Once upon a Time ...|    Once Upon a Time|   8.6|3.363636363636363|<br/>+--------------------+--------------------+------+-----------------+</span></pre><h2 id="5321" class="lm kj hi bd kk ln lo lp ko lq lr ls ks jf lt lu kw jj lv lw la jn lx ly le lz bi translated">结论</h2><p id="b048" class="pw-post-body-paragraph iu iv hi iw b ix lg iz ja jb lh jd je jf li jh ji jj lj jl jm jn lk jp jq jr hb bi translated">人工检查告诉我们，100部IMBD电影中有92部与GroupLens数据集的同类电影匹配，只有少数错误匹配。表明使用Spark可以轻松实现高效和有效的模糊字符串匹配。</p><ul class=""><li id="1b10" class="mz na hi iw b ix iy jb jc jf nb jj nc jn nd jr ne nf ng nh bi translated"><a class="ae ll" href="https://github.com/mielverkerken/FuzzyStringMatching/blob/master/fuzzy_string_matching.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本(GitHub) </a></li></ul></div></div>    
</body>
</html>