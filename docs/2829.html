<html>
<head>
<title>Logistic Regression in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的逻辑回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/logistic-regression-in-machine-learning-f3a90c13bb41?source=collection_archive---------3-----------------------#2021-05-19">https://medium.com/analytics-vidhya/logistic-regression-in-machine-learning-f3a90c13bb41?source=collection_archive---------3-----------------------#2021-05-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="6234" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">线性回归与逻辑回归</p><ol class=""><li id="6608" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">两者都是由<strong class="ig hi">监督的</strong>学习模型，并利用<strong class="ig hi">标记的数据</strong>进行预测。</li><li id="69cd" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated"><strong class="ig hi">线性回归</strong>用于<strong class="ig hi">回归(预测)</strong>问题，而<strong class="ig hi">逻辑回归</strong>可用于<strong class="ig hi">分类和回归问题</strong>，但广泛用作分类算法。</li></ol><p id="c1de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归使用预测建模的概念作为回归；因此，它被称为逻辑回归，但用于分类样本；因此，它属于分类算法。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es jq"><img src="../Images/a556caa732034c2c225b9b649fe6be29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*BrLF7ySJ_6Lfw2IXmNjsXQ.png"/></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">来源:<a class="ae kc" href="https://www.datacamp.com/" rel="noopener ugc nofollow" target="_blank">数据营</a></figcaption></figure><p id="6835" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。逻辑回归</strong>用于因变量为<strong class="ig hi">二进制时，如</strong>是否点击给定的广告链接，垃圾邮件检测。糖尿病预测，客户是否购买，员工是否离职，而<strong class="ig hi">线性回归</strong>用于因变量为<strong class="ig hi">连续</strong>的情况，如价格、年龄、工资等</p><p id="0ede" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.线性回归使用<strong class="ig hi">普通最小二乘法(OLS) </strong>即距离最小化近似值，而逻辑回归使用<strong class="ig hi">最大似然估计(MLE) </strong>方法，即确定最大似然产生期望输出的参数(均值和方差)。</p><h1 id="e53d" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">逻辑回归的类型:</h1><p id="2ccb" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">根据因变量，逻辑回归可以分为三种类型:</p><ol class=""><li id="18e3" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated"><strong class="ig hi">二项式:</strong>因变量只能有两种可能的类型，如0或1，通过或失败，购买或不购买，高或矮，胖或瘦，岩石或矿山等。</li><li id="dad2" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated"><strong class="ig hi">多项式:</strong>可能有3个或更多可能的<strong class="ig hi">无序</strong>因变量类型，如苹果、香蕉、橙子或猫、狗、山羊、绵羊或德里、孟买、班加罗尔、加尔各答。</li><li id="d1eb" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated"><strong class="ig hi">序数:</strong>在序数逻辑回归中，可以有3个或更多可能的<strong class="ig hi">有序的</strong>因变量类型，如高、中、低，或从1到5的餐馆评级或灯光强度，或5分的李克特量表等</li></ol><h1 id="7cb3" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">线性回归方程:</h1><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es lg"><img src="../Images/0c7c9d777ee94c54e50b56fa1ed1afad.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*P7JfKCR_-f9gU-sedYt5MQ.png"/></div></figure><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es lh"><img src="../Images/1dc5444074ca6fcd0963335af4a0026a.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*tuMmETFTJLEQ0TFaJhfEBg.png"/></div></figure><p id="471a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中y是因变量，X1、X2和Xn是自变量</p><p id="4771" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1.随着更多的离群值，最佳拟合线将偏离，这将降低系统的精度，因此线性回归对离群值非常敏感。</p><p id="9d7f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.它不适合输出超过0到1限制的数据点。</p><p id="320c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了克服这些缺点，使用了逻辑回归。</p><h1 id="8bf8" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">机器学习中的逻辑回归；</h1><ol class=""><li id="8e71" class="jc jd hh ig b ih lb il lc ip li it lj ix lk jb jh ji jj jk bi translated">逻辑回归使用sigmoid或logit函数来压缩最佳拟合直线，该直线将映射任何值，包括从0到1范围内的超出值。所以形成了一个“S”形曲线。</li><li id="53de" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">Sigmoid fun去除了离群点的影响，使输出在0到1之间。</li></ol><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es ll"><img src="../Images/59cd204978e3acfda2e7367f9d7f2754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*vC--ianl5Ua7hQjnivYUww.png"/></div></figure><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es lm"><img src="../Images/a0237b54b4c0725d7ac4cc5c16bdad3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/format:webp/1*oY82-D3RMBaDDx3P9XxPxA.png"/></div></figure><p id="e27b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在线性回归中应用Sigmoid函数</p><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es ln"><img src="../Images/d6c6555558dccc91f6c9bf2af9aa8fc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*UoDYmUyl3wkPLonelfWVTg.png"/></div></figure><h1 id="841f" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">Scikit中的模型构建-了解:</h1><p id="54d5" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">让我们建立一个模型，使用船只的声纳传统来分类探测到的物体是一块岩石还是一英里。这是一个二元分类问题。</p><p id="7d7c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以使用以下链接从Kaggle下载数据集:<a class="ae kc" href="https://www.kaggle.com/mattcarter865/mines-vs-rocks" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/mattcarter865/mines-vs-rocks</a></p><p id="4418" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以跟随我的<a class="ae kc" href="https://github.com/krantiw/Logistic-Regression" rel="noopener ugc nofollow" target="_blank"> Github库中的Jupyter笔记本。</a></p><h2 id="06b0" class="lo ke hh bd kf lp lq lr kj ls lt lu kn ip lv lw kr it lx ly kv ix lz ma kz mb bi translated">1.加载必要的库和数据</h2><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mc"><img src="../Images/77bc8c6e44714e845044e452bcecca3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bHu-LBqCNgn2c5VWTq4PHw.png"/></div></div></figure><p id="ad79" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">分析因变量:数据包含111个矿山和97个岩石。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es mh"><img src="../Images/7a2cebdca07272644767e38a92093ef9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*1Y1gXGqapRDw3n1Lwk4DOQ.png"/></div></figure><h2 id="7ac4" class="lo ke hh bd kf lp lq lr kj ls lt lu kn ip lv lw kr it lx ly kv ix lz ma kz mb bi translated">2.功能选择:</h2><p id="9e8c" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">将给定的61列分为两种类型:</p><p id="54a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1自变量或特征变量2。因变量或目标变量</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mi"><img src="../Images/31b20c230afe82839978b809df845553.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OZCSNAPV0i_Ra23hnY9eIw.png"/></div></div></figure><p id="83c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">绘制散点图，以可视化岩石或骡子特征变量的分布。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es mj"><img src="../Images/60dc5cb92098f168e3252bf9bf17397c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*MqCcJp-XTbyOq-sQqDcjkg.png"/></div></figure><h2 id="027c" class="lo ke hh bd kf lp lq lr kj ls lt lu kn ip lv lw kr it lx ly kv ix lz ma kz mb bi translated">3.拆分数据</h2><p id="987d" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">将数据集拆分为训练集和测试集，以了解模型性能。</p><p id="dcfd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里，数据集以80:20的比例分成两部分。这意味着80%的数据将用于模型训练，20%用于模型测试。</p><p id="e7b3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">分层= y根据因变量平均分割数据，以避免数据不平衡。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mk"><img src="../Images/3c821ddc686695447bcf5214bbb14b61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3eh80ciPFZPMH91RVtsZIg.png"/></div></div></figure><h2 id="4edd" class="lo ke hh bd kf lp lq lr kj ls lt lu kn ip lv lw kr it lx ly kv ix lz ma kz mb bi translated">4.部署模型</h2><p id="7336" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">导入类—逻辑回归，使用Logistic Regression()函数实例化模型。</p><p id="1317" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，使用fit()在训练集上拟合您的模型，并使用predict()在测试集上执行预测。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es ml"><img src="../Images/0bc99e1ef1859bfee6f10ced7c2acecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iKq3LA_UV0EHy4iai8EALg.png"/></div></div></figure><p id="926e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">计算训练和测试数据集的准确度分数</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mm"><img src="../Images/015c31c422853ee45e2a89c199be34e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bROIedyhu9zFzl6JJSUqRQ.png"/></div></div></figure><pre class="jr js jt ju fd mn mo mp mq aw mr bi"><span id="5731" class="lo ke hh mo b fi ms mt l mu mv">Accuracy scores of Training dataset : 0.8192771084337349<br/>Accuracy scores of Testing dataset : 0.8809523809523809</span></pre><h2 id="60a6" class="lo ke hh bd kf lp lq lr kj ls lt lu kn ip lv lw kr it lx ly kv ix lz ma kz mb bi translated">5.使用混淆矩阵的模型评估</h2><ul class=""><li id="0530" class="jc jd hh ig b ih lb il lc ip li it lj ix lk jb mw ji jj jk bi translated">混淆矩阵是一个2X2(模型是二进制分类)表</li><li id="7d29" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">它用于评估分类模型的性能。</li><li id="62a1" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">它是正确的和不正确的分类预测的总和。(岩石和矿山)</li></ul><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es mx"><img src="../Images/98e035b6d91b92c30227ace465c25f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XwkiSn96AzWFj3WoA7c6PA.png"/></div></div></figure><ul class=""><li id="cef2" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb mw ji jj jk bi translated">有两类岩石和矿山。</li><li id="5c40" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">对角线元素(20，17)代表准确的预测。</li><li id="b34f" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">而非对角线元素(2，3)表示不准确的预测。</li></ul><h2 id="29f5" class="lo ke hh bd kf lp lq lr kj ls lt lu kn ip lv lw kr it lx ly kv ix lz ma kz mb bi translated">使用热图可视化混淆矩阵</h2><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es my"><img src="../Images/8d9a432cf48144a476ac2b0217246ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YZ5VmuMy0rSCfVWUSTSEKQ.png"/></div></div></figure><figure class="jr js jt ju fd jv er es paragraph-image"><div class="er es mz"><img src="../Images/c00df0f31f877b7bd7fef74d89b5d9e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1058/format:webp/1*vTrsiAhrZoxO3MXjOCNJkg.png"/></div></figure><p id="014b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">计算矩阵的准确度分数</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es na"><img src="../Images/60465d3d06eb7bac2e8b2fcfd8182213.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hUaXNPAf5OUxxaI5mmOvDg.png"/></div></div></figure><pre class="jr js jt ju fd mn mo mp mq aw mr bi"><span id="ea89" class="lo ke hh mo b fi ms mt l mu mv">Accuracy of Confusion Matrix:0.8809523809523809</span></pre><h2 id="a56b" class="lo ke hh bd kf lp lq lr kj ls lt lu kn ip lv lw kr it lx ly kv ix lz ma kz mb bi translated">6.使用输入数据的模型评估</h2><p id="02ad" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">创建一个函数，该函数采用输出数据的所有特征，将行转换为数组，将数据整形为一行，其特征列为<br/>，并预测数据类别-岩石或英里。</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es nb"><img src="../Images/21a46dc510325ea09aa49bedf8fe28bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Q3nMJpbYINnfvx1D26iHQ.png"/></div></div></figure><p id="3f51" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">检查输入数据的模型。</p><p id="4a32" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第101排属于“英里”类，第1排属于“岩石”类</p><figure class="jr js jt ju fd jv er es paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="er es nc"><img src="../Images/086faa1552d60cd69762856f98ad386d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LfHP26HirCp28njLuD4oUA.png"/></div></div></figure><p id="51e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们得到了正确的输出。因此，我们的模型准确地分类了它的因变量。</p><h1 id="ef63" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">优势</h1><ul class=""><li id="3f78" class="jc jd hh ig b ih lb il lc ip li it lj ix lk jb mw ji jj jk bi translated">高效</li><li id="8639" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">不需要很高的计算能力</li><li id="60ba" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">易于实现，易于解释</li><li id="d42d" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">它不需要缩放特征。</li><li id="1bf2" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">逻辑回归为观察值提供了一个概率得分。</li></ul><h1 id="d05f" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">不足之处</h1><ul class=""><li id="1420" class="jc jd hh ig b ih lb il lc ip li it lj ix lk jb mw ji jj jk bi translated">逻辑回归不能处理大量的分类特征/变量。</li><li id="82b0" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">它容易过度拟合。</li><li id="a435" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">它不能用逻辑回归解决非线性问题，这就是为什么它需要非线性特征的变换。</li><li id="54bb" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb mw ji jj jk bi translated">对于与目标变量不相关且彼此非常相似或相关的独立变量，逻辑回归表现不佳。</li></ul></div></div>    
</body>
</html>