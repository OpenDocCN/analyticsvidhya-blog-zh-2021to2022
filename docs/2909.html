<html>
<head>
<title>Introduction to NLP with Disaster Tweets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">灾难推文NLP简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-nlp-with-disaster-tweets-3b672a75748c?source=collection_archive---------3-----------------------#2021-05-24">https://medium.com/analytics-vidhya/introduction-to-nlp-with-disaster-tweets-3b672a75748c?source=collection_archive---------3-----------------------#2021-05-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div class="er es hf"><img src="../Images/640fb279463f6ee656e4420e1dab6e88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*iuoT4P9L802xZPg0x1oGgA.jpeg"/></div></figure><div class=""/><h1 id="904b" class="il im ho bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">介绍</h1><p id="8f38" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">自然语言处理，也称为NLP，是计算机科学的一个子领域，特别是人工智能，专注于理解书面和口头文本。它涵盖各种任务，其中一些是语音识别、情感分析和语言生成；并且，它已经被应用在多个用例中，例如机器翻译、垃圾邮件检测、虚拟助手和聊天机器人。</p><p id="f453" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">本文涉及的项目是一个名为<a class="ae km" href="https://www.kaggle.com/c/nlp-getting-started" rel="noopener ugc nofollow" target="_blank"> <em class="kn">的自然语言处理与灾难推文</em> </a>的情感分析项目。情感分析是从文本中提取情感或态度等主观品质的过程。该项目的目标是确定一条特定的推文是否是一场真正的灾难。该项目是NLP初学者的理想选择。本文重点介绍了在这个项目中达到80%准确率的步骤，并重点介绍了预处理和模型构建步骤。</p><h1 id="bdd7" class="il im ho bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">关于数据</h1><p id="6d8e" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">训练和测试数据是结构化的带标签的数据，使用<a class="ae km" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> pd.read_csv </em> </a>方法从CSV文件中以pandas DataFrame格式导入。</p><p id="33e0" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">如下图所示，数据帧由以下4列组成:</p><ul class=""><li id="ef8f" class="ko kp ho jl b jm kh jq ki ju kq jy kr kc ks kg kt ku kv kw bi translated">id:每条推文的唯一标识符</li><li id="125d" class="ko kp ho jl b jm kx jq ky ju kz jy la kc lb kg kt ku kv kw bi translated"><strong class="jl hp">关键字</strong>:来自tweet的特定关键字(可以为空)</li><li id="ebbf" class="ko kp ho jl b jm kx jq ky ju kz jy la kc lb kg kt ku kv kw bi translated"><strong class="jl hp">位置</strong>:发送推文的位置(可以为空)</li><li id="e03f" class="ko kp ho jl b jm kx jq ky ju kz jy la kc lb kg kt ku kv kw bi translated"><strong class="jl hp">文本</strong>:推文的文本</li><li id="6883" class="ko kp ho jl b jm kx jq ky ju kz jy la kc lb kg kt ku kv kw bi translated"><strong class="jl hp">目标</strong>:仅出现在列车数据中，表示推文是关于真实灾难(1)还是非真实灾难(0)</li></ul><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lc"><img src="../Images/b703ecd3529a96c628fcb27d7eaaf685.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fw1FjQ4o1U9cL668SgQl9Q.png"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">图1:列车数据帧</figcaption></figure><h1 id="adb5" class="il im ho bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">文本预处理</h1><p id="33ae" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">在任何NLP项目中，文本预处理都是建立机器学习模型之前的第一步。这一步包括在以数字向量的形式对文本数据进行编码之前清理和准备文本数据。</p><p id="4834" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">本项目中遵循的文本预处理步骤是:</p><ul class=""><li id="8461" class="ko kp ho jl b jm kh jq ki ju kq jy kr kc ks kg kt ku kv kw bi translated"><strong class="jl hp">小写</strong></li><li id="7463" class="ko kp ho jl b jm kx jq ky ju kz jy la kc lb kg kt ku kv kw bi translated"><strong class="jl hp">实体、网址链接和标点符号删除</strong></li><li id="0d08" class="ko kp ho jl b jm kx jq ky ju kz jy la kc lb kg kt ku kv kw bi translated"><strong class="jl hp">拼写纠正</strong></li><li id="81ac" class="ko kp ho jl b jm kx jq ky ju kz jy la kc lb kg kt ku kv kw bi translated"><strong class="jl hp">通过关键词提取和实体识别填补缺失数据</strong></li><li id="4b8d" class="ko kp ho jl b jm kx jq ky ju kz jy la kc lb kg kt ku kv kw bi translated"><strong class="jl hp">词汇化</strong></li><li id="466d" class="ko kp ho jl b jm kx jq ky ju kz jy la kc lb kg kt ku kv kw bi translated"><strong class="jl hp">停止字清除</strong></li></ul><h2 id="bb40" class="lp im ho bd in lq lr ls ir lt lu lv iv ju lw lx iz jy ly lz jd kc ma mb jh mc bi translated">用小写字体书写</h2><p id="68cd" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">将文本转换成小写是任何NLP项目中必不可少的一步。虽然像<em class="kn">数据</em>、<em class="kn">数据</em>和<em class="kn">数据</em>这样的词对人类来说意思是一样的，但是如果不转换成小写，在向量空间模型中就会表现为三个不同的词。这一步可以简单地使用<a class="ae km" href="https://www.w3schools.com/python/ref_string_lower.asp" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> python string lower()方法</em> </a> <em class="kn">来完成。</em></p><p id="af83" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">在这个项目中，有三个特征(即列—“关键字”、“位置”和“文本”)要转换成小写。这可以在pandas中使用<a class="ae km" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> apply()方法</em> </a> <em class="kn"> </em>来完成。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es md"><img src="../Images/3994e486c9992ccf9d0588fcb4aa50ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HshEjRxZiXamNKfKe1k9Ug.png"/></div></div></figure><p id="4fb0" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">重要的是要注意“关键字”和“位置”列包含缺失值(即:NA值，如numpy.nan或None)；为了避免意外错误，使用<a class="ae km" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isna.html" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> pd.isna </em> </a>方法跳过空条目。</p><h2 id="6213" class="lp im ho bd in lq lr ls ir lt lu lv iv ju lw lx iz jy ly lz jd kc ma mb jh mc bi translated">实体、URL链接和标点符号删除</h2><p id="bd14" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">由于数据集是基于推文的，所以它可能包括许多提及(例如:@RyleeDowns02)和标签(例如:#CAfire)。通过创建如下所示的名为remove_entities的函数，可以删除这些内容。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es me"><img src="../Images/f0a1cc9045841a5400c009c8370c0e78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qxkluEPmeDLd0vucxJF1LA.png"/></div></div></figure><p id="28da" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">此外，你还可以找到像http://t.co/gkNRP0e8Qs这样的链接。regex <a class="ae km" href="https://www.w3schools.com/python/python_regex.asp#sub" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> sub() </em> </a>函数，由<a class="ae km" href="https://docs.python.org/3/library/re.html" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> re模块</em> </a>提供，用于将URL链接替换为空白，如下:</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mf"><img src="../Images/311d3d9dc23d91bcda3ff41058dbe464.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lbMtqgnGFnX59N2v5B4_TQ.png"/></div></div></figure><p id="135c" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">同理，标点也可以去掉。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mg"><img src="../Images/4793d0615e96c5fb840c18473b86dbf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GsW--w9cnNUI-8_hUPaQ0Q.png"/></div></div></figure><h2 id="5179" class="lp im ho bd in lq lr ls ir lt lu lv iv ju lw lx iz jy ly lz jd kc ma mb jh mc bi translated">拼写纠正</h2><p id="6554" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">预计推文将包括几个拼写错误，因此应用拼写纠正来提高性能。<a class="ae km" href="https://pypi.org/project/symspellpy/" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> symspellpy </em> </a>模块用于纠正拼写错误。接下来是如何创建和应用spelling_correction函数:</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mh"><img src="../Images/078b8436aa7e847c7a1342ade762c208.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dZnKfnNGM-0iniLzrUE8wA.png"/></div></div></figure><h2 id="b0b8" class="lp im ho bd in lq lr ls ir lt lu lv iv ju lw lx iz jy ly lz jd kc ma mb jh mc bi translated">填充缺失数据</h2><p id="d7a0" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated"><em class="kn"> train.info() </em>和<em class="kn"> test.info() </em>揭示列车数据在关键字列中有61个条目为空，在位置列中有2533个条目为空；并且，测试数据在关键字列中有26个空条目，在位置列中有1105个空条目。</p><p id="4f54" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated"><strong class="jl hp">关键词提取</strong></p><p id="2e4a" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">extract_keywords函数，如下图所示，灵感来自以下文章<a class="ae km" href="https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea" rel="noopener" target="_blank"> <em class="kn">用BERT </em> </a>和<a class="ae km" href="https://towardsdatascience.com/build-a-keyword-extraction-api-with-spacy-flask-and-fuzzywuzzy-4909d7ffc105" rel="noopener" target="_blank"> <em class="kn">构建关键字提取API用Spacy、Flask和FuzzyWuzzy </em> </a>。它的目标是填充关键字列中缺少的数据。<a class="ae km" href="https://github.com/UKPLab/sentence-transformers" rel="noopener ugc nofollow" target="_blank"> <em class="kn">语句-变形金刚</em> </a>和<a class="ae km" href="https://spacy.io/api/doc" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> spaCy </em> </a>包对于该函数的工作至关重要。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mi"><img src="../Images/27866b6822d8f671968f7bb83bc58582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7pRa_auyKIfVY4BD6wrq4Q.png"/></div></div></figure><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mj"><img src="../Images/5e355ba2127385a2e8e6985aa2204305.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RIGASkftrZqVEb588s1y-Q.png"/></div></div></figure><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mk"><img src="../Images/b6377e06c5a136330e9f77f890aed073.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wcNWeggWYgPTgSeLwCgTZA.png"/></div></div></figure><p id="a099" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated"><strong class="jl hp">实体识别</strong></p><p id="a4e0" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">实体识别用于填充位置列中的空条目。<a class="ae km" href="https://spacy.io/api/doc" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> SpaCy </em> </a>库再次用于实体识别。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es md"><img src="../Images/ac88325179e86b60cec35259b0b3e01c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pd84E-UQ9wg1kQahq7_ccQ.png"/></div></div></figure><h2 id="e123" class="lp im ho bd in lq lr ls ir lt lu lv iv ju lw lx iz jy ly lz jd kc ma mb jh mc bi translated">词汇化</h2><p id="02ed" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">词汇化的目标是将一个单词转换成它的词根形式。词汇化和词干化之间的主要区别在于，词汇化考虑了上下文，并将单词转换为其文本形式，而词干化仅删除单词的最后几个字符。下面是应用术语化所需的步骤。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es md"><img src="../Images/7d131e2b920b2996e48e4cad135724c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RtOsSm30rvGBGO9vW6YsqA.png"/></div></div></figure><h2 id="2d3d" class="lp im ho bd in lq lr ls ir lt lu lv iv ju lw lx iz jy ly lz jd kc ma mb jh mc bi translated">停止单词删除</h2><p id="e4c3" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">停用词为文本提供低级信息，并且经常大量出现；因此，删除它们是为了更加关注其他重要信息。使用spaCy模型，可以很容易地删除停用词。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ml"><img src="../Images/49416f906bf11ca861a3b8d6180d2f06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6apL2l0vdal7vJfj5xhC-Q.png"/></div></div></figure><h1 id="1eaa" class="il im ho bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">模型</h1><p id="964e" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">模型使用<a class="ae km" href="https://keras.io/getting_started/" rel="noopener ugc nofollow" target="_blank"><em class="kn">Keras</em></a><em class="kn"/>库和<a class="ae km" href="https://tfhub.dev/" rel="noopener ugc nofollow" target="_blank"><em class="kn">tensor flow hub</em></a><em class="kn">开发。</em></p><p id="15da" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">使用迁移学习来创建文本嵌入。迁移学习是一种机器学习技术，指的是使用一种模型，这种模型已经在一项任务上进行了训练，并重新用于另一项相关任务。迁移学习通过使用预训练的文本嵌入模型(从TensorFlow hub加载)应用于该项目，以将文本表示为嵌入向量。使用的预训练文本嵌入模型是<a class="ae km" href="https://tfhub.dev/google/nnlm-en-dim50/2" rel="noopener ugc nofollow" target="_blank"><em class="kn">【nnlm-en-dim 50】</em></a>，之前已经在英文Google News 7B语料库上进行了训练。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mm"><img src="../Images/b5b3ee4cef5ab0f3f00e7d6a4c6a381a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M0tOkz24HWJIXXDowCUImA.png"/></div></div></figure><p id="1785" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">加载的<em class="kn">‘嵌入’</em>模型用于创建关键字、位置和文本特征的嵌入。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mn"><img src="../Images/8fdb57c05933505d6ad101d51ea3d5e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_83GPROkN3thR1FTSZXuPg.png"/></div></div></figure><p id="1742" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">使用<a class="ae km" href="https://keras.io/guides/functional_api/" rel="noopener ugc nofollow" target="_blank"> <em class="kn">功能API </em> </a> <em class="kn"> </em>方法构建最终模型。为每个特征创建三个模型(关键词模型、位置模型和文本模型)，然后将这三个模型连接起来创建最终的模型。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mo"><img src="../Images/98467fbcf2dbcc91d34aaab379f8b261.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AtEadgCU67dhlKsk64_JvQ.png"/></div></div></figure><p id="ca66" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">由于目标要么是1，要么是0，损失被设置为<a class="ae km" href="https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class" rel="noopener ugc nofollow" target="_blank"><em class="kn">‘二元_交叉熵’</em></a>。<a class="ae km" href="https://keras.io/api/optimizers/sgd/" rel="noopener ugc nofollow" target="_blank"> <em class="kn">【随机梯度下降(SGD)】</em></a>用作优化器，<a class="ae km" href="https://keras.io/api/metrics/" rel="noopener ugc nofollow" target="_blank"> <em class="kn">【准确度】</em> </a>用作判断模型性能的度量。此外，早期停止作为一种正则化方法应用，以避免过拟合。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mp"><img src="../Images/19395cafb90834920eb2757b32f75ca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ujs6RiQ9dlx-u3iIZTSLDQ.png"/></div></div></figure><p id="d213" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">下图显示了模型拟合在第23个时段停止的结果，训练精度为0.8456，验证精度为0.8031。</p><figure class="ld le lf lg fd hj er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mq"><img src="../Images/2ef8be66052f1bfad743ac39a08d8e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1mH-QBRre8kwpPz4H4xe9Q.png"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">图2:最终模型拟合的结果</figcaption></figure><h1 id="e54a" class="il im ho bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">结论</h1><p id="251e" class="pw-post-body-paragraph jj jk ho jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">本文通过一个情感分析项目介绍了自然语言处理。它侧重于文本预处理和模型创建。</p><p id="da44" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">文本预处理由六个主要步骤组成:小写、实体、URL链接和标点符号去除、拼写校正、填充缺失数据、词条化和停用词去除。重要的是要记住，用户可以选择在文本预处理中包含更多的步骤(例如，将缩写转换为它们的原始形式)，或者排除一些她/他认为不必要的步骤。</p><p id="a4ca" class="pw-post-body-paragraph jj jk ho jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">在模型部分，迁移学习用于创建单词嵌入。人们可以通过尝试不同的预训练文本嵌入模型来进行实验。进一步评估模型性能的一些建议是试验增加或移除密集层、增加或减少神经元的数量、尝试不同的已知优化器以及尝试不同的学习率值。</p></div></div>    
</body>
</html>