<html>
<head>
<title>Akira’s Machine Learning news — #Week 13, 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Akira的机器学习新闻—2021年第13周</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/akiras-machine-learning-news-week-13-2021-9de2c66ce34?source=collection_archive---------32-----------------------#2021-04-03">https://medium.com/analytics-vidhya/akiras-machine-learning-news-week-13-2021-9de2c66ce34?source=collection_archive---------32-----------------------#2021-04-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="887f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2021年第13周(3月28日~)</p><p id="c742" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">论文或文章的发表日期不一定是同一周※</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="beaa" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated">本周特稿/新闻。</h2><ul class=""><li id="ad9e" class="ke kf hh ig b ih kg il kh ip ki it kj ix kk jb kl km kn ko bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.12731" rel="noopener ugc nofollow" target="_blank">在EfficientNet上使用基于Transformer的模型(带有一点CNN)的模型现已推出</a>。它被设计成通过使用自我注意而具有比CNN更宽的感受野，同时保持尽可能小的内存。</li><li id="8c30" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb kl km kn ko bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.13413" rel="noopener ugc nofollow" target="_blank">基于变压器的模型现已上市，可在深度估计等密集预测任务中实现SotA性能</a>。它是基于这样一种想法，即变压器对于这样的任务是有用的，因为它可以向前传播，同时保持不同于CNN的分辨率。</li><li id="a592" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb kl km kn ko bi translated"><a class="ae kp" href="https://sachinruk.github.io/blog/pytorch/pytorch%20lightning/loss%20function/gpu/2021/03/07/CLIP.html" rel="noopener ugc nofollow" target="_blank">有个博客是关于OpenAI的CLIP实现</a>，用的是Pytorch闪电和抱抱脸，实现起来还是比较容易的。</li></ul><h2 id="b061" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated">现实世界中的机器学习</h2><ul class=""><li id="e1fd" class="ke kf hh ig b ih kg il kh ip ki it kj ix kk jb kl km kn ko bi translated"><a class="ae kp" href="https://openai.com/blog/gpt-3-apps/" rel="noopener ugc nofollow" target="_blank"> GPT-3每天产生45亿个单词</a>，大约有300个应用程序使用GPT-3，尽管它们是付费的，但似乎相当成功。似乎一个草根<a class="ae kp" href="https://venturebeat.com/2021/01/15/ai-weekly-meet-the-people-trying-to-replicate-and-open-source-openais-gpt-3/" rel="noopener ugc nofollow" target="_blank">团队正在致力于开发一个免费的GPT-3 </a>，如果这个被开发出来，使用GPT-3的应用数量将会进一步扩大。</li><li id="cc41" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb kl km kn ko bi translated"><a class="ae kp" href="https://openai.com/blog/gpt-3-apps/" rel="noopener ugc nofollow" target="_blank">有一篇关于用深度假代替配音演员的文章</a>。技术上是可以的，但是法律好像还没跟上。面部识别等基于图像的任务的立法也仍处于起步阶段，所以立法者可能会很忙。</li></ul><h2 id="4108" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated">报纸</h2><ul class=""><li id="0660" class="ke kf hh ig b ih kg il kh ip ki it kj ix kk jb kl km kn ko bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.11955" rel="noopener ugc nofollow" target="_blank">已经发表的一项研究表明，该方法的准确性超过了传统方法，只有0.3%的数据</a>。“大数据集x大模型- &gt;高精度”公式现在已经很好地建立起来了，所以作为一个实业家，我很好奇一个可以用小数据集学习的机制会发展到什么程度。</li><li id="77fe" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb kl km kn ko bi translated">有人研究了CutMix的改进版本，这是一种数据增强方法，通过剪切和粘贴图像并将它们混合在一起来提高准确性。这与上面的故事有关，我认为对于应用程序来说，找到使用小数据集提高准确性的方法很重要。</li></ul><p id="f526" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><p id="8d71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在下面的章节中，我将介绍各种文章和论文，不仅仅是关于上述内容，还包括以下五个主题。</p><ol class=""><li id="9f1d" class="ke kf hh ig b ih ii il im ip kv it kw ix kx jb ky km kn ko bi translated">本周特稿/新闻</li><li id="33fb" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb ky km kn ko bi translated">机器学习用例</li><li id="0baa" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb ky km kn ko bi translated">报纸</li><li id="5cf5" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb ky km kn ko bi translated">机器学习技术相关文章</li><li id="1f5b" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb ky km kn ko bi translated">其他主题</li></ol><p id="1d74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="3416" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">1.本周特稿/新闻</h1><h2 id="a580" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.12731?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">变压器型高效网</strong> </a></h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es lq"><img src="../Images/029324caf77555cbc39048129166d451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sShWm5OD5GgwrG3ogVFsJw.png"/></div></div></figure><p id="5b01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2103.12731]为参数高效的视觉骨干缩放局部自我关注</p><p id="d460" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">建议HaloNet使用自我关注(和几个CNN)在EfficientNet上进行权衡。通过阻止局部自我注意，HaloNet可以处理高分辨率图像，比传统方法具有更宽的视野和更少的内存。基本思想是一种局部注意力机制，该机制使用划分图像(sizd=b)及其邻域(size=h)的块。图像类似于卷积，在大小为b的块图像及其邻域h中取局部注意，感受野的大小为(b+2h)，在与ResNet(表5)比较的实验中，b=32，h=3，感受野为38x38像素，相当大。与EfficientNetB7相当的H7模型使用b=10，h=3。然而，它不是一个纯粹的自我关注模型，而是在第一层使用Conv，它遵循<a class="ae kp" href="https://arxiv.org/abs/1906.05909" rel="noopener ugc nofollow" target="_blank">独立自我关注</a>。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="88f2" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.13413?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">深度估计和语义分割的精度大大提高</strong> </a></h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es mc"><img src="../Images/d7d4d428b60fcaa1ca8e1d82e0dcfe6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qZ3UpFIg42q07ElCp4AD8A.png"/></div></div></figure><p id="ed58" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2103.13413]用于密集预测的视觉转换器</p><p id="1f25" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">他们使用基于转换器的模型ViT来计算高精度的预测地图，用于语义分割和深度估计等任务。它显然是基于这样的想法，即ViT对于这些任务是有利的，因为它不像CNN那样在不损失分辨率的情况下传播。在深度估计和语义分割中实现了SotA性能，并且计算了精确的预测图。基本模型是基于ViT (DPT-Base，DPT-Large)的，但也有一种模型是使用ResNet50进行特征提取(DPT-Hybrid)，而不是直接排列斑块分割的RGB特征。让CNN进行初始特征提取的想法类似于<a class="ae kp" href="https://arxiv.org/abs/2103.11816" rel="noopener ugc nofollow" target="_blank">将卷积设计并入视觉变形金刚</a>。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="dca3" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://sachinruk.github.io/blog/pytorch/pytorch%20lightning/loss%20function/gpu/2021/03/07/CLIP.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">实施剪辑</a></h2><div class="md me ez fb mf mg"><a href="https://sachinruk.github.io/blog/pytorch/pytorch%20lightning/loss%20function/gpu/2021/03/07/CLIP.html" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">多语言剪辑，带Huggingface + PyTorch Lightning🤗 ⚡</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">对于像我这样没有经历过对比损失的人来说，这是最有趣的部分。我们知道我们…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">sachinruk.github.io</p></div></div></div></a></div><p id="fbb4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文描述了<a class="ae kp" href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision. pdf)" rel="noopener ugc nofollow" target="_blank"> OpenAI的CLIP </a>的实现，它可以获取特定语言的图像表示。本文解释了如何实现CLIP(。使用Huggingface和Pytorch Lightning。实现起来似乎相当简单。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="b9f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="a48a" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">2.机器学习用例</h1><p id="4949" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip mp ir is it mq iv iw ix mr iz ja jb ha bi translated"><a class="ae kp" href="https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">脸书打击恶意信息传播的行动史</strong> </a></p><div class="md me ez fb mf mg"><a href="https://www.technologyreview.com/2021/03/11/1020600/facebook-responsible-ai-misinformation/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">他让脸书迷上了人工智能。现在，他无法修复它的错误信息瘾</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">该公司的人工智能算法给了它一个永不满足的谎言和仇恨言论的习惯。现在这个建造了…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.technologyreview.com</p></div></div><div class="ms l"><div class="mt l mu mv mw ms mx ma mg"/></div></div></a></div><p id="1104" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章叙述性地解释了脸书在美国国会大厦骚乱等相关事件中对其社交网站上的许多虚假和恶意信息采取的行动。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="6d9f" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://www.wired.com/story/simpsons-voice-actors-ai-deepfakes/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">有没有可能用深假代替配音演员？</strong>T13】</a></h2><div class="md me ez fb mf mg"><a href="https://www.wired.com/story/simpsons-voice-actors-ai-deepfakes/" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">《辛普森一家》会用人工智能代替配音演员吗？</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">2015年5月,《辛普森一家》的配音演员哈里·谢尔——他扮演了许多关键角色，包括，非常不可思议的…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.wired.com</p></div></div><div class="ms l"><div class="my l mu mv mw ms mx ma mg"/></div></div></a></div><p id="1f14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一篇从技术和法律上考察在存储大量《辛普森一家》等配音演员数据的情况下，是否可以用Deep Fake来代替配音演员的文章。技术上是可以的，但是法律上，有一些模糊之处。</p><p id="e05c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae kp" href="https://openai.com/blog/gpt-3-apps/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi"/></a>GPT-3用例</p><div class="md me ez fb mf mg"><a href="https://openai.com/blog/gpt-3-apps/" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">GPT-3驱动下一代应用</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">自从我们的第一个商业产品OpenAI API发布以来的九个月里，已经有超过300个…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">openai.com</p></div></div><div class="ms l"><div class="mz l mu mv mw ms mx ma mg"/></div></div></a></div><p id="cb01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个关于GPT-3在OpenAI中的商业应用的博客。它描述了GPT-3目前如何在大约300个应用程序中使用，以及由于GPT-3的产生，人物现在如何能够进行自然对话。GPT 3号每天产生45亿个单词。</p><p id="e8ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="7352" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">3.报纸</h1><h2 id="8a1f" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.13023?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">训练ViT带不带自然图像</strong> </a></h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es na"><img src="../Images/7f07100988bf91eb9b8460657397c0a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VTybaqdJm3Uy1BdnRxpV1A.png"/></div></div></figure><p id="e23f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2103.13023]视觉变形金刚可以在没有自然图像的情况下学习吗？</p><p id="6c43" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在人造图像数据集FractalDB上对ViT进行预训练的研究。它产生的可视化结果不同于在ImageNet上训练的结果，但与在自然图像(如CIFAR10)上的ImageNet预训练模型一样准确。人工数据集的优点是没有隐私或其他问题。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="1f01" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.11955?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">用常规数据量的0.3%学习</strong> </a></h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es nb"><img src="../Images/b53b11b74d1c979bf494168bea510ea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dYgkcUEWcLCNdrpMrqMwZQ.png"/></div></div></figure><p id="89de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2103.11955]改进和简化模式开发培训</p><p id="001e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">提出的ADAPET修改了PET的损失函数，仅用0.3%的数据就超过了它的精度。受过两种类型损失的训练:对整个词汇表而不仅仅是关系令牌取softmax的数据效率损失，以及给定关系时填空的损失。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="d4e4" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://arxiv.org/abs/2005.09704?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> 8K图像修复</strong> </a></h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es nc"><img src="../Images/f63f16423a2a5a12a0ea03919b989671.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LBEEVY4igxs8DSgFYWhC7w.png"/></div></div></figure><p id="bb1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2005.09704]用于超高分辨率图像修复的上下文残差聚合</p><p id="d3e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在修复任务中，通过生成低分辨率图像，然后添加高频分量，他们可以在低内存的情况下修复超高分辨率图像。有可能生成8K图像，不像以前的研究。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="ad1c" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://arxiv.org/abs/2012.11101?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">针对缺失信息改进CutMix。</strong>T3】</a></h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es nd"><img src="../Images/b32f922e79afb1e31c7400caffb9124f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YCmoKR3XITtI-br1k4qzGg.png"/></div></div></figure><p id="dfc7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2012.11101] ResizeMix:将数据与保留的对象信息和真实标签混合</p><p id="09d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">CutMix是一种有用的数据扩充方法，它可以裁剪一幅图像并将其粘贴到另一幅图像中，但是该图像可能会被裁剪而丢失重要信息。他们提出了ResizeMix，通过调整图像大小而不进行裁剪和粘贴来防止重要信息的丢失。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="dade" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="baad" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">4.机器学习技术相关文章</h1><h2 id="1693" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://ai.facebook.com/blog/building-ai-that-can-understand-variation-in-the-world-around-us/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">学会对扰动保持稳健</strong> </a></h2><div class="md me ez fb mf mg"><a href="https://ai.facebook.com/blog/building-ai-that-can-understand-variation-in-the-world-around-us/" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">构建能够理解我们周围世界变化的人工智能</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">人类天生理解我们周围世界的无数变化。当我们看到一只狗时，我们知道它是什么，即使它是…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">ai.facebook.com</p></div></div><div class="ms l"><div class="ne l mu mv mw ms mx ma mg"/></div></div></a></div><p id="d688" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">脸书研究的介绍性博客。人类可以认出一辆公交车，即使它已经倒了，但机器学习模型不能。有一些技术可以区分这种扰动，但是这篇博客介绍了当前方法的问题和一种使用等变算子的方法。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="4b9a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="c5bc" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">5.其他主题</h1><h2 id="940e" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://ai.googleblog.com/2020/12/mediapipe-holistic-simultaneous-face.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">同时预测设备上的脸部、手部和身体位置</strong> </a></h2><div class="md me ez fb mf mg"><a href="https://ai.googleblog.com/2020/12/mediapipe-holistic-simultaneous-face.html" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">MediaPipe整体-在设备上同时进行面部、手部和姿势预测</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">由Ivan Grishchenko和Valentin Bazarevsky发布，研究工程师，谷歌研究实时，同步…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">ai.googleblog.com</p></div></div><div class="ms l"><div class="nf l mu mv mw ms mx ma mg"/></div></div></a></div><p id="b6ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">MediaPip整体介绍，这是一个开源框架，用于在移动设备上同时实时识别人体姿势、面部标志和手部跟踪。可以检测540+个关键点(33个姿势，21只手，468个面部标志)，该框架可用于移动(Android，iOS)和桌面设备。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="29f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="d0b3" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">你可以得到每周的时事通讯。请订阅！</h1><p id="deee" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip mp ir is it mq iv iw ix mr iz ja jb ha bi translated">过去的时事通讯</p><div class="md me ez fb mf mg"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-machine-learning-news-week-13-2021-520049" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">Akira的机器学习新闻-# 2021年第13周</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">Revue我每周都会介绍机器学习相关的文章和论文。我也出版月刊和半年刊…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.getrevue.co</p></div></div><div class="ms l"><div class="ng l mu mv mw ms mx ma mg"/></div></div></a></div><div class="md me ez fb mf mg"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-machine-learning-news-week-12-2021-496080" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">Akira的机器学习新闻-# 2021年第12周</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">本周特稿/新闻。有一项研究表明，将CNN整合到基于变压器的模型中…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.getrevue.co</p></div></div><div class="ms l"><div class="nh l mu mv mw ms mx ma mg"/></div></div></a></div><p id="bcc3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="b88e" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">关于我</h1><p id="19e3" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip mp ir is it mq iv iw ix mr iz ja jb ha bi translated">制造工程师/机器学习工程师/数据科学家/物理学硕士/<a class="ae kp" href="https://t.co/hjHHbG24Ph?amp=1" rel="noopener ugc nofollow" target="_blank">http://github.com/AkiraTOSEI/</a></p><p id="4486" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">推特，我贴一句纸评论。</p></div></div>    
</body>
</html>