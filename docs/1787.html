<html>
<head>
<title>Modeling customer conversion with causality</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用因果关系模拟客户转化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/modeling-customer-conversion-with-causality-c44d1d5cf868?source=collection_archive---------3-----------------------#2021-03-18">https://medium.com/analytics-vidhya/modeling-customer-conversion-with-causality-c44d1d5cf868?source=collection_archive---------3-----------------------#2021-03-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="cd19" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">探索特征选择中的因果关系</p><p id="6a56" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当对具有许多特征的数据集进行建模时，维数灾难是一个众所周知的问题，尤其是需要统计显著性的模型。然而，功能不会成为我们的敌人，因为它们提供了对客户的描述，例如，丰富我们对业务的理解。因此，如何为特定的任务选择合理的特性就成了本文将要讨论的问题。</p><h1 id="0bd0" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">流行的降维工具</h1><p id="5743" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">自动编码器或主成分分析(PCA)是一些流行的方法，用于捕获原始特征集的本质，并产生新的特征集，但具有较少数量的特征。然而，它们在解释上存在不足，因为每个转换后的特征都变成了原始特征的混合物，从而失去了它们的物理意义。然而，我的因果关系方法并没有“压缩”特征，而是提供了特征和预测变量之间关系的图形视图，因此人们可以选择直接影响预测变量的特征作为他们的建模预测器。</p><h1 id="54de" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">因果关系</h1><p id="3a65" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">因果模型有一个有向图表示来描述特征之间的因果关系，如下所示:</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es kf"><img src="../Images/88de000b46436ce4033098a0062f7d6b.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*50s_hmy7P9Md2cGfwmP53w.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">4个特征之间的图形因果模型</figcaption></figure><p id="6009" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果这种模型是用一些丰富的统计数据建立的，那么有人可能会说，不要用所有其他3个特征对“收入”建模，也许只使用“经验”和“教育”就足够了，因为它们是导致预测变量“收入”的<em class="kr">和</em>因素。</p><h1 id="1508" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">用IC*算法构建因果图</h1><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ks"><img src="../Images/5e048df609a2bb2208231b4299ea29a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*z34_YvqBWwRKF9vVypimmg.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">图的基本构件</figcaption></figure><p id="69f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然细节可以参考Pearl的书[1]，但是IC*算法从所有特征都相互连接的图开始，然后每当发现两个特征的条件独立性时断开这两个特征，留下部分连接的无向图。</p><p id="6fcf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">单连通不讲是哪一个导致哪一个，因此，算法下一步发现因果关系。</p><p id="bd90" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，只要有三个相连的特征(A-B-C)但是给定一组特征(不包括B)A和C是条件独立的，那么我们可以将这些连接变成箭头(A-&gt; BT3】碰撞器T5)</p><p id="65fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在第一步发现所有碰撞器后，我们继续迭代下面两步，直到再也画不出新的箭头。</p><ul class=""><li id="4bfa" class="kt ku hh ig b ih ii il im ip kv it kw ix kx jb ky kz la lb bi translated">但凡有(A -&gt; B — C)结构，就改成(A -&gt; B =&gt; C)，因为不可能是对撞机结构，否则早就被发现了。符号= &gt;与-&gt;相区别，以指示B =&gt; C是真正的有向关系，而B -&gt; C可以表示真正的有向关系(即B =&gt; C)或者存在潜在变量(在数据集中未观察到)U的可能性，使得B和C以这种方式相关:B  C，这是一个<strong class="ig hi"> <em class="kr">分叉</em> </strong>结构。</li><li id="5561" class="kt ku hh ig b ih lc il ld ip le it lf ix lg jb ky kz la lb bi translated">只要有一条链A是从A到B的真正有向路径，即A =&gt; F1 =&gt; F2 … =&gt; B，并且A与B相连(即A — B)，那么这种连接就应该变成A -&gt; B</li></ul><p id="cc0e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">提到潜在因素后，它指出了一种可能性(实际上是一种很大的可能性),即生成的图可能不是唯一的。然而，这应该是有意义的，因为我们可能无法将所有决定性因素纳入模型。潜在变量的存在本身就给了我们一些提示，告诉我们在收集数据时应该从哪里入手，做什么样的计划。</p><p id="57b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，对于那些无向的、相连的要素，它们之间的关系仍未确定，可能需要更多的数据。</p><h1 id="0958" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">使用电话销售数据集进行演示</h1><p id="780c" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">银行电话营销数据集[2]包含41，188名客户中每一位的20个特征，用于演示。其工艺流程可以在下面说明。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lh"><img src="../Images/262400a4124bff910d1e1a0feb51124c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*oA7pboAjW6nZ5czetGtyIw.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">数据集处理流程</figcaption></figure><p id="d6c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后通过IC*算法构建偶然模型。由于上一节讨论的原因，我们有不止一个模型。但是，如果我们关注预测变量(在这个电话销售数据集中是转换)，我们可以找到9个最接近它的特征，尽管没有直接联系。虽然这不是一个我可以干预以澄清关系的业务，但我选择了基于朴素马尔可夫假设的9个特征(标记为scm)作为我的建模参数。</p><p id="c732" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了与现代降维技术进行比较，应用pca还创建了一组9个嵌入特征(标记为PCA)。连同54个特征的原始集合(标记为基本)，有3个数据集用于比较。</p><p id="85c5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在下面的比较中，因果模型(红线)的特征表现始终优于主成分分析(绿线)。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es li"><img src="../Images/b32bd966514a90608b7805404fba12aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1034/format:webp/1*tbVsss7gg_xlpq_Jf7SCEg.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">分数成就比较</figcaption></figure><p id="8253" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一方面，因果模型特征(红线)比主成分分析(绿线)更能忍受训练数据集的变化。随着更多的数据在训练过程中被隐藏，绿线很快下降。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lj"><img src="../Images/d68689b4b8609f914955c3e36a35d96a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/1*25xahj4uQV5G3nWOj6xPvg.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">针对训练中可见数据的稳定性</figcaption></figure><h1 id="a5fd" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">结论</h1><p id="2454" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">虽然不能保证哪种归约技术总是比其他技术表现得更好，但因果模型提供了一种可解释的方法来推理我们的数据，同时允许选择特征。在电话销售数据集中，测试了任何9个特征的不同组合，由因果模型产生的组合排名前3%，至少在这个数据集中，这不仅仅是巧合。</p><h1 id="f36a" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">参考</h1><ol class=""><li id="0b2a" class="kt ku hh ig b ih ka il kb ip lk it ll ix lm jb ln kz la lb bi translated">j .珀尔(2000年)。因果关系:模型、推理和推论。剑桥大学出版社。</li><li id="1a7f" class="kt ku hh ig b ih lc il ld ip le it lf ix lg jb ln kz la lb bi translated">南莫罗p .科尔特斯和p .丽塔。(2014)预测银行电话营销成功的数据驱动方法。决策支持系统，爱思唯尔，62:22–31。从UCI机器学习库检索。<a class="ae lo" href="http://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank">http://archive.ics.uci.edu/ml/datasets/Bank+Marketing</a></li></ol></div></div>    
</body>
</html>