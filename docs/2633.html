<html>
<head>
<title>Face Mask Recognition using Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于张量流的人脸面具识别</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/face-mask-recognition-using-tensorflow-dbccbf8653d9?source=collection_archive---------4-----------------------#2021-05-09">https://medium.com/analytics-vidhya/face-mask-recognition-using-tensorflow-dbccbf8653d9?source=collection_archive---------4-----------------------#2021-05-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/986300db87badc2eff96416086a8efda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rOrP712lgOSHGRCqd2_Gsg.jpeg"/></div></figure><p id="be7f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这篇博客中，我将一步一步地分享如何利用tensorflow创建一个人工智能模型的教程，该模型应该能够发现一个人是否戴着面具。</p><h1 id="0d6f" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">步骤1:下载数据集</h1><p id="ab2f" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">我使用的数据集取自Kaggle人脸面具数据集。您可以点击<a class="ae km" href="https://bit.ly/3f8c7aG" rel="noopener ugc nofollow" target="_blank"> <em class="kn">这里的</em> </a>下载数据集。</p><h1 id="6abc" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">步骤2:创建config.py文件</h1><p id="59ba" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">调整模型训练过程需要对模型的预定义参数进行一些更改。我已经创建了一个配置文件来在培训前进行这些更改，它保持了代码文件的整洁。</p><p id="a46c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">config.py</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="e540" class="kx jk hh kt b fi ky kz l la lb">DATASET_DIR = ‘PASTE_LOCATION_OF_DATASET_HERE’</span><span id="25ec" class="kx jk hh kt b fi lc kz l la lb">IMG_WIDTH = 300<br/>IMG_HEIGHT = 300<br/>BATCH_SIZE = 32<br/>EPOCHS=15</span><span id="c369" class="kx jk hh kt b fi lc kz l la lb">MODELS_PATH = ‘./models/’ # Models will be saved to this folder</span></pre><h1 id="a5f6" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">步骤3:训练模型</h1><p id="56ba" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">I .导入库</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="2e4a" class="kx jk hh kt b fi ky kz l la lb">import warnings</span><span id="8598" class="kx jk hh kt b fi lc kz l la lb">import sys<br/>import os<br/>import time</span><span id="8ce6" class="kx jk hh kt b fi lc kz l la lb">import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import tensorflow as tf</span><span id="1aac" class="kx jk hh kt b fi lc kz l la lb">from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout<br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img<br/>from tensorflow.keras.callbacks import EarlyStopping</span></pre><p id="0d27" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">二。加载数据集</p><p id="4f67" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因为我们已经将数据分为训练和验证，保存在不同的文件夹中。我已经使用tensorflow中的<a class="ae km" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank"><em class="kn">imagedata generator</em></a>来加载数据集。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="1271" class="kx jk hh kt b fi ky kz l la lb"># cfg is config (see import)<br/>images_root_directory = cfg.DATASET_DIR<br/>train_path = ‘Train/’<br/>val_path = ‘Validation/’</span><span id="4ad3" class="kx jk hh kt b fi lc kz l la lb"># loaded from config<br/>IMG_WIDTH = cfg.IMG_WIDTH<br/>IMG_HEIGHT = cfg.IMG_HEIGHT<br/>batch_size = cfg.BATCH_SIZE<br/>epochs = cfg.EPOCHS</span><span id="cdc5" class="kx jk hh kt b fi lc kz l la lb">full_train_path = images_root_directory + train_path<br/>full_val_path = images_root_directory + val_path</span><span id="03fa" class="kx jk hh kt b fi lc kz l la lb"># load data using ImageDataGenerator<br/>train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)<br/>test_datagen = ImageDataGenerator(rescale=1./255)</span><span id="562b" class="kx jk hh kt b fi lc kz l la lb">train_generator = train_datagen.flow_from_directory(<br/> full_train_path,<br/> target_size=(IMG_WIDTH, IMG_HEIGHT),<br/> batch_size=batch_size,<br/> shuffle=True,<br/> class_mode=’categorical’)<br/>validation_generator = test_datagen.flow_from_directory(<br/> full_val_path,<br/> target_size=(IMG_WIDTH, IMG_HEIGHT),<br/> batch_size=batch_size,<br/> class_mode=’categorical’)</span></pre><p id="2a93" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">三。准备模型</p><p id="49d8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我使用了3层<a class="ae km" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D" rel="noopener ugc nofollow" target="_blank"> <em class="kn">卷积</em> </a>，然后是一个<a class="ae km" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten" rel="noopener ugc nofollow" target="_blank"> <em class="kn">展平</em> </a>层，接着是两个<a class="ae km" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense" rel="noopener ugc nofollow" target="_blank"> <em class="kn">密集</em> </a>层。最终致密层有2个节点，由<a class="ae km" href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> softmax </em> </a>激活组成。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="f6a3" class="kx jk hh kt b fi ky kz l la lb">def get_model(IMG_WIDTH, IMG_HEIGHT, NUM_CHANNELS=3):<br/>    model = Sequential()<br/>    # Conv layer 1<br/>    model.add(Conv2D(16, (3,3), activation=’relu’, input_shape=       (IMG_WIDTH, IMG_HEIGHT, NUM_CHANNELS)))<br/>    model.add(MaxPooling2D())<br/>    # Conv layer 2<br/>    model.add(Conv2D(16, (3,3), activation=’relu’))<br/>    model.add(MaxPooling2D())<br/>    # Conv layer 3<br/>    model.add(Conv2D(16, (3,3), activation=’relu’))<br/>    model.add(MaxPooling2D())<br/>    # Flatten<br/>    model.add(Flatten())<br/>    # Fully Connected<br/>    model.add(Dense(32, activation=’relu’))<br/>    model.add(Dropout(0.5))<br/>    # Output<br/>    model.add(Dense(2, activation=’softmax’))<br/>    model.compile(loss=’categorical_crossentropy’, optimizer=’adam’,  metrics=[‘accuracy’])<br/>    return model</span></pre><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es ld"><img src="../Images/f5175e0d68b9d554efad7ce1839a45f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*NeWNWr0PKFCJY6BJIuoJtA.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">模型架构</figcaption></figure><p id="6393" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">四。拟合模型</p><p id="6ea2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">Get model函数返回一个模型对象，该对象可用于拟合加载的数据。我还实现了一个<a class="ae km" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping" rel="noopener ugc nofollow" target="_blank"> <em class="kn">提前停止</em> </a>回调，如果验证损失停留在相同的值，就停止训练过程。</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="9fc5" class="kx jk hh kt b fi ky kz l la lb">model = get_model(IMG_WIDTH, IMG_HEIGHT)</span><span id="9d93" class="kx jk hh kt b fi lc kz l la lb"># early-stop to prevent overfitting<br/>early_stop = EarlyStopping(monitor=’val_loss’, patience=2)<br/># fit model to data generator<br/>model_history = model.fit_generator(train_generator, epochs=epochs, validation_data=validation_generator, callbacks=[early_stop])</span><span id="9299" class="kx jk hh kt b fi lc kz l la lb"># plot loss and accuracy<br/>history = pd.DataFrame(model_history.history)<br/>history[[‘loss’, ‘val_loss’]].plot()<br/>plt.show()<br/>history[[‘accuracy’, ‘val_accuracy’]].plot()<br/>plt.show()</span></pre><figure class="ko kp kq kr fd ii er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es li"><img src="../Images/e47bb97e77a100f9a775a8db55c6e568.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6DP2sFj6FI_xbcBJVPh27g.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">培训过程</figcaption></figure><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es ln"><img src="../Images/ce39497c8132868e683eb1fa97f55166.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*BaFzUqRdJZxFNJbfQSldCw.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">每次迭代的培训/验证损失</figcaption></figure><figure class="ko kp kq kr fd ii er es paragraph-image"><div class="er es ln"><img src="../Images/46903d900e574b201aba79f7aee01616.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*gdk0s1A7QkHnVDh_Fb4geA.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">每次迭代的培训/验证准确性</figcaption></figure><p id="6702" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">动词 （verb的缩写）保存模型</p><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="ee85" class="kx jk hh kt b fi ky kz l la lb">def save_model(model, models_path):<br/>    if not os.path.exists(models_path):<br/>      os.makedirs(models_path)<br/>    timestr = time.strftime(“%Y%m%d_%H%M%S”)<br/>    model_file_name = ‘MODEL_’ + timestr<br/>    model.save(models_path+model_file_name+’.h5')</span><span id="01e6" class="kx jk hh kt b fi lc kz l la lb">models_path = cfg.MODELS_PATH<br/>save_model(model, models_path)<br/>print(‘Model Saved.’)</span></pre><h1 id="d44f" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">结论</h1><p id="898e" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">最后，我们有一个模型，可以将图像分类为遮罩/无遮罩。我们可以准备一个推理管道来为模型服务。可以访问我的<a class="ae km" href="https://github.com/iamrajatroy/face-mask-recognition" rel="noopener ugc nofollow" target="_blank"> <em class="kn"> github库</em> </a>看推理代码。也可以看<a class="ae km" href="https://www.youtube.com/watch?v=TlrxpqBF_1w" rel="noopener ugc nofollow" target="_blank">试玩</a>。</p></div></div>    
</body>
</html>