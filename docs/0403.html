<html>
<head>
<title>Visualizations and NLP on New Year Resolution dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">新年决心数据集上的可视化和自然语言处理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/visualizations-and-nlp-on-new-year-resolution-dataset-c73a8876a327?source=collection_archive---------11-----------------------#2021-01-15">https://medium.com/analytics-vidhya/visualizations-and-nlp-on-new-year-resolution-dataset-c73a8876a327?source=collection_archive---------11-----------------------#2021-01-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="450f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可视化对于以图形、图表或任何其他可视格式的形式向人脑轻松传达洞察力是必不可少的。存在于一个视觉世界中，用图像交流数据是可靠的，以便于解释。</p><p id="2c6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我决定对Maven Analytics提供的新年决心推文数据集进行可视化。每行包含一条推文、日期和时间、地理位置、类别、主题等。有了一个定义tweets的专栏，我决定也在Python中应用NLP。</p><p id="2c6d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们从在Jupyter笔记本中导入必要的库开始:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="e985" class="jl jm hh jh b fi jn jo l jp jq">import pandas as pd<br/>from pandas import DataFrame<br/>from pandas.plotting import scatter_matrix<br/>import matplotlib.pyplot as plt<br/>from matplotlib import rcParams<br/>import plotly.express as px<br/>from plotly.colors import n_colors<br/>import numpy as np<br/>import seaborn as sns<br/>%matplotlib inline<br/>from matplotlib import rc<br/>import scipy.stats<br/>from matplotlib.gridspec import GridSpec<br/>from wordcloud import WordCloud, STOPWORDS <br/>from nltk.stem.wordnet import WordNetLemmatizer<br/>from textblob import TextBlob<br/>from nltk.sentiment import SentimentAnalyzer<br/>from wordcloud import WordCloud<br/>from nltk.stem import PorterStemmer<br/>from nltk.corpus import stopwords<br/>import plotly.graph_objects as go</span></pre><p id="cd09" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是针对该分析和可视化给出的数据集:</p><figure class="jc jd je jf fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es jr"><img src="../Images/93457d952709200a93e4c60b1506ac32.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tn1NGwnk4l5YqUjvJaoLqA.png"/></div></div></figure><p id="f416" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">给定的数据帧具有4723行和10列。为了探究tweet类别的流行程度，我用matplotlib包创建了一个饼图，并提供了大小、标签和颜色的值。</p><p id="290b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是相关的python代码:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="84be" class="jl jm hh jh b fi jn jo l jp jq">labels = 'Career', 'Education/Training','Family/Friends/Relationships', 'Finance','Health &amp; Fitness','Humor','Personal Growth','Philanthropic','Recreation &amp; Leisure', 'Time Management/Organization'<br/>sizes = [123,87,327,167,825,887,1678,83,461,85]<br/>explode = (0, 0, 0, 0,0,0,0.1,0,0,0)</span><span id="abf9" class="jl jm hh jh b fi jz jo l jp jq">plt.figure(1, figsize=(40,20))<br/>the_grid = GridSpec(2, 2)<br/>cmap = plt.get_cmap('Spectral')<br/>colors = [cmap(i) for i in np.linspace(0, 1, 8)]<br/>plt.subplot(the_grid[0, 1], aspect=0, title='Category of Tweets on NewYear Resolutions')<br/>type_show_ids = plt.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, colors=colors)<br/>plt.show()</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es ka"><img src="../Images/682b5e57ecbbee8cadda79118e59ffba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*MgkPGFqgaJwGyBC8Wrpqzg.png"/></div></figure><p id="1d0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">推文类别个人成长是最受欢迎的，其次是幽默、健康与健身、娱乐与休闲、家庭/朋友/关系、金融等。</p><p id="5cfc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们根据性别进一步检查类别的受欢迎程度:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="95e5" class="jl jm hh jh b fi jn jo l jp jq">newyear.user_gender.value_counts()</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es kb"><img src="../Images/5150cefcaf0d53c50c4e91e944e147d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*BC40hnrSDTrtZDK9BuQWyQ.png"/></div></figure><p id="ae53" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在4723条推文中，2367条推文是女性推文，2356条推文是男性推文。</p><p id="7e8f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了按性别显示类别的受欢迎程度，我使用了堆积条形图。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="d506" class="jl jm hh jh b fi jn jo l jp jq">tweetcategory_gender = newyear.groupby(by=['tweet_category','user_gender'],sort=False)['id'].agg([('count','count')]).reset_index().sort_values(by='count',ascending=False)</span><span id="cfdb" class="jl jm hh jh b fi jz jo l jp jq">list = ['Career', 'Education/Training','Family/Friends/Relationships', 'Finance','Health &amp; Fitness','Humor','Personal Growth','Philanthropic','Recreation &amp; Leisure', 'Time Management/Organization']</span><span id="33a9" class="jl jm hh jh b fi jz jo l jp jq">category_gender = tweetcategory_gender[tweetcategory_gender.tweet_category.str.contains('|'.join(list))]<br/><br/>pivot_df = category_gender.pivot(index='tweet_category', columns='user_gender', values='count')</span><span id="857e" class="jl jm hh jh b fi jz jo l jp jq">colors = ["#8B0A50", "#EE1289","#1E90FF"]</span><span id="35db" class="jl jm hh jh b fi jz jo l jp jq">pivot_df.loc[:,['male','female']].plot.barh(stacked=True, color=colors, figsize=(10,7))</span></pre><p id="115c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我已经使用group by函数过滤了类别和性别的值，并将其存储到一个变量中。然后，我使用该变量通过提供索引和列值来创建一个pivot数据框。然后，我使用了barh函数(用于水平条形图)来绘制我们的堆积条形图。</p><p id="fc27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上述代码的输出如下:</p><figure class="jc jd je jf fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kc"><img src="../Images/823152d90783d6eec10ec3fe9b8cdb2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TSC8RP7OvRNtOaRBFUxm3Q.png"/></div></div></figure><p id="2a36" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">女性对个人成长、健康和健身更感兴趣，而男性则更关注幽默和职业。为了从转发量的角度仔细检查tweet类别的受欢迎程度，我使用了一个简单的条形图来显示使用matplotlib库的类别的转发总量。其代码和输出如下:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="5049" class="jl jm hh jh b fi jn jo l jp jq">fig = plt.figure(figsize = (10, 5)) <br/># creating the bar plot <br/>plt.barh(newyear['tweet_category'], newyear['retweet_count'], color ='maroon') <br/>  <br/>plt.xlabel("Sum of Retweet") <br/>plt.ylabel("Categories") <br/>plt.title("Sum of Retweets By Categories") <br/>plt.show()</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es kd"><img src="../Images/ccd54f7eeba757449ae9d3ba1f137421.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/format:webp/1*2kdTrzsHVQOvS_9fhR16yA.png"/></div></figure><p id="8e12" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">转发量最高的是金融类、家庭/朋友/关系类和个人成长类。<br/>让我们看看推文在不同地区的受欢迎程度:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="c521" class="jl jm hh jh b fi jn jo l jp jq">sns.countplot(x='tweet_region',data=newyear,palette='viridis')<br/>plt.title('Number of tweets by different region')</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es ke"><img src="../Images/ecda3ccb2dc4daa917406f6ff0f89e57.png" data-original-src="https://miro.medium.com/v2/resize:fit:806/format:webp/1*Teb8kb_D6vm2ifWaqygQQQ.png"/></div></figure><p id="4d7d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">似乎南部地区的推文数量最多，其次是西部、东北部和中西部。<br/>为了更详细地分析各个地区，我们也来看看受欢迎程度:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="3510" class="jl jm hh jh b fi jn jo l jp jq">region_state = newyear.groupby(['tweet_region','tweet_state'],sort=False)['id'].agg([('count','count')]).reset_index().sort_values(by=['tweet_region','count'],ascending=[True,False])</span><span id="86cb" class="jl jm hh jh b fi jz jo l jp jq">region_state['us'] = 'US' # in order to have a single root node</span><span id="9514" class="jl jm hh jh b fi jz jo l jp jq">fig = px.treemap(region_state, path=['us', 'tweet_region', 'tweet_state'], values='count', color='tweet_state',color_continuous_scale='RdBu')</span><span id="e2dd" class="jl jm hh jh b fi jz jo l jp jq">fig.show()</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kf"><img src="../Images/0e26261bca6b0ba6441fa4e9afa46447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9DU5ss0hpxybPtePMuybxQ.png"/></div></div></figure><p id="bf9e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">南部地区拥有热门的德克萨斯州和佛罗里达州，西部地区拥有加利福尼亚州、华盛顿州和亚利桑那州，东北部地区拥有纽约州和宾夕法尼亚州，中西部地区拥有伊利诺伊州和俄亥俄州。</p><p id="f5cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一个可视化是关于tweet话题的流行度。我把tweet_topics一栏的文字去掉了空格，用词云来可视化。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="a2f4" class="jl jm hh jh b fi jn jo l jp jq">newyear.tweet_topics = newyear.tweet_topics.str.replace(' ', '')<br/>plt.subplots(figsize=(20,15))<br/>wordcloud = WordCloud(<br/>                          background_color='white',<br/>                          width=1920,<br/>                          height=1080<br/>                         ).generate(" ".join(newyear.tweet_topics))<br/>plt.imshow(wordcloud)<br/>plt.axis('off')<br/>plt.savefig('tweet_topics.png')<br/>plt.show()</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kg"><img src="../Images/80118659fbfb23518879c53b7a7db402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LndUoqnTeVUttPXKrHxLmg.png"/></div></div></figure><p id="22bc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最受欢迎的推文主题是“Bemorepositive”、“Improvemyattitude”、“humorabopersonalgrowthandinterestresolutions”和“humorabonotresolutionsingeneral”。</p><p id="55a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于我们已经在tweet_created专栏中给出了tweet的时间框架，我们将进行时间序列分析，并观察tweet的数量。为了处理这个列，我将数据类型更改为DateTime，并存储在date_time列中。我还从date_time列中提取了日期和时间值，并将它们存储到Date_hour中。<br/>代码如下:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="0cf7" class="jl jm hh jh b fi jn jo l jp jq">newyear['date_time'] = pd.to_datetime(newyear['tweet_created'])<br/>newyear['date_hour']  = newyear['date_time'].dt.strftime('%Y/%m/%d %H')</span></pre><p id="5985" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了进行每日和每小时的分析，我使用group by函数创建了两个数据框daily_df和daily_hour_df。对于每日分析，我从date_time中提取了日期，并将其存储在date列中。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="294b" class="jl jm hh jh b fi jn jo l jp jq">daily_hour_count = newyear.groupby('Date_hour').agg('count')<br/>daily_hour_df = pd.DataFrame(daily_hour_count)<br/>newyear['date'] = newyear['date_time'].dt.date<br/>newyear['Date'] = pd.to_datetime(newyear['date'])<br/>daily_count = newyear.groupby('Date').agg('count')<br/>daily_df = pd.DataFrame(daily_count)</span><span id="832f" class="jl jm hh jh b fi jz jo l jp jq"># Start and end of the date range to extract<br/>start, end = '2014-12-21','2015-01-02'<br/># Plot daily and weekly resampled time series together<br/>fig, ax = plt.subplots(figsize=(18,5))<br/>ax.plot(daily_hour_df.loc[start:end, 'tweet_text'],<br/>marker='.', linestyle='-', linewidth=0.5, label='Hourly')<br/>ax.plot(daily_df.loc[start:end, 'tweet_text'],<br/>marker='o', markersize=8, linestyle='-', label='Daily')<br/>ax.set_ylabel('Number of Tweets')<br/>ax.legend()<br/>ax.set_facecolor("silver")</span></pre><p id="895f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出如下:</p><figure class="jc jd je jf fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kh"><img src="../Images/18260d6f514e0b3e0f945c4c4ff45193.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bBtUuObfMFR-rWjpRHuzbw.png"/></div></div></figure><p id="046b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我们所观察到的，29日、31日和1日的推特量最高。小时模式和日模式遵循几乎相同的路径。</p><p id="18c6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，作为自然语言处理的一部分，我们将对tweet_text列执行一些操作。<br/>作为第一步，我将在<strong class="ig hi">中删除带有空格的特殊字符</strong>。其代码如下:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="d636" class="jl jm hh jh b fi jn jo l jp jq">cleaned_words = newyear['tweet_text'].str.replace("[^a-zA-Z]", " ")<br/>cleaned_words</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es ki"><img src="../Images/75fcfa648f95b3719b58fa26842b81b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*NG6kGSp_CXnsahcxZs5koA.png"/></div></figure><p id="48ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第二步是<strong class="ig hi">删除长度小于3的短词:</strong></p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="e6bf" class="jl jm hh jh b fi jn jo l jp jq">removed_short_words = cleaned_words.apply(lambda x: ' '.join([w for w in x.split() if len(w)&gt;3]))<br/>removed_short_words</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es kj"><img src="../Images/2105129a2f6cfba8c52fe20a6336331a.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*LyXbVtZTpz7We43ZgecPGA.png"/></div></figure><p id="9748" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是<strong class="ig hi">为了方便起见，将所有字母转换成小写字母</strong>:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="6b22" class="jl jm hh jh b fi jn jo l jp jq">lowercase_words = removed_short_words.str.lower()</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es kk"><img src="../Images/54f0ba166195313e16bc5927608b09f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*wa_zncPHXmdlH_OXnk5eeQ.png"/></div></figure><p id="16ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是<strong class="ig hi">标记化</strong>。我使用了单词标记化，我们将推文分解成一系列单词或小单元。这些小单位被称为代币。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="a794" class="jl jm hh jh b fi jn jo l jp jq">tokenized_tweet = lowercase_words.apply(lambda x: x.split())</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es kl"><img src="../Images/55af6bb4abe277b3a84fa536e4ea8b21.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*QNqeZtDBpbVtsppwV33LRQ.png"/></div></figure><p id="8242" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是<strong class="ig hi">移除停止字</strong>。停用词是对正文没有什么意义的词。这些单词可能会给文本添加噪声，并且会花费较长的处理时间，因此删除这些单词是合适的。NLTK库有一个用不同语言存储的停用词列表。我们在英语中使用了停用词。其代码如下:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="f4c5" class="jl jm hh jh b fi jn jo l jp jq">tokenized_tweet = lowercase_words.apply(lambda x: x.split())stop = set(stopwords.words("English"))<br/>stop.add("years")<br/>stop.add("newyearsresolution")<br/>stop.add("resolution")<br/>stop.add("http")<br/>stop.add("year")<br/>filtered_words = tokenized_tweet.apply(lambda x: [item for item in x if item not in stop])<br/>print(filtered_words)</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es km"><img src="../Images/4d8cb1ed16973e4dfee67f047a6a7215.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*b7EBsDUMm7Xl-R66Kre1Tg.png"/></div></figure><p id="7513" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我还添加了一些不必要的词作为停用词。<br/>现在，在删除停用词后，我创建了一个词云来查看推文中最受欢迎的词。<br/>其代码如下:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="a843" class="jl jm hh jh b fi jn jo l jp jq">wordcloud = WordCloud(stopwords=stop).generate(filtered_words.to_string())<br/>plt.figure( figsize=(20,10), facecolor='k')<br/>plt.imshow(wordcloud)<br/>plt.axis("off")<br/>plt.tight_layout(pad=0)<br/>plt.show()</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kn"><img src="../Images/56fe75be04fc1e1b0d5716834cf8ea59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8EzUbFSlfi4KxUJOYyfApw.png"/></div></div></figure><p id="355a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">推文中最受欢迎的词是“时间”、“停止”、“开始”、“开始”和“开始”、“进行”。</p><p id="56bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来的步骤是堵塞。我们通过将他们的单词转换成他们的词根来减小文本的大小。换句话说，这基本上是一个语言规范化的过程。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="db84" class="jl jm hh jh b fi jn jo l jp jq">stemmer = PorterStemmer()<br/>stemmed_tweet = filtered_words.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es ko"><img src="../Images/206fbb3b2e29129b7054041293e34b5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*OJc2YBg2C7-Kp1mpcrPvVw.png"/></div></figure><p id="734f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是词汇化。它是将一个单词缩减为其基本单词的过程。词根单独使用时可能有意义，也可能没有意义，而基本词单独使用时也有意义。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="6019" class="jl jm hh jh b fi jn jo l jp jq">df = filtered_words.to_frame()<br/>df['tweet'] = df['tweet_text'].astype(str)<br/>lemmatizer = WordNetLemmatizer()<br/>w_tokenizer = nltk.tokenize.WhitespaceTokenizer()<br/>def lemmatize_text(text):<br/>    return [lemmatizer.lemmatize(w) for w in       w_tokenizer.tokenize(text)]</span><span id="373d" class="jl jm hh jh b fi jz jo l jp jq">df['lemmatize_tweet'] = df.tweet.apply(lemmatize_text)<br/>df['lemmatize_tweet'] = df['lemmatize_tweet'].astype('str')</span></pre><p id="2871" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我已经对filtered_words应用了词条化，filtered _ words是去掉停用词后的文本。我首先定义了函数，然后将它应用于数据帧df的tweet列。词干化和词条化都是文本规范化技术，也是进一步处理的基础。对于词干，我在nltk包中使用波特·斯特梅尔的英语语言。<br/>现在我们将对词条化的文本执行<strong class="ig hi">情感分析</strong>。情感分析是定义作者态度或情感的方法。它可以是积极的、消极的或中性的。TextBlob包的情感函数返回分数，包括文本的主观性和极性。极性用于识别给定语言中的情感取向。极性给出的浮点值在-1到1的范围内，其中-1是负数，而+1是正数。主观性检查文本上的主观表达(描述人们对特定主题或话题的感受的观点)。主观性也给出范围在0到1之间的浮点值。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="36e1" class="jl jm hh jh b fi jn jo l jp jq">df[['polarity', 'subjectivity']] = df['lemmatize_tweet'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))</span><span id="4ffd" class="jl jm hh jh b fi jz jo l jp jq">def senti(x):<br/>    return TextBlob(x).sentiment  <br/> <br/>df['senti_score'] = df['lemmatize_tweet'].apply(senti)<br/>def getAnalysis(score):<br/>    if score &lt; 0:<br/>          return 'Negative'<br/>    elif score == 0:<br/>          return 'Neutral'<br/>    else:<br/>          return 'Positive'<br/>df['analysis'] = df['polarity'].apply(getAnalysis)<br/># Show the dataframe<br/>df</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kp"><img src="../Images/a11412045202a1abb2c0fcba80810741.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h7XDsOueG_zQQWIkWlZT2g.png"/></div></div></figure><p id="03d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">出于可视化和分析的目的，让我们理解极性和主观性的散点图:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="d5be" class="jl jm hh jh b fi jn jo l jp jq"># Plotting <br/>plt.figure(figsize=(8,6)) <br/>for i in range(0, df.shape[0]):<br/>      plt.scatter(df["polarity"][i], df["subjectivity"][i], color='Blue')   <br/>plt.title('Sentiment Analysis') <br/>plt.xlabel('Polarity') <br/>plt.ylabel('Subjectivity') <br/>plt.show()</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es kq"><img src="../Images/e7a99b62e12de22d74eecca248219fa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*qxzmR4lSLg9O9k6Mk4XpWA.png"/></div></figure><p id="9a22" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以看到大多数推文的极性在0.0到0.50之间。这意味着大多数推文要么是中性的，要么是积极的。还有，推文是随着主观性的价值而增加的。</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="fb32" class="jl jm hh jh b fi jn jo l jp jq"># Plotting and visualizing the counts<br/>plt.title('Sentiment Analysis')<br/>plt.xlabel('Sentiment')<br/>plt.ylabel('Counts')<br/>df['analysis'].value_counts().plot(kind = 'bar')<br/>plt.show()</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es kr"><img src="../Images/839172a230f7a52e555f8747f4407055.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*9-W0LX-tz6oyT77eTZZaVA.png"/></div></figure><p id="30ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以上是情感分析的条形图。</p><p id="7435" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是推特上的性别情感分析:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="0e6c" class="jl jm hh jh b fi jn jo l jp jq">fc = sns.factorplot(x="gender", hue="analysis", <br/>                    data=df, kind="count", <br/>                    palette={"Negative": "#FE2020", <br/>                             "Positive": "#BADD07", <br/>                             "Neutral": "#68BFF5"})</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div class="er es ks"><img src="../Images/c1c935c121afee679c19d8654d0b4e35.png" data-original-src="https://miro.medium.com/v2/resize:fit:818/format:webp/1*8NRj_em_pu3Dog9Cu06nLg.png"/></div></figure><p id="8308" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">女性比男性更沉迷于正面的推文。<br/>让我们探索状态情感分析:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="7b32" class="jl jm hh jh b fi jn jo l jp jq">df['state'] = newyear['tweet_state']<br/>df.analysis[df.analysis == 'Positive'] = 1<br/>df.analysis[df.analysis == 'Negative'] = -1<br/>df.analysis[df.analysis == 'Neutral'] = 0<br/>fig = go.Figure(data=go.Choropleth(<br/>    locations=df['state'], # Spatial coordinates<br/>    z = df['analysis'].astype(float), # Data to be color-coded</span><span id="7599" class="jl jm hh jh b fi jz jo l jp jq">    locationmode = 'USA-states', <br/>    colorscale = "Reds",<br/>    text=df['state'],<br/>    marker_line_color='white', # line markers between states<br/>    colorbar_title = "Sentiments"<br/>    <br/>))</span><span id="703f" class="jl jm hh jh b fi jz jo l jp jq">fig.update_layout(<br/>    geo_scope='usa',<br/>)</span><span id="7973" class="jl jm hh jh b fi jz jo l jp jq">fig.show()</span></pre><figure class="jc jd je jf fd js er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kt"><img src="../Images/7f75947a29d82ddb939ba52553f0c27b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qxe71mtJ-BeWyZqCsvRUgg.png"/></div></div></figure><p id="f2e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">大多数持积极态度的州是华盛顿、蒙大拿、内布拉斯加、俄克拉荷马、德克萨斯、缅因、弗吉尼亚、北卡罗来纳和佐治亚。<br/>负面情绪占多数的州是北达科他州、南达科他州、怀俄明州、阿肯色州和亚利桑那州，其余的州持中立态度。</p><p id="6497" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我希望这篇博客对那些尝试接触Python中的数据分析、NLP和可视化的人有所帮助。要获得更详细的代码，请访问我的Kaggle笔记本<a class="ae ku" href="https://www.kaggle.com/anerisavani/visualizations-nlp-on-new-year-resolution-data" rel="noopener ugc nofollow" target="_blank">这里</a>。</p></div></div>    
</body>
</html>