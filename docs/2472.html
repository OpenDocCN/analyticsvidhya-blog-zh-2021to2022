<html>
<head>
<title>CNN’s explainability papers review</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN的可解释论文评论</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cnns-explainability-papers-review-5ed380577c64?source=collection_archive---------4-----------------------#2021-04-26">https://medium.com/analytics-vidhya/cnns-explainability-papers-review-5ed380577c64?source=collection_archive---------4-----------------------#2021-04-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/a84d8ed5b53bb3aac4464cfaf5e415ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kCRZeh7WLYC-dwchTBCJzQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">可解释的IA字段</figcaption></figure><h1 id="bbe9" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">1导言</h1><p id="8b68" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">近年来，深度神经网络的使用显著增加。这可能是由于cpu和gpu计算能力的提高，使得DNNs在大多数领域，特别是在图像分类领域取得了最先进的结果。不幸的是，DNNs的不透明性使得它们难以解释，因此它们在军事或医学等关键领域没有被广泛采用。在过去的几年里，很多研究都集中在试图理解DNNs是如何工作的，以及如何使它们不那么模糊，以增加用户的信任。这个被称为XAI(可解释的人工智能)的新领域涵盖了广泛的不同技术。有了这个参考书目，我们的目标是涵盖现有的解释复杂模型的不同策略。我们在这里的目标是快速浏览现有内容，重点是CNN。首先，我们描述了用一个更简单的模型(通常是线性模型)局部逼近一个复杂模型的所有技术。然后，我们描述了解释模型行为的所有技术，要么通过显著图将测试项目与数据库元素进行比较。最后，我们将展示使用了哪些方法来验证或比较这些显著性图。</p><h1 id="27b7" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">2用更简单的模型近似</h1><p id="6118" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">现存的最简单的模型是线性模型。基于这一假设，Ribeiro，Singh和Guestrin (2016:37)提出了LIME，这是一个模型不可知的框架，通过线性模型在局部逼近您的模型。此线性模型的输入是您的要素，权重可视为每个要素对复杂模型输出的贡献。LIME也处理图像，输入是超像素(像素组)。</p><p id="1f10" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">2017年，Lundberg和Lee (2017:21)提出了一个统一的理论，将LIME与另外两种可解释性技术(分层相关性和DeepLift)联系起来。Lundberg和Lee基于由Lloyd Shapley在1951年首先引入的博弈理论，证明了在一定条件下，每个特征问题的贡献分布存在最优解，该最优解可以根据模型精确或近似地计算。</p><p id="5e73" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">2018年，Ribeiro，Singh和Guestrin推出了一个名为Anchors (2018:27)的LIME改进版本，该版本通过使用局部区域而不是线性分隔符来克服其前任的一些限制。</p><p id="b8c6" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">即使这三个框架是最广为人知的，该领域仍有研究，如Frosst和Hinton(2017:11)的工作，他们训练决策树来模拟深度神经网络决策，并能够使其性能优于经典决策树，但不如DNN，同时更具可解释性。</p><h1 id="f8a9" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">3视觉可解释性</h1><p id="01b7" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">在本节中，我们将讨论直接使用模型或信息技术输入的方法，以区分图像的哪一部分对预测贡献最大。我们现在将特别关注使用CNN的图像分类。以下所有方法都是事后的，这意味着它们可以应用于经过训练的神经网络，而无需修改或重新训练。在继续之前，定义什么是显著图是很重要的。显著图是输入图像的每个像素的重要性的视觉属性。它通常采用热图或掩膜的形式，突出显示输入图像中与模型最相关的区域，以便进行预测。</p><h1 id="f6c0" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">3.1基于反向传播</h1><p id="1937" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">给定输入图像I和类别c的分数Sc，获得显著性图的最简单方法是对Sc w.r.t I求导，这是Symonyan等人首先描述的(2013:33)。这种方法的一个缺点是获得的显著图是有噪声的，并且突出了正面和负面的贡献。为了改善结果，引入了另外两种方法，由斯普林根伯格(2014:34)引导的反向传播和由泽勒和弗格斯(2013:39)引导的去卷积，它们修改校正的线性单位梯度(ReLu)以消除负贡献。</p><p id="dc45" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">在2015年，周等人(2015:40)用最后一个完全连接层的参数加权的最后一个卷积层学习的特征的线性组合解释了CNN的输出。调整大小后，CAM允许查看哪些高级特征对输出的影响最大。一年后，Selvaraju等人(2016:31)提出了该方法的更一般化版本(Grad-CAM)。Grad-CAM对分数Sc w.r.t特征图进行求导，因此CNN不再需要以conv2D-完全连接的层结束。</p><p id="2c87" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">最近，梁等人(2020:20)修改了训练损失，并在最后一个卷积层后添加了一个门矩阵，以迫使模型为每一类学习单独的滤波器。这似乎提高了凸轮定位的能力，当应用后。然而，所有这些方法都没有考虑偏差项，因此[35]引入了FullGrad可视化，即输入乘以梯度加上每层偏差的导数。</p><p id="1ad3" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">尽管如此，基于梯度的方法面临饱和效应(由Shrikumar等人(2017:32)解释)，即使输入被修改，这也可能导致零梯度。因此，Grad-CAM和CAM已被王等人改进(2020:38)。它不再使用渐变并生成更清晰的贴图。为此，它计算最后一个卷积层的线性组合，该卷积层由当输入图像被特征映射掩盖时获得的分数加权。</p><p id="073c" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">Shrikumar等人(2017:32)介绍了DeepLift，它通过改变反向传播规则来解决饱和和不连续梯度问题，实际上，它将它们对“与参考的差异”的贡献分配到每个层，因此需要应用参考(图像)。</p><p id="bae8" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">以不同的方式，综合梯度解决了相同的问题(Sundararajan等人(2017:42))，通过沿图像和参考之间的插值创建的路径对图像计算梯度的平均值。基准电压源的选择对于基于基准电压源的方法的成功至关重要。最常用的参考是模糊、高斯和均匀参考，但也可以设想其他参考，以便更具体地执行任务。</p><p id="a03a" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">Kapishnikov等人(2019:16)表明，也可以一起使用几个参考文献来改进结果。他们还引入了XRAI，这是一种在应用集成梯度之前对输入图像进行过度分割的算法，目的是产生更少噪声和更有意义的显著区域。</p><p id="6107" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">类似地，由Bach等人(2015:4)开发的DeepLift逐层相关性传播或LRP定义了新的反向传播规则，该规则是希望属性特征相关性的方法应该遵守的有效规则，例如全局守恒属性(所有相关性的总和应该等于输出)。这些规则试图根据神经元的激活程度和它们之间的联系强度，按比例将相关性从一个神经元分配到另一个神经元。已经定义了几个LRP规则来服务于不同的目的(ε-规则想要仅传播最强的相关性，而例如γ-规则想要仅传播正相关性……)，Montavon等人(2019:24)提出了所有存在的规则的概述。</p><p id="e132" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">Montavon等人(2019:23)表明，LRP可以被视为每个神经元处的局部深度泰勒分解。它还定义了一种有效的方法来实现LRP/泰勒分解方法，方法是将梯度乘以输入图像与根图像之间的差值，根图像是通过掩蔽(使用尽可能最小的掩膜)输入图像来最小化模型的输出得分而获得的。</p><p id="1763" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">有趣的是，Kindermans (2018:18)表明，即使在线性情况下，如果输入有干扰物(噪声),那么仅分析权重不会给出关于输入的“方向”的任何信息，因此除了所有源自LRP的方法之外，所有先前的方法都是无效的。因此，在反向传递过程中，将模型的权重乘以信息梯度的方向所获得的模式属性方法应该产生更有效的属性图。</p><p id="8ad4" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">最后，Srinivas和Fleuret (2019:35) (SmoothGrad)表明，通过将随机噪声添加到我们想要解释的图像时获得的显著图进行平均，或者通过在训练期间将随机噪声添加到图像，可以获得更清晰的显著图。</p><figure class="kv kw kx ky fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ku"><img src="../Images/123ca93d8a981d33f3b9b5dee5fe9004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Y3Yi7cEueF0XLZP-"/></div></div></figure><p id="1445" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">产生的解释的一些例子</p><h1 id="bd3c" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">3.2输入遮挡</h1><p id="3228" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">找到图像显著区域的另一种方法是扰动输入并分析输出的变化。这是以下方法的主要思想。</p><p id="a332" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">Fong和Vedaldi (2017:9)通过试图找到使输出分数低于某个阈值的最小扰动区域来做到这一点。作者表明，该方法比Grad-Cam和其他基于梯度的方法产生更小和更精确的显著区域。</p><p id="f445" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">Fong、Patrick和Vedaldi通过将遮挡遮罩约束为来自平滑遮罩的预定空间，并将大小约束为输入图像大小的一部分，改进了先前定义的优化问题。这些简化也加快了过程，这很重要，因为这些方法的缺点之一是执行时间(对于我们想要解释的每个预测，都需要解决一个优化问题)。</p><p id="ebe4" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">为了加速该过程，提出了另外两种算法:</p><ul class=""><li id="bbba" class="kz la hh jt b ju kp jy kq kc lb kg lc kk ld ko le lf lg lh bi translated">Vitali Petsiuk、Das和Saenko (2018:25)建议将输入图像与随机掩码相乘几次，并对预测得分乘以掩码进行加权求和，以获得热图。</li><li id="fea4" class="kz la hh jt b ju li jy lj kc lk kg ll kk lm ko le lf lg lh bi translated">Dabkowski和Gal (2017:8)并行使用U形网在单次向前传递中产生掩模。</li></ul><p id="6aa8" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">然而，所有基于掩模的方法增加了无信息像素，因此修改了数据分布。</p><p id="4e0e" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">Zintgraf等人(2017:41)引入了一种更严格的方法，将遮挡问题理论化为输出相对于输入要素的概率边缘化。它改进了Robnik-Sikonja和Kononenko (2008:28)提出的理论，通过在感兴趣特征的邻域中对特征进行采样来改进条件概率的近似性。</p><p id="ec70" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">然后，Chang等人(2018:6)对该方法进行了改进，该方法使用预训练的GAN进行内涂，以便用数据分布后的点填充掩蔽区域。</p><h1 id="e312" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">3.3基于概念</h1><p id="f951" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">为了产生更易理解的结果，一些技术集中于突出用户先前已经引入的概念。</p><p id="b417" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">Bau等人(2017:5)使用一个非常庞大和密集分割的概念数据集来可视化和量化模型每个单元所学习的概念。为了做到这一点，他们计算了他们的数据集的图像的每个部分的每个单元的激活。</p><p id="df94" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">在2018年，Kim(2018:17)引入了一个称为概念激活向量测试(TCAV)的框架，允许用户通过利用衍生方向的洞察力来检查概念是否被模型使用。</p><p id="06e7" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">要做到这一点，用户只需要给出一些积极和消极的概念的例子。这两种方法都具有全局优势。</p><p id="42cf" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">人们还表明，可以通过显示训练数据集的哪些图像导致了这样的预测来解释预测。例如，Pruthi等人(2020:26)在训练步骤中保存损失函数的变化，以便在进行预测时将它们与损失进行比较。</p><p id="50bf" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">类似地，Koh和Liang (2017:19)使用hessian矩阵分析了损耗变化中某一点的影响。这两种方法在内存或计算能力上似乎都很昂贵。</p><p id="e1ef" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">在Chen等人(2018:7)中，引入了一种新的卷积层。这一层应该添加到经典CNN的末尾，以便不仅能够产生更精确的显著图，而且能够从最能解释预测的训练数据库中提取图像块。</p><h1 id="beba" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">4测量和有效性检查</h1><p id="2115" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">利用所有这些方法来寻找输入中的显著区域，有必要具有某种度量，以便有效地验证该方法或评估它们。</p><p id="8fb1" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">Adebayo等人引入了健全性检查(2018:1 ),每个显著图方法都应该遵守该检查以便有效。他们连续随机化层的权重，以查看显著性图是否真的依赖于模型的参数。他们还在训练过程中随机分配标签，并对模型行为进行类似的分析。他们的结论是，大多数众所周知的基于梯度的方法不能通过检查。</p><p id="98c4" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">因为训练和测试分布应该是相似的，Hooker、Erhan、Kindermans和Brain (2020:13)提出了一种方法，其中在重新训练模型之前，从所有图像中移除由显著图方法定义为重要的特征。然后我们才分析了模型预测得分的演变。与Adebayo等人的文章相同，大多数基于梯度的方法显示出较差的结果。</p><p id="a16c" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">Kindermans (2017:15)提交了一个新的公理，称为输入不变性，应该通过显著图方法进行验证。他们测试了几种方法，通过在输入中添加一个常数移位来比较两个等效(就行为而言)模型(它们的实现不同)，并注意到大多数方法的显著性图的差异。</p><p id="1f90" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">使用了几个目标指标，例如:</p><ul class=""><li id="9981" class="kz la hh jt b ju kp jy kq kc lb kg lc kk ld ko le lf lg lh bi translated">AUC(曲线下面积)及其所有导数经常用于评估移除顶部特征(方法定义的相关特征)时模型精度的下降。</li><li id="b034" class="kz la hh jt b ju li jy lj kc lk kg ll kk lm ko le lf lg lh bi translated">AUPR(精确召回下的区域)，以便评估不同技术返回的显著区域的定位(Arun (2020:3)，Ismail (2020:14))。</li><li id="e519" class="kz la hh jt b ju li jy lj kc lk kg ll kk lm ko le lf lg lh bi translated">SSIM(结构相似性)，以便基于视觉感知而不是Arun (2020:3)提出的像素方式来评估两个显著图之间的变化。</li><li id="4a46" class="kz la hh jt b ju li jy lj kc lk kg ll kk lm ko le lf lg lh bi translated">忠实度，这是一个度量标准，它采用了单点引起的输出变化与通过归因方法获得的相关性之间的皮尔逊相关性(Alvarez-Melis和Jaakkola(2018:2))。</li><li id="f2aa" class="kz la hh jt b ju li jy lj kc lk kg ll kk lm ko le lf lg lh bi translated">稳健性，一种评估Lipschitz常数近似值评估方法的局部稳定性的指标(Alvarez-Melis和Jaakkola(2018:2))。</li><li id="32a4" class="kz la hh jt b ju li jy lj kc lk kg ll kk lm ko le lf lg lh bi translated">信息传递率的提高(Philipp Schmidt和Felix Biessmann (2019 :30))。</li></ul><p id="3bdf" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">最后，Tomsett等人(2020:36)研究了这些现有指标的有效性。它表明，在使用这些指标时保持谨慎是很重要的，因为它们似乎依赖于独立于模型的因素，如实验方案。</p><p id="b4f8" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">由于解释技术的主要目标是提高用户的信任度，因此许多实验都将显著图的评估基于与人类的比较，如Mohseni (2018:22)。他们首先为每幅图像分割几个人的地面实况显著区域(为了更高的粒度)，然后将其与由可解释性方法输出的显著图进行比较。他们还概述了人类显著图评估中不同类型的偏差。还使用了其他类型的实验，如指向游戏等。</p><h1 id="3e36" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">5极限和反射</h1><p id="bdb5" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">总之，即使这些方法很有前途，它们仍然有Rudin (2018:29)强调的局限性，作者指出，可解释的模型应该优于DNNs。</p><p id="d4b7" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">最后，Ghorbani、Abid和Zou (2018:12)表明，显著图对对抗性攻击也很敏感。</p><h1 id="a286" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">参考</h1><p id="0011" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">[1]朱利叶斯·阿德巴约、贾斯汀·吉尔默、迈克尔·穆勒、伊恩·古德菲勒、莫里茨哈特和贝内金。显著图的健全性检查。S. Bengio、H. Wallach、H. Larochelle、K. Grauman、N. Cesa-Bianchi和R. Garnett编辑,《神经信息处理系统进展》,第31卷。柯伦联合公司，2018。</p><p id="e159" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[2]大卫·阿尔瓦雷斯-梅利斯和托米·s·亚科拉。论互可译性方法的稳健性. arXiv e-prints，第arXiv页:1806.08049，2018年6月。</p><p id="3b51" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[3] Nishanth Arun、Nathan Gaw、Praveer Singh、、Mehak Aggarwal、Bryan Chen、Katharina Hoebel、Sharut Gupta、Jay Patel、Mishka Gidwani、Julius Adebayo、Matthew D. Li和Jayashree Kalpathy-Cramer。评估用于医学成像中异常定位的显著图的(不)可信度。</p><p id="a70a" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[4]巴赫、亚历山大·宾德、格雷瓜尔·蒙塔冯、f·克劳琛、k·m·̈uller,and·w·萨梅克通过逐层相关传播对非线性分类器决策的逐像素解释。PLoS ONE，2015年第10期。</p><p id="b4f9" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[5]戴维·鲍尔、·周、阿迪蒂亚·科斯拉、奥德·奥利瓦和安东尼奥·托拉尔巴。网络剖析:深度视觉表征的可解释性量化。计算机视觉与模式识别，2017。</p><p id="c344" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[6]春-常昊、埃利奥特·克里奇尔、安娜·戈登堡和戴维·杜文瑙德。通过反事实生成解释图像分类器. arXiv e-prints，第arXiv页:1807.08024，2018年7月。</p><p id="8aea" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[7]范超·陈、奥斯卡·李、阿丽娜·巴尼特、乔纳森·苏和辛西娅·鲁丁。这个看起来是这样的:可解释图像识别的深度学习，062018。</p><p id="b9f7" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">8 Piotr Dabkowski和Yarin Gal。黑盒分类器的实时图像显著性。在I. Guyon、U. V. Luxburg、S. Bengio、H. Wallach、R. Fergus、S. Vishwanathan和R. Garnett编辑的《神经信息处理系统的进展》第30卷中。柯伦联合公司，2017年。</p><p id="57d1" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[9] R. C. Fong和A. Vedaldi。通过有意义的扰动对黑盒的可解释的解释。2017年IEEE计算机视觉国际会议(ICCV)，第3449–3457页，2017。</p><p id="94d2" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">10 Ruth Fong，Mandela Patrick和Andrea Vedaldi。通过极值扰动和平滑掩模理解深层网络。IEEE/CVF计算机视觉国际会议(ICCV)正在进行中，2019年10月。</p><p id="4c81" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">11尼古拉斯·弗罗斯特和杰弗里·辛顿。将神经网络提取为aSoft决策树. arXiv e-prints，第arXiv页:1711.09784，2017年11月。</p><p id="7776" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[12] Amirata Ghorbani、Abubakar Abid和James Zou。解读neu-ral网络脆弱，2018。</p><p id="7e9c" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[13] Sara Hooker，Dumitru Erhan，Pieter-Jan Kindermans和Kim Brain。深度神经网络中可解释性方法的基准。01 2020.</p><p id="1e3e" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[14] Aya Abdelsalam Ismail、Mohamed K. Gunady、H ector corra da Bravo和andSoheil Feizi。时间序列预测中深度学习可解释性的基准测试。澳大利亚统计局更正，2010.13924，2020。</p><p id="5495" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[15]彼得·扬·金德曼斯、萨拉·胡克、朱利叶斯·阿德巴约、马克西米连·阿尔伯、克里斯托夫·施·̈utt、斯文·̈ahne、杜米特鲁·埃汉和贝内·金。显著方法的(不)可靠性。2017.</p><p id="623c" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[16]安德烈·卡皮什尼科夫、托尔加·博卢克巴西、费尔南达·维希加斯和迈克尔特里。XRAI:通过区域实现更好的属性。arXiv电子印刷，pagearXiv:1906.02825，2019年6月。</p><p id="76b1" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[17] Been Kim、Martin Wattenberg、Justin Gilmer、Carrie Cai、James Wexler、Fernanda Viegas和Rory sayres。超越特征属性的可解释性:用概念激活向量进行定量测试(TCAV)。InJennifer Dy和Andreas Krause，编辑，第35届国际机器学习会议论文集，机器学习研究论文集第80卷，第2668-2677页，斯德哥尔摩̈assan，斯德哥尔摩瑞典，2018年7月10-15日。PMLR。</p><p id="8c8a" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[18]彼得-扬·金德曼斯、克里斯托夫·施·̈utt、马克西米连·阿尔伯、克劳斯-罗伯特alber、杜米特鲁·埃汉、贝内·金和斯文·̈ahne.学习如何解释神经网络:模式网络和模式分布。2018年国际学习表征会议。</p><p id="c399" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[19]庞维高和佩西梁。通过影响函数理解黑盒预测。2017年8月6日至11日，澳大利亚悉尼国际会议中心，编辑Doina Precup和Yee Whye Teh，第34届机器学习国际会议论文集，机器学习研究论文集第70卷，第1885-1894页。PMLR。</p><p id="9037" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[20]梁浩宇，欧阳志浩，，曾玉元，何子豪，，，舒.面向特定类别滤波器的可解释卷积神经网络训练，2020。</p><p id="bafb" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[21]斯科特·M·伦德伯格和李苏英。解释模型预测的统一方法。在I. Guyon、U. V. Luxburg、S. Bengio、H. Wallach、R. Fergus、S. Vishwanathan和R. Garnett编辑的《神经信息处理系统的进展》第30卷中。柯伦联合公司，2017年。</p><p id="ab56" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[22]西纳·莫塞尼、杰里米·布洛克和埃里克·拉冈。以人为基础的机器学习本地解释评估基准. arXive-prints，第arXiv页:1801.05075，2018年1月。</p><p id="ed05" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[23]埃戈里·蒙塔冯、塞巴斯蒂安·巴赫、亚历山大·宾德、沃伊切赫·萨梅克和克劳斯-罗伯特·̈uller.用深度泰勒分解解释非线性分类决策。arXiv电子版，第arXiv页:1512.02479，2015年12月。</p><p id="96b2" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[24]格雷瓜尔·蒙塔冯、亚历山大·宾德、塞巴斯蒂安·拉普什金、沃伊切赫萨梅克和克劳斯-罗伯特·̈uller.分层相关性传播:概述，第193-209页。施普林格国际出版公司，Cham，2019。</p><p id="569c" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[25] Vitali Petsiuk、Abir Das和Kate Saenko。RISE:随机输入示例解释黑盒模型。arXiv电子打印，pagearXiv:1806.07421，2018年6月。</p><p id="4607" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[26] Garima Pruthi、Frederick Liu、Satyen Kale和Mukund Sundararajan。通过追踪梯度下降估计训练数据影响。InNeurIPS，2020。</p><p id="7e34" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">27马尔科·图利奥·里贝罗、萨梅尔·辛格和卡洛斯·盖斯特林。锚:高精度模型不可知的解释。Sheila A. McIlraith和Kilian Q.Weinberger编辑，第三十二届AAAI人工智能会议(AAAI-18)、第三十届人工智能创新应用(IAAI-18)和第八届AAAI人工智能教育进步研讨会(EAAI-18)，美国路易斯安那州新奥尔良，2018年2月2日至7日，第1527-1535页。AAAI出版社，2018。</p><p id="e4c1" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[28]m . rob Nik-Sikonja和I. Kononenko。解释单个实例的分类。IEEE知识与数据工程汇刊，20(5):589–600，2008。</p><p id="0487" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">29辛西娅·鲁丁。停止解释高风险决策的黑盒机器学习模型，而是使用可解释的模型。</p><p id="3925" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">30菲利普·施密特和费利克斯·比斯曼。量化机器学习系统中的可解释性和信任。arXiv电子印刷品，第arXiv页:1901.08558，2019年1月。</p><p id="2729" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[31] Ramprasaath R. Selvaraju、Michael Cogswell、Abhishek Das、RamakrishnaVedantam、Devi Parikh和Dhruv Batra。Grad-CAM:通过基于梯度的定位从深度网络进行可视化解释。arXiv e-prints，arXiv页:1610.02391，2016年10月。</p><p id="a8b1" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[32]两代情·什里库马尔、佩顿·格林塞德和安舒尔·昆达耶。通过传播激活差异学习重要特征. arXiv e-prints，第arXiv页:1704.02685，2017年4月。</p><p id="50c3" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[33]卡伦·西蒙扬、安德里亚·维达尔迪和安德鲁·齐塞曼。深入内部卷积网络:可视化图像分类模型和语义图。arXiv电子版，arXiv:1312.6034页，2013年12月。</p><p id="1c2b" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[34] Jost Tobias Springenberg，Alexey Dosovitskiy，Thomas Brox和MartinRiedmiller。力求简单:全卷积网络，arXiv-prints，第arXiv页:1412.6806，2014年12月。</p><p id="6e87" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[35] Suraj Srinivas和F. Fleuret。神经网络可视化的全梯度表示。InNeurIPS，2019。</p><p id="0369" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[36]理查德·托姆塞特、丹·哈伯内、苏普利约·查克拉博蒂、普拉德维·古拉姆和阿伦·普里斯。显著性度量的健全性检查。AAAI人工智能会议论文集，34:6021–6029，04 2020。</p><p id="cb5f" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">37马尔科·图利奥·里贝罗、萨梅尔·辛格和卡洛斯·盖斯特林。“我为什么要相信你？”:解释任何分类器的预测. arXiv e-prints，第arXiv页:1602.04938，2016年2月。</p><p id="6c84" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[38] H. Wang，Z. Wang，M. Du，F. Yang，Z. Zhang，S. Ding，P. Mardziel和x .胡。分数cam:卷积神经网络的分数加权视觉解释。2020年IEEE/CVF计算机视觉和模式识别研讨会(CVPRW)，第111-119页，2020年。</p><p id="aeea" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">39马修·泽勒和罗布·弗格斯。可视化和理解会议网络。arXiv电子版，第arXiv页:1311.2901，2013年11月。</p><p id="e9bc" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[40]雷勃·周、阿迪蒂亚·科斯拉、阿加塔·拉皮德里扎、奥德·奥利瓦和安东尼奥·托雷亚尔巴。学习区别性定位的深度特征. arXive-prints，第arXiv页:1512.04150，2015年12月。</p><p id="880f" class="pw-post-body-paragraph jr js hh jt b ju kp jw jx jy kq ka kb kc kr ke kf kg ks ki kj kk kt km kn ko ha bi translated">[41]路易莎·辛格拉夫、塔科·科恩、塔米姆·阿德尔和马克斯·韦林。VI-利用深度神经网络决策:预测差异分析. arXiv e-prints，第arXiv页:1702.04595，2017年2月。</p></div></div>    
</body>
</html>