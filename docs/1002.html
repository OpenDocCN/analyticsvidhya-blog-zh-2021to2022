<html>
<head>
<title>Novel techniques to win an Image Classification hackathon (Part-1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">赢得图像分类黑客马拉松的新技术(第一部分)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/novel-techniques-to-win-an-image-classification-hackathon-part-1-64929dd696b7?source=collection_archive---------19-----------------------#2021-02-09">https://medium.com/analytics-vidhya/novel-techniques-to-win-an-image-classification-hackathon-part-1-64929dd696b7?source=collection_archive---------19-----------------------#2021-02-09</a></blockquote><div><div class="dt gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ew ey ig ih ii ij es et paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="es et if"><img src="../Images/cda3eaa57c69ee3aebffb9e52a1ce902.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y6UP0_7FcLXV8uK6Mqhqvw.jpeg"/></div></div></figure><p id="d9c1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在这一系列的帖子中，我将讨论最近开发的一些现代黑客技术，以赢得图像分类黑客马拉松。传统上，我们总是依赖普通的CNN架构来执行图像分类。然而，这只会让你在排行榜上名列前茅。要达到顶峰，需要一些特别的东西。</p><blockquote class="jo jp jq"><p id="e934" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated">如果你查看最近的Kaggle排行榜，前10%的人在0.0001-0.001的分数范围内战斗。</p></blockquote><p id="29a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">记住这一点，下面是我在不同的图像分类黑客马拉松中用来不断获得良好LB分数的一些新方法。</p><ol class=""><li id="17fb" class="jv jw hi is b it iu ix iy jb jx jf jy jj jz jn ka kb kc kd bi translated"><strong class="is hj">迁移学习</strong></li><li id="9447" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated"><strong class="is hj">渐进式图像缩放</strong></li><li id="1fa0" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated"><strong class="is hj"> CNN关注</strong></li><li id="7e6a" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated"><strong class="is hj">集合模型</strong></li><li id="a3c8" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated"><strong class="is hj">测试时间增强(TTA) </strong></li></ol></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><h1 id="d051" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">常见CNN架构概述</h1><p id="3c6b" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">几乎所有CNN架构都遵循相同的通用设计原则，即在输入端叠加卷积层，同时周期性地对空间维度进行下采样，并增加特征图的数量。</p><p id="1a11" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">传统网络架构仅由堆叠的卷积层组成，而现代架构则探索新的创新方法来构建卷积层，从而实现更高效的学习。几乎所有这些体系结构都基于一个可重复的单元，该单元在整个网络中使用。</p><p id="0bde" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是一些著名的经典网络架构:</p><ol class=""><li id="547b" class="jv jw hi is b it iu ix iy jb jx jf jy jj jz jn ka kb kc kd bi translated"><strong class="is hj">乐网</strong></li><li id="511e" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated"><strong class="is hj">亚历克斯网</strong></li><li id="55ea" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated">VGG-16 </li></ol><p id="aa5d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是一些现代网络架构:</p><ol class=""><li id="6bdc" class="jv jw hi is b it iu ix iy jb jx jf jy jj jz jn ka kb kc kd bi translated"><strong class="is hj">盗梦空间</strong></li><li id="bc92" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated"><strong class="is hj"> ResNet </strong></li><li id="c964" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated"><strong class="is hj">密网</strong></li><li id="1038" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated"><strong class="is hj"> ResNext </strong></li><li id="22c8" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated"><strong class="is hj">高效网</strong></li></ol><p id="05fe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我推荐阅读下面的帖子，深入探究各种CNN架构。</p><div class="lt lu fa fc lv lw"><a href="https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d" rel="noopener follow" target="_blank"><div class="lx ab dx"><div class="ly ab lz cl cj ma"><h2 class="bd hj fj z dz mb eb ec mc ee eg hh bi translated">插图:10个CNN架构</h2><div class="md l"><h3 class="bd b fj z dz mb eb ec mc ee eg dy translated">普通卷积神经网络的编译可视化</h3></div><div class="me l"><p class="bd b fq z dz mb eb ec mc ee eg dy translated">towardsdatascience.com</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk io lw"/></div></div></a></div></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><h1 id="9247" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">迁移学习</h1><p id="3e4a" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">用于图像分类的迁移学习背后的直觉是，如果模型在足够大且通用的数据集上训练，则该模型将有效地充当视觉世界的通用模型。然后，您可以利用这些学习到的要素地图，而不必通过在大型数据集上训练大型模型来从头开始。</p><blockquote class="jo jp jq"><p id="7726" class="iq ir jr is b it iu iv iw ix iy iz ja js jc jd je jt jg jh ji ju jk jl jm jn hb bi translated">正如我喜欢说的，与其重新发明轮子，不如试着专注于制造汽车。</p></blockquote><p id="cde8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">迁移学习具有减少神经网络模型的训练时间的优点，并且可以导致更低的泛化误差。</p><p id="0c13" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了这篇文章的目的，我将使用有效的网络模型来演示迁移学习过程。</p><p id="9b1c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我强烈推荐阅读下面的帖子来理解高效网络的模型架构。</p><div class="lt lu fa fc lv lw"><a href="https://towardsdatascience.com/complete-architectural-details-of-all-efficientnet-models-5fd5b736142" rel="noopener follow" target="_blank"><div class="lx ab dx"><div class="ly ab lz cl cj ma"><h2 class="bd hj fj z dz mb eb ec mc ee eg hh bi translated">所有高效网络模型的完整架构细节</h2><div class="md l"><h3 class="bd b fj z dz mb eb ec mc ee eg dy translated">让我们深入了解所有不同高效网络模型的体系结构细节，并找出它们的不同之处…</h3></div><div class="me l"><p class="bd b fq z dz mb eb ec mc ee eg dy translated">towardsdatascience.com</p></div></div><div class="mf l"><div class="ml l mh mi mj mf mk io lw"/></div></div></a></div></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><h2 id="3012" class="mm kr hi bd ks mn mo mp kw mq mr ms la jb mt mu le jf mv mw li jj mx my lm mz bi translated">步骤1:构建基础模型(高效网络— B5)</h2><p id="e8b6" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">Tensorflow库提供了一个现成的高效网络实现。所以我们将从导入包来构建基本模型开始。</p><figure class="nb nc nd ne fe ij es et paragraph-image"><div class="es et na"><img src="../Images/5796b0662043fb23a6bdf068084973f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*UioPM0FdKSPkxjPJTWxTnA.png"/></div></figure><p id="622d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们将构建有效的网络模型并冻结基础层，并保持模型中的顶部块可训练。此外，我正在使用“<strong class="is hj"> imagenet </strong>”分类问题的模型权重。</p><figure class="nb nc nd ne fe ij es et paragraph-image"><div class="es et nf"><img src="../Images/de1f40a2dcebbcc984763579de2260b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*Sc2v6jOBboTazP-ZyRkCzg.png"/></div></figure><p id="5cdd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="jr">使用高效网络进行迁移学习时需要注意的两件事:</em></p><ol class=""><li id="18af" class="jv jw hi is b it iu ix iy jb jx jf jy jj jz jn ka kb kc kd bi translated">每个模块都需要打开或关闭。这是因为该体系结构包括从每个块的第一层到最后一层的捷径。不尊重块也会严重损害最终性能。<strong class="is hj">在上面的图片中，我保留了模型中最上面的18层(这是最上面的模块)可训练。</strong></li><li id="9b91" class="jv jw hi is b it ke ix kf jb kg jf kh jj ki jn ka kb kc kd bi translated"><strong class="is hj">批标准化</strong>层需要保持冻结。如果它们也变成可训练的，解冻后的第一个纪元将显著降低精度。</li></ol></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><h2 id="5f15" class="mm kr hi bd ks mn mo mp kw mq mr ms la jb mt mu le jf mv mw li jj mx my lm mz bi translated">步骤2:在基本模型的基础上构建最终模型</h2><p id="6201" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">首先，我们将定义“<strong class="is hj">头</strong>”，它将位于基础模型的顶部，并将输出最终的模型预测。</p><figure class="nb nc nd ne fe ij es et paragraph-image"><div class="es et ng"><img src="../Images/bdde9b46ae678cf7ec3a1d7253445e78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1066/format:webp/1*jqe0pMJHMYxC_Q0mfNfaBg.png"/></div></figure><p id="0e5c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来，我们将结合基础模型和head，来定义最终的模型架构。</p><figure class="nb nc nd ne fe ij es et paragraph-image"><div class="es et nh"><img src="../Images/e183f106ac790b1eb62531b3048d0ec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*vvU8tuqPNrQan6KyueBRiw.png"/></div></figure><p id="55b9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">就是这样。现在模型已经准备好进行训练了。下面是我在研究黑客马拉松问题时，使用上述模型配置获得的学习曲线。</p><figure class="nb nc nd ne fe ij es et paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="es et ni"><img src="../Images/978fba164e559baabb51efdd443e36b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fhEDjSb5gs3dnvgOA9kc4Q.png"/></div></div></figure><p id="9c5f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该模型在60个时期内达到了90%的验证准确率。</p></div><div class="ab cl kj kk gp kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="hb hc hd he hf"><h1 id="bd78" class="kq kr hi bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">结束语</h1><p id="c4bf" class="pw-post-body-paragraph iq ir hi is b it lo iv iw ix lp iz ja jb lq jd je jf lr jh ji jj ls jl jm jn hb bi translated">这是图像分类新技术系列文章的第一部分。在下一篇<a class="ae nj" href="https://tdtapas.medium.com/novel-techniques-to-win-an-image-classification-hackathon-part-2-e33bf0ad5fe6" rel="noopener">文章</a>中，我将继续讲述其余的新颖技巧。我强烈建议获得你自己的数据集(无论是从Kaggle还是使用网络搜集),并尝试本帖中详述的迁移学习方法。</p><p id="7617" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请给我留下您的意见、反馈和挑战(如果您面临任何挑战)，我将与您单独联系，以便一起合作。</p></div></div>    
</body>
</html>