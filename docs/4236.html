<html>
<head>
<title>Data Preprocessing Using Sklearn</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Sklearn进行数据预处理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-preprocessing-using-sklearn-2c6fe013f594?source=collection_archive---------1-----------------------#2021-09-11">https://medium.com/analytics-vidhya/data-preprocessing-using-sklearn-2c6fe013f594?source=collection_archive---------1-----------------------#2021-09-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/d38504ad5b9d368fe9c5eea5c1dc304c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NfTkTp_35ylyDIdreYb9Sw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated"><a class="ae it" href="https://towardsai.net/p/data-science/data-preprocessing-concepts-with-python" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="585b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这个世界上，你永远不会找到一个完美的现成可用的数据集，可以直接应用于任何机器学习算法。为了应用机器学习算法，我们必须执行某些数据预处理以适应模型。</p><p id="dc05" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这篇文章背后的动机是解释整个数据预处理周期，这是任何机器学习项目的基础。</p><h1 id="0537" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">目录</h1><ol class=""><li id="c367" class="kq kr hh iw b ix ks jb kt jf ku jj kv jn kw jr kx ky kz la bi translated">特征缩放</li><li id="d5ad" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated">标准化</li><li id="19e1" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated">编码</li><li id="d67d" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated">[数]离散化</li><li id="7af1" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated">处理缺失值</li></ol><p id="bb6d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">那么，我们开始吧。</p><p id="f3fd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我将使用loan_prediction数据集来解释数据预处理概念。您可以在此 下载<a class="ae it" href="https://www.analyticsvidhya.com/wp-content/uploads/2016/07/loan_prediction-1.zip" rel="noopener ugc nofollow" target="_blank"> <em class="lg">的数据集。</em></a></p><p id="719d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们加载数据集。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="9aa9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">数据集将看起来像这样。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es ln"><img src="../Images/3af2102c74c2db6c08be9d0b8adc7454.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*AmhDpcJN_SbLk-Mub_NVzA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">资料组</figcaption></figure><p id="b9bb" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们进入文章的实际内容。</p><h1 id="f4b0" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">1.特征缩放或标准化</h1><p id="1924" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf lo jh ji jj lp jl jm jn lq jp jq jr ha bi translated">要素缩放是一种缩放技术，在这种技术中，值被移动和重新缩放，以便它们最终的范围在0和1之间，或者每个要素的最大绝对值被缩放到单位大小。</p><p id="ba5f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对连续变量执行特征缩放。让我们画出所有变量的分布图。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/420404fe346a54ac2d11e80bd2fb5ccb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*UlBu2BeW9Jdf9hl5vkxncQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">连续变量的分布</figcaption></figure><p id="367b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过理解该图，申请人收入和共同申请人收入在相同范围内，即0-50，000，而贷款金额在0-600美元范围内。</p><p id="dd16" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Loan_Amount_Term的情况与其他变量完全不同，因为它的单位是月，而其他变量的单位是美元。</p><p id="2644" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果我们将任何基于距离的方法直接应用于该数据，那么具有较高值范围的变量将占主导地位，因此其他一些重要的变量将变得不重要，因此在这种情况下，我们的准确度将较低。</p><p id="4857" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们直接把KNN应用到这个变量上，看看会有什么结果。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">在不缩放数据的情况下应用knn</figcaption></figure><p id="8ccb" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过在没有缩放值的情况下对该数据应用knn，我们获得了61%的准确度。</p><p id="b0e8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们先缩放数据，让我们应用特征缩放技术。</p><p id="b6e6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在sklearn中，我们可以通过两种方式扩展数据</p><h2 id="904e" class="ls jt hh bd ju lt lu lv jy lw lx ly kc jf lz ma kg jj mb mc kk jn md me ko mf bi translated">1.最小最大缩放器</h2><p id="06d7" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf lo jh ji jj lp jl jm jn lq jp jq jr ha bi translated">最小最大缩放器将数据点重新缩放到0到1的范围内。</p><p id="01a5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最小最大标量公式</p><p id="96ca" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">X_std = (X — X.min(轴=0)) / (X.max(轴=0) — X.min(轴=0))</p><p id="9239" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">X_scaled = X_std *(最大值—最小值)+最小值</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">应用最小最大缩放器</figcaption></figure><p id="77bd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">应用MinMaxScaler后，我们将获得大约75%的准确性。所以，MinMaxScaler帮助我们吹嘘我们模型的准确性。</p><p id="a446" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们看看，如果我们将MaxAbsScaler应用于这些变量会怎么样。</p><h2 id="6cd4" class="ls jt hh bd ju lt lu lv jy lw lx ly kc jf lz ma kg jj mb mc kk jn md me ko mf bi translated">2.MaxAbsScaler</h2><p id="a459" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf lo jh ji jj lp jl jm jn lq jp jq jr ha bi translated">MaxAbsScaler类似于minmax scaler，但它通过除以每个要素中的最大值来缩放[-1，1]范围内的值。它适用于已经以零或稀疏数据为中心的数据。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">应用MaxAbsScaler</figcaption></figure><p id="1163" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过应用MaxAbsScaler，我们获得了70.83%的准确率。所以，在这种情况下，minmax scaler更好。</p><p id="b673" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">换句话说，应用MinMaxScaler或MaxAbsScaler就是将数据置于某个基于值的范围的中心。</p><p id="6153" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">需要注意的是，在执行基于距离的方法时，我们必须尝试缩放数据，以便重要性较低的特征不会由于其较大的范围而最终支配目标函数。</p><p id="252a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在的问题是，将空间数据居中会破坏数据中的稀疏结构，因此很少是明智的做法。但是，缩放稀疏输入是有意义的，尤其是在要素处于不同比例的情况下。</p><p id="e1b6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">MaxAbsScaler是专门为缩放稀疏数据而设计的，建议采用这种方式。</p><p id="ac3b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，如果我们应用算法而不是基于距离的算法呢？让我们试试逻辑回归。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="48cc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过在缩放数据之前应用逻辑回归，我们得到61.46%的准确度，并且在缩放数据之后，我们得到63.54%的准确度。</p><p id="dc35" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里要注意的是，在knn的情况下，我们的准确率从61%大幅提高到75%，但在逻辑回归的情况下，我们没有得到这样的提升。那么，问题是什么？</p><p id="9eb7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个问题的答案是，在逻辑回归中，每个特征被分配一个权重或系数(Wi)。因此，如果有一个范围相对较大的特征，并且它在目标函数中不重要，那么逻辑回归本身将为其系数分配一个非常低的值，从而抵消该特定特征的主要影响，而基于距离的方法(如KNN)没有这种内在策略，因此它需要缩放。</p><p id="6646" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">但是，在逻辑回归的情况下，我们如何提高精确度呢？</p><p id="fbfb" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">标准化来了。</p><h1 id="5005" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">2.标准化</h1><p id="b908" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf lo jh ji jj lp jl jm jn lq jp jq jr ha bi translated">标准化(Z值归一化)是对要素进行重新缩放的过程，以便它们具有均值为0、标准差为1的标准正态分布的属性。</p><p id="bf41" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">样本的标准分数(z分数)可以计算为</p><p id="258c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">z =(X-平均值)/标准偏差</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="bc75" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们获得了75%的准确率，这与缩放后使用knn获得的准确率相同。这证明标准化输入确实有助于提高预测模型的准确性。</p><p id="8914" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其他算法如KNN、神经网络、SVM、LDA、PCA对标准化数据表现更好。</p><p id="ebf9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在本内容中，我必须明确的一点是，一般来说，标准化有3种技术:</p><ol class=""><li id="b193" class="kq kr hh iw b ix iy jb jc jf mg jj mh jn mi jr kx ky kz la bi translated"><strong class="iw hi">最小-最大正规化，我们已经看到的最小最大规模</strong></li><li id="91a3" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated"><strong class="iw hi">平均或均值归一化，即最小标度</strong></li><li id="16d4" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated"><strong class="iw hi"> Z分数标准化，也称为标准化</strong></li></ol><p id="24d6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我希望我已经消除了你对正常化的困惑。</p><p id="4fb9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，采访中最受欢迎的问题之一是，什么时候应用规范化，什么时候应用标准化？</p><p id="6654" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为此，深入研究数据和理解数据是必须的。您也可以两者都执行，并根据您的问题找出哪一个更好。</p><p id="2f9f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里有一些选择合适方法的提示。</p><ol class=""><li id="282c" class="kq kr hh iw b ix iy jb jc jf mg jj mh jn mi jr kx ky kz la bi translated">当您知道数据的分布不符合高斯分布时，可以使用归一化。这在不假设任何数据分布的算法中很有用，例如K-最近邻和神经网络。</li><li id="d5cc" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated">另一方面，在数据遵循高斯分布的情况下，标准化会有所帮助。然而，这并不一定是真的。此外，与标准化不同，标准化没有边界范围。因此，即使您的数据中有异常值，它们也不会受到标准化的影响。</li></ol><p id="3252" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">关于标准化和规范化的更多细节，您可以访问这篇文章。</p><blockquote class="mj"><p id="030e" class="mk ml hh bd mm mn mo mp mq mr ms jr dx translated"><strong class="ak">我们对连续数字特征进行了预处理。但是，我们的数据集也有其他特点，如性别，已婚，家属，自营职业者和教育。所有这些分类特征都具有字符串值，例如，性别具有值男性或女性。我们都知道计算机只理解数字，不理解其他任何东西，所以我们需要一种方法来将这些特征表示成数字特征。这个概念被称为标签编码。</strong></p></blockquote><h1 id="eed0" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd mt kf kg kh mu kj kk kl mv kn ko kp bi translated">3.编码</h1><p id="281a" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf lo jh ji jj lp jl jm jn lq jp jq jr ha bi translated">我们可以用Sklearn以两种方式执行编码</p><h2 id="6472" class="ls jt hh bd ju lt lu lv jy lw lx ly kc jf lz ma kg jj mb mc kk jn md me ko mf bi translated">1.标签编码</h2><p id="33cf" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf lo jh ji jj lp jl jm jn lq jp jq jr ha bi translated">标签编码可以通过sklearn中的LabelEncoder来完成。标签编码器对特征中的每个唯一值进行可变分类。</p><p id="2b15" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">例如，男性==&gt; 1，女性==&gt; 0</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="96fd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">应用LabelEncoder后的数据。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/b76513dbd33e7f865a5314fe8f29c811.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*9vl87i6QsVockf6VSdHAhA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">应用LabelEncoder后的数据</figcaption></figure><p id="f961" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">应用LabelEncoder后，我们得到了73.96%的准确率。因此，在这种情况下，通过添加分类特征，我们的准确性会降低。因此它没有太大的意义。</p><p id="eaa4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们也尝试对数据应用OneHotEncoding。</p><h2 id="7824" class="ls jt hh bd ju lt lu lv jy lw lx ly kc jf lz ma kg jj mb mc kk jn md me ko mf bi translated">2.OneHotEncoding</h2><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mx"><img src="../Images/8fcbfff8c71a0d93621ecaa0a06c4076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*CepD9EVoX4sDcNiINpS-dA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">应用OneHotEncoding后的数据</figcaption></figure><p id="18db" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在应用OneHotEncoding之后，我们获得了75%的准确率，这与我们之前在添加分类变量之前获得的准确率相同。</p><p id="4518" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在出现了另一个问题，即使用LabelEncoder还是OneHotEncoder？</p><p id="13ab" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这通常取决于数据集和您希望应用的模型。但是，在为您的模型选择正确的编码技术之前，仍然有几点需要注意。</p><p id="ae3e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在以下情况下，我们可以应用一键编码:</p><ol class=""><li id="d386" class="kq kr hh iw b ix iy jb jc jf mg jj mh jn mi jr kx ky kz la bi translated">分类特征是<strong class="iw hi">而不是顺序</strong>(就像上面的国家)</li><li id="a73f" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated">分类特征的数量较少，因此可以有效地应用一键编码</li></ol><p id="9d91" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们在以下情况下应用标签编码:</p><ol class=""><li id="44bc" class="kq kr hh iw b ix iy jb jc jf mg jj mh jn mi jr kx ky kz la bi translated">分类特征是<strong class="iw hi">序数</strong>(比如Jr. kg，Sr. kg，小学，高中)</li><li id="a45f" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated">类别的数量非常大，因为一键编码会导致高内存消耗</li></ol><p id="2baa" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">你可以在<a class="ae it" href="https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/" rel="noopener ugc nofollow" target="_blank"> <em class="lg">这篇</em> </a>文章中阅读更多关于LabelEncoder vs One-HotEncoder的内容。</p><h1 id="eb4f" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">4.[数]离散化</h1><p id="bd30" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf lo jh ji jj lp jl jm jn lq jp jq jr ha bi translated">数据离散化是通过分组将连续数据转换为离散桶的过程。离散化也因数据的易维护性而闻名。用离散数据训练模型比用连续数据训练模型更快、更有效。</p><p id="3dfd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">离散化，也称为量化或宁滨，将连续要素划分为预先指定数量的类别(箱)，从而使数据离散。</p><p id="54ac" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">离散化的主要目标之一是显著减少连续属性的离散区间数。因此，为什么这种转换可以提高基于树的模型的性能。</p><p id="9904" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Sklearn提供了一个KBinsDiscretizer类来处理这个问题。您唯一需要指定的是每个要素的条柱数量(n_bins)以及如何对这些条柱进行编码(序号、一个热或一个热密集)。可选策略参数可以设置为三个值:</p><ol class=""><li id="4955" class="kq kr hh iw b ix iy jb jc jf mg jj mh jn mi jr kx ky kz la bi translated">统一，其中每个要素中的所有条柱都具有相同的宽度。</li><li id="3f67" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated">分位数(默认)，其中每个要素中的所有条柱都具有相同的点数。</li><li id="ad9a" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated">k均值，其中每个条柱中的所有值都具有相同的1D k均值聚类的最近中心。</li></ol><p id="83b1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">小心选择策略参数很重要。例如，使用统一策略对异常值非常敏感，会使您最终得到只有几个数据点的条柱，即异常值。</p><p id="ade4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们转向我们的例子来进行一些澄清。导入KBinsDiscretizer类，并创建一个具有三个容器、序号编码和统一策略的新实例(所有容器都具有相同的宽度)。然后，拟合并转换我们所有原始的、缺失的指标和多项式数据。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="9746" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们在ML项目中普遍面临的另一个问题是处理缺失值。</p><h1 id="a809" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">5.处理缺失值</h1><p id="3ef3" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf lo jh ji jj lp jl jm jn lq jp jq jr ha bi translated">在应用任何ML算法之前，我们必须查看是否有任何值丢失。</p><p id="f43d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有许多方法可以处理丢失的值。</p><h2 id="75ff" class="ls jt hh bd ju lt lu lv jy lw lx ly kc jf lz ma kg jj mb mc kk jn md me ko mf bi translated">1.删除所有缺少的值</h2><p id="3adc" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf lo jh ji jj lp jl jm jn lq jp jq jr ha bi translated">丢弃值会删除许多观察值，如果这些信息非常有用，那么数据将会丢失。</p><h2 id="e93d" class="ls jt hh bd ju lt lu lv jy lw lx ly kc jf lz ma kg jj mb mc kk jn md me ko mf bi translated">2.归罪</h2><p id="c764" class="pw-post-body-paragraph iu iv hh iw b ix ks iz ja jb kt jd je jf lo jh ji jj lp jl jm jn lq jp jq jr ha bi translated">标识数据集中缺失的值并用数值替换它们。这被称为数据估算，或缺失数据估算。</p><p id="00c0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">一种简单而流行的数据插补方法是使用统计方法从现有的值中估计出某一列的值，然后用计算出的统计值替换该列中所有缺失的值。</p><p id="e258" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">它很简单，因为统计数据计算起来很快，它之所以受欢迎，是因为它经常被证明非常有效。</p><p id="4de3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">计算的常见统计数据包括:</p><ul class=""><li id="4add" class="kq kr hh iw b ix iy jb jc jf mg jj mh jn mi jr my ky kz la bi translated">列平均值。</li><li id="eb1a" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr my ky kz la bi translated">列中值。</li><li id="9f6a" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr my ky kz la bi translated">列模式值。</li><li id="4402" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr my ky kz la bi translated">一个常量值。</li></ul><p id="0d0c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们使用Titanic数据集来完成这个任务，因为它有很多缺失值。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="ll lm l"/></div></figure><p id="e3b6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在本文中，我们已经介绍了许多关于数据预处理的信息，我希望我已经消除了您对数据预处理的许多疑虑。</p><p id="6f2a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">感谢阅读这篇文章。😃</p><p id="f8e8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于类似的数据科学相关内容，请在medium上关注我。</p><h2 id="2ef2" class="ls jt hh bd ju lt lu lv jy lw lx ly kc jf lz ma kg jj mb mc kk jn md me ko mf bi translated">参考</h2><ol class=""><li id="cdbd" class="kq kr hh iw b ix ks jb kt jf ku jj kv jn kw jr kx ky kz la bi translated"><a class="ae it" href="https://scikit-learn.org/stable/modules/preprocessing.html#" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable/modules/preprocessing.html#</a></li><li id="afaa" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated"><a class="ae it" href="https://www.analyticsvidhya.com/blog/2016/07/practical-guide-data-preprocessing-python-scikit-learn/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2016/07/practical-guide-data-预处理-python-scikit-learn/ </a></li><li id="13c6" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated"><a class="ae it" href="https://towardsdatascience.com/data-normalization-in-machine-learning-395fdec69d02" rel="noopener" target="_blank">https://towards data science . com/data-normalization-in-machine-learning-395 fdec 69d 02</a></li><li id="f91d" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated"><a class="ae it" href="https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/" rel="noopener ugc nofollow" target="_blank">https://medium.com/r/?URL = https % 3A % 2F % 2fwww . analyticsvidhya . com % 2f blog % 2f 2020% 2f 04% 2f特征-缩放-机器-学习-标准化-标准化%2F </a></li><li id="0af4" class="kq kr hh iw b ix lb jb lc jf ld jj le jn lf jr kx ky kz la bi translated"><a class="ae it" href="https://machinelearningmastery.com/statistical-imputation-for-missing-values-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/statistical-attraction-for-missing-values-in-machine-learning/</a></li></ol></div></div>    
</body>
</html>