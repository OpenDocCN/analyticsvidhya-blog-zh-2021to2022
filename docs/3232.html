<html>
<head>
<title>Simple CNN using NumPy Part III(ReLU,Max pooling &amp; Softmax)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用NumPy第三部分的简单CNN(ReLU，Max pooling &amp; Softmax)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/simple-cnn-using-numpy-part-iii-relu-max-pooling-softmax-c03a3377eaf2?source=collection_archive---------5-----------------------#2021-06-20">https://medium.com/analytics-vidhya/simple-cnn-using-numpy-part-iii-relu-max-pooling-softmax-c03a3377eaf2?source=collection_archive---------5-----------------------#2021-06-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="53b7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">概述</h1><p id="a155" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在之前的帖子中，我讨论了以下主题</p><ul class=""><li id="751f" class="kb kc hi jf b jg kd jk ke jo kf js kg jw kh ka ki kj kk kl bi translated"><a class="ae km" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-i-introduction-data-processing-b6652615604d">图像的输入处理</a></li><li id="142b" class="kb kc hi jf b jg kn jk ko jo kp js kq jw kr ka ki kj kk kl bi translated"><a class="ae km" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-ii-convolution-operation-b8c5a02b0844">卷积运算</a></li></ul><p id="a28c" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">在本系列的第三部分中，我将介绍在正向传播过程中使用的三个函数。</p><ol class=""><li id="3bda" class="kb kc hi jf b jg kd jk ke jo kf js kg jw kh ka kv kj kk kl bi translated">热卢</li><li id="74c0" class="kb kc hi jf b jg kn jk ko jo kp js kq jw kr ka kv kj kk kl bi translated">最大池化</li><li id="457f" class="kb kc hi jf b jg kn jk ko jo kp js kq jw kr ka kv kj kk kl bi translated">Softmax</li></ol><h1 id="c703" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">ReLU函数</h1><p id="cdce" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">ReLU函数是一个非线性激活函数，它过滤掉负值。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es kw"><img src="../Images/d42f4ce1400840d61be423851da2af3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*xbYPRL-UXzFb5067UGyIaw.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">ReLU函数</figcaption></figure><p id="cc3c" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">在神经网络中应用的ReLU函数不会面临诸如消失梯度的问题。与sigmoid等饱和函数不同，ReLU函数导致正值的非零梯度。</p><p id="af90" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">给定ReLU函数的微分是常数，计算具有ReLU激活的层的梯度需要较少的时间。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es li"><img src="../Images/7a9fbaf46b2f3809a9922eba2d2358ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RURDPCzW90qfWoWL0DZ7WA.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">应用于sigmoid函数的大正值将收敛于1。这导致对于大的正值导数为零。零导数将阻止模型参数正确调整。</figcaption></figure><p id="5f5a" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">下面的代码片段包含ReLU的函数</p><pre class="kx ky kz la fd ln lo lp lq aw lr bi"><span id="9497" class="ls ig hi lo b fi lt lu l lv lw">def ReLU(x):<br/>    return (x&gt;0)*x</span></pre><h1 id="c2ad" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">最大池化</h1><p id="b5ee" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">最大池化是提取图像中低级特征的过程。这是通过挑选预定大小的图像块，并从这些图像块中保留最大值来实现的。</p><p id="fd9f" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">单个最大池操作会选取一个图像块，其大小与最大池过滤器相同，并从中选择最大值。根据每次最大池操作后我们允许最大池筛选器移动的量，完成多个最大池操作。这由一个名为<strong class="jf hj">步幅</strong>的预定义参数决定。</p><p id="c3f6" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">在这个项目中，我选择了步幅= 2，图像宽度和高度= 2。</p><p id="a69e" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">下图显示了应用于只有一个通道的图像的最大池操作的简单示例。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es lx"><img src="../Images/b35240413becb1f18356e6cc29d46d09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8yfDolcDtTR7lO88J9crag.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">单通道最大池操作</figcaption></figure><p id="6a02" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">下图显示了应用于具有两个通道的图像的最大池操作。通道的数量不变。图像的高度/宽度根据选择的过滤器高度/宽度而变化</p><p id="6463" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">使用以下公式计算新的高度或宽度</p><p id="3f43" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">新高度或新宽度=((图像高度或宽度-过滤器高度或宽度+2 *填充)/步幅)+1</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ly"><img src="../Images/0752c42ecf55529bf227ef5609d5f565.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SORWRVuBTV-spZ3bl-jbeg.png"/></div></div></figure><pre class="kx ky kz la fd ln lo lp lq aw lr bi"><span id="e04b" class="ls ig hi lo b fi lt lu l lv lw">def maxpool_multiple(input_image,stride=2):<br/>    input_width = input_image.shape[3]<br/>    input_height = input_image.shape[2]<br/>    filter_width = 2<br/>    filter_height = 2<br/>    <br/>    output_width = int((input_width-filter_width)/stride)+1<br/>    output_height = int((input_height-filter_height)/stride)+1<br/>    <br/>    output_image = np.zeros((input_image.shape[0],input_image.shape[1],output_width,output_height))<br/>    for i in range(output_image.shape[0]):<br/>        output_image[i:i+1,:,:,:] = maxpool(input_image[i:i+1,:,:,:],stride=2)<br/>    return output_image</span><span id="48de" class="ls ig hi lo b fi lz lu l lv lw">def maxpool(input_image,stride=2):<br/>    input_width = input_image.shape[3]<br/>    input_height = input_image.shape[2]<br/>    filter_width = 2<br/>    filter_height = 2<br/>    n_channels = input_image.shape[1]<br/>    num_images = input_image.shape[0] <br/>    <br/>    output_width = int((input_width-filter_width)/stride)+1<br/>    output_height = int((input_height-filter_height)/stride)+1<br/>    output = np.zeros((n_channels,output_width*output_height))<br/>    c=0<br/>    for height in range(0,input_height,stride):<br/>        if height+filter_height&lt;=input_height:<br/>            image_rectangle = input_image[0,:,height:height+filter_height,:]<br/>            for width in range(0,input_width,stride):<br/>                if width+filter_width&lt;=input_width:<br/>                    image_square = image_rectangle[:,:,width:width+filter_width]<br/>                    image_flatten = image_square.reshape(-1,1)<br/>#                     print(image_flatten)<br/>#                     print('----')<br/>                    output[:,c:c+1] = np.array([float(max(i)) for i in np.split(image_flatten,n_channels)]).reshape(-1,1)<br/>                    c+=1<br/>   <br/>            <br/>    final_output = np.array(np.hsplit(output,1)).reshape((1,n_channels,output_height,output_width))<br/>        <br/>    return final_output</span></pre><h1 id="05fc" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">软最大值函数</h1><p id="b45e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">softmax函数<strong class="jf hj">将一个实值向量转换为一个范围在0到1 </strong>之间的值向量。新变换的向量<strong class="jf hj">加起来是1；转换后的向量成为概率分布。</strong>大值将被转换为接近1的值，小值将被转换为接近0的值。</p><p id="33b9" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">软最大值函数将在最后一层用于预测；如果第一个节点具有最高值，则预测值将为0。如果第三个节点具有最高值，则预测将是2。</p><p id="3d0d" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">在下面的示例中，我们将查看softmax操作。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es ma"><img src="../Images/6bcdc3e7d5f9913efcb448c5e116a7aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*peMUUMmdgiyRSWz0x99Ujg.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">软最大值函数</figcaption></figure><p id="4c20" class="pw-post-body-paragraph jd je hi jf b jg kd ji jj jk ke jm jn jo ks jq jr js kt ju jv jw ku jy jz ka hb bi translated">softmax转换将如下所示</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="er es mb"><img src="../Images/86a3aac7288530dc7ea833ac6e7d7de8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3BRy_a41sBhQtc4M42BUsw.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">较小的值将被映射到接近零的值。</figcaption></figure><h1 id="169b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">资源</h1><ul class=""><li id="0fd6" class="kb kc hi jf b jg jh jk jl jo mc js md jw me ka ki kj kk kl bi translated"><a class="ae km" href="https://deepai.org/machine-learning-glossary-and-terms/softmax-layer" rel="noopener ugc nofollow" target="_blank"> Softmax函数定义| DeepAI </a></li><li id="d9f6" class="kb kc hi jf b jg kn jk ko jo kp js kq jw kr ka ki kj kk kl bi translated"><a class="ae km" href="https://deepai.org/machine-learning-glossary-and-terms/relu#:~:text=ReLu%20is%20a%20non-linear%20activation%20function%20that%20is,maximum%20value%20between%20zero%20and%20the%20input%20value." rel="noopener ugc nofollow" target="_blank"> ReLu定义| DeepAI </a></li></ul><h1 id="4bb5" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">反馈</h1><p id="f52d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">感谢您的阅读！如果您有任何反馈/建议，请随时在下面评论/您可以发邮件到padhokshaja@gmail.com<strong class="jf hj">给我</strong></p><h1 id="0763" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">下一篇文章</h1><p id="a9d5" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated"><a class="ae km" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-iv-back-propagation-through-fully-connected-layers-c5035d678307">通过全连接层的反向传播</a></p></div></div>    
</body>
</html>