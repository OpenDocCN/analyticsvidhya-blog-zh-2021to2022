<html>
<head>
<title>Mediapipe: Hand gesture-based volume controller in Python w/o GPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">media pipe:Python中基于手势的音量控制器，不带GPU</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/mediapipe-hand-gesture-based-volume-controller-in-python-w-o-gpu-67db1f30c6ed?source=collection_archive---------1-----------------------#2021-04-13">https://medium.com/analytics-vidhya/mediapipe-hand-gesture-based-volume-controller-in-python-w-o-gpu-67db1f30c6ed?source=collection_archive---------1-----------------------#2021-04-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="bb31" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">如果我说你想用python做一些手势识别的事情，你脑海中会出现的第一个解决方案是什么:训练一个CNN、contours或凸面外壳。听起来不错，也可行，但是当实际使用这些技术时，检测并不是很好，并且需要特殊的条件(如适当的背景或您在培训时使用的类似条件)。</p><p id="0120" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">最近，我偶然发现了一个超级酷的叫做<a class="ae je" href="https://mediapipe.dev/index.html" rel="noopener ugc nofollow" target="_blank"> Mediapipe </a>的库，它让我们的事情变得非常简单。我建议你通过它的官方网站去了解更多，因为这个网站解释了图书馆提供给你的几乎所有东西。在本文中，我要做的是展示我如何使用这个库来提出一些很棒的项目，因为这是让您阅读本文的原因。</p><p id="af88" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在我们开始真正的代码之前，让我们花点时间来欣赏一下这个库。我真的很着迷于使用这个库和做创新的事情是多么容易，否则我会发现从头开始编码非常困难。<strong class="ii hj"> <em class="jf">你甚至不需要一个GPU </em> </strong>来使用这个库，即使在普通的CPU上，这些东西也能非常流畅地工作。补充一下，它是由谷歌备份的，所以这给了另一个使用这个库的理由。在本文中，我将处理Python的东西，但是这个库支持几乎所有的<a class="ae je" href="https://google.github.io/mediapipe/solutions/solutions" rel="noopener ugc nofollow" target="_blank">平台</a> (Android、iOS、C++)。在我写这篇文章的时候，Python只有几个可用的模块，但是不要担心，它仍然在快速发展，你可以期待很快会有更多的模块出现。</p></div><div class="ab cl jg jh gp ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="hb hc hd he hf"><h1 id="24b8" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">介绍</h1><p id="46d2" class="pw-post-body-paragraph ig ih hi ii b ij kl il im in km ip iq ir kn it iu iv ko ix iy iz kp jb jc jd hb bi translated">在本文中，我将使用这个库的<a class="ae je" href="https://google.github.io/mediapipe/solutions/hands" rel="noopener ugc nofollow" target="_blank"> hands </a>模块来创建两个很酷的项目。<em class="jf">手部模块创建基于21个点的手部定位</em>。这意味着如果你给这个模块提供一个手的图像，它将返回一个21点的向量，显示你手上21个重要标志的坐标。如果你想知道它是如何做到这一点的，可以去查看他们页面上的文档。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kq"><img src="../Images/81b1d2e9b7ea40b50396714b4700fba5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JzJ_Ob4RfgsfEAbWtSbI6g.png"/></div></div><figcaption class="lc ld et er es le lf bd b be z dx translated">图片取自Mediapipe官网。请点击此处的<a class="ae je" href="https://google.github.io/mediapipe/solutions/hands" rel="noopener ugc nofollow" target="_blank">查看全部工作细节。</a></figcaption></figure><p id="273e" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">无论输入图像如何，这些点的意义都是一样的。这意味着点4永远是你的拇指尖，点8永远是你的食指尖。所以一旦你有了21点向量，你创造什么样的项目就取决于你的创造力了。</p></div><div class="ab cl jg jh gp ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="hb hc hd he hf"><h1 id="27e9" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">确定手部标志</h1><p id="b2c5" class="pw-post-body-paragraph ig ih hi ii b ij kl il im in km ip iq ir kn it iu iv ko ix iy iz kp jb jc jd hb bi translated">我们正在尝试通过以下手势控制我们的系统音量(注意右下角的音量变化):</p><figure class="kr ks kt ku fd kv"><div class="bz dy l di"><div class="lg lh l"/></div></figure><p id="4c30" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在Python中使用mediapipe库之前，您必须:</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="fc22" class="ln jo hi lj b fi lo lp l lq lr">pip install mediapipe</span></pre><p id="237d" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">让我们创建一个名为HandDetector的实用程序类，它将使我们的项目模块化</p><ol class=""><li id="13f1" class="ls lt hi ii b ij ik in io ir lu iv lv iz lw jd lx ly lz ma bi translated">导入所需的包</li></ol><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="e6a5" class="ln jo hi lj b fi lo lp l lq lr">import mediapipe as mp<br/>import cv2</span></pre><p id="85e8" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">2.创建由Mediapipe提供的hands模块的实例，后跟Mediapipe的绘图实用程序的实例。绘图工具有助于在您的图像或帧上绘制这21个地标和连接这些地标的线条(您在上面的视频中已经注意到了)。</p><p id="47d2" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">这一步几乎是不变的，必须在你的每个项目中完成。</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="c813" class="ln jo hi lj b fi lo lp l lq lr">mpHands = mp.solutions.hands<br/>mpDraw = mp.solutions.drawing_utils</span></pre><p id="222d" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">3.然后我们开始编写我们的类</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="0810" class="ln jo hi lj b fi lo lp l lq lr">class HandDetector:<br/>    def __init__(self, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5):<br/>        self.hands = mpHands.Hands(max_num_hands=max_num_hands, min_detection_confidence=min_detection_confidence,<br/>                                   min_tracking_confidence=min_tracking_confidence)</span></pre><p id="fe07" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><em class="jf"> max_num_hands </em>:您希望Mediapipe检测的手数。Mediapipe将返回一个手的数组，数组中的每个元素(或一只手)将依次有21个标志点</p><p id="b861" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><em class="jf"> min_detection_confidence </em>，<em class="jf">min _ tracking _ confidence</em>:media pipe第一次启动时，检测到手。之后，它试图跟踪手，因为检测比跟踪更耗时。如果跟踪置信度下降到指定值，则再次切换回检测。</p><p id="63e3" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">Hands()类需要所有这些参数，所以我们在下一行中将它们传递给Hands类。</p><p id="cbdd" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">4.接下来我们定义这个类的函数findHandLandMarks()<em class="jf">，主要的事情发生在这里</em></p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="9ff0" class="ln jo hi lj b fi lo lp l lq lr">def findHandLandMarks(self, image, handNumber=0, draw=False):<br/>    originalImage = image<br/>    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # mediapipe needs RGB<br/>    results = self.hands.process(image)<br/>    landMarkList = []<br/><br/>    if results.multi_hand_landmarks:  # returns None if hand is not found<br/>        hand = results.multi_hand_landmarks[handNumber] #results.multi_hand_landmarks returns landMarks for all the hands<br/><br/>        for id, landMark in enumerate(hand.landmark):<br/>            # landMark holds x,y,z ratios of single landmark<br/>            imgH, imgW, imgC = originalImage.shape  # height, width, channel for image<br/>            xPos, yPos = int(landMark.x * imgW), int(landMark.y * imgH)<br/>            landMarkList.append([id, xPos, yPos])<br/><br/>        if draw:<br/>            mpDraw.draw_landmarks(originalImage, hand, mpHands.HAND_CONNECTIONS)<br/><br/>    return landMarkList</span></pre><p id="68c0" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">函数参数:</p><p id="4bc0" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">将检测到手界标的<em class="jf">图像</em>。在图像有多只手的情况下，<em class="jf">手号</em>，所以我们的函数将只返回指定手号的地标。布尔参数<em class="jf"> draw </em>决定我们是否希望medapipe在我们的图像上绘制这些地标。</p><p id="453d" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">下一行做所有的事情。这一小段代码实际上在幕后做了很多工作，并为您获取了所有的地标</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="0505" class="ln jo hi lj b fi lo lp l lq lr">results = self.hands.process(image)</span></pre><p id="eb93" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">然后，我们创建一个空列表<em class="jf"> landMarkList </em>，其中包含从函数返回的最终结果。</p><p id="2e8e" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">如果没有检测到手，则<em class="jf">results . multi _ hand _ landmarks</em>返回None，因此您应该将其用作故障安全条件。</p><p id="7265" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><em class="jf">results . multi _ hand _ landMarks</em>返回检测到的所有手牌的界标，因此将<em class="jf"> handNumber </em>传递给它会给出正确手牌的数据。</p><p id="fca0" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><em class="jf">手标志</em>给出所选手的21个标志。所以我们迭代这21个点，其中<em class="jf"> id </em>保存每个地标的id</p><blockquote class="mb mc md"><p id="0e6b" class="ig ih jf ii b ij ik il im in io ip iq me is it iu mf iw ix iy mg ja jb jc jd hb bi translated">这里需要注意的重要一点是，Mediapipe返回的地标信息不是地标的像素位置。相反，它是图像尺寸的比率。为了获得地标像素的精确x和y坐标，我们进行以下简单计算:</p></blockquote><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="bd4a" class="ln jo hi lj b fi lo lp l lq lr">xPos, yPos = int(landMark.x * imgW), int(landMark.y * imgH)<br/>landMarkList.append([id, xPos, yPos])</span></pre><p id="1412" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">然后，我们将地标的id(0…21)以及相应的x和y坐标添加到我们之前创建的空列表中。我们将这个列表返回给调用函数。</p><blockquote class="mb mc md"><p id="fbf3" class="ig ih jf ii b ij ik il im in io ip iq me is it iu mf iw ix iy mg ja jb jc jd hb bi translated">这是findHandLandMarks()将返回的内容:</p><p id="279a" class="ig ih jf ii b ij ik il im in io ip iq me is it iu mf iw ix iy mg ja jb jc jd hb bi translated">第0个索引→地标id，第1个索引→地标x坐标，第2个索引→地标x坐标</p></blockquote><p id="b9a1" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">如果布尔变量<em class="jf"> draw </em>这样说，则最后一部分在图像上绘制界标</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="9b13" class="ln jo hi lj b fi lo lp l lq lr">mpDraw.draw_landmarks(originalImage, hand, mpHands.HAND_CONNECTIONS)</span></pre><p id="2b95" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">这基本上是我们定制课程的内容。因此，您需要做的就是将您的手部图像传递给findHandLandMarks()，您将获得包含所有21个地标信息的列表。</p></div><div class="ab cl jg jh gp ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="hb hc hd he hf"><h1 id="3dc7" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">音量控制器</h1><p id="5b90" class="pw-post-body-paragraph ig ih hi ii b ij kl il im in km ip iq ir kn it iu iv ko ix iy iz kp jb jc jd hb bi translated">现在来看看这篇文章的主要标题。</p><p id="9671" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">在我们编写任何自定义代码之前，我们需要安装一个外部python包<a class="ae je" href="https://github.com/AndreMiras/pycaw" rel="noopener ugc nofollow" target="_blank"> pycaw </a>。这个库将处理我们系统的音量控制。</p><ol class=""><li id="215a" class="ls lt hi ii b ij ik in io ir lu iv lv iz lw jd lx ly lz ma bi translated">我们首先导入在上一节中创建的自定义类和其他必需的包:</li></ol><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="d95e" class="ln jo hi lj b fi lo lp l lq lr">from handDetector import HandDetector<br/>import cv2<br/>import math<br/>import numpy as np</span></pre><p id="ae6a" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">此外，导入pycaw相关的包和类:</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="39ca" class="ln jo hi lj b fi lo lp l lq lr">from ctypes import cast, POINTER<br/>from comtypes import CLSCTX_ALL<br/>from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume</span></pre><p id="58ae" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">2.然后，我们创建自定义HandDetector类的一个实例:</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="04e9" class="ln jo hi lj b fi lo lp l lq lr">handDetector = HandDetector(min_detection_confidence=0.7)</span></pre><p id="d9ad" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">然后初始化我们的网络摄像头的标准代码:</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="3568" class="ln jo hi lj b fi lo lp l lq lr">webcamFeed = cv2.VideoCapture(0)</span></pre><p id="21a4" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">然后是音量控制器的一些标准初始化。这一部分我没有什么可以解释的:</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="5771" class="ln jo hi lj b fi lo lp l lq lr">#Volume related initializations<br/>devices = AudioUtilities.GetSpeakers()<br/>interface = devices.Activate(<br/>IAudioEndpointVolume._iid_, CLSCTX_ALL, None)<br/>volume = cast(interface, POINTER(IAudioEndpointVolume))<br/>print(volume.GetVolumeRange()) #(-65.25, 0.0)</span></pre><p id="dce5" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">仔细看看最后一行。<em class="jf">卷。GetVolumeRange() </em>给出您的系统支持的音量范围，-65.25是最小值，0.0是最大值。没有理由说明这些值是如何获得的或者它们意味着什么，它们只是最小值和最大值。在本文的后半部分，我们将需要这些值。所以请注意这些值。</p><p id="5013" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">3.主音量控制器的东西:</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="80e5" class="ln jo hi lj b fi lo lp l lq lr">while True:<br/>    status, image = webcamFeed.read()<br/>    handLandmarks = handDetector.findHandLandMarks(image=image, draw=True)<br/><br/>    if(len(handLandmarks) != 0):<br/>        #for volume control we need 4th and 8th landmark<br/>        #details: https://google.github.io/mediapipe/solutions/hands<br/>        x1, y1 = handLandmarks[4][1], handLandmarks[4][2]<br/>        x2, y2 = handLandmarks[8][1], handLandmarks[8][2]<br/>        length = math.hypot(x2-x1, y2-y1)<br/>        print(length)<br/><br/>        #Hand range(length): 50-250<br/>        #Volume Range: (-65.25, 0.0)<br/><br/>        volumeValue = np.interp(length, [50, 250], [-65.25, 0.0]) #coverting length to proportionate to volume range<br/>        volume.SetMasterVolumeLevel(volumeValue, None)<br/><br/><br/>        cv2.circle(image, (x1, y1), 15, (255, 0, 255), cv2.FILLED)<br/>        cv2.circle(image, (x2, y2), 15, (255, 0, 255), cv2.FILLED)<br/>        cv2.line(image, (x1, y1), (x2, y2), (255, 0, 255), 3)<br/><br/>    cv2.imshow("Volume", image)<br/>    cv2.waitKey(1)</span></pre><p id="d3f0" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">我们开始从网络摄像头读取帧，一次一帧，然后将帧图像发送到我们的findHandLandMarks()</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="c63e" class="ln jo hi lj b fi lo lp l lq lr">handLandmarks = handDetector.findHandLandMarks(image=image, draw=True)</span></pre><p id="f9c5" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">然后我们提取拇指和食指指尖的x和y坐标(查看youtube视频，你会知道这里感兴趣的是拇指和食指)。</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="1f91" class="ln jo hi lj b fi lo lp l lq lr">x1, y1 = handLandmarks[4][1], handLandmarks[4][2]</span></pre><p id="a9fa" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">[4]表示我们指的是第四个地标，也就是我们的拇指尖。[1]表示我们需要位于findHandLandMarks()返回的响应的第一个索引处的x坐标。剩下的你自己想办法。</p><p id="e533" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">然后，我们计算连接地标4和地标8的线的长度:</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="0618" class="ln jo hi lj b fi lo lp l lq lr">length = math.hypot(x2-x1, y2-y1)</span></pre><p id="5f17" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated"><em class="jf">这个长度变量有什么用？</em>当我们的食指和拇指的指尖相互接触时，将会有一个长度值(让我们说L1，这意味着我们想要将我们的系统音量设置为0%)。</p><p id="8f9d" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">当你张开食指和拇指时，将会有另一个长度值(让我们说L2，这意味着我们要将系统音量设置为100%)。</p><p id="ca1f" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">尝试在此时运行您的代码并打印出长度。记下手指感觉舒适的L1和L2的长度值。对我来说，L1 50岁，L2 250岁。如果你还记得第二点，我们已经注意到了体积的最小值和最大值，让我们称它们为V1和V2。</p><p id="2c2b" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">所以现在我们有L1=50，L2=250，V1=-65.25，V2=0</p><p id="8f2d" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">因此，下一行代码将我们的长度(L1，L2)转换成与我们的音量(V1，V2)成比例</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="639d" class="ln jo hi lj b fi lo lp l lq lr">volumeValue = np.interp(length, [50, 250], [-65.25, 0.0])</span></pre><p id="6a26" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">一旦您获得正确的音量值，您只需使用它来设置您的系统音量:</p><pre class="kr ks kt ku fd li lj lk ll aw lm bi"><span id="7542" class="ln jo hi lj b fi lo lp l lq lr">volume.SetMasterVolumeLevel(volumeValue, None)</span></pre><p id="e340" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">剩下的部分只是显示食指和拇指的指尖，为了更好的可视化，在这两点之间画一条线</p><p id="fe79" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">这差不多就是代码。当你运行这个程序时，你会注意到系统的容量在变化，而且变化非常平稳，没有任何滞后。代码可能看起来又长又复杂，但是一旦你把它整合到一个python文件中，这几乎不是几行代码。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es mh"><img src="../Images/52bf15763c3eeb43057cbd0021896730.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*hozWruOu_cz5kvi203hWSA.png"/></div><figcaption class="lc ld et er es le lf bd b be z dx translated">食指和拇指控制系统音量</figcaption></figure></div><div class="ab cl jg jh gp ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="hb hc hd he hf"><h1 id="2b98" class="jn jo hi bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">最后的话</h1><p id="0d4b" class="pw-post-body-paragraph ig ih hi ii b ij kl il im in km ip iq ir kn it iu iv ko ix iy iz kp jb jc jd hb bi translated">看看做一些有创意的事情是多么简单。这篇文章的目的是向你介绍这个超级棒的图书馆。休息一切都取决于你的意志和创造力。你可以在这里  找到这个项目  <a class="ae je" href="https://github.com/pdhruv93/computer-vision/tree/main/volume-controller" rel="noopener ugc nofollow" target="_blank"> <strong class="ii hj"> <em class="jf">的<strong class="ii hj"> <em class="jf">代码。抱歉Github不整洁，我通常会马上开始写代码，然后懒得整理东西。</em></strong></em></strong></a></p><p id="8ba0" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">再次感谢穆尔塔扎·哈桑，我是从他那里知道这个图书馆的。可以去他的<a class="ae je" href="https://www.murtazahassan.com/" rel="noopener ugc nofollow" target="_blank">网站</a>查一些很酷的项目。这篇文章的灵感也来自于他的项目和视频。</p><p id="2456" class="pw-post-body-paragraph ig ih hi ii b ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd hb bi translated">由于这篇文章比我预期的要长，我将使用相同的库为第二个项目写一篇单独的文章:<a class="ae je" href="https://dhruv-pandey93.medium.com/mediapipe-fingers-counting-in-python-w-o-gpu-f9494439090c" rel="noopener"> <strong class="ii hj"> <em class="jf">手指计数</em> </strong> </a> <strong class="ii hj"> <em class="jf">。</em> </strong>不忘检查文章。</p></div></div>    
</body>
</html>