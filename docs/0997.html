<html>
<head>
<title>Image Processing with Python: Applications in Machine Learning Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python处理图像:机器学习中的应用第二部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-processing-with-python-applications-in-machine-learning-part-2-c13ac25f7f6f?source=collection_archive---------14-----------------------#2021-02-09">https://medium.com/analytics-vidhya/image-processing-with-python-applications-in-machine-learning-part-2-c13ac25f7f6f?source=collection_archive---------14-----------------------#2021-02-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="2482" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">如何使用图像处理技术为机器学习算法准备数据？</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/ecae3a6ebdb23caeb447947cc2c6499e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Kym_jNECp9XOWfqq"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">照片由<a class="ae jm" href="https://unsplash.com/@marius?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Marius Masalar </a>在<a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="12ea" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在这篇文章中，我们将逐步学习如何预处理和准备图像数据集，以提取可用于机器学习算法的可量化特征。将使用诸如二值化、模板匹配、形态学操作和斑点检测之类的技术。这是对我在<a class="ae jm" href="https://jephraim-manansala.medium.com/image-processing-with-python-applications-in-machine-learning-17d7aac6bc97" rel="noopener">上一篇文章</a>中使用的图像处理技术的补充。</p><p id="5f64" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们开始吧。</p><p id="936a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">像往常一样，我们导入诸如<code class="du kj kk kl km b">numpy</code>、<code class="du kj kk kl km b">pandas</code>和<code class="du kj kk kl km b">matplotlib</code>之类的库。此外，我们从<code class="du kj kk kl km b">skimage</code>、<code class="du kj kk kl km b">sklearn</code>和<code class="du kj kk kl km b">imblearn</code>库中导入特定的函数。</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="9edb" class="kr ks hh km b fi kt ku l kv kw">import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>from matplotlib.patches import Rectangle<br/>from skimage.io import imread, imshow<br/>from skimage.feature import match_template, peak_local_max<br/>from skimage.measure import label, regionprops<br/>from skimage.morphology import erosion, dilation<br/>from skimage.feature import blob_dog, blob_log, blob_doh<br/>from skimage.util import invert<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.ensemble import RandomForestClassifier<br/>from imblearn.over_sampling import RandomOverSampler</span></pre><p id="5375" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们的目标是在乐谱上正确标注音高和音符。我们将不得不从每个音符中提取可量化的信息，作为我们机器学习算法的输入。让我们一步一步地解决这个问题吧！</p><h1 id="e37f" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤1:执行探索性数据分析(EDA) </strong></h1><p id="9114" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">我们应该永远记住，EDA是任何数据科学项目的重要组成部分。在开发机器学习管道之前，我们需要熟悉数据——这包括其结构、格式和细微差别。这对于确保将要概念化的项目方法适用于手头的数据集至关重要。</p><p id="79db" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">对于这个项目，我们将使用童谣“玛丽有一只小羊羔”的乐谱<em class="lt">(musescore.com的原始图像)</em></p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="96f7" class="kr ks hh km b fi kt ku l kv kw">music = imread('music-sheet.png')<br/>imshow(music);</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lu"><img src="../Images/cb950c1bcc0b346c0173d6915bd4f34b.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*ULl6VADYqxzRPsF5BQ5Cvg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><em class="lv">(musescore.com原创图片)</em></figcaption></figure><p id="4f67" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">请注意，我们只得到一张乐谱的一幅图像。该图像是单通道灰度图像，这意味着我们只需要将图像二值化。另外，请注意，每个音符上都有一个特定的符号和位置。这意味着要开发的机器学习流水线应该对音乐符号和所述符号的位置进行分类。最后，注意乐谱上的每一行都有一个G谱号。我们可以用它作为每条线的参考点。</p><h1 id="c2f2" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤2:应用图像二值化</strong></h1><p id="2bd5" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">根据EDA的发现，我们可以通过执行图像阈值处理来提取图像中的必要信息。为此，我们将把中点以上的所有值设置为255，同时把中点以下的所有值设置为0。</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="410d" class="kr ks hh km b fi kt ku l kv kw">music[music&lt;120]=0<br/>music[music&gt;=120]=255</span></pre><h1 id="fed5" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤3:使用模板匹配的图像分割</strong></h1><p id="c640" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">为了帮助简化图像分析，我们应该将图像分割成每一段音乐，并移除不必要的对象。从EDA中，我们已经观察到在每条音乐线上有一个G谱号。我们可以使用这个对象作为每个音乐行的参考点，并使用模板匹配<em class="lt">(对象检测)</em>技术。如果你不熟悉这个技巧，请查看我在<a class="ae jm" href="https://jephraim-manansala.medium.com/image-processing-with-python-object-detection-using-template-matching-fa82b8c94fbd" rel="noopener">之前的帖子</a>！</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="dd15" class="kr ks hh km b fi kt ku l kv kw">template = music[285:405, 70:140]<br/>imshow(template);</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lw"><img src="../Images/69577380ac56d5737eb6830161bf4caa.png" data-original-src="https://miro.medium.com/v2/resize:fit:284/format:webp/1*xRUtf8heW-vGFTaiIF4_bw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><em class="lv">(musescore.com原创图片)</em></figcaption></figure><p id="9c01" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，让我们尝试将这个模板图像定位到输入图像！</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="d36b" class="kr ks hh km b fi kt ku l kv kw">result = match_template(music, template)<br/>imshow(result, cmap='viridis');</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lx"><img src="../Images/131c593aee04494e45fc477ae41a3d87.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*tsSp3tnzaury5VpkJgR8mQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><em class="lv">(musescore.com原创图片)</em></figcaption></figure><p id="7e3a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">注意到生成的互相关图像上的黄色斑点了吗？这表示图像模板匹配输入图像的区域。我们可以看到，该技术成功地确定了G谱号在输入图像中的位置。从这里，我们可以使用匹配模板的坐标分割图像，并添加一系列值来封装整个五线谱线。</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="38c5" class="kr ks hh km b fi kt ku l kv kw">imshow(music)<br/>template_height, template_width  = template.shape<br/>music_lines = []</span><span id="e3de" class="kr ks hh km b fi ly ku l kv kw">for y, x in peak_local_max(result, threshold_abs=0.8):<br/>    rect = plt.Rectangle((x+55, y), <br/>                         template_width+600, <br/>                         template_height, <br/>                         color='r', <br/>                         fc='none')<br/>    plt.gca().add_patch(rect);<br/>    <br/>    music_lines.append(music[y:y+template_height, <br/>                             x+55:x+template_width+600+55])</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lz"><img src="../Images/e3c8ffb23ae94f8d337c80643690da2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KH1XVgEMVS4la5t_RIfCQg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><em class="lv">(musescore.com原创图片)</em></figcaption></figure><p id="d2de" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">注意到我们没有在图像片段上封装G谱号了吗？这是因为我们不再需要这个符号来确定每个音符的音符和音高。通过检测G谱号，它已经达到了自动封装乐谱每一行的目的。</p><h1 id="01e2" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤4:应用形态学运算</strong></h1><p id="4d32" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">下一步是从产生的分段音乐线中移除五线谱线，以专注于音符及其位置。我们可以通过对图像应用形态学操作来做到这一点。请注意，我们将使用一个垂直结构元素来移除图像上的水平线。</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="dfc0" class="kr ks hh km b fi kt ku l kv kw">element = np.array([[0,1],<br/>                    [0,1],<br/>                    [0,1],<br/>                    [0,1]])<br/>imshow(element);</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ma"><img src="../Images/5f86560c16e37ca031286d9f4c495147.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/1*LTZJtRJeXvlr_pqdRjQG0Q.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><em class="lv">(musescore.com原创图片)</em></figcaption></figure><p id="c3b1" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">使用垂直结构元素，我们现在可以对图像应用膨胀和腐蚀操作。</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="2faa" class="kr ks hh km b fi kt ku l kv kw">def remove_lines(image_used):<br/>    dilated_image = dilation(image_used, element)<br/>    eroded_image = erosion(dilated_image, element)<br/>    <br/>    plt.figure(figsize=(15,3))<br/>    plt.imshow(eroded_image, cmap='gray');<br/>    plt.axis('off')<br/>    return eroded_image</span><span id="7242" class="kr ks hh km b fi ly ku l kv kw">line1 = remove_lines(music_lines[0])<br/>line2 = remove_lines(music_lines[1])<br/>line3 = remove_lines(music_lines[2])</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mb"><img src="../Images/7644c5e3cc4c1f18c0c828ba39c7f250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v0yUxVrPW_NziDoOHAh0_Q.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><em class="lv">(musescore.com原创图片)</em></figcaption></figure><p id="b1cd" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">注意背景是白色的，物体是黑色的？这表示背景具有最大值<em class="lt"> (255) </em>，而对象具有最小值<em class="lt"> (0) </em>。因为这种倒置，我们将需要倒置形态学操作的功能。我们将不得不在腐蚀<em class="lt">(恢复剩余物品的原始形状)</em>之前应用扩张<em class="lt">(移除五线谱线)</em>，而不是先应用腐蚀。</p><h1 id="7b36" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤5:执行斑点检测</strong></h1><p id="5ee2" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">现在，五线谱线已经移除，我们现在可以应用斑点检测来识别音符的位置。如果你还不熟悉这项技术，请检查这个<a class="ae jm" href="https://jephraim-manansala.medium.com/image-processing-with-python-detecting-blobs-in-digital-images-edebfd22328c" rel="noopener">链接</a>！</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="1f03" class="kr ks hh km b fi kt ku l kv kw">def blob_detection(eroded_image):<br/>    blobs = blob_dog(invert(eroded_image), <br/>                     min_sigma=15, max_sigma = 20, threshold=0.70)</span><span id="6f37" class="kr ks hh km b fi ly ku l kv kw">fig, ax = plt.subplots( figsize=(15,3))<br/>    ax.imshow(eroded_image, cmap='gray')<br/>    ax.axis('off')<br/>    for blob in blobs:<br/>        y, x, area = blob<br/>        ax.add_patch(plt.Circle((x, y), area*np.sqrt(2), color='r', <br/>                                fill=False))</span><span id="d43f" class="kr ks hh km b fi ly ku l kv kw">    blobs = [(xaxis, yaxis) for yaxis, xaxis, z in blobs]<br/>    blobs = sorted(blobs, key=lambda x: x[0])<br/>    return blobs<br/>blobs1 = blob_detection(line1)<br/>blobs2 = blob_detection(line2)<br/>blobs3 = blob_detection(line3)</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mc"><img src="../Images/4ca01d4690cf3b0e8a05f485f49bf20d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z26o3Jr6UOErg_Nm6pxbzw.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><em class="lv">(musescore.com原创图片)</em></figcaption></figure><p id="033a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">对于这一步，我选择了使用高斯差分而不是连通分量进行斑点检测，因为我试图识别的对象没有完全连通<em class="lt">(特别是2拍音符)</em>。此外，斑点检测算法将足以在该步骤中识别斑点，因为我们仅需要每个音符的质心的坐标来适当地单独分割音乐符号。</p><h1 id="da7b" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤6:音高评估器</strong></h1><p id="c1a5" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">现在，我们可以根据斑点检测中收集的坐标，从图像片段边界上的相对位置来确定每个音符的音高。我们通过在每个音符的质心范围上创建if-else语句来实现这一点。偏差范围<code class="du kj kk kl km b">dev</code>也被创建，以便当音符没有正确地在五线谱线上居中时，算法具有灵活性。</p><p id="375e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lt">提示:当定义每个音符的值的范围时，使用</em> <code class="du kj kk kl km b"><em class="lt">matplotlib</em></code> <em class="lt">中的</em> <code class="du kj kk kl km b"><em class="lt">axhline</em></code> <em class="lt">功能在图像上创建一条水平线会更容易估计。</em></p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="0c85" class="kr ks hh km b fi kt ku l kv kw">def define_pitch(number, dev=4):<br/>    if int(number) in range(11-dev, 11+dev):<br/>        return "A"<br/>    elif int(number) in range(19-dev, 19+dev): <br/>        return "G"<br/>    elif int(number) in range(28-dev, 28+dev): <br/>        return "F"<br/>    elif int(number) in range(36-dev, 36+dev): <br/>        return "E"<br/>    elif int(number) in range(45-dev, 45+dev): <br/>        return "D"<br/>    elif int(number) in range(53-dev, 53+dev): <br/>        return "C"<br/>    elif int(number) in range(61-dev, 61+dev): <br/>        return "B"<br/>    elif int(number) in range(69-dev, 69+dev): <br/>        return "A"<br/>    elif int(number) in range(78-dev, 78+dev): <br/>        return "G"<br/>    elif int(number) in range(86-dev, 86+dev): <br/>        return "F"<br/>    elif int(number) in range(95-dev, 95+dev): <br/>        return "E"<br/>    elif int(number) in range(104-dev, 104+dev): <br/>        return "D"<br/>    elif int(number) in range(113-dev, 113+dev): <br/>        return "C"</span></pre><p id="fef3" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">测试创建的函数，我们得到了以下结果。</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="ce20" class="kr ks hh km b fi kt ku l kv kw">imshow(music_lines[1])<br/>plt.axhline(69);<br/>print([define_pitch(x[1]) for x in blobs2])</span><span id="eb3e" class="kr ks hh km b fi ly ku l kv kw">&gt;&gt; ['A', 'B', 'D', 'D', 'B', 'A', 'G', 'A']</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es md"><img src="../Images/0bea03e268c53d343c661a757cca9e71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*ygFhkzE3HCi85lpS7T015g.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><em class="lv">(musescore.com原创图片)</em></figcaption></figure><p id="a8cb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">请注意，这个函数之所以有效，是因为我们在算法中固定了图像分割的长度和宽度。在<code class="du kj kk kl km b">define_pitch</code>功能中设置的像素坐标值对其他图像分割设置不起作用。</p><h1 id="ac41" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤7:使用连接组件检索对象属性</strong></h1><p id="ffac" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">既然我们已经确定了图像上每个音乐符号的质心，现在我们可以单独分割这些符号。然后我们可以应用<code class="du kj kk kl km b">regionprops</code>函数来提取每个符号的关键特征和属性。我们将提取符号的以下属性:</p><ol class=""><li id="442c" class="me mf hh jp b jq jr jt ju jw mg ka mh ke mi ki mj mk ml mm bi translated"><code class="du kj kk kl km b">area</code> —区域的像素数。</li><li id="5276" class="me mf hh jp b jq mn jt mo jw mp ka mq ke mr ki mj mk ml mm bi translated"><code class="du kj kk kl km b">convex_area</code> —凸包图像的像素数，它是包围该区域的最小凸多边形。</li><li id="0fb1" class="me mf hh jp b jq mn jt mo jw mp ka mq ke mr ki mj mk ml mm bi translated"><code class="du kj kk kl km b">major_axis_length</code>-椭圆长轴的长度与区域具有相同的归一化第二中心矩。</li><li id="2789" class="me mf hh jp b jq mn jt mo jw mp ka mq ke mr ki mj mk ml mm bi translated"><code class="du kj kk kl km b">minor_axis_length</code>-椭圆短轴的长度与该区域具有相同的归一化第二中心矩。</li><li id="1ca9" class="me mf hh jp b jq mn jt mo jw mp ka mq ke mr ki mj mk ml mm bi translated"><code class="du kj kk kl km b">perimeter</code> —对象的周长，使用4-连接将轮廓近似为通过边界像素中心的线。</li></ol><p id="2451" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">以下功能会自动执行这些步骤:</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="daf6" class="kr ks hh km b fi kt ku l kv kw">def properties(regions):<br/>    area= np.sum([x.area for x in regions])<br/>    convex_area = np.sum([x.convex_area for x in regions]) <br/>    perimeter = np.sum([x.perimeter for x in regions]) <br/>    major_axis= np.mean([x.major_axis_length for x in regions]) <br/>    minor_axis = np.mean([x.minor_axis_length for x in regions]) <br/>    return {'area': area, <br/>            'convex_area': convex_area,<br/>            'perimeter': perimeter,<br/>            'major_axis': major_axis,<br/>            'minor_axis': minor_axis}</span><span id="1d2d" class="kr ks hh km b fi ly ku l kv kw">def blob_properties(eroded_image, blobs):<br/>    fig, ax = plt.subplots(1, len(blobs), figsize=(15,2.5))</span><span id="0191" class="kr ks hh km b fi ly ku l kv kw">props = {}<br/>    for num, data in enumerate(blobs):<br/>        columns=int(data[0])<br/>        rows=int(data[1])<br/>        new_image = eroded_image[:, columns-15:columns+20]<br/>        <br/>        label_im = label(invert(new_image))<br/>        regions = regionprops(label_im)<br/>        <br/>        props[num] = properties(regions)<br/>        <br/>        ax[num].imshow(new_image, cmap='gray')<br/>    return pd.DataFrame(props).T</span><span id="b0b1" class="kr ks hh km b fi ly ku l kv kw">props1 = blob_properties(line1, blobs1);<br/>props2 = blob_properties(line2, blobs2);<br/>props3 = blob_properties(line3, blobs3);</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ms"><img src="../Images/a4fea116f670d9052ef27e30520d720b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_fGWg-MWiRLJ9628o2t8dQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><em class="lv">(musescore.com原创图片)</em></figcaption></figure><p id="ed85" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">既然我们已经收集了每个音乐符号的属性，我们需要手动将每个符号标记到其适当的类别<strong class="jp hi"><em class="lt"/></strong>。注意，我们不需要标注所有的符号。我们只需要足够的数据，这样算法就可以知道哪个是哪个。</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="17f2" class="kr ks hh km b fi kt ku l kv kw">one_beat = pd.concat([props1.iloc[[1,2,3,4,5,6,8,9]], <br/>                      props2.iloc[[1,2,4,5,6,7]], <br/>                      props3.iloc[[0,1,3,4,5,6]]], axis=0)<br/>one_beat['class'] = '1'<br/>two_beat = pd.concat([props1.iloc[[7]], <br/>                      props2.iloc[[0,3]], <br/>                      props3.iloc[[2,7]]], axis=0)<br/>two_beat['class'] = '2'<br/>timesig = props1.iloc[[0]*2]<br/>timesig['class'] = 'timesig'<br/>end = props3.iloc[[8]*2]<br/>end['class'] = 'end'</span><span id="35fa" class="kr ks hh km b fi ly ku l kv kw">df = pd.concat([one_beat, two_beat, timesig, end])<br/>df.sample(10)</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mt"><img src="../Images/880e01b2943c7e7d57e5d99e2e37df94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*2ASa6V1LT_ZZyC4Qq-rx6A.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">(图片由作者提供)</figcaption></figure><p id="2c19" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">注意，我们增加了<code class="du kj kk kl km b">timesig</code>和<code class="du kj kk kl km b">end</code>对象中的项目数量。我们这样做是为了表示训练集和测试集中的所有对象<em class="lt">(在后面的步骤中)</em>。</p><h1 id="c5e1" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤8:应用特征工程</strong></h1><p id="274b" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">从提取的特征中，我们可以通过导出新的特征来进一步扩展特征。我们通过将提取的特征的比率放在一起来做到这一点。让我们试试这个！</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="222c" class="kr ks hh km b fi kt ku l kv kw">def feature_engineering(df):<br/>    df['ratio_length'] = df['minor_axis'] / df['major_axis']<br/>    df['perimeter_ratio_major'] = df['perimeter'] / df['major_axis']<br/>    df['perimeter_ratio_minor'] = df['perimeter'] / df['minor_axis']<br/>    df['area_ratio_convex'] = df['area'] / df['convex_area']<br/>    df['area_ratio_major'] = df['area'] / df['major_axis']<br/>    df['area_ratio_minor'] = df['area'] / df['minor_axis']<br/>    df['area_ratio_peri'] = df['area'] / df['perimeter']<br/>    df['convex_ratio_major'] = df['convex_area'] / df['major_axis']<br/>    df['convex_ratio_minor'] = df['convex_area'] / df['minor_axis']<br/>    df['convex_ratio_peri'] = df['convex_area'] / df['perimeter']<br/>    return df<br/>final_df = feature_engineering(df)<br/>final_df['class'] = df['class']</span></pre><p id="063a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">通过这样做，我们能够将我们的数据框架扩展到15个特性！</p><h1 id="aefd" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤9:拆分训练和测试集</strong></h1><p id="15fa" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">下一步是从图像数据上提取和导出的特征的数据帧中分割数据。这对于确保机器学习模型将具有一组“看不见的”数据以确保训练不会过拟合或欠拟合是至关重要的。我们使用<code class="du kj kk kl km b">sklearn.model_selection</code>库中的<code class="du kj kk kl km b">train_test_split</code>函数来完成这个任务。</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="8bef" class="kr ks hh km b fi kt ku l kv kw">X = final_df.drop('class', axis=1)<br/>y = final_df['class']</span><span id="fc4f" class="kr ks hh km b fi ly ku l kv kw">X_train, X_test, y_train, y_test = train_test_split(X, y, <br/>                                                    test_size=0.3, <br/>                                                    stratify = y)</span></pre><h1 id="9b41" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤10:数据不平衡处理</strong></h1><p id="82f6" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">分割数据集后，我们可以注意到每个类中对象实例的数量并不相等。这可能是一个问题，因为这可能导致在机器学习算法上偏向多数类。为了解决这个问题，我们使用RandomOverSampler来应用数据不平衡处理，以确保每个类中的实例数量是相等的。<em class="lt">注意，其他数据不平衡处理技术也可用于此(如RandomUnderSampler、SMOTE或AdaSyn)。</em></p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="74e6" class="kr ks hh km b fi kt ku l kv kw">oversample = RandomOverSampler()<br/>X_train, y_train = oversample.fit_resample(X_train, y_train)</span></pre><h1 id="0b17" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">步骤11:训练随机森林分类器模型</strong></h1><p id="c71a" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">使用训练数据集，我们现在可以训练机器学习分类器模型。我们将使用随机森林分类器，因为众所周知，尽管它的算法很简单，但它可以产生很高的准确性。请注意，由于随机森林模型是基于树的模型，我们不需要缩放数据集。但是，如果您将使用其他机器学习模型，则必须缩放数据集的要素。</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="e6b1" class="kr ks hh km b fi kt ku l kv kw">RF = RandomForestClassifier(max_depth=5, n_estimators=500)<br/>RF.fit(X_train, y_train)<br/>y_pred_RF= RF.predict(X_test)</span><span id="df03" class="kr ks hh km b fi ly ku l kv kw">df = pd.DataFrame()</span><span id="4a3e" class="kr ks hh km b fi ly ku l kv kw">cols = ['Machine Learning Classification Method',<br/>        'Train Accuracy', <br/>        'Test Accuracy', <br/>        "Top 1 Feature Predictor",<br/>        "Top 2 Feature Predictor",<br/>        "Top 3 Feature Predictor"]</span><span id="5255" class="kr ks hh km b fi ly ku l kv kw">df.loc['Machine Learning Classification Method', <br/>       'Details'] = 'Random Forest Classifier'<br/>df.loc['Train Accuracy', 'Details'] = RF.score(X_train, y_train) <br/>df.loc['Test Accuracy', 'Details'] = RF.score(X_test, y_test)</span><span id="9c45" class="kr ks hh km b fi ly ku l kv kw">importance = X.columns[np.argsort(RF.feature_importances_)][-3:]<br/>df.loc['Top 1 Feature Predictor', 'Details'] = importance[2]<br/>df.loc['Top 2 Feature Predictor', 'Details'] = importance[1]<br/>df.loc['Top 3 Feature Predictor', 'Details'] = importance[0]</span><span id="844d" class="kr ks hh km b fi ly ku l kv kw">display(df)</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mu"><img src="../Images/a638c756d37162bbaaa054206236dd4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*KqJ-hdUK96wzjE1ifzY1kw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">(图片由作者提供)</figcaption></figure><p id="02d1" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">随机森林分类器产生了100%的测试准确度。对不同叶子进行分类的主要特征是它们的<code class="du kj kk kl km b">perimeter_ratio_minor</code>、<code class="du kj kk kl km b">convex_area</code>和<code class="du kj kk kl km b">convex_ratio_minor</code>。我们可以看到，由于音乐符号的不同形状，凸面积、周长和短轴是主要特征。例如，<code class="du kj kk kl km b">1-beat note</code>的凸面_area更大，因为它覆盖的面积更大，而<code class="du kj kk kl km b">2-beat note</code>的周长更大，因为它有很多区域。</p><p id="7f06" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">太棒了，对吧？同样，这是一个既准确又可解释的模型！现在，剩下唯一要做的就是显示预测的音符分类和音高。</p><pre class="ix iy iz ja fd kn km ko kp aw kq bi"><span id="0acd" class="kr ks hh km b fi kt ku l kv kw">def blob_labeling(eroded_image, blobs):<br/>    fig, ax = plt.subplots(1, len(blobs), figsize=(15,2))</span><span id="9acb" class="kr ks hh km b fi ly ku l kv kw">    for num, data in enumerate(blobs):<br/>        columns=int(data[0])<br/>        rows=int(data[1])<br/>        new_image = eroded_image[:, columns-15:columns+20]<br/>        <br/>        label_im = label(invert(new_image))<br/>        regions = regionprops(label_im)<br/>        <br/>        dataset = pd.DataFrame([properties(regions)])<br/>        final_df = feature_engineering(dataset)<br/>        <br/>        note = RF.predict(final_df)<br/>        if (note[0] == '1') | (note[0] == '2'):<br/>            pitch = define_pitch(rows)<br/>        else:<br/>            pitch = ''<br/>        title = str(pitch + " " + str(note[0]))</span><span id="c452" class="kr ks hh km b fi ly ku l kv kw">        ax[num].imshow(new_image, cmap='gray')<br/>        ax[num].axis('off')<br/>        ax[num].set_title(title)</span><span id="b081" class="kr ks hh km b fi ly ku l kv kw">props1 = blob_labeling(line1, blobs1);<br/>props2 = blob_labeling(line2, blobs2);<br/>props3 = blob_labeling(line3, blobs3);</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mv"><img src="../Images/440e0d614809d131e1f54440ab74f539.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sNKwB1lIiAwrpkZJQmJ1bw.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><em class="lv">(musescore.com原创图片)</em></figcaption></figure><h1 id="32c1" class="kx ks hh bd ky kz la lb lc ld le lf lg in lh io li iq lj ir lk it ll iu lm ln bi translated"><strong class="ak">总之</strong></h1><p id="3efd" class="pw-post-body-paragraph jn jo hh jp b jq lo ii js jt lp il jv jw lq jy jz ka lr kc kd ke ls kg kh ki ha bi translated">我们已经探索了如何使用图像处理技术来准备和预处理图像数据集，以实现机器学习算法。使用<code class="du kj kk kl km b">regionprops</code>函数，我们从图像中提取了有价值的、可量化的特征。此外，我们已经表明，预处理技术，如二值化，模板匹配，形态学操作，和斑点检测可以用来实现我们的目标。</p><p id="57bd" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">从这个例子中，我希望你能体会到每种技术如何被用来操纵图像使之对我们有利，以及它如何能使我们创建机器学习管道的过程自动化！</p><p id="90c7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lt">想了解更多信息？在此</em> <a class="ae jm" href="https://github.com/jephraim-manansala/iip-machine-learning-2" rel="noopener ugc nofollow" target="_blank"> <em class="lt">链接</em> </a> <em class="lt">查看我的GitHub库！</em></p></div></div>    
</body>
</html>