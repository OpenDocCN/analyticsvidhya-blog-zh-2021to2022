<html>
<head>
<title>An overview on MnasNet: Platform-Aware Neural Architecture Search for Mobile</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MnasNet综述:面向移动设备的平台感知神经架构搜索</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/an-overview-on-mnasnet-platform-aware-neural-architecture-search-for-mobile-8a681d17a80c?source=collection_archive---------17-----------------------#2021-05-27">https://medium.com/analytics-vidhya/an-overview-on-mnasnet-platform-aware-neural-architecture-search-for-mobile-8a681d17a80c?source=collection_archive---------17-----------------------#2021-05-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="f951" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">神经结构搜索(NAS)</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/4ae059d8c04c001011f1cda482a8eea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*TzHQwxzcX3aN1b7aHlBfCQ.png"/></div></figure><p id="540a" class="pw-post-body-paragraph jk jl hh jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">神经架构搜索是使用学习算法和深度学习自动寻找有效神经网络架构的任务。基于强化学习的方法通常用于这项任务。NAS设计的网络在许多指标上都优于手工制作的神经架构。</p><h1 id="c79e" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">关键概念</h1><ul class=""><li id="88ed" class="ki kj hh jm b jn kk jr kl jv km jz kn kd ko kh kp kq kr ks bi translated">本文没有使用间接的延迟测量方法(例如FLOPS ),而是使用移动设备上的真实延迟作为优化目标。建议的NAS结合了现实世界的延迟和验证准确性。</li><li id="f943" class="ki kj hh jm b jn kt jr ku jv kv jz kw kd kx kh kp kq kr ks bi translated">提出一个<em class="ky">分解的层次搜索空间</em>，允许每层之间的多样性。</li></ul><h1 id="2f2e" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">目标函数</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kz"><img src="../Images/972b24d429766dea5ec252e08a004003.png" data-original-src="https://miro.medium.com/v2/resize:fit:410/format:webp/1*SqIDQcNxgWrvQjzRmQAHxA.png"/></div></figure><p id="c63a" class="pw-post-body-paragraph jk jl hh jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">先前的工作试图优化单个度量(准确性),其中T是固定的目标等待时间。一个共同的目标是在延迟的约束下最大化<em class="ky"> ACC(m) </em>。</p><p id="2fde" class="pw-post-body-paragraph jk jl hh jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">非正式地，帕累托最优模型是指模型在不增加延迟的情况下具有最高的准确性，或者在不降低准确性的情况下具有最低的延迟。上面的目标函数不能找到多个帕累托最优模型，因为它没有适当地调节准确性和等待时间。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es la"><img src="../Images/026ce2ea7a388c6b5b13e8b6330a48d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*9jAnu8aB9SuZj_ty0RBqHg.png"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lb"><img src="../Images/cfe5f1700c0acdf89790802c7069ca2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*r2KYI4RNTJy6_L-ZR_K2IQ.png"/></div></figure><p id="3eaa" class="pw-post-body-paragraph jk jl hh jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">本文建议优化上述目标，以优化延迟和准确性，同时限制过大的延迟。这两个目标基于超参数α和β进行缩放。基于延迟加倍通常会增加5%的准确度的现象，如果没有明确说明，则使用α=β=-0.07。</p><h1 id="bec0" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">分解的层次搜索空间</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lc"><img src="../Images/e3daef6c32ab44d2addb196ce3ae091f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*52ntJFxPHc6MM7DIaikQLQ.png"/></div></div></figure><p id="1a1b" class="pw-post-body-paragraph jk jl hh jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">大多数以前的NAS方法搜索空间以构建复杂的单元，并以相同的配置重复该单元以构建整个网络。然而，这些方法不允许分层多样性。为此，MNasNet定义了多个块，并为每个块搜索不同的超参数。如上图所示，有7个模块，每个模块将被分配不同的体系结构。</p><p id="a307" class="pw-post-body-paragraph jk jl hh jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">每个块发现以下内容:</p><ul class=""><li id="fbbb" class="ki kj hh jm b jn jo jr js jv lh jz li kd lj kh kp kq kr ks bi translated">Conv op:常规Conv/深度方向conv/移动反向瓶颈conv</li><li id="54e2" class="ki kj hh jm b jn kt jr ku jv kv jz kw kd kx kh kp kq kr ks bi translated">内核大小:3x3/5x5</li><li id="d7ee" class="ki kj hh jm b jn kt jr ku jv kv jz kw kd kx kh kp kq kr ks bi translated">挤压与激励比(SERatio): 0/ 0.25</li><li id="627d" class="ki kj hh jm b jn kt jr ku jv kv jz kw kd kx kh kp kq kr ks bi translated">输出过滤器大小:{0.75，1.0，1.25} * MobileNetV2过滤器大小</li><li id="facb" class="ki kj hh jm b jn kt jr ku jv kv jz kw kd kx kh kp kq kr ks bi translated">层数:{-1，0，+1 }+MobileNetV2 #层</li></ul><p id="29d5" class="pw-post-body-paragraph jk jl hh jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">使用这种分块设计代替逐层搜索，搜索大小从10 ⁹减少到10。</p><h1 id="7ce7" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">搜索算法</h1><p id="41a8" class="pw-post-body-paragraph jk jl hh jm b jn kk jp jq jr kl jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ha bi translated">使用强化学习方法来寻找优化所提出的目标函数的模型架构。在每一步，控制器首先通过基于其RNN网络预测一系列表征来对一批模型进行采样。每个模型m在ImageNet数据集上训练5个时期以获得准确度ACC(m ),并在真实电话上执行以获得延迟LAT(m)。在该步骤结束时，按照上述公式计算R(m ),并使用{近似策略优化(PPO )}更新RNN的参数。</p><h1 id="8f1c" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">实验</h1><p id="1ce1" class="pw-post-body-paragraph jk jl hh jm b jn kk jp jq jr kl jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ha bi translated">我们在ImageNet和COCO对象检测数据集上展示了所提出的MnasNet的结果。如下图所示，提议的网络MnasNet-A1优于之前的SOTA MobileNetV2。</p><h2 id="fdc5" class="ln if hh bd ig lo lp lq ik lr ls lt io jv lu lv is jz lw lx iw kd ly lz ja ma bi translated">ImageNet</h2><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es mb"><img src="../Images/666efca850e7210bddf3b9cae7e0562e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zp_V1uRKD0UalI-u5JQ-BA.png"/></div></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es mc"><img src="../Images/d19ce2e4403d6e431c547ed7de58b167.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X3VG6AS0TFU4sU9z1WIZ3Q.png"/></div></div></figure><h2 id="4088" class="ln if hh bd ig lo lp lq ik lr ls lt io jv lu lv is jz lw lx iw kd ly lz ja ma bi translated">COCO对象检测</h2><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es md"><img src="../Images/d5065774660dbaf7039be229303f0e5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7zgxo-AiD0qCMCZyqvbp9A.png"/></div></div></figure><h2 id="d897" class="ln if hh bd ig lo lp lq ik lr ls lt io jv lu lv is jz lw lx iw kd ly lz ja ma bi translated">消融研究</h2><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es me"><img src="../Images/63116fc741f4d08528e438ca4946e72e.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*KE0TZccQi_TCmouoxMStKA.png"/></div></figure><h2 id="4bac" class="ln if hh bd ig lo lp lq ik lr ls lt io jv lu lv is jz lw lx iw kd ly lz ja ma bi translated">提议的模型架构</h2><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mf"><img src="../Images/a936821be948856977ec19aaa28e8b8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*psf6gzez3_FHmWQ0gqK42A.png"/></div></figure><h1 id="36b1" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">摘要</h1><p id="a031" class="pw-post-body-paragraph jk jl hh jm b jn kk jp jq jr kl jt ju jv lk jx jy jz ll kb kc kd lm kf kg kh ha bi translated">提出的新的目标函数优化了准确性和等待时间。纸张流水线允许分层多样性，因此与以前的方法相比实现了更好的性能。使用这种方法找到的模型架构:MnasNet优于MobileNetV2，在ImageNet分类和COCO对象检测中表现出优越的性能。</p></div></div>    
</body>
</html>