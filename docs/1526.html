<html>
<head>
<title>Pearson’s Correlation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">皮尔逊相关</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/pearsons-correlation-b6ea5cb0eb24?source=collection_archive---------9-----------------------#2021-03-06">https://medium.com/analytics-vidhya/pearsons-correlation-b6ea5cb0eb24?source=collection_archive---------9-----------------------#2021-03-06</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><ul class=""><li id="d55d" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated"><strong class="ig hi">皮尔逊相关</strong>是特征选择方法。</li><li id="a05e" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir is it iu iv bi translated">它显示了因变量和自变量之间的方向和强度。</li><li id="72c2" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir is it iu iv bi translated">当从属和独立之间存在线性关系时，这种方法最合适。</li><li id="1b3c" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir is it iu iv bi translated">其值范围从<strong class="ig hi"> -1到1 </strong>。</li></ul><ol class=""><li id="ba25" class="ie if hh ig b ih ii ij ik il im in io ip iq ir jb it iu iv bi translated">-1表示受抚养人和独立人之间有很强的关系。</li><li id="a908" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir jb it iu iv bi translated">0表示从属和独立之间没有任何关系。</li><li id="692c" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir jb it iu iv bi translated">1表示依赖者和独立者之间有很强的+ve关系。</li><li id="c54a" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir jb it iu iv bi translated">当相关值越来越接近0时，这种关系就越来越弱。</li></ol><h1 id="cddb" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated"><strong class="ak">皮尔逊关联背后的数学</strong></h1><ul class=""><li id="9a4c" class="ie if hh ig b ih ka ij kb il kc in kd ip ke ir is it iu iv bi translated">皮尔逊相关是<strong class="ig hi"> x </strong>和<strong class="ig hi"> y </strong>之间的协方差与<strong class="ig hi"> x </strong>和<strong class="ig hi">y</strong>的标准偏差的乘积之比</li><li id="a771" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir is it iu iv bi translated">首先我们要明白什么是<strong class="ig hi">方差</strong>、<strong class="ig hi">标准差、</strong>和<strong class="ig hi">协方差</strong>。</li><li id="d055" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir is it iu iv bi translated">下面是皮尔逊相关的公式。</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es kf"><img src="../Images/4a6fc25bc3cec0b7478781e102b38d0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*nGzgrPTxO-r5wgSGyJ0ktQ.png"/></div></figure><h1 id="89b1" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">1)差异:</h1><ul class=""><li id="33ab" class="ie if hh ig b ih ka ij kb il kc in kd ip ke ir is it iu iv bi translated"><strong class="ig hi">方差</strong>衡量数据与其均值的差异。</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es kn"><img src="../Images/aa3e25cdad8bafafbcc4bd91a26e33c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*Iq91ftrW8OpWEet-0M1S3w.png"/></div></div></figure><h1 id="f47d" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">2)标准偏差:</h1><ul class=""><li id="8dbc" class="ie if hh ig b ih ka ij kb il kc in kd ip ke ir is it iu iv bi translated"><strong class="ig hi">标准差</strong>是方差的平方根。</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ks"><img src="../Images/7a3479fb92a80501cbb8f5b39d5955da.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*DznJEZUug6bMzk0FLwKelw.png"/></div></figure><h1 id="3574" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">3)协方差:</h1><ul class=""><li id="8964" class="ie if hh ig b ih ka ij kb il kc in kd ip ke ir is it iu iv bi translated"><strong class="ig hi">协方差</strong>衡量变量之间的线性关系。</li></ul><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es kt"><img src="../Images/f5ba55e51380068e26120313d2917337.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*qBCS4Katvv9qxCT9s3USdQ.png"/></div></figure><ul class=""><li id="320b" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">让我们开始实施皮尔逊相关。</li></ul><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="74d5" class="kz jd hh kv b fi la lb l lc ld"><strong class="kv hi"># importing libraries</strong></span><span id="0e09" class="kz jd hh kv b fi le lb l lc ld"><strong class="kv hi">import</strong> <strong class="kv hi">numpy</strong> <strong class="kv hi">as</strong> <strong class="kv hi">np</strong><br/><strong class="kv hi">import</strong> <strong class="kv hi">pandas</strong> <strong class="kv hi">as</strong> <strong class="kv hi">pd</strong><br/><strong class="kv hi">import</strong> <strong class="kv hi">matplotlib.pyplot</strong> <strong class="kv hi">as</strong> <strong class="kv hi">plt</strong><br/><strong class="kv hi">import</strong> <strong class="kv hi">seaborn</strong> <strong class="kv hi">as</strong> <strong class="kv hi">sns</strong><br/>%matplotlib inline</span></pre><ul class=""><li id="f3af" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">以下是确定因变量和自变量之间关系的三种方法。</li></ul><h2 id="84c9" class="kz jd hh bd je lf lg lh ji li lj lk jm il ll lm jq in ln lo ju ip lp lq jy lr bi translated">1)如果X在增加，y也在增加:</h2><ul class=""><li id="ecef" class="ie if hh ig b ih ka ij kb il kc in kd ip ke ir is it iu iv bi translated">我们可以说，因变量和自变量之间存在<strong class="ig hi">强+ve关系</strong>。</li></ul><h2 id="125f" class="kz jd hh bd je lf lg lh ji li lj lk jm il ll lm jq in ln lo ju ip lp lq jy lr bi translated">2)如果X增加而y不变:</h2><ul class=""><li id="e275" class="ie if hh ig b ih ka ij kb il kc in kd ip ke ir is it iu iv bi translated">我们可以说，因变量和自变量之间根本没有关系。</li></ul><h2 id="c58f" class="kz jd hh bd je lf lg lh ji li lj lk jm il ll lm jq in ln lo ju ip lp lq jy lr bi translated">3)如果X在减少，y在增加:</h2><ul class=""><li id="dcf1" class="ie if hh ig b ih ka ij kb il kc in kd ip ke ir is it iu iv bi translated">我们可以说，因变量和自变量之间存在着强相关关系。</li></ul><h1 id="6745" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">数据创建</h1><ol class=""><li id="7c74" class="ie if hh ig b ih ka ij kb il kc in kd ip ke ir jb it iu iv bi translated">我们正在创建一些原始数据来理解这两者之间的关系。</li><li id="1cd6" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir jb it iu iv bi translated">为了更好地理解，我们还将绘制线性图。</li></ol><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="7cb1" class="kz jd hh kv b fi la lb l lc ld"># X is increasing and y is also increasing <br/>X1 = [1,2,3,4,5]<br/>y1 = [1,2,3,4,5]</span><span id="b513" class="kz jd hh kv b fi le lb l lc ld"># if X is increasing and y is constant<br/>X2 = [1,2,3,4,5]<br/>y2 = [1,1,1,1,1]</span><span id="6345" class="kz jd hh kv b fi le lb l lc ld"># if X is decreasing and y is increasing<br/>X3 = [5,4,3,2,1]<br/>y3 = [1,2,3,4,5]</span></pre><p id="8383" class="pw-post-body-paragraph ls lt hh ig b ih ii lu lv ij ik lw lx il ly lz ma in mb mc md ip me mf mg ir ha bi translated">现在，想象一下上面的数据</p><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="9a2f" class="kz jd hh kv b fi la lb l lc ld"># plot for X is increasing and y is also increasing<br/>plt.figure(figsize=(15,5))<br/>plt.subplot(1,3,1)<br/>plt.plot(X1, y1)<br/>plt.title('Fig: 1.1 <strong class="kv hi">\n</strong>increasing X, y increasing ')<br/>plt.xlabel('+ ve correlation')<br/>plt.ylabel('increasing value of y')</span><span id="612a" class="kz jd hh kv b fi le lb l lc ld"># plot for if X is increasing and y is constant<br/>plt.subplot(1,3,2)<br/>plt.plot(X2, y2)<br/>plt.title('Fig: 1.2 <strong class="kv hi">\n</strong>increasing X, y constant ')<br/>plt.xlabel('no correlation')<br/>plt.ylabel('constant value of y')</span><span id="58cb" class="kz jd hh kv b fi le lb l lc ld"># plot for if X is decreasing and y is increasing<br/>plt.subplot(1,3,3)<br/>plt.plot(X3, y3)<br/>plt.title('Fig: 1.3, <strong class="kv hi">\n</strong>decreasing X, y increasing ')<br/>plt.xlabel('-ve correlation')<br/>plt.ylabel('increasing value of y')<br/><br/>plt.show()</span></pre><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mh"><img src="../Images/e3a71202bd25c59dd94bb585f9623d2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8bpz5uK7x8eCqBM7YSpsSg.png"/></div></div></figure><ul class=""><li id="116e" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">在图1.1中，我们可以观察到，如果X的值增加，y的值也增加，这意味着这两者之间有很强的+ve相关性。</li><li id="3bbd" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir is it iu iv bi translated">在图1.2中，我们可以观察到，如果X的值是增加的，y的值是不变的，这意味着根本没有相关性。</li><li id="f594" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir is it iu iv bi translated">在图1.3中，我们可以观察到，如果X的值减少，y的值增加，这意味着这两者之间有很强的相关性。</li></ul><p id="84af" class="pw-post-body-paragraph ls lt hh ig b ih ii lu lv ij ik lw lx il ly lz ma in mb mc md ip me mf mg ir ha bi translated">现在，是时候应用皮尔逊相关性了。</p><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="e876" class="kz jd hh kv b fi la lb l lc ld"><em class="mi"># import dataset</em><br/><em class="mi"># here we are using housing dataset.</em></span><span id="cb8f" class="kz jd hh kv b fi le lb l lc ld">train_data = pd.read_csv('/content/drive/MyDrive/My Datasets/House Price/train.csv')</span><span id="b328" class="kz jd hh kv b fi le lb l lc ld">train_data.shape</span><span id="3290" class="kz jd hh kv b fi le lb l lc ld">output:</span><span id="c377" class="kz jd hh kv b fi le lb l lc ld">(1460, 81)</span></pre><ul class=""><li id="28ef" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">这里，我们没有进行任何类型的特性工程，所以我们只选择整数列，删除具有null值的行，以应用Pearson相关性。</li></ul><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="fbca" class="kz jd hh kv b fi la lb l lc ld"><em class="mi"># getting only integer columns.</em><br/><br/>train_data.drop(train_data.select_dtypes(include='object').columns, inplace=<strong class="kv hi">True</strong>, axis=1)</span><span id="919d" class="kz jd hh kv b fi le lb l lc ld"><em class="mi"># dropping columns which have missing value percentage greater than 60</em><br/><br/>train_data.drop(train_data.columns[train_data.isnull().mean()&gt;0.60], inplace=<strong class="kv hi">True</strong>, axis=1)<br/>train_data.shape</span><span id="6d8c" class="kz jd hh kv b fi le lb l lc ld">output:</span><span id="1920" class="kz jd hh kv b fi le lb l lc ld">(1460, 38)</span></pre><ul class=""><li id="2c7a" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">此热图显示数据集中有多少空值。</li></ul><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="a95c" class="kz jd hh kv b fi la lb l lc ld">plt.figure(figsize=(20, 7))<br/>sns.heatmap(train_data.isnull(), yticklabels=<strong class="kv hi">False</strong>, cbar=<strong class="kv hi">False</strong>)<br/>plt.show()</span></pre><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mj"><img src="../Images/1e16676af1095480cb4539d9e862a440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tX_Y4of8z8ndOryNoip-VQ.png"/></div></div><figcaption class="mk ml et er es mm mn bd b be z dx translated">具有空值的热图</figcaption></figure><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="bc7e" class="kz jd hh kv b fi la lb l lc ld"><em class="mi"># dropping rows which have missing values.</em></span><span id="7920" class="kz jd hh kv b fi le lb l lc ld">train_data.dropna(inplace=<strong class="kv hi">True</strong>, axis=0)</span><span id="5fcb" class="kz jd hh kv b fi le lb l lc ld">train_data.shape</span><span id="144d" class="kz jd hh kv b fi le lb l lc ld">output:</span><span id="6a63" class="kz jd hh kv b fi le lb l lc ld">(1121, 38)</span><span id="71ba" class="kz jd hh kv b fi le lb l lc ld">plt.figure(figsize=(20, 7))<br/>sns.heatmap(train_data.isnull(), yticklabels=<strong class="kv hi">False</strong>, cbar=<strong class="kv hi">False</strong>)<br/>plt.show()</span></pre><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mo"><img src="../Images/62eaf2444cd93dc5cf7614e88ad4c066.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y3LFYcPZODXk_ZqU0pG4lA.png"/></div></div><figcaption class="mk ml et er es mm mn bd b be z dx translated">没有空值的热图</figcaption></figure><ul class=""><li id="feef" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">到目前为止，我们已经清理了数据集。是时候使用皮尔逊相关性了。</li></ul><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="14ea" class="kz jd hh kv b fi la lb l lc ld"><strong class="kv hi">from</strong> <strong class="kv hi">sklearn.feature_selection</strong> <strong class="kv hi">import</strong> f_regression, SelectKBest<br/><br/><em class="mi"># f_regression method used for pearson's correlation.</em><br/><em class="mi"># SelectKBest method used to select top k best features.</em></span></pre><ul class=""><li id="e8f4" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">将因变量赋给变量X和。</li><li id="9aeb" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir is it iu iv bi translated">将自变量赋给变量y。</li></ul><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="1f43" class="kz jd hh kv b fi la lb l lc ld">X = train_data.drop(['SalePrice'], axis=1)<br/>y = train_data['SalePrice']</span></pre><ul class=""><li id="5e83" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">这里我们用k值为10的得分函数<strong class="ig hi"> f_regression </strong>创建一个<strong class="ig hi"> SelectKBest </strong>类的对象。</li></ul><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="e370" class="kz jd hh kv b fi la lb l lc ld">skb = SelectKBest(score_func=f_regression, k=10)</span></pre><ul class=""><li id="abf6" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">现在，用变量X和y来拟合我们的模型。</li></ul><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="c6f2" class="kz jd hh kv b fi la lb l lc ld"><em class="mi"># fit meathod used to fit model on dataset using our score function.</em><br/><br/>skb.fit(X, y)</span></pre><ul class=""><li id="4079" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">上面的代码返回下面的输出。</li></ul><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="97ab" class="kz jd hh kv b fi la lb l lc ld">SelectKBest(k=10, score_func=&lt;function f_regression at 0x7fded4e704d0&gt;)</span></pre><ul class=""><li id="ddbb" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated"><strong class="ig hi"> get_support() </strong>方法返回真值和假值的布尔列表。我们可以使用这个列表从数据集中获取我们的列。如果为True，则考虑该列，否则不考虑要返回的列。</li></ul><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="9b11" class="kz jd hh kv b fi la lb l lc ld"><em class="mi"># get_support() returns the boolean list of columns .</em><br/><br/>col = skb.get_support()<br/>col</span><span id="2f22" class="kz jd hh kv b fi le lb l lc ld">output:</span><span id="f25c" class="kz jd hh kv b fi le lb l lc ld">array([False, False, False, False,  True, False,  True,  True, False,<br/>       False, False, False,  True,  True, False, False,  True, False,<br/>       False,  True, False, False, False,  True, False, False,  True,<br/>        True, False, False, False, False, False, False, False, False,<br/>       False])</span></pre><ul class=""><li id="13ab" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">get _ support(indexes = True)返回表示特定列的编号(位置)的整数列表。</li></ul><pre class="kg kh ki kj fd ku kv kw kx aw ky bi"><span id="fd82" class="kz jd hh kv b fi la lb l lc ld"><em class="mi"># get_support(indices=True) returns the list of k columns indices which have high pearson's correlations.</em><br/><br/>col = skb.get_support(indices=<strong class="kv hi">True</strong>)<br/>col</span><span id="6638" class="kz jd hh kv b fi le lb l lc ld">output:<br/>array([ 4,  6,  7, 12, 13, 16, 19, 23, 26, 27])</span><span id="0eb4" class="kz jd hh kv b fi le lb l lc ld"><em class="mi"># scores_ returns correlation values of every feature.</em><br/>skb.scores_</span><span id="b595" class="kz jd hh kv b fi le lb l lc ld">output:</span><span id="95b6" class="kz jd hh kv b fi le lb l lc ld">array([2.49023403e+00, 8.73950826e+00, 1.50458329e+02, 1.10639690e+02,<br/>       1.96036658e+03, 1.75866077e+01, 4.26662160e+02, 4.17465247e+02,<br/>       3.51021787e+02, 2.01096191e+02, 8.79325850e-01, 5.32479989e+01,<br/>       6.82869769e+02, 6.56137887e+02, 1.16337572e+02, 2.45763523e-03,<br/>       1.10672093e+03, 6.64373624e+01, 1.49381397e+00, 5.29173583e+02,<br/>       8.69809362e+01, 3.20295557e+01, 2.25333340e+01, 4.77935018e+02,<br/>       3.03445055e+02, 3.82561158e+02, 8.05838393e+02, 6.96288859e+02,<br/>       1.43226582e+02, 1.49551920e+02, 2.74886917e+01, 1.06092031e+00,<br/>       1.38136215e+01, 9.65457023e+00, 1.45543888e+00, 2.98365208e+00,<br/>       1.57654584e-01])</span><span id="1ccc" class="kz jd hh kv b fi le lb l lc ld"><em class="mi"># this is our final dataset after using pearson's correlation</em></span><span id="6fd1" class="kz jd hh kv b fi le lb l lc ld">X.iloc[:, col]</span></pre><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="er es mp"><img src="../Images/67463ad9735848b6b1f448585bba524c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Du3uaupoNljWMEDrGPMLKw.png"/></div></div></figure><ul class=""><li id="7381" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">这是我关于皮尔森相关性的完整笔记本。 <a class="ae mq" href="https://colab.research.google.com/drive/1YLNN54xU9FpU3rLcxvDagnFeBDhCKhSJ?usp=sharing" rel="noopener ugc nofollow" target="_blank">点击这里</a></li></ul><p id="eb6b" class="pw-post-body-paragraph ls lt hh ig b ih ii lu lv ij ik lw lx il ly lz ma in mb mc md ip me mf mg ir ha bi translated"><strong class="ig hi">概要:</strong></p><ul class=""><li id="7710" class="ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv bi translated">我们已经学习了如何使用Pearson的相关性，以及如何使用Sklearn库来实现。</li><li id="255b" class="ie if hh ig b ih iw ij ix il iy in iz ip ja ir is it iu iv bi translated">我们还看到了如何使用SelectKBest方法从数据集中选择K要素。</li></ul></div></div>    
</body>
</html>