<html>
<head>
<title>Huggingface transformers in Azure Machine learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Azure机器学习中的拥抱脸变形金刚</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/huggingface-transformers-in-azure-machine-learning-8fa2664181d?source=collection_archive---------1-----------------------#2021-11-13">https://medium.com/analytics-vidhya/huggingface-transformers-in-azure-machine-learning-8fa2664181d?source=collection_archive---------1-----------------------#2021-11-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/564b79184829ebc50d30bb42928c7987.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*0Su_AjqyN53rD10f"/></div></div></figure><h1 id="021b" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">如何使用拥抱脸模型</h1><h1 id="f4b2" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">先决条件</h1><ul class=""><li id="ceed" class="jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke bi translated">Azure帐户</li><li id="c651" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">Azure存储</li><li id="beb1" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">Azure机器学习服务</li><li id="06de" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">Github帐户和存储库</li><li id="4ba1" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">Azure服务主帐户</li><li id="722f" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">向服务主要贡献者提供对机器学习资源的访问</li><li id="8e61" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">Azure Keyvault存储秘密</li><li id="0e62" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">用服务主体机密更新密钥库</li><li id="4ac9" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">这将自动化训练代码并注册模型</li></ul><h1 id="7649" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">步伐</h1><ul class=""><li id="4faf" class="jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke bi translated">登录ml.azure.com</li><li id="1897" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">启动您计算实例</li><li id="8173" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">去笔记本开始写代码</li><li id="c236" class="jn jo hh jp b jq kf js kg ju kh jw ki jy kj ka kb kc kd ke bi translated">请注意，如果需要，请升级您的aml sdk</li></ul><h1 id="def9" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">装置</h1><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="440a" class="kt iq hh kp b fi ku kv l kw kx">pip install transformers</span><span id="b8af" class="kt iq hh kp b fi ky kv l kw kx">pip install transformers[torch]</span></pre><h1 id="61d0" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">密码</h1><ul class=""><li id="a76a" class="jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke bi translated">测试情感模型</li></ul><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="bffb" class="kt iq hh kp b fi ku kv l kw kx">from transformers import pipeline; <br/>print(pipeline('sentiment-analysis')('we love you'))</span></pre><ul class=""><li id="d013" class="jn jo hh jp b jq kz js la ju lb jw lc jy ld ka kb kc kd ke bi translated">让我们试试伯特模型</li></ul><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="42ba" class="kt iq hh kp b fi ku kv l kw kx">from transformers import BertTokenizer, FlaxBertForQuestionAnswering</span><span id="eb5e" class="kt iq hh kp b fi ky kv l kw kx">tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')<br/>model = FlaxBertForQuestionAnswering.from_pretrained('bert-base-uncased')</span><span id="20a6" class="kt iq hh kp b fi ky kv l kw kx">question, text = "Who was Jim Henson?", "Jim Henson was a nice puppet"<br/>inputs = tokenizer(question, text, return_tensors='jax')</span><span id="0577" class="kt iq hh kp b fi ky kv l kw kx">outputs = model(**inputs)<br/>start_scores = outputs.start_logits<br/>end_scores = outputs.end_logits</span></pre><ul class=""><li id="c6e6" class="jn jo hh jp b jq kz js la ju lb jw lc jy ld ka kb kc kd ke bi translated">现在运行GPT2模型</li></ul><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="7ab3" class="kt iq hh kp b fi ku kv l kw kx">from transformers import GPTNeoForCausalLM, GPT2Tokenizer<br/>model = GPTNeoForCausalLM.from_pretrained("EleutherAI/gpt-neo-1.3B")<br/>tokenizer = GPT2Tokenizer.from_pretrained("EleutherAI/gpt-neo-1.3B")</span><span id="73b0" class="kt iq hh kp b fi ky kv l kw kx">prompt = "In a shocking finding, scientists discovered a herd of unicorns living in a remote, " \<br/>         "previously unexplored valley, in the Andes Mountains. Even more surprising to the " \<br/>         "researchers was the fact that the unicorns spoke perfect English."</span><span id="7f90" class="kt iq hh kp b fi ky kv l kw kx">input_ids = tokenizer(prompt, return_tensors="pt").input_ids</span><span id="a378" class="kt iq hh kp b fi ky kv l kw kx">gen_tokens = model.generate(input_ids, do_sample=True, temperature=0.9, max_length=100,)<br/>gen_text = tokenizer.batch_decode(gen_tokens)[0]</span></pre><ul class=""><li id="6718" class="jn jo hh jp b jq kz js la ju lb jw lc jy ld ka kb kc kd ke bi translated">另一个GPT2</li></ul><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="95c8" class="kt iq hh kp b fi ku kv l kw kx">import tensorflow as tf<br/>from transformers import GPT2Tokenizer, TFGPT2DoubleHeadsModel</span><span id="987f" class="kt iq hh kp b fi ky kv l kw kx">tokenizer = GPT2Tokenizer.from_pretrained('gpt2')<br/>model = TFGPT2DoubleHeadsModel.from_pretrained('gpt2')</span><span id="1c38" class="kt iq hh kp b fi ky kv l kw kx"># Add a [CLS] to the vocabulary (we should train it also!)<br/>num_added_tokens = tokenizer.add_special_tokens({'cls_token': '[CLS]'})</span><span id="d63d" class="kt iq hh kp b fi ky kv l kw kx">embedding_layer = model.resize_token_embeddings(len(tokenizer))  # Update the model embeddings with the new vocabulary size</span><span id="ac66" class="kt iq hh kp b fi ky kv l kw kx">choices = ["Hello, my dog is cute [CLS]", "Hello, my cat is cute [CLS]"]<br/>encoded_choices = [tokenizer.encode(s) for s in choices]<br/>cls_token_location = [tokens.index(tokenizer.cls_token_id) for tokens in encoded_choices]</span><span id="8ae6" class="kt iq hh kp b fi ky kv l kw kx">input_ids = tf.constant(encoded_choices)[None, :]  # Batch size: 1, number of choices: 2<br/>mc_token_ids = tf.constant([cls_token_location])  # Batch size: 1</span><span id="62ce" class="kt iq hh kp b fi ky kv l kw kx">outputs = model(input_ids, mc_token_ids=mc_token_ids)<br/>lm_prediction_scores, mc_prediction_scores = outputs[:2]</span></pre><ul class=""><li id="d13d" class="jn jo hh jp b jq kz js la ju lb jw lc jy ld ka kb kc kd ke bi translated">Prophnet样本</li></ul><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="f7ad" class="kt iq hh kp b fi ku kv l kw kx">from transformers import ProphetNetTokenizer, ProphetNetEncoder<br/>import torch</span><span id="7069" class="kt iq hh kp b fi ky kv l kw kx">tokenizer = ProphetNetTokenizer.from_pretrained('microsoft/prophetnet-large-uncased')<br/>model = ProphetNetEncoder.from_pretrained('patrickvonplaten/prophetnet-large-uncased-standalone')<br/>inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")<br/>outputs = model(**inputs)</span><span id="b582" class="kt iq hh kp b fi ky kv l kw kx">last_hidden_states = outputs.last_hidden_state</span></pre><ul class=""><li id="f9a1" class="jn jo hh jp b jq kz js la ju lb jw lc jy ld ka kb kc kd ke bi translated">开启AI GPT 2</li></ul><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="1644" class="kt iq hh kp b fi ku kv l kw kx">from transformers import GPT2Tokenizer<br/>tokenizer = GPT2Tokenizer.from_pretrained("gpt2")<br/>tokenizer("Hello world")['input_ids']<br/>tokenizer(" Hello world")['input_ids']</span></pre><ul class=""><li id="dc52" class="jn jo hh jp b jq kz js la ju lb jw lc jy ld ka kb kc kd ke bi translated">飞马xsum</li></ul><pre class="kk kl km kn fd ko kp kq kr aw ks bi"><span id="fb5f" class="kt iq hh kp b fi ku kv l kw kx">from transformers import PegasusForConditionalGeneration, PegasusTokenizer<br/>import torch<br/>src_text = [<br/>    """ PG&amp;E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow."""<br/>]</span><span id="ecfc" class="kt iq hh kp b fi ky kv l kw kx">model_name = 'google/pegasus-xsum'<br/>device = 'cuda' if torch.cuda.is_available() else 'cpu'<br/>tokenizer = PegasusTokenizer.from_pretrained(model_name)<br/>model = PegasusForConditionalGeneration.from_pretrained(model_name).to(device)<br/>batch = tokenizer(src_text, truncation=True, padding='longest', return_tensors="pt").to(device)<br/>translated = model.generate(**batch)<br/>tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)<br/>assert tgt_text[0] == "California's largest electricity provider has turned off power to hundreds of thousands of customers."</span></pre><ul class=""><li id="2a28" class="jn jo hh jp b jq kz js la ju lb jw lc jy ld ka kb kc kd ke bi translated">以后还会有更多</li></ul></div><div class="ab cl le lf go lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ha hb hc hd he"><p id="2c5c" class="pw-post-body-paragraph ll lm hh jp b jq kz ln lo js la lp lq ju lr ls lt jw lu lv lw jy lx ly lz ka ha bi translated"><em class="ma">最初发表于</em><a class="ae mb" href="https://github.com/balakreshnan/Samples2021/blob/main/AzureML/hugginface1.md" rel="noopener ugc nofollow" target="_blank"><em class="ma">【https://github.com】</em></a><em class="ma">。</em></p></div></div>    
</body>
</html>