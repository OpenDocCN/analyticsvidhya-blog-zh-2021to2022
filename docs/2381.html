<html>
<head>
<title>Diving Deeper into AdaBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深入到AdaBoost</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/diving-deeper-into-adaboost-92a9642e484f?source=collection_archive---------22-----------------------#2021-04-20">https://medium.com/analytics-vidhya/diving-deeper-into-adaboost-92a9642e484f?source=collection_archive---------22-----------------------#2021-04-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/c9554a3a04c8e0e9bc37732aa76ab2c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*32eFIT4tuU6jkCHijx8Srg.jpeg"/></div></div></figure><p id="6906" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">作为一名机器学习工程师，AdaBoost是你武库中的一个地狱般的算法。它基于boosting集成技术，广泛应用于机器学习领域。在我们深入本文之前，您应该对<a class="ae jn" rel="noopener" href="/analytics-vidhya/decision-tree-101-e94a5d131fa0">决策树</a>和<a class="ae jn" href="https://srivastava-arpan2411.medium.com/" rel="noopener">随机森林</a>算法有一个基本的概念。</p><p id="0cfe" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">让我们开始吧</strong></p><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jo"><img src="../Images/ff730d4c77801032ac47cd6047aeb1b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FulbGFAkf_LckWr9W1DRlA.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">阿达布斯特姆</figcaption></figure><ul class=""><li id="09a5" class="jx jy hh ir b is it iw ix ja jz je ka ji kb jm kc kd ke kf bi translated">AdaBoost背后的基本概念是多个弱学习者可以一起工作，并给出更好的性能。</li><li id="34e3" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">在random forest中，树的深度没有预先定义，但是在AdaBoost中，我们使用了只有两个叶节点的树桩。</li><li id="c13f" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">这些树桩在技术上被称为“<strong class="ir hi">弱学习者</strong>”。</li><li id="446a" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">许多弱学习器的集合构成了AdaBoost算法。</li></ul><p id="edbb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">与随机森林的比较</strong></p><ul class=""><li id="2786" class="jx jy hh ir b is it iw ix ja jz je ka ji kb jm kc kd ke kf bi translated">在随机森林中，创建的所有树都是相互独立的，而在AdaBoost中，一个树桩中的错误分类示例决定了另一个树桩的输入数据。</li><li id="dba7" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">在随机森林中，树的深度不是预定义的，而在AdaBoost中，深度被限制为每个树桩只有两个叶节点。</li><li id="2e9d" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">在random forest中，每棵树在分类中都有平等的发言权，而在AdaBoost中，一些树桩在分类中可能有更高的发言权。</li></ul><p id="a74c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">让我们深入算法</strong></p><figure class="jp jq jr js fd ii er es paragraph-image"><div class="er es kl"><img src="../Images/c4dc3973519ea17be4bc9bd001648e73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*t0xWUFtH7BUnj3fPskXC_g.jpeg"/></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">虹膜数据集</figcaption></figure><ul class=""><li id="7912" class="jx jy hh ir b is it iw ix ja jz je ka ji kb jm kc kd ke kf bi translated">让我们以虹膜数据集为例。该数据集包含4个特征，即萼片长度、萼片宽度、花瓣长度和花瓣宽度，然后我们有4个目标类(物种)。</li><li id="db49" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">我们指定样品重量(样品重量。)并且最初，该权重被设置为1/n(n =示例的数量)。</li><li id="2182" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">现在，我们使用每一列创建一个树桩，然后使用基尼指数为每个特征选择最佳的一个。</li><li id="6b27" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">现在我们需要决定这个树桩在分类中有多少发言权。发言权的大小取决于树桩对例子的分类程度。</li><li id="f404" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">我们计算残肢的总误差，该误差由错误分类样本总数的样本权重之和给出。假设我们的数据集包含100个例子，而我们的stump错误分类了其中的10个。在这种情况下，残肢的总误差将是(1/100) * 10。(1/100)是每个示例的初始样品重量。</li><li id="df9e" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">现在我们计算树桩的say量，它由下面的公式给出:</li></ul><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es km"><img src="../Images/b8d6c89644c6c85740f794f14852d097.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rdrmgjGdYgIQVVJf69SJAw.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">树桩的发言权</figcaption></figure><ul class=""><li id="d783" class="jx jy hh ir b is it iw ix ja jz je ka ji kb jm kc kd ke kf bi translated">让我们看一下V/S总误差量之间的图表，以便更好地了解情况</li></ul><figure class="jp jq jr js fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kn"><img src="../Images/78c1857755eac08072f99e475d9aed3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3h9e9PA18xs-3g36UfvQ9w.png"/></div></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">图片来源:youtube上的Statquest频道</figcaption></figure><ul class=""><li id="6eb1" class="jx jy hh ir b is it iw ix ja jz je ka ji kb jm kc kd ke kf bi translated">从上图我们可以看出，如果stump的总误差较低，它将具有较高的发言权，反之亦然。</li><li id="61e3" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">现在我们强调对被初始残肢错误分类的样本进行分类。我们通过更新样本Wt来做到这一点。每一个例子。</li><li id="f392" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">对于正确分类的示例，权重更新为:</li></ul><figure class="jp jq jr js fd ii er es paragraph-image"><div class="er es ko"><img src="../Images/997656642bf81c7fc04242cb40d0ebe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/1*vwRtuqqQk8K9DU4Rk5QFRg.gif"/></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">更新样品重量。对于正确分类的示例</figcaption></figure><ul class=""><li id="0494" class="jx jy hh ir b is it iw ix ja jz je ka ji kb jm kc kd ke kf bi translated">对于分类错误的样品，其样品重量使用以下公式进行更新:</li></ul><figure class="jp jq jr js fd ii er es paragraph-image"><div class="er es kp"><img src="../Images/ec0311867fdcebc1b4b375fcc13c7a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/1*atMGxJAFGg4jAy2_IM5OHg.gif"/></div><figcaption class="jt ju et er es jv jw bd b be z dx translated">更新样品重量。对于错误分类的例子</figcaption></figure><ul class=""><li id="63f7" class="jx jy hh ir b is it iw ix ja jz je ka ji kb jm kc kd ke kf bi translated">现在我们可以看到，正确分类的例子的更新权重低于错误分类的例子的更新权重。</li><li id="a074" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">在此之后，我们对更新后的样本权重进行归一化，使得它们的总和等于1。</li><li id="9448" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">现在我们使用旧的数据集创建一个新的数据集，这样它就包含了更多被stump 1错误分类的例子。这可以使用更新的样本权重来完成，因为错误分类的样本将具有更高的权重。</li><li id="f306" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">由于我们有了一个新的数据集，我们重复上述过程，直到我们得到多个树桩。</li></ul><p id="818c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">【Adaboost如何进行预测？</p><ul class=""><li id="9457" class="jx jy hh ir b is it iw ix ja jz je ka ji kb jm kc kd ke kf bi translated">你带来了一个例子，你把这个例子传递给我们创造的所有树桩。</li><li id="a94b" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">现在，在6个树桩中，假设3个属于A类，3个属于b类。哦，不，这是一个平局。别担心，我们不会像在随机森林中那样遵循聚合。</li><li id="a0d5" class="jx jy hh ir b is kg iw kh ja ki je kj ji kk jm kc kd ke kf bi translated">记得我们计算了每个树桩的发言权。是的，那现在会进入画面。我们将预测A的树桩的发言权数量和预测b的树桩的发言权数量的总和相加。然后，无论哪个总和更高，都将是赢家，这些树桩将对我们的示例进行分类。</li></ul><p id="3d9a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">希望您对AdaBoost有了基本的了解。</p><p id="f288" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">直到那时快乐学习！！</strong></p></div></div>    
</body>
</html>