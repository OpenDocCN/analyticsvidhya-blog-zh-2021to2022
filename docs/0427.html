<html>
<head>
<title>Everything you need to know about K-Means Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于K-均值聚类你需要知道的一切</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/everything-you-need-to-know-about-k-means-clustering-88ad4058cce0?source=collection_archive---------8-----------------------#2021-01-16">https://medium.com/analytics-vidhya/everything-you-need-to-know-about-k-means-clustering-88ad4058cce0?source=collection_archive---------8-----------------------#2021-01-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="75aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想知道K-means聚类是怎么一回事，那你就来对地方了！让我们立即开始吧！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/928b4326a7dd769faac14d8f8cce75b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*r6eAIMrlfiNGwy-C.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片来源:谷歌图片</figcaption></figure><h1 id="8b1f" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">介绍</h1><h2 id="8099" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">聚类的类型</h2><p id="0e18" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">聚类是一种无监督学习，其中数据点根据其相似程度被分组到不同的集合中。</p><p id="b79d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">了解更多关于监督/非监督学习的信息</em>——<a class="ae lk" rel="noopener" href="/analytics-vidhya/a-beginners-guide-for-getting-started-with-machine-learning-7ba2cd5796ae"><strong class="ig hi"><em class="jc">机器学习入门指南</em> </strong> </a></p><p id="eb00" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">聚类主要有两类:</em> </strong></p><ul class=""><li id="8449" class="ll lm hh ig b ih ii il im ip ln it lo ix lp jb lq lr ls lt bi translated"><em class="jc">层次聚类</em></li><li id="e1da" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><em class="jc">划分聚类</em></li></ul><h2 id="1d7a" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">分层聚类</h2><p id="b368" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">层次聚类进一步细分为:</em> </strong></p><ul class=""><li id="1706" class="ll lm hh ig b ih ii il im ip ln it lo ix lp jb lq lr ls lt bi translated"><em class="jc">凝聚聚类</em></li><li id="5ef5" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><em class="jc">分裂聚类</em></li></ul><p id="57bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">层次聚类采用树状结构，像这样:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/291acd3de1778b896125df6f3b6dec1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/0*4qpg5d3Kh9ViV5kS.JPG"/></div></figure><p id="8b94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在<strong class="ig hi"> <em class="jc">凝聚式聚类</em> </strong>中，有一种<strong class="ig hi"> <em class="jc">自下而上的方法</em> </strong>。我们从每个元素作为一个独立的集群开始，然后将它们合并成更大的集群，如下所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/169ea834bba7985369af5553f47d084d.png" data-original-src="https://miro.medium.com/v2/resize:fit:310/0*7I9cZWVBZPkSfCMU.JPG"/></div></figure><p id="54a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"><em class="jc"/></strong>是一种<strong class="ig hi"> <em class="jc">自上而下的方法</em> </strong>。我们从整个集合开始，然后将它分成一个个更小的集群，如下所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mb"><img src="../Images/33273aaf2aed54f1fc338b8785580ef3.png" data-original-src="https://miro.medium.com/v2/resize:fit:258/0*E6E0ibMYXBqX2jEX.JPG"/></div></figure><h2 id="11bb" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">划分聚类</h2><p id="c071" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">划分聚类进一步细分为:</em> </strong></p><ul class=""><li id="cd78" class="ll lm hh ig b ih ii il im ip ln it lo ix lp jb lq lr ls lt bi translated"><em class="jc"> K均值聚类</em></li><li id="3a5a" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><em class="jc">模糊C均值聚类</em></li></ul><p id="a164" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">划分聚类分为两个子类型——<em class="jc">K均值聚类</em>和<em class="jc">模糊C均值。</em></p><p id="b65b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在K-means聚类中，对象被分成几个由数字“K”表示的聚类</p><blockquote class="mc md me"><p id="33db" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">因此，如果我们说K = 2，对象被分成两个集群，c1和c2，如下所示:</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mi"><img src="../Images/9311b6170f33139a7c037ef6fc0e29bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:282/0*uZjMmuvN8OsxECN2.JPG"/></div></figure><blockquote class="mc md me"><p id="4f86" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">这里，比较特征或特性，并且将具有相似特性的所有对象聚集在一起。</p></blockquote><p id="398b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">模糊c均值</em>非常类似于k均值，它将具有相似特征的对象聚类在一起。在k-means聚类中，一个对象不能属于两个不同的聚类。但是在c-means中，对象可以<em class="jc">属于多个集群</em>，如图所示。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mj"><img src="../Images/ff2b0375e8459dd2c190b8a2d820aa4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:244/0*Oq-suwkYb_ZL16Db.JPG"/></div></figure><h2 id="0813" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">k均值聚类</h2><p id="11c5" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">K-means类似于<strong class="ig hi"> <em class="jc"> KNN </em> </strong>，因为它着眼于距离来预测类成员。然而，与KNN不同，K-means是一种<strong class="ig hi"> <em class="jc">无监督学习算法</em> </strong> <em class="jc">。它的目标是发现不同的点如何聚集在一起。这个数学模型背后的直觉是，相似的数据点会靠得更近。</em></p><p id="26bc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">K-means随后尝试确定称为<strong class="ig hi"> <em class="jc">质心</em> </strong>的不同k点，这些点位于与同一类的其他点的<em class="jc">(最小累积距离)</em>的中心，但是离另一类的点更远。</p><blockquote class="mc md me"><p id="73a8" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">这种算法很直观，但计算量很大，因此它主要用于对较小的数据集进行探索性分析。</p></blockquote><p id="e317" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">了解更多关于KNN</em>—<a class="ae lk" href="https://tp6145.medium.com/a-beginners-guide-to-knn-and-mnist-handwritten-digits-recognition-using-knn-from-scratch-df6fb982748a" rel="noopener"><strong class="ig hi"><em class="jc">KNN和MNIST手写数字识别入门使用KNN从零开始</em> </strong> </a></p><blockquote class="mc md me"><p id="387d" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">为了更好地理解K-means，让我们举一个板球的例子。假设您收到了来自世界各地的许多板球运动员的数据，这些数据提供了运动员得分以及他们在最近十场比赛中的得分情况。</p></blockquote><p id="b6ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于这些信息，我们需要将数据分为两类，即击球手和投球手。<em class="jc">让我们来看看创建这些集群的步骤:</em></p><h2 id="8289" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">解决办法</h2><p id="8fde" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">分配数据点</em> </strong></p><p id="255c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里，我们将数据集标绘在“x”和“y”坐标上。y轴上的信息是关于得分的跑垒，x轴上的信息是关于运动员的三柱门。</p><p id="04cf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">如果我们绘制数据，它看起来是这样的:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mk"><img src="../Images/75adcfc446ed2695851722b0b9d6b637.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8PNFGFM_Zmlr-H0WcXClYA.png"/></div></div></figure><h2 id="9adc" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">执行聚类</h2><p id="57b8" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><em class="jc">我们需要创建集群，如下所示:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ml"><img src="../Images/6b014f2077f14a348e6b8c3731b27bbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/0*Z7fRsUZxZCQrsmqK.JPG"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mm"><img src="../Images/35466813a53ad09ae72fc4a4a60ef8ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/0*_fEQrT6BBDj1x_Hl.JPG"/></div></figure><p id="cdb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">考虑相同的数据集，让我们使用K均值聚类(取K = 2)来解决这个问题。K均值聚类的第一步是随机分配两个质心(当K=2时)。两个点被指定为质心。</p><blockquote class="mc md me"><p id="deea" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">它们被称为质心，但最初，它们不是给定数据集的中心点。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mn"><img src="../Images/2e43fa1ad24cf8ca435ee8094c74589b.png" data-original-src="https://miro.medium.com/v2/resize:fit:372/0*2K1CWgPXTe6cyX9C.JPG"/></div></figure><p id="2819" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是从随机分配的质心确定每个数据点之间的距离。对于每个点，距离都是从两个质心开始测量的，无论哪个距离更小，该点都被指定给该质心。</p><blockquote class="mc md me"><p id="51dc" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">您可以看到连接到质心的数据点，在这里用蓝色和黄色表示。</p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mo"><img src="../Images/94e4e3223228682b8ccff12d7404c680.png" data-original-src="https://miro.medium.com/v2/resize:fit:360/0*fZvScJwtHfUKLlFn.JPG"/></div></figure><p id="26ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是确定这两个集群的实际质心。原始随机分配的质心将被重新定位到聚类的实际质心。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mp"><img src="../Images/ad30734d86a16b6e3ae034de7f81697d.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/0*TX0DN25907BjgzIU.JPG"/></div></figure><p id="0c0f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个计算距离和重新定位质心的过程一直持续到我们获得最终的聚类。<em class="jc">然后质心重新定位停止。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mp"><img src="../Images/fa1a11994f6c7013ae1300eaaf1bd208.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/0*4XYaiJfujzKSVnxy.JPG"/></div></div></figure><blockquote class="mc md me"><p id="706d" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">如上所述，质心不需要再重新定位，这意味着算法已经收敛，我们有两个具有质心的聚类。</p></blockquote><h2 id="ebc3" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">应用程序</h2><p id="eeea" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><em class="jc"> K-Means聚类在现实生活中的各种例子或商业案例中使用，比如:</em></p><ul class=""><li id="cd8f" class="ll lm hh ig b ih ii il im ip ln it lo ix lp jb lq lr ls lt bi translated"><em class="jc">学习成绩</em></li><li id="bc6e" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><em class="jc">诊断系统</em></li><li id="cfc5" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><em class="jc">搜索引擎</em></li><li id="2c57" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><em class="jc">无线传感器网络</em></li></ul><h2 id="4a6f" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">测量距离</h2><p id="912b" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">距离度量决定了两个元素之间的相似性，并影响聚类的形状。</em>T15】</strong></p><p id="ddea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc"> K-Means聚类支持各种距离度量，例如:</em></p><ul class=""><li id="e747" class="ll lm hh ig b ih ii il im ip ln it lo ix lp jb lq lr ls lt bi translated"><strong class="ig hi"> <em class="jc">欧几里得距离度量</em> </strong></li><li id="77fe" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><strong class="ig hi"> <em class="jc">曼哈顿距离测量</em> </strong></li><li id="9c17" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><strong class="ig hi"> <em class="jc">欧氏距离的平方度量</em> </strong></li><li id="7e2c" class="ll lm hh ig b ih lu il lv ip lw it lx ix ly jb lq lr ls lt bi translated"><strong class="ig hi"> <em class="jc">余弦距离度量</em> </strong></li></ul><h2 id="0dcd" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">欧几里德距离测度</h2><p id="eca2" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">最常见的情况是确定两点之间的距离。如果我们有一个点P和点Q，欧氏距离就是一条普通的直线。<strong class="ig hi"> <em class="jc">它是欧氏空间中两点之间的距离。</em> </strong></p><p id="46d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">两点间距离的公式如下:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/94431ba82eeeb64cdd1278f9703ee7b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/0*-aY6LHQKCG9M36Dk.JPG"/></div></figure><h2 id="d2c9" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">平方欧几里德距离测度</h2><p id="62c8" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">这与欧几里德距离测量相同，但最后不求平方根。<em class="jc">公式如下:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mr"><img src="../Images/63e9a28f6795e7cba28d201443e7d68b.png" data-original-src="https://miro.medium.com/v2/resize:fit:302/0*8wfw6K7h-3_yiF13.JPG"/></div></figure><h2 id="882c" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">曼哈顿距离度量</h2><p id="a976" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">曼哈顿距离是水平和垂直分量的简单总和，或者是沿垂直轴测量的两点之间的距离。</p><p id="a33b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">公式如下:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ms"><img src="../Images/0a9339bad410a99ea1af1d6749e90fb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/0*v6NtKYc0UevoloFP.JPG"/></div></div></figure><h2 id="43b2" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">余弦距离度量</h2><p id="a969" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><em class="jc">在这种情况下，我们取两个向量之间的角度，这两个向量是通过连接原点的点形成的。公式如下所示:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mt"><img src="../Images/cb3ddbbea367d0dfa5cba70b9d0082fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/0*mTNwmA-i1axRVSuj.JPG"/></div></figure><p id="98fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有关<strong class="ig hi"> <em class="jc">距离度量</em> </strong>的更多信息，请参考—<a class="ae lk" href="https://tp6145.medium.com/a-beginners-guide-to-knn-and-mnist-handwritten-digits-recognition-using-knn-from-scratch-df6fb982748a" rel="noopener"><strong class="ig hi"><em class="jc">【KNN和MNIST手写数字识别入门指南】从头开始使用KNN</em></strong></a></p><h2 id="89b9" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">工作</h2><p id="24ed" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><em class="jc">下面的流程图总结了</em> <strong class="ig hi"> <em class="jc"> K均值聚类</em> </strong> <em class="jc">如何工作:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mu"><img src="../Images/855e17cabeead3e692cd06c06b11fa3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/0*xxEtC3OJNjMXwqJZ.JPG"/></div></figure><p id="eb7d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以通过指定<strong class="ig hi"> <em class="jc"> K (=3，4，5)的值来使用<em class="jc">试错法</em>..)</em> </strong>。随着我们的进展，我们不断改变值，直到我们得到最好的集群。</p><p id="eb59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一种方法是用<strong class="ig hi"> <em class="jc">肘法</em> </strong>来确定k的值</p><blockquote class="mc md me"><p id="456c" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">一旦我们得到了K的值，系统将随机分配那么多质心，并测量每个数据点到这些质心的距离。</p></blockquote><p id="3ee9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，它会将这些点分配给距离最小的相应质心。因此，每个数据点将被分配到离它最近的质心。因此，我们有K个初始聚类。</p><p id="7761" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">肘法</em> </strong>是求星团个数的最好方法。肘方法构成了在数据集上运行K-Means聚类。</p><p id="dc66" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们使用平方和作为一种度量，来寻找可以为给定数据集形成的最佳聚类数。<strong class="ig hi"><em class="jc">【WSS】</em></strong>内的平方和被定义为<em class="jc">集群中每个成员与其质心之间距离的平方之和。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mv"><img src="../Images/72142bb28270b98c9fea3d80483bf157.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/0*xbO9q8yc4E3lujlT.JPG"/></div></figure><p id="45f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为K的每个值测量WSS。<em class="jc">WSS量最少的K值被作为</em> <strong class="ig hi"> <em class="jc">最佳值。</em>T19】</strong></p><p id="61ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们在WSS和星团数量之间画一条曲线。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mw"><img src="../Images/f99d17fcfb52da62a8a92dc1420d3ae6.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/0*uroTpBBKbq-aBBuj.JPG"/></div></figure><blockquote class="mc md me"><p id="cb5f" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">这里，y轴是WSS，x轴是星团数量。</p></blockquote><p id="96e8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可以看到随着K值从2开始增加，WSS的值有一个非常<strong class="ig hi"> <em class="jc">的渐变</em> </strong>。</p><p id="23fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以，你可以把肘点值作为k的最优值，它应该是二，三，或者最多四。但是，除此之外，增加群集数量<em class="jc">不会显著改变</em>WSS的值，它会使<strong class="ig hi"> <em class="jc">变得稳定。</em>T29】</strong></p><h1 id="5812" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">k-均值聚类算法</h1><p id="6772" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><em class="jc">假设我们有x1，x2，x3……x(n)作为我们的输入，我们想把它分成K个集群。</em></p><p id="d130" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">形成集群的步骤有:</em> </strong></p><p id="7055" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">第一步:</em> </strong>选择K个随机点作为聚类中心称为<strong class="ig hi"> <em class="jc">质心。</em> </strong></p><p id="6299" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">步骤2: </em> </strong>通过实现欧几里德距离(即，计算其到每个质心的距离)将每个x(i)分配到最近的聚类</p><p id="b4fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">第三步:</em> </strong>通过取指定点的平均值来识别新的质心。</p><p id="97d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">第四步:</em> </strong>不断重复第二步和第三步，直到达到收敛！</p><p id="91ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">让我们在这些步骤中的每一步都仔细看看:</em> </strong></p><h2 id="8ecc" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">第一步</h2><p id="93a9" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">我们随机选择K(质心)。我们把它们命名为 <strong class="ig hi"> <em class="jc"> c1，c2，…..ck </em> </strong> <em class="jc">，我们可以这么说:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mx"><img src="../Images/75b9d2120223ac33a4e5ff6f0becbc3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:296/0*tcslT1dwGYrLQlLX.JPG"/></div></figure><p id="56ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里C是所有质心的集合。</p><h2 id="e693" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">第二步</h2><p id="3496" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">我们将每个数据点分配到其最近的中心，这是通过计算欧几里德距离来实现的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es my"><img src="../Images/0dd983c031ea0788aa2b20917cb28818.png" data-original-src="https://miro.medium.com/v2/resize:fit:292/0*YawHdEJ6gEqLXFSI.JPG"/></div></figure><p id="5ae4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">其中dist()是</em> <strong class="ig hi"> <em class="jc">的欧氏距离。</em> </strong></p><blockquote class="mc md me"><p id="5de8" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">这里，我们从每个c值计算每个x值的距离，即x1-c1、x1-c2、x1-c3之间的距离，以此类推。然后我们找到最低的值，并将x1指定给这个质心。</p><p id="7def" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">类似地，我们找到x2、x3等的最小距离。</p></blockquote><h2 id="926c" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">第三步</h2><p id="f0c3" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><em class="jc">我们通过取分配给该聚类的所有点的平均值来识别实际质心。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mz"><img src="../Images/4d21b4d180f33050677cb575c7d64d8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:308/0*qRflR6QY9dN3qlz8.JPG"/></div></figure><p id="5aab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">其中Si是分配给第I个聚类的所有点的集合。</em></p><blockquote class="mc md me"><p id="b9e9" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">这意味着原来的点，我们认为是质心，将转移到新的位置，这是每个组的实际质心。</p></blockquote><h2 id="e669" class="kr ju hh bd jv ks kt ku jz kv kw kx kd ip ky kz kh it la lb kl ix lc ld kp le bi translated">第四步</h2><p id="f84a" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><em class="jc">不断重复步骤2和步骤3，直到达到收敛。</em></p><blockquote class="mc md me"><p id="84cc" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">一旦聚类变成静态的，k-means算法就被认为是收敛的。</p></blockquote><h1 id="a79e" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">其他资源和参考</h1><p id="3d7b" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">关于K-means聚类的更多实现:</em> </strong></p><div class="na nb ez fb nc nd"><a href="https://tp6145.medium.com/crime-data-pattern-analysis-and-visualization-using-k-means-clustering-ceeb963a2b47" rel="noopener follow" target="_blank"><div class="ne ab dw"><div class="nf ab ng cl cj nh"><h2 class="bd hi fi z dy ni ea eb nj ed ef hg bi translated">基于K均值聚类的犯罪数据模式分析与可视化</h2><div class="nk l"><h3 class="bd b fi z dy ni ea eb nj ed ef dx translated">犯罪模式分析通过发现犯罪事件发生的地点、时间和地点，揭示了犯罪事件之间潜在的相互作用过程</h3></div><div class="nl l"><p class="bd b fp z dy ni ea eb nj ed ef dx translated">tp6145.medium.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr jn nd"/></div></div></a></div><div class="na nb ez fb nc nd"><a href="https://tp6145.medium.com/image-segmentation-using-k-means-clustering-from-scratch-1545c896e38e" rel="noopener follow" target="_blank"><div class="ne ab dw"><div class="nf ab ng cl cj nh"><h2 class="bd hi fi z dy ni ea eb nj ed ef hg bi translated">从头开始使用K-均值聚类的图像分割</h2><div class="nk l"><h3 class="bd b fi z dy ni ea eb nj ed ef dx translated">在数字图像处理和计算机视觉中，图像分割是将一幅数字图像分割成几个部分的过程</h3></div><div class="nl l"><p class="bd b fp z dy ni ea eb nj ed ef dx translated">tp6145.medium.com</p></div></div><div class="nm l"><div class="ns l no np nq nm nr jn nd"/></div></div></a></div><div class="na nb ez fb nc nd"><a href="https://tp6145.medium.com/extracting-dominant-colours-in-an-image-using-k-means-clustering-from-scratch-2ce79a3eea5d" rel="noopener follow" target="_blank"><div class="ne ab dw"><div class="nf ab ng cl cj nh"><h2 class="bd hi fi z dy ni ea eb nj ed ef hg bi translated">从零开始使用K-均值聚类提取图像中的主色</h2><div class="nk l"><h3 class="bd b fi z dy ni ea eb nj ed ef dx translated">从头开始，在不到5分钟的时间内从您选择的任何图像中提取主色！</h3></div><div class="nl l"><p class="bd b fp z dy ni ea eb nj ed ef dx translated">tp6145.medium.com</p></div></div><div class="nm l"><div class="nt l no np nq nm nr jn nd"/></div></div></a></div><div class="na nb ez fb nc nd"><a href="https://github.com/tanvipenumudy/Winter-Internship-Internity/tree/main/Day%2011%20-%20K-means%20%26%20Image%20Segmentation" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab dw"><div class="nf ab ng cl cj nh"><h2 class="bd hi fi z dy ni ea eb nj ed ef hg bi translated">tanvipenumudy/Winter-实习-实习</h2><div class="nk l"><h3 class="bd b fi z dy ni ea eb nj ed ef dx translated">存储库跟踪每天分配的工作-tanvipenumudy/Winter-实习-实习</h3></div><div class="nl l"><p class="bd b fp z dy ni ea eb nj ed ef dx translated">github.com</p></div></div><div class="nm l"><div class="nu l no np nq nm nr jn nd"/></div></div></a></div><blockquote class="mc md me"><p id="9eb2" class="ie if jc ig b ih ii ij ik il im in io mf iq ir is mg iu iv iw mh iy iz ja jb ha bi translated">希望你喜欢并充分利用这篇文章！敬请关注我即将发布的博客！如果您觉得我的内容有帮助/有帮助，请务必鼓掌<strong class="ig hi">并跟随</strong>和<strong class="ig hi">！</strong></p></blockquote></div></div>    
</body>
</html>