<html>
<head>
<title>Manipulating class weights and decision threshold</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">操纵类别权重和决策阈值</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/manipulating-class-weights-and-decision-threshold-cb7d8d9433a4?source=collection_archive---------5-----------------------#2021-06-29">https://medium.com/analytics-vidhya/manipulating-class-weights-and-decision-threshold-cb7d8d9433a4?source=collection_archive---------5-----------------------#2021-06-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="c760" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">比较两种保持分类平衡的方法</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/a405a6743005fb2e33d2cbc0cf052702.png" data-original-src="https://miro.medium.com/v2/resize:fit:1336/format:webp/1*SNwsiQrTEP8O29C9K-w5VA.jpeg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">来源:谷歌图片</figcaption></figure><h1 id="2fc6" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">背景:</h1><p id="64b0" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">处理分类问题中的数据集不平衡是机器学习(ML)社区中的一个非常热门的话题。这里我们指的是每个响应类的样本比例的不平衡。在阅读詹姆斯·威滕、哈斯蒂、提布拉尼的<em class="kr"> ISLR时，我发现了这一点，处理这种失衡的不利影响的方法是通过操纵决定预测决策边界的阈值概率极限。然而，sklearn中的逻辑回归文档向我介绍了类权重的概念，这似乎也是为了同样的目的。所以我的疑问由此而来-</em></p><blockquote class="ks kt ku"><p id="3ec8" class="ie if kr ig b ih ii ij ik il im in io kv iq ir is kw iu iv iw kx iy iz ja jb ha bi translated"><strong class="ig hi">操纵类权重和阈值限制会导致相同的结果吗？</strong></p></blockquote><p id="5326" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将尝试通过进行一些模拟的实证研究来解决这个问题。</p><h1 id="a974" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">一.摘要:</h1><p id="65d6" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated"><strong class="ig hi"> <em class="kr">首先要注意的是——我们将把我们的研究局限于逻辑回归，以便专注于问题本身的本质。</em> </strong></p><p id="cac5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">分类问题中有两种错误——假阴性和假阳性。操纵阈值极限决定了假阴性和假阳性的比率。</p><blockquote class="ks kt ku"><p id="6447" class="ie if kr ig b ih ii ij ik il im in io kv iq ir is kw iu iv iw kx iy iz ja jb ha bi translated"><strong class="ig hi">我们猜测，与使用0.5作为阈值的假阳性率相比，过高的假阴性率是由于数据集的不平衡——与y=0条目相比，y=1条目太低。</strong></p></blockquote><p id="f204" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这似乎是合乎逻辑的，因为与y=1个条目相比，y=0个条目对分类器具有更大的影响。因此，与y=1类相比，y=0类中的错误率较低。首先，我们将检验这个假设。</p><p id="c733" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果假设是有效的，我们将检查操纵类权重是否达到与操纵阈值限制相同的目的。因此有两个问题需要回答—</p><ul class=""><li id="53a8" class="ky kz hh ig b ih ii il im ip la it lb ix lc jb ld le lf lg bi translated">假阴性率真的取决于数据集的不平衡吗？</li><li id="e4a7" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb ld le lf lg bi translated">如果以上答案是肯定的，那么操纵阈值限制和类权重是否达到了相同的目的？</li></ul><h1 id="8e89" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">二。准备模拟训练数据</h1><p id="d49b" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">我们首先决定训练数据集的特征。</p><p id="a54f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">训练数据的特征:</strong></p><ol class=""><li id="2cfc" class="ky kz hh ig b ih ii il im ip la it lb ix lc jb lm le lf lg bi translated">将有一个功能，信用余额-0-20，000之间的数字和一个响应-默认状态。1表示默认值=是，0表示默认值=否。训练集大小将为1000。</li><li id="bf94" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb lm le lf lg bi translated">我们将采用概率分布P(y=1|x ),这样信用余额较高的人违约的几率较高。这个概率分布将用于生成训练数据集— (X，Y)。</li><li id="e109" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb lm le lf lg bi translated">在训练集<strong class="ig hi"><em class="kr">(y = 1的条目)/(样本数)=正类条目比例</em> </strong>。</li></ol><p id="ced5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用逻辑函数，e^(b_0+B1 . x)/(1+e^(b_0+b_01.x)，选择B0和B1来满足我们的上述要求，以生成任何给定x的y。下面是获得的概率分布曲线—</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ln"><img src="../Images/10db822f3c41ad2c2a53f401769a99fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*Ns7EVCB59xcBY9g-M2ffYg.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">图1</figcaption></figure><p id="bdc6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还确保训练集中y=1个条目的给定比例。</p><p id="bf43" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是训练集中默认=是和默认=否条目的贷方余额分布，使用10%默认=是条目生成。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lo"><img src="../Images/b33fcd02ffc4674d3b69811e4ce371ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*i57aMIf6SJeteY7Ix4Ze8Q.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">图2:每种违约状态的信用余额分布</figcaption></figure><p id="9836" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这样生成的训练集是(前5个条目)—</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lp"><img src="../Images/52977f91cbb716366145e1f8799cf101.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/1*77tmnS3VQKGTuVF93WmjMA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">表1:训练集(前5个条目)</figcaption></figure><p id="4104" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是逻辑回归的经典案例。</p><h1 id="fd45" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">三。寻找假阴性率</h1><p id="7d47" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">使用上述训练集，应用逻辑回归，以下是获得的预测—</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lq"><img src="../Images/5d64c74ff7f575fc3a61aba711973b14.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*tESP2EBnzTna25I8mujyFw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">表2:在训练集上获得的预测</figcaption></figure><p id="7129" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相关的混淆矩阵如下—</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lr"><img src="../Images/34f73f4c50efbf0352286025751863d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*mGhRAk7x0JWYWn79B6YTWw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">表3:每行都标准化的混淆矩阵</figcaption></figure><p id="d8d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从混淆矩阵来看，假阴性和真阳性率分别为44%和56%。假阳性率为2.22%，总错误率(此处未显示)为6.4%。</p><p id="cd0e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在将研究针对训练数据集不平衡(默认=是训练集中的比例)的假阴性、假阳性和总体错误率。这项研究将证实假阴性率是否确实取决于数据集的不平衡？</p><h1 id="2962" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">四。错误率与训练数据集中的不平衡</h1><p id="ef45" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">我们在100个步骤中从1%到50%不断改变默认=是比例，并针对每个比例值分别绘制假阴性、假阳性和总体错误率。</p><p id="197f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">获得了下图——</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/60b3394bcdefa8735abb871569f3d681.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mb5WBNo622zSMKx6CrthFg.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">图3:错误率与违约率=是比例</figcaption></figure><p id="df7e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">随着训练数据集从不平衡(较低的𝑦=1比例)到平衡，假阴性率将降低(绿点)。这是合乎逻辑的，因为模型将在y=1域中更多地学习'<strong class="ig hi"><em class="kr">'</em></strong>，因此将在该区域中产生更低的误差。假阳性率也会增加(红点),因为模型学习y=0域的范围相对较小。</p><blockquote class="ks kt ku"><p id="75d7" class="ie if kr ig b ih ii ij ik il im in io kv iq ir is kw iu iv iw kx iy iz ja jb ha bi translated">然而，为什么总的错误率，它表示模型总的'<strong class="ig hi">学习不足'</strong>，增加了呢？它同样可以保持不变或减少。</p></blockquote><p id="2004" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了回答这个问题，我们将仔细研究原始的和预测的决策边界，即P(y=1|x)=0.5的x值。</p><h2 id="87fc" class="lx jp hh bd jq ly lz ma ju mb mc md jy ip me mf kc it mg mh kg ix mi mj kk mk bi translated">IV a .为什么总错误率会随着余额的增加而增加？</h2><p id="ed07" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">原始决策边界由用于模拟训练数据集的分布控制。预测边界是从学习模型获得的。</p><p id="3776" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们采用分别具有10%、30%和50%默认=是比例的三个训练集，从不平衡移动到平衡，并研究原始和预测的边界。</p><p id="a38f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是我们得到的图—</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ml"><img src="../Images/6670f0fc9ea799ffc48e86e8d428787f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l6sPGDs6Ghk15AqaZVjEBA.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">图4:默认值=是10%</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mm"><img src="../Images/00a93b3e904ec6df92f08113f4943444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RFb4UcScSDtg3ywX1rFVSA.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">图5:默认值=是30%</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mn"><img src="../Images/84b184a7d752406cfbfd5d2f21d96b3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1UyC_zd5mO4eT29ddxg_LQ.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">图6:默认值=是50%</figcaption></figure><p id="2280" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">三行数字分别代表数据中10%、30%和50%默认=是的比例。左边的图显示了default=yes(绿色)的原始数据。右边的图显示了原始数据，其中default=no(红色)。在每个图中，后面的垂直线表示由模拟函数控制的决策边界；它始终保持不变。蓝色垂直线显示预测的决策边界。</p><blockquote class="ks kt ku"><p id="f488" class="ie if kr ig b ih ii ij ik il im in io kv iq ir is kw iu iv iw kx iy iz ja jb ha bi translated">首先，我们看一下左侧的3幅图，其中只显示了默认=是的情况。</p></blockquote><p id="7d3d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">顶部的<em class="kr">默认=是比例为10%。</em> </strong></p><ul class=""><li id="8f80" class="ky kz hh ig b ih ii il im ip la it lb ix lc jb ld le lf lg bi translated">原始决策边界左侧的情况是根据控制函数违约概率小于50%的情况；然而违约还是发生了。这是大自然引入不可避免的随机误差的方式。</li><li id="0070" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb ld le lf lg bi translated">如果预测边界与原始边界完全相同，这将是模型对自然的精确学习；最好的情况。即使这样，预测边界左侧的所有数据点都将被预测为default=no，但最初的default = yes这就是假阴性误差。当预测边界与原始边界相同时，唯一的假阴性误差是由自然界不可避免的随机性引起的。</li><li id="f97e" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb ld le lf lg bi translated">但是，预测边界位于原始边界的右侧，因为训练集的default=yes样本数很少。<strong class="ig hi">为了说明这一点，如果没有default=yes样本，预测边界将位于最右侧，将所有样本标识为default = no。</strong></li><li id="1ee1" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb ld le lf lg bi translated">这是比通常更高的假阴性率的来源；由于默认=是或正情况的比例较低，预测边界位于原始边界的右侧。</li></ul><p id="b59d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="kr">在它下面第二行，默认=是比例为30%。</em>T11】</strong></p><ul class=""><li id="e5b1" class="ky kz hh ig b ih ii il im ip la it lb ix lc jb ld le lf lg bi translated">随着default=yes样本比例的增加，预测边界会向左移动。<strong class="ig hi">激励这一运动—如果所有训练样本都是默认的=是。预测边界将位于最左侧，预测所有情况下的default=yes。</strong></li><li id="4c88" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb ld le lf lg bi translated">随着预测边界向左移动，假阴性误差减小。这将试图降低整体误差。</li></ul><p id="fe6d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="kr">在底部，其中默认=是比例为50%-</em>-</strong></p><ul class=""><li id="b8bc" class="ky kz hh ig b ih ii il im ip la it lb ix lc jb ld le lf lg bi translated">预测边界更加左移，进一步减少了假阴性误差。</li></ul><blockquote class="ks kt ku"><p id="77d4" class="ie if kr ig b ih ii ij ik il im in io kv iq ir is kw iu iv iw kx iy iz ja jb ha bi translated"><strong class="ig hi">接下来，我们浏览右侧的3个图，其中仅显示了默认情况=无案例。</strong></p></blockquote><p id="29b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="kr">顶部默认=是比例为10%。</em> </strong></p><ul class=""><li id="791c" class="ky kz hh ig b ih ii il im ip la it lb ix lc jb ld le lf lg bi translated">原始决策边界右侧的案例是违约概率超过50%的案例；然而，违约并没有发生。这是不可避免的随机误差。</li><li id="779b" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb ld le lf lg bi translated">预测边界位于原始边界的右侧。预测边界右侧的情况是预测default=yes或y=1，但最初default=no或y=0的情况。这些是假阳性错误。</li></ul><p id="fda7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="kr">在它下面第二行，默认=是比例为30%。</em>T3】</strong></p><ul class=""><li id="913a" class="ky kz hh ig b ih ii il im ip la it lb ix lc jb ld le lf lg bi translated">随着预测边界向左移动，假阳性误差增加。这将试图提高整体误差。</li></ul><p id="e407" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="kr">在底部，这里默认=是比例为50% - </em> </strong></p><ul class=""><li id="def1" class="ky kz hh ig b ih ii il im ip la it lb ix lc jb ld le lf lg bi translated">预测边界更加左移，进一步增加了假阳性误差。</li></ul><blockquote class="ks kt ku"><p id="0f04" class="ie if kr ig b ih ii ij ik il im in io kv iq ir is kw iu iv iw kx iy iz ja jb ha bi translated"><strong class="ig hi">随着预测边界向左移动，假阴性误差下降。然而，假阳性误差上升。但是为什么整体误差会上升呢？。这里有一个非常棘手的问题。</strong></p></blockquote><ul class=""><li id="f211" class="ky kz hh ig b ih ii il im ip la it lb ix lc jb ld le lf lg bi translated">请看图4-6中左边的图。随着蓝线向左移动，其左侧构成假阴性错误的病例数减少。然而，当默认值=是比例较低时，这些绿点的密度较低(低y=1个样本)。因此，即使蓝线明显左移，其左侧点数的减少也很少。</li><li id="80d7" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb ld le lf lg bi translated">现在看右边的数字。随着蓝线向左移动，其右侧的病例数增加，即假阳性误差增加。然而，红点的密度更大(高y=0样本)。因此，蓝线的相同左移可能会导致其右边的案例数量相对更大的增加。</li><li id="b53d" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb ld le lf lg bi translated">因此，当default=yes样本从10%增加到30%时，假阳性的增加通常会超过假阴性的减少。</li><li id="a774" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb ld le lf lg bi translated">然而，站在一个更平衡的场景，假设default=yes为30%，蓝线向左移动可能不会在假阴性的减少和假阳性的增加之间产生明显的差异。因此，从30%到50%，总误差率可能相对更稳定。</li><li id="d75d" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb ld le lf lg bi translated">现在查看图3。总体错误率先上升，然后逐渐稳定在30%以上的正比例。</li></ul><h2 id="6f53" class="lx jp hh bd jq ly lz ma ju mb mc md jy ip me mf kc it mg mh kg ix mi mj kk mk bi translated"><strong class="ak">因此，我们研究的第一部分到此结束——假阴性率是否取决于数据集的不平衡？答案是肯定的，确实如此。</strong></h2><h1 id="6e97" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">动词 （verb的缩写）阈值限制操作和类别权重达到相同的目的吗？</h1><p id="fa67" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">为此，给定一个不平衡的训练集，我们首先绘制一个ROC曲线，该曲线给出了在不同阈值水平下的假阳性与真阳性的比率。现在，用于不同级别的类别权重的不同分类器适合于相同的数据，并且假阳性率对真阳性率绘制在相同的图上。</p><p id="0181" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是获得的数字—</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mo"><img src="../Images/b45da2c9a3458374e44adb8e16907415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*jqzWE3OxoSUa6p7MVA3sOg.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">图7: ROC(阈值)和类权重</figcaption></figure><blockquote class="ks kt ku"><p id="41dc" class="ie if kr ig b ih ii ij ik il im in io kv iq ir is kw iu iv iw kx iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">蓝色曲线为ROC曲线。彩条表示正的等级权重或默认=是等级。类别权重从5.0到1.0不等(根本不使用类别权重)。全部位于ROC曲线上的散点图表示操纵类别权重与操纵阈值相同。红点是当类权重=“平衡”时分类器的性能，即类权重为5.0到正类。我们看到，如果没有任何类别权重，即类别权重=1.0，真实的阳性率是最差的。</em>T3】</strong></p></blockquote><h1 id="11be" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">不及物动词结论:</h1><p id="7b37" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">所以看起来我们有两个选择来处理不平衡的集合。</p><ol class=""><li id="1d03" class="ky kz hh ig b ih ii il im ip la it lb ix lc jb lm le lf lg bi translated">通过类别权重实现平衡</li><li id="0fba" class="ky kz hh ig b ih lh il li ip lj it lk ix ll jb lm le lf lg bi translated">选择合适的阈值</li></ol><p id="49aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不过，我对第一点有一些疑问。通过类别权重的平衡为少数正面响应样本提供了额外的权重。如果这些样本确实代表了真实世界的积极响应类别，那就太好了。然而，如果这些样本被破坏，比如说由于不正确的测量，那么给它们增加额外的权重会对学习结果产生负面影响。然而，对于阈值操纵来说，这种挑战可能不存在；在这里，这取决于人的决定，即为了获得低的假阴性率，人们愿意接受多大的总误差。诚然，这种推理需要进一步的实证研究，基于测试集的性能，以建立。</p><h1 id="6f81" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">PS:</h1><p id="6584" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">用于生成上述图的代码可以在<a class="ae mp" href="https://github.com/AnirbanChakraborty06/StatisticalLearning-ConfusionToClarity/blob/main/AnswersAndDemos/Class%20weights%20and%20threshold%20in%20Logistic%20Regression.ipynb" rel="noopener ugc nofollow" target="_blank">我的github库</a>中找到。</p></div></div>    
</body>
</html>