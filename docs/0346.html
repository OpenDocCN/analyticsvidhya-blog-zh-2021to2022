<html>
<head>
<title>How to retrain an object detection model with a custom training set</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用自定义训练集重新训练对象检测模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-retrain-an-object-detection-model-with-a-custom-training-set-c827aa3eb796?source=collection_archive---------3-----------------------#2021-01-13">https://medium.com/analytics-vidhya/how-to-retrain-an-object-detection-model-with-a-custom-training-set-c827aa3eb796?source=collection_archive---------3-----------------------#2021-01-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="fb3c" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">本教程将展示如何在15分钟内使用一组自定义图像重新训练mobilenetV2模型。</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/72f68fcc75b2779481ee75aba03cf357.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ULguTOY_M42K3Fx3KJJWQ.png"/></div></div></figure><p id="4dc9" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">从头开始训练对象检测模型将需要长时间的模型训练。为了节省时间，最简单的方法是使用已经训练好的模型，并重新训练它来检测您的自定义对象。这个过程被称为“<a class="ae ke" rel="noopener" href="/practical-deep-learning/a-complete-transfer-learning-toolchain-for-semantic-segmentation-3892d722b604">迁移学习”。</a></p><h1 id="b87a" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">为什么选择mobilenetV2？</h1><p id="d6a9" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">对象检测模型的性能持续提高。截至2020年，MobilenetV2是可以在web浏览器中运行的最快的对象检测模型。</p><p id="fbac" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">还有其他模型的对象检测，如YOLO和更多。你可以在这里找到<a class="ae ke" rel="noopener" href="/analytics-vidhya/a-review-of-object-detection-models-f575c515655c">详细的物体探测模型评论。</a></p><h1 id="ea8b" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">关于Google Colab</h1><p id="eaf4" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">MobilenetV2是基于TensorFlow的模型，因此我们将在google colab环境中使用基于TensorFlow的开源API执行命令。Google colab是免费的，但是它很快就会删除你的输出文件，这是一个不幸的缺点。</p><blockquote class="lg lh li"><p id="2322" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">您可以创建自己的Linux服务器/docker，运行已经安装了所有库的<code class="du lc ld le lf b"><em class="hh">object_detection</em></code> API。详情请看这篇<a class="ae ke" href="https://towardsdatascience.com/tensorflow-object-detection-with-docker-from-scratch-5e015b639b0b" rel="noopener" target="_blank">博客</a>。</p></blockquote><h1 id="e28a" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">本教程的议程</h1><p id="9ee1" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">在本教程中，我们将重新训练mobilenetV2模型来检测Pickachu玩具。我们将执行这10个步骤:</p><ul class=""><li id="7b4e" class="ln lo hh jk b jl jm jo jp jr lp jv lq jz lr kd ls lt lu lv bi translated"><strong class="jk hi">步骤1: </strong>在您的colab笔记本中克隆对象检测API库</li><li id="a30b" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd ls lt lu lv bi translated"><strong class="jk hi">步骤2至4 </strong>:安装物体检测API，导入其函数</li><li id="adeb" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd ls lt lu lv bi translated"><strong class="jk hi">步骤5: </strong>将您的训练图像集导入colab</li><li id="eb2c" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd ls lt lu lv bi translated"><strong class="jk hi">第六步:</strong>设置培训配置</li><li id="a2b2" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd ls lt lu lv bi translated"><strong class="jk hi">步骤7: </strong>加载预训练的mobilenetv2模型及其权重和最新的检查点</li><li id="f97e" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd ls lt lu lv bi translated"><strong class="jk hi">步骤8: </strong>用我们的定制训练集训练我们的新模型</li><li id="4098" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd ls lt lu lv bi translated"><strong class="jk hi">第九步:</strong>将我们训练好的模型导出为“SavedModel”格式</li><li id="dc38" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd ls lt lu lv bi translated"><strong class="jk hi">步骤10: </strong>使用我们的模型检测测试图像中的Pickachu。</li></ul><p id="bff2" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><a class="ae ke" href="https://gist.github.com/KostaMalsev/5d08cecc99f7a7ce72893060a06aba71?short_path=fb0f527" rel="noopener ugc nofollow" target="_blank">在这里</a>你可以找到完整的笔记本，只需在colab中运行即可(运行所有步骤大约需要15分钟)。</p><h1 id="d71f" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">colab环境中的文件系统映射</h1><p id="c1f4" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">使用对象检测API库的棘手部分是跟踪所有的输入和输出文件。</p><p id="b031" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">为了让生活变得简单一点，这里有一个colab环境的文件图，包含了我们将在本教程中使用的所有文件。</p><blockquote class="lg lh li"><p id="c218" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">文件夹根据执行顺序进行编号，图标指示该目录是培训过程的输入部分还是输出部分。</p><p id="80fe" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">文件将根据本教程的执行步骤加载，因此并非所有文件从一开始就在那里。</p></blockquote><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mb"><img src="../Images/150fe097e42861e3c89b2d9b14c675c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p0RCCZKUdmtqObvUFiTeUA.png"/></div></div></figure><h1 id="1940" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">执行步骤</h1><p id="9584" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">在colab笔记本中运行以下步骤(完整笔记本可在此<a class="ae ke" href="https://gist.github.com/KostaMalsev/5d08cecc99f7a7ce72893060a06aba71?short_path=fb0f527" rel="noopener ugc nofollow" target="_blank">获得</a>)。</p><p id="95d8" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">步骤1: </strong>将TensorFlow2对象检测API文件夹克隆到您的colab:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="7495" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">第二步:</strong>在colab中安装对象检测API:</p><blockquote class="lg lh li"><p id="4a50" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">注意:不幸的是，由于某种原因，您需要运行该步骤两次来修复安装中的错误。</p></blockquote><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="2030" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">步骤3: </strong>将TensorFlow库导入colab:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="4372" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">步骤4: </strong>运行该命令，测试<code class="du lc ld le lf b">object detection API</code>是否安装正确:</p><pre class="ix iy iz ja fd me lf mf mg aw mh bi"><span id="a921" class="mi kg hh lf b fi mj mk l ml mm">!python /content/models/research/object_detection/builders/model_builder_tf2_test.py</span></pre><p id="c4c4" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">步骤5: </strong>准备用于训练的定制图像集。在这个例子中，我使用<a class="ae ke" href="https://roboflow.com/" rel="noopener ugc nofollow" target="_blank"> Roboflow </a>从训练图像中创建<a class="ae ke" href="https://www.tensorflow.org/tutorials/load_data/tfrecord" rel="noopener ugc nofollow" target="_blank"> TFRecord </a>文件。</p><blockquote class="lg lh li"><p id="d57d" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">你也可以用可用的开源库创建一个带标签的训练数据集。</p><p id="65c8" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">Roboflow为您提供有限的免费访问权限，让您尝试其自动化过程，这一过程简单明了。</p><p id="937a" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">TFRecord文件的一个例子可以在<a class="ae ke" href="https://github.com/KostaMalsev/RetrainModelExample/blob/main/TrainingSet/Picka/Pickachu.v1.tfrecord.zip" rel="noopener ugc nofollow" target="_blank">我的git库</a>找到。</p><p id="b46f" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">在本教程中，我只用了10张图片来训练模型。在大多数情况下，将图像添加到训练集将改善检测。</p></blockquote><p id="44a5" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">下载的文件会放在colab环境下的<code class="du lc ld le lf b">/content/train/</code>文件夹中。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="b1d7" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">第六步:</strong>设置训练模型的配置参数:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="cb18" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">步骤7: </strong>从TensorFlow站点加载训练好的模型权重，以及我为此示例准备的自定义配置文件:</p><p id="ba1a" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><code class="du lc ld le lf b"><a class="ae ke" href="https://raw.githubusercontent.com/KostaMalsev/RetrainModelExample/main/ssd_mobilenet_v2_320x320_coco17_tpu-8.config" rel="noopener ugc nofollow" target="_blank"><em class="lj">https://raw.githubusercontent.com/KostaMalsev/RetrainModelExample/main/ssd_mobilenet_v2_320x320_coco17_tpu-8.config</em></a></code></p><blockquote class="lg lh li"><p id="d13f" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated"><strong class="jk hi">注意</strong>:确保文件名、文件夹和路径使用短名称。如果在配置文件中使用长路径名，训练过程将失败！</p><p id="08ff" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">以下是关于<code class="du lc ld le lf b">pipeline_file</code>配置文件(<code class="du lc ld le lf b"><a class="ae ke" href="https://raw.githubusercontent.com/KostaMalsev/RetrainModelExample/main/ssd_mobilenet_v2_320x320_coco17_tpu-8.config" rel="noopener ugc nofollow" target="_blank"><em class="hh">ssd_mobilenet_v2_320x320_coco17_tpu-8.config</em></a><em class="hh">)</em></code>的一些注意事项:</p></blockquote><pre class="ix iy iz ja fd me lf mf mg aw mh bi"><span id="c2b8" class="mi kg hh lf b fi mj mk l ml mm">#Choose type ssd_mobilenet_v2_keras<br/>feature_extractor {                             <br/>  type: <strong class="lf hi">"ssd_mobilenet_v2_keras"</strong><br/>..</span><span id="5fd3" class="mi kg hh lf b fi mn mk l ml mm">#Training batch size: if you have more memory on server,by increasing batch_size will run the training faster.<br/><strong class="lf hi">batch_size: 16</strong></span><span id="33bf" class="mi kg hh lf b fi mn mk l ml mm">#The path to pretrained model checkpoint:(choose short names) <strong class="lf hi">fine_tune_checkpoint:</strong> <strong class="lf hi">"/content/deploy/mobilnetv2/checkpoint/ckpt-0"</strong></span><span id="76fa" class="mi kg hh lf b fi mn mk l ml mm">#Number of training steps:<br/><strong class="lf hi">num_steps: 1800</strong></span><span id="bd38" class="mi kg hh lf b fi mn mk l ml mm">#Type of checkpoint when loading from pretrained model: fine_tune_checkpoint_type:<strong class="lf hi"> "detection"</strong></span><span id="d3ff" class="mi kg hh lf b fi mn mk l ml mm">#Defines the location of train set of images TFRecords and label maps<br/>train_input_reader {                                        label_map_path:<strong class="lf hi"> "/content/train/Toy_label_map.pbtxt"</strong>                         tf_record_input_reader {                                    input_path:<strong class="lf hi"> "/content/train/Toy.tfrecord"</strong>                         }<br/>..</span></pre><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="ac70" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">第8步:</strong> <strong class="jk hi">运行培训流程:</strong></p><p id="e9b7" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">以下参数和<code class="du lc ld le lf b">pipeline_file</code>配置将在培训过程中使用。</p><p id="a2c5" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><code class="du lc ld le lf b">pipline_file (<a class="ae ke" href="https://raw.githubusercontent.com/KostaMalsev/RetrainModelExample/main/ssd_mobilenet_v2_320x320_coco17_tpu-8.config" rel="noopener ugc nofollow" target="_blank"><em class="lj">ssd_mobilenet_v2_320x320_coco17_tpu-8.config</em></a><em class="lj">)</em></code> <em class="lj"> </em>中的配置值将覆盖行内参数。</p><pre class="ix iy iz ja fd me lf mf mg aw mh bi"><span id="642a" class="mi kg hh lf b fi mj mk l ml mm"><strong class="lf hi">pipeline_file</strong>: defined above in writing custom training configuration. (<a class="ae ke" href="https://raw.githubusercontent.com/KostaMalsev/RetrainModelExample/main/ssd_mobilenet_v2_320x320_coco17_tpu-8.config" rel="noopener ugc nofollow" target="_blank"><em class="lj">ssd_mobilenet_v2_320x320_coco17_tpu-8.config)</em></a></span><span id="4238" class="mi kg hh lf b fi mn mk l ml mm"><strong class="lf hi">model_dir</strong>: the location where logs and saved model checkpoints will save to.</span><span id="7847" class="mi kg hh lf b fi mn mk l ml mm"><strong class="lf hi">num_train_steps</strong>: how long to train for.</span><span id="992b" class="mi kg hh lf b fi mn mk l ml mm"><strong class="lf hi">num_eval_steps:</strong> perform eval on validation set after this many steps</span></pre><blockquote class="lg lh li"><p id="adad" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated"><strong class="jk hi">注意</strong>:训练过程需要几分钟，取决于你的机器。</p><p id="e82d" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">在大多数情况下，训练时间越长，检测结果越好。</p><p id="1246" class="ji jj lj jk b jl jm ii jn jo jp il jq lk js jt ju ll jw jx jy lm ka kb kc kd ha bi translated">在这个例子中，我用<code class="du lc ld le lf b">loss=0.159</code>得到了1100步的声音结果。在colab运行了大约10分钟。</p></blockquote><p id="64c5" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">在<code class="du lc ld le lf b">/content/training/train</code>文件夹中查找检查点(<code class="du lc ld le lf b">ckpt</code>)文件。</p><p id="25e7" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">如果损失函数结果满足您的要求，您可以停止训练过程。损失函数结果可以在笔记本日志中找到，请查找以下行:</p><pre class="ix iy iz ja fd me lf mf mg aw mh bi"><span id="e656" class="mi kg hh lf b fi mj mk l ml mm">Step 1100 per-step time 0.478s loss=0.159</span></pre><p id="aaea" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">从我的经验来看，值低于<code class="du lc ld le lf b">0.2</code>的损失函数结果对于一个演示应用来说已经足够了。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="a51a" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">步骤9: </strong>保存重新训练的模型:</p><p id="5519" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">导出的模型将存储在<code class="du lc ld le lf b">output_directory.</code>中。在本例中，模型将导出到<code class="du lc ld le lf b">/content/fine_tuned_model.</code></p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="cd07" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">就这样</strong>。</p><p id="73eb" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">现在你有了一个重新训练的模型<code class="du lc ld le lf b">.pb </code>文件和<code class="du lc ld le lf b">checkpoint</code>文件，你以后可以用它来进行物体检测。</p><h1 id="e35c" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">测试我们的再培训模型:</h1><p id="0aa5" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">为了测试我们重新训练的模型，执行4个额外的步骤:</p><p id="ff21" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">步骤A </strong>:将需要测试的图像导入到<code class="du lc ld le lf b">/content/test</code>文件夹中。我用了Pinterest上的Pickachu图片。</p><pre class="ix iy iz ja fd me lf mf mg aw mh bi"><span id="c75f" class="mi kg hh lf b fi mj mk l ml mm">#Import your test images to colab. <br/>#I use Pinterest to store the the images.</span><span id="5116" class="mi kg hh lf b fi mn mk l ml mm">%mkdir /content/test/</span><span id="151b" class="mi kg hh lf b fi mn mk l ml mm">%cd /content/test/</span><span id="be8f" class="mi kg hh lf b fi mn mk l ml mm">!curl -L "https://i.pinimg.com/564x/f5/46/c4/f546c47505e1f5f8d17f8458d641b262.jpg" &gt; test.jpeg;</span></pre><p id="076c" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">步骤B </strong>:导入可视化库和对象检测功能:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="9f4b" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">步骤C: </strong>导入我们重新训练的模型，它的<strong class="jk hi">最后一个</strong>训练检查点和地图对象标签。对于这个例子，我选择了<code class="du lc ld le lf b">ckpt-2</code>(第二个检查点)。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="ea30" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">步骤D: </strong>对测试图像进行目标检测:</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="beab" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">结果如下:)</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/72f68fcc75b2779481ee75aba03cf357.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5ULguTOY_M42K3Fx3KJJWQ.png"/></div></div></figure><p id="1950" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">你可以在这里找到完整的笔记本<a class="ae ke" href="https://gist.github.com/KostaMalsev/5d08cecc99f7a7ce72893060a06aba71?short_path=fb0f527" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="f8da" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">摘要</h1><ul class=""><li id="bbf2" class="ln lo hh jk b jl kx jo ky jr mo jv mp jz mq kd ls lt lu lv bi translated">在本教程中，我们使用对象检测API库和我们选择的训练图像来重新训练对象检测模型“mobilenetV2”。</li><li id="953d" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd ls lt lu lv bi translated">重新训练的模型被导出为冻结格式<code class="du lc ld le lf b">.pb</code>文件，也称为“保存模型”格式。</li><li id="4d5d" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd ls lt lu lv bi translated">我们在测试图像上测试了新的重新训练的对象检测模型。使用Roboflow平台将训练和测试图像转换为TFRecord格式。</li></ul><h1 id="e565" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">后续步骤</h1><p id="727f" class="pw-post-body-paragraph ji jj hh jk b jl kx ii jn jo ky il jq jr kz jt ju jv la jx jy jz lb kb kc kd ha bi translated">我们可以使用重新训练的mobilenetV2在网络浏览器中的直播摄像机上执行对象检测，有关教程，请参见<a class="ae ke" href="https://kostya-malsev.medium.com/build-custom-object-detection-web-application-using-tensorflow-js-d1664f96a18b" rel="noopener">我在这里的文章</a>。</p><p id="3fba" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">感谢您的阅读！</p><h1 id="57e7" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">参考资料:</h1><ol class=""><li id="c02a" class="ln lo hh jk b jl kx jo ky jr mo jv mp jz mq kd mr lt lu lv bi translated"><a class="ae ke" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank">物体检测API </a>。</li><li id="b15b" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd mr lt lu lv bi translated"><a class="ae ke" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">张量流站点</a>。</li><li id="5ce0" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd mr lt lu lv bi translated"><a class="ae ke" href="https://colab.research.google.com/drive/1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD" rel="noopener ugc nofollow" target="_blank">用Roboflow例子</a>再培训YOLO模式。</li><li id="f7a8" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd mr lt lu lv bi translated"><a class="ae ke" href="https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet" rel="noopener ugc nofollow" target="_blank">git上的MobilenetV2模型</a>。</li><li id="ee1c" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd mr lt lu lv bi translated"><a class="ae ke" href="https://gist.github.com/KostaMalsev/5d08cecc99f7a7ce72893060a06aba71" rel="noopener ugc nofollow" target="_blank">本教程完整笔记本</a>。</li><li id="f5de" class="ln lo hh jk b jl lw jo lx jr ly jv lz jz ma kd mr lt lu lv bi translated"><a class="ae ke" href="https://app.roboflow.com/ds/3BEuFXmB2K?key=Xpbcwj23it" rel="noopener ugc nofollow" target="_blank">本教程中使用的关于Roboflow的训练图像。</a></li></ol></div></div>    
</body>
</html>