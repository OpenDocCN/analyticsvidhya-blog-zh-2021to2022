<html>
<head>
<title>Key Concepts of BigGAN: Training and assessing large-scale image generation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">BigGAN的关键概念:训练和评估大规模图像生成</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/key-concepts-of-biggan-training-and-assessing-large-scale-image-generation-4c8303dcf73f?source=collection_archive---------6-----------------------#2021-03-25">https://medium.com/analytics-vidhya/key-concepts-of-biggan-training-and-assessing-large-scale-image-generation-4c8303dcf73f?source=collection_archive---------6-----------------------#2021-03-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="17ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">论文<a class="ae jc" href="https://arxiv.org/abs/1809.11096" rel="noopener ugc nofollow" target="_blank">高保真自然图像合成的大规模GAN训练</a></p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jk"><img src="../Images/a8508961c8a79bd27ad9d6ae242e1244.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0s7IRf3SdpJ3GjsyIHlN-w.png"/></div></div></figure><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jw"><img src="../Images/88a01ff7e0b1a9d29bf71508f99931f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V83Gg8hvLyMvYhNiWsZ7Jg.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">由所提出的方法生成的512×512图像的例子</figcaption></figure><p id="3213" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">哇！这种具有高多样性和高分辨率的伟大图像可以通过bigGAN生成。我们将回顾该模型提出的关键见解和整体方法。尽管已经有多篇研究论文提出了高质量图像生成的这一阶段，但是本文中的方法并不复杂。</p><h1 id="1b3f" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">关键概念</h1><ul class=""><li id="1a5c" class="kz la hh ig b ih lb il lc ip ld it le ix lf jb lg lh li lj bi translated">本文建立在SAGAN(自我注意GAN)之上，它由自我注意机制组成，从细节上参考完整的图像。自我注意块在本文中被称为“非局部块”。</li><li id="3fda" class="kz la hh ig b ih lk il ll ip lm it ln ix lo jb lg lh li lj bi translated">这项工作表明，简单地增加批量大小和缩放模型可以极大地影响图像质量。</li><li id="9cf0" class="kz la hh ig b ih lk il ll ip lm it ln ix lo jb lg lh li lj bi translated">潜在向量Z和类嵌入y通过具有多尺度的类条件BatchNorm的生成器，并帮助在生成的图像中加强类一致性。</li><li id="d8b4" class="kz la hh ig b ih lk il ll ip lm it ln ix lo jb lg lh li lj bi translated">这篇论文对G和D在训练和模崩溃时的行为提供了有趣的见解。</li></ul><h2 id="a8bc" class="lp kc hh bd kd lq lr ls kh lt lu lv kl ip lw lx kp it ly lz kt ix ma mb kx mc bi translated">铰链损耗</h2><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es md"><img src="../Images/8ab0cf479f9d4d086aec5a4f51c4cc98.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*4BwcIS01BozH5BBc2lqtZg.png"/></div></figure><p id="7399" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">铰链损耗是一种类似上图的损耗，也用于支持向量机。这种用于对抗性训练的铰链损耗被用于SA-GAN，并且训练发生器和鉴别器有一点不同。鉴别器被训练来预测D(x)&gt;1的真实数据和D(G(z))  0。为了精确起见，每个网络的损耗公式描述如下。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div class="er es me"><img src="../Images/9cacda6f9a66282713cb27f165cefdce.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*GoQRQUm4ErBWdZxSadp9JQ.png"/></div></figure><h2 id="47f1" class="lp kc hh bd kd lq lr ls kh lt lu lv kl ip lw lx kp it ly lz kt ix ma mb kx mc bi translated">扩大gan的规模</h2><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es mf"><img src="../Images/adc63484b8c0f3f602417a9221c38523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Th_1a6gUp0ZABdeJ3censQ.png"/></div></div></figure><p id="b4ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据实验结果，GANs的性能可以从基线SA-GAN得到显著改善。上表比较了将批处理大小从最初的256增加到2048所带来的性能优势。该模型还可以在更少的迭代中达到更好的最终性能，如表中所示。渠道规模增加50%也会使IS(初始得分)增加21%。</p><h2 id="575f" class="lp kc hh bd kd lq lr ls kh lt lu lv kl ip lw lx kp it ly lz kt ix ma mb kx mc bi translated">跳过z，共享嵌入</h2><p id="3844" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip mg ir is it mh iv iw ix mi iz ja jb ha bi translated">对于skip-z连接，所提出的模型将潜在向量分成块，并且每个块被馈送到与类嵌入连接的残差块中。更具体地，140个浮点的向量被分割成7个20个浮点的切片，并被馈送到每个残差块中的条件批量归一化层。嵌入对于每个残差块是共享的，因为它显示了经验性能提高。</p><h2 id="bb6f" class="lp kc hh bd kd lq lr ls kh lt lu lv kl ip lw lx kp it ly lz kt ix ma mb kx mc bi translated">条件批处理规范化</h2><p id="41a6" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip mg ir is it mh iv iw ix mi iz ja jb ha bi translated">在批处理规范化中，批处理规范化图层的参数被设置为批处理元素的平均值和方差。在条件批处理规范化中，平均值和方差被设置为神经网络的输出。在这种情况下，它基于潜在切片z和类嵌入来进行调节。该模型获得关于类嵌入和噪声的知识的唯一方式是通过有条件的批量规范化。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es mj"><img src="../Images/a366d9a90a8a7caae516b8423dd74d70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*54s-odxanafouv3h.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">图片来自代码为的<a class="ae jc" href="https://paperswithcode.com/method/conditional-batch-normalization#" rel="noopener ugc nofollow" target="_blank">张纸</a></figcaption></figure><h2 id="b8f9" class="lp kc hh bd kd lq lr ls kh lt lu lv kl ip lw lx kp it ly lz kt ix ma mb kx mc bi translated">截断技巧</h2><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es mk"><img src="../Images/e9442861d2541c6e90592704c1c498f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cQljyng0oNrq9b4T9pD7HA.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">增加截断的影响。从左到右，阈值设置为2，1，0.5，0.04。(b)对条件差的模型应用截断产生的饱和伪像。</figcaption></figure><p id="98b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文提出的截断技巧是一种折衷生成图像的多样性和质量的方法。这是通过改变潜在向量z的范围来实现的。如上图所述，如果潜在向量被截断到一个较小的范围内，图像质量会高得多，尽管会损失一些变化。</p><h2 id="0ff9" class="lp kc hh bd kd lq lr ls kh lt lu lv kl ip lw lx kp it ly lz kt ix ma mb kx mc bi translated">自我注意机制/非局部阻滞</h2><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es ml"><img src="../Images/946b56fbbafd8e311eb8a1fed13dcf73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*psN8SFuwvcYTQXiM.png"/></div></div></figure><p id="9209" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://arxiv.org/abs/1805.08318" rel="noopener ugc nofollow" target="_blank">萨根</a>在网络的中间层应用自我关注，使得能够从完整图像的细节进行调节。SAGAN论文中详细阐述了这一指标，这超出了本文讨论bigGAN方法的范围。BigGAN在生成器和鉴别器的64x64分辨率中都应用了自我关注层。</p><h1 id="86c3" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">模型架构</h1><div class="jl jm jn jo fd ab cb"><figure class="mm jp mn mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><img src="../Images/b1b3f5cce6bc568df2a4568c73b7cd9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*Jd5Sa86PFuAe0gS_2W7L0A.png"/></div></figure><figure class="mm jp ms mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><img src="../Images/48e2c9e17f8931c2ca999f3d10bd1769.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*M9xXYCNDaDa1ZvR_0eyepg.png"/></div></figure><figure class="mm jp mt mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><img src="../Images/b5ceef70cb150c344a938135d1664ae0.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*efLhSI6OrltdTDJEbhP9sg.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx mu di mv mw translated">BIgGAN架构，分别用于128x128、256x256、512x512图像生成。</figcaption></figure></div><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es mx"><img src="../Images/f633be2bb2ce0b38625e68fa3652cb81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hNQWQpIAGqYe106ADqmccA.png"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">分别为生成器架构、G剩余块、D剩余块架构。</figcaption></figure><p id="a934" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面关于BigGAN模型架构的图总结了完整的管道。潜在向量z和类嵌入被连接并馈入生成器中的每个残差块。每个剩余块基本上由两个卷积和一个跳跃连接组成。类嵌入连接在鉴别器的最后一层之前。</p><h2 id="1764" class="lp kc hh bd kd lq lr ls kh lt lu lv kl ip lw lx kp it ly lz kt ix ma mb kx mc bi translated">比根深海</h2><div class="jl jm jn jo fd ab cb"><figure class="mm jp my mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><img src="../Images/31024e060d1b6f1fe52c82d2fe9b119e.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*JzsWKY95fdfuHWY1mI7Vxg.png"/></div></figure><figure class="mm jp mz mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><img src="../Images/7519e3c3919a04e7dec73e9f63b7c2a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*2GBctQCay5esyjv50_UkwA.png"/></div></figure><figure class="mm jp na mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><img src="../Images/b0780496a63fb3aecb14c1c516c3418b.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/1*UvjpiZiu8Wa8AJKonX2jUg.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx nb di nc mw translated">BIgGAN-deep架构，分别用于128x128、256x256、512x512图像生成。</figcaption></figure></div><div class="ab cb"><figure class="mm jp nd mo mp mq mr paragraph-image"><img src="../Images/fa336be6bf3ef04be06d7f90a72caed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:324/format:webp/1*4SkQHa9E7qo_rzobpEe4jQ.png"/></figure><figure class="mm jp ne mo mp mq mr paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><img src="../Images/4e4ba9cd0b2f4ae6bbe272c8c7ad302a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1520/format:webp/1*vgE0GwfSdMdh2f2GzT6YoA.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx nf di ng mw translated">分别为生成器架构、G剩余块、D剩余块架构。</figcaption></figure></div><p id="1d21" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文还提出了原始模型的一个更深层次的变体:BigGAN-deep。残差块结构变得更加复杂，具有4个卷积，残差块的数量增加了一倍，导致模型深度增加了大约4倍。如下表所述，这个修改版本显示了IS/FID的显著增加，并显示了GANs也从增加深度中受益。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es nh"><img src="../Images/f0e4b80647704aabfe5933884eda4a60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LuHu-J2z_2FKeRZcI-_4dg.png"/></div></div></figure><h2 id="d33d" class="lp kc hh bd kd lq lr ls kh lt lu lv kl ip lw lx kp it ly lz kt ix ma mb kx mc bi translated">评估不稳定性</h2><p id="cead" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip mg ir is it mh iv iw ix mi iz ja jb ha bi translated">本文实验了各种情况下的模式崩溃，并观察了D和超参数配置的各种约束的训练曲线。这在论文的大部分和附录中有详细的阐述，我强烈推荐阅读原文。可以读到关于G和D在训练期间和在模式崩溃时的行为的有趣见解。</p><blockquote class="ni nj nk"><p id="edaf" class="ie if nl ig b ih ii ij ik il im in io nm iq ir is nn iu iv iw no iy iz ja jb ha bi translated">作者引用</p><p id="4ed5" class="ie if nl ig b ih ii ij ik il im in io nm iq ir is nn iu iv iw no iy iz ja jb ha bi translated">我们还观察到，在训练期间，D的损失接近于零，但在崩溃时会急剧上升。 <strong class="ig hi">这种行为的一种可能解释是D对训练集过度拟合，</strong>记忆训练实例而不是学习真实和生成图像之间的一些有意义的边界。作为对D的记忆的简单测试，我们在ImageNet训练和验证集上评估未崩溃的鉴别器，并测量被分类为真实或生成的样本的百分比。虽然训练准确率始终在98%以上，但验证准确率却在50–55%之间，不比随机猜测好多少。<strong class="ig hi">这证实了D确实在背训练集；</strong>我们认为这符合D的角色，D的角色不是明确地进行概括，而是提取训练数据，并为g提供有用的学习信号。</p><p id="9d22" class="ie if nl ig b ih ii ij ik il im in io nm iq ir is nn iu iv iw no iy iz ja jb ha bi translated"><strong class="ig hi">我们发现稳定性不仅仅来自G或D，而是来自他们在对抗训练过程中的相互作用</strong>。虽然他们状态不佳的症状可以用来跟踪和识别不稳定性，但确保合理的状态对于训练来说是必要的，但不足以防止最终的训练崩溃。通过强约束D来加强稳定性是可能的，但是这样做会导致巨大的性能损失。使用当前的技术，<strong class="ig hi">可以通过放松这种调节并允许在训练的后期阶段发生崩溃来实现更好的最终性能，此时模型已经得到充分的训练以实现良好的结果。</strong></p></blockquote><h1 id="5473" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">摘要</h1><p id="430f" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip mg ir is it mh iv iw ix mi iz ja jb ha bi translated">在本文中，我们回顾了在训练BigGAN生成大规模图像时使用的各种方法。我们回顾了以下技术:</p><ul class=""><li id="c03c" class="kz la hh ig b ih ii il im ip np it nq ix nr jb lg lh li lj bi translated">铰链损耗</li><li id="3df3" class="kz la hh ig b ih lk il ll ip lm it ln ix lo jb lg lh li lj bi translated">自我注意机制</li><li id="ccf6" class="kz la hh ig b ih lk il ll ip lm it ln ix lo jb lg lh li lj bi translated">条件批处理规范化</li><li id="b160" class="kz la hh ig b ih lk il ll ip lm it ln ix lo jb lg lh li lj bi translated">扩大模型规模的能力(批量大小、深度、渠道)</li><li id="1c8b" class="kz la hh ig b ih lk il ll ip lm it ln ix lo jb lg lh li lj bi translated">截断技巧</li><li id="b85c" class="kz la hh ig b ih lk il ll ip lm it ln ix lo jb lg lh li lj bi translated">BigGAN/BigGAN-deep建筑</li></ul><p id="49dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还了解到GAN培训中存在的问题</p><ul class=""><li id="43aa" class="kz la hh ig b ih ii il im ip np it nq ix nr jb lg lh li lj bi translated">鉴别器在训练图像上过度拟合，因此不能向发生器提供有意义的信号。</li><li id="e837" class="kz la hh ig b ih lk il ll ip lm it ln ix lo jb lg lh li lj bi translated">在不约束D的情况下，模式崩溃是不可避免的，并且必须是可能的，这将导致性能下降。</li></ul></div></div>    
</body>
</html>