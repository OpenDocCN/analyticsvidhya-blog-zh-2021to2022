<html>
<head>
<title>Review — A Human-Computer Duet System for Music Performance (Automatic Accompaniment)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">音乐表演人机对唱系统(自动伴奏)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/review-a-human-computer-duet-system-for-music-performance-automatic-accompaniment-572ccbeb014e?source=collection_archive---------24-----------------------#2021-03-08">https://medium.com/analytics-vidhya/review-a-human-computer-duet-system-for-music-performance-automatic-accompaniment-572ccbeb014e?source=collection_archive---------24-----------------------#2021-03-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="8bdd" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">与人合作演奏，自动产生小提琴音乐。</h2></div><p id="84a2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这篇文章中，<strong class="iy hi">介绍了一个由中央研究院开发的用于音乐表演的人机对唱系统</strong>【1】。在本文中:</p><ul class=""><li id="d870" class="js jt hh iy b iz ja jc jd jf ju jj jv jn jw jr jx jy jz ka bi translated"><strong class="iy hi">一个虚拟小提琴家</strong>被创造出来，他可以和人类钢琴家一起演奏室内乐<strong class="iy hi">不需要任何干预</strong>。</li><li id="cee9" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">提议的系统<strong class="iy hi">已经在一场公开音乐会</strong>上表演过。</li><li id="9eba" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">对系统的有效改进进行了讨论。</li></ul><p id="7b1a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这项工作得到了该研究所的自动音乐音乐会动画(AMCA)项目的支持。</p><h1 id="8dca" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">概述</h1><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ky"><img src="../Images/f6f2c2ca128698bcda8d991e1a4e9dda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*q4zzGiN16WaoikTb.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">自动音乐会动画系统插图。</figcaption></figure><ol class=""><li id="26a1" class="js jt hh iy b iz ja jc jd jf ju jj jv jn jw jr lo jy jz ka bi translated">提议的虚拟音乐家系统</li><li id="bfd0" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr lo jy jz ka bi translated">实时音乐跟踪</li><li id="90aa" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr lo jy jz ka bi translated">自动动画</li><li id="2da9" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr lo jy jz ka bi translated">讨论</li></ol><h1 id="acbd" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">1.提议的虚拟音乐家系统</h1><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lp"><img src="../Images/4ca26653678456dd7bb4429856991f9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kGb35etFxMewgNCB.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">提议的虚拟音乐家动画和互动系统。</figcaption></figure><ul class=""><li id="fde9" class="js jt hh iy b iz ja jc jd jf ju jj jv jn jw jr jx jy jz ka bi translated">该系统具有同步参考、排练和现场内容的能力。</li><li id="c55f" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">开始时，要和虚拟小提琴手一起演奏的人选择一首乐曲。</li><li id="9da5" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">使用离线DTW算法对准参考和现场钢琴音频。</li><li id="a11a" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">在现场演奏中，实时音乐跟踪器<strong class="iy hi">在在线DTW (ODTW)校准的帮助下跟踪现场钢琴音频</strong>。</li><li id="5c4f" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">音乐跟踪器然后创建视觉动画和声音合成，以便生成虚拟小提琴手的身体运动和小提琴音乐。</li><li id="1cf1" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">自动动画使用两种生成运动的方法:姿态估计和音乐到运动的生成技术。</li><li id="bd0b" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">最后，用实时声音合成器和动画制作工具渲染虚拟小提琴手的声音和动作。</li></ul><h1 id="f85d" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">2.实时音乐跟踪</h1><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lq"><img src="../Images/b63ad2420cecfd89286b85222f8a988c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lMWqBDLXxCOAS0HH.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">实时音乐跟踪系统。</figcaption></figure><ul class=""><li id="4104" class="js jt hh iy b iz ja jc jd jf ju jj jv jn jw jr jx jy jz ka bi translated">Arzt和Widmer [2，3]重新实现了T10“任何时间”音乐跟踪器T11。</li><li id="c518" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">当演出开始时，音乐检测器开始跟踪。</li><li id="4e3f" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">粗略位置估计器返回符合排练钢琴的现场钢琴信号的可能位置的集合。</li><li id="85f3" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">决策者选择一个ODTW线程作为最可信的线程，然后输出跟踪结果。</li></ul><h1 id="641a" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">3.自动动画</h1><ul class=""><li id="04e9" class="js jt hh iy b iz ls jc lt jf lu jj lv jn lw jr jx jy jz ka bi translated">通过使用[4]提取violinistsâăź15身体关节的3d位置来完成姿态估计。</li><li id="debc" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">毫不奇怪，身体运动生成需要一个包含音频以及小提琴演奏的姿势内容的数据集来建模音乐到身体运动的对应关系。</li><li id="03ee" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">说到产生运动，他们将音频到身体(A2B)动力学的框架扩展到三维空间，如下所示。</li></ul><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lx"><img src="../Images/427237743e04c6ac127022feaf3033ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-2-P0hOJQn8JJtkU.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">身体运动生成综述。</figcaption></figure><h1 id="90f4" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">4.讨论</h1><h2 id="8bf1" class="ly kh hh bd ki lz ma mb km mc md me kq jf mf mg ks jj mh mi ku jn mj mk kw ml bi translated">实时音乐跟踪评估</h2><ul class=""><li id="8beb" class="js jt hh iy b iz ls jc lt jf lu jj lv jn lw jr jx jy jz ka bi translated">直觉上是用以下程序测量在线音乐跟踪和现场录音的<em class="lr">离线校准之间的偏差:</em></li></ul><ol class=""><li id="a99a" class="js jt hh iy b iz ja jc jd jf ju jj jv jn jw jr lo jy jz ka bi translated">使用多通道录音设备来录制现场钢琴和小提琴音频。</li><li id="d40e" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr lo jy jz ka bi translated">如下所示，通过离线同步将录制的现场钢琴与参考钢琴MIDI的时间映射进行比较。</li><li id="d8e3" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr lo jy jz ka bi translated">也通过离线同步比较现场小提琴和估计小提琴的时间映射。</li></ol><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mm"><img src="../Images/f487bf21826720dd44f3870ffdc5b9f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sZk7FdMu_fgyjqLn.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">在120 BPM的样本上评估实时音乐跟踪系统的概念图。圆圈表示节拍位置，用垂直虚线连接的圆圈是同步的。注意，同步结果决定了小提琴声部应该如何演奏(即，估计的小提琴声部)。</figcaption></figure><ul class=""><li id="b606" class="js jt hh iy b iz ja jc jd jf ju jj jv jn jw jr jx jy jz ka bi translated">他们使用以下四个标准进行评估:</li></ul><p id="cff0" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">1.正常速度(115–145 BPM)</p><p id="82e3" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">2.低速(90–120 BPM)</p><p id="29a2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">3.快速(135–175 BPM)</p><p id="83a9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">4.加速从80bpm左右开始，到160 bpm结束</p><ul class=""><li id="39df" class="js jt hh iy b iz ja jc jd jf ju jj jv jn jw jr jx jy jz ka bi translated">对于所有这四种情况，系统采取了大约四种措施来与现场钢琴同步。一旦它与人类钢琴家同步，偏差值为0.25拍。</li><li id="ceab" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">此外，我们可以观察到速度的突然改变并不总是导致延迟的改变。</li></ul><h2 id="27e2" class="ly kh hh bd ki lz ma mb km mc md me kq jf mf mg ks jj mh mi ku jn mj mk kw ml bi translated">身体运动生成评估</h2><ul class=""><li id="d2dc" class="js jt hh iy b iz ls jc lt jf lu jj lv jn lw jr jx jy jz ka bi translated">该模型在包含140个小提琴独奏视频的数据集上进行训练和评估，视频总长度为11小时。</li><li id="b642" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">为了训练，他们从其中一个小提琴手那里选择视频，并进行14重交叉验证来训练14个模型。</li><li id="c1c5" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">每个模型都是在被遗漏的部分上进行评估的(对于该折叠分区)。</li><li id="37cf" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">结果是由小提琴手的数量来平均的。</li><li id="da67" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">L1距离和弓形攻击F1分数用于度量。</li><li id="8007" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">L1距离由生成的节理和地面真实节理之间的距离定义。</li><li id="271c" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">在本文中，弓形攻击是指弓形方向改变的时刻。</li><li id="6788" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">在他们识别出弓形攻击的所有真阳性、假阳性和假阴性之后，他们计算F1分数。</li><li id="8df2" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">我们可以观察到F1分数比基线好得多，这意味着该模型是有效的。</li><li id="01f3" class="js jt hh iy b iz kb jc kc jf kd jj ke jn kf jr jx jy jz ka bi translated">还有两个改进:右手位置的偏差和弓击的时机。</li></ul><h1 id="672a" class="kg kh hh bd ki kj kk kl km kn ko kp kq in kr io ks iq kt ir ku it kv iu kw kx bi translated">参考</h1><p id="f88a" class="pw-post-body-paragraph iw ix hh iy b iz ls ii jb jc lt il je jf mn jh ji jj mo jl jm jn mp jp jq jr ha bi translated">[1]<a class="ae mq" href="https://arxiv.org/abs/2009.07816" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2009.07816</a></p><p id="0d7f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[2]安德烈亚斯·阿尔兹特和格哈德·威德默。用于实时音乐跟踪的简单速度模型。在2010年声音和音乐计算会议(SMC)的会议录中</p><p id="29f0" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[3]安德烈亚斯·阿尔兹特和格哈德·威德默。实现有效的“随时”音乐跟踪。《第五届人工智能研究者研讨会论文集》，2010年，第24页。</p><p id="4033" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[4]达里奥·帕夫洛、克里斯托弗·费希滕霍费尔、戴维·格兰吉尔和迈克尔·奥利。基于时间卷积和半监督训练的视频三维人体姿态估计。IEEE计算机视觉和模式识别会议(CVPR)论文集，第7753-7762页，2019年。</p><p id="4d75" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[5] Eli Shlizerman、Lucio Dery、Hayden Schoen和Ira Kemelmacher-Shlizerman。音频到身体动力学。《IEEE计算机视觉和模式识别会议论文集》(CVPR)，第7574–7583页，2018年。</p></div><div class="ab cl mr ms go mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ha hb hc hd he"><p id="a379" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="lr">原载于2021年3月8日</em><a class="ae mq" href="https://cuda-chen.github.io/paper%20review/2021/03/08/review-a-human-computer-duet-system-for-music-performance.html" rel="noopener ugc nofollow" target="_blank"><em class="lr">https://cuda-Chen . github . io</em></a><em class="lr">。</em></p></div><div class="ab cl mr ms go mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ha hb hc hd he"><blockquote class="my mz na"><p id="6b43" class="iw ix lr iy b iz ja ii jb jc jd il je nb jg jh ji nc jk jl jm nd jo jp jq jr ha bi translated"><em class="hh">如果你有什么想法和问题要分享，请联系我</em><a class="ae mq" href="http://clh960524@gmail.com/" rel="noopener ugc nofollow" target="_blank"><strong class="iy hi"><em class="hh">clh 960524【at】Gmail . com</em></strong></a><em class="hh">。还有，其他作品可以查看我的</em> <a class="ae mq" href="https://github.com/Cuda-Chen" rel="noopener ugc nofollow" target="_blank"> <em class="hh"> GitHub资源库</em> </a> <em class="hh">。如果你和我一样热衷于机器学习、图像处理和并行计算，欢迎在LinkedIn上</em> <a class="ae mq" href="https://www.linkedin.com/in/lu-hsuan-chen-78071b171/" rel="noopener ugc nofollow" target="_blank"> <em class="hh">加我</em> </a> <em class="hh">。</em></p></blockquote></div></div>    
</body>
</html>