# 用 Keras 调谐器超调谐 LSTM 预报太阳辐照度

> 原文：<https://medium.com/analytics-vidhya/hypertuning-a-lstm-with-keras-tuner-to-forecast-solar-irradiance-7da7577e96eb?source=collection_archive---------0----------------------->

![](img/695aa9562cd57ca41b83d25fbde745e6.png)

努诺·马克斯在 [Unsplash](https://unsplash.com/s/photos/photovoltaic?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄的照片

# 项目概述

你们大多数人已经知道，光伏能源和可再生能源的主要问题之一是这些技术生产的不确定性。这个问题使得很难将它们集成到网格中。如果你有电气工程方面的背景，你就会知道，为了避免电网上的问题，我们必须在每时每刻使能源的生产和消耗相匹配。如果不这样做，电网就会变得不稳定。

当我们使用传统的发电厂时，我们可以随心所欲地调度能源。然后，电网运营商只需预测电力消耗，并相应地调整电厂。但是，当我们引进可再生能源时，我们不能随心所欲地使用它们。因此，为了安排和协调所有不同的能源以可靠的方式供应能量，我们需要估计可再生能源的产量。

# 预测太阳辐照度

在我的项目中，我使用了由 [PVGIS](https://re.jrc.ec.europa.eu/pvg_tools/es/#TMY) 提供的数据集，它包含了一整年每小时的气象数据。

我将使用过去 10 天(240 步)的数据来预测第二天(24 步)的太阳辐照度。

# LSTM 概述

近年来，LSTM 网络已经成为一种非常流行的时间序列预测工具。有些人认为没有那么好，而且有过度拟合的倾向。正如生活中的一切，我认为没有银弹，所以你总是要尝试不同的模式，以选择正确的。

![](img/98e835adac456ab74c518b877dbb07b3.png)

照片由 [Alina Grubnyak](https://unsplash.com/@alinnnaaaa?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 在 [Unsplash](https://unsplash.com/s/photos/neural-network?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 上拍摄

# 什么是 LSTM？

长短期记忆是一种递归神经网络(RNN)架构。RNN 主要用于处理序列数据(文本、自然语言或图像字幕)和时间序列预测。它们与前馈或卷积网络的主要区别在于，它们有某种“记忆”。rnn 将输出作为输入反馈，使输出依赖于先前的事件。

# 为什么是 LSTM？

RNN 背后的想法是建立一个能够学习使用过去信息的神经网络。当有用的信息及时接近时，RNN 可以做这项工作。但是如果我们需要回到更早的时候，RNN 失败了，这就是 LSTM 发挥作用的地方。LSTMs 能够保留重要的信息，不介意回到过去，忘记无用的信息。

另一方面，如果我们将其与传统的统计技术相比较。LSTM 允许捕捉传统技术难以捕捉的复杂模式。例如，太阳辐照度有多个季节(一天一次和一年一次)。比如说，捕捉 ARIMA 的多重季节性可能会很成问题。

如果你想更多地了解 LSTM，请看那篇文章。

# 什么是超调，为什么它很重要？

在每个机器学习算法中，我们都有参数和超参数。参数由算法本身通过训练来学习。另一方面，超参数由用户手动设置。

如果你熟悉神经网络，你会意识到没有明确的指导方针或任何正式的程序来设计和选择神经网络超参数。所以，通常使用试错法和直觉。

为了使这一过程更加有效，Keras 开发了一个 hypertuner，它基本上允许您轻松地配置空间搜索，您将在其中部署搜索算法，以找到最佳的超参数组合。

# 放弃

在这篇文章中，我将专注于构建神经网络。但是，不要忘记在开始构建模型之前分析您的数据。知道你正在处理的数据总是好的。

# 让我们编码

首先，我们必须导入我们将使用的所有模块和包。它可能会根据您的项目需求而变化。

# 数据加载

然后，我们将加载数据集并清理数据。我们不会谈论数据清理，因为它错过了教程的要点。

# 数据分割

一旦我们有了数据，我们将把它分成训练集和验证集。如前所述，我们想做提前 24 小时的预测。因此，我们将拆分数据，使两个集合都由全天组成。

# 将其转化为监督学习

然后，我们必须将数据转换成有监督的学习形式。这个概念有点复杂。

在监督学习问题中，我们有一个输入(X)和一个输出(Y ),我们的机器学习算法的任务是找到一个将输入映射到输出的函数。

当我们处理时间序列时，我们有一个离散的数据集合。因此，我们必须将这些数据重新组织成输入输出对的集合。为此，我们将使用前面的时间步骤作为输入变量，下一步作为输出变量。

让我们用一个例子来说明这一点，我们有以下时间序列:

我们可以通过以下方式将其重新定义为监督学习问题:

这是一个简单的例子，当我们进行多变量和多步预测时，情况变得更加复杂，正如我的项目中的情况一样。

如果你不熟悉这个概念，我强烈建议你在继续之前阅读这篇文章。

为了重新构造数据集，我使用了以下函数:

# 缩放数据

神经网络在处理大规模数据时工作得更好，收敛得更快。有很多文章解释了背后的数学原理。对于我的应用程序，我使用了由 *sklearn，*提供的 MinMax 定标器，但是你可以使用更复杂的定标器。

在函数 *scale_data* 中，我们将训练集和验证集作为参数。然后，我们为特征创建一个缩放器，为目标创建另一个缩放器。我们缩放数据，并返回我们使用的缩放数据集和缩放器作为输出。

请不要将培训和测试集放在一起。它会将测试信息泄漏回列车测试。正确的做法是仅使用训练集来构建缩放器，并使用相同的缩放器来缩放测试数据。

请注意保存您的缩放器，因为在算法部署阶段，您将需要它来缩放流数据。

# 放在一起！！！

现在，我们已经构建了所有需要的函数。是时候把这些放在一起开始训练我们的神经网络了。

# Keras 调谐器

到目前为止，我们没有做什么特别的事情。我们刚刚准备好数据，准备接受神经网络的训练。但是，现在我们要应用 Keras 调谐器魔术！！！

首先，我们必须创建一个函数来定义我们的模型[空间搜索](https://en.wikipedia.org/wiki/State_space_search)。

在这里，我将尝试分解代码，使其尽可能易于理解。

我们要做的第一件事是实例化 *Sequential()，*这将是我们的堆栈层。

我使用了一个 n_layers x LSTM+ Dropout + Dense 的架构，但是你也可以使用其他的。您可能已经注意到，选择架构是一件棘手的事情，需要进行超参数调整。

# 什么是“惠普”？

*Hp* 是我们传递给建模函数的对象，它允许我们定义超参数的空间搜索。

# 第一 LSTM 层

设置第一个 LSTM 层有点棘手。当我们将我们的时间序列重新构建为监督学习问题时，我们创建了一个 3D 数组。第一个维度是输入-输出对的数量，它是由层本身推断的。第二维是向后的步数，例如，我使用了前 10 天的数据(240 步)，第三维是使用的标签数，在我的例子中是 8(温度、辐照度、压力等。).第二和第三维必须明确设置在第一 LSTM 层(第 3 行)。

另一个重要的事情是设置 *return_sequences* 为**真**，**假**为默认值。当我们将 *return_sequences* 设置为**真时，**使输出可用于另一个 LSTM。如果下一层不是 LSTM，就让*的 return_sequences* 保持默认值。

如果你想了解更多，请查看[帖子](https://machinelearningmastery.com/stacked-long-short-term-memory-networks/)。

# 选择神经元的数量

没有办法知道一层应该有多少神经元。这就是为什么我们使用 *hp* 对象来定义超参数的取值范围。

在上面的代码中，我们告诉调谐器使用 32 到 512 之间的值，步长为 32。

# 选择层数

与神经元的数量一样，没有办法知道最佳的层数，这就是为什么我们在 for 循环中插入了一个 *hp.int()* 。

这里，每个试验范围()将采用一个新值。例如，第一次迭代“n_layer”可能取值 1，这意味着循环将具有范围(1)，因此我们将添加 1 个 LSTM 层，或者可以取值 4 并添加 4 个层。

# 脱落层

为了避免过度拟合神经网络，我们添加了一个辍学层。脱落层随机隐藏神经元，隐藏的神经元数量由脱落率设置。如果退出率为 0.5，则退出层将在每次迭代中隐藏一半的神经元。

为了找到正确的辍学率，我们将使用 *hp.float()* :

直观地说，你可能会注意到它的工作方式类似于 *hp.int()* ，我们设置一个值的范围，并设置一个步长，然后调谐器将根据选择的搜索算法从该范围中选择值。

# **密集层和激活功能**

在大多数 LSTM 深度学习架构中，都有一个最终的密集层。在我的例子中，我必须选择一个激活函数来确保正值(负辐照度是没有意义的)。为了确保正值，我选择使用 relu 或 sigmoid 激活函数。像往常一样，没有办法知道哪一个会表现得更好。但对我们来说幸运的是，Keras Tuner 为我们提供了 *hp.choice()* ，它允许我们设置一个可能的选择列表，从中可以获取值。

在上面的代码中，我告诉密集层我想要的输出数量( *Y_train.shape[1]* )，并且我将激活函数设置为 relu 或 sigmoid。记住 *Y_train.shape[1]* 是 24，也就是一整天。

# 编译模型

一旦我们建立了模型，我们必须编译它。我们必须设置 3 个参数:

*   *Loss:* 它定义了我们将在训练阶段用来测量模型误差的指标
*   *Optimizer:* 它定义了我们将用来改变输入权重的优化技术。这是一个棘手的概念，如果你想知道更多，请看这篇文章。
*   *指标:*这是我们将用来评估我们的模型的指标，类似于*损失*，但在培训期间不使用。

# 创建调谐器对象

现在，我们已经定义了模型构建函数，我们可以创建一个 tuner 对象。当我们创建一个 tuner 对象时，我们将设置将要部署的搜索算法。

出于简单起见，我决定使用随机搜索，但是你也可以选择其他的(代码可能会有一点变化)，但是[文档](https://keras.io/api/keras_tuner/tuners/)非常清楚。你不应该有问题。

然后，在类内部，我们必须设置一些参数。

我们必须通过一个超模(我们刚刚创建的建模函数)。我们必须设定“目标”，这是搜索算法将用来评估每个模型试验的指标。当我们在处理一个预测问题时，我使用 MSE 作为一个度量。

现在，有两个参数我在开始时很难理解，但实际上非常简单。

*   *max_trials:* 搜索算法将尝试的超参数组合的数量。正如你可能注意到的，尝试每一种可能的组合是不现实的，所以你设置你希望搜索算法尝试多少种组合。
*   *execution_per_trial:* 您可能知道，神经网络具有显著的随机成分，即您可以用相同的数据训练相同的神经网络，并得到略有不同的模型。因此，如果您正在寻找尽可能最佳的准确性，您可能需要多次重新训练相同的神经网络架构，直到您找到最佳架构。

一旦我们创建了 tuner 对象，我们就可以使用方法 search 来查找最佳模型。

如果你熟悉神经网络，你应该知道什么是 epochs 和 batch_size，如果不是看这篇文章。

# 获得最佳模型

搜索完成后(可能需要很长时间)。我们准备得到最好的模型。

现在我们有了自己的模型，我将向你展示如何使用*预测*方法。

*X_test[0]* 是一个 2D 数组，有 240 个值(10 天数据)和 8 个特征(气象特征)。如你所知，LSTM 只接受 3D 数组，因此我们必须改变形状 *X_test[0]* 来得到一个 3D 数组。

# 保存模型和缩放器

如果您已经建立并开发了一个神经网络，您可能希望保留该模型，以便以后使用或部署它。

我会建议将其保存为. h5 文件。

正如我之前提到的，您应该保存您在训练阶段使用的缩放器，以便在流数据之后使用。我会推荐把它当泡菜保存。

# 结论

我写这篇文章的主要目的是让大家了解如何使用 Keras Tuner 以及如何在深度学习环境中使用 LSTM 图层。