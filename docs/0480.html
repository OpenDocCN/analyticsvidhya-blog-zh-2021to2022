<html>
<head>
<title>LeNet with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带张量流的LeNet</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/lenet-with-tensorflow-a35da0d503df?source=collection_archive---------2-----------------------#2021-01-18">https://medium.com/analytics-vidhya/lenet-with-tensorflow-a35da0d503df?source=collection_archive---------2-----------------------#2021-01-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ddd3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LeNet被认为是卷积神经网络的祖先，并且是计算机视觉社区中的一个众所周知的模型。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/7766ca2cee50be68c989add12b775df7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/0*u-yUNdr5JhIDgmYs"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">数字识别网络</figcaption></figure><h2 id="c632" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">介绍</h2><p id="b9dc" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">LeNet是最基本的深度学习模型之一，主要用于对手写数字进行分类。LeNet由Yann LeCun[1]于1989年提出，是最早采用卷积运算的神经网络之一。LeCun等人将新开发的反向传播算法与卷积神经网络相结合，成为了使用深度学习进行图像分类的先驱。LeNet这个名称通常与LeNet-5互换使用，LeNet-5表示卷积掩码的内核大小。</p><p id="fbf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本教程旨在让初学者在MNIST数据集上演示LeNet的基本TensorFlow实现。相关论文的参考资料分享在博客文章的末尾。为了更好地理解基本概念，您可以浏览这些视频:</p><p id="2237" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">反向传播:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kp kq l"/></div></figure><p id="251b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷积神经网络；</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kp kq l"/></div></figure><h2 id="0017" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">带张量流的LeNet</h2><p id="52c7" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">Tensorflow是最受欢迎的深度学习框架之一，它使机器学习爱好者能够与通用原型模型一起工作。虽然在没有检查某些设计选择的结果的情况下，通过TensorFlow的默认设置来建立模型不是一个好习惯，但Keras(一个在TensorFlow后端执行的深度学习库)在正确使用时可以非常容易地测试灵活的模型。</p><p id="ea21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">无需进一步介绍，我们可以直接使用TensorFlow实现LeNet。代码被写成一个Jupyter笔记本[5]由Google Colab[6]托管。整个笔记本的链接在References部分之前共享。为了利用谷歌的免费GPU进行计算，请遵循:<em class="kr">运行时间&gt;更改运行时间&gt;硬件加速器:您的Colab笔记本中的GPU </em>。</p><p id="103a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，导入所需的库。TensorFlow和Matplotlib分别用于设计网络和可视化结果。此外，Keras提供了某些架构和训练模板以及通用数据集，使用起来非常方便。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="f200" class="jp jq hi kt b fi kx ky l kz la"><strong class="kt hj">import</strong> <strong class="kt hj">tensorflow</strong> <strong class="kt hj">as</strong> <strong class="kt hj">tf</strong><br/><strong class="kt hj">import</strong> <strong class="kt hj">matplotlib.pyplot</strong> <strong class="kt hj">as</strong> <strong class="kt hj">plt</strong><br/><strong class="kt hj">from</strong> <strong class="kt hj">tensorflow.keras</strong> <strong class="kt hj">import</strong> datasets, layers, models, losses</span></pre><p id="e407" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kr">数据</em> </strong></p><p id="228e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在导入库之后，通过一行代码下载数据集。注意以如下的正确格式获取输出:</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="2e8b" class="jp jq hi kt b fi kx ky l kz la">x_train,y_train),(x_test,y_test) = datasets.mnist.load_data()<br/>x_train.shape</span><span id="7657" class="jp jq hi kt b fi lb ky l kz la">(60000, 28, 28)</span></pre><p id="e892" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">原始LeNet模型接收32×32的图像，因此28×28的MNIST图像用零填充，并且8位(0-255范围)像素值在0和1之间缩放:</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="b4fb" class="jp jq hi kt b fi kx ky l kz la">x_train = tf.pad(x_train, [[0, 0], [2,2], [2,2]])/255<br/>x_test = tf.pad(x_test, [[0, 0], [2,2], [2,2]])/255<br/>x_train.shape</span><span id="4736" class="jp jq hi kt b fi lb ky l kz la">TensorShape([60000, 32, 32])</span></pre><p id="7efd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，大多数CNN接受4维张量作为输入，具有批量大小、高度、宽度和通道的维度。因为MNIST图像是灰度的，所以最后一个维度不一定存在。我们需要展开张量，在3号轴上创建一个虚拟维度。(回想一下，张量最初有轴0、1和2。)</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="742e" class="jp jq hi kt b fi kx ky l kz la">x_train = tf.expand_dims(x_train, axis=3, name=<strong class="kt hj">None</strong>)<br/>x_test = tf.expand_dims(x_test, axis=3, name=<strong class="kt hj">None</strong>)<br/>x_train.shape</span><span id="cc83" class="jp jq hi kt b fi lb ky l kz la">TensorShape([60000, 32, 32, 1])</span></pre><p id="faac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练集的最后2000个样本保留给验证集。验证集主要用于调整模型的超参数。测试集在最终评估之前从未使用过。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="6609" class="jp jq hi kt b fi kx ky l kz la">x_val = x_train[-2000:,:,:,:] <br/>y_val = y_train[-2000:] <br/>x_train = x_train[:-2000,:,:,:] <br/>y_train = y_train[:-2000]</span></pre><p id="7fbd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kr">型号</em> </strong></p><p id="8552" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LeNet的架构非常简单。有3个<em class="kr">卷积层</em>，每个卷积层具有5乘5的核，分别具有6、16和120个特征图。在这两者之间，有2个<em class="kr">子采样层</em>作为<em class="kr">平均池</em>。所有这5层都使用<em class="kr">步距</em> 1，平均池层使用2乘2 <em class="kr">内核</em>作为默认设置。在卷积层之后，使用<em class="kr">双曲正切非线性激活</em>，而子采样层之后是<em class="kr"> sigmoid非线性</em>。在最后一个卷积层之后，激活<em class="kr">变平</em>并馈入<em class="kr">具有84和10个神经元的全连接层</em>。最后一层的输出(在<em class="kr"> softmax </em>操作之后)代表输入图像的类别概率(从0到9)。</p><p id="ea63" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如今，<em class="kr"> tanh </em>和<em class="kr"> sigmoid </em>激活由于饱和问题很少使用。反而<em class="kr"> ReLU </em>和<em class="kr">漏ReLU </em>更受欢迎。此外，使用两个连续的3×3层代替单一的5×5层是更优选的，因为相同的感受野大小是通过相当少数量的可训练参数获得的。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="6f0f" class="jp jq hi kt b fi kx ky l kz la">model = models.Sequential()<br/>model.add(layers.Conv2D(6, 5, activation='tanh', input_shape=x_train.shape[1:]))<br/>model.add(layers.AveragePooling2D(2))<br/>model.add(layers.Activation('sigmoid'))<br/>model.add(layers.Conv2D(16, 5, activation='tanh'))<br/>model.add(layers.AveragePooling2D(2))<br/>model.add(layers.Activation('sigmoid'))<br/>model.add(layers.Conv2D(120, 5, activation='tanh'))<br/>model.add(layers.Flatten())<br/>model.add(layers.Dense(84, activation='tanh'))<br/>model.add(layers.Dense(10, activation='softmax'))<br/>model.summary()</span><span id="f40c" class="jp jq hi kt b fi lb ky l kz la">Model: "sequential"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d (Conv2D)              (None, 28, 28, 6)         156       <br/>_________________________________________________________________<br/>average_pooling2d (AveragePo (None, 14, 14, 6)         0         <br/>_________________________________________________________________<br/>activation (Activation)      (None, 14, 14, 6)         0         <br/>_________________________________________________________________<br/>conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      <br/>_________________________________________________________________<br/>average_pooling2d_1 (Average (None, 5, 5, 16)          0         <br/>_________________________________________________________________<br/>activation_1 (Activation)    (None, 5, 5, 16)          0         <br/>_________________________________________________________________<br/>conv2d_2 (Conv2D)            (None, 1, 1, 120)         48120     <br/>_________________________________________________________________<br/>flatten (Flatten)            (None, 120)               0         <br/>_________________________________________________________________<br/>dense (Dense)                (None, 84)                10164     <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 10)                850       <br/>=================================================================<br/>Total params: 61,706<br/>Trainable params: 61,706<br/>Non-trainable params: 0</span></pre><p id="300e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型被设置为由<em class="kr">Adam</em>optimizer【7】进行优化。<em class="kr">稀疏分类交叉熵</em>测量真实分类概率的自然对数的负值。例如，如果模型的最终输出是诸如[0.03，0.78，…，0.05]的向量，并且输入图像的真实类别是1；这种情况下的损失将是-ln(0.78) = 0.248。<em class="kr">精度</em>度量是针对每个历元报告的。模型被训练40个<em class="kr">周期</em>，批量<em class="kr">为64 <em class="kr">的</em>。history </em>对象有一个名为<em class="kr"> history </em>的属性，用于跟踪训练阶段。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="46e7" class="jp jq hi kt b fi kx ky l kz la">model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])<br/>history = model.fit(x_train, y_train, batch_size=64, epochs=40, validation_data=(x_val, y_val))<br/></span><span id="4bba" class="jp jq hi kt b fi lb ky l kz la">Epoch 1/40 907/907 [==============================] - 11s 6ms/step - loss: 1.8860 - accuracy: 0.2950 - val_loss: 0.2266 - val_accuracy: 0.9450 <br/>Epoch 2/40 907/907 [==============================] - 4s 5ms/step - loss: 0.3354 - accuracy: 0.8943 - val_loss: 0.1769 - val_accuracy: 0.9490<br/>...<br/>Epoch 40/40 907/907 [==============================] - 5s 5ms/step - loss: 0.0375 - accuracy: 0.9875 - val_loss: 0.0428 - val_accuracy: 0.9915</span></pre><h2 id="eab9" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">结果</h2><p id="569e" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">训练集和验证集的损失和准确度存储在<em class="kr">历史</em>对象中，并使用Matplotlib库绘制。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="0f70" class="jp jq hi kt b fi kx ky l kz la">fig, axs = plt.subplots(2, 1, figsize=(15,15))  axs[0].plot(history.history['loss']) axs[0].plot(history.history['val_loss']) axs[0].title.set_text('Training Loss vs Validation Loss') axs[0].legend(['Train', 'Val'])  axs[1].plot(history.history['accuracy']) axs[1].plot(history.history['val_accuracy']) axs[1].title.set_text('Training Accuracy vs Validation Accuracy') axs[1].legend(['Train', 'Val'])</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lc"><img src="../Images/37fe631d535c5099ebc10a7fb0f08bef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wMh37U3zr6nABv3Td01g6A.png"/></div></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">训练集和验证集的损失和准确度</figcaption></figure><p id="7c24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该模型的测试准确率为98.51%，对于这个简单的任务来说，这是非常令人满意的，但略低于训练准确率。上图和测试精度表明，该模型能够学习数字绘图的模式，并具有足够的泛化能力，不会过拟合。</p><pre class="je jf jg jh fd ks kt ku kv aw kw bi"><span id="94c1" class="jp jq hi kt b fi kx ky l kz la">model.evaluate(x_test, y_test)</span><span id="650a" class="jp jq hi kt b fi lb ky l kz la">313/313 [==============================] - 1s 2ms/step - loss: 0.0468 - accuracy: 0.9851</span></pre><h2 id="cb3f" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">lenet_tensorflow.ipynb</h2><p id="f898" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">你可以在Github和Google Colab上不间断地查看整个笔记本。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lh kq l"/></div></figure><h2 id="38e1" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">结论</h2><p id="042b" class="pw-post-body-paragraph if ig hi ih b ii kk ik il im kl io ip iq km is it iu kn iw ix iy ko ja jb jc hb bi translated">当代CNN的目标远远超出了像MNIST分类这样的简单任务，然而，在像MNIST这样的公共数据集上分析像LeNet这样的基本模型以获得更复杂模型的潜在思想是不可或缺的。尝试复制简单的模型并获得相似的结果是深入新任务的良好开端。此外，检查这些模型的缺点同样重要和有用。在这篇文章中，LeNet架构是用TensorFlow解释和实现的。</p><p id="6326" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望你喜欢。以下CNN模特再见。</p><p id="8ecb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最美好的祝愿…</p><p id="b457" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">mrgrhn</p><p id="3eab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">后续帖子，请访问:</p><div class="li lj ez fb lk ll"><a href="https://mrgrhn.medium.com/alexnet-with-tensorflow-46f366559ce8" rel="noopener follow" target="_blank"><div class="lm ab dw"><div class="ln ab lo cl cj lp"><h2 class="bd hj fi z dy lq ea eb lr ed ef hh bi translated">带TensorFlow的AlexNet</h2><div class="ls l"><h3 class="bd b fi z dy lq ea eb lr ed ef dx translated">上一篇文章，请访问:</h3></div><div class="lt l"><p class="bd b fp z dy lq ea eb lr ed ef dx translated">mrgrhn.medium.com</p></div></div><div class="lu l"><div class="lv l lw lx ly lu lz jj ll"/></div></div></a></div><h2 id="3052" class="jp jq hi bd jr js jt ju jv jw jx jy jz iq ka kb kc iu kd ke kf iy kg kh ki kj bi translated">参考</h2><ol class=""><li id="92cc" class="ma mb hi ih b ii kk im kl iq mc iu md iy me jc mf mg mh mi bi translated">纽约州勒村；博瑟湾；登克，J. S。亨德森博士；霍华德；哈伯德，w。杰克尔法学博士(1989年12月)。“应用于手写邮政编码识别的反向传播”。<em class="kr">神经计算</em>。1(4): 541–551.</li><li id="f51a" class="ma mb hi ih b ii mj im mk iq ml iu mm iy mn jc mf mg mh mi bi translated">Yann le Cun(1989年6月)。“一般化和网络设计策略”。技术报告CRG-TR-89–4。多伦多大学计算机科学系。</li><li id="dbe0" class="ma mb hi ih b ii mj im mk iq ml iu mm iy mn jc mf mg mh mi bi translated">纽约州勒村；博瑟湾；登克，J. S。亨德森博士；霍华德；哈伯德，w。张天龙法学博士(1990年6月)。“用反向传播网络进行手写数字识别”。神经信息处理系统进展2:396–404。</li><li id="9194" class="ma mb hi ih b ii mj im mk iq ml iu mm iy mn jc mf mg mh mi bi translated">纽约州勒村；博图湖；纽约州本吉奥；哈夫纳，P. (1998年)。“基于梯度的学习应用于文档识别”。IEEE会议录。86 (11): 2278–2324.</li><li id="bc86" class="ma mb hi ih b ii mj im mk iq ml iu mm iy mn jc mf mg mh mi bi translated"><a class="ae mo" href="https://jupyter-notebook.readthedocs.io/en/stable/notebook.html" rel="noopener ugc nofollow" target="_blank">https://jupyter-notebook . readthedocs . io/en/stable/notebook . html</a></li><li id="55f3" class="ma mb hi ih b ii mj im mk iq ml iu mm iy mn jc mf mg mh mi bi translated">【https://colab.research.google.com/notebooks/intro.ipynb T4】</li><li id="1fb2" class="ma mb hi ih b ii mj im mk iq ml iu mm iy mn jc mf mg mh mi bi translated">金玛，迪德里克&amp;巴，吉米。(2014).“亚当:随机优化的方法”。学习表征国际会议。</li></ol></div></div>    
</body>
</html>