<html>
<head>
<title>K-Nearest Neighbors in a nutshell</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简而言之，k-最近邻</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/k-nearest-neighbors-in-a-nutshell-761464057775?source=collection_archive---------12-----------------------#2021-04-08">https://medium.com/analytics-vidhya/k-nearest-neighbors-in-a-nutshell-761464057775?source=collection_archive---------12-----------------------#2021-04-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/29a3e6a47e8e0bfa529620d29c972eab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*l48LxSSFzuc9nhY0nGyCgw.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx translated">k最近邻</figcaption></figure><blockquote class="ip iq ir"><p id="d392" class="is it iu iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">你是五个和你相处时间最长的人当中的平均T2。</p></blockquote><p id="55d2" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">上面的引用很好地总结了K-最近邻算法。唯一的区别是，在KNN，朋友的数量可能会有所不同。</p><p id="1c18" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">k-最近邻是一种非常简单但直观的机器学习算法，我们将深入研究这种算法的本质细节。</p><p id="0624" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated"><strong class="iv hi">什么是K近邻算法？</strong></p><p id="924e" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">k-最近邻是一种分类算法(也可用于回归),其基本原理是属于同一类的点应该彼此更靠近。让我们借助一个例子来理解这一点</p><figure class="jv jw jx jy fd ii er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es ju"><img src="../Images/969a4dfc54f3ecf9b6cdbf25618eabc5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*TOoV0i9oe6pKYZkaRxzUCw.jpeg"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">k-最近邻</figcaption></figure><p id="c165" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">假设我们有一个数据集，它有两个特征X1和X2，我们使用散点图来绘制数据点。在上图中，我们可以看到橙色的点属于类别1，蓝色的点属于类别2。</p><p id="831d" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">现在，一个新的数据点(即绿点)出现了，我们需要分类它是属于橙色类还是蓝色类。</p><p id="af82" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">现在我们执行以下步骤。</p><ol class=""><li id="b60f" class="kd ke hh iv b iw ix ja jb jr kf js kg jt kh jq ki kj kk kl bi translated">选择K值(此处为3)，即我们要考虑的离绿点最近的点的数量。</li><li id="692c" class="kd ke hh iv b iw km ja kn jr ko js kp jt kq jq ki kj kk kl bi translated">计算绿点与这些点的距离，找出K(这里是3)个最近的点。</li><li id="8fad" class="kd ke hh iv b iw km ja kn jr ko js kp jt kq jq ki kj kk kl bi translated">在找到K(这里是3)个最近的点之后，我们检查这些点属于哪一类。</li><li id="44ca" class="kd ke hh iv b iw km ja kn jr ko js kp jt kq jq ki kj kk kl bi translated">现在，我们的绿点将属于在所选最近点中具有最大点数的类别。</li></ol><p id="3514" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated"><strong class="iv hi">直觉</strong></p><p id="202c" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">K-最近邻背后的直觉是，与属于不同类别的点相比，属于同一类别的点应该彼此更接近<strong class="iv hi">。</strong></p><p id="1f56" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated"><strong class="iv hi">我该如何选择K？</strong></p><ul class=""><li id="b0df" class="kd ke hh iv b iw ix ja jb jr kf js kg jt kh jq kr kj kk kl bi translated">选择k的值是一个高度迭代的过程。</li><li id="90dd" class="kd ke hh iv b iw km ja kn jr ko js kp jt kq jq kr kj kk kl bi translated">您可以尝试K的多个值，并为每个K值计算预测的错误率。</li><li id="b18f" class="kd ke hh iv b iw km ja kn jr ko js kp jt kq jq kr kj kk kl bi translated">现在绘制K v/s误差率，并选择误差率最小的K值。</li></ul><p id="a2be" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated"><strong class="iv hi">我们如何计算点与点之间的距离？</strong></p><p id="007f" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">现在我们知道了K近邻是如何工作的。让我们看看如何计算两点之间的距离。在K-NN中最好有两种方法来测量距离。</p><ul class=""><li id="b9aa" class="kd ke hh iv b iw ix ja jb jr kf js kg jt kh jq kr kj kk kl bi translated"><strong class="iv hi">欧几里得和曼哈顿的距离</strong></li></ul><figure class="jv jw jx jy fd ii er es paragraph-image"><div class="er es ks"><img src="../Images/e8325f9611fb54240dcbf7c3ac890b6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*lTYhxn9o3H8g9twdEoyiRA.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">欧几里德距离和曼哈顿距离</figcaption></figure><ul class=""><li id="8961" class="kd ke hh iv b iw ix ja jb jr kf js kg jt kh jq kr kj kk kl bi translated">上面清楚地显示了欧几里德距离和曼哈顿距离</li><li id="16da" class="kd ke hh iv b iw km ja kn jr ko js kp jt kq jq kr kj kk kl bi translated">当数据维数过高时，曼哈顿距离优于欧几里德距离。</li></ul><p id="530e" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated"><strong class="iv hi">数据对KNN的影响</strong></p><ul class=""><li id="2ab9" class="kd ke hh iv b iw ix ja jb jr kf js kg jt kh jq kr kj kk kl bi translated">如果我们有高度不平衡的数据，那么我们的KNN模型将偏向于具有更多数据点的类。这是因为当我们计算最近邻时，大部分点很有可能属于具有更多数据点的类(随着K值的增加，这种可能性也会增加)。</li><li id="c81e" class="kd ke hh iv b iw km ja kn jr ko js kp jt kq jq kr kj kk kl bi translated">KNN对数据集中异常值的存在高度敏感。离群值会对我们的KNN模型的性能产生不利影响。</li></ul><p id="fabe" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated"><strong class="iv hi">KNN的实际应用</strong></p><ul class=""><li id="639e" class="kd ke hh iv b iw ix ja jb jr kf js kg jt kh jq kr kj kk kl bi translated"><strong class="iv hi">推荐系统:</strong> KNN被大量用于推荐系统，就像你在亚马逊、网飞等网站上看到的那种。KNN用于推荐与您搜索的类别最接近的组。</li><li id="f25c" class="kd ke hh iv b iw km ja kn jr ko js kp jt kq jq kr kj kk kl bi translated"><strong class="iv hi">概念搜索:</strong>概念搜索是基于根据您提供的查询从非结构化数据库中搜索相似项目的概念的搜索。</li></ul><p id="bd2d" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated"><strong class="iv hi">给你的作业</strong></p><ul class=""><li id="15d5" class="kd ke hh iv b iw ix ja jb jr kf js kg jt kh jq kr kj kk kl bi translated">了解如何使用scikit learn在我们的数据上实现KNN。</li><li id="78af" class="kd ke hh iv b iw km ja kn jr ko js kp jt kq jq kr kj kk kl bi translated">了解如何在回归问题中使用KNN。</li></ul><p id="eebd" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated"><strong class="iv hi">到那时快乐学习！</strong></p></div></div>    
</body>
</html>