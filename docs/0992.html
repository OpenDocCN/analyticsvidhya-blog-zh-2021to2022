<html>
<head>
<title>Classification in Click-Through Rate Prediction in Display Advertising</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">展示广告点击率预测中的分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/classification-in-click-through-rate-prediction-in-display-advertising-a487a03f8631?source=collection_archive---------9-----------------------#2021-02-09">https://medium.com/analytics-vidhya/classification-in-click-through-rate-prediction-in-display-advertising-a487a03f8631?source=collection_archive---------9-----------------------#2021-02-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/2c6b3cecf8eabc1af1cbaa3bb96b6368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*J5zAqfGq6cb5NVptHO8n7w.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx translated">CTR</figcaption></figure><h1 id="2d57" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated"><strong class="ak">简介</strong></h1><p id="782e" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi kl translated"><span class="l km kn ko bm kp kq kr ks kt di"> O </span>如今，在线展示广告是一项价值数十亿美元的业务，2016财年的年收入为317亿美元，比2015财年增长29%。展示广告努力解决的一个核心问题是在正确的时间，在正确的背景下，向正确的人投放正确的广告。准确预测点击率是解决这一问题的关键，在过去的几年里受到了广泛的关注。</p><blockquote class="ku kv kw"><p id="fe88" class="jn jo kx jp b jq ky js jt ju kz jw jx la lb ka kb lc ld ke kf le lf ki kj kk ha bi translated">CTR预测中涉及的数据通常是多字段分类数据，这些数据在除了显示广告之外的许多应用中也非常普遍，例如推荐系统。这种数据具有以下特性。首先，所有的特征都是分类的，并且非常稀疏，因为它们中的许多是标识符，因此，特征的总数很容易达到数百万。第二，每个特征属于一个且仅属于一个领域，可以有几十到几百个领域。</p></blockquote><p id="e1f9" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">多字段分类数据的特征显示了一些独特的挑战:</p><p id="a16a" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">1- <strong class="jp hi">特征交互很普遍，需要专门建模。</strong></p><p id="2f3e" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">来自一个领域的特征通常与来自其他不同领域的特征有不同的交互。</p><p id="6b8c" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">3- <strong class="jp hi">需要注意潜在的高模型复杂性。</strong></p><p id="46ab" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">根据这些提到的问题，通常常用的分类模型在这种数据上不能很好地运行。在本文中，首先，我们将解释我们的数据集的特点，其次，我们将实现一些著名的分类算法，如逻辑回归，SVM，随机森林，等等。</p><h1 id="0ec3" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">资料组</h1><p id="04b9" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">多亏了Yektanet(伊朗的一个数字广告平台),我们将要处理的数据集才得以呈现。数据集标记为“训练”的部分包含超过400万个数据。</p><p id="96ea" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">该数据集由14个特征+ 1个目标组成，即点击了的<strong class="jp hi">。拥有唯一<strong class="jp hi">【用户Id】</strong>的用户每次访问拥有<strong class="jp hi">【文档Id】</strong>的网页，都会有页面浏览量。对于每个页面视图，将产生一个唯一的<strong class="jp hi">‘显示Id’</strong>。在每个页面视图中，一些广告会同时显示给用户。<strong class="jp hi">‘时间戳’</strong>表示事件发生的时间。正如我们可以从标题中得知的那样，<strong class="jp hi">“一天中的某个小时”</strong>和<strong class="jp hi">“一周中的某一天”</strong>显示了事件发生的时间。每个广告内容由<strong class="jp hi">‘创意Id’，</strong>表示，并且这些内容中的每一个都属于由<strong class="jp hi">‘活动Id’</strong>表示的广告活动，每个活动属于由<strong class="jp hi">‘广告商Id’</strong>表示的广告商。每个用户使用一个特定的<strong class="jp hi">【设备】</strong>来访问一个网页。我们很容易识别出<strong class="jp hi">‘OS’</strong>栏表示用户使用的操作系统。<strong class="jp hi">‘浏览器’</strong>栏显示用户使用什么浏览器访问网页。每个广告显示在被称为窗口小部件的网页的特定部分，<strong class="jp hi">‘窗口小部件Id’</strong>指示网页的哪个部分被分配给该广告。每个网页都有一个<strong class="jp hi">‘发布者’</strong>和一个<strong class="jp hi">‘来源’</strong>。</strong></p><p id="a66d" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">你也可以把我们在这里做的所有工作用在其他免费的著名的CTR预测数据集上。由于版权问题，我们不能公布我们数据的内容。</p><h1 id="125b" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">数据清理</h1><p id="f5a7" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">首先，我们将看到大约10个数据样本，以确定我们正在处理的是什么:</p><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lg"><img src="../Images/8194e94e47897c441cc23b29de448a31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m-ZAqBnilhjy95r4TTXOvg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">数据样本</figcaption></figure><p id="f493" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">然后，您需要迭代所有要素并找到NaN或Null值:</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="ba0d" class="lu iq hh lq b fi lv lw l lx ly"><em class="kx">count_missing = df_train.isnull().sum()<br/>missing_value_df = pd.DataFrame({ ‘Count Missing’ : count_missing})<br/>missing_value_df</em></span></pre><p id="a72d" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">上面的代码片段将向我们展示，我们的数据集没有太多的清理问题:</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/faa6c5b53d9887bb3a6fe9a7c2b4796d.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/format:webp/1*5N69IcQiQ2EuuwSfFMI5WQ.png"/></div></figure><p id="5f7e" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">正如您所看到的，这里没有太多要讨论的，所以我们将只打印特性之间的相关性。我们想删除一些冗余的数据和列。这会让我们对将要做的事情有所了解。</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="b626" class="lu iq hh lq b fi lv lw l lx ly">cor = df_train.corr()</span><span id="5b47" class="lu iq hh lq b fi ma lw l lx ly">plt.figure(figsize=(15,15))</span><span id="ef18" class="lu iq hh lq b fi ma lw l lx ly">sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)</span><span id="5e8c" class="lu iq hh lq b fi ma lw l lx ly">plt.show()</span></pre><p id="24a9" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">上述代码片段的输出将类似如下:</p><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mb"><img src="../Images/b060eac32254f55ab82926ad598fa874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*knswdhKJNnIt0k66NmWphg.png"/></div></div></figure><p id="a667" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">如您所见，我们的一些特征高度相关，因此我们可以每对去掉一个。</p><p id="d7d6" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">例如，我们看到(' timestamp '，' display ')，(' source '，' publisher ')，(' os '，device ')'在这里是双绞线，我们将删除每个功能中的一个。但是正如我上面所描述的，我们可以在数据集描述中看到,“时间戳”和“显示Id”在数据集中是唯一的，我们可以将这一特征解释为索引，并删除这两个特征。</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="74b7" class="lu iq hh lq b fi lv lw l lx ly">drop_columns = ['timestamp', 'publisher','os', 'displayId']</span><span id="233f" class="lu iq hh lq b fi ma lw l lx ly">df_train = df_train.drop(columns=drop_columns, axis=1)</span></pre><p id="af62" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">到目前为止，我们在每个数据集中所做的只是正常和明显的清理标准，但在这种数据中，我们需要做一些魔术来增加功能交互，并丢弃无用的数据，如我们在整个数据集中只看到几次的“userId ”,或“docId”或任何其他具有类似行为的功能。</p><h1 id="c282" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">删除无用的列</h1><p id="0116" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">首先，我们将绘制一些关于每个特征的PDF和CDF的有用图表，然后基于这些图表，我们将为每个特征选择一个阈值，并删除无用的行。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="e3b9" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">例如,“userId”上这两个函数的输出如下所示:</p><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es me"><img src="../Images/99435307ff2c3d1745bb30c93b58acd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IEjFO908NC9T7VA51okhQw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">“用户Id”的PDF和CDF分发</figcaption></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mf"><img src="../Images/16a6f6e57181fba84a2fb57950cabbf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*cr6iPPYu-OhRaQztUVWtRQ.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">基于重复次数的最佳用户标识</figcaption></figure><p id="b546" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">基于我们所看到的，我们为每个特性选择一个阈值，并删除不符合该条件的行。然后，我们将对选定的行进行聚合，并删除重复的行。</p><p id="d548" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">通过这项工作，剩余的数据将确保我们每个数据至少有一个好的特征。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div><figcaption class="il im et er es in io bd b be z dx translated">丢弃无用的数据</figcaption></figure><h1 id="cabd" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">不平衡数据集</h1><p id="c761" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">您可能知道，在点击率预测类型的数据集中，我们总是会遇到不平衡的格式。我不会讨论什么是不平衡数据集，你也可以在这里阅读这个<a class="ae mg" href="https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb" rel="noopener" target="_blank"><strong class="jp hi"/></a>和<a class="ae mg" href="https://elitedatascience.com/imbalanced-classes" rel="noopener ugc nofollow" target="_blank"><strong class="jp hi"/></a>。</p><p id="6a09" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">对于这个问题，我们将使用下采样(欠采样)方法。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><blockquote class="mh"><p id="cefa" class="mi mj hh bd mk ml mm mn mo mp mq kk dx translated">缩减取样前负类的形状:(2926235，16)</p><p id="eeb6" class="mi mj hh bd mk ml mr ms mt mu mv kk dx translated">缩减采样后负类的形状:(842181，16)</p></blockquote><h1 id="5711" class="ip iq hh bd ir is it iu iv iw ix iy iz ja mw jc jd je mx jg jh ji my jk jl jm bi translated">一键编码</h1><p id="f418" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">如您所知，这类数据中的所有特征都是分类的，在这些情况下，您必须对您的特征进行一次性编码。</p><p id="15fb" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">这种情况下的一个严重问题是，您必须管理您的训练和测试集，使其具有相同的特性(要了解更多信息，您可以阅读<a class="ae mg" rel="noopener" href="/@vaibhavshukla182/how-to-solve-mismatch-in-train-and-test-set-after-categorical-encoding-8320ed03552f"> <strong class="jp hi">这篇</strong> </a>简短文章)</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><h1 id="0057" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated"><strong class="ak">逻辑回归</strong></h1><p id="7d64" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">在我们做了所有的工作之后，现在我们将实现我们的分类方法。</p><p id="f3f9" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">您可以在下面的代码片段中看到逻辑回归的实现:</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mz"><img src="../Images/6e5cd4e1d4382be2c0e7835dc045d7c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jfc5ZHsnMya-qP3F_5sRpA.png"/></div></div></figure><h1 id="3d9d" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">SVM</h1><p id="94c6" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">SVM在这一特定领域有许多倒退，例如，你不能在可行的时间内用超过20k的数据在SVM上训练，而且SVM在稀疏数据上工作得很差。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es na"><img src="../Images/4878c563796ff0605275b0af78c2279d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vGuGKic9bZU9Ndft_wJ0SA.png"/></div></div></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es nb"><img src="../Images/71dd0ec4041c29e5464d3fddece47227.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*ug6KnzWcKZw-5Ubac3ozHw.png"/></div></figure><h1 id="c107" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">随机森林</h1><p id="6957" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">这个特定区域的随机森林回退是关于使用具有许多特征的稀疏矩阵，所以我们只能在我们的树中使用一点深度，这表明我们可能没有很好的准确性。</p><p id="f5d3" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated"><strong class="jp hi"> <em class="kx">交叉验证部分:</em> </strong></p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="cf78" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated"><strong class="jp hi"> <em class="kx">火车上的评价:</em> </strong></p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="c26f" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated"><strong class="jp hi"> <em class="kx">对测试的评价:</em> </strong></p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es nc"><img src="../Images/cae16caf606f0a97a2f5e0bb6e8943ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YFshBleCVExX7FiMgLu64w.png"/></div></div></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es nd"><img src="../Images/6f4309b0046dfbec378f6cabf6fa55c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*5myYGbwBmqe2u2Vyq_1FUQ.png"/></div></figure><h1 id="8450" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">XGBoost</h1><p id="ceea" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">XGBoost比以前的方法快得多，并且获得的结果也是可接受的。(但还不够好)</p><p id="fa81" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated"><strong class="jp hi"> <em class="kx">列车上评价:</em> </strong></p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="4e79" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated"><strong class="jp hi"> <em class="kx">对测试的评价:</em> </strong></p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es ne"><img src="../Images/bb8da2fcea5bb3f75e925cac968d0810.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*prED3lK2a2Qo_YCjgO4OKQ.png"/></div></div></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es nf"><img src="../Images/dde8571f03b1c58853ae588a851740a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*DbID5-hxIVxOiESXgt_5rw.png"/></div></figure><h1 id="b5ca" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">结论</h1><p id="2742" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">正如您可能注意到的那样，所有解释的方法在该数据集上的表现都不好，这种方法中如此巨大的稀疏矩阵存在一个巨大的问题，在下一篇文章中，我们将介绍两种全新的方法，称为因子分解模型和字段权重因子分解模型，它们在稀疏数据集上工作得非常好。</p><p id="f59b" class="pw-post-body-paragraph jn jo hh jp b jq ky js jt ju kz jw jx jy lb ka kb kc ld ke kf kg lf ki kj kk ha bi translated">你可以在<a class="ae mg" href="https://colab.research.google.com/drive/1D12AIDb9ODnCrxhEiNxD7U3_oGY3UFqO?usp=sharing" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">这个链接</strong> </a>里看到所有解释的代码和其他方法比如FM，FWFM</p></div></div>    
</body>
</html>