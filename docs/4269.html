<html>
<head>
<title>Real Time Object Tracking System using Thermal Camera</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用热像仪的实时目标跟踪系统</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/real-time-object-tracking-system-using-thermal-camera-b4d077a20f16?source=collection_archive---------1-----------------------#2021-09-14">https://medium.com/analytics-vidhya/real-time-object-tracking-system-using-thermal-camera-b4d077a20f16?source=collection_archive---------1-----------------------#2021-09-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1786" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">夜间光线强度很低，人类很难看到和识别周围的物体。人类需要额外的工具才能在晚上看得更清楚，比如路灯和手电筒等照明设备，甚至是夜视或热成像相机等其他先进技术。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/c4db06e3a64721ff0c8a75a4dda67f93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ETu0GjCdIzWqxfSs.jpg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">图片取自<a class="ae js" href="https://fortune.com/2020/04/20/coronavirus-fever-temperature-thermal-imaging-cameras/" rel="noopener ugc nofollow" target="_blank">财富</a></figcaption></figure><p id="32d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jt">但是热感相机是如何工作的呢？</em></p><p id="d1c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所有物体都会发出热信号，也称为<strong class="ig hi">红外线</strong>能量。热像仪检测和测量物体的红外能量。然后，摄像机将红外数据转换成电子图像，显示物体的表面温度，以便进一步处理。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><h1 id="debe" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">构建产品</h1><p id="4889" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">在这个项目中，我被分配到一个团队去开发一个在夜晚工作的实时人物跟踪系统。我们使用FLIR轻子作为我们的热成像相机，NVIDIA Jetson Nano作为处理单元的单板计算机，以及两个伺服电机来旋转相机，以便它可以跟踪目标。该产品的主要目标是识别画面上是否有人，同时保持和调整摄像机位置以实时跟踪目标。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es le"><img src="../Images/6f8ebdbbf1011aaa0f8f9e42163cb938.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*40OX4AuaBcT0CuPR.jpg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">杰特森纳米，图片来自<a class="ae js" href="https://developer.nvidia.com/embedded/jetson-nano-developer-kit" rel="noopener ugc nofollow" target="_blank">英伟达</a></figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es le"><img src="../Images/65050ffc8a7dad85bde4c278b23eef1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b078xIm3id4Nd_3S.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">前视轻子3.5，图片来自<a class="ae js" href="https://www.flir.com/news-center/camera-cores--components/flir-lepton-3.5-now-available-to-manufacturers-and-makers/" rel="noopener ugc nofollow" target="_blank">前视轻子</a></figcaption></figure><p id="8747" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们采取了几个步骤来构建跟踪系统。</p><ol class=""><li id="be51" class="lf lg hh ig b ih ii il im ip lh it li ix lj jb lk ll lm ln bi translated">首先，我们研究了最新的目标检测算法。在所有选项中，我们选择了YOLO目标检测架构。</li><li id="560d" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lk ll lm ln bi translated">然后，我们收集热图像中人的数据集，并将其训练到我们的模型中。</li><li id="4b50" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lk ll lm ln bi translated">之后，我们将该模型实现到NVIDIA Jetson Nano中，并与其他组件组装在一起。</li><li id="38fd" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lk ll lm ln bi translated">最后要做的是测试和校准我们的产品，以实现更好的性能。</li></ol></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><h1 id="ecd0" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">你只看一次(YOLO)</h1><p id="9d3f" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated"><strong class="ig hi">Y</strong>O<strong class="ig hi">O</strong>only<strong class="ig hi">L</strong>ook<strong class="ig hi">O</strong>nce(YOLO)是众所周知的对象检测算法的最新发展水平之一。该算法是一个突破，其中对象检测情况被识别为一个回归问题，以将图像划分为某些更小的像素组，并将它们与用边界框检测到对象的概率和类的概率相关联。</p><p id="46b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们用的是YOLO(当时)的最新版本，是YOLOv4。因为我们要在单板计算机上部署它，所以我们使用微型版本。下图显示了与处理时间或FPS(每秒帧数)相关的对象检测算法的基准比较。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lt"><img src="../Images/38498b60c824cd4c7d08fdd769518ac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/1*QeLl_KSOUEsDDsDbL0G8CQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">几种物体检测算法的基准比较，图片来自<a class="ae js" href="https://alexeyab84.medium.com/yolov4-the-most-accurate-real-time-neural-network-on-ms-coco-dataset-73adfd3602fe" rel="noopener"> Aleksey Bochkovskiy的博客</a></figcaption></figure><p id="8482" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">YOLO相对于其他对象检测算法的优势在于其处理时间快得多，因为它仅对每个像素处理一次。我们需要具有快速处理时间(高FPS)的算法，因为我们的跟踪系统实时工作。</p><p id="fb55" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个项目中，我们使用<strong class="ig hi"> darknet </strong>框架来适应YOLO架构。Darknet是人工神经网络(ANN)的工作框架，常用于开发深度学习项目。Darknet是用C和CUDA编程语言编写的。它有几个优点，处理时间快，易于安装在任何设备上，我们可以选择运行CPU或GPU的框架。</p><p id="ce8e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想了解更多关于Darknet和YOLOv4的详细信息，你可以在<a class="ae js" href="https://alexeyab84.medium.com/yolov4-the-most-accurate-real-time-neural-network-on-ms-coco-dataset-73adfd3602fe" rel="noopener">阿列克谢·博奇科夫斯基的博客</a>这里阅读。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><h1 id="4f61" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">收集数据集</h1><p id="8731" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">我们必须手动收集数据集，因为很难在互联网上找到它，因为热图像研究仍然非常罕见。该数据集是通过使用FLIR轻子3.5相机记录人的视频来收集的。我们改变了背景点，并使用尽可能多的人样本，以防止过度拟合，或者模型可能只在某些情况下工作。我们还改变了姿势，如面向后、举起手、蹲下等等，以提高模型本身的性能。</p><p id="cd10" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在收集了数据集之后，我们对每张图像进行标记，以标注照片中人的位置。提供的标签必须符合YOLO的格式。以下是数据集中的图像以及该图像标签的示例。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lu"><img src="../Images/d200382c6f8cc56457c8035309836d08.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/1*S4NIT50b5oT7KUQinXbcYA.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">一个人的数据集，图片来自私人收藏</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lv"><img src="../Images/cec45cebc83fc67cf8b5778680487130.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*3gWRVnAgeIANlC_J3Vxf1w.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">前一张图片的标签，图片来自私人收藏</figcaption></figure><p id="7d18" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于数据集中的每个图像，都有一个. txt文件作为与图像文件同名的标签，其中包含图像上的对象注释信息。以下是我们在这个标签中遵循的一些YOLO注释规则。</p><ul class=""><li id="9a87" class="lf lg hh ig b ih ii il im ip lh it li ix lj jb lw ll lm ln bi translated">标签文件中的行数表示图像中检测到的对象的数量。</li><li id="4391" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lw ll lm ln bi translated">值为0的第一列是被检测对象的类别索引，即人类。</li><li id="f92e" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lw ll lm ln bi translated">第二列和第三列是边界框中心点的坐标(x，y)。</li><li id="ac53" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lw ll lm ln bi translated">第四和第五列是创建的边界框的宽度和高度(w，h)。</li><li id="3d05" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lw ll lm ln bi translated">第二至第五列的十进制值介于0和1之间，因为该列是对图像大小(416x416像素)进行规范化处理的结果。</li></ul><p id="aa95" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用了慈大麟创造的图像注释工具，这样我们可以更容易、更快地标记数百张图像。你可以从他的Github页面<a class="ae js" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">这里</a>访问它。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><h1 id="bbe4" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">培训模式</h1><p id="dd2e" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">收集数据集后，下一步是将数据集上传到培训存储库，并将其分成三个不同的文件夹，即培训、验证和测试。这个项目中使用的比例是7:2:1，即679幅图像用于训练，194幅图像用于验证，97幅图像用于测试过程。</p><p id="8304" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">之后，我们使用数据集训练模型。目标是获得神经网络中神经元的权重或乘数系数。在这项研究中，使用Google Collaboratory进行训练，以获得良好的GPU资源并加快训练过程。darknet框架也支持训练过程，因此darknet被选为这个过程的代码库。下面是在终端中使用darknet运行训练过程的代码片段。</p><pre class="jd je jf jg fd lx ly lz ma aw mb bi"><span id="e95b" class="mc kc hh ly b fi md me l mf mg">./darknet detector train data/obj.data cfg/custom-yolov4-tiny-detector.cfg yolov4-tiny.conv.29 -dont_show -map</span></pre><p id="1af4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">代码片段解释:</p><ol class=""><li id="ed46" class="lf lg hh ig b ih ii il im ip lh it li ix lj jb lk ll lm ln bi translated">上面代码片段中的第一个词，<strong class="ig hi"> darknet detector </strong>，是初始化darknet框架中特性的默认命令。</li><li id="c1f8" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lk ll lm ln bi translated">发出<strong class="ig hi">训练</strong>命令来训练模型。</li><li id="f29a" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lk ll lm ln bi translated">第一个参数<strong class="ig hi"> data/obj.data </strong>是一个包含数据集的所有路径的文件，该数据集已被划分为前面的三个部分。</li><li id="3ced" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lk ll lm ln bi translated">第二个参数<strong class="ig hi">CFG/custom-yolov 4-tiny-detector . CFG</strong>，包含tiny YOLOv4的架构配置。</li><li id="c5a2" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lk ll lm ln bi translated">第三个参数，<strong class="ig hi"> yolov4-tiny.conv.29 </strong>，是一个包含预训练权值的文件或者是已经预训练到一定阶段的权值文件，用于执行卷积和特征提取。</li><li id="f8be" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lk ll lm ln bi translated">接下来的两个参数，<strong class="ig hi">–dont _ show</strong>和<strong class="ig hi"> -map </strong>，用于在训练过程中减少终端的输出，并且只关注map(平均精度)度量。</li></ol><p id="48d3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的定制模型表现良好。它得到了地图价值的96.61%。然后，我们决定下载权重文件，并将其部署到Jetson Nano进行现场测试。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mh"><img src="../Images/fc0e663a4fa3393926b5ceb83cb59d59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gjv9nDdtUu1ovkNOohCOmg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">终端输出显示私人收藏的地图、图片</figcaption></figure><p id="0848" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想了解更多关于训练过程的信息，我在参考资料中加入了Roboflow的这篇关于用自定义数据集训练YOLOv4的<a class="ae js" href="https://blog.roboflow.com/training-yolov4-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank">博客</a>。在我们进行这个项目的时候，它真的帮了我们很多。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><h1 id="6e2d" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">结果和现场测试</h1><p id="e099" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">这是该产品的视频演示。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">实时测试，视频上传到<a class="ae js" href="https://www.youtube.com/watch?v=kQFtU8FpsDM" rel="noopener ugc nofollow" target="_blank"> youtube </a></figcaption></figure><p id="36ea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该系统成功地检测到具有高置信度(超过90%)的人。它还通过旋转伺服系统不断调整摄像机位置，使目标人物保持在画面中。</p><p id="1b66" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还试图通过在程序执行时从日志中抓取FPS数据来测试它的<strong class="ig hi"> FPS </strong>(每秒帧数)性能。FPS值通过将每帧的执行持续时间除以1来计算。有数百个记录的FPS数据，所以我们需要创建一个Python脚本来抓取并绘制它，如下所示。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mk"><img src="../Images/d6fa633e76009241b721b6f0216c3c9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*GOvydV7UYQzHsuWDLajr8g.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">FPS图表，图片来自私人收藏</figcaption></figure><p id="ab58" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从上图可以看出，经常出现的FPS值是<strong class="ig hi"> 14 </strong>。有时该值为13或接近1。但是，似乎这些信息是Jetson Nano设备或使用的摄像头产生的噪音，因为数量远远少于14。这也表明YOLOv4算法是实时对象检测情况下的正确选择。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><h1 id="b56f" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">参考</h1><ul class=""><li id="3ab1" class="lf lg hh ig b ih kz il la ip ml it mm ix mn jb lw ll lm ln bi translated"><a class="ae js" href="https://www.fluke.com/en-us/learn/blog/thermal-imaging/how-infrared-cameras-work" rel="noopener ugc nofollow" target="_blank">热成像相机是如何工作的？</a></li><li id="9d73" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lw ll lm ln bi translated"><a class="ae js" href="https://developer.nvidia.com/embedded/jetson-nano" rel="noopener ugc nofollow" target="_blank"> NVIDIA Jetson Nano规格</a></li><li id="2673" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lw ll lm ln bi translated"><a class="ae js" href="https://www.flir.com/products/lepton/?model=3.5%20Lepton" rel="noopener ugc nofollow" target="_blank">前视轻子3.5规格</a></li><li id="85c5" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lw ll lm ln bi translated"><a class="ae js" href="https://alexeyab84.medium.com/yolov4-the-most-accurate-real-time-neural-network-on-ms-coco-dataset-73adfd3602fe" rel="noopener">阿列克谢·博奇科夫斯基的博客</a></li><li id="a3f9" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lw ll lm ln bi translated"><a class="ae js" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank">慈达林的图像标注图形工具</a></li><li id="0ad2" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lw ll lm ln bi translated"><a class="ae js" href="https://blog.roboflow.com/training-yolov4-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank">在暗网上训练自定义数据集</a></li><li id="d005" class="lf lg hh ig b ih lo il lp ip lq it lr ix ls jb lw ll lm ln bi translated"><a class="ae js" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">暗网知识库</a></li></ul></div></div>    
</body>
</html>