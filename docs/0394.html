<html>
<head>
<title>Sentiment Analysis On Voice Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">语音数据的情感分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sentiment-analysis-of-voice-data-64533a952617?source=collection_archive---------2-----------------------#2021-01-15">https://medium.com/analytics-vidhya/sentiment-analysis-of-voice-data-64533a952617?source=collection_archive---------2-----------------------#2021-01-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/20355a2c904bd6b6558fe41e046730e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qGncbRDIVEDzzbut2Ikrsg.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><strong class="bd iu">对语音数据的情感分析</strong></figcaption></figure><p id="67cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> D </strong>感知情感是当今世界最重要的营销策略之一。我们可以为个人定制不同的东西来满足他们的兴趣。了解顾客的情绪会提高产品的质量。通常，情感分析是通过文本数据完成的，但是我们有很多未使用的音频数据。出于这个原因，我们决定做一个处理器，它可以通过人的声音来检测人的情绪，这将让我们管理许多与人工智能相关的应用程序。一些例子可以包括当一个人在电话中生气时，呼叫中心播放音乐。另一种可能是当一个人生气或害怕时，一辆智能汽车会减速。另一个可能是网络安全。因此，这种类型的应用在世界上有很大的潜力，将有利于公司，甚至对消费者的安全。</p></div><div class="ab cl jt ju gp jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="hb hc hd he hf"><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/ac16fdbfada3b67ea0f7106aa1ed79a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:714/format:webp/1*yjYWxgzlbpVIZRHNXSbphA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><em class="kf">语音情感分析</em></figcaption></figure><p id="b3c4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kg">用于案例研究的数据集:</em><a class="ae kh" href="http://neuron.arts.ryerson.ca/ravdess/?f=3" rel="noopener ugc nofollow" target="_blank"><em class="kg">http://neuron.arts.ryerson.ca/ravdess/?f=3</em></a><em class="kg">，</em><a class="ae kh" href="http://kahlan.eps.surrey.ac.uk/savee/Download.html" rel="noopener ugc nofollow" target="_blank"><em class="kg">http://kahlan.eps.surrey.ac.uk/savee/Download.html</em></a></p><p id="50ea" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们选择了只有音频的zip文件，因为我们要从语音中寻找情感。zip文件由大约1500个wave格式的音频文件组成。第二个网站包含了大约500段来自四个不同演员的不同情感的音频演讲。</p><p id="1347" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们测试了其中一个音频文件，通过绘制其波形和频谱图来了解其特征。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es ki"><img src="../Images/9ca853d62d99da586de1481f1745e5c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*s4VsyAL7GkQ0zIjEKcDQyg.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">音频的波形</figcaption></figure><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es kj"><img src="../Images/cdeedb3c345f6bc07888ca4d08cddc54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*AA7Pr-WCIBKlps20f9iwDw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">音频的声谱图</figcaption></figure><p id="12d6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一步是组织音频文件。每个音频文件在文件名的第6位都有一个唯一的标识符，可以用来确定音频文件包含的情感。我们的数据集中有5种不同的情绪。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kk"><img src="../Images/197877319bf49640537d60630da3041f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FSsGNkLh7QGLJ93jkVLnug.png"/></div></div></figure><blockquote class="kl km kn"><p id="1721" class="iv iw kg ix b iy iz ja jb jc jd je jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">1.冷静2。快乐3。伤心4。愤怒5。可怕的</p></blockquote><p id="a0c3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们使用Python中的Librosa库来处理和提取音频文件中的特征。Librosa是一个用于音乐和音频分析的python包。它提供了创建音乐信息检索系统所必需的构件。使用librosa库，我们能够提取特征，即MFCC(梅尔频率倒谱系数)。MFCCs是在自动语音和说话人识别中广泛使用的特征。我们还通过使用网站中提供的标识符来区分女性和男性的声音。这是因为作为一项实验，我们发现区分男性和女性的声音增加了15%。可能是因为声音的音高影响了结果。</p><p id="1993" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每个音频文件给了我们许多特性，这些特性基本上是许多值的数组。这些特征随后被附加上我们在上一步中创建的标签。</p><p id="89f4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下一步涉及处理一些长度较短的音频文件的缺失特征。我们将采样率提高了两倍，以获得每个情感语音的独特特征。我们没有增加采样频率，因为它可能会收集噪音，从而影响结果</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kr"><img src="../Images/eacd83c759f02b3a1294d8a2e5b4089d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M8CdmRy98LMeElggVj_izQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">列车分离</figcaption></figure><p id="f7c2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来的步骤包括整理数据，分成训练和测试，然后建立一个模型来训练我们的数据。将很快添加代码</p><blockquote class="kl km kn"><p id="431c" class="iv iw kg ix b iy iz ja jb jc jd je jf ko jh ji jj kp jl jm jn kq jp jq jr js hb bi translated">我们建立了多感知器模型、LSTM模型和CNN模型。MLP和LSTM不适合，因为它给我们的准确性低。因为我们的项目是一个分类问题，我们对不同的情绪进行分类，CNN对我们来说是最好的。</p></blockquote><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es ks"><img src="../Images/3a2654d107a1379ae65db7120f605361.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*xbtdcV9hPuvDOYHqGSrkiQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">美国有线新闻网；卷积神经网络</figcaption></figure><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es kt"><img src="../Images/b6e6b785bd5bc0145684d0bf3f33a523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*3rQFBcGeDk_TrH5rUbIDtA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">训练-测试验证</figcaption></figure><p id="c352" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在建立了许多不同的模型之后，我们找到了我们情感分类问题的最佳CNN模型。我们利用现有模型实现了70%的验证准确率。如果我们有更多的数据来处理，我们的模型会表现得更好。更令人惊讶的是，该模型在区分男性和女性声音时表现出色。我们还可以从上面看到模型是如何预测实际值的。在未来，我们可以建立一个序列到序列的模型，根据不同的情绪产生声音。例如快乐的声音、惊讶的声音等。</p><figure class="kb kc kd ke fd ij er es paragraph-image"><div class="er es ku"><img src="../Images/71d708ab1a452924a9294e1bacbadb56.png" data-original-src="https://miro.medium.com/v2/resize:fit:728/format:webp/1*JS_Rp-R00KIwfCrmlTORHg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">预测产量</figcaption></figure><div class="kv kw ez fb kx ky"><a href="https://www.linkedin.com/in/vijay-anadan/" rel="noopener  ugc nofollow" target="_blank"><div class="kz ab dw"><div class="la ab lb cl cj lc"><h2 class="bd hj fi z dy ld ea eb le ed ef hh bi translated">维贾伊·阿南丹-助理工程师1 -认知| LinkedIn</h2><div class="lf l"><h3 class="bd b fi z dy ld ea eb le ed ef dx translated">好奇心驱动的数据科学家，渴望利用机器学习和数据分析来提取有意义的…</h3></div><div class="lg l"><p class="bd b fp z dy ld ea eb le ed ef dx translated">www.linkedin.com</p></div></div><div class="lh l"><div class="li l lj lk ll lh lm io ky"/></div></div></a></div></div></div>    
</body>
</html>