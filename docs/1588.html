<html>
<head>
<title>Mining Fanfics on AO3 â€” Part 3: English &amp; Chinese Text Analysis with Decision Tree &amp; Clustering</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AO3ç²‰ä¸æŒ–æ˜ç¬¬ä¸‰éƒ¨åˆ†:åŸºäºå†³ç­–æ ‘å’Œèšç±»çš„è‹±æ±‰æ–‡æœ¬åˆ†æ</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/analytics-vidhya/mining-fanfics-on-ao3-part-3-english-chinese-text-analysis-with-decision-tree-clustering-6dcaa0e8a7a6?source=collection_archive---------17-----------------------#2021-03-08">https://medium.com/analytics-vidhya/mining-fanfics-on-ao3-part-3-english-chinese-text-analysis-with-decision-tree-clustering-6dcaa0e8a7a6?source=collection_archive---------17-----------------------#2021-03-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7d65" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">é¦–å…ˆï¼Œè®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹è¿„ä»Šä¸ºæ­¢ä»AO3æ”¶é›†çš„æ•°æ®:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="3344" class="jl jm hh jh b fi jn jo l jp jq">Title                     object<br/>Author                    object<br/>ID                         int64<br/>Date_updated      datetime64[ns]<br/>Rating                    object<br/>Pairing                   object<br/>Warning                   object<br/>Complete                  object<br/>Language                  object<br/>Word_count                 int64<br/>Num_chapters               int64<br/>Num_comments               int64<br/>Num_kudos                  int64<br/>Num_bookmarks              int64<br/>Num_hits                   int64<br/>Tags                      object<br/>Summary                   object<br/>Date_published    datetime64[ns]<br/>Content                   object<br/>Comments                  object</span></pre><p id="a1e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">(æ•°æ®æ”¶é›†è¿‡ç¨‹è§<a class="ae jr" href="https://moinmoin150.medium.com/mining-fanfics-on-ao3-part-1-data-collection-eac8b5d7a7fa" rel="noopener">ç¬¬1éƒ¨åˆ†</a>)</p><p id="0d6d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">åœ¨ç¬¬2éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹æ”¾åœ¨äº†æ›´ç»“æ„åŒ–çš„æ•°æ®ä¸Šï¼Œå¿½ç•¥äº†æ ‡ç­¾ã€æ‘˜è¦ã€å†…å®¹(å®é™…ä¸Šæ˜¯è™šæ„çš„æ–‡æœ¬)å’Œæ³¨é‡Šã€‚è¿™äº›å°†æ˜¯è¿™ç¯‡æ–‡ç« çš„é‡ç‚¹ã€‚</p><p id="237d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">é™¤äº†ç®€å•çš„è¯é¢‘ç»Ÿè®¡ï¼Œæˆ‘é¦–å…ˆæ¢ç´¢äº†å°†å†³ç­–æ ‘(DT)åº”ç”¨äºæ ‡ç­¾çš„å¯èƒ½æ€§ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å°†å°è¯´åˆ†ä¸ºé«˜æµè¡Œå’Œä½æµè¡Œä¸¤ç±»ã€‚ç„¶åï¼Œæˆ‘å°è¯•äº†å¸¦æ‘˜è¦çš„k-meansèšç±»ã€‚</p></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="8fa4" class="jz jm hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">å†³ç­–å›¾è¡¨</h1><p id="1f1c" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">è¿™æœ¬ç”±<a class="lb lc ge" href="https://medium.com/u/d7e4530589?source=post_page-----6dcaa0e8a7a6--------------------------------" rel="noopener" target="_blank"> Gustavo Hideo </a>æ’°å†™çš„<a class="ae jr" href="https://towardsdatascience.com/decision-tree-build-prune-and-visualize-it-using-python-12ceee9af752" rel="noopener" target="_blank"> DTå®æ–½æŒ‡å—</a>ç»™äº†æˆ‘å¾ˆå¤§çš„å¸®åŠ©ã€‚ç†è§£sk learn DTåˆ†ç±»å™¨ä¸­çš„å„ç§å¯ç”¨å‚æ•°å¾ˆæœ‰å¸®åŠ©ã€‚æœ‰ä¸€æ¬¡ï¼Œæˆ‘ä¸å¾—ä¸ç”¨Pythonä»å¤´å¼€å§‹æ„å»ºDTæ¨¡å‹ï¼Œä½†å®ƒçš„çµæ´»æ€§å’Œç»†å¾®å·®åˆ«è¿œè¿œä¸åŠsklearnçš„â€œç½è£…â€æ¨¡å‹æ‰€èƒ½æä¾›çš„æ‰€æœ‰ä¿®å‰ªé€‰é¡¹ã€‚ç®€ç›´æ˜¯å¤©èµè‰¯æœºã€‚</p><p id="77d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿™æ˜¯æˆ‘ä»¬åœ¨è¿™ä¸€éƒ¨åˆ†éœ€è¦çš„ä¸œè¥¿:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="0f59" class="jl jm hh jh b fi jn jo l jp jq">from sklearn import tree<br/>from sklearn.tree import DecisionTreeClassifier<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import confusion_matrix<br/>from sklearn.tree import export_graphviz<br/>import pydotplus<br/>import matplotlib.pyplot as plt<br/>import matplotlib.image as pltimg<br/>from sklearn.metrics import accuracy_score<br/>import pandas as pd<br/>import numpy as np</span></pre><h2 id="ca08" class="jl jm hh bd ka ld le lf ke lg lh li ki ip lj lk km it ll lm kq ix ln lo ku lp bi translated">æ•°æ®æ“ä½œ</h2><p id="37e6" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">ä¸ºäº†åº”ç”¨DTï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ‰‹å¤´çš„æ–‡æœ¬æ•°æ®åˆ›å»ºè™šæ‹Ÿå˜é‡ã€‚æ­¤å¤–ï¼Œæ ‡ç­¾ä»¥é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²æ ¼å¼å­˜å‚¨ï¼Œä¾‹å¦‚</p><blockquote class="lq lr ls"><p id="b102" class="ie if lt ig b ih ii ij ik il im in io lu iq ir is lv iu iv iw lw iy iz ja jb ha bi translated">G <!-- -->å¯¹æš´åŠ›ã€ä¸»è¦äººç‰©æ­»äº¡ã€å¦ä¸€ä¸ªå®‡å®™ã€POVç¬¬ä¸€äººç§°ã€äº¤å‰çš„å›¾å½¢æè¿°â€¦â€¦</p></blockquote><p id="38b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å› æ­¤ï¼Œåœ¨åº”ç”¨pandasçš„get_dummies()å‡½æ•°ä¹‹å‰ï¼Œå®ƒä»¬éœ€è¦ä¸€äº›é¢å¤–çš„å¤„ç†æ¥å°†å®ƒä»¬è½¬æ¢æˆåˆ—è¡¨:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="e240" class="jl jm hh jh b fi jn jo l jp jq">df.Tags = df.Tags.apply(lambda x: x.split(','))</span><span id="4313" class="jl jm hh jh b fi lx jo l jp jq"># first option<br/>t = pd.get_dummies(pd.DataFrame(df.Tags.values.tolist()), prefix_sep='', prefix='')</span></pre><p id="53d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç¬¬ä¸€ä¸ªé€‰é¡¹æ²¡æœ‰åƒé¢„æœŸçš„é‚£æ ·å·¥ä½œï¼Œä¸»è¦æ˜¯å› ä¸ºå®ƒç”¨é‡å¤å€¼æ‰©å¤§äº†åˆ—ã€‚å¯¹äºæœ‰ç»„ç»‡çš„ã€æœ‰åºçš„æˆ–å•å€¼çš„åˆ—ï¼Œå®ƒåº”è¯¥å·¥ä½œå¾—å¾ˆå¥½ï¼Œä½†æ˜¯å¯¹äºä¸åŒé•¿åº¦çš„æ— åºåˆ—è¡¨ï¼Œè€ƒè™‘æ¯ä¸€åˆ—(å‚ç›´å¯¹é½)ï¼Œç„¶åä¾æ¬¡â€œè™šæ‹ŸåŒ–â€å®ƒä»¬ä¼šå¯¼è‡´æ„æƒ³ä¸åˆ°çš„ç»“æœã€‚</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="bfca" class="jl jm hh jh b fi jn jo l jp jq"># second option<br/>t2 = df.Tags.astype(str).str.strip('[]').str.get_dummies(', ')</span></pre><p id="6cb7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¿™ç¬¬äºŒä¸ªé€‰é¡¹ä½¿ç”¨<a class="ae jr" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.get_dummies.html" rel="noopener ugc nofollow" target="_blank"> pdã€‚Series.str.get_dummies() </a>é‡‡ç”¨äº†ä¸€ç§æ›´å¤æ‚çš„æ–¹æ³•ï¼Œä½†åœ¨è¿™ç§æƒ…å†µä¸‹å¯ä»¥æŒ‰é¢„æœŸå·¥ä½œã€‚</p><p id="e363" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä½ å¯èƒ½æƒ³æ•°ä¸€ä¸‹æœ€å—æ¬¢è¿çš„æ ‡ç­¾ã€‚è™½ç„¶æœ‰è®¸å¤šå…¶ä»–æ–¹æ³•å¯ä»¥åšåˆ°è¿™ä¸€ç‚¹ï¼Œä½†ç”±äºæˆ‘ä»¬æ‰‹å¤´å·²ç»æœ‰äº†è¿™ä¸ªè™šæ‹Ÿè¡¨ï¼Œæˆ‘ä»¬å¯ä»¥åƒè¿™æ ·æ„å»ºä¸€ä¸ªå­—å…¸:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="2bce" class="jl jm hh jh b fi jn jo l jp jq">dic = {}<br/>for val, i in zip(t2.sum(axis=0), t2.sum(axis=0).index):<br/>    dic[i] = val<br/>dic</span></pre><p id="9a50" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬çš„æ ‘çš„ç‰¹å¾åˆ—è¡¨å¯ä»¥è¢«é¢„å…ˆä¿®å‰ªã€‚æˆ‘è®¤ä¸ºä¸€å¼€å§‹å»æ‰æå…¶ç½•è§çš„æ ‡ç­¾æ˜¯æœ‰æ„ä¹‰çš„ï¼Œä½†è¿™æ˜¯å¦æœ‰å¿…è¦ï¼Œæ˜¯å¦æ˜¯æœ€ä½³å®è·µè¿˜æœ‰å¾…è®¨è®ºã€‚</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="6ad7" class="jl jm hh jh b fi jn jo l jp jq"># I examined the number of rare tags and found the cutoff point I'm most happy with<br/>len([key for key, val in dic.items() if val &lt; 30])</span><span id="41e8" class="jl jm hh jh b fi lx jo l jp jq">t2 = t2.drop([key for key, val in dic.items() if val &lt; 30], axis=1)</span><span id="8c3c" class="jl jm hh jh b fi lx jo l jp jq"># You may also want to exclude other non-informative tags, such as ['Creator Chose Not To Use Archive Warnings','No Archive Warnings Apply', 'Don't copy to another site'], which turned out to skew the result a lot</span></pre><p id="e138" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘çš„æ•°æ®æ²¡æœ‰ä»»ä½•é¢„å®šä¹‰çš„åˆ†ç±»æ ‡ç­¾ã€‚å‡ºäºæˆ‘è‡ªå·±çš„æ¢ç´¢ç›®çš„ï¼Œæˆ‘ä»»æ„åˆ›å»ºäº†ä¸€ä¸ªç”±é«˜äºä¸­å€¼çš„å·¥è—¤æ•°å®šä¹‰çš„â€œæˆåŠŸâ€å˜é‡:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="992d" class="jl jm hh jh b fi jn jo l jp jq">mark = np.median(df.Num_kudos)<br/>df['Success'] = df.Num_kudos.apply(lambda x: int(x&gt;=mark))</span></pre><p id="9c7c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç„¶åï¼Œæˆ‘å°†è¿™ä¸ªå˜é‡ä»¥åŠå…¶ä»–æ„Ÿå…´è¶£çš„å˜é‡æ·»åŠ åˆ°æˆ‘çš„è™šæ‹Ÿè¡¨ä¸­:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="026e" class="jl jm hh jh b fi jn jo l jp jq">for_tree = pd.concat([df[['Success','Word_count']],t2], axis=1)</span></pre><h2 id="b449" class="jl jm hh bd ka ld le lf ke lg lh li ki ip lj lk km it ll lm kq ix ln lo ku lp bi translated">è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹</h2><p id="1f63" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">æˆ‘ä»¬éœ€è¦å®šä¹‰é¢„æµ‹å€¼(x)å’Œé¢„æµ‹å€¼(y ),ç„¶åå°†å®ƒä»¬åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="683b" class="jl jm hh jh b fi jn jo l jp jq">X = for_tree.iloc[:,1:]<br/>y = for_tree[['Success']]<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1) #default 75% train</span></pre><p id="47ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å¯ä»¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹â€”</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="cbcf" class="jl jm hh jh b fi jn jo l jp jq">dt = DecisionTreeClassifier(criterion="entropy", max_depth=5, min_impurity_decrease=0.003)<br/>dt.fit(X_train, y_train)</span></pre><p id="76da" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å“ªäº›ç‰¹å¾åœ¨åˆ†ç±»ä¸­è¢«è®¤ä¸ºæ˜¯æœ€é‡è¦çš„ï¼Œå³åœ¨åˆ†å‰²åæœ€æœ‰æ•ˆåœ°ä½¿ç»„æ›´çº¯:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="55e5" class="jl jm hh jh b fi jn jo l jp jq">for i in dt.feature_importances_.argsort()[:-20:-1]: # Top 20<br/>    print(X.columns[i])</span></pre><p id="d8f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬è¿˜å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ£€æŸ¥æ·±åº¦</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="5c59" class="jl jm hh jh b fi jn jo l jp jq">dt.get_depth() # when max_depth is set low (to improve interpretability in my case), it usually reaches the maximum, but in some cases it might not.</span></pre><p id="d3a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä¸ºäº†è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹åœ¨åˆ†ç±»æ–¹é¢çš„è¡¨ç°ï¼Œæ··æ·†çŸ©é˜µå°±æ´¾ä¸Šäº†ç”¨åœº:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="8979" class="jl jm hh jh b fi jn jo l jp jq">y_pred = dt.predict(X_test)<br/>a = confusion_matrix(y_test, y_pred)<br/>np.diag(a).sum()/a.sum() # percent of accurately classified fictions</span></pre><h2 id="d362" class="jl jm hh bd ka ld le lf ke lg lh li ki ip lj lk km it ll lm kq ix ln lo ku lp bi translated">è§£é‡Šç»“æœ</h2><p id="1882" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">ç”±äºDTåœ¨è§†è§‰è¡¨ç°ä¸Šæœ‰ä¼˜åŠ¿ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›åœ¨æ ‘å½¢å›¾ä¸­çœ‹åˆ°æˆ‘ä»¬çš„æœ€ç»ˆç»“æœï¼Œå¹¶è¯•å›¾è§£é‡Šå®ƒã€‚</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="4029" class="jl jm hh jh b fi jn jo l jp jq">data = tree.export_graphviz(dt, out_file=None, feature_names=list(X.columns))<br/>graph = pydotplus.graph_from_dot_data(data)<br/>graph.write_png('mydecisiontree.png')</span><span id="ba2c" class="jl jm hh jh b fi lx jo l jp jq"># I encounter "ValueError: Program dot not found in path" when running this. Using "<!-- -->brew install" instead of "pip" somehow solved the issue for me.</span></pre><figure class="jc jd je jf fd lz er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es ly"><img src="../Images/7ff8699856e92e5c24baa0ba3d00b31a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K9sE8cn_phG18rh9m1AL0g.png"/></div></div><figcaption class="mg mh et er es mi mj bd b be z dx translated">ç»“æœæ ‘å›¾çš„ä¸€éƒ¨åˆ†</figcaption></figure><p id="84c3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æŒ‰ç…§è¿™ä¸ªå›¾ï¼Œæˆ‘ä»¬åªéœ€è¦è®°ä½ï¼Œå¯¹äºæ ‡ç­¾ä¼ªå˜é‡ï¼Œä¸åŒ…å«å®ƒ(0)å¯¼è‡´å·¦æ ‘ï¼ŒåŒ…å«å®ƒ(1)å¯¼è‡´å³æ ‘ã€‚åœ¨â€œvalue = [aï¼Œb]â€ä¸­ï¼Œaè¡¨ç¤ºâ€œå‡â€(0)çš„æ•°é‡ï¼Œè€Œbç»™å‡ºè¿˜æœ‰å¤šå°‘â€œçœŸâ€(1)ã€‚(ç»éªŒæ³•åˆ™:å·¦è¾¹æ€»æ˜¯æ›´å°)</p><p id="1bb0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä»ä¸Šé¢çš„å›¾è¡¨ä¸­æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå­—æ•°ä¼¼ä¹æ¯”ä»»ä½•æ ‡ç­¾éƒ½é‡è¦ï¼Œå¹¶ä¸”è¯¥æ ‘å°†å°è¯´åˆ†ä¸º14kå­—ä»¥ä¸‹ã€14kåˆ°41kä¹‹é—´å’Œ41kä»¥ä¸Šã€‚å¯¹äºä¸åŒé•¿åº¦çš„å°è¯´ï¼ŒåŒ…å«æŸäº›æ ‡ç­¾ä¼šå¯¼è‡´å®Œå…¨ä¸åŒçš„ç»“æœã€‚ä¾‹å¦‚ï¼Œå¯¹äºè¾ƒçŸ­çš„å°è¯´ï¼ŒåŒ…æ‹¬â€œä½³èƒ½åŒæ€§æ‹å…³ç³»â€ä¼¼ä¹æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ã€‚ä½†æ˜¯è¿™å†³ä¸æ˜¯è§„å®šæ€§çš„ï¼Œå› ä¸ºæˆ‘ä»¬ä¸èƒ½åœ¨è¿™é‡Œå»ºç«‹å› æœå…³ç³»ã€‚ä½†æˆ‘ä»¬ç¡®å®å¯ä»¥ä»æ•°æ®ä¸­è§‚å¯Ÿåˆ°ä¸€èˆ¬è¯»è€…çš„åå¥½ã€‚</p><p id="eebf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä½ å¯èƒ½æƒ³çŸ¥é“æˆ‘æ˜¯å¦‚ä½•ä¸ºDTåˆ†ç±»å™¨é€‰æ‹©å‚æ•°å€¼çš„ã€‚ä¸ºä»€ä¹ˆæ˜¯ç†µè€Œä¸æ˜¯åŸºå°¼ï¼Ÿäº‹å®ä¸Šï¼Œè¿™äº›é€‰æ‹©å¯èƒ½ä¼šä¸¥é‡å½±å“æ¨¡å‹æ€§èƒ½ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå¾ªç¯æ¥æ”¶é›†ä¸åŒå€¼çš„å½±å“ã€‚ä¾‹å¦‚ï¼Œmin _ infinity _ decreaseä½œä¸ºæ˜¯å¦ä¼šå‘ç”Ÿåˆ†è£‚çš„é˜ˆå€¼æ˜¯éå¸¸æœ‰å½±å“çš„ã€‚æˆ‘ä»¬å¯ä»¥æ£€æŸ¥å¹¶æƒ³è±¡å®ƒçš„æ•ˆæœï¼Œä»¥é€‰æ‹©æœ€ä½³æ–¹æ¡ˆ:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="5f8f" class="jl jm hh jh b fi jn jo l jp jq">min_decrease = []<br/><br/>for i in range(1,10):<br/>    dtree = DecisionTreeClassifier(criterion='entropy', max_depth=20, min_impurity_decrease=i/1000)<br/>    dtree.fit(X_train, y_train)<br/>    pred = dtree.predict(X_test)<br/>    acc_entropy.append(accuracy_score(y_test, pred))<br/>    <br/>    min_decrease.append(i)</span><span id="d2db" class="jl jm hh jh b fi lx jo l jp jq">d = pd.DataFrame({'acc_entropy':pd.Series(acc_entropy), 'min_decrease':pd.Series([i/1000 for i in min_decrease])})<br/>plt.plot('min_decrease','acc_entropy', data=d, label='entropy')<br/>plt.xlabel('min_decrease')<br/>plt.ylabel('accuracy')<br/>plt.legend()</span></pre><figure class="jc jd je jf fd lz er es paragraph-image"><div class="er es mk"><img src="../Images/c2decda8f5ce51b7c88933726f90ee53.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*QGmk9vwLhYsedYKPf5bzww.png"/></div></figure><p id="510e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å¯ä»¥æ„å»ºå¤šçº¿å›¾è¡¨æ¥æ¯”è¾ƒåŸºå°¼ç³»æ•°å’Œç†µä¸ä¸åŒæ·±åº¦æˆ–åˆ†å‰²é˜ˆå€¼çš„å…³ç³»ã€‚å‰é¢æåˆ°çš„æ–‡ç« æ›´è¯¦ç»†åœ°è¯´æ˜äº†è¿™ä¸ªè¿‡ç¨‹ã€‚</p></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="85ac" class="jz jm hh bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">kå‡å€¼èšç±»</h1><p id="1dc2" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">æˆ‘è¿˜å¯¹å°è¯´ä½œè€…åœ¨è¿™ä¸ªçˆ±å¥½è€…åœˆå­é‡Œå†™çš„ä¸»é¢˜æ„Ÿå…´è¶£ï¼Œè€Œå¯¹å°è¯´æ–‡æœ¬è¿›è¡Œèšç±»å°†æ˜¯ä¸€é¡¹è¦æ±‚è¿‡é«˜çš„å·¥ä½œï¼Œå¯èƒ½ä¼šçƒ§åæˆ‘å¯æ€œçš„ç¬”è®°æœ¬ç”µè„‘â€”â€”<em class="lt">å¯¹æˆ‘æ¥è¯´ï¼Œå¯¹åƒå°è¯´è¿™æ ·çš„é•¿æ–‡æœ¬è¿›è¡Œèšç±»æ˜¯å¦æ˜¯ä¸€ä»¶æ ‡å‡†/æ˜æ™º/å¯è¡Œçš„äº‹æƒ…ä»ç„¶ä¸æ¸…æ¥šã€‚</em></p><p id="009a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä¸ºäº†ä¿æŒè¿™ä¸ªé¡¹ç›®çš„èƒƒå£ï¼Œæˆ‘å†³å®šå…ˆæŠŠæ‘˜è¦èšé›†èµ·æ¥ï¼Œå¸Œæœ›å®ƒä»¬èƒ½ä¸ºçœŸå®çš„å°è¯´æä¾›ä¸€ä¸ªå¾ˆå¥½çš„é¢„è§ˆã€‚</p><p id="f92f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä»¥ä¸‹æ˜¯æ‰€éœ€çš„é™„åŠ åº“:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="4113" class="jl jm hh jh b fi jn jo l jp jq">import nltk<br/>import re<br/>from sklearn import feature_extraction<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.metrics.pairwise import cosine_similarity<br/>from sklearn.cluster import KMeans<br/>from nltk.stem.snowball import SnowballStemmer<br/># from gensim import corpora, models, similarities &lt;-- use if LDA</span></pre><h2 id="cd6e" class="jl jm hh bd ka ld le lf ke lg lh li ki ip lj lk km it ll lm kq ix ln lo ku lp bi translated">æ•°æ®æ“ä½œ</h2><p id="5292" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¿¡æ¯æ£€ç´¢çš„ç†è®ºæˆ‘å°±ä¸æ·±ç©¶äº†ã€‚ä¸€ä¸ªç®€åŒ–çš„è¿‡ç¨‹åŒ…æ‹¬æ ‡è®°åŒ–ã€è¯å¹²åŒ–ã€åˆ é™¤åœç”¨è¯å’ŒçŸ¢é‡åŒ–ã€‚</p><p id="0565" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä»¥ä¸‹æ˜¯è‹±è¯­çš„æµç¨‹:</p><figure class="jc jd je jf fd lz"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="09b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬æ„å»ºäº†è‡ªå®šä¹‰çš„åœç”¨è¯è¡¨ã€æ ‡è®°å™¨å’Œè¯å¹²åˆ†æå™¨ï¼Œä»¥è¾“å…¥åˆ°TfidfVectorizerä¸­ï¼Œç„¶åä½¿ç”¨å®ƒä¾æ¬¡å¯¹æ¯ä¸ªæ‘˜è¦è¿›è¡Œç¼–ç ã€‚ç»“æœå°†æ˜¯å½¢çŠ¶çš„ç¨€ç–çŸ©é˜µâ€”(æ–‡æ¡£æ•°ã€ç‰¹å¾æ•°)ã€‚</p><p id="2730" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä½ å¯ä»¥æ·±å…¥ç ”ç©¶TfidfVectorizerçš„<a class="ae jr" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html" rel="noopener ugc nofollow" target="_blank">æ–‡æ¡£</a>æ¥å¯»æ‰¾æ›´å¤šçš„æ æ†ã€‚ä¾‹å¦‚ï¼ŒMax_df=0.8è¡¨ç¤ºæˆ‘ä¸ä¼šæŸ¥çœ‹åœ¨è¶…è¿‡80%çš„æ–‡æ¡£ä¸­å‡ºç°çš„æœ¯è¯­(è¿™å¯èƒ½ä¸ä¼šæä¾›å¤ªå¤šæœ‰ç”¨çš„ä¿¡æ¯)ã€‚min_df=5è¡¨ç¤ºè¯¥æœ¯è¯­éœ€è¦å‡ºç°åœ¨5ä¸ªä»¥ä¸Šçš„æ–‡æ¡£ä¸­æ‰èƒ½è¢«è®¤ä¸ºæ˜¯æœ‰ä»·å€¼çš„ã€‚</p><p id="1502" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä»¥ä¸‹æ˜¯è·å–è¿™äº›åŠŸèƒ½çš„æ–¹æ³•:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="faea" class="jl jm hh jh b fi jn jo l jp jq">terms = tfidf_vectorizer.get_feature_names()</span></pre><p id="501b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬ä½¿ç”¨TF-IDF(æœ¯è¯­é¢‘ç‡ä¹˜ä»¥é€†æ–‡æ¡£é¢‘ç‡)è€Œä¸æ˜¯ç®€å•çš„è®¡æ•°ï¼Œå› ä¸ºå®ƒè€ƒè™‘äº†æœ¯è¯­åœ¨ç‰¹å®šæ–‡æ¡£ä¸­çš„é‡è¦æ€§åŠå…¶ç›¸å¯¹äºæ•´ä¸ªè¯­æ–™åº“çš„é‡è¦æ€§ã€‚è¿™ä¸ªæƒ³æ³•æ˜¯ï¼Œå¦‚æœä¸€ä¸ªåœ¨æ•´ä¸ªè¯­æ–™åº“ä¸­ç½•è§çš„æœ¯è¯­ç¡®å®å‡ºç°åœ¨æŸä¸ªæ–‡æ¡£ä¸­ï¼Œå®ƒä¸€å®šå¯¹è¯¥æ–‡æ¡£æœ‰ç‰¹æ®Šçš„æ„ä¹‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é™ä½äº†å‡ºç°åœ¨å¤§å¤šæ•°æ–‡æ¡£ä¸­çš„æ ‡è®°çš„æƒé‡ï¼ŒåŒæ—¶çªå‡ºäº†æ›´æœ‰æ„ä¹‰çš„æ ‡è®°ã€‚</p><p id="2c69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ç”±äºæˆ‘ä»¬çš„tfidf_matrixä¸­çš„å€¼è¡¨ç¤ºå®ƒä»¬çš„ç›¸å¯¹é‡è¦æ€§ï¼Œæˆ‘ä»¬ç”šè‡³å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ‰¾åˆ°æŸä¸ªæ–‡æ¡£çš„å…³é”®å­—â€”â€”</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="c575" class="jl jm hh jh b fi jn jo l jp jq">for i in tfidf_matrix[your document's index].toarray()[0].argsort()[::-1][:30]:<br/>    print(terms[i])</span></pre><p id="e0a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ¥æŸ¥æ‰¾æœ€æ¥è¿‘çš„æ–‡æ¡£ï¼Œä½†æˆ‘ä¸ä¼šåœ¨è¿™é‡Œè¯¦ç»†ä»‹ç»:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="1d82" class="jl jm hh jh b fi jn jo l jp jq">cosine_similarity(tfidf_matrix)[your document's index].argsort()[:-5:-1] # top 4 neighbors since the first would always be itself</span></pre><p id="b521" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æ­¤å¤–ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªå…³äº<a class="ae jr" href="https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words" rel="noopener ugc nofollow" target="_blank">ä½¿ç”¨åœç”¨è¯</a>çš„æœ‰ç”¨è¯´æ˜ï¼Œå› ä¸ºæˆ‘ä¸€è·¯ä¸Šé‡åˆ°äº†å¾ˆå¤šè¿™æ ·çš„è­¦å‘Š:</p><blockquote class="lq lr ls"><p id="5d58" class="ie if lt ig b ih ii ij ik il im in io lu iq ir is lv iu iv iw lw iy iz ja jb ha bi translated">Y <!-- -->æ‚¨è¿˜åº”è¯¥ç¡®ä¿åœç”¨è¯è¡¨å·²ç»åº”ç”¨äº†ä¸çŸ¢é‡å™¨ä¸­ä½¿ç”¨çš„ç›¸åŒçš„é¢„å¤„ç†å’Œæ ‡è®°åŒ–ã€‚å•è¯<em class="hh">we have</em>è¢«CountVectorizerçš„é»˜è®¤æ ‡è®°å™¨æ‹†åˆ†ä¸º<em class="hh"> we </em>å’Œ<em class="hh"> ve </em>ï¼Œå› æ­¤å¦‚æœ<em class="hh">we have</em>åœ¨<code class="du mn mo mp jh b">stop_words</code>ä¸­ï¼Œè€Œ<em class="hh"> ve </em>ä¸åœ¨ï¼Œé‚£ä¹ˆåœ¨è½¬æ¢åçš„æ–‡æœ¬ä¸­ï¼Œå°†ä»<em class="hh">we have</em>ä¸­ä¿ç•™<em class="hh"> ve </em>ã€‚æˆ‘ä»¬çš„çŸ¢é‡å™¨å°†è¯•å›¾è¯†åˆ«å’Œè­¦å‘ŠæŸäº›ç±»å‹çš„ä¸ä¸€è‡´ã€‚</p></blockquote></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><p id="145a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">Processing Chinese summaries is a totally different story. While English has clearly space-delimited words as tokens, Chinese token definition can be a little complicated. More than one characters can stick together to constitute one token, such as â€˜å­¦æ ¡â€™ for â€˜schoolâ€™ â€” either of these characters alone wouldnâ€™t carry the intended meaning.</p><p id="142c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å®ƒè¿˜éœ€è¦ä¸€ç»„ä¸åŒçš„åœç”¨è¯ã€å¥å°¾å’Œæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼åŒ¹é…è§„åˆ™ã€‚å¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬æœ‰å¾ˆå¤šå¯ç”¨çš„å¥½èµ„æº:</p><blockquote class="lq lr ls"><p id="0226" class="ie if lt ig b ih ii ij ik il im in io lu iq ir is lv iu iv iw lw iy iz ja jb ha bi translated">åœå­—:<a class="ae jr" href="https://github.com/stopwords-iso/stopwords-zh" rel="noopener ugc nofollow" target="_blank">https://github.com/stopwords-iso/stopwords-zh</a></p><p id="60a0" class="ie if lt ig b ih ii ij ik il im in io lu iq ir is lv iu iv iw lw iy iz ja jb ha bi translated">unicodeä¸­çš„æ±‰å­—:ã€https://github.com/tsroten/zhon/blob/develop/zhon/hanzi.py T2ã€‘</p><p id="5416" class="ie if lt ig b ih ii ij ik il im in io lu iq ir is lv iu iv iw lw iy iz ja jb ha bi translated">æ ‡è®°åŒ–:ã€https://github.com/fxsjy/jiebaã€‘T4</p><p id="f4ac" class="ie if lt ig b ih ii ij ik il im in io lu iq ir is lv iu iv iw lw iy iz ja jb ha bi translated">æ·±åº¦å­¦ä¹ :<a class="ae jr" href="https://github.com/PaddlePaddle/Paddle" rel="noopener ugc nofollow" target="_blank">https://github.com/PaddlePaddle/Paddle</a></p></blockquote><p id="1eb3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è¦åŠ è½½çš„å…¶ä»–å·¥å…·åŒ…å¯èƒ½éœ€è¦å…ˆå®‰è£…:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="36e3" class="jl jm hh jh b fi jn jo l jp jq">import jieba<br/>from __future__ import unicode_literals<br/>import paddle</span></pre><p id="e90b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä¸­å›½äººçš„æµç¨‹æ˜¯è¿™æ ·çš„:</p><figure class="jc jd je jf fd lz"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="b2e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å¯¹äºè¿™ä¸¤ç§è¯­è¨€ï¼Œä¸‹é¢çš„è¿‡ç¨‹æ˜¯ç›¸åŒçš„ã€‚</p><h2 id="1815" class="jl jm hh bd ka ld le lf ke lg lh li ki ip lj lk km it ll lm kq ix ln lo ku lp bi translated">æ„å»ºæ¨¡å‹</h2><p id="89ca" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">ä¸ºäº†æ£€æŸ¥æœ€ä½³çš„é›†ç¾¤æ•°é‡ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å»ºç«‹ä¸€ä¸ªè‚˜å½¢å›¾</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="ac65" class="jl jm hh jh b fi jn jo l jp jq">km = [KMeans(n_clusters=i) for i in range(1,11)]<br/>score = [k.fit(tfidf_matrix).inertia_ for k in km]<br/>plt.plot(range(1,11),score)</span></pre><figure class="jc jd je jf fd lz er es paragraph-image"><div class="er es mq"><img src="../Images/752044f1751d6703824d848e2b1f3b39.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*EhxAVoCwkv-NE5mgXhsuhA.png"/></div></figure><p id="1935" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è™½ç„¶çœ‹èµ·æ¥åªæœ‰3ä¸ªé›†ç¾¤æ˜¯æœ€ä½³çš„ï¼Œä½†ç»è¿‡å‡ æ¬¡å°è¯•åï¼Œæˆ‘å‘ç°5ä¸ªé›†ç¾¤çš„è§£å†³æ–¹æ¡ˆæ˜¯æœ€åˆç†çš„ã€‚</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="a3a5" class="jl jm hh jh b fi jn jo l jp jq">km = KMeans(n_clusters=5)<br/>km.fit(tfidf_matrix)</span><span id="c803" class="jl jm hh jh b fi lx jo l jp jq"># append cluster labels back to the dataframe<br/>clusters = km.labels_.tolist()<br/>eng_sum['Clusters'] = clusters</span><span id="928e" class="jl jm hh jh b fi lx jo l jp jq"># compare each cluster's centrality measures<br/>grouped = eng_sum.groupby('Clusters') # or chi_sum<br/>grouped.mean()</span></pre><figure class="jc jd je jf fd lz er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es mr"><img src="../Images/611f78d104919a4d356e4e0514817d8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E2luPWcpgt5XC7VgEoqjgQ.png"/></div></div></figure><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="dc28" class="jl jm hh jh b fi jn jo l jp jq"># to know how many members each cluster has<br/>grouped.size()</span></pre><h2 id="60fd" class="jl jm hh bd ka ld le lf ke lg lh li ki ip lj lk km it ll lm kq ix ln lo ku lp bi translated">è§£é‡Šç»“æœ</h2><p id="b95c" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">ä¸ºäº†ç†è§£è¿™äº›èšç±»ï¼Œæˆ‘ä»¬å¯ä»¥æŒ‰ç…§TF-IDFå€¼ä»¥åŠå‡ ä¸ªæœ‰ä»£è¡¨æ€§çš„å‡è®¾æ¥æŸ¥çœ‹æ¯ä¸ªèšç±»çš„å…³é”®å­—:</p><pre class="jc jd je jf fd jg jh ji jj aw jk bi"><span id="3173" class="jl jm hh jh b fi jn jo l jp jq">importance_by_cluster = km.cluster_centers_.argsort()[:, ::-1] </span><span id="707b" class="jl jm hh jh b fi lx jo l jp jq">for i in range(5):<br/>    print("Cluster {} words:".format(i))<br/>    <br/>    for ind in importance_by_cluster[i, :20]:<br/>        print(terms[ind]+', ', end=' ') # top 20 words<br/>        # terms are the list of features<br/>    <br/>    subset = eng_sum[eng_sum.Clusters==i].copy() # or chi_sum<br/>    subset = subset.sort_values(by='Num_hits', ascending=False)<br/>    print(subset.iloc[:10,[0,2]]) # print out most popular fictions belong to the cluster as representatives</span></pre><p id="84b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ä¾‹å¦‚ï¼Œåœ¨æˆ‘æ¢ç´¢çš„ç²‰ä¸åœˆä¸­ï¼Œæˆ‘å‘ç°äº†ä¸€ä¸ªå…³æ³¨å“ˆåˆ©Â·æ³¢ç‰¹å’Œä¼åœ°é­”ä¹‹é—´äº’åŠ¨çš„é›†ç¾¤ï¼Œå…³é”®è¯æ˜¯â€œå“ˆåˆ©ã€ä¸–ç•Œã€æ³¢ç‰¹ã€å·«å¸ˆã€æ±¤å§†ã€é»‘æš—ã€æ—¶é—´ã€ç”Ÿå‘½ã€æ­»äº¡ã€éœæ ¼æ²ƒèŒ¨ã€ä¼åœ°é­”ã€é­”æ³•ã€riddlã€æ´»ç€ã€åŠ›é‡ï¼Œâ€å¦ä¸€ä¸ªé›†ç¾¤æ˜¾ç„¶ä»tumblrçš„å†™ä½œæç¤ºä¸­è·å¾—äº†çµæ„Ÿâ€”â€”â€œæç¤ºã€æç¤ºå»ã€å»ã€ç¬¦å·ã€Tumblrã€drabblã€exchangã€challengï¼Œâ€è¿˜æœ‰å¦ä¸€ä¸ªæƒ…æ„Ÿä¸°å¯Œçš„ä½œè€…ç¾¤è§¦æ‘¸ç€å„é‡Œæ–¯ä¹‹é•œâ€”â€”â€œé•œå­ã€é•œå­å„é‡Œæ–¯ã€å„é‡Œæ–¯ã€çœ‹è§ã€è¢œå­ã€çœ‹é•œå­</p><p id="9b3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">While Chinese and English topics are vastly different, interestingly, they both had one cluster dedicated to the mirror of erised. The Chinese version has somewhat similar keywords â€” â€œå„é‡Œæ–¯ (erised), é­”é•œ (mirror), è‡ªæˆ‘, ç«™, æ¨, é‚“æ ¡, æ¬ºéª—, åŒå¼ƒ, å¹´å°‘è½»ç‹‚, å°‘ä¸æ›´äº‹, å¾·å§†æ–¯ç‰¹æœ—, çœ‹åˆ° (see), æ’’è° (lie), é¢å‰ (front).â€ (overlapping ones translated)</p><p id="78a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">æˆ‘ä»¬å¯ä»¥å°†æˆ‘ä»¬ä»æŸ¥çœ‹è¿™äº›å…³é”®å­—ä¸­è·å¾—çš„å¯¹èšç±»çš„ç†è§£ä¸æ¥è‡ªå…¶ä»–æ•°å€¼å˜é‡çš„ä¸­å¿ƒæ€§åº¦é‡ç»“åˆèµ·æ¥ï¼Œä»¥å¾—å‡ºæ›´æœ‰è§åœ°çš„ç»“è®ºï¼Œä¾‹å¦‚ä»€ä¹ˆä¸»é¢˜ä¼šå¼•å‘æœ€å¤šçš„ååº”ï¼Œä»¥åŠå“ªäº›ä¸»é¢˜ä¼šæ˜¯æ›´å¥½çš„ç‚¹å‡»è¯±é¥µã€‚</p><p id="17bc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">è™½ç„¶æˆ‘å¦å¤–å°è¯•äº†ä¸»é¢˜å»ºæ¨¡ï¼Œä½†å®ƒåŸºæœ¬ä¸Šè¯å®äº†æ¥è‡ªé›†ç¾¤çš„è§è§£ï¼Œæ‰€ä»¥æˆ‘ä¸ä¼šåœ¨è¿™é‡Œä»‹ç»å®ƒã€‚</p><p id="a738" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">å½“ç„¶è¿˜æœ‰æ›´å¤šçš„å¯èƒ½æ€§å¯ä»¥ç©ã€‚æˆ‘ä¼šç»§ç»­æ¢ç´¢æ–°çš„é€‰æ‹©ğŸ˜Š</p></div></div>    
</body>
</html>