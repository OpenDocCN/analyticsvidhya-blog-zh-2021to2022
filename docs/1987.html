<html>
<head>
<title>Possible issues of the loss for Deep Learning-based Super-Resolution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的超分辨率可能存在的损失问题</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/possible-issues-of-the-loss-for-deep-learning-based-super-resolution-649c5bd79635?source=collection_archive---------4-----------------------#2021-03-30">https://medium.com/analytics-vidhya/possible-issues-of-the-loss-for-deep-learning-based-super-resolution-649c5bd79635?source=collection_archive---------4-----------------------#2021-03-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="017d" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">超分辨率</h1><p id="12b0" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">超分辨率(SR)是从低分辨率(LR)图像中恢复高分辨率(HR)图像的任务。最近的方法显示了惊人的重建性能方面的定性感知和定量基准(PSNR，SSIM)。尽管以前方法中的许多问题通过进一步的研究得到了解决，但我们仍然认为当前基于DL的随机共振方法继承了一些基本问题，特别是损失函数。我们将特别关注单幅图像超分辨率(SISR)的当前方法的问题，其中我们接收一幅单幅LR图像并旨在输出一幅HR图像。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ka"><img src="../Images/59bd15e1b1231fddb75580fc047db966.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HdGzBPByulokfYMFV_0S0A.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated"><a class="ae kq" href="https://arxiv.org/abs/1904.07523" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1904.07523</a></figcaption></figure><p id="0602" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">我们将首先非常快速地概述当前基于深度学习的SR方法。要深入了解基于DL的软件无线电方法，请参考<a class="ae kq" href="https://arxiv.org/abs/1904.07523" rel="noopener ugc nofollow" target="_blank">的这篇文章</a>和<a class="ae kq" href="https://blog.paperspace.com/image-super-resolution/" rel="noopener ugc nofollow" target="_blank">的这篇博文</a>。</p><h2 id="1d91" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated">模型架构</h2><p id="1b01" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在损失函数和模型架构方面，有多种方法来完成SISR的任务。上面描述了一些方法。在SRCNN首次将卷积神经网络引入SR任务之后，数百种改变模型架构的变体被提出。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lk"><img src="../Images/46847a4b6a0f7bc15404788eaf9d0532.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SYVGAZiQmEu0bkVZqEJSyg.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated"><a class="ae kq" href="https://paperswithcode.com/sota/image-super-resolution-on-set14-4x-upscaling" rel="noopener ugc nofollow" target="_blank">https://papers with code . com/sota/image-super-resolution-on-set 14-4x-upscaling</a></figcaption></figure><p id="8cf4" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">这些方法包括FSRCNN、VDSR、ESRCNN，以及基于残差块的模型，如EDSR、MDSR、CARN。还介绍了基于递归网络的方法和基于DenseNet块的方法。最后，提出了基于注意力的体系结构，该体系结构主要利用基于通道和基于渐进的模型。</p><p id="28a3" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">还提出了各种上采样技术，如ESRCNN像素平铺、预上采样和去卷积，并应用于各种模型架构。</p><h2 id="c516" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated">基于内容的损失</h2><p id="77a8" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">诸如SRCNN的第一种方法提出了基于重建图像f(LR)和HR图像之间的内容损失或者主要是MSE损失的训练算法。这也直接有利于PSNR度量。这个损失建议似乎非常合理和直接，但它继承了SRGAN论文提出的一个非常基本的问题。</p><p id="f210" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">这些面向PSNR的方法倾向于输出平滑的结果，而没有足够的高频细节，因为MSE损失和PSNR度量从根本上与人类观察者的主观评价不一致。这是因为对于一个给定的LR面片有多个可能的输出，并且基于MSE的解决方案通常找到解决方案的逐像素平均值，这可能不存在于真实的HR流形上并且被平滑。下图对此进行了描述。</p><p id="3ab8" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">例如，可能存在输出非常相似的LR图像的两个HR图像HR1和HR2。因此，当仅给出LR时，重建f(LR)可能是HR1或HR2，但是MSE损失倾向于输出两个可能的HR片的平均值。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ll"><img src="../Images/448e62b1fef329ef112cabba4541acfb.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*Cy_vZQyZcq4W_3ATPLv7pQ.png"/></div></figure><p id="0c87" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">尽管一些情况可以通过非常复杂的神经网络来学习，但是对于一个给定的LR图像，SR的正确HR片不是奇异的这种行为对基于MSE的解决方案造成了基本限制，并且具有输出过度平滑的输出的行为。</p><h2 id="3d07" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated">对此行为的解决方案</h2><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lm"><img src="../Images/d95b781e36f677ba78d97af2cbe9f5e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ypr1l4Dw-uNpHX3uc7_5WA.png"/></div></div></figure><p id="1f64" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">作为对SR模型输出过度平滑图像这一现象的解决方案，一个工作分支提出了生成对抗网络(GAN)。这些作品包括SRGAN、EnchanceNet、e SRGAN和最近的RSRGAN。甘作品通常采用内容损失和对抗损失之和。他们还经常利用感知损失，通常是预先训练的VGG19网络的中间激活。下面的等式是ESRGAN的损耗公式。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ln"><img src="../Images/688e8ea38328c9cb0444b5bd8bc6a655.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*yt6sXIRWAuS4kjfAI-xnuQ.png"/></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lo"><img src="../Images/18bccc3041c21ad1da8cbee0e1b414a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YJjNXmy3tQB_VugQtcIuSg.png"/></div></div></figure><p id="4389" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">根据SRGAN论文的经验结果，单独使用GAN损失不足以生成高分辨率纹理细节，必须与感知损失相结合。</p><p id="43e1" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">基于GAN的解决方案在基于像素的量化指标(如PSNR和SSIM)方面的表现不如基于MSE的模型，但表现出更好的感知质量和非常高的平均意见得分(MOS ),这是许多情况下的关键兴趣。</p><p id="05a6" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">虽然基于GAN的解决方案是偏好感知质量的最佳解决方案，并且它们在生成照片般逼真的HR图像方面最为成功，但是它们继承了GAN训练的问题。对GAN基SR解决方案的观察和我个人的看法发现学习GAN基SR有四个实际和概念上的问题。</p><ol class=""><li id="3cff" class="lp lq hh je b jf kr jj ks jn lr jr ls jv lt jz lu lv lw lx bi translated">不想要的伪像:发生器通常生成远离LR图像的图像，图像中存在不想要的伪像。GAN训练的不稳定性和下面的所有问题结合起来解释了这些伪像。</li><li id="19db" class="lp lq hh je b jf ly jj lz jn ma jr mb jv mc jz lu lv lw lx bi translated">D的过拟合:BigGAN提出的GAN训练中的一个基本问题，对抗性训练永远不会完成，鉴别器容易过拟合。我相信D的过拟合在SR中可能更多地存在，因为图像的数量很少，并且G没有接收到任何种类的噪声，因此限制了G输出图像分布的能力。</li><li id="e9e7" class="lp lq hh je b jf ly jj lz jn ma jr mb jv mc jz lu lv lw lx bi translated"><strong class="je hi">没有输出分布</strong>的能力:常规GAN和用于SR的GAN之间的发电机网络的一个基本区别是没有噪声或潜在矢量的<strong class="je hi">。因此，对于一个给定的LR补片，该模型只能输出一个图像。根据<a class="ae kq" href="https://arxiv.org/abs/1804.02815" rel="noopener ugc nofollow" target="_blank"> STF-SR论文</a>，模型必须能够针对不同的环境和纹理信息输出不同的SR结果。我相信这是在对抗损失率较高的情况下训练时容易出现模式崩溃的关键原因。</strong></li><li id="7e5d" class="lp lq hh je b jf ly jj lz jn ma jr mb jv mc jz lu lv lw lx bi translated">混合损失:混合多种损失在引入两种极端状态之间的权衡方面是有益的。但这也意味着这两种损耗都不是衡量SR整体性能的最佳指标。我认为GAN基SR中有一个关键元素丢失了，必须通过修改损耗函数来解决。</li></ol><p id="525b" class="pw-post-body-paragraph jc jd hh je b jf kr jh ji jj ks jl jm jn kt jp jq jr ku jt ju jv kv jx jy jz ha bi translated">总之，生成器只能输出一个对应的随机共振，而根据特定零件的完整图像和纹理，可能会有多个解决方案。这也可能导致D的过度拟合，因为生成的图像具有较小的变化。混合损失也不是解决这两种损失的根本办法。我非常有信心有空间从概念上改进SR的损失函数。</p><h1 id="5c49" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">下采样操作</h1><p id="5996" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">如果LR对应物是通过双三次下采样或另一种特定方法LR=bic(HR)生成的，则超分辨率旨在le<strong class="je hi">arn BIC:f(LR)= HR的反函数</strong>，但是在现实问题中，不能保证下采样操作是用于训练的特定操作。我们将在下一篇文章中讨论这个问题。</p></div></div>    
</body>
</html>