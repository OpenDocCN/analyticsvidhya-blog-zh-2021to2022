<html>
<head>
<title>Deep Learning Specialization Course Notes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习专业化课程笔记</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-learning-specialization-course-notes-3cb2734ea36e?source=collection_archive---------24-----------------------#2021-01-08">https://medium.com/analytics-vidhya/deep-learning-specialization-course-notes-3cb2734ea36e?source=collection_archive---------24-----------------------#2021-01-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="3237" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">课程2:改进神经网络:超参数调整、正则化和优化</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/0eb8d3e938ac7415ff6620de68bfb1d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S6YgMFJwgPUrkyWsGpmZbg.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">图片来源:www.giveffect.com</figcaption></figure><p id="4691" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">我从Coursera开始写深度学习专业化课程的课程笔记。当我写的时候，我的概念变得清晰，我对主题有了更好的理解。希望这些笔记对大家有用。</p><p id="daf9" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">有了这篇文章，我准备跳到深度学习专业化课程的课程2。如果你还没有看我关于第一门课的文章，请点击<a class="ae ki" rel="noopener" href="/analytics-vidhya/deep-learning-specialization-353c997af655">这个</a>链接。</p><p id="fafc" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">本课程将集中于机器学习的实践方面，例如学习使神经网络工作良好的方面。它将从超参数调整到优化算法，使它们能够快速运行。不要再拖延了，让我们开始吧。</p></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><h2 id="96bc" class="kq kr hh bd ks kt ku kv kw kx ky kz la jv lb lc ld jz le lf lg kd lh li lj lk bi translated">如何选择培训、开发和测试集</h2><p id="67d9" class="pw-post-body-paragraph jm jn hh jo b jp ll ii jr js lm il ju jv ln jx jy jz lo kb kc kd lp kf kg kh ha bi translated">在训练数据时，我们必须做出几个决定，例如选择隐藏单元的数量、激活函数的类型、隐藏层的数量、学习速率等，并且不可能一次正确预测所有的参数和超参数。因此，机器学习是一个高度迭代的过程，我们从一个想法开始，在代码中实现它，并尝试运行它。根据结果，我们尝试改进这个想法，并不断迭代，直到我们找到一个更好的神经网络。</p><p id="eeea" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">决定我们进展速度的参数之一是我们在这个迭代周期中的效率。另一个重要的参数是在训练、开发和测试集中设置数据，从而提高效率。</p><p id="535f" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">传统上，当我们有数据时，我们会保留其中的很大一部分用于训练，称为<strong class="jo hi">训练集</strong>。然后其中的一部分将用于交叉验证或开发，称为<strong class="jo hi">交叉验证集或开发集。</strong>其中一部分将用于最终测试，称为<strong class="jo hi">测试集</strong>。</p><p id="4a42" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">随着工作流的进行，我们使用训练集来训练几个算法，并使用许多不同的算法来查看哪一个在dev集上执行得最好。一旦我们完成了这种方法，我们将采用我们的最终模型，并在测试集上对其进行评估，以获得该算法表现如何的公正评估。在以前，将数据分成70/30%的训练和测试部分，或者60/20/20%的训练、开发和测试部分，这是一种被广泛接受的做法。在现代大数据时代，将有数百万的数据，我们可能不需要开发集的整个20%来测试算法。例如，如果我们有一百万个例子，那么我们可以将10，000个例子作为开发集，10，000个作为测试集，这样就有98%是训练集，1%是开发集，1%是测试集。</p><p id="f45a" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在训练算法时观察到的一个更常见的错误是在不匹配的训练和测试集上训练它。我们应该遵循的经验法则是确保所有集合都来自同一个分布。</p><p id="c7e3" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">将数据分成训练/开发集或训练/开发/测试集允许我们更快地迭代，并测量偏差和方差，以便我们可以有效地改进算法。</p></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><h2 id="5f21" class="kq kr hh bd ks kt ku kv kw kx ky kz la jv lb lc ld jz le lf lg kd lh li lj lk bi translated">偏差和方差</h2><p id="d25f" class="pw-post-body-paragraph jm jn hh jo b jp ll ii jr js lm il ju jv ln jx jy jz lo kb kc kd lp kf kg kh ha bi translated">当算法使用某些特征在更大的数据集中进行更好的概括时，这被称为<strong class="jo hi">高偏差或欠拟合</strong>。相反，当一个算法变得对某些噪声敏感时，它被称为<strong class="jo hi">高方差或过拟合</strong>。</p><p id="f409" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">了解偏差和方差的两个关键数字是<strong class="jo hi">训练集误差和开发集误差。</strong>在训练<strong class="jo hi"> </strong>数据集时，如果我们的训练集误差低而开发集误差高，那么该算法将被认为具有高方差，因为它无法在开发集上很好地推广。相反，如果数据集具有较高的训练集误差和大致相同的偏差集误差，则该算法被认为具有较高的偏差。假设基本误差或人为误差为0%,两种情况都被认为是有效的，并且两组都来自相同的分布。下面是一些偏差和方差的例子。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lq"><img src="../Images/3d275e04bbba6601c87631ba3eca3ee0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1300/format:webp/1*ngAmMpyqYGjegRzhQicd4w.png"/></div></figure><p id="d771" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">根据算法是否遭受高偏差或高方差或两者，我们可以尝试做几件事来改进算法。</p></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><h2 id="b9ad" class="kq kr hh bd ks kt ku kv kw kx ky kz la jv lb lc ld jz le lf lg kd lh li lj lk bi translated">机器学习的基本方法</h2><p id="e685" class="pw-post-body-paragraph jm jn hh jo b jp ll ii jr js lm il ju jv ln jx jy jz lo kb kc kd lp kf kg kh ha bi translated">为了改进算法以具有低偏差或方差，我们可以遵循一些基本步骤。</p><ol class=""><li id="d7de" class="lr ls hh jo b jp jq js jt jv lt jz lu kd lv kh lw lx ly lz bi translated">训练初始模型</li><li id="b3de" class="lr ls hh jo b jp ma js mb jv mc jz md kd me kh lw lx ly lz bi translated">确定模型是否具有高偏差，如果是，尝试选取具有更多隐藏层或隐藏单元的网络，或者尝试训练模型更长一点时间。</li><li id="d3ae" class="lr ls hh jo b jp ma js mb jv mc jz md kd me kh lw lx ly lz bi translated">确定模型是否具有高方差，如果是，尝试获取更多数据或尝试正则化。</li><li id="7705" class="lr ls hh jo b jp ma js mb jv mc jz md kd me kh lw lx ly lz bi translated">不断重复第3步和第4步，直到我们得到最适合的。</li></ol></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><h2 id="13fd" class="kq kr hh bd ks kt ku kv kw kx ky kz la jv lb lc ld jz le lf lg kd lh li lj lk bi translated">L2正则化</h2><p id="330d" class="pw-post-body-paragraph jm jn hh jo b jp ll ii jr js lm il ju jv ln jx jy jz lo kb kc kd lp kf kg kh ha bi translated">减少方差的基本技术之一是<strong class="jo hi">正则化</strong>。让我们理解它是如何应用于算法的。我们将使用逻辑回归来发展正规化的概念。</p><p id="3aec" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">为了在逻辑回归的损失函数中添加正则化，我们将使用被称为正则化参数的λ和w参数的L2范数，w参数只不过是x个特征的w之和。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mf"><img src="../Images/5ca087e5c6fc762abf6d829cad2c3f81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*TLZqLIrhUl6BQUPfzUiKeQ.png"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mg"><img src="../Images/c98d8218109f04fe34820c771cf5e178.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*22-s4fFNKg7y-e7KuECJNw.png"/></div></figure><p id="a09b" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">通常，只有w被考虑用于正则化，因为它是高维参数向量，而b只是单个数字，因此在实践中正则化b参数没有太大区别。</p><p id="094b" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">lambda的值通常是使用开发集来设置的，我们在开发集中尝试不同的值，看看什么是最好的。如下所示，通过在计算dw值时添加正则化项，它可以与梯度下降一起使用。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mh"><img src="../Images/c90a6cd612ff84cb5e63996b0034c468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*oe5CAC4yMAEY3zRFQGAIEA.png"/></div></figure><h2 id="8ef2" class="kq kr hh bd ks kt ku kv kw kx ky kz la jv lb lc ld jz le lf lg kd lh li lj lk bi translated">为什么正则化减少过拟合？</h2><p id="e66b" class="pw-post-body-paragraph jm jn hh jo b jp ll ii jr js lm il ju jv ln jx jy jz lo kb kc kd lp kf kg kh ha bi translated">关于为什么正则化参数减少过拟合，很少有直觉。</p><ol class=""><li id="bcc6" class="lr ls hh jo b jp jq js jt jv lt jz lu kd lv kh lw lx ly lz bi translated">如果我们将lambda的值增大到巨大，则权重矩阵减小到零，从而导致简化的网络，这可能导致高偏差。因此，谨慎选择λ值是明智的。</li><li id="af13" class="lr ls hh jo b jp ma js mb jv mc jz md kd me kh lw lx ly lz bi translated">另一个直觉，让我们考虑一下tan-h函数。对于小的z值，tan-h函数充当线性函数，并且如果我们将λ的值增大到巨大，则权重矩阵减小到更小的值，最终反映更小的z值。</li></ol><h2 id="81c6" class="kq kr hh bd ks kt ku kv kw kx ky kz la jv lb lc ld jz le lf lg kd lh li lj lk bi translated">辍学正规化</h2><p id="6e75" class="pw-post-body-paragraph jm jn hh jo b jp ll ii jr js lm il ju jv ln jx jy jz lo kb kc kd lp kf kg kh ha bi translated">L2正则化是一种常用的正则化技术，但剔除正则化和L2一样强大。</p><p id="4944" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在退出正则化中，我们将访问神经网络中的每个节点，并设置消除神经网络中节点的概率。然后，我们删除到这些节点的输入和输出链接，这导致了一个小的和减少的网络。对于另一组训练示例，我们将消除另一组节点，并对每个训练示例重复此步骤。这似乎是一个疯狂的技术，但它的工作。</p><p id="de36" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">实现退出正则化的一种常用技术是反向退出。让我们看看如何在一个层中实现它。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mi"><img src="../Images/2994306e19e54d8fba6222edaab30e28.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YPk8yEsGfgHianBRl78Szw.png"/></div></div></figure><p id="4cfd" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在d3矩阵中，任何隐藏单元有80%的几率为1，20%的几率为0。当a3和d3之间发生乘法时，20%的值将被清零，因此，在计算z的值时仅使用80%的激活函数。</p><h2 id="ce3d" class="kq kr hh bd ks kt ku kv kw kx ky kz la jv lb lc ld jz le lf lg kd lh li lj lk bi translated">为什么退学行得通？</h2><ol class=""><li id="767f" class="lr ls hh jo b jp ll js lm jv mj jz mk kd ml kh lw lx ly lz bi translated">Dropout随机地消除隐藏单元，从而导致一个小网络，而小网络应该具有正则化效果。</li><li id="5339" class="lr ls hh jo b jp ma js mb jv mc jz md kd me kh lw lx ly lz bi translated">对于任何特定的单元来说，要完成它的工作，它都需要输入，但是在丢失的情况下，输入可以被随机消除，因此，它不能依赖于一个特征，所以它必须分散权重。</li></ol><h2 id="d66c" class="kq kr hh bd ks kt ku kv kw kx ky kz la jv lb lc ld jz le lf lg kd lh li lj lk bi translated">其他正则化技术</h2><p id="c758" class="pw-post-body-paragraph jm jn hh jo b jp ll ii jr js lm il ju jv ln jx jy jz lo kb kc kd lp kf kg kh ha bi translated"><strong class="jo hi">数据扩充:</strong>为了减少过度拟合，增加训练样本可能是一个不错的选择，但有时会被证明代价高昂。因此，在计算机视觉领域的情况下，我们可以通过旋转、裁剪、翻转和缩放数据来增加现有的示例，而不是获得更多的训练示例。获取新数据总是一个好的选择，但是数据扩充是增加示例数量的一种廉价方式。</p><p id="f7a3" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">提前停止:</strong>在这种方法中，当我们运行梯度下降时，我们应该绘制成本函数，因为它预计会随着dev set误差而降低。通常，dev set误差预计在初始水平降低，然后从那里增加。提前停止会在最低值处停止训练，假设算法在这些值下表现最佳。</p></div><div class="ab cl kj kk go kl" role="separator"><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko kp"/><span class="km bw bk kn ko"/></div><div class="ha hb hc hd he"><p id="12f0" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">要继续阅读本周的笔记，请查看<a class="ae ki" rel="noopener" href="/analytics-vidhya/deep-learning-specialization-course-notes-138ecd5ad4ef">这个</a>链接。</p><p id="4fbb" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">快乐学习！！</strong></p></div></div>    
</body>
</html>