<html>
<head>
<title>Share Price Prediction using RNN and LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用RNN和LSTM预测股价</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/share-price-prediction-using-rnn-and-lstm-8776456dea6f?source=collection_archive---------4-----------------------#2021-06-28">https://medium.com/analytics-vidhya/share-price-prediction-using-rnn-and-lstm-8776456dea6f?source=collection_archive---------4-----------------------#2021-06-28</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/2f886f36af78ba24562f30ec40473755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4_meWQFx3uP9-lzS9ptMrQ.jpeg"/></div></div></figure><div class=""/><p id="4842" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你有兴趣建立一个算法，可以预测股票的价格趋势，这可能是你的网页。</p><p id="2eb9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">本文讨论了一种使用深度学习技术(如递归神经网络和长短期记忆)进行股票价格预测的方法。</p><p id="6e4b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将通过使用RNN和LSTM构建深度学习模型的每个步骤，并检查哪一个更适合预测趋势。任何具有深度神经网络基础知识的人都可以很容易地理解这篇文章。</p></div><div class="ab cl jo jp gp jq" role="separator"><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt ju"/><span class="jr bw bk js jt"/></div><div class="hb hc hd he hf"><figure class="jw jx jy jz fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es jv"><img src="../Images/05b1e50d0d16777a821606f370fa7bdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eE-_txA3mEOFHV1Bs4xFQw.jpeg"/></div></div></figure><p id="56a0" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">股票价格预测的深度学习方法。</strong></p><p id="02df" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在进行步骤之前，让我们先了解一下RNN和LSTM的概念。</p><p id="b378" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> RNN: </strong></p><p id="f7a9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">递归神经网络(RNN)是一类强大的神经网络，用于建模序列数据，如时间序列或自然语言。我用它来预测股票价格。这背后的逻辑是，它会记住特定序列后的价格，模型会根据该模式获得经验。示意性地，RNN层使用for循环在序列的时间步长上迭代，同时维护内部状态，该内部状态编码关于它到目前为止已经看到的时间步长的信息。RNN只能在短时间内保持序列模式，因此，我们转移到LSTM，它能记住长短期记忆中的模式。</p><p id="efff" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu"> LSTM: </strong></p><p id="b7cd" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">LSTM是一种用于深度学习领域的人工递归神经网络架构。它优于前馈神经网络，因为它可以在更长的时间内记忆数据点，因此得名长期短期记忆。LSTM网络由单元、输入门、输出门和遗忘门组成。<br/>细胞就像一个存储器，可以存储任意时间的值，三个门控制着细胞内外的信息。</p><p id="48ca" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要获得RNN和LSTM的详细视图，请点击下面的图片:</p><figure class="jw jx jy jz fd hk er es paragraph-image"><a href="https://purnasaigudikandula.medium.com/recurrent-neural-networks-and-lstm-explained-7f51c7f6bbb9"><div class="er es ka"><img src="../Images/e94742cbe3c1e2f65be03633042929d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*HZTEsWqk4b4XUDI0FDnv_Q.png"/></div></a></figure><p id="dda6" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">数据采集&amp;预处理:</strong></p><p id="a330" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要做的第一件事是安装yfinance。如果你还没有安装它。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="7129" class="kg kh ht kc b fi ki kj l kk kl">pip install yfinance</span></pre><p id="3745" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">导入yfinance模块来收集特定股票的数据。对于我们的情况，我们将使用护送有限公司。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="8a52" class="kg kh ht kc b fi ki kj l kk kl">#importing yfinance<br/>import yfinance as yf</span><span id="780f" class="kg kh ht kc b fi km kj l kk kl">#Collecting data<br/>data = yf.download('ESCORTS.NS',period='5y',interval='1d')</span></pre><p id="9395" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">yfinance.download()需要的参数是股票代码tickerperiod:您希望提取数据的总持续时间，interval:指连续记录，例如1天put“1d”。这将提取5年来每天的股票数据，不包括节假日。</p><p id="3779" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">导入以下库:</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="49d2" class="kg kh ht kc b fi ki kj l kk kl">import pandas as pd<br/>import numpy as np<br/>import tensorflow as tf<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span></pre><p id="c835" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们已经收集了数据，我们需要选择所需的列。数据包含股票的历史数据，包括开盘价、收盘价、最低价、最高价、成交量和调整后的收盘价。我们将使用调整关闭模式检测和预测。此外，将数据分为训练集和测试集，以便我们可以在以后评估我们的模型。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="040b" class="kg kh ht kc b fi ki kj l kk kl">data_target = data.iloc[:1182,4]<br/>data_test = data.iloc[1132:,4]<br/>steps = 7</span><span id="9e3f" class="kg kh ht kc b fi km kj l kk kl">#return numpy representation of data<br/>data = data.loc[:,["Adj Close"]].values<br/>test = data[len(data) - len(data_test) - steps:]</span><span id="f25b" class="kg kh ht kc b fi km kj l kk kl">#4 the column is Adj Close</span></pre><p id="7e95" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们通过可视化来检查趋势。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="ba2b" class="kg kh ht kc b fi ki kj l kk kl">plot = data_target.plot()</span></pre><figure class="jw jx jy jz fd hk er es paragraph-image"><div class="er es kn"><img src="../Images/a1415321cff288adefa136c6548cfa68.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*ff2PoRG2N46G02TTMyznEQ.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">NSE护送有限公司</figcaption></figure><p id="eb20" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在此之前，我们需要定义一些函数来缩小数据，并将数据转换成一组特定价格的模式。</p><p id="e6ba" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了缩小，我们将使用ScikitLearn下的MinMaxScaler。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="65e0" class="kg kh ht kc b fi ki kj l kk kl">#Scaling Dataset<br/>def scaledata(data_target):</span><span id="c823" class="kg kh ht kc b fi km kj l kk kl">    #Import scaler and initialise it<br/>    from sklearn.preprocessing import MinMaxScaler<br/>    scaler = MinMaxScaler(feature_range=(0,1))<br/>    #transform by converting it to array and shape of (-1,1)<br/>    data_target_scaled = scaler.fit_transform(np.array(data_target).reshape(-1,1))<br/>    #plot the scaled version of data<br/>    plot_scaled = pd.DataFrame(data_target_scaled).plot()<br/>    print(data_target.shape)</span><span id="f11e" class="kg kh ht kc b fi km kj l kk kl">    #returns scaled data<br/>    return data_target_scaled, scaler</span></pre><p id="0e58" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在进行下一个函数之前，让我们了解一下为什么需要它。现在，我们知道RNN保留了这种模式，例如，如果你周日穿红色，周一穿蓝色，周二穿绿色，然后重复这种模式，RNN可以在短时间内保留这种模式。它可以预测你今天穿红色t恤明天穿蓝色。因此，数据必须有一个模式才能被识别。</p><p id="e7cf" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们将构建一个函数，将数据转换为价格模式，并根据该模式得出目标价格。这样，我们的模型可以学习价格模式的反应。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="f072" class="kg kh ht kc b fi ki kj l kk kl">#Create pattern and end price set<br/>def createPatternSet(data_target_scaled,steps=7):   <br/>    x_patern = []  #Independent Variable<br/>    y_price = []   #Dependent Variable</span><span id="5bbe" class="kg kh ht kc b fi km kj l kk kl">    for day in range(steps,data_target_scaled.shape[0]):<br/>        row = data_target_scaled[day-steps:day,0]<br/>        #print(len(row))<br/>        x_patern.append(row)<br/>        y = data_target_scaled[day,0]<br/>        #print(y)<br/>        y_price.append(y)<br/>    <br/>    x_patern,y_price = np.array(x_patern),np.array(y_price)<br/>    #RNN and LSTM takes 3D inputs, we need to change the shape of array to 3 dimensional.</span><span id="3494" class="kg kh ht kc b fi km kj l kk kl">    x_patern = x_patern.reshape(x_patern.shape[0],x_patern.shape[1],1)</span><span id="8d01" class="kg kh ht kc b fi km kj l kk kl">    #returns independent and dependent variable sets<br/>    return x_patern,y_price</span></pre><p id="e2f9" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">上述函数将待转换的数据和步数作为步数。默认情况下，我们将步长设置为7，这意味着7天模式和之后的价格将分别被记录为自变量和因变量。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="6977" class="kg kh ht kc b fi ki kj l kk kl">#Scale Down Target<br/>data_target_scaled = scaledata(data_target)[0]<br/>scaler = scaledata(data_target)[1]<br/>#prepare test data<br/>test = data[len(data) - len(data_test) - steps:]<br/>test = scaler.transform(test)</span></pre><p id="7733" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">训练和测试集:</strong></p><p id="764a" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将使用我们的函数来处理和构建x_train和y_train。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="2573" class="kg kh ht kc b fi ki kj l kk kl">#Overwrite steps to 50. it doesnt really matter here because we will be doing a lot of iterations with it (Take anyhthing less than 100).<br/>train_pattern = createPatternSet(data_target_scaled,steps=50)<br/>x_train = train_pattern[0]<br/>y_train = train_pattern[1]</span><span id="0cb9" class="kg kh ht kc b fi km kj l kk kl">#Input Shape needs to be 3D.<br/>x_train.shape<br/>&gt;&gt;&gt; (1132, 50, 1)</span></pre><p id="65fc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们已经完成了训练集的构建，我们将构建测试集。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="1416" class="kg kh ht kc b fi ki kj l kk kl">#create pattern and price for test set.<br/>test_pattern = createPatternSet(test,steps=50)<br/>x_test = test_pattern[0]<br/>y_test = test_pattern[1]</span><span id="37d5" class="kg kh ht kc b fi km kj l kk kl">#Dont forget to check the shape of x_test (3D reuired).<br/>x_test.shape</span></pre><p id="b257" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">测试数据将用于模型的评估。我们将基于x_test预测这些值，然后将它们与原始y_test值进行比较。</p><p id="cf9c" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">至此，我们已经完成了数据预处理，现在是有趣的部分<strong class="is hu">。</strong></p><p id="fb40" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">模型建筑:</strong></p><p id="e7cc" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将定义一个带有方法的类，这些方法可以构建体系结构，编译它，并使它适合给定的数据。该类还将拥有设置参数的方法，如神经元的数量、batch_size和epoch。构建这个类的原因是，我们可以使用传递的不同参数运行一个for循环，并分析结果。这将有助于读者尝试超参数的其他组合。</p><p id="67fb" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">后来，我们也可以从这个类继承LSTM，并改写建筑的建造方法。有其他选项可用于超调模型，但我们坚持这一最基本的理解。</p><p id="3556" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为RNN构建类:</p><figure class="jw jx jy jz fd hk"><div class="bz dy l di"><div class="ks kt l"/></div></figure><p id="2817" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">默认情况下，模型的架构包含以下几层:</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="743c" class="kg kh ht kc b fi ki kj l kk kl">Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>simple_rnn_44 (SimpleRNN)    (None, 50, 50)            2600      <br/>_________________________________________________________________<br/>dropout_32 (Dropout)         (None, 50, 50)            0         <br/>_________________________________________________________________<br/>simple_rnn_45 (SimpleRNN)    (None, 50, 50)            5050      <br/>_________________________________________________________________<br/>dropout_33 (Dropout)         (None, 50, 50)            0         <br/>_________________________________________________________________<br/>simple_rnn_46 (SimpleRNN)    (None, 50, 50)            5050      <br/>_________________________________________________________________<br/>dropout_34 (Dropout)         (None, 50, 50)            0         <br/>_________________________________________________________________<br/>simple_rnn_47 (SimpleRNN)    (None, 50)                5050      <br/>_________________________________________________________________<br/>dropout_35 (Dropout)         (None, 50)                0         <br/>_________________________________________________________________<br/>dense_19 (Dense)             (None, 1)                 51        <br/>=================================================================<br/>Total params: 17,801<br/>Trainable params: 17,801<br/>Non-trainable params: 0</span></pre><p id="331d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于编译，我使用了Adam和，对于损失函数均方误差。</p><p id="a0c5" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为LSTM构建类:</p><p id="2235" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">继承以前类的属性并覆盖架构。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="2886" class="kg kh ht kc b fi ki kj l kk kl">class LstmModel(StocksPriceRNN):<br/>    StocksPriceRNN.model = tf.keras.Sequential()<br/>    def __init__(self,x_train,y_train,epoch):<br/>        super().__init__(x_train,y_train,epoch)<br/>    <br/>    def buildArchitecture(self,dense=1):<br/>        StocksPriceRNN.model = tf.keras.Sequential()<br/>        StocksPriceRNN.model.add(tf.keras.layers.LSTM(<br/>                                 StocksPriceRNN.neurons,<br/>                                 input_shape=(None,1)))<br/>        #Output<br/>        StocksPriceRNN.model.add(tf.keras.layers.Dense(units=1))<br/>        return StocksPriceRNN.model.summary()</span></pre><p id="6b2f" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">可视化:<br/> </strong>接下来，我们构建一个函数来绘制验证曲线。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="4a80" class="kg kh ht kc b fi ki kj l kk kl">def plotting(org_vals,output):<br/>    plt.figure(figsize=(10,5), dpi=80, facecolor='w', edgecolor='k')<br/>    plt.plot(org_vals,color="Green",label="Org value")<br/>    plt.plot(output,color="Yellow",label="Predicted")<br/>    plt.legend()<br/>    plt.xlabel("Days")<br/>    plt.ylabel("Price")<br/>    plt.grid(True)<br/>    plt.show()</span></pre><p id="5335" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是一个很大的工作量，但我们已经建立了我们的算法，唯一剩下的事情就是把它们放在一起。</p><p id="aa54" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">迭代&amp;评估:</strong></p><p id="5a27" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，我们将迭代RNN，然后是LSTM。将比较两者的最佳输出以进行评估。</p><p id="1dcd" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">构建一个For-Loop语句来传递不同的时期和批处理大小。对数据运行模型并可视化输出:</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="d2da" class="kg kh ht kc b fi ki kj l kk kl">for steps in [7,30,90]:<br/>    for epoch in [20,30,50]:<br/>        #prepare train data<br/>        train_pattern = createPatternSet(data_target_scaled,steps=steps)<br/>        #prepare test data<br/>        test = data[len(data) - len(data_test) - steps:]<br/>        test = scaler.transform(test)</span><span id="872c" class="kg kh ht kc b fi km kj l kk kl">        test_pattern = createPatternSet(inputs,steps=steps)<br/>        x_test = test_pattern[0]<br/>        y_test = test_pattern[1]<br/>        #Build Model<br/>        RNN1 = StocksPriceRNN(x_train,y_train,epoch)<br/>        RNN1.buildArchitecture(2,0)<br/>        RNN1.compiler()<br/>        #fit model<br/>        history = RNN1.modelfit()<br/>        #Predict Values<br/>        pred = RNN1.model.predict(x=x_test)<br/>        output = scaler.inverse_transform(pred)<br/>        org_vals = scaler.inverse_transform(y_test)<br/>        #visualise<br/>        print("Plotting for Steps {} and Epoch {}".format(steps,epoch))<br/>        plotting(org_vals,output)</span></pre><p id="50f7" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将在9次迭代中输出。在比较了迭代之后，我发现RNN在90–30和90–50(步长-纪元)的组合上给出了草率但相对最好的结果。</p><p id="e408" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是输出:</p><figure class="jw jx jy jz fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ku"><img src="../Images/e5b62d2096cc888b8d17911adb1ac8a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bweld_eLgriNMYtoDICW6Q.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">RNN:为步骤90和时代50绘图</figcaption></figure><p id="e69b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">30-50个历元之间没有太大的差别，但是准确度可以随着历元的增加而增加。</p><p id="b7e2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">类似地，我们为LSTM: <br/>运行迭代。请注意，将会有一些与“超出调用范围”相关的警告，这是很自然的，因为我们只将测试数据分割为100个记录。为了避免这种情况，请确保experimental_relax_shapes=True，这是一个放松参数形状的选项，可以避免不必要的缩进(不一定需要)。</p><pre class="jw jx jy jz fd kb kc kd ke aw kf bi"><span id="3972" class="kg kh ht kc b fi ki kj l kk kl"># for different epochs, batch size, and neurons/units. <br/>for epch in [60,100,200]:<br/>    for batch in [2,4,6]:<br/>        for neurons in [8,10,12]:<br/>            LSTM2 = LstmModel(x_train,y_train,epoch=epch)<br/>            LSTM2.changeBatchSize(batch)<br/>            LSTM2.changeNeurons(neurons)</span><span id="4c62" class="kg kh ht kc b fi km kj l kk kl">            LSTM2.buildArchitecture()<br/>            LSTM2.compiler()<br/>            history = LSTM2.modelfit()</span><span id="4f00" class="kg kh ht kc b fi km kj l kk kl">            pred = LSTM2.model.predict(x_test)<br/>            pred = scaler.inverse_transform(pred)<br/>            #org = scaler.inverse_transform(y_test)</span><span id="ffee" class="kg kh ht kc b fi km kj l kk kl">            print("For epch {}, neurons {} and batch {}".format(epch,neurons,batch))<br/>            plotting(org,pred)</span></pre><p id="2ac2" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出将包含27次迭代。</p><p id="e5a3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">分析LSTM的输出，很明显LSTM在数据集上的表现优于RNN。LSTM在批量大小= 2、单位= 10和纪元= 200时给出了更好的结果。</p><p id="f6df" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是输出:</p><figure class="jw jx jy jz fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es kv"><img src="../Images/75bb41542193285253154e2f73642b81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LyATHGlVodC5V8f1JEPO1g.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">LSTM</figcaption></figure><p id="f9c3" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">尾注:</strong> <br/>我们建立的模型能够进行更多的迭代。我们只尝试了其中的一些，仍然设法接近原始价格曲线。去吧！并且自己尝试其他超参数，因为我们已经构建了一个类实例，我们可以做很多修改，而无需编写整个代码或对同一代码进行更改。</p><p id="ed0d" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面是完整的代码:<br/><a class="ae kw" href="https://www.kaggle.com/rishirajak/share-price-prediciton-using-lstm-and-rnn" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/rishirajak/share-price-prediction-using-lstm-and-rnn</a></p><p id="e20b" class="pw-post-body-paragraph iq ir ht is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hu">感谢</strong>阅读我的作品。</p></div></div>    
</body>
</html>