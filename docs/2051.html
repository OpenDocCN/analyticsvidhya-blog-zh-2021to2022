<html>
<head>
<title>Calculation of Bias &amp; Variance in python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">python中偏差和方差的计算</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/calculation-of-bias-variance-in-python-8f96463c8942?source=collection_archive---------2-----------------------#2021-04-03">https://medium.com/analytics-vidhya/calculation-of-bias-variance-in-python-8f96463c8942?source=collection_archive---------2-----------------------#2021-04-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6b5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">去神秘化的偏差-方差分解</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/69fc8d5899bfa4f5a012022aabcb9254.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SWr5OredIl-3QWVjpWBxwQ.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:图片由G T在<a class="ae jt" href="https://unsplash.com/photos/cdZROYxsPt8" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="9d45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于任何机器学习，模型的性能可以根据<em class="ju">偏差</em>和<em class="ju">方差</em>来确定和表征。</p><blockquote class="jv jw jx"><p id="aa93" class="if ig ju ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated">在监督机器学习中，算法从训练数据中学习模型。<br/> <strong class="ih hj"> Y=f(X) + E </strong> <br/>任何有监督的机器学习算法的目标都是在给定输入数据(X)的情况下，对输出变量(Y)的映射函数(f)进行最佳估计。<br/>映射函数通常被称为目标函数，因为它是给定的监督机器学习算法旨在逼近的函数。<br/>除了f(X)之外，我们还有一个误差项分量，用“E”表示。</p></blockquote><p id="ff91" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">任何机器学习算法的预测误差(E)都可以分解为三部分:</p><blockquote class="jv jw jx"><p id="2c9c" class="if ig ju ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated">1.模型偏差<br/> 2。型号差异<br/> 3。不可约误差</p></blockquote><p id="01fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">无论使用何种算法，都无法减少<strong class="ih hj">不可约误差</strong>。它是从问题的选择框架中引入的误差，并且可能由诸如影响输入变量到输出变量的映射的未知变量等因素引起。</p><p id="6c6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">概括地说，</p><h2 id="89a5" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">误差(模型)=方差+偏差+不可约误差</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kw"><img src="../Images/f53b4c94074afdd34da7edfd1631f582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*tVvZbpWA9tlswzEDx-J4pw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><p id="be8b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先让我们试着理解这些是什么，然后我们将借助一个样本数据集来检查偏差和方差，以理解实时计算。</p><p id="ff36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我试着用一个简单的例子来说明，在深入这个概念之前先打个比方。</p><p id="0c18" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑一个学生参加数学考试的例子。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kx"><img src="../Images/4db50d5dfdb28b05906ee6c2a8e602ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0-kHaqAD0lcrWcikBQqKhw.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来源:javier trueba在<a class="ae jt" href="https://unsplash.com/photos/iQPr1XkF5F0" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="c658" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在的任务是<strong class="ih hj">为考试学习书本</strong>或<strong class="ih hj">相关章节</strong>s<strong class="ih hj">/模块</strong>。</p><p id="4c32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果学生只是略读题目和章节，而不是真正地学习，那么同一个学生将无法在考试中表现良好，因为他/她只是略读了题目。</p><p id="0d5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑另一种情况，其中学生<em class="ju">记住</em>章节和问题中的所有内容，而不是实际学习/理解概念、理论及其含义——在这种情况下，如果任何问题来自书但基于概念，学生将无法处理或解决问题。</p><p id="896e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以在上面的例子中，研究这本书就是任务(模型期望)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ky"><img src="../Images/a139c7a49aa05c11aed8fc793f1197f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nqtUT8c5xtAI845LwNo23Q.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">不合适-作者提供的图像</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ky"><img src="../Images/280552c26565d09f00e97f7645a0d784.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mmOce5AMQhaaCfL0TgSaiw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">过度拟合—作者提供的图像</figcaption></figure><blockquote class="kz"><p id="811b" class="la lb hi bd lc ld le lf lg lh li jc dx translated">那么模型的理想场景应该是什么样的呢？</p></blockquote><p id="d324" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">最理想的是，我们必须<strong class="ih hj"> <em class="ju">能够</em> </strong> <strong class="ih hj"> <em class="ju">概括模型</em> </strong>。在上述情况下，我们必须能够通过研究问题的概念、理论和方法来解决任何问题，而不是略读或记忆问题。</p><p id="af98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的例子只是外行人用来解释的术语。</p><p id="5992" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们试着实时了解模型的细节</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/df46064e406423e91df528aad81934e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OcTiMuQdIjFqB9u8UP_06A.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lp"><img src="../Images/e77c52c6e205f734c45b5f8714f1349b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fLkSbFOudU-tLlsgioPSnA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">区分偏差和方差</figcaption></figure><p id="964c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">不可约误差:</strong></p><p id="b170" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简言之，</p><p id="fe08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ju">模型误差=可约误差+不可约误差</em></p><p id="be49" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可减少的错误只是我们可以改进的因素。这是当模型在训练数据集上学习时我们减少的数量，我们试图让这个数字尽可能接近零。</p><p id="91c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不可约误差是我们无法控制的误差，就像上文开始提到的那样——这可能是由于各种原因，如统计元素[噪声]。这不是我们能控制的。</p><p id="9633" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这也表明没有一种模式是完美的。</p><h1 id="d295" class="lq kc hi bd kd lr ls lt kh lu lv lw kl lx ly lz ko ma mb mc kr md me mf ku mg bi translated">偏差与方差的权衡</h1><p id="8ecc" class="pw-post-body-paragraph if ig hi ih b ii mh ik il im mi io ip iq mj is it iu mk iw ix iy ml ja jb jc hb bi translated">模型的偏差和方差总是联系在一起的。</p><p id="69eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们通常更喜欢低偏差和低方差的模型，但在实时环境中，这将是最大的挑战——这也可以被视为任何机器学习问题的具体目标。</p><p id="4012" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">偏差和方差成反比</p><p id="032c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">偏差∝1/方差</p><p id="cf86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上述关系被称为权衡。这有助于选择型号和型号配置。</p><blockquote class="jv jw jx"><p id="bb3d" class="if ig ju ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated">如何在给定数据集上计算任何算法的偏差-方差权衡？</p></blockquote><p id="885f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们考虑计算，对于预测建模问题，计算实际偏差和方差是相当困难的。这是因为我们不知道预测建模问题的真实映射函数。</p><p id="7451" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管偏差-方差权衡更概念化，但在某些情况下，我们实际上可以计算偏差-方差权衡。</p><p id="a446" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有一个由<a class="ae jt" href="https://sebastianraschka.com/" rel="noopener ugc nofollow" target="_blank">定义的库<a class="ae jt" href="http://rasbt.github.io/mlxtend/" rel="noopener ugc nofollow" target="_blank">mlx tend</a>Sebastian博士</a>提供了一个名为<a class="ae jt" href="http://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/" rel="noopener ugc nofollow" target="_blank"> bias_variance_decomp() </a>的函数，帮助我们在许多bootstrap样本上估计各种模型的偏差与方差。</p><p id="c16d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个库<em class="ju"> mlxtend </em>具有最近引入的巨大功能。偏差和方差的计算就是其中之一。</p></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><p id="7192" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将看一个回归模型和分类模型的例子，用于偏差和方差的权衡。</p><p id="e1b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请注意，我们现在有能力找出Tensorflow/Keras支持的模型偏差和方差，这也将在本文中讨论。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mt"><img src="../Images/d05179887f10caf8d3862e27bd1608ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mddfL1vr7BuGWVUn5Xo3LA.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片来源:沃尔夫冈·罗特曼在<a class="ae jt" href="https://unsplash.com/photos/ArP8LTekkDw" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></figcaption></figure><p id="8fba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为此，我们必须pip安装mlxtend库</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mu"><img src="../Images/a626059a66d1cecbe8c64ea57893a2e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:348/format:webp/1*qPiqNnJDJcoeTDntmu_Z0A.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">安装mlxtend库</figcaption></figure><p id="fdce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了支持张量流/keras，mlxtend和tf的预期版本为:</p><ol class=""><li id="ce3b" class="mv mw hi ih b ii ij im in iq mx iu my iy mz jc na nb nc nd bi translated"><em class="ju"> mlxtend v0.18.0或更高版本</em></li><li id="8c7e" class="mv mw hi ih b ii ne im nf iq ng iu nh iy ni jc na nb nc nd bi translated"><em class="ju"> tf.version ≥ 2.4.1 </em></li></ol><p id="2b08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">概述我们将在这篇文章中看到的内容。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nj"><img src="../Images/8ddc300855ebaca161b5797c706e0952.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*ygLyAjrK9-cB50yJHpWdUw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><p id="dfcb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们也试着理解一下库内部使用的<em class="ju">函数</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nk"><img src="../Images/6e3143ab44aec010486dbf973f7509b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*vNhxicH7gdV6J8ZrdIxuHA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">该函数对于上述图表中的所有存储桶都是相同的</figcaption></figure><h2 id="58de" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">我们将看看函数bias_varaince_decomp</h2><blockquote class="jv jw jx"><p id="b96b" class="if ig ju ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated">bias_variance_decomp(estimator，X_train，y_train，X_test，y_test，loss='mse '，num_rounds=200，random_seed=None)</p></blockquote><p id="3c21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">估计器</strong> : <em class="ju">分类器或回归器</em>实现类似于scikit-learn API的<code class="du nl nm nn no b">fit</code> <code class="du nl nm nn no b">predict</code>方法的对象或类。</p><p id="a155" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du nl nm nn no b">X_train</code>:期望一个数组，shape=(数量_示例，数量_特征)</p><p id="f0b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个<strong class="ih hj">训练</strong>数据集，用于抽取bootstrap样本以执行偏差-方差分解。</p><p id="5788" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du nl nm nn no b">y_train</code>:需要一个数组，shape=(num_examples)</p><p id="de94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与<code class="du nl nm nn no b">X_train</code>示例相关的目标(类别标签，回归情况下的连续值)。</p><p id="ce45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du nl nm nn no b">X_test</code>:需要一个数组，shape=(数量_示例，数量_特征)</p><p id="213a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于计算平均损失、偏差和方差的测试数据集。</p><p id="1787" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du nl nm nn no b">y_test</code>:需要一个数组，shape=(num_examples)</p><p id="027c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与<code class="du nl nm nn no b">X_test</code>示例相关的目标(类别标签，回归情况下的连续值)。</p><p id="122d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du nl nm nn no b">loss</code> : str(默认值='0-1_loss ')</p><p id="2440" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">执行偏差-方差分解的损失函数。当前允许的值是'<strong class="ih hj">MSE</strong>'[在<em class="ju">回归</em>的情况下]和'<strong class="ih hj">0–1 _损失</strong>'[在<em class="ju">分类器</em>的情况下]。</p><p id="e6ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du nl nm nn no b">num_rounds</code> : int ( <strong class="ih hj">默认</strong> =200)</p><p id="58b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">执行偏差-方差分解的引导轮数。</p><p id="28d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du nl nm nn no b">random_seed</code> : int(默认值=无)</p><p id="9745" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于偏差方差分解的bootstrap抽样的随机种子。</p><p id="f22b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du nl nm nn no b">fit_params</code>:附加参数</p><p id="1607" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要传递给。当估计量适合bootstrap样本时，它的fit()函数(这是最新mlxtend版本的一部分)</p><p id="4261" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">退货</strong></p><p id="b201" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du nl nm nn no b">avg_expected_loss, avg_bias, avg_var</code>:返回预期的平均值</p><p id="7b58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">平均偏差和平均偏差(所有浮点)，其中平均值是在<strong class="ih hj">测试</strong>集中的数据点上计算的。</p><h2 id="4f55" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">一、偏差和方差的计算(用于回归):</h2><p id="6706" class="pw-post-body-paragraph if ig hi ih b ii mh ik il im mi io ip iq mj is it iu mk iw ix iy ml ja jb jc hb bi translated">让我们考虑波士顿数据集的回归问题。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nr"><img src="../Images/dbe3ad7f99601a07fcb7acb7bf60b50f.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*bh8ULatQJ0mIx970ocMz5w.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">从上面我们的计算结果可以明显看出，总误差=偏差+方差，我们还可以看到，从sckit-library计算的MSE几乎等于平均预期损失。</figcaption></figure><p id="c6e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">修剪后——使用套索，</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ns"><img src="../Images/c9bfe1528b2e17dfa442a1f072b79d34.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*j5lF1xpQeYk3HappObZREg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">可以观察到，在正则化之后偏差已经减小，并且方差略有增加，并且总的平均误差也降低了</figcaption></figure><p id="3ff1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管我们实际上已经理解了，让我们也看看它的一些数学部分。</p><p id="642e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于回归模型，偏差-方差分解可以看作是平方损失函数，基本上分为三项——方差、偏差和噪声[这一部分对于分类器也是如此]。</p><p id="f666" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">忽略噪声项，</p><p id="385c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看偏差和方差的价值</p><p id="9df1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">目标函数，y = f(x)；<br/>预测目标函数，ŷ=<em class="ju">f</em>^(x)=h(x)；<br/>平方损失s=(y−ŷ)2；<br/>期望(e[ŷ)——这超过了训练集。对于平方误差损失的主要预测仅仅是预测E[ŷ的平均值(期望是在训练集上)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nt"><img src="../Images/ab832195988f11e229326ff6ae60b4bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*eHQvYrk7BczGRA8vW4ZtJA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">上表参考自<a class="ae jt" href="http://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/" rel="noopener ugc nofollow" target="_blank"> mlxtend </a> github</figcaption></figure><h2 id="8a0c" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated"><strong class="ak">二。</strong>偏差&amp;方差的计算(分类器<strong class="ak">):</strong></h2><p id="61e7" class="pw-post-body-paragraph if ig hi ih b ii mh ik il im mi io ip iq mj is it iu mk iw ix iy ml ja jb jc hb bi translated">对于分类器，我们将使用相同的库——唯一的区别是损失函数。这里我们将使用-0–1损失函数。</p><blockquote class="jv jw jx"><p id="1935" class="if ig ju ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated"><strong class="ih hj">什么是0–1损失？</strong></p></blockquote><p id="6acb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设您有一个分类问题(0或1)，假设您的数据集有20行。在用任何算法分类后，例如:naive baye算法——如果我们发现它正确预测了15个，而5个被错误分类，这被识别出来并被称为0–1损失。[所有正确预测的项目15将被标记为“0”，所有错误分类的项目将被标记为“1”]。</p><p id="e9b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上述情况下，0–1损失为((5/20)* 100)-25%</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nu"><img src="../Images/f356bffe4cdb17c87d8c23b5de12b420.png" data-original-src="https://miro.medium.com/v2/resize:fit:808/format:webp/1*lTXhFOcaZnToXBHW5SgwpQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">作者图片</figcaption></figure><p id="f30b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ju">注:</em>对于0–1损失，<strong class="ih hj">模式</strong>用于定义0–1损失的主要预测=&gt;<em class="ju">【e[ŷ】</em></p><p id="42d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">0–1损失的偏差和方差如下。</p><p id="5f93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果主预测与真实标签<em class="ju"> y </em>不一致，偏差为1，否则为0；</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nv"><img src="../Images/42064fa580fd2d25697c75f99b82d16c.png" data-original-src="https://miro.medium.com/v2/resize:fit:456/format:webp/1*Ju6ryf9k3PrFQ68aaIA2pA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片取自<a class="ae jt" href="http://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/" rel="noopener ugc nofollow" target="_blank"> mlxtend </a></figcaption></figure><p id="de58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">0–1损失的<em class="ju">方差</em>定义为预测标签与主预测不匹配的概率:</p><p id="2ad4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="ju">方差=p(ŷ≠e[ŷ】)</em></p><blockquote class="jv jw jx"><p id="d7b1" class="if ig ju ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated">损失=偏差+方差</p></blockquote><p id="5aae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看一个例子来说明——考虑虹膜数据集，</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="np nq l"/></div></figure><p id="c6df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">加载数据集后，让我们尝试使用mlxtend库找出错误(损失),我们还将看到某些模型(例如:RandomForest)如何具有减少方差的能力。</p><p id="520b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先让我们用决策树来试试，</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nw"><img src="../Images/4950a86eb38873d62dbb830f33df72c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/1*wENJt7GyRchZLjcaCFgyHA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">如果你在这里观察，修剪后模型的方差在某种程度上减少了，但偏差仍然相同。</figcaption></figure><p id="62fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面，我们观察到总的期望损失=偏差+方差之和&amp;修剪对方差的减少有一些影响。</p><p id="b335" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们听说随机森林模型通常有助于减少方差(减少过度拟合)。让我们也试着看看RF模型的结果。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nx"><img src="../Images/c31f22ca539ae213b76b64700fd4b71b.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/format:webp/1*XlvEJQN2BGgzSHnUAQLfEA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">方差有显著差异，它已经急剧减少。</figcaption></figure><blockquote class="jv jw jx"><p id="c2a0" class="if ig ju ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated">从上面可以观察到，<strong class="ih hj"> RF </strong>实际上有助于<strong class="ih hj">减少数据集的方差。</strong></p></blockquote><p id="e82b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们尝试使用GridSearchCV或K-fold调整或超调整参数，我们最终可能会减少更多的方差。</p><p id="affe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面可以清楚地证明，RF有助于减少过拟合，或者换句话说，有助于减少模型的方差。</p><p id="0cc8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们也试着去了解一下<strong class="ih hj"> <em class="ju"> KNN </em> </strong></p><p id="c772" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">众所周知，低k值的KNN模型通常具有高方差和低偏差，但是随着k值的增加，方差减小，偏差增大。</p><p id="cc03" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们通过使用相同的虹膜数据集来检验这一点。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ny"><img src="../Images/cb1a3e3f05798208a6ff7d2fdc33a543.png" data-original-src="https://miro.medium.com/v2/resize:fit:518/format:webp/1*q-SV7e1wwVGuhhBK_flyVg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">可以观察到，与方差相比，偏差相对较高[对于k=3]。并且预期损失比RF模型更多。</figcaption></figure><p id="9ebf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们看看对于不同的k值，什么是训练和测试图</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nz"><img src="../Images/47e7ce736f9e11afbde4722ef64a9c36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KaTRp5Y4u3EmpBeBWQqGJg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">关于该数据集，我们可以观察到，对于低K值，训练的测试分数更多，而测试数据集低。另一方面，对于较高K值，测试结果比训练好。在选择最佳k值时，要权衡偏差方差。</figcaption></figure><p id="93ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于kNN中k的各种值，让我们也来看看我们的损失，偏差和方差会是怎样的。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es oa"><img src="../Images/9212c362e4eefbd1970d5f8648d14475.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*QrcffKk9HeT8oHvRUv9Msw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">可以看出，对于这个特定的数据集，随着k的增加，偏差也在增加。</figcaption></figure><h2 id="0a84" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">三。偏差和方差的计算(以张量流/角为单位):</h2><p id="72b3" class="pw-post-body-paragraph if ig hi ih b ii mh ik il im mi io ip iq mj is it iu mk iw ix iy ml ja jb jc hb bi translated">如前所述，这个库只在mlxtend的最新版本(<em class="ju"> v0.18.0 </em> &amp;以上)和tf (≥ <em class="ju"> 2.4.1 </em>)中支持keras/tf。</p><p id="4beb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看一下我们案例中的同一个波士顿住房数据集，</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ob"><img src="../Images/098d0a09f49b7c90b001f01c6c373299.png" data-original-src="https://miro.medium.com/v2/resize:fit:306/format:webp/1*boO7FKaRWn8xTFzLSljacw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">针对上述内容计算的MSE值</figcaption></figure><p id="e63d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们使用mlxtend计算损失、偏差和方差。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es oc"><img src="../Images/e37c1208506745677c8665420542515b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lNcT9WwbZkERYY2-yxEZ2g.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">运行模型后，上面列出了损失、偏差和方差。</figcaption></figure><p id="8453" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，绝对建议使用与原始训练集中相同数量的训练历元，以确保实现适当的收敛。</p></div><div class="ab cl mm mn gp mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hb hc hd he hf"><blockquote class="kz"><p id="987e" class="la lb hi bd lc ld od oe of og oh jc dx translated"><em class="oi">需要记住的要点</em></p></blockquote><blockquote class="jv jw jx"><p id="5688" class="if ig ju ih b ii lj ik il im lk io ip jy ll is it jz lm iw ix ka ln ja jb jc hb bi translated"><strong class="ih hj">参数或线性机器学习算法</strong>通常有一个<strong class="ih hj">高偏差</strong>但有一个<strong class="ih hj">低方差</strong>。参数算法的一些例子是线性、逻辑和LDA。这里对目标函数的形式做了更多的假设。<strong class="ih hj">较高的偏置</strong>经常导致<strong class="ih hj"> </strong>到<strong class="ih hj">欠拟合<strong class="ih hj">的模型。</strong></strong></p></blockquote><h2 id="1a79" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">克服拟合不足的方法:</h2><p id="fb5a" class="pw-post-body-paragraph if ig hi ih b ii mh ik il im mi io ip iq mj is it iu mk iw ix iy ml ja jb jc hb bi translated">a.尝试更复杂的模型(不做任何假设)</p><p id="7d4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b.添加具有更高预测能力的功能(执行功能工程)。</p><p id="50d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">c.如果可能，添加更多培训数据。</p><p id="d4c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">d.去除数据中的噪声。</p><blockquote class="jv jw jx"><p id="ceb0" class="if ig ju ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated"><strong class="ih hj">非参数或非线性机器学习算法</strong>通常具有<strong class="ih hj">低偏差</strong>但具有<strong class="ih hj">高方差</strong>。非参数算法的一些例子是SVM kNN的决策树。高方差模型非常重视训练数据，不会对以前没有见过的数据进行归纳。<strong class="ih hj">高方差</strong>往往导致<strong class="ih hj">模型</strong>的<strong class="ih hj">过拟合</strong>。</p></blockquote><h2 id="637c" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">克服过度拟合的方法:</h2><p id="15b4" class="pw-post-body-paragraph if ig hi ih b ii mh ik il im mi io ip iq mj is it iu mk iw ix iy ml ja jb jc hb bi translated">a.在决策树的情况下，如果树长得很大，尝试修剪树。</p><p id="1bac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b.对于SVM，尝试修改C值，使用线性核来代替RBF。</p><p id="0836" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">c.对于kNN，尝试获得最佳k值(低k值意味着过拟合，非常高的k值导致欠拟合)。</p><p id="6b7e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">d.尝试正则化技术。</p><p id="0e7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">e.尝试添加更多功能(交叉验证，保留一个验证集)。</p><h2 id="bbe9" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated">摘要</h2><p id="07da" class="pw-post-body-paragraph if ig hi ih b ii mh ik il im mi io ip iq mj is it iu mk iw ix iy ml ja jb jc hb bi translated">总而言之，在这篇文章中，我们已经看到了什么是模型偏差；什么是方差，什么是不可约误差。</p><blockquote class="jv jw jx"><p id="1dbe" class="if ig ju ih b ii ij ik il im in io ip jy ir is it jz iv iw ix ka iz ja jb jc hb bi translated">在<strong class="ih hj">偏差&amp;方差</strong>之间的<strong class="ih hj">权衡</strong>是什么，以及如何在某些模型的帮助下实现这一点。我们还看到了如何使用<strong class="ih hj"> mlxtend </strong>库计算回归模型和分类器的偏差和方差。</p></blockquote><p id="30da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用的代码库可以在<a class="ae jt" href="https://github.com/NallaperumalK/Data-science-Projects/tree/master/Bias%20Variance%20Decomposition" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h2 id="f39a" class="kb kc hi bd kd ke kf kg kh ki kj kk kl iq km kn ko iu kp kq kr iy ks kt ku kv bi translated"><em class="oi">参考文献:</em></h2><div class="oj ok ez fb ol om"><a href="http://rasbt.github.io/mlxtend/user_guide/evaluate/bias_variance_decomp/" rel="noopener  ugc nofollow" target="_blank"><div class="on ab dw"><div class="oo ab op cl cj oq"><h2 class="bd hj fi z dy or ea eb os ed ef hh bi translated">偏差-方差分解</h2><div class="ot l"><h3 class="bd b fi z dy or ea eb os ed ef dx translated">不同损失函数下机器学习算法的偏差方差分解。从mlxtend.evaluate导入…</h3></div><div class="ou l"><p class="bd b fp z dy or ea eb os ed ef dx translated">rasbt.github.io</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa jn om"/></div></div></a></div><div class="oj ok ez fb ol om"><a href="https://machinelearningmastery.com/calculate-the-bias-variance-trade-off/" rel="noopener  ugc nofollow" target="_blank"><div class="on ab dw"><div class="oo ab op cl cj oq"><h2 class="bd hj fi z dy or ea eb os ed ef hh bi translated">如何通过Python -机器学习掌握计算偏差-方差权衡</h2><div class="ot l"><h3 class="bd b fi z dy or ea eb os ed ef dx translated">机器学习模型的性能可以根据模型的偏差和方差来表征。一个…</h3></div><div class="ou l"><p class="bd b fp z dy or ea eb os ed ef dx translated">机器学习掌握。</p></div></div><div class="ov l"><div class="pb l ox oy oz ov pa jn om"/></div></div></a></div></div></div>    
</body>
</html>