<html>
<head>
<title>Lasso Regression Fundamentals and Modeling in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的Lasso回归基础和建模</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/lasso-regression-fundamentals-and-modeling-in-python-ad8251a636cd?source=collection_archive---------0-----------------------#2021-05-01">https://medium.com/analytics-vidhya/lasso-regression-fundamentals-and-modeling-in-python-ad8251a636cd?source=collection_archive---------0-----------------------#2021-05-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="9be7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博文中，我将首先尝试解释套索回归的基础知识。然后，我们将通过Python使用数据集构建模型。最后，我们将通过计算均方差来评估模型。让我们一步一步开始吧。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/885e39fbb68e7310fe8628fcffa62278.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WG4u9kaKfD4RVpVtZjD9pA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">资源:<a class="ae jt" href="https://waterprogramming.wordpress.com/2017/02/22/dealing-with-multicollinearity-a-brief-overview-and-introduction-to-tolerant-methods/" rel="noopener ugc nofollow" target="_blank">https://water gramming . WordPress . com/2017/02/22/处理多重共线性-概述-介绍-容忍-方法/ </a></figcaption></figure><h1 id="8d93" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">什么是套索回归？</h1><p id="7fca" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">Lasso回归的主要目的是通过对这些系数应用惩罚来找到最小化误差平方和的系数。在另一个来源中，它被定义如下:</p><blockquote class="kx ky kz"><p id="69f4" class="if ig la ih b ii ij ik il im in io ip lb ir is it lc iv iw ix ld iz ja jb jc hb bi translated">“套索”代表<strong class="ih hj"> L </strong>东<strong class="ih hj">A</strong>b<strong class="ih hj">S</strong>h<strong class="ih hj">S</strong>选举<strong class="ih hj"> O </strong>操作员。套索回归是一种正则化技术。它用于回归方法之上，以获得更准确的预测。这个模型使用收缩。收缩是指数据值向中间点收缩。Lasso回归使用L1正则化技术。当我们有更多的特征时使用它，因为它自动执行特征选择。</p></blockquote><h2 id="be87" class="le jv hi bd jw lf lg lh ka li lj lk ke iq ll lm ki iu ln lo km iy lp lq kq lr bi translated">套索回归的特征</h2><ul class=""><li id="066c" class="ls lt hi ih b ii ks im kt iq lu iu lv iy lw jc lx ly lz ma bi translated">岭回归的所有相关-不相关变量已被提出，以克服离开模型的缺点。</li><li id="20fb" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">套索回归使系数更接近于零。</li><li id="252b" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">但是当范数L1足够大的时候，它使得一些系数为零。因此，变量做出选择。</li><li id="bc82" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">λ选择正确非常重要。为此使用了交叉验证。</li><li id="38fe" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">山脊法和套索法互不优越。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mg"><img src="../Images/0af0b6c03e84bd4dca5b8d42ed4e5c7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iAOdHbwIVp7PBOxiRzUvJQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">https://spotio.com/blog/regression-analysis/</figcaption></figure><h1 id="22f5" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">套索回归模型</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mh"><img src="../Images/bde48469d69691f899d0b8c72285b43b.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/1*XPlbHrdvd8o1d2tonsZNxw.png"/></div></figure><ul class=""><li id="9134" class="ls lt hi ih b ii ij im in iq mi iu mj iy mk jc lx ly lz ma bi translated">λ表示收缩量。</li><li id="78ee" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">λ = 0表示考虑了所有特征，这相当于线性回归，其中仅考虑残差平方和来构建预测模型</li><li id="50c1" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">λ = ∞表示不考虑任何特征，即当λ接近无穷大时，它会消除越来越多的特征</li><li id="ff01" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">偏差随着λ的增加而增加</li><li id="885c" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc lx ly lz ma bi translated">方差随着λ的减小而增加</li></ul><h1 id="d6ce" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">用Python建模</h1><p id="cd4e" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">现在让我们在一个样本数据集上建立一个<code class="du ml mm mn mo b">Lasso Regression</code>模型。然后让我们计算模型的平方根，这将给出模型误差。</p><p id="6470" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们照常导入建模所需的库。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="dc78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后我们做数据读取和一些数据编辑操作。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="ab42" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用套索回归，我们在训练集上建立模型。</p><p id="3854" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我不会深入概念细节，比如什么是fit，什么是train set。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="6c16" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们发现Lasso回归模型的常数为<strong class="ih hj"> -5.58 </strong>，其函数如下。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="92a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据我们拥有的数据集中的变量，我们发现Lasso模型中的可变系数如下。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="7324" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">众所周知，Lasso回归中的系数可能会根据确定的alpha参数而变化。在下面的操作中，我们根据不同的λ值确定α，然后根据确定的α值建立模型并计算系数。然后，我们用append命令将系数添加到名为coefs的列表中。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="88dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以从下图中看到系数是如何随着我们随机选择的alpha值而变化的。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h2 id="2377" class="le jv hi bd jw lf lg lh ka li lj lk ke iq ll lm ki iu ln lo km iy lp lq kq lr bi translated">预言；预测；预告</h2><p id="92fc" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">现在让我们在不指定任何参数的正常条件下进行模型预测。我们可以看到列车组的模型预测的前5个观察值如下。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="89b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，我们可以看到测试集的模型预测的前5个观察值如下。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="fe0e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们将在测试集上预测的值保存在一个名为y_pred的集群中。通过下面的计算，我们发现RMSE值为<strong class="ih hj"> 356，09 </strong>。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="9412" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果我们发现R平方的分数是<strong class="ih hj"> 0，41 </strong>。R平方得分是自变量解释的因变量变化的百分比。</p><p id="267e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">换句话说，我们可以说Lasso回归模型中的自变量解释了该数据集因变量的<strong class="ih hj"> 41，42% </strong>的变化。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="2a87" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">什么是R平方？</strong></p><blockquote class="kx ky kz"><p id="1b5d" class="if ig la ih b ii ij ik il im in io ip lb ir is it lc iv iw ix ld iz ja jb jc hb bi translated">r平方(R2)是一种统计测量方法，表示由回归模型中的一个或多个自变量解释的因变量方差的比例。相关性解释了自变量和因变量之间的关系强度，而R平方解释了一个变量的方差在多大程度上解释了第二个变量的方差。因此，如果模型的R2是0.50，那么大约一半的观察到的变化可以用模型的输入来解释。</p></blockquote><h2 id="46db" class="le jv hi bd jw lf lg lh ka li lj lk ke iq ll lm ki iu ln lo km iy lp lq kq lr bi translated">模型调整</h2><p id="7960" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在本节中，我们将使用LassoCV方法进行运算，以找到最佳的lambda值。</p><p id="9b5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用LassoCV进行套索调优。我们给出参数的alpha数据集为<strong class="ih hj"> <em class="la"> np.random.randint (0，1000，100) </em> </strong>。我们将交叉验证的数量设置为10。随着您增加cv的数量，您的结果将会改变，因为您将进行更多的组合。但是做得多并不总是好的。cv的数量会从某一点开始增加误差值。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="8b5f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们发现用交叉验证建立的套索模型的alpha值为<strong class="ih hj"> 169。</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="0cd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后我们用这个最佳的alpha值来设置正确的套索模型。然后，我们将测试集上的预测值打印到y_pred。结果，我们发现RMSE值为<strong class="ih hj"> 362，4。</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><p id="0644" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们知道，套索回归中不使用的系数和无关紧要的系数都等于零。你可以这样观察。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mp mq l"/></div></figure><h1 id="a448" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">最后</h1><p id="2d36" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">首先，我们在这篇博文中考察了什么是Lasso回归。然后我们讲了Lasso回归的特点和基础。数学上，我们检查了这个算法的模型。然后根据当前条件建立模型，计算误差值。在模型调整部分，我们通过用LassoCV计算最优alpha值，并根据这个alpha值重建校正模型，从而计算出调整后的误差值。Lasso中的基本逻辑是将未使用的系数设置为零。结果我们观察到了这一点。</p><h1 id="26a6" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">资源</h1><ol class=""><li id="9470" class="ls lt hi ih b ii ks im kt iq lu iu lv iy lw jc mr ly lz ma bi translated"><a class="ae jt" href="https://www.mygreatlearning.com/blog/understanding-of-lasso-regression/" rel="noopener ugc nofollow" target="_blank">https://www . mygreatlearning . com/blog/understanding-of-lasso-regression/</a></li><li id="7880" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc mr ly lz ma bi translated">【https://dataaspirant.com/lasso-regression/ T4】</li><li id="2a9c" class="ls lt hi ih b ii mb im mc iq md iu me iy mf jc mr ly lz ma bi translated"><a class="ae jt" href="https://www.investopedia.com/terms/r/r-squared.asp" rel="noopener ugc nofollow" target="_blank">https://www.investopedia.com/terms/r/r-squared.asp</a></li></ol></div></div>    
</body>
</html>