<html>
<head>
<title>SQL problem solved using Pyspark !!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Pyspark解决了SQL问题！！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sql-problem-solved-using-pyspark-1bbc3a0fb108?source=collection_archive---------16-----------------------#2021-05-14">https://medium.com/analytics-vidhya/sql-problem-solved-using-pyspark-1bbc3a0fb108?source=collection_archive---------16-----------------------#2021-05-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="325f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章是写给那些使用SQL进行数据分析的人的。我们在使用SQL时都面临的一个大问题是，它不允许您创建用户定义的函数并轻松使用它。</p><p id="cada" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jc translated"><span class="l jd je jf bm jg jh ji jj jk di"> C </span>尤里乌斯？？？想知道你是怎么做到的！！别担心，我会在这篇文章中分享。</p><p id="135f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Spark在核心spark之上构建了一些API，如GraphQL、MLIb、SQL和spark Streaming。我们的目标是创建一个函数，自动接受输入并执行一些操作给我们结果，使用SQL api中的相同函数来获得所需的输出。</p><h1 id="7b67" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">如何在pyspark中创建自定义函数？？</h1><p id="f921" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi jc translated"><span class="l jd je jf bm jg jh ji jj jk di"> S </span> park允许您轻松完成这项工作，即创建用户定义的函数并在SQL中使用它。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/34b8097bbe89a9d5b2f40a6ac60da3c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*io2Owwwvj22rzdwsLnU04Q.jpeg"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated"><a class="ae la" href="https://www.freepik.com/premium-vector/flat-thinking-concept_4457224.htm" rel="noopener ugc nofollow" target="_blank">来源:Freepik </a></figcaption></figure><h1 id="9de1" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">仍然在想，让我教你一个简单而有趣的方法来学习和创建你自己的用户自定义函数。</h1><blockquote class="lb"><p id="9619" class="lc ld hh bd le lf lg lh li lj lk jb dx translated">问题:创建一个接受一个输入并提供作为参数传递给函数的数字的平方的函数</p></blockquote><pre class="ll lm ln lo lp lq lr ls lt aw lu bi"><span id="7b6f" class="lv jm hh lr b fi lw lx l ly lz"><strong class="lr hi">def</strong> squared_func(s):<br/>  <strong class="lr hi">return</strong> s * s<br/>spark.udf.register("squaredWithPython", squared_func)</span></pre><ol class=""><li id="3bd3" class="ma mb hh ig b ih ii il im ip mc it md ix me jb mf mg mh mi bi translated">我们用python定义了一个函数</li></ol><p id="60a4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.注册它(在spark环境中定义它，以便可以在sql命令中使用它)</p><pre class="kp kq kr ks fd lq lr ls lt aw lu bi"><span id="38c6" class="lv jm hh lr b fi lw lx l ly lz">spark.range(1, 20).createOrReplaceTempView(“test”)</span></pre><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es mj"><img src="../Images/fe9de88e7adb1922272be43fff819f03.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*y7vae1Ca3NBikgyyZg3owA.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">数据帧测试输出</figcaption></figure><p id="ead4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.创建spark数据帧并创建临时视图以使用sql查询数据帧</p><pre class="kp kq kr ks fd lq lr ls lt aw lu bi"><span id="5ad8" class="lv jm hh lr b fi lw lx l ly lz">%sql select id, squaredWithPython(id) as id_squared from test</span></pre><p id="459d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.在sql查询中使用udf并提供列作为输入，我们将得到如下输出。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es mk"><img src="../Images/23eb03fbb7d4f4594ee1ce4a135382d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/1*GsbwubNlcDZ5fp0fPoq1jA.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">数据块示例1输出</figcaption></figure><p id="0d69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">示例2:</p><pre class="kp kq kr ks fd lq lr ls lt aw lu bi"><span id="37d2" class="lv jm hh lr b fi lw lx l ly lz">from pyspark.sql.types import StringType<br/>def young_or_old(s):<br/>  return 'Old' if s &gt; 60 else 'Young'<br/>  <br/>  <br/>spark.udf.register("young_or_oldWithPython", young_or_old, StringType())</span></pre><p id="a64d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的示例显示了一个函数，它将年龄作为输入参数，并返回该输入的age_group。如果你仔细注意到在第二个例子中，我们在函数注册命令中包含了“StringType ”,我们定义了该函数的返回数据类型</p><pre class="kp kq kr ks fd lq lr ls lt aw lu bi"><span id="ebe9" class="lv jm hh lr b fi lw lx l ly lz">%sql select id as Age, young_or_oldWithPython(id) as Age_group from test</span></pre><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="mm mn di mo bf mp"><div class="er es ml"><img src="../Images/d6b406e0e4b2eda45f35c0f2fb0213f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xRorH2MJQrr2kTKJTLf-Ww.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">数据块示例2输出</figcaption></figure><h1 id="79c4" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">感谢阅读文章直到最后:)</h1></div></div>    
</body>
</html>