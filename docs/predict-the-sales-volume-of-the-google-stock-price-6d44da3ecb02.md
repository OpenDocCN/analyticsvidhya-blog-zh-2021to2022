# é¢„æµ‹è°·æ­Œè‚¡ç¥¨ä»·æ ¼çš„é”€å”®é‡

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/predict-the-sales-volume-of-the-google-stock-price-6d44da3ecb02?source=collection_archive---------20----------------------->

![](img/4eb99523a77fa780a0fe33d40bbdecdd.png)

æ•°æ®é›†:[ç‚¹å‡»](https://drive.google.com/file/d/1oAQFQu9PSk0DRhEocefULy_qhzb9KHmO/view?usp=sharing)

# å¯é‡ç°ç»“æœçš„è®¾ç½®

è¦è·å¾—å¯é‡å¤çš„ç»“æœï¼Œæ‚¨å¿…é¡»æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼Œå¦åˆ™æ‚¨å°†è·å¾—ä¸åŒçš„ç»“æœ:

1)å°† PYTHONHASHSEED ç¯å¢ƒå˜é‡è®¾ç½®ä¸ºå›ºå®šå€¼

2)å°† python å†…ç½®çš„ä¼ªéšæœºç”Ÿæˆå™¨è®¾ç½®ä¸ºå›ºå®šå€¼

3)å°† numpy ä¼ªéšæœºå‘ç”Ÿå™¨è®¾ç½®ä¸ºå›ºå®šå€¼

4)å°†å¼ é‡æµä¼ªéšæœºç”Ÿæˆå™¨è®¾ç½®ä¸ºå›ºå®šå€¼

5)é…ç½®æ–°çš„å…¨å±€å¼ é‡æµä¼šè¯

```
# Seed value
# Apparently you may use different seed values at each stage
seed_value= 0# 1\. Set the `PYTHONHASHSEED` environment variable at a fixed value
import os
os.environ['PYTHONHASHSEED']=str(seed_value)# 2\. Set the `python` built-in pseudo-random generator at a fixed value
import random
random.seed(seed_value)# 3\. Set the `numpy` pseudo-random generator at a fixed value
import numpy as np
np.random.seed(seed_value)# 4\. Set the `tensorflow` pseudo-random generator at a fixed value
import tensorflow as tf
tf.random.set_seed(seed_value)# for latest versions:
# tf.compat.v1.set_random_seed(seed_value)
# 5\. Configure a new global `tensorflow` sessionfrom keras import backend as K
session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)
sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)K.set_session(sess)
```

é€šè¿‡éµå¾ªä¸Šè¿°ä»£ç ï¼Œæ‚¨å¯ä»¥è·å¾—å¯é‡å¤çš„ç»“æœ

æˆ‘ä»¬å¿…é¡»å¯¼å…¥ä¸€äº›åº“ã€‚å› ä¸ºå¤§å¤šæ•° python åº“éƒ½æœ‰ä¸€ç»„æœ‰ç”¨çš„å‡½æ•°ï¼Œå¯ä»¥ç®€å•åœ°æ¶ˆé™¤ä»å¤´ç¼–å†™ä»£ç çš„éœ€è¦ã€‚æ‰€ä»¥æˆ‘å¯¼å…¥äº†ä¸‹é¢çš„åº“

```
import warnings
warnings.filterwarnings('ignore')
import os
import numpy as np
import pandas as pd
import scipy.stats as stats
from matplotlib import pyplot as plt
%matplotlib inlineimport sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn import preprocessing
```

å®‰è£… Google Drive å¹¶åŠ è½½æ•°æ®é›†

æˆ‘å·²ç»æ·»åŠ äº†ä»¥ä¸‹ä»£ç ï¼Œç”¨äºå°† google drive å¸æˆ·å®‰è£…åˆ° google colaboratoryï¼Œä»¥è®¿é—® drive ä¸Šå¯ç”¨çš„æ–‡ä»¶ã€‚å½“æˆ‘ä»¬æ‰§è¡Œä¸‹é¢çš„ä»£ç æ—¶ï¼Œæˆ‘ä»¬å¿…é¡»è½¬åˆ°ç”Ÿæˆçš„ URLï¼Œå¹¶è·å¾—æˆæƒä»£ç æ‰èƒ½è¿›å…¥è¿™é‡Œã€‚

```
from google.colab import drive
drive.mount('/content/drive')
```

è¾“å…¥æˆæƒç åã€‚æ‚¨å°†æ”¶åˆ°ä¸€æ¡æ¶ˆæ¯ï¼Œæ˜¾ç¤ºâ€œå®‰è£…åœ¨[/å†…å®¹/é©±åŠ¨å™¨](https://colab.research.google.com/drive/1LPOegMGgG8ubnJmQ9oSG1AmXIYhSzPJd?authuser=1#)â€ã€‚æ­¤åï¼Œé€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæ‚¨å¯ä»¥è®¿é—®æ‚¨è¿æ¥çš„ google drive ä¸Šçš„æ–‡ä»¶ã€‚

```
import pandas as pddf = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/Google_Stock_Price.csv')
```

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæ‚¨å¯ä»¥çœ‹åˆ°è¯¥å˜é‡ä¸­å­˜å‚¨çš„å‰ 10 ä¸ªæ•°æ®è¡Œã€‚Pandas libary æä¾›äº†ä¸€ä¸ªåä¸º head()çš„æ–¹æ³•ï¼Œå¹¿æ³›ç”¨äºè¿”å›æ•°æ®å¸§æˆ–æ•°æ®ç³»åˆ—çš„å‰ n è¡Œã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•è¿”å›å­˜å‚¨æ•°æ®é›†çš„å‰ 5 è¡Œã€‚

```
df.head(10)
```

![](img/4bfab18e225e54cd9cc5f931ddecc028.png)

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ•°æ®é›†ä¸Šå¯ç”¨çš„è®°å½•æ•°

```
len(df)
```

1258 æ˜¯ä¸Šè¿°ä»£ç çš„è¾“å‡ºã€‚æ•°æ®é›†ä¸Šæœ‰ 1258 æ¡å¯ç”¨è®°å½•ã€‚

# æ­¥éª¤ 01 â€”æ•°æ®é¢„å¤„ç†

æ•°æ®é¢„å¤„ç†æ˜¯ä¸€ä¸ªä¸»è¦æ­¥éª¤ï¼Œå› ä¸ºä»æ•°æ®é›†ä¸­æå–çš„æœ‰ç”¨ä¿¡æ¯ç›´æ¥å½±å“åˆ°æ¨¡å‹çš„è´¨é‡ï¼Œæ‰€ä»¥åœ¨å°†æ•°æ®è¾“å…¥æ¨¡å‹ä¹‹å‰ï¼Œè‡³å°‘å¯¹æ•°æ®è¿›è¡Œå¿…è¦çš„é¢„å¤„ç†æ˜¯éå¸¸é‡è¦çš„ã€‚

## æ­¥éª¤ 01 A-å¤„ç†ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼

> æ­¥éª¤ 01 A â€”å¤„ç†ç¼ºå¤±å€¼

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ•°æ®é›†ä¸­ç¼ºå¤±çš„å€¼ã€‚

```
df.isnull().any()
```

![](img/14941cc29b901be2c7a03414f3718b27.png)

ä»ä¸Šé¢çš„è¾“å‡ºæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œæˆ‘ä»¬åœ¨æ•°æ®é›†ä¸­æ²¡æœ‰ä»»ä½•ä¸¢å¤±çš„å€¼ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥ã€‚

> æ­¥éª¤ 01 B â€”å¤„ç†é‡å¤å€¼

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ•°æ®é›†ä¸­çš„é‡å¤è¡Œã€‚

```
print(df.duplicated().value_counts()) # To check duplicated values
```

![](img/416abd9b182bc4ad8d80b8e643b106c9.png)

ä»ä¸Šé¢çš„è¾“å‡ºæˆ‘ä»¬å¯ä»¥å¾—å‡ºç»“è®ºï¼Œæ•°æ®é›†ä¸­æ²¡æœ‰é‡å¤çš„è¡Œ

> æ­¥éª¤ 01c-å¤„ç†å¼‚å¸¸å€¼

a)æ£€æŸ¥åˆ—åâ€œOpenâ€ä¸Šçš„å¼‚å¸¸å€¼

å¼€ç›˜ä»·æ˜¯äº¤æ˜“æ‰€å½“å¤©å¼€å¸‚æ—¶è¯åˆ¸é¦–æ¬¡äº¤æ˜“çš„ä»·æ ¼ã€‚å¼€ç›˜ä»·ä¸åŒäºå‰ä¸€å¤©çš„æ”¶ç›˜ä»·ã€‚

```
plt.rcParams["figure.figsize"] = (24, 3)
temp_df = pd.DataFrame(df, columns=['Open'])temp_df.boxplot(vert=False)
```

![](img/148a6c76058a6fa36561ddd778afeaa4.png)

```
from matplotlib import pyplot
plt.rcParams["figure.figsize"] = (24, 8)
plt.plot(df['Open'])
plt.title("Google Stock Open Price Changes")
plt.xlabel("Time")
plt.ylabel("Open Price")
plt.show()
```

![](img/5af5a560da9c1d33f4cde6dc293064f3.png)

é€šè¿‡æŸ¥çœ‹ä¸Šé¢çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥è¯´åœ¨ç‰¹æ€§æ–¹é¢æ²¡æœ‰å¤ªå¤§çš„é—®é¢˜ï¼Œ

b)æ£€æŸ¥åˆ—åâ€œé«˜â€ä¸Šçš„å¼‚å¸¸å€¼

é«˜ç‚¹æ˜¯ä¸€æ®µæ—¶é—´å†…è‚¡ç¥¨äº¤æ˜“çš„æœ€é«˜ä»·æ ¼ã€‚

```
plt.rcParams["figure.figsize"] = (24, 3)
temp_df = pd.DataFrame(df, columns=['High'])
temp_df.boxplot(vert=False)
```

![](img/2474aea6f92b73886174e5d941df622c.png)

```
plt.rcParams["figure.figsize"] = (24, 8)
plt.plot(df['High'])
plt.title("Google Stock High Price Changes")
plt.xlabel("Time")
plt.ylabel("High Price")
plt.show()
```

![](img/b38d42bb17819c19c362d1cc552a830f.png)

é€šè¿‡æŸ¥çœ‹ä¸Šé¢çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥è¯´åœ¨ç‰¹æ€§æ–¹é¢æ²¡æœ‰å¤ªå¤§çš„é—®é¢˜ï¼Œ

c)æ£€æŸ¥åˆ—åâ€œä½â€ä¸Šçš„å¼‚å¸¸å€¼

ä½ç‚¹æ˜¯è¿™ä¸€æ—¶æœŸçš„æœ€ä½ä»·ã€‚

```
plt.rcParams["figure.figsize"] = (24, 3)
temp_df = pd.DataFrame(df, columns=['Low'])
temp_df.boxplot(vert=False)
```

![](img/b86d4468e69ae3a85fb94b73989b2064.png)

```
plt.rcParams["figure.figsize"] = (24, 8)
plt.plot(df['Low'])
plt.title("Google Stock Low Price Changes")
plt.xlabel("Time")
plt.ylabel("Low Price")
plt.show()
```

![](img/fec7a25d92e8843289c0d093991b5f55.png)

é€šè¿‡æŸ¥çœ‹ä¸Šé¢çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥è¯´åœ¨ç‰¹æ€§æ–¹é¢æ²¡æœ‰å¤ªå¤§çš„é—®é¢˜ï¼Œ

d)æ£€æŸ¥åˆ—åâ€œCloseâ€ä¸Šçš„å¼‚å¸¸å€¼

æ”¶ç›˜ä»·æ˜¯ä¸€ç§è¯åˆ¸åœ¨æ­£å¸¸äº¤æ˜“æ—¥çš„æœ€åäº¤æ˜“ä»·æ ¼ã€‚è¯åˆ¸çš„æ”¶ç›˜ä»·æ˜¯æŠ•èµ„è€…ç”¨æ¥è·Ÿè¸ªå…¶é•¿æœŸè¡¨ç°çš„æ ‡å‡†åŸºå‡†ã€‚æ”¶ç›˜ä»·ä¸ä¼šåæ˜ ç°é‡‘è‚¡åˆ©ã€è‚¡ç¥¨è‚¡åˆ©æˆ–è‚¡ç¥¨åˆ†å‰²çš„å½±å“ã€‚

```
df['Close'] = df['Close'].str.replace(',','')
df['Close'] = df['Close'].astype('float')
plt.rcParams["figure.figsize"] = (24, 3)
temp_df = pd.DataFrame(df, columns=['Close'])
temp_df.boxplot(vert=False)
```

![](img/d75745d3bfedb067b2e85917762ae35c.png)

```
plt.rcParams["figure.figsize"] = (24, 8)
plt.title("Google Stock Close Price Changes")
plt.xlabel("Time")
plt.ylabel("Close Price")
plt.plot(df['Close'])
plt.show()
```

![](img/e10534d895e05f4b8c86e2d1bf89c354.png)

é€šè¿‡æŸ¥çœ‹ä¸Šé¢çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥è¯´åœ¨åŠŸèƒ½ä¸Šæœ‰ç›¸å½“å¤šçš„é—®é¢˜ï¼Œ

æ‰€ä»¥æˆ‘æ£€æŸ¥äº†ä»¥ä¸‹æƒ…å†µ:

```
df[ df['High']< df['Close']]
```

![](img/880b7bfaf79a914bf1ec7781e1c4efdd.png)

æˆ‘å·²ç»æ”¾å¼ƒäº†æ”¶ç›˜ä»·å€¼ï¼Œå› ä¸ºè¿™äº›ä»·å€¼ä¸­çš„å¤§å¤šæ•°éƒ½å¤§äºé«˜ä»·æ ¼ä»·å€¼ï¼Œæ‰€ä»¥å®é™…ä¸Šä¸å¯èƒ½åƒé‚£æ ·ã€‚

```
df = df.drop(â€˜Closeâ€™, axis = 1)
```

e)æ£€æŸ¥åˆ—åâ€œVolumeâ€ä¸Šçš„å¼‚å¸¸å€¼

```
plt.rcParams["figure.figsize"] = (24, 3)
df['Volume'] = df['Volume'].str.replace(',','')
df['Volume'] = df['Volume'].astype('float')
temp_df = pd.DataFrame(df, columns=['Volume'])
temp_df.boxplot(vert=False)
```

![](img/ae9fc8281723beeb73c12c749befd96b.png)

```
plt.rcParams["figure.figsize"] = (24, 8)
plt.title("Google Stock Volume Changes")
plt.xlabel("Time")
plt.ylabel("Volume")
plt.plot(df['Volume'])
plt.show()
```

![](img/c61f9489ef370b47f2ea4a4d28b0e0ec.png)

é€šè¿‡æŸ¥çœ‹ä¸Šé¢çš„è¾“å‡ºï¼Œæˆ‘ä»¬å¯ä»¥è¯´åœ¨åŠŸèƒ½ä¸Šæ²¡æœ‰å¤ªå¤§çš„é—®é¢˜

# æ­¥éª¤ 02 â€”ç‰¹å¾ç¼–ç 

äººå·¥ç¥ç»ç½‘ç»œæ¨¡å‹è¦æ±‚æ‰€æœ‰çš„è¾“å…¥å’Œè¾“å‡ºå€¼éƒ½åº”è¯¥æ˜¯æ•°å€¼ã€‚å› æ­¤ï¼Œå¦‚æœæ•°æ®é›†åŒ…å«åˆ†ç±»æ•°æ®ï¼Œæ‚¨å¿…é¡»åœ¨æ‹Ÿåˆå’Œè¯„ä¼°æ¨¡å‹ä¹‹å‰å°†å…¶ç¼–ç ä¸ºæ•°å­—ã€‚æœ‰å‡ ç§æ–¹æ³•å¯ä»¥å®Œæˆè¿™é¡¹ä»»åŠ¡ï¼Œå¦‚ä¸€é”®ç¼–ç ã€æ•´æ•°(æ ‡ç­¾)ç¼–ç ã€‚è¿™é‡Œæˆ‘ä½¿ç”¨äº†ä¸€é”®ç¼–ç 

## ä»€ä¹ˆæ˜¯å‘¨æœ«æ•ˆåº”ï¼Ÿ

å‘¨æœ«æ•ˆåº”æ˜¯é‡‘èå¸‚åœºä¸­çš„ä¸€ç§ç°è±¡ï¼Œåœ¨è¿™ç§å¸‚åœºä¸­ï¼Œå‘¨ä¸€çš„è‚¡ç¥¨å›æŠ¥ç‡å¾€å¾€æ˜¾è‘—ä½äºå‰ä¸€ä¸ªå‘¨äº”çš„å›æŠ¥ç‡ã€‚å‘¨æœ«æ•ˆåº”ä¹Ÿè¢«ç§°ä¸ºå‘¨ä¸€æ•ˆåº”ã€‚

## ä»€ä¹ˆæ˜¯æœˆæœ«æ•ˆåº”ï¼Ÿ

â€œæœˆæœ«æ•ˆåº”â€ä¸€ç›´æ˜¯è®¸å¤šç§‘å­¦ç ”ç©¶çš„ä¸»é¢˜ã€‚ç»Ÿè®¡æ•°æ®æ˜¾ç¤ºï¼Œè‚¡ç¥¨ä»·æ ¼ï¼Œå°¤å…¶æ˜¯ç¾å›½è‚¡ç¥¨ä»·æ ¼ï¼Œå¾€å¾€ä¼šåœ¨è¿™ä¸ªæœˆçš„æœ€åå‡ å¤©å’Œå¤´å‡ å¤©ä¸Šæ¶¨ã€‚

## ä¹°è‚¡ç¥¨æœ€å¥½çš„æœˆä»½æ˜¯å“ªä¸ªæœˆï¼Ÿ

åœ¨å²æœ«å¹´åˆä»¥åŠå¤å­£ï¼Œå¸‚åœºå¾€å¾€ä¼šæœ‰å¼ºåŠ²çš„å›æŠ¥ã€‚ä¹æœˆä¼ ç»Ÿä¸Šæ˜¯ä¸€ä¸ªæ·¡å­£ã€‚å°½ç®¡ 1929 å¹´å’Œ 1987 å¹´åˆ†åˆ«ä¸‹è·Œäº† 19.7%å’Œ 21.5%ï¼Œä½† 10 æœˆä»½çš„å¹³å‡å›æŠ¥ç‡ä»å†å²ä¸Šçœ‹æ˜¯æ­£çš„ã€‚

è€ƒè™‘åˆ°ä¸Šé¢çš„å®è·µï¼Œæˆ‘å¢åŠ äº†ä¸€ä¸ªé¢å¤–çš„åˆ—â€œæ—¥-å‘¨â€æ¥æ˜¾ç¤ºä¸€å‘¨ä¸­çš„å“ªä¸€å¤©ã€‚ä½™å³å¾å¾—æœˆï¼Œæ—¥ä¹Ÿã€‚

```
df['Date'] = pd.to_datetime(df['Date'])
df['Day_week'] = df['Date'].dt.day_name()#df['Year'] = pd.DatetimeIndex(df['Date']).year
df['Month'] = pd.DatetimeIndex(df['Date']).month
df['Day'] = pd.DatetimeIndex(df['Date']).day
df = df.drop('Date', axis = 1)
df.head(10)
```

åœ¨ä»æ•°æ®ä¸­è·å¾—ä¸€äº›é™„åŠ ç‰¹å¾ä¹‹åï¼Œ

![](img/b4beae75f6a96e35735a20b424e2d285.png)

```
month_dummies = pd.get_dummies(df[â€˜Monthâ€™],prefix=â€™Mâ€™)
df=pd.concat([df, month_dummies], axis=1)day_dummies = pd.get_dummies(df['Day_week'],prefix='W')
df=pd.concat([df, day_dummies], axis=1)dayNum_dummies = pd.get_dummies(df['Day'],prefix='D')
df=pd.concat([df, dayNum_dummies], axis=1)df = df.drop('Month', axis = 1)
df = df.drop('Day_week', axis = 1)
df = df.drop('Day', axis = 1)df.head(10)
```

ä¿®æ”¹æ•°æ®é›†ï¼Œ

![](img/420a4d60fd4c3972043c09336591e4f7.png)

# æ­¥éª¤ 03 æ•°æ®è½¬æ¢

```
plt.rcParams["figure.figsize"] = (24, 12)
X[['High','Low','Open']].hist()
```

![](img/b2380a1446abf3b7243a7f0daee8a8c2.png)

ç”±äºæœ€ç»ˆå€¼ï¼Œä¸éœ€è¦ä½“ç§¯åˆ—è½¬æ¢ã€‚

# æ­¥éª¤ 04-ç¼©æ”¾å’Œ/æˆ–æ ‡å‡†åŒ–ç‰¹å¾

é€šè¿‡æ‰§è¡Œä»¥ä¸‹ä»£ç ï¼Œæˆ‘åˆ é™¤äº†æ•°æ®é›†ä¸­åˆ†ç±»åˆ—ï¼Œä»¥ä¾¿è¿›è¡Œç¼©æ”¾:

```
dummies = day_dummies.columns.tolist() + month_dummies.columns.tolist()+dayNum_dummies.columns.tolist()Remove_columns_values = dummiesX_without_Cat=X.drop(Remove_columns_values, axis = 1)
X_without_Cat.head(5)
```

åˆ é™¤åˆ†ç±»åˆ—åï¼Œ

![](img/1dd47de576049777c69f4d606264ddbc.png)

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘ä½¿ç”¨ sklearn çš„ minmax scaler ç¼©æ”¾äº†è¡¨ä¸­çš„è¿ç»­å€¼

```
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()data_training = scaler.fit_transform(X_without_Cat)
data_training
```

![](img/7ce5d066ea2077bf0b83ea0574e69d39.png)

```
columns_value_new=X_without_Cat.columns
X_Scaled_Except = pd.DataFrame(data_training, columns=columns_value_new)plt.rcParams[â€œfigure.figsizeâ€] = (24, 12)
X_Scaled_Except.hist()
```

æ˜¾ç¤ºç¼©æ”¾/æ ‡å‡†åŒ–æ•ˆæœï¼Œ

![](img/09611f4d1d07f361479cbbfe1182c533.png)

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘å·²ç»åˆ†åˆ«ç¼©æ”¾äº†ä½“ç§¯åˆ—ï¼Œç”¨äºæ¨¡å‹è¾“å‡ºçš„é€†å˜æ¢ï¼Œ

```
scalerVol= MinMaxScaler()
data_trainingVol= scalerVol.fit_transform(X_without_Cat.iloc[:,3:4])
data_trainingVol
```

![](img/2161bf9e54525e5235389b6698d5d308.png)

# æ­¥éª¤ 05 ç›¸å…³çŸ©é˜µ

```
import seaborn as sns
plt.rcParams["figure.figsize"] = (24, 8)
sns.heatmap(X_Scaled_Except.corr(),annot=True);
```

![](img/83126d6a831716d8ce8cd92f741fbb14.png)

```
X_Scaled_Except.corr()
```

![](img/49303d1deccc58b5b486e067282c1e28.png)

ä»ä¸Šè¡¨å’Œç›¸å…³çŸ©é˜µæˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼Œä½å¼€é«˜èµ°ä¹‹é—´æœ‰å¾ˆé«˜çš„ç›¸å…³æ€§ã€‚æ‰€ä»¥æˆ‘ä»¬åªèƒ½é€‰æ‹©ä¸€ä¸ª 1 æ¥å¹³è¡¡å·¥ä½œã€‚ç”±äºä»·æ ¼ä¹‹é—´çš„å·®å¼‚å¾ˆå°ï¼Œæˆ‘é€‰æ‹©äº†å¹³è¡¡å·¥ä½œçš„æ‰€æœ‰åŠŸèƒ½

```
data_Final =X_Scaled_Except
for f in dummies:
    data_Final = data_Final.join(X[f])
```

# æ­¥éª¤ 06 é€’å½’ç¥ç»ç½‘ç»œ

**å°†å¤šå…ƒåºåˆ—åˆ†å‰²æˆæ ·æœ¬ï¼Œ**

```
def split_series(series, n_past):
     X, y = list(), list()
     for window_start in range(len(series)):
          past_end = window_start + n_past
          if past_end >= len(series):
          break# slicing the past and future parts of the window
           past, future = series[window_start:past_end, 0:4]
                          ,series[past_end,3]
           X.append(past)
           y.append(future)
      return np.array(X), np.array(y)
```

æˆ‘å·²ç»ä½¿ç”¨äº†ä¸Šé¢çš„å‡½æ•°ï¼ŒæŒ‰ç…§ä¸‹é¢çš„ä»£ç åšäº†è¿™ä¸ªä¾‹å­ã€‚

```
X, y = split_series(data_Final.to_numpy(), 6)
```

æˆ‘è€ƒè™‘äº†è¿‡å» 6 å¤©çš„è®°å½•æ¥é¢„æµ‹ç¬¬ 7 å¤©çš„äº¤æ˜“é‡

```
import math
n_test = math.floor(len(y)*0.2)
X_train, X_test, y_train, y_test = X[:-n_test], X[-n_test:], y[:-n_test], y[-n_test:]
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)
```

æˆ‘å°†æ•°æ®é›†åˆ†æˆ 20 %ç”¨äºæµ‹è¯•ï¼Œ80 %ç”¨äºè®­ç»ƒã€‚æˆ‘ä»¥é€‚å½“çš„æ–¹å¼ä½¿ç”¨äº†ä¸Šè¿°ä»£ç ã€‚å› ä¸ºæˆ‘ä»¬å¿…é¡»åœ¨ä¸æ”¹å˜é¡ºåºçš„æƒ…å†µä¸‹æ‹†åˆ†æ•°æ®é›†ã€‚

**é•¿çŸ­æœŸè®°å¿†(LSTM)**

é•¿çŸ­æœŸè®°å¿†(LSTM)ç½‘ç»œæ˜¯ä¸€ç§èƒ½å¤Ÿåœ¨åºåˆ—é¢„æµ‹é—®é¢˜ä¸­å­¦ä¹ é¡ºåºä¾èµ–æ€§çš„é€’å½’ç¥ç»ç½‘ç»œã€‚

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œä½ å¯ä»¥å®šä¹‰ä¸€ä¸ªæ¨¡å‹ã€‚

```
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout
from tensorflow.keras.layers import RNNregressor = Sequential()
regressor.add(LSTM(units = 60, activation = 'relu', return_sequences = True, input_shape = (6, 4)))
regressor.add(Dropout(0.2))
regressor.add(LSTM(units = 60, activation = 'relu', return_sequences = True))
regressor.add(Dropout(0.2))
regressor.add(LSTM(units = 80, activation = 'relu', return_sequences = True))
regressor.add(Dropout(0.2))
regressor.add(LSTM(units = 120, activation = 'relu'))
regressor.add(Dropout(0.2))
regressor.add(Dense(units = 1))
regressor.summary()
```

## **æ¨¡å‹çš„ç¼–åˆ¶**

é€šè¿‡ä¸‹é¢ç»™å®šçš„ä»£ç æ¥ç¼–è¯‘æ¨¡å‹ï¼Œæˆ‘ä½¿ç”¨äº†ä¸€ä¸ªä¼˜åŒ–å™¨ä½œä¸ºâ€œäºšå½“â€å’ŒæŸå¤±ä½œä¸ºâ€œå‡æ–¹è¯¯å·®â€ã€‚åœ¨ä¼˜åŒ–ç®—æ³•éƒ¨åˆ†ï¼Œæˆ‘ä»¬å¿…é¡»è®¡ç®—æ¨¡å‹å½“å‰çŠ¶æ€çš„è¯¯å·®ï¼Œå¹¶ä¸”è¦åå¤ä¼°è®¡è¯¯å·®ã€‚å› æ­¤ï¼Œå®ƒå¯ä»¥ç”¨æ¥ä¼°è®¡è®­ç»ƒæ¨¡å‹çš„æŸå¤±ï¼Œä»è€Œå¯ä»¥æ›´æ–°è®­ç»ƒæ¨¡å‹çš„æƒé‡ï¼Œä»¥å‡å°‘ä¸ä¸‹ä¸€é˜¶æ®µä¸€æ ·å¤šçš„æŸå¤±ã€‚

```
regressor.compile(optimizer=â€™adamâ€™, loss = â€˜mean_squared_errorâ€™)
```

## **æ‹Ÿåˆæ¨¡å‹**

æ‰¹é‡å¤§å°æ§åˆ¶åœ¨æ¨¡å‹çš„å†…éƒ¨å‚æ•°æ›´æ–°ä¹‹å‰è¦å¤„ç†çš„è®­ç»ƒæ ·æœ¬çš„æ•°é‡ã€‚å†å…ƒæ•°æ§åˆ¶è®­ç»ƒæ•°æ®é›†ä¸­çš„å®Œæ•´éæ•°ã€‚æˆ‘ç»™äº† 150 ä¸ªçºªå…ƒã€‚å› æ­¤ï¼Œå°†ä¼šå‘ç”Ÿ 150 æ¬¡å¯¹è®­ç»ƒæ•°æ®é›†çš„å®Œæ•´éå†ã€‚

```
history=regressor.fit(X_train, y_train, epochs=150, batch_size=32, verbose=2,validation_data=(X_test, y_test) )
```

## è¯„ä¼°æ¨¡å‹

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°å‡æ–¹å·®(MSE ),å®ƒå‘Šè¯‰ä½ ä¸€æ¡å›å½’çº¿ç¦»ä¸€ç»„ç‚¹æœ‰å¤šè¿‘ã€‚è¿™æ˜¯é€šè¿‡ä»ç‚¹åˆ°å›å½’çº¿çš„è·ç¦»å¹¶å¹³æ–¹å®ƒä»¬æ¥å®ç°çš„ã€‚å‡æ–¹æ ¹è¯¯å·®(RMSE)æ˜¯ä»¥ MSE çš„å¹³æ–¹æ ¹è¡¨ç¤ºçš„è¯¯å·®ç‡ã€‚

```
from numpy import sqrt
mse = regressor.evaluate(X_test, y_test, verbose=0)
print('MSE: %.9f, RMSE: %.9f' % (mse, sqrt(mse)))
```

åœ¨è¿™é‡Œï¼Œæˆ‘å·²ç»æ”¶åˆ°äº† MSE: 0.000936066ï¼Œå’Œ RMSE:0.0399536567

## ç»˜åˆ¶å­¦ä¹ æ›²çº¿

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶æ¨¡å‹çš„å­¦ä¹ æ›²çº¿ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å­¦ä¹ æ›²çº¿æ¥è¯Šæ–­å­¦ä¹ ä¸­çš„é—®é¢˜ï¼Œä¾‹å¦‚è®­ç»ƒæœŸé—´æ¨¡å‹çš„æ¬ æ‹Ÿåˆæˆ–è¿‡æ‹Ÿåˆã€‚

```
plt.figure(figsize=(14,5))
from matplotlib import pyplot
pyplot.title('Learning Curves')
pyplot.xlabel('Epoch')
pyplot.ylabel('Root Mean Squared Error')
pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='val')
pyplot.legend()
pyplot.show()
```

![](img/aa5e7ce74ad7c771175ab9e64a79bdb9.png)

é€šè¿‡ä½¿ç”¨å­¦ä¹ æ›²çº¿ï¼Œåœ¨è¿‡æ‹Ÿåˆå’Œæ¬ æ‹Ÿåˆæ¨¡å‹æ¡ä»¶ä¹‹é—´å­˜åœ¨è‰¯å¥½çš„æ‹Ÿåˆã€‚æˆ‘ä»¬å¯ä»¥è¯´è‰¯å¥½æ‹Ÿåˆæ˜¯æŒ‡è®­ç»ƒå’ŒéªŒè¯æŸå¤±éƒ½é™ä½åˆ°ä¸€ä¸ªç¨³å®šç‚¹ï¼Œä¸¤ä¸ªæœ€ç»ˆæŸå¤±å€¼ä¹‹é—´çš„å·®è·æœ€å°ã€‚

## é¢„è¨€ï¼›é¢„æµ‹ï¼›é¢„å‘Š

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥é¢„æµ‹ç»™å®šè¾“å…¥çš„éŸ³é‡ã€‚ç„¶è€Œæœ€ç»ˆå‡ºæ¥çš„ä¸æ˜¯é‡ã€‚å› ä¸ºæˆ‘ä»¬å·²ç»æŠŠå®ƒä½œä¸ºæ¨¡å‹çš„è¾“å…¥ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»é‡æ–°è°ƒæ•´è¾“å‡ºå€¼ï¼Œä»¥è·å¾—é¢„æµ‹çš„ä½“ç§¯ã€‚

```
y_pred = regressor.predict(X_test)
```

## é‡æ–°è°ƒæ•´è¾“å‡º

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹é¢çš„ä»£ç é‡æ–°è°ƒæ•´æ¨¡å‹çš„è¾“å‡ºæ¥å¾—åˆ°ä½“ç§¯ã€‚æˆ‘å·²ç»ç”¨é€†å˜æ¢å‡½æ•°åšäº†ç›¸å…³çš„å·¥ä½œã€‚

```
y_predVol = scalerVol.inverse_transform(y_pred)
y_test = y_test.reshape(y_test.shape[0], 1)
y_testVol = scalerVol.inverse_transform(y_test)volume_pred= []
for i in range(len(y_predVol)):
     volume_pred.append(y_predVol[i,0])volume_test= []
for i in range(len(y_testVol)):
     volume_test.append(y_testVol[i,0])
```

## å¯è§†åŒ–ç»“æœ

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥ç»˜åˆ¶å‡ºæ˜¾ç¤ºå®é™…è°·æ­Œé‡ä¸é¢„æµ‹è°·æ­Œé‡çš„å›¾è¡¨ã€‚æˆ‘ç”¨çº¢è‰²çº¿æ˜¾ç¤ºäº†çœŸå®çš„è°·æ­Œé‡ï¼Œç”¨è“è‰²çº¿é¢„æµ‹äº†è°·æ­Œé‡ã€‚

```
plt.figure(figsize=(14,5))
plt.plot(volume_test, color = 'red', label = 'Real Google Volume')
plt.plot(volume_pred, color = 'blue', label = 'Predicted Google Volume')plt.title('Google Stock Volume Prediction')
plt.xlabel('Time')
plt.ylabel('Google Stock Volume')
plt.legend()
plt.show()
```

![](img/31419f991a3ec4e38feef015586b4974.png)

## ä½¿ç”¨ğ‘…^2 ç»Ÿè®¡è®¡ç®—æ¨¡å‹çš„å‡†ç¡®æ€§

é€šè¿‡ä¸‹é¢çš„ä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æ¨¡å‹çš„ r2 åˆ†æ•°ã€‚å¯¹ r å¹³æ–¹æœ€å¸¸è§çš„è§£é‡Šæ˜¯å›å½’æ¨¡å‹ä¸è§‚æµ‹æ•°æ®çš„æ‹Ÿåˆç¨‹åº¦ã€‚é€šå¸¸ï¼Œè¾ƒé«˜çš„ r å¹³æ–¹è¡¨ç¤ºæ¨¡å‹æ›´é€‚åˆ

```
from sklearn import metricsaccuracy = metrics.r2_score(volume_test,volume_pred)
print(" Accuracy:", accuracy)
```

ç²¾ç¡®åº¦:0.38386868686