<html>
<head>
<title>Illustrated Vision Transformers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图解视觉变形金刚</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/illustrated-vision-transformers-165f4d0c3dd1?source=collection_archive---------8-----------------------#2021-07-27">https://medium.com/analytics-vidhya/illustrated-vision-transformers-165f4d0c3dd1?source=collection_archive---------8-----------------------#2021-07-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="b2de" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="c1b8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">自从2017年推出Transformer以来，在自然语言处理(NLP)领域取得了巨大的成功。几乎所有的NLP任务都使用了变形金刚，并且取得了巨大的成功。与rnn和LSTMs相比，Transformer有效的主要原因是它处理长期依赖性的能力。在NLP中获得成功后，有各种各样的方法将其用于计算机视觉任务。Dosovitskiy等人的论文<a class="ae kb" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank">一幅图像相当于16x16个字:用于图像识别的变形金刚</a>提出使用变形金刚，并在各种计算机视觉任务中取得了一些很好的结果。</p><p id="381d" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">Vison Transformer (ViT)在训练模型时使用了非常大的数据集。在ImageNet(纸张将ImageNet标记为中型数据集)等数据集上进行训练时，模型的准确性低于ResNets。这是因为转换器缺乏归纳偏差，如翻译等变和局部性，因此当在不充分的数据上训练时，它不能很好地概括。</p><h1 id="df6d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">视觉转换器概述</h1><ul class=""><li id="4553" class="kh ki hi jf b jg jh jk jl jo kj js kk jw kl ka km kn ko kp bi translated">将图像分割成小块</li><li id="2c09" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">提供这些补片的线性嵌入序列，作为transformer(展平图像)的输入。在这里，图像补片被视为与令牌相同的方式(如在NLP任务中)</li><li id="e9ab" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">向每个补丁嵌入添加位置嵌入和可学习嵌入<code class="du kv kw kx ky b">class</code>(类似于BERT)</li><li id="34d5" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">通过Transformer encoder传递这些(补丁+位置+ <code class="du kv kw kx ky b">class</code>)嵌入，并获得每个<code class="du kv kw kx ky b">class</code>令牌的输出值</li><li id="6d57" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated">将<code class="du kv kw kx ky b">class</code>的表示通过MLP头，得到最终的类预测。</li></ul><h1 id="bfcc" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">方法</h1><figure class="la lb lc ld fd le er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es kz"><img src="../Images/3ba365f5891e939cca76692da82caaa6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-ZQKvTSw4UEJx1tT.gif"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated"><strong class="bd ih">来源:</strong> <a class="ae kb" href="https://ai.googleblog.com/2020/12/transformers-for-image-recognition-at.html" rel="noopener ugc nofollow" target="_blank"> <strong class="bd ih">谷歌AI博客</strong> </a></figcaption></figure><p id="9fe8" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">上图描述了视觉转换器的概况。如图所示，给定图像，图像被分割成小块。这些图像碎片被展平，并作为一系列标记传递给转换器编码器。与面片嵌入一起，位置嵌入也作为输入传递给转换器编码器。在这里，位置嵌入与面片嵌入一起添加，以保留位置信息。</p><h1 id="1a4a" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">如何将一幅图像转换成一系列矢量，并输入到transformer编码器中？</h1><p id="f1d3" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">让我们通过拍摄大小为256 * 256 * 3的RGB图像来解码上图。第一步是从输入图像创建大小为16 * 16的面片。我们可以创建总共16 * 16 = 256个补丁。将输入图像分割成小块后，另一个步骤是线性放置所有分割的图像。该图显示第一个补片位于最左侧，最右侧位于最右侧。然后，我们线性投影这些小块以获得$1 * 768$矢量表示。这种表示被称为补丁嵌入。补丁嵌入的大小变成$256 * 768$(因为我们总共有256个补丁，每个补丁表示为$1 * 768$向量。</p><p id="d071" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">接下来，我们预先考虑可学习嵌入<code class="du kv kw kx ky b">class</code>令牌和位置嵌入以及补丁嵌入，使得大小为257 * 768美元。这里，位置嵌入用于保留位置信息。将图像转换成矢量表示后，我们需要按顺序发送图像，因为转换器不知道补丁的顺序，这与CNN不同。因此，我们需要手动添加一些关于补丁位置的信息。</p><h1 id="6144" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">视觉转换器的组件</h1><p id="6484" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">由于Vision Transformer基于标准的Transformer架构，唯一的区别是它用于图像任务，而不是文本，这里使用的组件几乎相同。在这里，我们讨论视觉转换器中使用的组件及其重要性。</p><blockquote class="lp lq lr"><p id="961a" class="jd je ls jf b jg kc ji jj jk kd jm jn lt ke jq jr lu kf ju jv lv kg jy jz ka hb bi translated"><em class="hi">边注:如果你想深入钻研《变形金刚》，那么Jay Alammar的</em> <a class="ae kb" href="https://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank"> <em class="hi">这里的</em> </a> <em class="hi">是个不错的起点。</em></p></blockquote><h1 id="1430" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">补丁嵌入</h1><p id="d4e0" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">正如论文的名字“一个图像相当于16 * 16个单词的变形金刚”，论文的主要要点是将图像分解成小块。给定图像，它被重塑成2D展平补丁。</p><h1 id="382f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">可学习嵌入<code class="du kv kw kx ky b">class</code></h1><p id="59d4" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">可学习的嵌入被添加到嵌入的补丁中。在变换器编码器输出端的这个嵌入类的状态用作表示y。这个分类头在预训练和微调期间被附加。</p><h1 id="a6b9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">位置嵌入</h1><p id="983c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">位置嵌入和一个<code class="du kv kw kx ky b">class</code>令牌一起被添加到补丁嵌入中，然后这个令牌被输入到转换器编码器中。</p><h1 id="c8c4" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">变压器编码器</h1><figure class="la lb lc ld fd le er es paragraph-image"><div class="er es lw"><img src="../Images/9558936d00ceaf0acec8b3cd1352b93a.png" data-original-src="https://miro.medium.com/v2/resize:fit:552/format:webp/0*udJTqxolVVJvP1IN.png"/></div></figure><p id="e091" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">transformer编码器是一种标准的transformer编码器架构，如最初的transformer <a class="ae kb" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">论文</a>所示。该编码器采用嵌入的补丁(补丁嵌入、位置嵌入和<code class="du kv kw kx ky b">class</code>嵌入)。变压器编码器包括交替层的多头自我关注和MLP块。在每个块之前使用层归一化，在每个块之后使用剩余连接。</p><h1 id="29ae" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">使用混合架构</h1><p id="abfa" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">以前，图像补片用于形成输入序列，形成输入序列的另一种方法可以是CNN(卷积神经网络)的特征图。这里，从CNN图中提取的补丁被用作补丁嵌入。来自报纸:</p><blockquote class="lp lq lr"><p id="c8a0" class="jd je ls jf b jg kc ji jj jk kd jm jn lt ke jq jr lu kf ju jv lv kg jy jz ka hb bi translated"><em class="hi">作为原始图像补片的替代，输入序列可以由CNN的特征图形成。在这个混合模型中，面片嵌入投影E(等式。1)应用于从CNN特征图提取的面片。作为一种特殊情况，面片可以具有1×1的空间大小，这意味着输入序列是通过简单地展平特征图的空间维度并投影到变换器维度而获得的。</em></p></blockquote><h1 id="d7d9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">参考</h1><ul class=""><li id="f784" class="kh ki hi jf b jg jh jk jl jo kj js kk jw kl ka km kn ko kp bi translated"><a class="ae kb" href="https://arxiv.org/pdf/2010.11929.pdf" rel="noopener ugc nofollow" target="_blank">一幅图像相当于16 * 16个字:用于大规模图像识别的变形金刚</a></li><li id="8e93" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><a class="ae kb" href="https://amaarora.github.io/2021/01/18/ViT.html" rel="noopener ugc nofollow" target="_blank"> ViT博客—阿曼·阿罗拉</a></li><li id="32c2" class="kh ki hi jf b jg kq jk kr jo ks js kt jw ku ka km kn ko kp bi translated"><a class="ae kb" href="https://theaisummer.com/vision-transformer/" rel="noopener ugc nofollow" target="_blank">艾夏</a></li></ul></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><p id="6693" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><em class="ls">原载于2021年7月27日</em><a class="ae kb" href="https://nepalprabin.github.io/2021/07/27/illustrated-vision-transformers.html" rel="noopener ugc nofollow" target="_blank"><em class="ls">https://nepalprabin . github . io</em></a><em class="ls">。</em></p></div></div>    
</body>
</html>