<html>
<head>
<title>Video Preprocessor and Augmentation for Deep Learning tasks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于深度学习任务的视频预处理器和增强</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/video-preprocessor-and-augmentation-for-deep-learning-tasks-12dd3fcce868?source=collection_archive---------4-----------------------#2021-03-24">https://medium.com/analytics-vidhya/video-preprocessor-and-augmentation-for-deep-learning-tasks-12dd3fcce868?source=collection_archive---------4-----------------------#2021-03-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class="hf hg ez fb hh ab cb"><figure class="hi hj hk hl hm hn ho paragraph-image"><img src="../Images/8a4f13f54095ed8655c516f2e0dd5d6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/1*TonVU1mxzS5FJ-aNpZkgVw.gif"/></figure><figure class="hi hj hk hl hm hn ho paragraph-image"><img src="../Images/8853f2c7786ac5fb4c2bf7bc639773ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/1*mOueTknEUAftauFDgj4EZQ.gif"/><figcaption class="hr hs et er es ht hu bd b be z dx hv di hw hx translated">来自魏茨曼视频数据集的增强视频</figcaption></figure></div><div class=""/><p id="59a7" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">随着多种视频处理任务对视频分类和识别模型的需求不断增长，了解如何使用python库处理视频非常重要。因此，在本文中，我们将了解如何处理原始视频数据，并根据我们的具体需求进行相应的调整。</p><h1 id="f1c6" class="jv jw ia bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">1.预处理视频数据</h1><p id="3c26" class="pw-post-body-paragraph ix iy ia iz b ja kt jc jd je ku jg jh ji kv jk jl jm kw jo jp jq kx js jt ju ha bi translated">为了预处理视频数据，我们将使用python库，例如</p><ul class=""><li id="88d6" class="ky kz ia iz b ja jb je jf ji la jm lb jq lc ju ld le lf lg bi translated">OpenCV:<a class="ae lh" href="https://opencv.org/" rel="noopener ugc nofollow" target="_blank">https://opencv.org/</a></li><li id="b7ba" class="ky kz ia iz b ja li je lj ji lk jm ll jq lm ju ld le lf lg bi translated">环球:【https://docs.python.org/3/library/glob.html T2】</li><li id="7484" class="ky kz ia iz b ja li je lj ji lk jm ll jq lm ju ld le lf lg bi translated">https://pypi.org/project/imageio/<a class="ae lh" href="https://pypi.org/project/imageio/" rel="noopener ugc nofollow" target="_blank"/></li><li id="e707" class="ky kz ia iz b ja li je lj ji lk jm ll jq lm ju ld le lf lg bi translated">OS:<a class="ae lh" href="https://docs.python.org/3/library/os.html" rel="noopener ugc nofollow" target="_blank">https://docs.python.org/3/library/os.html</a></li></ul><p id="ecb3" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">请访问以上链接，以便更好地理解和使用每个库。</p><p id="5d01" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">你可能很熟悉，视频只是以帧的形式堆叠起来的图像，所以一个视频是由多个帧组合而成的。</p><p id="af65" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">我将使用<a class="ae lh" href="http://www.wisdom.weizmann.ac.il/~vision/SpaceTimeActions.html" rel="noopener ugc nofollow" target="_blank"> <em class="ln">魏茨曼视频数据集</em> </a>进行处理。</p><p id="823d" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">数据集的主文件夹应该具有以下结构。在从这些子目录输入数据时，您还可以编辑子文件夹的名称，以便更好地重定向。</p><figure class="lp lq lr ls fd hj er es paragraph-image"><div class="er es lo"><img src="../Images/c04ebfe393a9911d1101ba8b9947e9fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*MUna41GiNprLTlHcYuPqzQ.png"/></div></figure><p id="91ec" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">正如你在上面的结构中看到的，我已经根据类标签重命名了Weizmann数据集的所有子目录，以便将来更容易获取。</p><figure class="lp lq lr ls fd hj"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="db9a" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">从上面的代码片段中，你可以看到我分别使用os和glob来列出和获取所有文件，我还将X &amp; labels作为空列表，并在其中附加各自的数据。最后，我将这两个列表作为NumPy数组返回。之后，X将所有的视频文件作为一个帧数组，下面我分享了load_video代码片段，以便更好地理解这个流程。</p><figure class="lp lq lr ls fd hj"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="d8ac" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">正如我们所看到的，我使用OpenCV读取特定视频中的所有帧，将它们添加到frames数组中，调整它们的大小，并将其作为一个NumPy数组返回，像素值在0到1之间归一化。</p><p id="2769" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">为了理解这个流程，我还在下面附上了crop_center_square(框架)代码:</p><figure class="lp lq lr ls fd hj"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="45a6" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">现在，如果您调用loaddata(“视频目录的路径”，类的数量)函数，您将获得视频处理为一个NumPy数组和所有视频的标签。</p><pre class="lp lq lr ls fd lv lw lx ly aw lz bi"><span id="97c5" class="ma jw ia lw b fi mb mc l md me">Xin, Yin = loaddata(“path to the video directory”, number of classes)</span></pre><p id="f379" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">如果您检查Xin[index]的形状，其中index是将视频作为帧数组的任何有效索引，您将得到(x，224，224，3)的输出，其中x是该视频中的帧数，224是帧的宽度和高度，3是红色、绿色和蓝色的通道大小。</p><p id="98b8" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">现在，为了可视化来自已处理的NumPy数组的任何视频，我们可以使用下面提到的to_gif函数。</p><figure class="lp lq lr ls fd hj"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="ce1f" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">我们可以看到，我们正在将归一化像素值转换回255范围格式，以便正确显示。</p><p id="3f6a" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">如果我们调用_gif(sample_video ),我们将得到如下输出:</p><figure class="lp lq lr ls fd hj er es paragraph-image"><div class="er es mf"><img src="../Images/7d14a4a2ffa6c7676cdd3d866d06644d.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/1*0Dz9FvljLZ_5o5Z0JgVKaw.gif"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">示例视频的gif</figcaption></figure><h1 id="3838" class="jv jw ia bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">2.视频数据增强</h1><p id="f33c" class="pw-post-body-paragraph ix iy ia iz b ja kt jc jd je ku jg jh ji kv jk jl jm kw jo jp jq kx js jt ju ha bi translated">为了克服<strong class="iz ib">数据</strong>数量有限、多样性有限的问题，我们用现有的<strong class="iz ib">数据生成(制造)自己的<strong class="iz ib">数据</strong>。</strong>哪个<strong class="iz ib"> </strong>我们用任何特定类别的更多样化的数据来训练任何深度学习模型。</p><p id="b53a" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">我主要使用<a class="ae lh" href="https://github.com/okankop/vidaug" rel="noopener ugc nofollow" target="_blank"><em class="ln">vidau</em></a><em class="ln">g</em>进行视频增强相关的任务。</p><ul class=""><li id="0d78" class="ky kz ia iz b ja jb je jf ji la jm lb jq lc ju ld le lf lg bi translated">https://github.com/okankop/vidaug</li></ul><p id="7da6" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">在<a class="ae lh" href="https://github.com/okankop/vidaug" rel="noopener ugc nofollow" target="_blank"> vidaug </a>库中探索了对特定视频进行增强或不进行增强的可能性，我附上了用于增强的代码片段，以及如何使我们的训练数据比以前更大以获得更好的结果，并减少深度学习任务中那些不健康的过度拟合。</p><p id="d738" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">数据扩充包括以下方式:</p><ul class=""><li id="fad6" class="ky kz ia iz b ja jb je jf ji la jm lb jq lc ju ld le lf lg bi translated">随机作物</li><li id="5d78" class="ky kz ia iz b ja li je lj ji lk jm ll jq lm ju ld le lf lg bi translated">随机旋转</li><li id="de9b" class="ky kz ia iz b ja li je lj ji lk jm ll jq lm ju ld le lf lg bi translated">水平翻转</li><li id="8c86" class="ky kz ia iz b ja li je lj ji lk jm ll jq lm ju ld le lf lg bi translated">垂直滑动</li><li id="a7f8" class="ky kz ia iz b ja li je lj ji lk jm ll jq lm ju ld le lf lg bi translated">高斯-布朗勒</li><li id="a67b" class="ky kz ia iz b ja li je lj ji lk jm ll jq lm ju ld le lf lg bi translated">等等。</li></ul><p id="d683" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">以下是关于如何使用vidaug进行视频增强的代码:</p><figure class="lp lq lr ls fd hj"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="68f6" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">下面给出了创建增强视频数据的NumPy数组的函数:</p><figure class="lp lq lr ls fd hj"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="1401" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">在所需数据的扩增后，我们应该能够使用扩增的数据，所以我附加了如何与现有的训练数据连接的代码，以创建一个新的更大的训练数据集。</p><figure class="lp lq lr ls fd hj"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="fb59" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">以下是扩充数据的示例:</p><figure class="lp lq lr ls fd hj er es paragraph-image"><div class="er es mf"><img src="../Images/f2b65946260deed117825f19880bad6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:448/1*XoHylVojPyCMIif-VrS5EQ.gif"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">扩充数据</figcaption></figure><p id="96e8" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">正如我们所看到的，上面的视频是使用随机旋转和垂直翻转来增强的。</p><p id="0371" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">谢谢大家，我会带来更多关于视频分类和识别的文章。</p><p id="32f6" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">请通过以下方式联系我:</p><div class="hf hg ez fb hh mg"><a href="https://www.linkedin.com/in/biplab-barman/" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd ib fi z dy ml ea eb mm ed ef hz bi translated">Biplab酒保</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">在全球最大的职业社区LinkedIn上查看Biplab Barman的个人资料。Biplab有3个工作列在他们的…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.linkedin.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu hp mg"/></div></div></a></div><p id="c1dc" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">请检查:</p><div class="hf hg ez fb hh mg"><a href="https://github.com/Biplab097/i3d_finetuning" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd ib fi z dy ml ea eb mm ed ef hz bi translated">Biplab097/i3d_finetuning</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">在这个库中，我们使用迁移学习和微调新的双流膨胀3D ConvNet (I3D)这是…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">github.com</p></div></div></div></a></div><p id="0030" class="pw-post-body-paragraph ix iy ia iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated">更多问题。</p><figure class="lp lq lr ls fd hj er es paragraph-image"><div role="button" tabindex="0" class="mw mx di my bf mz"><div class="er es mv"><img src="../Images/ea47e29735bb5761f9425ff9a75445c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_NuRz9j3oxGIZI_r_ovIaA.jpeg"/></div></div></figure></div></div>    
</body>
</html>