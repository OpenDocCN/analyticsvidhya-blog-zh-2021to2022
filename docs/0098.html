<html>
<head>
<title>ML18: NLP — Surname Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML18: NLP —姓氏分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ml18-6e9b1b66c30e?source=collection_archive---------19-----------------------#2021-01-04">https://medium.com/analytics-vidhya/ml18-6e9b1b66c30e?source=collection_archive---------19-----------------------#2021-01-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="635f" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">一个迷你项目实现MLP，有线电视新闻网，RNN与PyTorch</h2></div><p id="b5a9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">关键词</strong>:自然语言处理(NLP)、文本挖掘、分类、多层感知器(MLP)、卷积神经网络(CNN)、递归神经网络(RNN)</p><blockquote class="js jt ju"><p id="3b5a" class="iw ix jv iy b iz ja ii jb jc jd il je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated"><strong class="iy hi"> <em class="hh">完整PPT&amp;WORD on GitHub</em></strong><em class="hh">:</em><a class="ae jz" href="https://bit.ly/3VLcxYp" rel="noopener ugc nofollow" target="_blank">https://bit.ly/3VLcxYp</a><em class="hh"><br/></em><strong class="iy hi"><em class="hh">完整Python code on Colab</em></strong><em class="hh">:<br/>1 .预处理:</em><a class="ae jz" href="https://bit.ly/3hGWYhs" rel="noopener ugc nofollow" target="_blank">https://bit.ly/3hGWYhs</a><em class="hh"><br/>2。</em><a class="ae jz" href="https://bit.ly/3nTLxpf" rel="noopener ugc nofollow" target="_blank">https://bit.ly/3nTLxpf</a><em class="hh"><br/>MLP 3。CNN:</em><a class="ae jz" href="https://bit.ly/3rwRCKr" rel="noopener ugc nofollow" target="_blank">https://bit.ly/3rwRCKr</a><em class="hh"><br/>4。</em>https://bit.ly/3ptfcG8<a class="ae jz" href="https://bit.ly/3ptfcG8" rel="noopener ugc nofollow" target="_blank">RNN</a></p></blockquote></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="0bca" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">代码主要来源于本书<strong class="iy hi"> <em class="jv"> Rao，D. &amp; McMahan，B. (2019)。用PyTroch进行自然语言处理。加利福尼亚州:奥莱利媒体</em> </strong>。在此基础上，我调整了模型并可视化了结果。</p><p id="e463" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这篇文章实际上是我在<em class="jv"> NCCU </em>的<em class="jv"> PyTorch和机器学习</em>课程的最终项目。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es kh"><img src="../Images/24d67889a85c8c45a225e333e1aa2217.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*YYzoV6THJ2QIp9tyQdytBw.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">图1: Rao，d .和McMahan，B. (2019年)。用PyTroch进行自然语言处理。加利福尼亚州:奥赖利媒体。</figcaption></figure></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><blockquote class="js jt ju"><p id="f81a" class="iw ix jv iy b iz ja ii jb jc jd il je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated"><strong class="iy hi"> <em class="hh">大纲</em></strong><em class="hh"><br/>(1)</em><a class="ae jz" href="#aefc" rel="noopener ugc nofollow"><em class="hh">数据介绍&amp;数据预处理</em></a><em class="hh"><br/>(2)</em><a class="ae jz" href="#b4a9" rel="noopener ugc nofollow"><em class="hh">神经网络调优技巧</em></a><em class="hh"><em class="hh"><a class="ae jz" href="#a76f" rel="noopener ugc nofollow"><em class="hh">模型介绍&amp;基线模型</em></a><em class="hh"/></em></em></p></blockquote></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><h1 id="aefc" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><em class="ll"> (1) </em>数据介绍&amp;数据预处理</h1><h2 id="477f" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">1.数据介绍</h2><p id="3aed" class="pw-post-body-paragraph iw ix hh iy b iz ma ii jb jc mb il je jf mc jh ji jj md jl jm jn me jp jq jr ha bi translated">姓氏数据集，是作者从互联网上不同的姓名来源收集到的18个不同国籍的10000个姓氏的集合。我们将数据分成70%的训练数据、15%的验证数据和15%的测试数据。</p><h2 id="28ec" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">2.数据预处理</h2><p id="97af" class="pw-post-body-paragraph iw ix hh iy b iz ma ii jb jc mb il je jf mc jh ji jj md jl jm jn me jp jq jr ha bi translated">首先，我们将姓氏数据集分成70%的训练数据、15%的验证数据和15%的测试数据。</p><p id="5743" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">接下来，我们使用<em class="jv">一键编码</em>对姓氏进行矢量化。我们利用两种变体——“折叠的独热向量”和“独热矩阵”我们在MLP使用“折叠的热点向量”来节省运行时间，在RNN使用CNN &amp;的“热点矩阵”。简而言之，“折叠的独热向量”不保留顺序信息，只给出字符出现或不出现的布尔值，而“独热矩阵”记录顺序信息。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><h1 id="b4a9" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">(2)神经网络调谐提示</h1><p id="a32c" class="pw-post-body-paragraph iw ix hh iy b iz ma ii jb jc mb il je jf mc jh ji jj md jl jm jn me jp jq jr ha bi translated">检查ML17的神经网络调谐提示。</p><div class="mf mg ez fb mh mi"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/ml17-a2f9315e5f1a"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hi fi z dy mn ea eb mo ed ef hg bi translated">ML17:调整深层网络</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">活化剂、优化剂、时期、小批量、BN、漏失和重量衰减</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">medium.com</p></div></div><div class="mr l"><div class="ms l mt mu mv mr mw kn mi"/></div></div></a></div></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><h1 id="a76f" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">(3)模型介绍&amp;基线模型</h1><h2 id="b6d8" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">1.模型介绍</h2><p id="0888" class="pw-post-body-paragraph iw ix hh iy b iz ma ii jb jc mb il je jf mc jh ji jj md jl jm jn me jp jq jr ha bi translated"><strong class="iy hi">神经元</strong>:神经网络的最小单元。<br/><strong class="iy hi">感知器</strong>:单层神经网络。<br/><strong class="iy hi">FNN(前馈神经网络)</strong> : MLP(多层感知器，也叫“全连接”网络)，CNN(卷积神经网络)。<br/><strong class="iy hi">RNN(递归神经网络)</strong> : RNN，LSTM(长短期记忆)，GRU(门控递归单元)。</p><h2 id="c6d4" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">2.基线模型</h2><p id="6643" class="pw-post-body-paragraph iw ix hh iy b iz ma ii jb jc mb il je jf mc jh ji jj md jl jm jn me jp jq jr ha bi translated">我们使用从书中检索的MLP和CNN的完全相同的模型分别作为MLP和CNN的基线模型。至于RNN，我们做了同样的事情，但略微调整了<em class="jv">下降概率</em>从50%到0%,因为0%产生更好的性能。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><h1 id="3d20" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><em class="ll"> MLP </em></h1><h2 id="b601" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">1.基线MLP模型</h2><div class="ki kj kk kl fd ab cb"><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/10cfda801698e587fed1e4621030e96f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*KF_adr1jL63BbRMGEJYwNg.png"/></div></figure><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/4aa49319059db2e36561f2a512403beb.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*GyPkelZAtVDQ8OSYq119Vw.png"/></div></figure><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/16b660f362a5f3ca5f9d1de8b53c5f0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*yZz18ZyJOMyoNtw34gXHvg.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx nh di ni nj translated">图2、3和4:基线MLP模型的细节。</figcaption></figure></div><h2 id="86e4" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">2.最佳MLP模特</h2><div class="ki kj kk kl fd ab cb"><figure class="mx km nk mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/f16886da2fb3e9c00519135ba722de99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ODVYSaSprmz2HG0pOa5BtA.png"/></div></figure><figure class="mx km nk mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/e2fce791cc0407743e25702ba56448eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*XfIrfmCMe9Bjjhvi3JagAw.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx nl di nm nj translated">图5和图6:最佳MLP模型的细节。</figcaption></figure></div><h2 id="97fa" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">3.MLP摘要</h2><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="er es nn"><img src="../Images/b68128e6f273746c185c9ab1e63bf74c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xc5A-CGMgoIy1Qxpvyoz7g.png"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">图7:MLP模型总结。</figcaption></figure></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><h1 id="fe31" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">(5)美国有线电视新闻网</h1><h2 id="4041" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">1.基线CNN模型</h2><div class="ki kj kk kl fd ab cb"><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/a53c780f7024e68b0e7fa8b10a6bbc33.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*VT2MGCpGKN765KIhK2eOkw.png"/></div></figure><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/cad945d6b9ae2812971c50ce5fec5e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*uuaW_aA_vr65URR1MSk9ew.png"/></div></figure><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/2220298e1aeb92680b7e88f2d56f5fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*eTXZ0iOtcbeawkNNmyjPEQ.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx nh di ni nj translated">图8、9和10:基线CNN模型的细节。</figcaption></figure></div><h2 id="7b2c" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">2.最佳CNN模式</h2><div class="ki kj kk kl fd ab cb"><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/bcf10a3ae5ec7575782ae3c2e01c7613.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*b0hQ1tMQGe6VuV9Pwr3PUQ.png"/></div></figure><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/83dc5609714c819974e1dc04285fe3af.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*JwFOCAm5SBqDc3-0JzhskA.png"/></div></figure><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/0233b696d3f6af468ac50689d7bda0b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*MveGrlzR8vIu9AcPswMVcQ.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx nh di ni nj translated">图11 &amp; 12 &amp; 13:最佳CNN模型的细节。</figcaption></figure></div><h2 id="7647" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">3.CNN摘要</h2><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="er es nn"><img src="../Images/2263a2fbad19b7b6c80190ff9c69d6ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WLtIIC6wqR3TLfjnuBFRzA.png"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">图14:CNN模型总结。</figcaption></figure></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><h1 id="70df" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">(6) RNN</h1><h2 id="eb57" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">1.基线RNN模型</h2><div class="ki kj kk kl fd ab cb"><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/755909e9e0a1899aba51201046f50004.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*Y5aqUYDZdeqra-7mbLyx6A.png"/></div></figure><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/a4a65aa780e7afa3fdf8568f180a7c66.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*UH_a_sGIMGoJHSzDAMaMmg.png"/></div></figure><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/39e907f378be6b120528b38b7fa3844d.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*2zGa-sSO5Vz9XEtw73VAdA.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx nh di ni nj translated">图15 &amp; 16 &amp; 17:基线RNN模型的细节。</figcaption></figure></div><h2 id="c72d" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">2.最佳RNN模特</h2><div class="ki kj kk kl fd ab cb"><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/3c5c0b9085edf9684d641f886e7e8fdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*7cw0AFKfXMlj4D45iRBJ8Q.png"/></div></figure><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/a6f532b543eeb16a3e4206ea59231b36.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*KnpX9BKL7t-1uZ74_0B6oQ.png"/></div></figure><figure class="mx km my mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/87a8a8872d04c75af6d6cc1f889c609a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*4d4OeV7SvI8W_xFT3yo-cA.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx nh di ni nj translated">图18 &amp; 19 &amp; 20:最佳RNN模型的细节。</figcaption></figure></div><h2 id="bd25" class="lm ku hh bd kv ln lo lp kz lq lr ls ld jf lt lu lf jj lv lw lh jn lx ly lj lz bi translated">3.RNN摘要</h2><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="er es nn"><img src="../Images/9e86bf049d7a30277edef7542e88d6ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hegriH0f0QQ6IXjJnbcwVg.png"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">图21:RNN模型的总结。</figcaption></figure></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><h1 id="f434" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">(7)结论</h1><div class="ki kj kk kl fd ab cb"><figure class="mx km nk mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/cf97f3d69afea922877f6d5dfafb3905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*OP4l01Njl4t7n28R81MJ4Q.png"/></div></figure><figure class="mx km nk mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/a727556e7882b817d17438c5d20b81c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*nXgTQ8FkiZZ2Ujxqyt-GhA.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx nl di nm nj translated">图22和23:“MLP对CNN”和“CNN对RNN”</figcaption></figure></div><div class="ab cb"><figure class="mx km nk mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/b2f32f7e5561d6f86146db68f86bbefa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*RbqRAWF6-eUgVFr0OHxpOg.png"/></div></figure><figure class="mx km nk mz na nb nc paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><img src="../Images/54017748f3dcc70b808e45cd414a53df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*m5OtqmECuDUgchWWCD3iFg.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx nl di nm nj translated">图24和25:“集成学习”和“前景”</figcaption></figure></div></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><h1 id="2d50" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated"><em class="ll"> (8)参考文献</em></h1><p id="1ead" class="pw-post-body-paragraph iw ix hh iy b iz ma ii jb jc mb il je jf mc jh ji jj md jl jm jn me jp jq jr ha bi translated">1.Géron，A. (2019)。使用Scikit-Learn、Keras和TensorFlow进行机器学习(第二版。).加利福尼亚州:奥赖利媒体。</p><p id="d210" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">2.Rao d .和McMahan b .(2019年)。用PyTroch进行自然语言处理。加利福尼亚州:奥赖利媒体。</p><p id="6eef" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">3.萨卡尔博士(2019)。用Python进行文本分析(第二版。).印度卡纳塔克邦:新闻。</p><p id="8f62" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">4.t . ganegedara(2018年)。用张量流进行自然语言处理。英国伯明翰:Packt出版公司。</p><p id="4277" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">5.Subramanian，V. (2018)。用PyTorch进行深度学习。英国伯明翰:Packt出版公司。</p><p id="a6ba" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">6.j .帕特森和a .吉布森(2017)。一个实践者的方法。加利福尼亚州:奥赖利媒体。</p><p id="a9cf" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi">7. 斎藤康毅 (2016). ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実. Japan, JP: O’Reilly Japan.</p><p id="c802" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">8.郭，男(2021)。ML16:动手文本预处理。检索自</p><div class="mf mg ez fb mh mi"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/ml16-ef6105b5bb34"><div class="mj ab dw"><div class="mk ab ml cl cj mm"><h2 class="bd hi fi z dy mn ea eb mo ed ef hg bi translated">ML16:动手文本预处理</h2><div class="mp l"><h3 class="bd b fi z dy mn ea eb mo ed ef dx translated">自然语言处理的第一步&amp;文本挖掘</h3></div><div class="mq l"><p class="bd b fp z dy mn ea eb mo ed ef dx translated">medium.com</p></div></div><div class="mr l"><div class="no l mt mu mv mr mw kn mi"/></div></div></a></div></div></div>    
</body>
</html>