# ä¸»é¢˜å»ºæ¨¡æŠ€æœ¯

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/topic-modelling-techniques-37826fbab549?source=collection_archive---------4----------------------->

## NLP ä¸­ç”¨äºä¸»é¢˜å»ºæ¨¡çš„ä¸åŒæŠ€æœ¯çš„ç®€è¦æ¦‚è¿°ä»¥åŠæŠ½è±¡ä»£ç ç¤ºä¾‹

![](img/a4c79b2ff4229ecb71a611c30167ef0c.png)

ä½œè€…å›¾ç‰‡

ä½ æ˜¯å¦æ›¾ç»æ‹¥æœ‰å¤§é‡æ¥è‡ªå„ç§æ¥æºçš„æ–‡æœ¬ï¼Œå¹¶å¸Œæœ›åˆ†æäººä»¬è°ˆè®ºçš„å¹¿æ³›ä¸»é¢˜/è¯é¢˜ï¼Œå¹¶å°†å®ƒä»¬åˆ†æˆç‰¹å®šçš„ç¾¤ç»„ï¼Œé‚£ä¹ˆä¸»é¢˜å»ºæ¨¡å°±æ˜¯ä¸ºä½ å‡†å¤‡çš„ã€‚é‚£ä¹ˆä»€ä¹ˆæ˜¯ä¸»é¢˜å»ºæ¨¡ã€‚ä¸»é¢˜å»ºæ¨¡æ˜¯ä¸€ä¸ªç»Ÿè®¡è¿‡ç¨‹ï¼Œé€šè¿‡å®ƒæ‚¨å¯ä»¥ä»ç»™å®šçš„æ–‡æ¡£é›†åˆä¸­è¯†åˆ«ã€æå–å’Œåˆ†æä¸»é¢˜ã€‚

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡ä¸€äº›è‘—åçš„æŠ€æœ¯æ¥æ¢ç´¢ä¸»é¢˜å»ºæ¨¡ã€‚

æœ‰ä¸€ä¸ªç»†å¾®çš„åŒºåˆ«ï¼Œäººä»¬å¯èƒ½ä¼šæ„Ÿåˆ°å›°æƒ‘ã€‚å’Œè¯é¢˜åˆ†ç±»æ˜¯ä¸åŒçš„è¿˜æ˜¯ä¸€æ ·çš„ï¼Ÿé¦–å…ˆï¼Œä¸»é¢˜åˆ†ç±»å±äºæœ‰ç›‘ç£çš„ ML ç®—æ³•ï¼Œä¸»é¢˜å»ºæ¨¡å±äºæ— ç›‘ç£çš„ ML ç®—æ³•ã€‚æœŸæœ›ä½ å·²ç»çŸ¥é“å…¶ä¸­çš„åŒºåˆ«ï¼Œä¸‡ä¸€ä½ ä¸çŸ¥é“ï¼ŒæŠŠå®ƒæ”¾åœ¨ä¸€è¡Œç¨‹åºä¸­ä¸»é¢˜å»ºæ¨¡ä¸éœ€è¦ä»»ä½•é¢„å…ˆçš„è®­ç»ƒï¼Œä¸åƒä¸»é¢˜åˆ†ç±»ã€‚

å› ä¸ºå¯¹æ–‡æœ¬å»ºæ¨¡ä¸éœ€è¦ä»»ä½•è®­ç»ƒï¼Œæ‰€ä»¥åˆ†ææ•°æ®å¾ˆå®¹æ˜“ã€‚ä½†æ˜¯ï¼Œè°ä¹Ÿä¸èƒ½ä¿è¯ä¼šå¾—åˆ°ç²¾ç¡®çš„ç»“æœã€‚

# é‚£ä¹ˆå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„:

ä¸»é¢˜å»ºæ¨¡çš„åŸºæœ¬å‡è®¾æ˜¯

*   æ¯ä¸ªæ–‡æ¡£ç”±ä¸»é¢˜çš„[ç»Ÿè®¡æ··åˆ](https://www.statisticshowto.datasciencecentral.com/mixture-distribution/)(å³æ‰€æœ‰ä¸»é¢˜çš„ç»Ÿè®¡åˆ†å¸ƒï¼Œå¯ä»¥é€šè¿‡â€œæ€»ç»“â€è¯­æ–™åº“ä¸­è¦†ç›–çš„æ‰€æœ‰ä¸»é¢˜çš„æ‰€æœ‰åˆ†å¸ƒæ¥è·å¾—)

ä¸»é¢˜å»ºæ¨¡æŠ€æœ¯çš„ä½œç”¨æ˜¯æ‰¾å‡ºè¯­æ–™åº“ä¸­çš„æ–‡æ¡£ä¸­å­˜åœ¨å“ªäº›ä¸»é¢˜ï¼Œä»¥åŠæ¯ä¸ªä¸»é¢˜çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆã€‚

è®©æˆ‘ä»¬ä»æœ€è‘—åçš„ LSA å¼€å§‹ï¼Œè·³åˆ°æˆ‘ä»¬ä¸Šé¢è®¨è®ºè¿‡çš„å‡ ä¸ªè¿™æ ·çš„æŠ€æœ¯ã€‚

# æ½œåœ¨ç‹„åˆ©å…‹é›·åˆ†é…(LDA):

æ½œåœ¨ç‹„åˆ©å…‹é›·åˆ†é…æ˜¯ä¸€ä¸ªç”Ÿæˆç»Ÿè®¡æ¨¡å‹ï¼Œå®ƒå…è®¸é€šè¿‡[æœªè§‚å¯Ÿåˆ°çš„](https://en.wikipedia.org/wiki/Latent_variable)ç»„æ¥è§£é‡Šè§‚å¯Ÿç»“æœï¼Œè¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆæ•°æ®çš„æŸäº›éƒ¨åˆ†æ˜¯ç›¸ä¼¼çš„ã€‚å®ƒå‡è®¾ä»»ä½•æ–‡æ¡£éƒ½æ˜¯ä¸»é¢˜å’ŒçŸ­è¯­çš„ç»„åˆã€‚å®ƒä½¿ç”¨ä¼˜åŒ–çš„ VEM(å˜åˆ†ä¾‹å¤–æœ€å¤§åŒ–)æŠ€æœ¯æ¥è¯„ä¼°æ•´ä¸ªæ–‡æœ¬è¯­æ–™åº“ã€‚è¿™å¯ä»¥é€šè¿‡å•è¯æ’åæ¥å…‹æœã€‚ç„¶è€Œï¼Œè¿™ç§æ–­è¨€åœ¨å¥å­ä¸­ç¼ºä¹è¯­ä¹‰ã€‚æˆ‘ä»¬çœŸçš„å¯ä»¥æ›´å¥½åœ°äº†è§£ä¸»é¢˜ä¹‹é—´çš„å…³ç³»ã€‚

![](img/1476ab50ccf6d546ffbfddb919c0fc91.png)

[https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)

è€ƒè™‘åˆ°è½¦ç‰Œç¬¦å·ã€‚ç›’å­æ˜¯ä»£è¡¨â€œé‡å¤å®ä½“â€æˆ–â€œé‡å¤è€…â€çš„æ¿å—å¤–è¡¨é¢/æ¿ä»£è¡¨æ–‡æ¡£ï¼Œè€Œå†…è¡¨é¢/æ¿ä»£è¡¨ç»™å®šæ–‡æ¡£ä¸­é‡å¤çš„å•è¯ä½ç½®ã€‚

ä»å‡ºç°åœ¨ç‰¹å®šæ–‡æ¡£çš„ä¸»é¢˜ä¸­çš„ç‹„åˆ©å…‹é›·åˆ†å¸ƒä¸­ï¼Œæˆ‘ä»¬æŠ½å–éšæœºæ ·æœ¬ï¼Œå…¶ä¸­Î±æ˜¯è¡¨ç¤ºæ–‡æ¡£åˆ†å¸ƒçš„å‚æ•°ã€‚è¿™ä¸ªè¯é¢˜åˆ†å¸ƒæ˜¯Î¸ï¼Œæˆ‘ä»¬æ ¹æ®è¿™ä¸ªè°“è¯­çš„åˆ†å¸ƒä»ä¸­é€‰æ‹©ä¸€ä¸ªå…·ä½“çš„è¯é¢˜ Zã€‚

æ¥ä¸‹æ¥ï¼Œä»å¦ä¸€ä¸ªç‹„åˆ©å…‹é›·åˆ†å¸ƒğ›½ï¼Œåƒå­—æ•°åˆ†å¸ƒ Dir(Î±)ï¼Œæˆ‘ä»¬æŒ‘ä¸€ä¸ªéšæœºæ ·æœ¬ä»£è¡¨é¢˜ç›® z çš„å­—åˆ†å¸ƒï¼Œè¿™ä¸ªå­—åˆ†å¸ƒæ˜¯Ï†ã€‚ç”±æ­¤æˆ‘ä»¬é€‰æ‹©æˆ‘ä»¬çš„å•è¯ wã€‚

ä»æ–‡æœ¬ä¸­äº§ç”Ÿæ¯ä¸ªå•è¯çš„æ–¹æ³•åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤:

![](img/e4420692babd5a2968624577bee79ce8.png)

[https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation)

è¿™é‡Œçš„å¤šé¡¹å¼åˆ†å¸ƒæ˜¯æŒ‡åªæœ‰ä¸€ä¸ªå°¾è¿¹çš„å¤šé¡¹å¼ï¼Œä¹Ÿç§°ä¸º[åˆ†ç±»åˆ†å¸ƒ](https://en.wikipedia.org/wiki/Categorical_distribution)ã€‚

## ä»£ç ç‰‡æ®µ:

ä½ å¯ä»¥ä½¿ç”¨ [genism](https://radimrehurek.com/gensim/models/ldamodel.html) è½¯ä»¶åŒ…ï¼Œå®ƒæœ‰ä¸€ä¸ªé¢„å®šä¹‰çš„ LDA æ¨¡å‹

```
**from** **gensim.test.utils** **import** common_texts
**from** **gensim.corpora.dictionary** **import** Dictionary

*# Create a corpus from a list of texts*
dictionary = Dictionary(common_texts)
corpus = [common_dictionary.doc2bow(text) **for** text **in** common_texts]

*# Train the model on the corpus.*
lda = LdaModel(corpus, num_topics=10)
```

# æ½œåœ¨è¯­ä¹‰åˆ†æ(LSA):

LSA æ˜¯ä¸€ä¸ªå‘ç°æ–‡æœ¬åŠå…¶ç›¸å…³æœ¯è¯­ä¹‹é—´å…³ç³»çš„è¿‡ç¨‹ã€‚å®ƒæ„å‘³ç€å…·æœ‰ç›¸ä¼¼å«ä¹‰çš„æœ¯è¯­ä¹Ÿå°†ä¸€èµ·ä½¿ç”¨(åˆ†å¸ƒå‡è®¾)ã€‚ä»è¯­æ–™åº“ä¸­æ„å»ºæœ¯è¯­-æ–‡æ¡£çŸ©é˜µ(è¡Œä»£è¡¨å•è¯ï¼Œåˆ—ä»£è¡¨æ¯ä¸ªç‰¹å®šæ–‡æ¡£)ã€‚è¯¥çŸ©é˜µå‡çº§ä¸º [tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) çŸ©é˜µï¼Œå…¶ä¸­æ¯ä¸ªå•å…ƒæ ¼ç¡®å®šå½“å‰æ–‡æ¡£ä¸­å•è¯çš„è¯é¢‘/è¯¥å•è¯åœ¨æ‰€æœ‰æ–‡æ¡£ä¸­çš„è¯é¢‘ã€‚

![](img/f6ec1bdf8ea2d52e47aa71d27e5f465e.png)

Pic é¸£è°¢:Chris Albonï¼Œ[https://towards data science . com/TF-term-frequency-IDF-inverse-document-frequency-from-scratch-in-python-6c2b 61 b 78558](https://towardsdatascience.com/tf-term-frequency-idf-inverse-document-frequency-from-scratch-in-python-6c2b61b78558)

ç›´è§‚åœ°è¯´ï¼Œå¦‚æœå•è¯åœ¨ç‰¹å®šæ–‡æ¡£ä¸­çš„å‡ºç°é¢‘ç‡é«˜äºæ‰€æœ‰å…¶ä»–æ–‡æ¡£çš„å‡ºç°é¢‘ç‡ï¼Œåˆ™è¯¥å•è¯å¯ä»¥å”¯ä¸€åœ°åœ¨ç‰¹å®šä¸»é¢˜è¯†åˆ«ä¸­åŠ æƒã€‚

![](img/e39cb0e41c5f4eb3d8a2087af2258d67.png)

å¥‡å¼‚å€¼åˆ†è§£ï¼Œ[https://read01.com/gRK7gJ2.html#.X_17g9gzZEY](https://read01.com/gRK7gJ2.html#.X_17g9gzZEY)

ä½œä¸ºé”¦ä¸Šæ·»èŠ±ï¼Œæˆ‘ä»¬ä½¿ç”¨[å¥‡å¼‚å€¼åˆ†è§£](https://en.wikipedia.org/wiki/Singular_value_decomposition) (SVD)æ¥æœ€å°åŒ–çŸ©é˜µçš„ç»´æ•°ï¼ŒåŒæ—¶ä¿æŒåˆ—é—´çš„ç›¸ä¼¼æ€§ã€‚

ç„¶åï¼Œé€šè¿‡å–å®ƒä»¬ä¹‹é—´è§’åº¦çš„ä½™å¼¦(æˆ–å®ƒä»¬çš„å½’ä¸€åŒ–å€¼ä¹‹é—´çš„ç‚¹ç§¯)æ¥æ¯”è¾ƒæ–‡æ¡£å¯¹ã€‚å½“å€¼æ¥è¿‘ 1 æ—¶ï¼Œæ–‡æ¡£éå¸¸ç›¸ä¼¼ï¼›å€¼æ¥è¿‘ 0ï¼Œæ–‡æ¡£éå¸¸ä¸åŒã€‚

## ä»£ç ç‰‡æ®µ:

ä½ å¯ä»¥ä½¿ç”¨ [genism](https://radimrehurek.com/gensim/models/ldamodel.html) è½¯ä»¶åŒ…ï¼Œå®ƒæœ‰ä¸€ä¸ªé¢„å®šä¹‰çš„ LSA æ¨¡å‹ï¼Œä¹Ÿå°±æ˜¯ LSI(æˆ‘æŒ‡çš„æ˜¯ç´¢å¼•)

```
**from** **gensim.test.utils** **import** common_dictionary, common_corpus
**from** **gensim.models** **import** LsiModel

model = LsiModel(common_corpus, id2word=common_dictionary)
vectorized_corpus = model[common_corpus] 
```

# æ¦‚ç‡æ½œåœ¨è¯­ä¹‰åˆ†æ(PLSA):

PLSA æ˜¯ LSA çš„è¿›æ­¥ã€‚è¿™æ˜¯ä¸€ç§ç”¨äºåŒæ¨¡å¼å’Œå…±ç°æ•°æ®åˆ†æçš„[ç»Ÿè®¡æŠ€æœ¯](https://en.wikipedia.org/wiki/Statistical_technique)ã€‚å®ƒè¯•å›¾é€šè¿‡ç”¨æ¦‚ç‡æ¨¡å‹ä»£æ›¿ LSA ä¸­çš„å¥‡å¼‚å€¼åˆ†è§£æ¥å‘ç°æ½œåœ¨ä¸»é¢˜ä»¥å¡«å……æœ¯è¯­-æ–‡æ¡£çŸ©é˜µã€‚

è€ƒè™‘åˆ°å•è¯å’Œæ–‡æ¡£ä¹‹é—´å…±ç°çš„å¯èƒ½æ€§ï¼ŒPLS å°†è¿™äº›å•è¯å’Œæ–‡æ¡£å…±ç°çš„æ¦‚ç‡å»ºæ¨¡ä¸ºæ¡ä»¶ç‹¬ç«‹çš„[å¤šé¡¹å¼åˆ†å¸ƒ](https://en.wikipedia.org/wiki/Multinomial_distribution)çš„æ··åˆ:

![](img/cec75b4c6da416dccb69ca4f4c6563d9.png)

[https://en . Wikipedia . org/wiki/probability _ latent _ semantic _ analysis](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis)

![](img/396516d6bf283c0936618580a1b08ca1.png)

[https://en . Wikipedia . org/wiki/probability _ latent _ semantic _ analysis](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis)

ä»£è¡¨ PLSA æ¨¡å‹çš„å›¾ç‰ˆç¬¦å·ã€‚(â€œä¸å¯¹ç§°â€ææ³•)ã€‚d æ˜¯æ–‡æ¡£å‘é‡ï¼Œz æ˜¯å•è¯çš„ä¸»é¢˜ï¼Œw æ˜¯ä»å•è¯çš„ä¸»é¢˜åˆ†å¸ƒä¸­æŠ½å–çš„å•è¯ï¼Œc æ˜¯ä»å•è¯çš„ä¸»é¢˜åˆ†å¸ƒä¸­æŠ½å–çš„å•è¯ã€‚å˜é‡ d å’Œ W æ˜¯å¯æµ‹çš„ï¼Œä½†æ½œå˜é‡çš„ä¸»è¯­æ˜¯ c/zï¼Œè¿™ä¸‰ä¸ªå€¼å°±æ˜¯æˆ‘ä»¬æ¨¡å‹ä¸­çš„å‚æ•°ã€‚P(D)ç›´æ¥ä»æˆ‘ä»¬çš„æ•°æ®åº“ä¸­è§£æã€‚å¯ä»¥ä½¿ç”¨[æœŸæœ›æœ€å¤§åŒ–](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm)ç®—æ³•(EM)æ¥è®­ç»ƒå‚æ•° P(Z|D)å’Œ P(W|Z)ã€‚EM æ˜¯ä¸€ç§ä¸ºä¾èµ–äºæ½œåœ¨å˜é‡çš„æ¨¡å‹å¯»æ‰¾æœ€å¯èƒ½çš„å‚æ•°ä¼°è®¡çš„æ–¹æ³•ã€‚EM æœ‰ä¸¤ä¸ªæ­¥éª¤:(I)æœŸæœ›(E)æ­¥éª¤ï¼Œè®¡ç®—æ½œåœ¨å˜é‡çš„åéªŒæ¦‚ç‡ï¼Œ(ii)æœ€å¤§åŒ–(M)æ­¥éª¤ï¼Œæ›´æ–°å‚æ•°ã€‚

ğŸ˜‚æ²¡é—®é¢˜ï¼Œæˆ‘å¹¶æ²¡æœ‰é’»ç ”å¤ªå¤šçš„æ•°å­¦ï¼Œç°åœ¨è¯·æŸ¥çœ‹æ•°å­¦éƒ¨åˆ†çš„ç»´åŸºé“¾æ¥ğŸ˜‚

## ä»£ç ç‰‡æ®µ:

æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨ PyPI [plsa](https://pypi.org/project/plsa/) åŒ…ä¸­çš„ plsa æ¨¡å‹

```
**from** **plsa** **import** Corpus, Pipeline, Visualize
**from** **plsa.pipeline** **import** DEFAULT_PIPELINE
**from** **plsa.algorithms** **import** PLSAcorpus = Corpus.from_csv(csv_file, pipeline)
n_topics = 5plsa = PLSA(corpus, n_topics, **True**)
result = plsa.fit()
```

# éè´ŸçŸ©é˜µåˆ†è§£(NMF):

NMF å±äºæ— ç›‘ç£æœºå™¨å­¦ä¹ çš„èŒƒç•´ã€‚NMF æ˜¯ä¸€ä¸ªçº¿æ€§ä»£æ•°ç®—æ³•å®¶æ—ï¼Œç”¨äºå®šä¹‰ç»“æœä¸­çš„æ½œåœ¨ç»“æ„ã€‚NMF çš„å·¥ä½œåŸç†æ˜¯å°†é«˜ç»´æ•°ç»„åˆ†è§£æˆä½ç»´æ•°ç»„ã€‚åˆ†è§£æˆä¸¤ä¸ªçŸ©é˜µ W å’Œ Hï¼Œå‰ææ˜¯è¿™ä¸‰ä¸ªçŸ©é˜µéƒ½ç”±éè´Ÿå…ƒç´ ç»„æˆã€‚è¿™é‡Œ V æŒ‡çš„æ˜¯æœ¯è¯­æ–‡æ¡£çŸ©é˜µï¼Œé€šå¸¸æ˜¯ TF-IDF æ ‡å‡†åŒ–ã€‚ä½ å·²ç»åœ¨ä¸Šé¢çœ‹åˆ°äº†ã€‚w è¡¨ç¤ºæ‰¾åˆ°çš„ä¸»é¢˜ï¼ŒH è¡¨ç¤ºè¯¥ä¸»é¢˜çš„ç³»æ•°ã€‚æ¢å¥è¯è¯´ï¼ŒV æŒ‰è¯ä»£è¡¨æ–‡ç« (åŸå§‹æ–‡æ¡£)ï¼ŒH æŒ‰ä¸»é¢˜ä»£è¡¨æ–‡ç« ï¼ŒW æŒ‰è¯ä»£è¡¨ä¸»é¢˜ã€‚

![](img/f3ded9111bba53a746bf94300949f4aa.png)

[https://www . researchgate . net/publication/312157184 _ Crime _ Topic _ Modeling/figuresï¼Ÿlo=1](https://www.researchgate.net/publication/312157184_Crime_Topic_Modeling/figures?lo=1)

## ä»£ç ç‰‡æ®µ:

å‚è€ƒä»£ç ç¤ºä¾‹é“¾æ¥[https://sci kit-learn . org/stable/auto _ examples/applications/plot _ topics _ extraction _ with _ NMF _ LDA . html](https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html)

```
**import** **numpy** **as** **np**
X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])**from** **sklearn.decomposition** **import** NMFmodel = NMF(n_components=2, init='random', random_state=0)
W = model.fit_transform(X)
H = model.components_
```

# lda2vec:

è¿™ä¸ªæ¨¡å‹å¯ä»¥è¢«è®¤ä¸ºæ˜¯ word2vec æ¨¡å‹çš„æ‰©å±•ï¼ŒåŒ…å«äº†æˆ‘ä»¬ä¸Šé¢è®¨è®ºçš„ LDA ç®—æ³•[å‡­ç›´è§‰ï¼Œä½ å·²ç»çŸ¥é“ä»€ä¹ˆæ˜¯ word2vecã€‚(æ³¨:å¦‚æœä½ ä¸çŸ¥é“æˆ‘åœ¨è¯´ä»€ä¹ˆï¼Œå‚è€ƒè¿™ä¸ª[word2veclick](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa))æˆ‘ä¸ä¼šè¿‡å¤šè®¨è®º word 2 vec éƒ¨åˆ†ã€‚Word2vec æ•è·äº†æ¸…æ™°çš„è¯ä¸è¯ä¹‹é—´çš„å…³ç³»ï¼Œä½†æ˜¯äº§ç”Ÿçš„å‘é‡åŸºæœ¬ä¸Šæ˜¯ä¸å¯è§£é‡Šçš„ï¼Œå¹¶ä¸”ä¸ä»£è¡¨è®°å½•ã€‚å¦ä¸€æ–¹é¢ï¼ŒLDA æ˜¯éå¸¸å®¹æ˜“ç†è§£çš„ï¼Œä½†æ˜¯ä¸æ¨¡æ‹Ÿæœ¬åœ°å•è¯å…³ç³»ï¼Œæ¯”å¦‚ word2vecã€‚Lda2vec æ˜¯ä½œä¸ºä¸€ä¸ªæ¨¡å‹æ„å»ºçš„ï¼Œå®ƒåˆ›å»ºå•è¯å’Œæ–‡æ¡£ä¸»é¢˜ï¼Œä½¿å®ƒä»¬å¯è§£é‡Šï¼Œåˆ›å»ºä¸»é¢˜ï¼Œå¹¶ä½¿å®ƒä»¬æˆä¸ºå®¢æˆ·æœºã€æ—¶é—´å’Œæ–‡æ¡£çš„ç›‘ç£ä¸»é¢˜ã€‚

![](img/74dc60701eace4b20486aa2816040afe.png)

è·³æ ¼æ¨¡å‹ï¼Œä½œè€…å›¾ç‰‡ï¼Œ

LDA2Vec æ˜¯ skip-gram word2vec ç®—æ³•çš„ä¿®æ”¹ç‰ˆæœ¬ã€‚è¯¥æ¨¡å‹è¢«å­¦ä¹ ä»¥åŸºäºåŸå§‹è·³æ ¼è¿‡ç¨‹ä¸­çš„ä¸­æ¢è¯æ¥é¢„æµ‹èƒŒæ™¯è¯ã€‚åœ¨ lda2vec ä¸­ï¼Œä¸ºäº†è·å¾—èƒŒæ™¯å‘é‡ï¼Œæ’å…¥äº†ä¸­æ¢å•è¯å‘é‡å’Œæ–‡æ¡£å‘é‡ã€‚ä¸ºäº†é¢„æµ‹ä¸Šä¸‹æ–‡è¡¨è¾¾å¼ï¼Œç„¶åä½¿ç”¨è¿™ä¸ªä¸Šä¸‹æ–‡å‘é‡ã€‚

åƒçº¿æ€§åˆ¤åˆ«åˆ†ææ¨¡å‹ä¸€æ ·ï¼Œå°†æ–‡æ¡£å‘é‡ã€å‚è€ƒ [Gidi Shperber](/@gidishperber?source=post_page-----db3e8c0cce5e--------------------------------) çš„ [doc2vec](/@amarbudhiraja/understanding-document-embeddings-of-doc2vec-bfe7237a26da) åˆ†è§£ä¸ºæ–‡æ¡£æƒé‡å‘é‡å’Œä¸»é¢˜çŸ©é˜µã€‚æ–‡æ¡£æƒé‡å‘é‡æŒ‡ç¤ºè®¨è®ºäº†å¤šå°‘ä¸åŒçš„ä¸»é¢˜ï¼Œè€Œä¸»é¢˜çŸ©é˜µä»¥åˆ†ç±»çš„æ–¹å¼å¯¹ä¸»é¢˜è¿›è¡Œåˆ†ç±»ã€‚å› æ­¤ï¼Œé€šè¿‡ç»„åˆæ–‡æ¡£å‡ºç°çš„ä¸åŒä¸Šä¸‹æ–‡æ¥æ„å»ºä¸Šä¸‹æ–‡å‘é‡ã€‚

ç®€è¨€ä¹‹

![](img/8017821bebef9c920244a87f3b3f3fc3.png)

ã€https://github.com/cemoody/lda2vec 

Word2vec è¯•å›¾å¯¹è¯ä¸è¯ä¹‹é—´çš„å…³ç³»è¿›è¡Œå»ºæ¨¡ã€‚

![](img/9f30683262450d12074570e53014c36f.png)

[https://github.com/cemoody/lda2vec](https://github.com/cemoody/lda2vec)

LDA å¯¹æ–‡æ¡£åˆ°å•è¯çš„å…³ç³»è¿›è¡Œå»ºæ¨¡ã€‚

![](img/35c5bb26d68c13e423d8e87fe136bb23.png)

[https://github.com/cemoody/lda2vec](https://github.com/cemoody/lda2vec)

LDA åœ¨æ¯ä¸ªæ–‡æ¡£ä¸Šåˆ›å»ºä¸»é¢˜ã€‚

![](img/b9d38c25462aacbca05b6a199dba67c0.png)

[https://github.com/cemoody/lda2vec](https://github.com/cemoody/lda2vec)

lda2vec ä¸ä»…åˆ›å»ºæ–‡æ¡£ä¸»é¢˜ï¼Œè¿˜åˆ›å»ºåŒºåŸŸä¸»é¢˜ã€‚

![](img/2c891d30c1a60175890bfef231242a59.png)

[https://github.com/cemoody/lda2vec](https://github.com/cemoody/lda2vec)

lda2vec è¿˜åœ¨å®¢æˆ·æœºä¸Šåˆ›å»ºä¸»é¢˜

![](img/e1fabbac1ed67761ddd4d5ac3df943fd.png)

[https://github.com/cemoody/lda2vec](https://github.com/cemoody/lda2vec)

åœ¨ lda2vec ä¸­ï¼Œä¸»é¢˜å¯ä»¥è¢«â€œç›‘ç£â€,å¹¶è¢«è¿«é¢„æµ‹å¦ä¸€ä¸ªç›®æ ‡ã€‚

GitHub ä»£ç å’Œè§£é‡Šçš„ç¡®è®¤å’Œå¼•ç”¨[https://github.com/cemoody/lda2vec](https://github.com/cemoody/lda2vec)ã€‚ä½ å¯èƒ½ä¼šåƒæˆ‘ä¸€æ ·å–œæ¬¢å®ƒã€‚

å‚è€ƒ lda2vec å®˜æ–¹æ–‡ä»¶[https://lda2vec.readthedocs.io/en/latest/?badge=latest](https://lda2vec.readthedocs.io/en/latest/?badge=latest)

```
model = LDA2Vec(n_words, max_length, n_hidden, counts)
model.add_component(n_docs, n_topics, name='document id')
model.fit(clean, components=[doc_ids])
topics = model.prepare_topics('document_id', vocab)
prepared = pyLDAvis.prepare(topics)
pyLDAvis.display(prepared)
```

# æŒ‡æ ‡:

æ—¢ç„¶æˆ‘ä»¬å·²ç»å­¦ä¹ äº†ä¸»é¢˜å»ºæ¨¡çš„å„ç§æŠ€æœ¯ã€‚æˆ‘ä»¬ä¹Ÿéœ€è¦ä¸€äº›ä¾æ®æ¥è¡¡é‡ä»–ä»¬çš„è¡¨ç°ã€‚è™½ç„¶æˆ‘ä»¬å¾ˆå°‘æœ‰æ–¹æ³•æ¥è¡¡é‡ä¸»é¢˜å»ºæ¨¡çš„æ€§èƒ½ï¼Œå¦‚ç›®æµ‹æ³•ï¼Œå†…åœ¨è¯„ä»·æŒ‡æ ‡ï¼Œäººå·¥åˆ¤æ–­ï¼Œå¤–åœ¨è¯„ä»·æŒ‡æ ‡ã€‚æˆ‘æƒ³é›†ä¸­è®¨è®ºä¸¤ç§æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯æŠ½è±¡å±‚æ¬¡ä¸Šçš„å›°æƒ‘å’Œä¸»é¢˜è¿è´¯æ€§ï¼Œä¸è¦æ·±å…¥æ¢è®¨ã€‚

## å›°æƒ‘:

å›°æƒ‘æ˜¯ç”¨æ¥è¡¡é‡ä¸€ä¸ªè¯çš„æ„æ€çš„è®¡ç®—æ–¹æ³•ä¹‹ä¸€ã€‚å®ƒæ•æ‰äº†è¿™ä¸ªæ¨¡å‹å¯¹å®ƒä»¥å‰æ²¡æœ‰è§è¿‡çš„æ–°æ•°æ®æœ‰å¤šæƒŠè®¶ï¼Œå¹¶è¢«è®¡ç®—ä¸ºæ‹’ä¸æ¥å—çš„æµ‹è¯•é›†çš„å¯èƒ½æ€§ã€‚

å›°æƒ‘åº¦é‡ç”¨äºè¡¡é‡æ–°çš„ã€çœ‹ä¸è§çš„æ•°æ®å¦‚ä½•å½±å“å…ˆå‰å»ºç«‹çš„æ¨¡å‹çš„æ¦‚ç‡ã€‚ä¸¾ä¸ªä¾‹å­ï¼Œè¿™ä¸ªæ¨¡å‹ä¸æ•°æ®çš„å»åˆç¨‹åº¦å¦‚ä½•ï¼Ÿ

ç„¶è€Œï¼Œæœ€è¿‘çš„ç ”ç©¶å‘ç°ï¼Œäººç±»çš„åˆ¤æ–­å¹¶ä¸æ€»æ˜¯ä¸é¢„æµ‹çš„å¯èƒ½æ€§å¯†åˆ‡ç›¸å…³ã€‚ä¸€ä¸ªä¾‹å­æ˜¯ä¼˜åŒ–å¹¶ä¸æ€»æ˜¯äº§ç”Ÿäººç±»å¯ä»¥è§£é‡Šçš„ä¸»é¢˜ã€‚

æœ‰äº†è¯é¢˜è¿è´¯ï¼Œæˆ‘ä»¬å°±æœ‰å¯èƒ½æ¨¡æ‹Ÿäººç±»çš„å†³ç­–ï¼Œè¿™å°±å…‹æœäº†å›°æƒ‘çš„å±€é™æ€§ï¼Œä»è€Œäº§ç”Ÿäº†è¯é¢˜è¿è´¯ç†è®ºã€‚

## è¯é¢˜è¿è´¯æ€§:

ä¸»é¢˜è¿è´¯çš„æ¡†æ¶åŒ…å«äº†ä»ä¸»é¢˜è¿è´¯å’Œæ–‡ç« æ•´ä½“è¿è´¯ä¸­å¾—å‡ºçš„å„ç§è€ƒè™‘ã€‚å®ƒæµ‹è¯•æ ·æœ¬æ®µè½ä¸­çš„æœ¯è¯­åœ¨ä¸Šä¸‹æ–‡ä¸­çš„ä¸€è‡´ç¨‹åº¦ã€‚åº¦é‡å…è®¸æˆ‘ä»¬åŒºåˆ†è¯­ä¹‰ä¸Šå¯è§£é‡Šçš„ä¸»é¢˜å’Œç»Ÿè®¡æ¨æ–­çš„å¯¹è±¡ã€‚å®ƒå¯ä»¥è¢«æè¿°ä¸ºä¸€èˆ¬çš„åˆ©ç”¨æˆ–è€…æˆå¯¹çš„å•è¯ç›¸ä¼¼æ€§åˆ†æ•°çš„æ ‡å‡†ã€‚ä¸€ä¸ªæˆåŠŸçš„æ¨¡å‹èƒ½å¤Ÿäº§ç”Ÿè¿è´¯çš„ææ–™ã€‚è¯·é˜…è¯»ä¸‹é¢çš„å•è¯ï¼Œä»¥è·å¾—å¯¹è¿™äº›ä¸»é¢˜çš„æ›´è¯¦ç»†çš„æè¿°ã€‚

# è‡´è°¢å’Œå‚è€ƒ:

[](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm) [## æœŸæœ›å€¼æœ€å¤§åŒ–ç®—æ³•

### åœ¨ç»Ÿè®¡å­¦ä¸­ï¼ŒæœŸæœ›æœ€å¤§åŒ–(EM)ç®—æ³•æ˜¯ä¸€ç§å¯»æ‰¾(å±€éƒ¨)æœ€å¤§ä¼¼ç„¶æˆ–â€¦

en.wikipedia.org](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm) [](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis) [## æ¦‚ç‡æ½œåœ¨è¯­ä¹‰åˆ†æ

### æ¦‚ç‡æ½œåœ¨è¯­ä¹‰åˆ†æ(PLSA)ï¼Œä¹Ÿç§°ä¸ºæ¦‚ç‡æ½œåœ¨è¯­ä¹‰ç´¢å¼•(PLSIï¼Œå°¤å…¶æ˜¯â€¦

en.wikipedia.org](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis) 

[https://pypi.org/project/plsa/](https://pypi.org/project/plsa/)https://arxiv.org/abs/1301.6705T2

[](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) [## sk learn . decomposition . NMF-sci kit-learn 0 . 24 . 0 æ–‡æ¡£

### éè´ŸçŸ©é˜µåˆ†è§£(NMF)ã€‚æ‰¾å‡ºä¸¤ä¸ªéè´ŸçŸ©é˜µ(Wï¼ŒH ),å®ƒä»¬çš„ä¹˜ç§¯é€¼è¿‘éè´ŸçŸ©é˜µçš„ä¹˜ç§¯

scikit-learn.org](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html) [](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization#:~:text=Non%2Dnegative%20matrix%20factorization%20%28NMF,matrices%20have%20no%20negative%20elements.) [## éè´ŸçŸ©é˜µåˆ†è§£

### éè´ŸçŸ©é˜µåˆ†è§£(NMF æˆ– NNMF)ï¼Œä¹Ÿéè´ŸçŸ©é˜µè¿‘ä¼¼æ˜¯ä¸€ç»„ç®—æ³•åœ¨â€¦

en.wikipedia.org](https://en.wikipedia.org/wiki/Non-negative_matrix_factorization#:~:text=Non%2Dnegative%20matrix%20factorization%20%28NMF,matrices%20have%20no%20negative%20elements.) [](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0) [## è¯„ä¼°ä¸»é¢˜æ¨¡å‹:æ½œåœ¨ç‹„åˆ©å…‹é›·åˆ†é…(LDA)

### æ„å»ºå¯è§£é‡Šä¸»é¢˜æ¨¡å‹çš„åˆ†æ­¥æŒ‡å—

towardsdatascience.com](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0) [](http://www.aclweb.org/anthology/N10-1012) [## è¯é¢˜è¿è´¯æ€§çš„è‡ªåŠ¨è¯„ä¼°

### æˆ´ç»´Â·çº½æ›¼ï¼Œåˆ˜æµæ±‰ï¼Œå¡å°”Â·æ ¼é‡Œæ³½ï¼Œè’‚è«è¥¿Â·é²å¾·æ¸©ã€‚äººç±»è¯­è¨€æŠ€æœ¯:2010 å¹´å¹´åº¦ä¼šè®®â€¦

www.aclweb.org](http://www.aclweb.org/anthology/N10-1012) [](https://github.com/cemoody/lda2vec) [## cemoody/lda2vec

### lda2vec æ¨¡å‹è¯•å›¾å°† word2vec å’Œ lda çš„æœ€ä½³éƒ¨åˆ†æ··åˆåˆ°ä¸€ä¸ªæ¡†æ¶ä¸­ã€‚word2vec æ•æ‰å¼ºå¤§çš„â€¦

github.com](https://github.com/cemoody/lda2vec) [](https://towardsdatascience.com/lda2vec-word-embeddings-in-topic-models-4ee3fc4b2843) [## LDA2vec:ä¸»é¢˜æ¨¡å‹ä¸­çš„è¯åµŒå…¥

### äº†è§£æœ‰å…³ LDA2vec çš„æ›´å¤šä¿¡æ¯ï¼ŒLDA 2 vec æ˜¯ä¸€ç§ä¸ç‹„åˆ©å…‹é›·åˆ†å¸ƒæ½œåœ¨å‘é‡è”åˆå­¦ä¹ å¯†é›†è¯å‘é‡çš„æ¨¡å‹â€¦

towardsdatascience.com](https://towardsdatascience.com/lda2vec-word-embeddings-in-topic-models-4ee3fc4b2843) [](https://towardsdatascience.com/tf-term-frequency-idf-inverse-document-frequency-from-scratch-in-python-6c2b61b78558) [## python ä¸­ä»å¤´å¼€å§‹çš„ TF(è¯é¢‘)-IDF(é€†æ–‡æ¡£é¢‘)ã€‚

### ä»å¤´å¼€å§‹åˆ›å»º TF-IDF æ¨¡å‹

towardsdatascience.com](https://towardsdatascience.com/tf-term-frequency-idf-inverse-document-frequency-from-scratch-in-python-6c2b61b78558)