<html>
<head>
<title>Regularization path using Lasso regression.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用套索回归的正则化路径。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/regularization-path-using-lasso-regression-c450eea9321e?source=collection_archive---------4-----------------------#2021-07-30">https://medium.com/analytics-vidhya/regularization-path-using-lasso-regression-c450eea9321e?source=collection_archive---------4-----------------------#2021-07-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="b623" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">什么是正规化道路，为什么要走正规化道路！</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/86bff279ad936819000163093d3c9061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*ju4vmfZNp0lJxVJ5.jpg"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">使用套索回归的通往更美好世界之路</figcaption></figure><h1 id="b066" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">首先…什么是线性回归？</h1><p id="96e5" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">线性回归是一种表示目标和解释变量之间的<em class="jc">关系</em>的线性方法。一个<em class="jc">预测</em>可以这样计算。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ks"><img src="../Images/d8fa8000f20b0c521960caf261fa751d.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/0*3ZGfSkRJ7ajDXzYI"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">其中，ŷ是预测值，xᵢ是变量，θᵢ是系数。</figcaption></figure><p id="feb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是变量的<strong class="ig hi">加权和</strong>加上<strong class="ig hi">截距</strong>。好的，但是我们如何获得θ变量呢？为了找到最佳的θ，我们需要一个最小化函数。你好<strong class="ig hi"> MSE </strong> ( <em class="jc">均方差</em>)！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kt"><img src="../Images/aa2b29b174f869d069a50ebefa9fd2e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:566/0*sJdftYkhsnkipPal"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">其中，Yᵢ是线性回归的第一个实际值，ŷᵢ是第一个预测值。</figcaption></figure><p id="c072" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">MSE是误差平方的平均值，它是线性回归中最常用的<em class="jc">成本函数</em>。</p><h1 id="9c54" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">从线性回归到套索回归</strong></h1><p id="0f4a" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">一个套索回归(<em class="jc">最小绝对收缩和选择算子</em>)是一个<strong class="ig hi">正则化的</strong> <strong class="ig hi">线性回归。</strong>线性回归的<em class="jc">成本函数(MSE) </em>中增加了一个正则化项。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ku"><img src="../Images/12d76272396a7c8f47f244470f2ee38a.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/1*4yK4gvB8o84lcmddkUMoYA.gif"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">套索回归的成本函数</figcaption></figure><p id="c09e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与线性回归一样，θ = (θ₁,…,θₙ)是特征的<strong class="ig hi">权重向量</strong>，而<strong class="ig hi"> MSE </strong> ( <em class="jc">均方误差</em>)仍然是误差平方的平均值。但这最后一个术语是什么？是正则项！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kv"><img src="../Images/e170524a635b47da06c7ea0efd80b044.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/0*9JOEZCGqay5raxRX"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">Lasso回归的正则项</figcaption></figure><p id="6eae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过添加这个正则项，对应于权重的<em class="jc"> L1范数</em>，它<strong class="ig hi">将迫使</strong> <strong class="ig hi">不太重要的特征为零</strong>。换句话说套索回归是在做一个<strong class="ig hi">特征选择</strong>，<strong class="ig hi">越高</strong>阿尔法的值越少<strong class="ig hi">特征被选择。</strong></p><h1 id="03ae" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">让我们创造自己的正规化道路！</h1><p id="5f54" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">现在我们知道什么是套索回归，我们可以创建我们的正则化路径，<strong class="ig hi">正则化路径</strong>是所有系数值对阿尔法值的绘图。这是观察套索回归<strong class="ig hi">行为</strong>的最佳方式。</p><p id="2ff8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们需要从<em class="jc"> sklearn库导入一些库以及<em class="jc">波士顿房价</em>数据集。</em></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kw kx l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ky"><img src="../Images/c84793adc30e6ff0e8b9370daab8aa39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/0*bcGq9MtyHjDr2QUe.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">波士顿数据集的负责人</figcaption></figure><p id="3b3f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们已经导入了库和数据，我们可以<em class="jc">创建我们的正则化路径。</em></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="9b98" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后我们<em class="jc">标准化</em>我们的数据，并绘制我们的正则化路径！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es kz"><img src="../Images/2f2834359845bb857201b3c639fa17bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*htzmbtHN-cOKChuH.png"/></div></div></figure><p id="9ca5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">太神奇了！基于阿尔法值，拉索选择了一些功能！</p><p id="7d44" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我们可以看到的，当alpha值<strong class="ig hi">太高</strong>时，Lasso回归无法将权重拟合到特征，这就是为什么我们有这样的<strong class="ig hi">低分</strong>，此外<strong class="ig hi">太低</strong> alpha是没有用的，成本函数已经<strong class="ig hi">收敛到下限。</strong></p><h1 id="c455" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">性能和可解释性之间的权衡</h1><p id="246f" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">如果我们看一看我们的正则化路径，我们可以看到，当alpha为0.1左右时，套索选择了<strong class="ig hi"> 4个附加特征</strong>来对<strong class="ig hi">的得分进行轻微的改进</strong>。</p><p id="7d0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些特性是真正的改进吗？不尽然，它们可以被认为是<em class="jc">噪音</em>，它们会因为分数的<strong class="ig hi">轻微增加</strong>而大幅<strong class="ig hi">降低可解释性</strong>。</p><p id="0507" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些特征可能是<strong class="ig hi">过度拟合</strong>的结果，它们相互抵消以给出稍微好一点的分数。我们绝对不希望这样。</p><h1 id="5caf" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">极限值</strong></h1><p id="c50b" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">当特征数的<strong class="ig hi">比变量数</strong>的<strong class="ig hi">大<strong class="ig hi">时，或者当特征数<strong class="ig hi">强相关</strong>时，套索回归可能<em class="jc">不可预测</em>！<em class="jc">不要跳过特征工程！</em></strong></strong></p><h1 id="2140" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论</h1><p id="588d" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">规则化路径是一个神奇的工具，可以看到我们的套索回归的<strong class="ig hi">行为</strong>，它让我们了解<strong class="ig hi">特征的重要性</strong>以及我们可以预期的分数！但是任何事情都是有代价的，拟合大量的回归可能在计算上<em class="jc"/><em class="jc">很昂贵。</em></p><h1 id="f328" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">奖金</h1><p id="caf1" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">对于<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html" rel="noopener ugc nofollow" target="_blank">脊</a>或<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html" rel="noopener ugc nofollow" target="_blank">弹力网</a>的回归也可以完全相同；)</p><p id="8dfe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你不想像我一样，让自己的<em class="jc">变得惊艳而互动</em>正规化；)可以使用sklearn库中的<a class="ae le" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.lasso_path.html" rel="noopener ugc nofollow" target="_blank">sk learn . linear _ model . lasso _ path</a>函数。</p><h1 id="025f" class="jp jq hh bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">感谢阅读！</h1><p id="57a7" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">如果你觉得有趣，请给我点个赞或通过LinkedIn联系我！</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lf"><img src="../Images/3be8cd5a623aa9a32349020a5916b364.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_Vnd3U9nvMlhpSU7.jpg"/></div></div></figure></div></div>    
</body>
</html>