<html>
<head>
<title>Apache Spark Structured Streaming with Pyspark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Pyspark的Apache Spark结构化流</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/apache-spark-structured-streaming-with-pyspark-b4a054a7947d?source=collection_archive---------0-----------------------#2021-01-11">https://medium.com/analytics-vidhya/apache-spark-structured-streaming-with-pyspark-b4a054a7947d?source=collection_archive---------0-----------------------#2021-01-11</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="8be6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上一篇文章中，我们讨论了Apache Spark离散化流(d Streams ),这是Spark流的一个基本概念。在本文中，我们将研究Spark流的结构化部分。</p><p id="fffa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结构化流构建在Apache Spark的SparkSQL引擎之上，该引擎将在继续接收数据时处理流的运行。就像Spark的其他引擎一样，它具有可扩展性和容错性。结构化流通过流特性增强了Spark DataFrame APIs。</p><p id="04c3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结构化流还确保在检查点和缓存选项的帮助下尽快恢复任何故障。总之，结构化流是一种可扩展的、容错的和近乎即时的操作。</p><p id="fc27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在是时候用第一个例子来弄脏我们的手了😉</p><p id="3ce2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个例子，我们将使用csv文件作为我们的流的输入数据。我将简单地在我们的目录中上传5个csv文件。这些csv文件包含一些关于随机生成的人的数据(每个文件10行)和一些关于他们的信息，如他们的年龄、职业、城市和工资。下面你可以看到一个输入数据的例子；</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/674af49b6fbebb856572fff6c233d5d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*sYQq5dS7S-nhXwe6esGAVw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">Csv数据示例</figcaption></figure><p id="36f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们将从Python导入所需的Pyspark库，并启动SparkSession。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jp"><img src="../Images/7a2858151512fad26af8316b54e92587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zOG2WLZIMADpoNR-J2gUVA.png"/></div></div></figure><p id="7b90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请记住，结构化流处理总是需要为流中的数据指定一个模式。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es ju"><img src="../Images/3259aa079fc208794e5cc2f476813d51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uTvOMPQl1yYOnyaJCQ_ayg.png"/></div></div></figure><p id="6acf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用“readStream”将数据加载到流数据帧中。我们还可以用“isStreaming”方法检查我们的流状态。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jv"><img src="../Images/b2fb7fa3f02ff03cc0f51ca3209036db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v4oRn-3_gt-C6W8gVauaqQ.png"/></div></div></figure><p id="9e35" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">是啊！它正在工作…现在我们已经创建了一个流数据帧。现在是我们演示的棘手部分，🧐，当我们在做一个例子时，我们的csv数据不是实时创建的，所以我们必须模拟流条件。我们将把每个csv文件一次一个地复制到我们在上面的代码中的“readStream”中指定的路径中，而不是在数据进来时进行流式处理。这就是为什么我们还将“maxFilesPerTrigger”选项设置为1，这告诉我们一次只能传输一个csv文件。</p><p id="40c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看树格式的DataFrame的模式</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jw"><img src="../Images/04d8c4d008465d17195c9ebbbce09065.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*61_FzvVsM8rg1dy45pHITA.png"/></div></div></figure><p id="3058" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将应用一些转换，这些转换将向我们显示每个职业的人数，以及每个新文件都会更新的数据框架中降序排列的职业平均工资。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es jx"><img src="../Images/057352e0ff2972620ef5d9896dfb0a92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b087idCK_cAiTEwUOLkUWw.png"/></div></div></figure><p id="f0da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，除了最后一点之外，我们已经为流式传输做好了准备；我们需要为到目的地的流指定一个“format()”，并为确定要写入流接收器的数据指定一个“outputMode()”。</p><p id="e575" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最常用的格式是控制台，卡夫卡，拼花和内存。我将使用控制台选项作为格式，这样我们就可以从终端跟踪我们的流结果。</p><p id="f7b7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于outputMode()方法，我们有三个选项。这些是；</p><ul class=""><li id="3e6d" class="jy jz hi ih b ii ij im in iq ka iu kb iy kc jc kd ke kf kg bi translated">append:只有新行会被写入接收器。</li><li id="1edb" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">complete:每次有更新时，所有行都将被写入接收器。</li><li id="6e4b" class="jy jz hi ih b ii kh im ki iq kj iu kk iy kl jc kd ke kf kg bi translated">update:每次有更新时，只有更新的行将被写入接收器。</li></ul><p id="b552" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我还将使用“完整”选项，因为我们的数据框架中有一个聚合。</p><p id="6dd6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们可以用“start()”方法开始流式传输。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es km"><img src="../Images/fbeab6da5535fe488f9892575beccd06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yJ-2IvT2ANkOwGDaqxOF0w.png"/></div></div></figure><p id="3be8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在是时候一次加载一个csv文件了。记住，我们有5个不同的csv文件，每个文件包含10行数据。</p><p id="dbc8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们来看看终端加载每个文件后的结果(批次0到4)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kn"><img src="../Images/a424eaed57d074aab533b61242c1e207.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*PpYJG6rbDCS1zgngW5Cgvw.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">在第一个csv文件之后</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ko"><img src="../Images/655c432c1103d4591dbb8a6cd90a92db.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*KjJkZjrW551GmIQpCHnFXg.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">在第二个csv文件之后</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kp"><img src="../Images/3f239e6e94b45687f74fea4565f03905.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*oIiJuc9-_EPTGwHWtnWVtA.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">在第三个csv文件之后</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kq"><img src="../Images/801d1c1ca2710f2e4b20e937ec0b7ac5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*K2g2xze8mYdrh6IGhb2WIQ.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">在第四个csv文件之后</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kr"><img src="../Images/ca9108c589890dfa80e45cd8f1faa466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*2N23wcrqBB3PV9LkxzUnxQ.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated">在第五个csv文件之后</figcaption></figure><p id="e007" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如您从截图中看到的，我们从流数据创建的DataFrame随着新文件的加载更新了它的列。</p><h1 id="860e" class="ks kt hi bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结构化流中的窗口操作</h1><p id="9cf4" class="pw-post-body-paragraph if ig hi ih b ii lq ik il im lr io ip iq ls is it iu lt iw ix iy lu ja jb jc hb bi translated">正如我在上一篇关于数据流的文章中提到的窗口操作，我想用下面的例子来演示它；</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lv"><img src="../Images/0b6e9814bf87dd07cc717ad048fb8696.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A4BSNwRPvkCabwGPaUJZzg.png"/></div></div></figure><p id="9f5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本例中，我们使用socket作为我们的格式，这使我们能够在netcat实用程序的帮助下从终端输入数据。假设我们有一个市场，我们想知道我们每分钟卖出的产品数量。因此，我们通过在终端中键入产品名称，并从另一个终端(控制台格式)以数据帧的形式获得结果。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lv"><img src="../Images/3a55ef51fc3b82c7a5e8784a8ac11ffc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rZB5N8WWwMY-ti6uNd2hpw.png"/></div></div></figure><p id="4ef1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先看看我们用作数据输入插座的终端</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lw"><img src="../Images/608d9a2f321c1446c8c8130d8ee3c129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_KfXyc5hB-vnnxP-jcfoqw.png"/></div></div></figure><p id="7f66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我在大约两分钟内(03:02- 03:04)从终端输入了几个产品名称。让我们看看来自控制台的结果，这是一个Anaconda终端。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lx"><img src="../Images/bfe61e6f9acb42a975a93f33c1fbed2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*qhMdKHMmpOYwcqmGg6ltIg.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/491ec38917b022ef07a528145997160a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1340/format:webp/1*QuWxMKc2c5bItORaepMNOw.png"/></div></figure><p id="ddf4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的查询非常成功。现在我们很容易理解结构化窗口流的概念。正如您可以从终端屏幕截图中看到的，我们的数据帧用新的数据更新了自己。我们实现了我们的期望，通过从最近的时间开始排序，有一个数据框显示我们每一分钟的销售额。</p><p id="5639" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们将使用“stop()”方法停止流式传输</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="er es lz"><img src="../Images/492fea95dd28f6f0c2c44a9efaca4b5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5lfvKF1mQ-US1D_YTXlNGw.png"/></div></div></figure><h1 id="4366" class="ks kt hi bd ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp bi translated">结论</h1><p id="58fb" class="pw-post-body-paragraph if ig hi ih b ii lq ik il im lr io ip iq ls is it iu lt iw ix iy lu ja jb jc hb bi translated">在本文中，我试图通过使用Pyspark API向您简要介绍Apache Spark中结构化流的基础知识。在结构化流上定义了更高级的操作。您可以通过在Apache Spark文档中搜索pyspark的<a class="ae ma" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html" rel="noopener ugc nofollow" target="_blank"> Spark结构化流编程指南</a>和<a class="ae ma" href="https://spark.apache.org/docs/latest/api/python/pyspark.streaming.html" rel="noopener ugc nofollow" target="_blank"> Python Api文档</a>来提高您的知识。</p><p id="715c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望这篇文章对你有所帮助。在下一篇文章中，我将通过使用Amazon Elastic MapReduce服务(EMR)的云环境，讲述如何将Jupyter Notebook用于我们的Spark应用程序。</p><p id="40f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将很高兴听到您的任何意见或问题。愿数据伴随你！</p></div></div>    
</body>
</html>