<html>
<head>
<title>Shopee Product Matching EDA and Cleaning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Shopee产品匹配EDA和清洗</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/shopee-product-matching-kaggle-challenge-comprehensive-eda-26cf1ca62945?source=collection_archive---------15-----------------------#2021-04-26">https://medium.com/analytics-vidhya/shopee-product-matching-kaggle-challenge-comprehensive-eda-26cf1ca62945?source=collection_archive---------15-----------------------#2021-04-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="6bfa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">还包括图像的光学字符识别。</p><h2 id="ec93" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">导入所需的库</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="8625" class="jc jd hh kc b fi kg kh l ki kj">import pandas as pd<br/>import numpy as np<br/>import cv2<br/>import seaborn as sns<br/>import sklearn<br/>import matplotlib.pyplot as plt<br/>from textwrap import wrap<br/>import pytesseract<br/>import re,string<br/>from wordcloud import WordCloud, STOPWORDS<br/>from tqdm.notebook import tqdm<br/>from joblib import dump, load<br/>import nltk<br/>from nltk.corpus import stopwords<br/>nltk.download('stopwords')</span><span id="d3c3" class="jc jd hh kc b fi kk kh l ki kj">[nltk_data] Downloading package stopwords to /usr/share/nltk_data...<br/>[nltk_data]   Package stopwords is already up-to-date!<br/><br/><br/><br/><br/><br/>True</span><span id="3afb" class="jc jd hh kc b fi kk kh l ki kj">path = '../input/shopee-product-matching'<br/>train_path = '../input/shopee-product-matching/train_images'<br/>test_path = '../input/shopee-product-matching/test_images'</span></pre><p id="117b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">让我们看看数据头</strong></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="30b8" class="jc jd hh kc b fi kg kh l ki kj">data = pd.read_csv(path+'/'+'train.csv')<br/>data.head()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/1e7b77979ff97fd5a19ea73767bb155a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*VKpVdJx5GKTvmd0XlR87fA.png"/></div></figure><h2 id="9a5c" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">关于数据的基本细节</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="cf20" class="jc jd hh kc b fi kg kh l ki kj">print(f"The Shape of the train data : {data.shape}")<br/>print(f"Duplicate Rows : {data.shape[0] - len(data['posting_id'].unique())}")</span><span id="f6dd" class="jc jd hh kc b fi kk kh l ki kj">The Shape of the train data : (34250, 5)<br/>Duplicate Rows : 0</span><span id="28da" class="jc jd hh kc b fi kk kh l ki kj">print("Number unique label_groups = {}".format( len(data["label_group"].unique()) ))</span><span id="8396" class="jc jd hh kc b fi kk kh l ki kj">Number unique label_groups = 11014</span></pre><p id="0910" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">这里一个标签组表示相似的产品，即:所有具有相同label_id的产品都是相似的</strong></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="526d" class="jc jd hh kc b fi kg kh l ki kj">num_label_groups = {}<br/>for i in data['label_group']:<br/>    num_label_groups[i] = data[data['label_group'] == i]</span><span id="2e3e" class="jc jd hh kc b fi kk kh l ki kj">len_label_groups = {}<br/>for i in num_label_groups:<br/>    len_label_groups[i] = len(num_label_groups[i])<br/><br/>print(f"Max of all the label groups : {max(len_label_groups.values())}")<br/>print(f"Min of all the label groups : {min(len_label_groups.values())}")</span><span id="20df" class="jc jd hh kc b fi kk kh l ki kj">Max of all the label groups : 51<br/>Min of all the label groups : 2</span><span id="f4d8" class="jc jd hh kc b fi kk kh l ki kj">label_names = list(num_label_groups.keys())<br/>num_label_groups[label_names[5]]</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/c748c526d3f956246a153ef3ca3eac5a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*mmTcwqWGsgOe28GntQu1gA.png"/></div></figure><p id="ae93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">让我们想象一些类似的产品</strong></p><p id="254e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此功能允许您输入label_id并查看前10个(或更少，如适用)类似产品。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="474f" class="jc jd hh kc b fi kg kh l ki kj">def visualize_sim_products(label_id):<br/>    sns.set_style("whitegrid")<br/>    plt.rcParams['font.size'] = '28'<br/>    plt.figure(figsize=(50,50))<br/>    length = len_label_groups[label_id]<br/>    if length &gt; 10:<br/>        length = 10<br/>    for i in range(length):<br/>        img = plt.imread(train_path + '/' + num_label_groups[label_id]['image'].iloc[i])<br/>        plt.subplot(length,2,i+1)<br/>        plt.imshow(img)<br/>        plt.title("\n".join(wrap(num_label_groups[label_id]['title'].iloc[i],60)))<br/>        plt.axis('off')<br/>    plt.show()</span><span id="8b03" class="jc jd hh kc b fi kk kh l ki kj">visualize_sim_products(label_names[14])</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/ad36caa37508ce2e7cc5ec59437c4493.png" data-original-src="https://miro.medium.com/v2/format:webp/1*YUVA6eJLSGopxAHNe8lPfA.png"/></div></figure><h2 id="3a1e" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">感知哈希</h2><p id="e541" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">根据维基百科，在这个挑战中提供了永久散列，所以我仔细阅读了它:</p><blockquote class="ku kv kw"><p id="f02f" class="ie if kx ig b ih ii ij ik il im in io ky iq ir is kz iu iv iw la iy iz ja jb ha bi translated">感知散列是使用一种算法来产生各种形式的多媒体的片段或指纹。[1][2]如果多媒体的特征相似，感知散列函数是类似的，而加密散列依赖于输入值的微小变化产生输出值的剧烈变化的雪崩效应。感知哈希函数广泛用于查找在线版权侵权案件以及数字取证，因为它能够在哈希之间建立关联，从而可以找到相似的数据(例如具有不同的水印)。</p></blockquote><p id="0271" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，可能相似的对象具有相似的感知散列值。这是我的假设，我们来验证一下这是不是真的。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="62ba" class="jc jd hh kc b fi kg kh l ki kj">num_label_groups[label_names[17]]['image_phash']</span><span id="0750" class="jc jd hh kc b fi kk kh l ki kj">18       bf38f0e083d7c710<br/>4636     bf3cf0e08197c712<br/>14656    bf38f0e08397c712<br/>Name: image_phash, dtype: object</span></pre><p id="64c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">看来我的假设是错的。</p><p id="e6fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是我们可以使用这些相位之间的汉明距离作为一个特征(特征工程)，这将用于另一个笔记本。</p><p id="190b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">似乎完全相同的图像有相同的相位。</p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="49b9" class="jc jd hh kc b fi kg kh l ki kj">def hamming(s1, s2):<br/>    return float(sum(c1 != c2 for c1, c2 in zip(s1, s2))) / float(len(s1))<br/>hamming('bf38f0e08397c712','bf38f0e083d7c710')</span><span id="67ec" class="jc jd hh kc b fi kk kh l ki kj">0.125</span></pre><h2 id="da16" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">让我们找出有多少完全相同的图像</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="0505" class="jc jd hh kc b fi kg kh l ki kj">copies = {}<br/>for i in data['image_phash']:<br/>    copies[i] = data[data['image_phash'] == i]<br/>phash_list = list(copies.keys())<br/><br/>copies[phash_list[14]]</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/599330181f4d6768816ebac9eeb50b1d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*D1HIaG4QILMPUXFGMISqRg.png"/></div></figure><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="24ae" class="jc jd hh kc b fi kg kh l ki kj">copies_len = {}<br/>for i in copies.keys():<br/>    copies_len[i] = len(copies[i])</span><span id="cb0b" class="jc jd hh kc b fi kk kh l ki kj">copies_len = pd.DataFrame({'phash':copies_len.keys(),'count':copies_len.values()})<br/># copies_len.reset_index(inplace=True)<br/>copies_len.head()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/4d90fcf484bb53e17c7c32cc74feb3ec.png" data-original-src="https://miro.medium.com/v2/format:webp/1*8CXFE2DRtyEuAKmFLaEa5A.png"/></div></figure><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="ad10" class="jc jd hh kc b fi kg kh l ki kj">copies_len.sort_values(by='count',ascending = False, inplace = True)</span></pre><h2 id="7af8" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">前10个重复图像的相位</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="56b2" class="jc jd hh kc b fi kg kh l ki kj">fig = plt.figure(figsize=(70,50))<br/>sns.barplot(x = copies_len.iloc[:10]['phash'],y=copies_len.iloc[:10]['count'])<br/>plt.show()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/e091139b8f4286f4897e20ef4e2cce72.png" data-original-src="https://miro.medium.com/v2/format:webp/1*VEA2UD7J-XW4ky3qW-9tJg.png"/></div></figure><h2 id="b7da" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">让我们来看一些确切的副本</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="4ebe" class="jc jd hh kc b fi kg kh l ki kj">def visualize_sim_phashes(phash):<br/>    sns.set_style("whitegrid")<br/>    plt.rcParams['font.size'] = '28'<br/>    plt.figure(figsize=(50,50))<br/>    length = len(copies[phash])<br/>    if length &gt; 10:<br/>        length = 10<br/>    for i in range(length):<br/>        img = plt.imread(train_path + '/' + copies[phash]['image'].iloc[i])<br/>        plt.subplot(length,2,i+1)<br/>        plt.imshow(img)<br/>        plt.title("\n".join(wrap(copies[phash]['title'].iloc[i],60)))<br/>        plt.axis('off')<br/>    plt.show()</span><span id="50fb" class="jc jd hh kc b fi kk kh l ki kj">visualize_sim_phashes(phash_list[14])</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/81173c024c2c4a22c9de07fefd1bb98f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Vy2T1i2jd39ch1o8_4Antw.png"/></div></figure><h1 id="d62f" class="lb jd hh bd je lc ld le ji lf lg lh jm li lj lk jp ll lm ln js lo lp lq jv lr bi translated">基于自然语言处理的EDA</h1><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="592c" class="jc jd hh kc b fi kg kh l ki kj">title_text = data['title'].values</span><span id="e62f" class="jc jd hh kc b fi kk kh l ki kj">def clean(title):<br/>    stop = stopwords.words('english')<br/>    title = [x for x in title.split() if not x in stop]<br/>    title = " ".join(title)<br/>    title = title.lower()<br/>    title = re.sub(r"\-","",title)<br/>    title = re.sub(r"\+","",title)<br/>    title = re.sub (r"&amp;","and",title)<br/>    title = re.sub(r"\|","",title)<br/>    title = re.sub(r"\\","",title)<br/>    title = re.sub(r"\W"," ",title)<br/>    for p in string.punctuation :<br/>        title = re.sub(r"f{p}","",title)<br/>    <br/>    title = re.sub(r"\s+"," ",title)<br/>    <br/>    return title</span><span id="6d97" class="jc jd hh kc b fi kk kh l ki kj">data.head()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/1e7b77979ff97fd5a19ea73767bb155a.png" data-original-src="https://miro.medium.com/v2/format:webp/1*VKpVdJx5GKTvmd0XlR87fA.png"/></div></figure><h2 id="f91c" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">词汇云</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="dbfe" class="jc jd hh kc b fi kg kh l ki kj">stopwords_wc = set(STOPWORDS) <br/>token_text = ''<br/><br/>for i in tqdm(title_text):<br/>    token_l = i.split()<br/>    token_text += " ".join(token_l) + " "</span><span id="a966" class="jc jd hh kc b fi kk kh l ki kj">0%|          | 0/34250 [00:00&lt;?, ?it/s]</span></pre><h2 id="6b9e" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">标题文字的文字云</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="870d" class="jc jd hh kc b fi kg kh l ki kj">wordcloud = WordCloud(width = 800, height = 800, <br/>                background_color ='white', <br/>                stopwords = stopwords_wc, <br/>                min_font_size = 10).generate(token_text)<br/><br/>plt.figure(figsize = (8, 8), facecolor = None) <br/>plt.imshow(wordcloud) <br/>plt.axis("off") <br/>plt.tight_layout(pad = 0) <br/>  <br/>plt.show()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/0cdf34307fafe49003be5e2ada273071.png" data-original-src="https://miro.medium.com/v2/format:webp/1*4B4fk5geqMVOfcuBaICTuQ.png"/></div></figure><p id="e578" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">让我们尽可能从图像中提取所有信息，也许将来会用作特征</strong></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="8c77" class="jc jd hh kc b fi kg kh l ki kj"># Use this for OCR extraction<br/># ocr_text = []<br/># for i in tqdm(range(data.shape[0])):<br/>#     img = cv2.imread(train_path + '/' + data['image'].iloc[i])<br/>#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)<br/>#     text = pytesseract.image_to_string(img)<br/>#     text = " ".join(text.split())<br/>#     if len(text) != 0:<br/>#         ocr_text.append(text)<br/>#     else:<br/>#         ocr_text.append('Nothing Found')<br/><br/># data['ocr_text'] = ocr_text</span><span id="e9ad" class="jc jd hh kc b fi kk kh l ki kj"># data.to_csv('cleaned_and _raw_ocr.csv')<br/>data = pd.read_csv('../input/cleaned-shopee-data-with-ocr/cleaned_title_and_ocr_sw.csv')<br/># Cleaning titles and ocr text again for stopwords, which I missed before<br/>data.drop(['cleaned_title','cleaned_ocr_text'],axis=1,inplace=True)<br/>data['cleaned_title'] = data['title'].map(clean)</span><span id="566e" class="jc jd hh kc b fi kk kh l ki kj">data['cleaned_ocr_text'] = data['ocr_text'].map(clean)<br/># data.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1,inplace=True)<br/>data.to_csv('cleaned_title_and_ocr_sw.csv')</span><span id="1b5c" class="jc jd hh kc b fi kk kh l ki kj">data.head()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/4d18b9dd21ecab5813ed91daad0ed073.png" data-original-src="https://miro.medium.com/v2/format:webp/1*JtI57SFyLdU2G2i6l_b9Pw.png"/></div></figure><h2 id="ab47" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">用于OCR数据的WordCloud</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="2915" class="jc jd hh kc b fi kg kh l ki kj">title_text = data['cleaned_ocr_text'].values<br/>stopwords_wc = list(STOPWORDS)<br/>token_text = ''<br/><br/>for i in tqdm(title_text):<br/>    if i.strip() != 'Nothing Found'.lower():<br/>        token_l = i.split()<br/>        token_text += " ".join(token_l) + " "<br/><br/>wordcloud = WordCloud(width = 800, height = 800, <br/>                background_color ='white', <br/>                stopwords = stopwords_wc, <br/>                min_font_size = 10,contour_color='steelblue').generate(token_text)<br/><br/>plt.figure(figsize = (8, 8), facecolor = None) <br/>plt.imshow(wordcloud,interpolation='bilinear') <br/>plt.axis("off") <br/>plt.tight_layout(pad = 0) <br/>  <br/>plt.show()</span><span id="2619" class="jc jd hh kc b fi kk kh l ki kj">0%|          | 0/34250 [00:00&lt;?, ?it/s]</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/4fb579045c179ca73deeee4540c320e5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*n1rUCGbKhOajuD3i76V1tw.png"/></div></figure><h2 id="381b" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">让我们看看标题和OCR文本</h2><h2 id="03cc" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">标题文本长度的分布</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="907d" class="jc jd hh kc b fi kg kh l ki kj">plt.figure(figsize = (10, 6))<br/>sns.set_style("whitegrid")<br/>sns.kdeplot(data['cleaned_title'].apply(lambda x: len(x)),fill = True,edgecolor='black',alpha=0.9)<br/>plt.xlabel('Title Text Length')<br/>plt.show()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/65c180a88fe65b131fbd499ae899d004.png" data-original-src="https://miro.medium.com/v2/format:webp/1*fgPNy9y_DZdbOvrGJaB0Fg.png"/></div></figure><h2 id="96e4" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">标题文本令牌计数的分布</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="fa16" class="jc jd hh kc b fi kg kh l ki kj">plt.figure(figsize = (10, 6))<br/>sns.set_style("whitegrid")<br/>sns.kdeplot(data['cleaned_title'].apply(lambda x: len(x.split())),fill = True,edgecolor='black',alpha=0.9,color='cyan')<br/>plt.xlabel('Title Text Tokens Count')<br/>plt.show()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/d8b91ecbf2189ee454c43f349d80131f.png" data-original-src="https://miro.medium.com/v2/format:webp/1*OfqWj5-YOFIyAyinx4w3vg.png"/></div></figure><h2 id="62ff" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">OCR文本长度的分布</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="d21f" class="jc jd hh kc b fi kg kh l ki kj">plt.figure(figsize = (10, 6))<br/>sns.set_style("whitegrid")<br/>sns.kdeplot(data['cleaned_ocr_text'].apply(lambda x: len(x)),fill = True,color = 'red',edgecolor='black',alpha=0.9)<br/>plt.xlabel('OCR Text Length')<br/>plt.show()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/e06aa960ecd01d4bf253305d5c0bd3fb.png" data-original-src="https://miro.medium.com/v2/format:webp/1*6j0XartOPAugViQ5p4Ca5Q.png"/></div></figure><h2 id="e98e" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">OCR文本令牌计数的分布</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="31de" class="jc jd hh kc b fi kg kh l ki kj">plt.figure(figsize = (10, 6))<br/>sns.set_style("whitegrid")<br/>sns.kdeplot(data['cleaned_ocr_text'].apply(lambda x: len(x.split())),fill = True,color = 'maroon',edgecolor='black',alpha=0.9)<br/>plt.xlabel('OCR Text Tokens Count')<br/>plt.show()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/78f83b48db6d0d2ac7b52a752568bcf4.png" data-original-src="https://miro.medium.com/v2/format:webp/1*GQ00gXAU1oVHvCoYFUdLKA.png"/></div></figure><h2 id="1b72" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">图像形状EDA</h2><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="c696" class="jc jd hh kc b fi kg kh l ki kj">image_shapes_h = []<br/>image_shapes_w = []<br/>image_shapes_c = []<br/>for i in tqdm(range(data.shape[0])):<br/>    img = cv2.imread(train_path + '/' + data['image'].iloc[i])<br/>    h, w, c = img.shape<br/>    image_shapes_h.append(h)<br/>    image_shapes_w.append(w)<br/>    image_shapes_c.append(c)</span><span id="4e78" class="jc jd hh kc b fi kk kh l ki kj">0%|          | 0/34250 [00:00&lt;?, ?it/s]</span><span id="729b" class="jc jd hh kc b fi kk kh l ki kj">dump(image_shapes_h,'heights.pkl')<br/>dump(image_shapes_w,'widths.pkl')<br/>dump(image_shapes_c,'channels.pkl')<br/><br/>image_shapes_h = load('heights.pkl')<br/>image_shapes_w = load('widths.pkl')<br/>image_shapes_c = load('channels.pkl')</span><span id="2d53" class="jc jd hh kc b fi kk kh l ki kj">set(image_shapes_c)</span><span id="9d19" class="jc jd hh kc b fi kk kh l ki kj">{3}</span></pre><p id="0e99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">没有任何黑白图像&amp;</strong></p><pre class="jx jy jz ka fd kb kc kd ke aw kf bi"><span id="6bad" class="jc jd hh kc b fi kg kh l ki kj">sns.set_style("white")<br/>sns.axes_style('whitegrid')<br/>h = sns.JointGrid(x =  image_shapes_h,y = image_shapes_w,height=8)<br/>h.plot_joint(sns.scatterplot)<br/>h.plot_marginals(sns.histplot, kde=True)<br/>plt.show()</span></pre><figure class="jx jy jz ka fd kl er es paragraph-image"><div class="ab fe cl km"><img src="../Images/36f7300a6618b1ab5ed967a1c62254f9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*T2iITQZ1NkeRjOYPF3ri9w.png"/></div></figure><h2 id="19e9" class="jc jd hh bd je jf jg jh ji jj jk jl jm ip jn jo jp it jq jr js ix jt ju jv jw bi translated">数据洞察(汇编)</h2><ul class=""><li id="8763" class="ls lt hh ig b ih kp il kq ip lu it lv ix lw jb lx ly lz ma bi translated">数据库中总共有34250个产品是唯一的，这意味着没有重复的行。</li><li id="07d3" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">数据集中提供了11014个label_groups。</li><li id="dae2" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">所有标签组的最大数量:51</li><li id="9063" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">所有标签组的最小值:2</li><li id="cb8a" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">一个标签组中所有图像的感知哈希并不相同，但是存在一些标题不同的相同图像。</li><li id="831a" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">Phash hamming distance可能是将来使用的一个好功能。</li><li id="4b5a" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">我们可以参考各自的单词云来了解标题和ocr文本中经常使用的单词。</li><li id="c774" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">OCR文本可能是模型的一个很好的特性。</li><li id="173c" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">大多数数据的标题文本长度似乎少于90个字符。</li><li id="683c" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">大多数数据的标题文本标记计数似乎少于20个单词。</li><li id="ffc8" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">同样，OCR文本长度似乎也少于90–100个字符。</li><li id="e910" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">OCR文本标记的数量似乎少于18–20个标记(这些标记中的大部分是来自糟糕的OCR的乱码)</li><li id="a222" class="ls lt hh ig b ih mb il mc ip md it me ix mf jb lx ly lz ma bi translated">所有图像都是3通道RGB图像，数据集中没有B&amp;W或灰度图像。结合图可以得到图像的高度和宽度分布的概念。</li></ul></div></div>    
</body>
</html>