<html>
<head>
<title>TableNet: Deep Learning Model for End to End Table Detection and Tabular Data Extraction from Scanned Document Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TableNet:深度学习模型，用于从扫描的文档图像中进行端到端表格检测和表格数据提取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tablenet-deep-learning-model-for-end-to-end-table-detection-and-tabular-data-extraction-from-a26790097a50?source=collection_archive---------6-----------------------#2021-08-16">https://medium.com/analytics-vidhya/tablenet-deep-learning-model-for-end-to-end-table-detection-and-tabular-data-extraction-from-a26790097a50?source=collection_archive---------6-----------------------#2021-08-16</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/35f86cd82815aeecbfdddac5b175c476.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3CgaVDqm06uIiFz4"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://unsplash.com/@homajob?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">斯科特·格雷厄姆</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="bd79" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi jt translated"><span class="l ju jv jw bm jx jy jz ka kb di">在现代，智能手机和扫描仪被广泛用于拍摄和分享重要文件的图像。这些文档中的许多信息都存储在表格中。从表中提取文本信息的需求变得非常迫切。目前，这种信息提取是手动执行的，这需要大量的工作和相当多的时间。因此，拥有一个可以执行这项任务的深度学习模型将节省我们大量的精力和时间。</span></p><p id="90d3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这篇博客中，我将讨论一篇研究论文<a class="ae iu" href="https://arxiv.org/abs/2001.01469" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj">【TableNet】</strong></a>，发表于<em class="kc">2020年1月</em>由<a class="ae iu" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Paliwal%2C+S" rel="noopener ugc nofollow" target="_blank"><em class="kc">Shubham Pali wal</em></a><em class="kc">，</em><a class="ae iu" href="https://arxiv.org/search/cs?searchtype=author&amp;query=D%2C+V" rel="noopener ugc nofollow" target="_blank"><em class="kc">Vishwanath D</em></a><em class="kc">，</em><a class="ae iu" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rahul%2C+R" rel="noopener ugc nofollow" target="_blank"><em class="kc">Rohit Rahul</em><em class="kc">，</em> </a><a class="ae iu" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+M" rel="noopener ugc nofollow" target="_blank"> <em class="kc"/></a></p></div><div class="ab cl kd ke gp kf" role="separator"><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki kj"/><span class="kg bw bk kh ki"/></div><div class="hb hc hd he hf"><h1 id="b12d" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">目录:</h1><ol class=""><li id="79aa" class="li lj hi ix b iy lk jc ll jg lm jk ln jo lo js lp lq lr ls bi translated">介绍</li><li id="4449" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">资料组</li><li id="83f7" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">问题陈述</li><li id="3b8f" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">映射到ML/DL问题</li><li id="a71d" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">性能指标</li><li id="6902" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">分析数据集并制作掩模图像。</li><li id="890d" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">数据预处理</li><li id="4e4f" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">模型架构和培训</li><li id="05fc" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">从图像中提取表格</li><li id="f9e3" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">在Streamlit上部署</li><li id="607e" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">丰富</li><li id="ff06" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">参考</li><li id="228d" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">联系我</li></ol><h1 id="8c81" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">介绍</h1><p id="a732" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">从表中提取数据的任务带来了一系列新的挑战:</p><blockquote class="mg mh mi"><p id="28ec" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">I .表格区域的精确检测称为<strong class="ix hj">表格检测。</strong></p><p id="737b" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">二。从被检测表格的行和列中检测和提取信息称为<strong class="ix hj">表格结构识别。</strong></p></blockquote><p id="4121" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这个问题的现有技术解决方案已经通过使用专用于单独任务的两个独立模型解决了这些问题。然而，考虑到这两个任务的相互依赖性，用一个单一的模型来做是有益的。</p><p id="5569" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> TableNet </strong>就是这样一个深度学习模型，它只使用一个网络来同时解决这两个任务。它是一个端到端的模型，将文档的1024x1024分辨率的图像<strong class="ix hj">作为输入，并产生两个语义标记的输出，<em class="kc">一个用于图像</em>中的表，<em class="kc">一个用于表</em>中的列，分别称为<em class="kc">表和列掩码</em><em class="kc">。</em>一旦生成这些蒙版，使用表格蒙版从图像中过滤出表格，并使用<strong class="ix hj"> Tesseract OCR模块</strong><a class="ae iu" href="https://pypi.org/project/pytesseract/" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj">pytesse ract</strong></a><strong class="ix hj"/>从表格中提取文本信息。</strong></p><p id="ca47" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">至于模型的架构，它类似于<em class="kc">编码器-解码器模型</em>，编码器对图像中表格的位置和结构信息进行编码，解码器使用这些信息为表格和列生成掩码。对于编码器，使用在ImageNet数据集上预先训练的<em class="kc"> VGG-19模型。随后是两个单独的解码器分支，分别用于表和列的分段。解码器分支彼此独立地被训练，而编码器可以使用来自两个解码器的梯度来微调。然而，在这篇博客中，我没有微调编码器，并将其设置为不可训练。</em></p><h2 id="6fe0" class="mm kl hi bd km mn mo mp kq mq mr ms ku jg mt mu ky jk mv mw lc jo mx my lg mz bi translated">资料组</h2><p id="6ea2" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">这里使用的数据集是<strong class="ix hj"> Marmot表识别数据集。</strong>Marmot表检测数据集是一个表检测数据集，但它不包含用于列检测的基础真值。因此，作者手动注释了数据集中所有图像的列，以了解列的基本情况。marmot数据集总共包含1016张图像，其中509张是英文文档，其余是中文文档。对于培训，仅使用英文文档。数据集包含中的图像。bmp格式和一个对应于每个图像的XML文件，该文件包含文档中每列边界框的坐标。</p><p id="9d30" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">数据集可以从这里下载:</p><div class="na nb ez fb nc nd"><a href="https://drive.google.com/drive/folders/1410iMmQCXbA9GJP5CqLEMfjjv-hOWlac" rel="noopener  ugc nofollow" target="_blank"><div class="ne ab dw"><div class="nf ab ng cl cj nh"><h2 class="bd hj fi z dy ni ea eb nj ed ef hh bi translated">Marmot_data -谷歌驱动</h2><div class="nk l"><h3 class="bd b fi z dy ni ea eb nj ed ef dx translated">编辑描述</h3></div><div class="nl l"><p class="bd b fp z dy ni ea eb nj ed ef dx translated">drive.google.com</p></div></div><div class="nm l"><div class="nn l no np nq nm nr io nd"/></div></div></a></div><h1 id="331b" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">问题陈述</h1><ol class=""><li id="3372" class="li lj hi ix b iy lk jc ll jg lm jk ln jo lo js lp lq lr ls bi translated">如果图像中存在任何表，则对输入图像中的表的表掩码和列掩码进行分段。</li><li id="ff50" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated">使用表格遮罩，从图像中过滤表格，并使用OCR提取表格的内容。</li></ol><h1 id="dddb" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">映射到ML/DL模型</h1><p id="baba" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">为了从图像中提取表格，我们需要首先从图像中分割出表格和列，并为每个图像创建一个表格和列掩码。图像将是我们模型的输入，表和列掩码将是输出。因此，这个问题可以被认为是一个<em class="kc">图像分割</em>问题。</p><h1 id="1257" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">性能指标</h1><p id="9e2c" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">我们将用于评估车型性能的性能指标是<strong class="ix hj"> F1得分。</strong>这也是原文中使用的指标。使用F1分数作为衡量标准的原因是，我们希望模型完成的分割是纯T4和完整的。</p><blockquote class="mg mh mi"><p id="b692" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated"><strong class="ix hj">纯:</strong>由模型创建的遮罩不包含不在表格区域中的图像的任何部分。</p><p id="9bf9" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated"><strong class="ix hj">完成:</strong>模型创建的遮罩不会遗漏图像中的任何表格区域。</p></blockquote><p id="deba" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">蒙版的<em class="kc">纯度</em>可以认为是模型的<em class="kc">精度</em>，蒙版的<em class="kc">完整性</em>可以认为是模型的<em class="kc">召回</em>，因此F1评分是一个很好的评估选择。为了评估，计算每幅图像的F1分数，然后平均得到最终分数。</p><h1 id="1a18" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">分析数据并制作掩模图像</h1><p id="421e" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">首先，让我们看看数据中的一些图像，以了解我们正在处理哪种图像和表格:</p><figure class="nt nu nv nw fd ij er es paragraph-image"><div class="er es ns"><img src="../Images/0cee9703fbb205a33c388e09798dd3af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1322/format:webp/1*zsDhZD7mWDN9MXhpJwMBIA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自旱獭数据集的样本图像</figcaption></figure><p id="862a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">查看数据集中的一些图像后，可以观察到以下情况:</p><blockquote class="mg mh mi"><p id="018d" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">表格出现在整个图像中。他们没有特定的位置。</p><p id="3ca6" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">它们也没有固定的大小。一些图像中的表格非常小，而一些图像中的表格相当大。一些图像甚至可能只有一个表格。</p><p id="9413" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">说到表结构，所有图像中的表都非常不同。有些表格在列、行之间有明确的边界，表格也被边界包围。而有些只有列或行之间的分隔。</p><p id="d5e8" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">查看一个图像中的表的数量，我们可以看到这里也有相当多的多样性，有些图像只有一个表，有些有两个，有些有三个。</p></blockquote><p id="1bae" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们来看看其中一幅图像的XML文件:</p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div></figure><p id="9700" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">XML文件包含几个标签，如文件名、路径、大小、对象等。文件名标签包含XML文件所属图像的名称。<em class="kc">尺寸</em>标签表示图像的尺寸。<em class="kc">对象</em>标签包含列的边界框坐标。</p><p id="263c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于每个<strong class="ix hj"> &lt;对象&gt;，</strong>我们有一个<strong class="ix hj"> &lt; bndbox &gt; </strong>元素，它包含<strong class="ix hj"> xmin，ymin，xmax </strong>和<strong class="ix hj"> ymax </strong>，这些元素包含列边界框的相应点的坐标。因为XML文件只包含列边界框的坐标，所以表格边界框的坐标必须从这些坐标中导出。下面是从XML文件创建蒙版图像的代码:</p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">用于创建遮罩的辅助函数</figcaption></figure><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">为每个图像创建遮罩。</figcaption></figure><p id="7970" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于每个图像，我们使用上面定义的函数创建一个<strong class="ix hj">表格掩码</strong> <em class="kc"> </em>和一个<strong class="ix hj">列掩码</strong> <em class="kc"> </em>，给定它的<strong class="ix hj"> XML文件</strong>。然后，我们制作一个包含列的数据帧，这些列包含图像的路径、相应的表掩码和列掩码。</p><figure class="nt nu nv nw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nz"><img src="../Images/b39891ecea3caff232c02924d38f6dd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6SXB2vqed_4Lg00wlnhEsg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">数据帧</figcaption></figure><figure class="nt nu nv nw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oa"><img src="../Images/4c3e24a956351f5ea04a0d4cd0349562.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_UBCq9hikuS_r0DIeiRDSw.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">样品柱掩模</figcaption></figure><figure class="nt nu nv nw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es oa"><img src="../Images/ab801c05a71a27eb499d3d8717ad4638.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Tp1Hm3ollRDjeHtZT_aaQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">样本表掩码</figcaption></figure><h1 id="7743" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">数据预处理</h1><p id="7625" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">在这一节中，我们将讨论如何构建一个定制的数据生成器/数据加载器，用于向模型提供数据以进行训练，以及我们将应用于图像的所有预处理。但在此之前，我们需要首先将数据集分成训练集和测试集。我们将对训练和测试数据分别使用80–20%的比率。</p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">列车测试分离</figcaption></figure><p id="1500" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">由于数据集中大约有<strong class="ix hj"> 495张图像</strong>并且<em class="kc">每张图像有几兆字节，</em>不可能在训练期间将它们全部加载到RAM中。因此，我们将不得不创建一个定制的输入管道，以便在训练过程中向模型提供数据。为此，我们将使用<a class="ae iu" href="https://www.tensorflow.org/tutorials/load_data/images" rel="noopener ugc nofollow" target="_blank"> tf.data.dataset </a>创建一个定制的输入管道。</p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">tf.data.dataset对象</figcaption></figure><p id="43a0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">所有图像都是RGB图像，因此它们分别具有红色、蓝色和绿色的3个通道。然而，它们没有固定的分辨率，因此，我们必须将它们调整到固定的大小，本文建议将图像调整到<strong class="ix hj"> 1024x1024 </strong>。因此，掩模图像也被调整到<strong class="ix hj"> 1024x1024x1 </strong>。之后，我们将通过将每个像素值除以<strong class="ix hj"> 255来归一化所有图像。</strong></p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div></figure><p id="679a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上述函数从各自的路径加载图像及其各自的遮罩，并对其进行预处理。它最终返回一个元组<strong class="ix hj"> (image，dictionary) </strong>，其中<em class="kc">字典包含表和列掩码</em>。在此之后，我们将<a class="ae iu" href="https://www.tensorflow.org/tutorials/load_data/images#configure_dataset_for_performance" rel="noopener ugc nofollow" target="_blank">配置上述训练和测试数据集，以便在训练时获得更好的性能</a>。我们需要这样做，因为在训练期间，我们希望数据是:</p><blockquote class="mg mh mi"><p id="7f27" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">洗得很好</p><p id="1126" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">成批的</p><p id="ccbc" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">尽快提供批次</p></blockquote><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">配置数据集以获得更好的性能</figcaption></figure><h1 id="bf85" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">模型架构和培训</h1><p id="2c76" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">现在一切都准备好了，接下来就是我们做模型架构，最后训练的时候了。TableNet体系结构类似于编码器-解码器模型，其中一个编码器将对图像中的表格信息进行编码，两个解码器将使用编码信息分别创建表和列掩码。</p><figure class="nt nu nv nw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ob"><img src="../Images/3a2a0c9ea4c36da084e49b803f7e493b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kghEO057vJWwU0p2yb7MaQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">TableNet架构</figcaption></figure><h2 id="b554" class="mm kl hi bd km mn mo mp kq mq mr ms ku jg mt mu ky jk mv mw lc jo mx my lg mz bi translated">A.编码器</h2><p id="5a93" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">研究论文使用的编码器是在ImageNet数据集上预先训练的<em class="kc"> VGG-19模型。</em>VGG-19型号的重量设置为不可训练，在训练期间不会改变。在VGG-19模型的最后一层之后，<em class="kc">使用两个1x1卷积层，后面是丢失率为0.2的丢失层</em>。这就完成了模型的编码器部分。</p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">TableNet架构</figcaption></figure><p id="4c13" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">除了使用论文中提到的VGG-19编码器，我还决定使用不同的架构，看看这是否会导致模型性能的任何变化。我使用了以下编码器:</p><p id="24f5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">一、VGG-19(默认)</strong></p><p id="bf2a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">二。ResNet-50 </strong></p><p id="cc1e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">三。DenseNet-121 </strong></p><p id="1cfa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于最终模型，将选择三种模型中性能最佳的模型/编码器。</p><h2 id="b206" class="mm kl hi bd km mn mo mp kq mq mr ms ku jg mt mu ky jk mv mw lc jo mx my lg mz bi translated">B.表格解码器</h2><p id="0c9e" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">表解码器是TableNet模型中的两个解码器之一。它负责从输入图像中分割表格。表解码器的架构如下:</p><blockquote class="mg mh mi"><p id="2823" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">张量= 1x1卷积(编码器_输出)</p><p id="1f79" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">张量=向上扩展(张量，2x) +池4</p><p id="3ebe" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">张量=向上扩展(张量，2x) +池3</p><p id="873a" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">张量=放大(张量，以匹配输入维度，即1024x1024) -&gt;这将是表解码器的最终输出。</p></blockquote><p id="73c7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">表格解码器将被定义为<a class="ae iu" href="https://www.tensorflow.org/tutorials/customization/custom_layers" rel="noopener ugc nofollow" target="_blank">自定义张量流层</a>。</p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">自定义表格解码器层</figcaption></figure><h2 id="ddd3" class="mm kl hi bd km mn mo mp kq mq mr ms ku jg mt mu ky jk mv mw lc jo mx my lg mz bi translated">B.列解码器</h2><p id="590d" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">列解码器将是模型的第二个解码器。它将负责从图像中分割出列，并构建一个<em class="kc">列遮罩。</em>列解码器的架构如下:</p><blockquote class="mg mh mi"><p id="d07e" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">张量= 1x1卷积和ReLU激活(编码器_输出)</p><p id="e6db" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">张量=下降(0.8，张量)</p><p id="e2cd" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">张量= 1x1卷积(张量)</p><p id="b734" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">张量=向上扩展(张量，2x) +池4</p><p id="8282" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">张量=升级(高音，2x) +池3</p><p id="b35f" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">tensor = Upscaling(tensor，以匹配输入维度，即1024x1024) -&gt;这将是列解码器的最终输出</p></blockquote><p id="53ce" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">列解码器也将被定义为自定义张量流层。</p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">列解码器的自定义层</figcaption></figure><h2 id="2021" class="mm kl hi bd km mn mo mp kq mq mr ms ku jg mt mu ky jk mv mw lc jo mx my lg mz bi translated">培训详情</h2><p id="dee3" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">所有三个模型都被训练了<em class="kc"> 20个周期</em>。优化器是学习率=0.0001 和<em class="kc">ε= 1e-8的<em class="kc">亚当。稀疏分类交叉熵</em>被选为两个输出的模型的损失函数，并且<em class="kc"> F1分数</em>被用作两个输出的性能度量。</em></p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">模型编译以及损失和性能指标</figcaption></figure><h2 id="6bbe" class="mm kl hi bd km mn mo mp kq mq mr ms ku jg mt mu ky jk mv mw lc jo mx my lg mz bi translated">每个型号的性能评审</h2><p id="460e" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">以下是所有三种型号的性能曲线图和性能评论，曲线图将分别为<em class="kc">时期与型号损失、时期与列解码器的F1分数、时期与表解码器的F1分数。</em></p><ol class=""><li id="457e" class="li lj hi ix b iy iz jc jd jg oc jk od jo oe js lp lq lr ls bi translated"><strong class="ix hj"> VGG-19编码器型号:</strong></li></ol><figure class="nt nu nv nw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es of"><img src="../Images/29b23b7499835a07f21fe2c47169430c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZsgmxQgXY9xI50VZTno_BA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">对于VGG-19编码器模型的性能图，每个图中的x轴是时期，第一个图的y轴是模型损耗，第二个图的列解码器的F1分数，第三个图的表解码器的F1分数。</figcaption></figure><blockquote class="mg mh mi"><p id="3a42" class="iv iw kc ix b iy iz ja jb jc jd je jf mj jh ji jj mk jl jm jn ml jp jq jr js hb bi translated">注意:下面两个图是从Tensorboard中提取的，因此有不同的图例。这里的蓝线代表验证分数，而橙线代表训练分数。</p></blockquote><p id="b46b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 2。</strong> <strong class="ix hj"> ResNet-50编码器型号:</strong></p><div class="nt nu nv nw fd ab cb"><figure class="og ij oh oi oj ok ol paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/58f1a21962aee2c9fa2b91d4b509907c.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*WshhtndnAkj2Z9gNtiTcLg.jpeg"/></div></figure><figure class="og ij om oi oj ok ol paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/bbe0659fc19d1ac1a8c77b05e9256241.png" data-original-src="https://miro.medium.com/v2/resize:fit:670/format:webp/1*uyJJzurlos-zejoeGbprNA.jpeg"/></div></figure><figure class="og ij on oi oj ok ol paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/7581dee9c8e9705e165ac54348260754.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*qAAGgDsy0abf-3zlBXkDAQ.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx oo di op oq translated">ResNet 50编码器模型的性能图。每个图的x轴是时期，而第一个图的y轴是模型损失、第二个图的列解码器的F1分数和第三个图的表解码器的F1分数。</figcaption></figure></div><p id="08fd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 3。DenseNet-121编码器型号:</strong></p><div class="nt nu nv nw fd ab cb"><figure class="og ij or oi oj ok ol paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/2dcad460c4d34dc58fad1f08135f415f.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*7oCE_RpvjTYDEqVjIZ_0WA.jpeg"/></div></figure><figure class="og ij os oi oj ok ol paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/6785d46703be360c196f868dfe50f024.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*kMSXBdZxdd9XBrqsRsMwNw.jpeg"/></div></figure><figure class="og ij ot oi oj ok ol paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/ed787af1f44eda6c9966855d8d8c5a6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*7WgaGUhqrseJcm2kvdFofA.jpeg"/></div><figcaption class="iq ir et er es is it bd b be z dx ou di ov oq translated">DenseNet 121编码器模型的性能图。每个图的x轴是时期，而第一个图的y轴是模型损失、第二个图的列解码器的F1分数和第三个图的表解码器的F1分数。</figcaption></figure></div><figure class="nt nu nv nw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ow"><img src="../Images/c8c59f15f5a8271c94107c7fa140a433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8sfOrKGJECJKpN9iKGEKYA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">所有三种型号的性能指标。制表匠来源:<a class="ae iu" href="https://cloud.xara.com/" rel="noopener ugc nofollow" target="_blank">https://cloud.xara.com/</a></figcaption></figure><p id="d78a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从上面的表和图中，我们可以看到，在三种型号中，<em class="kc">采用DenseNet-121编码器的型号效果最佳。</em>因此，为了进一步的评估和部署，将使用该模型。</p><h1 id="bbb8" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">从图像中提取表格</h1><p id="1237" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">为了从图像中提取表格，首先，输入图像需要作为形状为<strong class="ix hj"> (1，1024，1024，3) </strong>的张量传递给模型，这将给出表格和列掩码作为形状为<strong class="ix hj"> (1，1024，1024，2) </strong>的输出张量。<strong class="ix hj"> </strong>然后我们将沿着深度执行<strong class="ix hj"> argmax </strong>来得到最大概率得到表和列掩码的类。</p><p id="afd2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">然后，提取的表掩码将被用作过滤器来获取表。为此，我们将使用灰度格式的表格遮罩来改变输入图像中每个像素的alpha值。</p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="nx ny l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">从图像中提取表格并从表格中获取文本数据</figcaption></figure><p id="9f5c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的代码从测试数据中提取一个图像，对两个掩码进行预测，使用表掩码从图像中提取表，并显示所有4个图像，即原始图像、表掩码、列掩码和过滤后的表。它还从表格中提取文本并打印出来。为了从表格中提取文本，我们使用了<a class="ae iu" href="https://pytesseract.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj">pytesserac模块</strong> </a> <strong class="ix hj">。</strong></p><figure class="nt nu nv nw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ox"><img src="../Images/c55eab48f72925b904c53117911d45c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iZq8O2iXddUGzhPXkIzTHA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">使用TableNet进行样本预测和表格提取。</figcaption></figure><p id="9fcc" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">对于上图，从表格中提取的文本如下所示:</p><pre class="nt nu nv nw fd oy oz pa pb aw pc bi"><span id="2f32" class="mm kl hi oz b fi pd pe l pf pg">Aligned Features %Ace_ SE J] Unaligned Feauwses Wrce. _%S.</span><span id="21f6" class="mm kl hi oz b fi ph pe l pf pg">AIKLaws only, AN Eng. | 77.5 07 || HKLaws only, Al Eng. | 77.9 0.8<br/>Features + CKIP Tags Features + CKIP Tags<br/>WSJ + HKLaws, All Eng | 806 06 WSJ + HKLaws, Al Eng. | 762 0.6<br/>eatmres + UPenn VA-Tac Features + Peri. Part.</span><span id="66dd" class="mm kl hi oz b fi ph pe l pf pg">Angnea Unaligned<br/>Change- | Creation 7] All Verbs [Change All Verbs<br/>of-State | Transfor- of State<br/>ation<br/>Features F F Acc. (FE) F F Ace GFE.<br/>Chi. Only 0.77 079° [78.1 (7) 0.82 0.80 S13 (6)<br/>Sng. Only 0.63 0-63 62.5 (12) ‘Aligned — Unaligned<br/>ea 0.80 0.82 81.3 (6) 0.63 0.68 62.5 2)<br/>42 0.58 0.61 59.4 (13) 0.73 0.76 75.0 (8)<br/>+3 0.52 0.55 53.1 (15) 0.80 0.82 81.3 (6)<br/>+12 0.79 0.83 81.3 (6) 0.83 0.86 84-4 (5)<br/>0.48 0.57 53.1 (15) 0.69 65.8 (10)<br/>+13 0.79 0.83 81.3 (6) 0.67 62.5 (12)<br/>+128 0.79 O.8F 81.3 (6) 0.62 0.74 68.8 (101</span></pre><h1 id="34a7" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">在Streamlit上部署</h1><p id="e06d" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">为了部署，使用<a class="ae iu" href="https://streamlit.io/" rel="noopener ugc nofollow" target="_blank"> Streamlit </a>库制作了一个webapp。此处的<a class="ae iu" href="https://github.com/AmanSavaria1402/TableNet/blob/main/app.py" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">代码可用</strong> </a>。</p><p id="d1a5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">部署视频:</p><figure class="nt nu nv nw fd ij"><div class="bz dy l di"><div class="pi ny l"/></div></figure><h1 id="8abd" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">丰富</h1><p id="660e" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">通过增加用于训练模型的数据量，可以提高模型的性能。</p><h1 id="70bd" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">参考</h1><ol class=""><li id="c98e" class="li lj hi ix b iy lk jc ll jg lm jk ln jo lo js lp lq lr ls bi translated"><a class="ae iu" href="https://arxiv.org/abs/2001.01469" rel="noopener ugc nofollow" target="_blank"> TableNet论文</a></li><li id="517d" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated"><a class="ae iu" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">应用人工智能课程</a></li><li id="50c3" class="li lj hi ix b iy lt jc lu jg lv jk lw jo lx js lp lq lr ls bi translated"><a class="ae iu" rel="noopener" href="/analytics-vidhya/tablenet-deep-learning-model-for-end-to-end-table-detection-and-tabular-data-extraction-from-1961fb2f97e1">https://medium . com/analytics-vid hya/tablenet-deep-learning-model-for-end-to-end-table-detection-and-table-data-extraction-from-1961 fb2f 97 e 1</a></li></ol><h1 id="37a0" class="kk kl hi bd km kn ly kp kq kr lz kt ku kv ma kx ky kz mb lb lc ld mc lf lg lh bi translated">联系我</h1><p id="e644" class="pw-post-body-paragraph iv iw hi ix b iy lk ja jb jc ll je jf jg md ji jj jk me jm jn jo mf jq jr js hb bi translated">你可以在<a class="ae iu" href="https://www.linkedin.com/in/amansavaria/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>上和我联系。整个项目的代码可以在我的<a class="ae iu" href="https://github.com/AmanSavaria1402/TableNet" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上找到。</p></div></div>    
</body>
</html>