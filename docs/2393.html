<html>
<head>
<title>Databricks: Setting up A Spark Dataframe for Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据块:为线性回归设置Spark数据框架</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/databricks-setting-up-our-spark-dataframe-for-linear-regression-ba08c880bcd2?source=collection_archive---------5-----------------------#2021-04-21">https://medium.com/analytics-vidhya/databricks-setting-up-our-spark-dataframe-for-linear-regression-ba08c880bcd2?source=collection_archive---------5-----------------------#2021-04-21</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/27bf666d502d5ef7d2edef2a56c5219a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zo5u7_AHnNRIJJnzVPzKuw.png"/></div></div></figure><p id="3c5a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们开始这个有趣的旅程之前，有一个<strong class="is hj">忠告</strong>:这个博客的重点是<strong class="is hj">而不是</strong>清理数据和检查是否满足线性回归的假设(下面简要列出)。相反，重点是如何格式化数据集，以便我们可以使用PySpark将其输入线性回归模型！</p><h1 id="b8fa" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">线性回归的假设</h1><p id="7ffb" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated"><strong class="is hj">线性回归</strong>是一种评估一个或多个特征变量是否能解释目标变量的分析。</p><p id="f118" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">线性回归有5个关键假设</strong>:</p><ul class=""><li id="11d9" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated">线性关系</li><li id="e957" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">多元正态性</li><li id="c215" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">没有或很少多重共线性</li><li id="bb73" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">无自相关</li><li id="f2aa" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">同方差性</li></ul><p id="c46e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您想了解更多关于上述假设的信息，您可以访问<a class="ae lf" href="https://www.statisticssolutions.com/assumptions-of-linear-regression/" rel="noopener ugc nofollow" target="_blank">此链接</a>了解更多信息。既然我们已经解决了这个问题…让我们开始吧！</p><h1 id="0d1a" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">数据砖</h1><p id="b807" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在这篇博客中，我们使用Databricks作为平台，通过PySpark构建我们的线性回归模型。如果你以前没有使用过Databricks，请随意访问我的博客<a class="ae lf" rel="noopener" href="/analytics-vidhya/beginners-guide-on-databricks-spark-using-python-pyspark-de74d92e4885">这里</a>，我会带你快速完成设置！</p><p id="11ff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您已经熟悉Databricks:登录，创建一个新的集群和一个新的笔记本。完成后，只需将集群连接到笔记本电脑:</p><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es lg"><img src="../Images/6fcfa589a27e72d69add6c8d5d2a37ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-lBU3HY3n8FM95SjEZYgCQ.jpeg"/></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">将群集连接到笔记本电脑</figcaption></figure><p id="008f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们将加载一些我们需要访问数据的库。我们将在本博客中使用的数据集将是波士顿房价数据集，我们可以从sklearn.datasets库中加载该数据集:</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="85c0" class="lu jp hi lq b fi lv lw l lx ly">import pyspark<br/>import numpy as np<br/>import pandas as pd<br/>from sklearn.datasets import load_boston</span></pre><p id="b744" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦我们运行了上面的单元格，我们就可以访问数据集了。我们将数据加载到Pandas数据帧中，然后将该数据帧转换为Spark数据帧，这样我们就可以使用Spark的MLlib库进行线性回归。</p><h1 id="0c1c" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤1:将数据集加载到Pandas数据框架中</h1><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="552a" class="lu jp hi lq b fi lv lw l lx ly"># loading an instance of the boston dataset<br/>boston = load_boston()</span><span id="126d" class="lu jp hi lq b fi lz lw l lx ly"># Gathering the features of the dataset<br/>feats = boston.data</span><span id="7c6a" class="lu jp hi lq b fi lz lw l lx ly"># Putting the array of features into a pandas Dataframe<br/>df = pd.DataFrame(feats)</span><span id="9931" class="lu jp hi lq b fi lz lw l lx ly"># Naming the columns of the dataframe their respective feature names<br/>df.columns = boston.feature_names</span><span id="ce4a" class="lu jp hi lq b fi lz lw l lx ly"># Creating a new column in the Dataframe called 'PRICE' that holds <br/># the target values <br/>df['PRICE'] = boston.target</span><span id="eb85" class="lu jp hi lq b fi lz lw l lx ly"># Viewing the df to make sure everything looks okay<br/>df.head()</span></pre><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/2610173c967e714899db0d6f2a227ad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AgxUtEz9n7_GWCeHAsByIw.jpeg"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">查看熊猫数据框的前5行</figcaption></figure><p id="8123" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">太好了，数据框看起来不错！现在我们必须将这个熊猫数据帧转换成Spark数据帧。</p><h1 id="8d2b" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤2:将熊猫数据帧转换成Spark数据帧</h1><p id="aa93" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">要将数据帧转换成Spark数据帧，我们只需运行一行简单的代码:</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="2242" class="lu jp hi lq b fi lv lw l lx ly"># This line will create a spark dataframe from our pandas dataframe<br/>spark_df = spark.createDataFrame(df)</span><span id="b612" class="lu jp hi lq b fi lz lw l lx ly"># Viewing first 5 rows of the spark_df<br/>spark_df.show(5)</span></pre><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mb"><img src="../Images/34cb57bf3a291009d76777e33c1314b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ti_2ipovayojR7EUn2PVkA.jpeg"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">查看火花数据帧的前5行</figcaption></figure><p id="62f1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你比较熊猫数据帧和火花数据帧的前5行，你会发现它们是一样的。到目前为止，一切都在按计划进行…</p><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/0f3baa3d9b67fc237bc067532df8ff61.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/1*7qA2Edu9pL4MQPEbri_ZfA.gif"/></div></figure><h1 id="18dd" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">MLlib和Sklearn线性回归的区别</h1><p id="2666" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在Sci-kit Learn中，每个特性都有自己的列，我们不需要担心对数据帧应用更多的转换。但是，在MLlib中，我们不能为每个特性提供单独的列。MLlib要求一行中特性的所有值都包含在一个数组中，并且它们都位于一个名为“特性”的列中。让我们看一个例子来说明我的意思:</p><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/41f2d962e68c7fa63d36ee70f2ac4fb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kE5BqD8bPzMv613f1HFpQQ.jpeg"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">请注意末尾的“功能”栏</figcaption></figure><p id="ea53" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">“功能”列包含数组。这些数组中的每一个都包含一行中的所有特性值。例如，第一行包含:</p><ul class=""><li id="f9d3" class="kr ks hi is b it iu ix iy jb kt jf ku jj kv jn kw kx ky kz bi translated">卷曲= 0.00632</li><li id="95c9" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">锌= 18.0</li><li id="8a3a" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">印度河= 2.31</li><li id="8ef2" class="kr ks hi is b it la ix lb jb lc jf ld jj le jn kw kx ky kz bi translated">等等。</li></ul><p id="cf5b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了使我们的Spark数据框架与MLlib线性回归模型兼容，我们希望将每行中的所有值压缩到一个数组中，放在一个列中，我们称之为“features”。那么我们该怎么做呢？</p><h1 id="37d1" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">输入:VectorAssembler</h1><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="8ab6" class="lu jp hi lq b fi lv lw l lx ly">from pyspark.ml.feature import VectorAssembler</span></pre><p id="a9d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这项工作我们需要的工具是<strong class="is hj"> PySpark的VectorAssembler </strong>。VectorAssembler所做的是将多个值组合成一个数组(或行向量)；即，其中新生成的列的每个行元素是通过连接来自指定输入列的每个行元素而形成的向量。我们可以通过以下语句在数据帧上实现这一点:</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="b7e1" class="lu jp hi lq b fi lv lw l lx ly"># Creating an instance of the VectorAssembler<br/>assembler = VectorAssembler(inputCols=[‘CRIM’,’ZN’,’INDUS’,’CHAS’,<br/>                                       ’NOX’,’RM’,’AGE’,’DIS’,’RAD’,<br/>                                       ’TAX’,‘PTRATIO’,’B’,’LSTAT’],<br/>                            outputCol=’features’)</span></pre><p id="42b3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了使用VectorAssembler，我们分配一个名为“Assembler”的变量，该变量将引用VectorAssembler的位置。接下来，我们必须传入一个字符串列表，这些字符串是我们希望包含在模型中的特性的列名。这些名字将会出现在分配给<strong class="is hj"> inputCols </strong>参数的列表中。</p><p id="037d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">重要提示:不要包含任何值没有经过StringIndexed或OneHotEncoded的分类列名</strong></p><p id="8dfb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">注意<strong class="is hj">我们没有将目标变量</strong>添加到<strong class="is hj"> inputCols </strong>的列表中。这个VectorAssembler被设计成只接受数据集的独立变量，然后将它们压缩成包含一个值数组的单个列。<strong class="is hj"> outputCol </strong>参数为将要创建的压缩列指定一个名称—我建议将其命名为‘features’(这是许多MLlib模型用来标识特性列的默认名称)。要转换我们的Spark数据框架:</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="7f4a" class="lu jp hi lq b fi lv lw l lx ly"># transforming our spark dataframe<br/>df_out = assembler.transform(spark_df)</span><span id="231b" class="lu jp hi lq b fi lz lw l lx ly"># Viewing the first 5 rows<br/>df_out.show(5)</span></pre><figure class="lh li lj lk fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/41f2d962e68c7fa63d36ee70f2ac4fb0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kE5BqD8bPzMv613f1HFpQQ.jpeg"/></div></div></figure><p id="6da5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要为线性回归模型定型的唯一列是“功能”和“价格”列。让我们创建一个只包含这些列的新spark数据框架:</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="f7c4" class="lu jp hi lq b fi lv lw l lx ly"># While we could say something like this...<br/>clean_df = df_out.select(['features', 'PRICE'])</span><span id="5a74" class="lu jp hi lq b fi lz lw l lx ly"># I want to rename the 'PRICE' column to 'label' as well<br/>clean_df = df_out.select([‘features’, col(‘PRICE’).alias(‘label’)])</span><span id="659a" class="lu jp hi lq b fi lz lw l lx ly">clean_df.show(5)</span></pre><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es me"><img src="../Images/419ed23dcc3613061c3a7e398fd57852.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*UGDb0LyUDZ59FNZwHj0YRQ.jpeg"/></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">漂亮整洁</figcaption></figure><h1 id="cad4" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">创建训练集和测试集</h1><p id="3454" class="pw-post-body-paragraph iq ir hi is b it km iv iw ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn hb bi translated">在用数据拟合模型之前，我们的最后一步是:我们必须创建训练集和测试集！简而言之，在对数据建模时，训练集和测试集是极其重要的。如果你碰巧有一个R平方的分数，比如说… 0.99(非常高)，并且没有其他数据来验证这个分数，你怎么知道你的模型是否过度拟合？简单来说，你不会。如果你想知道更多关于建立训练集和测试集(以及验证集)的重要性。)随意查看<a class="ae lf" href="https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7" rel="noopener" target="_blank">这篇文章</a>。让我们继续创建我们的训练集和测试集吧！</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="19e9" class="lu jp hi lq b fi lv lw l lx ly"># Creating our train and test sets<br/>train, test = clean_df.randomSplit([0.7, 0.3], seed=42)</span></pre><p id="07b4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Spark数据帧有一个名为randomSplit()的内置方法，允许我们直接从Spark数据帧创建训练集和测试集。上面，我们说“将clean_df随机分成70%和30%的块，分别进入训练和测试集，并将随机种子设置为42。我们的下一步是创建和拟合一个线性回归模型。</p><h1 id="f7c9" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">创建线性回归模型</h1><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="dd34" class="lu jp hi lq b fi lv lw l lx ly">from pyspark.ml.regression import LinearRegression</span></pre><p id="bc85" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第一步是创建LinearRegression()模型的实例:</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="400d" class="lu jp hi lq b fi lv lw l lx ly"># creating an instance of a linear regression model<br/>lr_model = LinearRegression(featuresCol=’features',labelCol=’label’)</span></pre><p id="2bc9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">默认情况下，线性回归模型假定featuresCol和labelCol的名称分别为“features”和“label”。只要要素被正确格式化为一列，并且标注列也存在，那么它们的名称是什么并不重要(例如。如果您将标签列的名称保留为“PRICE”，那么label col =“PRICE”)。接下来，我们让模型适合我们的列车组:</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="eb9a" class="lu jp hi lq b fi lv lw l lx ly"># fitting the model to the train set<br/>fit_model = lr_model.fit(train)</span></pre><p id="c399" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们终于可以评估我们模型的性能了！我们将创建一个名为“test_results”的新变量，它将保存我们的测试集的评估结果。这实质上是模型在测试集上的性能总结:</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="40ec" class="lu jp hi lq b fi lv lw l lx ly">test_results = fit_model.evaluate(test)</span></pre><p id="b4fe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要访问像R平方这样的值，我们可以说:</p><pre class="lh li lj lk fd lp lq lr ls aw lt bi"><span id="236e" class="lu jp hi lq b fi lv lw l lx ly">test_results.r2</span></pre><figure class="lh li lj lk fd ij er es paragraph-image"><div class="er es mf"><img src="../Images/5db0182f20fa82384af0437afe408fd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*eVPMw_t8jZUjlvkj6IEi4w.jpeg"/></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">我们的测试集的r平方结果</figcaption></figure><p id="bc8b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请记住<strong class="is hj">这篇博客的目的是让我们的数据集被正确格式化，以便它可以与MLlib的线性回归</strong>一起使用。在浏览这篇博客时，我们没有检查或清理任何数据，也没有检查是否违反了线性回归的任何假设。非常感谢您的阅读！如果你有任何问题，请随时提问！</p></div></div>    
</body>
</html>