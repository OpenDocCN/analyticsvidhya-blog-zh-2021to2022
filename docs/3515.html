<html>
<head>
<title>OhMyGraphs: GraphSAGE in PyG</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">oh my graphs:PyG中的GraphSAGE</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ohmygraphs-graphsage-in-pyg-598b5ec77e7b?source=collection_archive---------0-----------------------#2021-07-06">https://medium.com/analytics-vidhya/ohmygraphs-graphsage-in-pyg-598b5ec77e7b?source=collection_archive---------0-----------------------#2021-07-06</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ea3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在之前的一篇文章中，我描述了一个基本的图形神经网络(GNN)算法GraphSAGE背后的直觉和一些数学。我们如何为实际任务实现GraphSAGE？</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/a60eb0d66be164b91197e47e97a7c4f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DQsnhJnirljBS31s.png"/></div></div></figure><p id="6c30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我是PyTorch的人，PyG是我在GNN实验中的助手。对于更大的图形，<a class="ae jd" href="https://www.dgl.ai/" rel="noopener ugc nofollow" target="_blank"> DGL </a>可能是更好的选择，好消息是他们有PyTorch后端！</p><p id="b38c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您以前使用过PyTorch，那么大部分都很直观，所以让我们开始吧！</p><h1 id="ad27" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">安装</strong></h1><p id="c25f" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">PyG正在快速开发中，新的发布也很频繁。我发现每当有新的发布时，我总是与各种需要的包有某种冲突。下面是我在这个笔记本上使用的版本。你可以用<code class="du kt ku kv kw b">pip</code>或<code class="du kt ku kv kw b">conda</code>安装，但要注意选择正确的设备版本:即<code class="du kt ku kv kw b">cuda10</code>、<code class="du kt ku kv kw b">cuda9</code>或<code class="du kt ku kv kw b">cpu</code>。文档中的安装说明在此处为<a class="ae jd" href="https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html" rel="noopener ugc nofollow" target="_blank"/>。</p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="10c2" class="lb jr hi kw b fi lc ld l le lf">torch                         1.8.0<br/>torch-cluster                 1.5.9<br/>torch-geometric               1.7.0<br/>torch-scatter                 2.0.6<br/>torch-sparse                  0.6.9<br/>torch-spline-conv             1.2.1</span></pre><h1 id="1d0b" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated"><strong class="ak">卷积层</strong></h1><p id="f23c" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">图卷积的目标是改变图中每个节点的特征空间。重要的是要认识到图<em class="lg">的结构</em>并没有改变ie，在下面的前后视觉中，相同的节点是相互连接的。图形卷积背后的神奇之处在于如何为每个节点计算新特征。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lh"><img src="../Images/56c5a98a24615ee6435408a1f223038e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OAzS46ZMJq2qm6vBlERqWg.png"/></div></div></figure><p id="fcbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PyG有各种类型的卷积层；在本帖中，我们将简单地回顾一下SAGEConv层，它是聚合和更新步骤的一个迭代。)。您可以通过简单地指定预期的输入和输出要素形状来实例化一层图形卷积，这与PyTorch中的普通卷积非常相似。</p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="eee2" class="lb jr hi kw b fi lc ld l le lf">from torch_geometric.nn import SAGEConv<br/>conv = SAGEConv(input_dim, output_dim)</span></pre><p id="e663" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">向前通过卷积层需要两样东西，节点特征矩阵，<strong class="ih hj"> X </strong>和<strong class="ih hj">邻接矩阵。</strong></p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="de67" class="lb jr hi kw b fi lc ld l le lf">x = conv(data.x, data.adj_t)</span></pre><p id="97c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">回想一下，<strong class="ih hj"> X </strong>矩阵是一个<strong class="ih hj"> (n x D) </strong>矩阵，其中<strong class="ih hj"> D </strong>是图中每个节点的维度。或者，如果你不能创建一个邻接矩阵(因为它们会随着大量的节点而爆炸！)，可以使用边缘列表。<strong class="ih hj">边缘列表</strong>预期是一个<strong class="ih hj">(2×n)</strong>矩阵，其中矩阵的第一行代表源节点，第二行代表目标节点。</p><h2 id="6e4b" class="lb jr hi bd js li lj lk jw ll lm ln ka iq lo lp ke iu lq lr ki iy ls lt km lu bi translated">引擎盖下发生了什么？</h2><p id="b91c" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated"><code class="du kt ku kv kw b">SAGEConv</code>的默认聚合函数是均值聚合，也就是说，我将获取我的相邻结点要素并对它们进行平均(这是第二个术语)。更新步骤只是邻居表示和新变换的当前节点表示的线性组合(第一项)。PyG处理消息传递并计算出每个节点<em class="lg"> i </em>等的邻居。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lv"><img src="../Images/16115f21d1d9bacfa75d07e88deb89f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*XiBebokpG43VlX2p8C0Orw.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">SAGEConv方程(参见<a class="ae jd" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SAGEConv" rel="noopener ugc nofollow" target="_blank">文档</a>)</figcaption></figure><h1 id="ae3d" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">创建模型</h1><p id="2156" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">GraphSAGE模型只是一堆堆叠在一起的<code class="du kt ku kv kw b">SAGEConv</code>层。下面的模型有3层卷积。在forward方法中，您会注意到我们可以添加激活层和dropout(您甚至可以加入一些批处理规范！)</p><p id="451a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的模型是训练一个<strong class="ih hj">节点分类</strong>模型。该模型有效地尝试使模型的最后一层具有与数据集中的类相同数量的神经元。在末尾添加一个softmax可以训练模型为每个节点输出最可能的类。</p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="0b92" class="lb jr hi kw b fi lc ld l le lf">class GraphSAGE(torch.nn.Module):<br/>    def __init__(self, in_dim, hidden_dim, out_dim, dropout=0.2):<br/>        super().__init__()<br/>        self.dropout = dropout<br/>        self.conv1 = SAGEConv(in_dim, hidden_dim)<br/>        self.conv2 = SAGEConv(hidden_dim, hidden_dim)<br/>        self.conv3 = SAGEConv(hidden_dim, out_dim)<br/>    <br/>    def forward(self, data):<br/>        x = self.conv1(data.x, data.adj_t)<br/>        x = F.elu(x)<br/>        x = F.dropout(x, p=self.dropout)<br/>        <br/>        x = self.conv2(x, data.adj_t)<br/>        x = F.elu(x)<br/>        x = F.dropout(x, p=self.dropout)<br/>        <br/>        x = self.conv3(x, data.adj_t)<br/>        x = F.elu(x)<br/>        x = F.dropout(x, p=self.dropout)<br/>        return torch.log_softmax(x, dim=-1)</span></pre><p id="b0df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意，我称这个模型为<code class="du kt ku kv kw b">GraphSAGE</code>，但是原始文件的conv层的设置，激活等在这里<a class="ae jd" href="https://arxiv.org/abs/1706.02216" rel="noopener ugc nofollow" target="_blank">描述</a>。这个模型唯一“明智”的地方是<code class="du kt ku kv kw b">SAGEConv</code>层。</p><h1 id="d628" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">数据集</h1><p id="9a41" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">我没有过多地谈论数据集，因为GNNs中的许多研究都使用PyG中可用的标准数据集。毫无疑问，没有什么可以阻止你创建一个自定义数据集，但这是另一天的另一篇文章(尤其是当你有一个大图的时候！).在这个例子中，我将使用打包在<a class="ae jd" href="https://ogb.stanford.edu/" rel="noopener ugc nofollow" target="_blank"> OGB </a>中的数据集。要将此加载到您的笔记本中，请确保<code class="du kt ku kv kw b">pip install ogb</code>。</p><p id="a872" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的代码片段从<code class="du kt ku kv kw b">ogb</code>加载了一个亚马逊产品数据集。</p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="eccd" class="lb jr hi kw b fi lc ld l le lf">import torch<br/>import torch_geometric.transforms as T<br/>from ogb.nodeproppred import PygNodePropPredDataset</span><span id="04fe" class="lb jr hi kw b fi ma ld l le lf">device = f'cuda' if torch.cuda.is_available() else 'cpu'<br/>device = torch.device(device)</span><span id="0514" class="lb jr hi kw b fi ma ld l le lf">dataset = PygNodePropPredDataset(name='ogbn-products',<br/>                                 transform=T.ToSparseTensor())<br/>data = dataset[0]</span><span id="7b55" class="lb jr hi kw b fi ma ld l le lf"># this dataset comes with train-val-test splits predefined for benchmarking<br/>split_idx = dataset.get_idx_split()<br/>train_idx = split_idx['train'].to(device)</span></pre><p id="52e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">关于数据集的一些基本信息打包在<code class="du kt ku kv kw b">data</code>对象中:</p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="5160" class="lb jr hi kw b fi lc ld l le lf">print(f' dataset has {data.num_nodes} nodes where each node has a {data.num_node_features} dim feature vector')</span><span id="7abc" class="lb jr hi kw b fi ma ld l le lf">print(f' dataset has {data.num_edges} edges where each edge has a {data.num_edge_features} dim feature vector')</span><span id="15a5" class="lb jr hi kw b fi ma ld l le lf">print(f' dataset has {dataset.num_classes} classes')</span></pre><p id="f066" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个特殊的数据集(训练、val和测试索引)是为我们分离出来的。</p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="fd4e" class="lb jr hi kw b fi lc ld l le lf">print(split_idx['train'].shape)<br/>print(split_idx['valid'].shape)<br/>print(split_idx['test'].shape)</span></pre><p id="20fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">邻接矩阵预先填充在<code class="du kt ku kv kw b">data.adj_t</code>中，它是一个<code class="du kt ku kv kw b">SparseTensor </code>矩阵，因为它在形状上是<code class="du kt ku kv kw b">n x n</code>，这是巨大的，因为有～2M节点！</p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="b115" class="lb jr hi kw b fi lc ld l le lf">SparseTensor(row=tensor([      0,       0,       0,  ..., 2449028, 2449028, 2449028]),<br/>             col=tensor([    384,    2412,    7554,  ..., 1787657, 1864057, 2430488]),<br/>             size=(2449029, 2449029), nnz=123718280, density=0.00%)</span></pre><h1 id="16c6" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">培养</h1><p id="eb67" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">当我第一次开始玩GNNs时，我觉得在train循环中我们总是传递整个图很奇怪——我们必须传递整个图，因为我们需要完整的结构来计算聚合和更新步骤。但是，由于我们需要在一组特定的节点上<em class="lg">训练</em>并在另一组节点上进行验证/测试，我们只需用我们的训练/验证/测试集中的节点索引来屏蔽我们想要的梯度！</p><p id="6c04" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">附注:以下代码是从马蒂亚斯·菲的<a class="ae jd" href="https://github.com/snap-stanford/ogb/tree/master/examples/nodeproppred/products" rel="noopener ugc nofollow" target="_blank"> ogb </a>提交中窃取的！</p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="e0e1" class="lb jr hi kw b fi lc ld l le lf"># compute activations for train subset<br/>out = model(data)[train_idx]</span><span id="5edd" class="lb jr hi kw b fi ma ld l le lf"># get gradients for train subset<br/>loss = F.nll_loss(out, data.y.squeeze(1)[train_idx])</span><span id="8aee" class="lb jr hi kw b fi ma ld l le lf"># evaluate model on test set<br/>out = model(data)[test_idx]</span></pre><p id="5f0a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个<code class="du kt ku kv kw b">ogb</code>数据集，<code class="du kt ku kv kw b">train</code>和<code class="du kt ku kv kw b">test</code>函数可以这样打包:</p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="78d8" class="lb jr hi kw b fi lc ld l le lf">def train(model, data, train_idx, optimizer):<br/>    model.train()</span><span id="4c7e" class="lb jr hi kw b fi ma ld l le lf">    optimizer.zero_grad()<br/>    out = model(data)[train_idx]<br/>    loss = F.nll_loss(out, data.y.squeeze(1)[train_idx])<br/>    loss.backward()<br/>    optimizer.step()</span><span id="4d38" class="lb jr hi kw b fi ma ld l le lf">return loss.item()</span><span id="2e39" class="lb jr hi kw b fi ma ld l le lf"><a class="ae jd" href="http://twitter.com/torch" rel="noopener ugc nofollow" target="_blank">@torch</a>.no_grad()<br/>def test(model, data, split_idx, evaluator):<br/>    model.eval()</span><span id="5d5a" class="lb jr hi kw b fi ma ld l le lf">    out = model(data)<br/>    y_pred = out.argmax(dim=-1, keepdim=True)</span><span id="262f" class="lb jr hi kw b fi ma ld l le lf">    train_acc = evaluator.eval({<br/>        'y_true': data.y[split_idx['train']],<br/>        'y_pred': y_pred[split_idx['train']],<br/>    })['acc']<br/>    valid_acc = evaluator.eval({<br/>        'y_true': data.y[split_idx['valid']],<br/>        'y_pred': y_pred[split_idx['valid']],<br/>    })['acc']<br/>    test_acc = evaluator.eval({<br/>        'y_true': data.y[split_idx['test']],<br/>        'y_pred': y_pred[split_idx['test']],<br/>    })['acc']</span><span id="075d" class="lb jr hi kw b fi ma ld l le lf">    return train_acc, valid_acc, test_acc</span></pre><p id="46bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du kt ku kv kw b">ogb</code>附带一个<code class="du kt ku kv kw b">Evaluator</code>来帮助对输出预测评分。</p><pre class="jf jg jh ji fd kx kw ky kz aw la bi"><span id="cc74" class="lb jr hi kw b fi lc ld l le lf">lr = 1e-4 <br/>epochs = 50 <br/>hidden_dim = 75<br/>evaluator = Evaluator(name='ogbn-products')</span><span id="2960" class="lb jr hi kw b fi ma ld l le lf">model = GraphSAGE(in_dim=data.num_node_features, <br/>                 hidden_dim=hidden_dim, <br/>                 out_dim=dataset.num_classes)</span><span id="22f1" class="lb jr hi kw b fi ma ld l le lf">optimizer = torch.optim.Adam(model.parameters(), lr=lr)</span><span id="4874" class="lb jr hi kw b fi ma ld l le lf">for epoch in range(1, 1 + epochs):<br/>    loss = train(model, data, train_idx, optimizer)<br/>    result = test(model, data, split_idx, evaluator)<br/>    #logger.add_result(run, result)</span><span id="da5d" class="lb jr hi kw b fi ma ld l le lf">if epoch % 10 == 0:<br/>        train_acc, valid_acc, test_acc = result<br/>        print(f'Epoch: {epoch}/{epochs}, '<br/>              f'Loss: {loss:.4f}, '<br/>              f'Train: {100 * train_acc:.2f}%, '<br/>              f'Valid: {100 * valid_acc:.2f}% '<br/>              f'Test: {100 * test_acc:.2f}%')</span></pre><h1 id="1271" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">TL，DR:在PyG快速构建GNNs是ez！</h1><p id="5356" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">此外，如果您想试验<code class="du kt ku kv kw b"><a class="ae jd" rel="noopener" href="/@nabila.abraham/ohmygraphs-graph-attention-networks-b7562289ae4b">GAT</a></code>或其他类型的卷积层，这将(在很大程度上)是一个简单的换入换出场景。点击查看文档<a class="ae jd" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers" rel="noopener ugc nofollow" target="_blank">中的其他可用图层。</a></p><p id="37d7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">完整的笔记本脚本可以在这里<a class="ae jd" href="https://github.com/nabsabraham/ohmygraphs/blob/master/ogb_sage.ipynb" rel="noopener ugc nofollow" target="_blank">获得</a>，尽管它主要是马蒂亚斯<a class="ae jd" href="https://github.com/snap-stanford/ogb/tree/master/examples/nodeproppred/products" rel="noopener ugc nofollow" target="_blank">代码</a>的分解版本。</p></div></div>    
</body>
</html>