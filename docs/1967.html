<html>
<head>
<title>Detection and Semantic Segmentation of Pneumothorax Disease from X-Ray Images using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用深度学习从X射线图像中检测和语义分割气胸疾病</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/detection-and-semantic-segmentation-of-pneumothorax-disease-from-x-ray-images-using-deep-learning-890bbfcb5bd6?source=collection_archive---------5-----------------------#2021-03-29">https://medium.com/analytics-vidhya/detection-and-semantic-segmentation-of-pneumothorax-disease-from-x-ray-images-using-deep-learning-890bbfcb5bd6?source=collection_archive---------5-----------------------#2021-03-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="9c39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">建立二值图像分类模型，检测图像是否包含气胸。如果是，则通过语义分割模型来识别和标记受影响的部分。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/37526434cf3d0b618e77be1cafe2840f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H2Q6DGutG8AYqGxEcGekVw.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">来源:https://www.svhlunghealth.com.au/conditions/pneumothorax</figcaption></figure><p id="582e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">目录:<br/> </strong> 1。简介<br/> 2。气胸疾病的种类<br/> 3。症状<br/> 4。诊断<br/> 5。商业问题<br/> 6。DL公式<br/> 7。业务约束<br/> 8。数据集列分析<br/> 9。绩效指标<br/> 10。探索性数据分析<br/> 11。我的车型中的现有方法和改进<br/> 12。数据预处理<br/> 13。深度学习模型<br/> 14。最终数据管线<br/> 15。错误分析<br/> 16。未来的工作。LinkedIn和GitHub知识库<br/> 18。参考</p><h1 id="6094" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">1.简介:</h1><p id="f703" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated"><strong class="ig hi">什么是气胸病？<br/> </strong>气胸是指由于空气进入肺部周围的空间(称为胸膜空间)而导致肺部塌陷。在一个健康的身体里，肺接触胸腔的壁。空气可以通过胸壁或肺部的开口进入胸膜腔。胸膜腔中的空气使肺周围的压力增加，导致肺萎陷。肺可能完全萎陷，但最常见的是只有一部分萎陷。这种虚脱也会对心脏造成压力，导致进一步的症状。</p><p id="28d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">气胸可能很严重，这取决于胸膜腔中滞留了多少空气。如果没有其他并发症，少量滞留的空气通常可以自行消失。如果不进行医疗处理，大量滞留的空气可能会很严重并导致死亡。</p><h1 id="9d6a" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">2.气胸疾病的类型</h1><p id="4dc9" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">观察到的气胸主要有4种类型。</p><p id="c092" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> a)原发性自发性:<br/> </strong>原发性自发性气胸(PSP)好发于没有任何肺部病史的年轻人(15-34岁)。PSP的直接原因不明。处于危险中的人包括吸烟者、高个子男人和那些有家庭成员患气胸的人。</p><p id="64c4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。继发性自发性:<br/> </strong>继发性自发性气胸(SSP)可由多种肺部疾病(如慢性阻塞性肺疾病、囊性纤维化、肺结核、肺炎、肺癌、结节病、肺纤维化或囊性肺部疾病)和组织障碍(如马凡氏综合征)引起。SSP比PSP携带更严重的症状，它更有可能导致死亡。</p><p id="8750" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。<br/> </strong>创伤性气胸:创伤性气胸是由于撞击或损伤造成的。潜在的原因包括钝性创伤或损伤胸壁和胸膜空间。发生这种情况最常见的方式之一是有人折断了一根肋骨。碎骨的尖端会刺穿胸壁并损伤肺组织。其他原因包括运动损伤、车祸、穿刺或刺伤。</p><p id="15ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 4。张力性气胸:<br/> </strong>张力性气胸是由于胸膜间隙出现类似单向活瓣的渗漏引起的。当一个人吸气时，空气漏入胸膜空间并被截留。呼气时不能释放。这一过程导致胸膜腔内气压增加，危及生命，需要立即治疗。</p><h1 id="d7f0" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">3.症状:</h1><p id="df70" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">a)呼吸急促<br/> b)心率异常加快(称为心动过速)<br/> c)胸痛，一侧胸部可能更严重<br/> d)吸气时剧痛<br/> e)皮肤或嘴唇发蓝变色<br/> f)出冷汗<br/>有些气胸病例几乎没有任何症状。这些只能通过x光或其他类型的扫描来诊断。</p><h1 id="1150" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">4.诊断:</h1><p id="1348" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">气胸的诊断通常通过<strong class="ig hi">胸部x光</strong>来完成，该x光拍摄图像以检测胸膜空间(肺部周围的区域)中空气的存在。CT扫描和胸部超声波也可以用来帮助诊断气胸。<br/>然后，医生(放射科医师)检查X射线报告以诊断气胸和受影响的区域。</p><h1 id="dc7e" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">5.业务问题:</h1><p id="71da" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">气胸通常由医生或放射科医师通过胸部x光检查发现。但是这需要手工操作。由于当前的成像量非常大，所以检查每一幅图像并准备一份报告需要很长时间。如果没有及早发现，气胸会由于肺萎陷和呼吸或循环窘迫而导致危及生命的紧急情况。</p><p id="a02b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的目标是建立一个自动的方法来预测气胸的X射线并分割受影响的区域。这将有助于优先治疗气胸患者。自动图像分割可以以更高的准确率辅助医生进行疾病的治疗和诊断，加快诊断过程，提高效率。</p><h1 id="10e1" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">6.DL公式:</h1><p id="cef8" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">由于我们有气胸和没有气胸的图像，我们将首先建立分类模型，然后建立语义分割模型。<br/> <strong class="ig hi"> a)分类模型:</strong> <br/>先建立二值图像分类模型，预测图像是否包含气胸。我将使用给定的图像和类别标签来训练我的分类模型。<br/> <strong class="ig hi"> b)语义分割模型:<br/> </strong>我们的任务是预测受气胸影响的面罩。这是一个语义切分问题。如果分类模型预测到阳性结果，那么将图像通过另一个语义分割模型来标记气胸影响区域。我将使用给定的图像和RLE面具来训练我的模型。</p><p id="844c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">什么是图像分割？<br/> </strong>图像分割是一项任务，我们将图像的像素值分类为属于特定的对象类。因此，基于对这些像素进行分类的方式，大致有两种类型的分割。<br/> <strong class="ig hi"> I) </strong>语义切分和<strong class="ig hi"> II) </strong>实例切分。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kw"><img src="../Images/738f667c5ac3d541c46888f5cbc02543.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YzDx4ZKI2WDFetUvMCzT5A.jpeg"/></div></div></figure><p id="1638" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> I)语义分割:<br/> </strong>在语义分割中，每一个像素都属于一个特定的类(背景或人物)。此外，属于特定类的所有像素都用相同的颜色表示(背景为黑色，人物为粉红色)。</p><p id="eb11" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> II)实例分割:<br/> </strong>在实例分割中每个像素也属于一个特定的类。然而，同一类别的不同对象具有不同的颜色，即不同的类别标签(人1为红色，人2为绿色，背景为黑色，等等。).</p><p id="027e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如前所述，我们的问题是语义分割问题，我们必须预测每个像素，无论是掩模还是背景。</p><h1 id="9eec" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">7.业务限制:</h1><p id="8ce1" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">a)对于这个问题没有这样的延迟限制，但是模型应该在几分钟内预测。<br/> b)随着类别标签预测，模型应该分割气胸影响区域。</p><h1 id="734e" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">8.数据集列分析:</h1><p id="4f29" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated"><strong class="ig hi">数据来源:</strong>数据集在Kaggle的网站上给出。请找到下面的链接。</p><div class="kx ky ez fb kz la"><a href="https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation/data" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hi fi z dy lf ea eb lg ed ef hg bi translated">SIIM-阿克尔气胸分割法</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">在胸片中识别气胸疾病</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">www.kaggle.com</p></div></div><div class="lj l"><div class="lk l ll lm ln lj lo jm la"/></div></div></a></div><div class="kx ky ez fb kz la"><a href="https://www.kaggle.com/seesee/siim-train-test" rel="noopener  ugc nofollow" target="_blank"><div class="lb ab dw"><div class="lc ab ld cl cj le"><h2 class="bd hi fi z dy lf ea eb lg ed ef hg bi translated">SIIM _火车_测试</h2><div class="lh l"><h3 class="bd b fi z dy lf ea eb lg ed ef dx translated">Kaggle是世界上最大的数据科学社区，拥有强大的工具和资源来帮助您实现您的数据…</h3></div><div class="li l"><p class="bd b fp z dy lf ea eb lg ed ef dx translated">www.kaggle.com</p></div></div><div class="lj l"><div class="lp l ll lm ln lj lo jm la"/></div></div></a></div><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lq"><img src="../Images/30585ad97680987d90899e67774e2740.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oZXPvyd8SC3jAzC4irg02g.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated"><strong class="bd jv">给定数据集</strong></figcaption></figure><p id="d9b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">给定的数据由ImageId和EncodedPixels组成。对于每个ImageId，我们都有一个DICOM格式的图像。具有'-1 '值的编码像素表示图像没有气胸。气胸的图像具有游程编码(RLE)格式的掩模。我们必须解码并制作面具。</p><h1 id="cd92" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">9.绩效指标:</h1><p id="ab3c" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated"><strong class="ig hi"> a)分类模型:<br/> </strong>我将基于<strong class="ig hi">“召回”</strong>来衡量分类模型的性能。在气胸检测问题中，将阴性气胸预测为阳性是可以的，因为当它将被传递到下一个分割模型时，很可能它将预测空白掩模。但是，如果阳性病例被检测为阴性，则它甚至不会通过分割模型，患者将遭受痛苦。<br/>由于这是一个二元分类问题，所以我将<strong class="ig hi">“二元_交叉熵”</strong>作为损失函数。</p><p id="adcd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> b)分割模型:<br/> </strong>我已经给了图像和蒙版。我必须使用这些数据训练一个模型，并预测测试数据的掩码。所以，这是一个语义图像分割问题。<br/>在这个语义图像分割问题中，我将基于<strong class="ig hi">“IOU得分”</strong>来衡量模型的性能。我将使用“二元交叉熵”和“骰子损失”的组合<strong class="ig hi"/>作为损失函数。这些术语解释如下。</p><p id="02ab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">一、并集上的交集(IoU)得分:<br/> </strong>并集上的交集(IoU)指标，也称为Jaccard指数。这是一种量化目标遮罩和我们的预测输出之间的重叠百分比的方法。这一指标与Dice系数密切相关。<br/>IoU度量测量目标和预测掩码之间共有的像素数除以两个掩码中存在的像素总数。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lr"><img src="../Images/cfe020df59ebb65754b37e0f35aa7707.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/0*EnmgImGE6M69JyI7.jpg"/></div></figure><p id="40ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">二。逐像素交叉熵损失:<br/> </strong>该损失单独检查每个像素，将类别预测(逐深度像素向量)与我们的独热编码目标向量进行比较。<br/>像素损失计算为所有可能类别的对数损失总和。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ls"><img src="../Images/944be9e387e8e271840de937883532fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xnKm4Fhf_oTJkobf.jpg"/></div></div></figure><p id="eb18" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">三。骰子损失:<br/>骰子损失= 1-骰子系数</strong> <br/>其中骰子系数(D)= 1</p><div class="jd je jf jg fd ab cb"><figure class="lt jh lu lv lw lx ly paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/6675b3daf2ba6866c45b0867d883b1fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*tFdAwXerycv7rcHwtEq49g.jpeg"/></div></figure><figure class="lt jh lz lv lw lx ly paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/da33b2ebf9b1515f11d32545bf426d88.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*y9V50q0ys-xHT652YdmUTw.jpeg"/></div></figure></div><p id="c0fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里，pi =预测像素值。<br/> gi = groung真实像素值。<br/>在图像分割场景中，pi和gi的值不是0就是1。<br/> 1 →像素是边界<br/> 0 →像素不是边界<br/>在dice系数中，<br/>分子→ 2 *正确预测的边界像素之和。(当pi和gi都为1) <br/>分母→预测和地面真实的总边界像素之和。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ma"><img src="../Images/c2b1ffc9de54f7dbeb55096b11dc4f3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*b5bzq29pO5j2GAf9.jpg"/></div></div></figure><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><h1 id="6e51" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">10.探索性数据分析:</h1><p id="3503" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">首先，对给定的数据执行一些基本的数据清理操作。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es md"><img src="../Images/dbce99003beb4c8368f99b9196ca2fd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1382/format:webp/1*Hpjxa6-Klis5xWAYR6p23w.jpeg"/></div></figure><p id="0c47" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在12954个图像id中，有12047个是唯一的。意思是有重复的。因此，我必须删除重复的图像id。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="026a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图像以DICOM格式给出。我们必须从EDA的元数据中提取信息。样本图像的元数据打印如下:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es me"><img src="../Images/d0aa6f87522d4c87f1373fb6344c8f05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tte_cYiJAeuUcml68Wo4nA.jpeg"/></div></div></figure><p id="9e99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">从元数据中提取一些信息:</strong>提取每张给定图像的年龄、性别、形态、身体部位和观看位置。我将把这些数据用于EDA。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="2ae2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> a)分类标签的分布:</strong></p><p id="f601" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果图像的RLE掩模场是“-1”，那么这是阴性气胸，否则是阳性气胸。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mf"><img src="../Images/43721d142a72c9d762a24039c1aac408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a1fUlvURP9dojeXUs5f7xA.jpeg"/></div></div></figure><p id="760f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">观察:<br/> </strong>这是一个不平衡的数据集。其中77.85%无气胸，22.15%有气胸。</p><p id="cded" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> b)性别分布:</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mg"><img src="../Images/5049265aaf999f6390500aa211b8c2fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CJumop-TbmXZG_G9WNIhIg.jpeg"/></div></div></figure><p id="29c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">观察:<br/> </strong>在给定的数据集中，男性患者占55%，女性患者占45%。</p><p id="d7a4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> c)性别分布和等级标签:</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mh"><img src="../Images/0d1277cd66bcbce8359008d12dc3d65f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tFUCiKbqJXgYkbS1kvy30Q.jpeg"/></div></div></figure><p id="9b58" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">观察:<br/> </strong>男性患者无气胸占77.53%，有气胸占22.47%，女性患者无气胸占78.23%，有气胸占21.77%。男性和女性患者的气胸分布几乎相似。</p><p id="ca96" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> d)视图位置分布:</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mi"><img src="../Images/c2719ac3a41807d9877dd7e8935c241c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R2xa3Siu8PUp9kbhARts7w.jpeg"/></div></div></figure><p id="e78e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">后前位视图(PA):<br/></strong>x射线源的位置应确保x射线束通过胸部的后(背)面进入，并从前(前)面射出，在此处对射线束进行检测。<br/> <strong class="ig hi">前后位视图(AP):<br/></strong>x射线源和探测器颠倒:x射线束从胸部前侧进入，从胸部后侧退出。AP胸透比PA胸透更难阅读，因此通常用于患者难以获得普通胸透的情况，例如当患者卧床不起时。</p><p id="575f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">观察:<br/> </strong>数据集中60.38%的图像视点位置为PA，39.62%的图像视点位置为AP。</p><p id="740f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> e)不同类别标签的患者年龄分布:</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mj"><img src="../Images/e9f4fa028e6c36c87e501151128b453d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lQSSzzF1IBpyHTTtZhf0jA.jpeg"/></div></div></figure><p id="e958" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">观察:<br/></strong>a)0–6岁和90–100岁以内的患者，没有气胸。<br/> b)对于16岁以下的患者，气胸计数多于无气胸。</p><h1 id="abd9" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">11.我的模型中的现有方法和改进:</h1><p id="bdda" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">在现有的方法中，所有的图像及其相应的掩模(如果掩模不可用，则传递空白掩模)被直接用于分割模型中来训练模型。对于预测，x射线图像被输入到模型中以获得预测的掩模。如果图像不包含气胸，它将显示一个空白掩模，否则它将标记并显示受影响的区域。</p><p id="9ecc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于78%的给定图像不包含气胸，所以我将解决方案分成两部分:<br/> <strong class="ig hi"> a)分类:</strong>首先，我将使用预先训练的模型和迁移学习来建立二值图像分类模型，以将图像分类为阳性气胸或阴性气胸。我将使用图像及其类别标签来训练分类模型。<br/> <strong class="ig hi"> b)分割:</strong>我会建立一个图像分割模型来分割气胸患区。我将只使用包含气胸的图像和它们相应的掩模来训练分割模型。我将使用UNET架构和DenseNet121作为图像分割的编码器。如果分类模型预测为阳性气胸，则图像将通过分割模型进行掩模预测。</p><h1 id="669a" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">12。数据预处理:</h1><p id="84de" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated"><strong class="ig hi"> a)解码dicom格式给出的图像:</strong>数据集中给出的图像是DICOM格式。我们不能在模型中直接使用它们。我必须解码图像以适合我们的模型。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="56ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> b)将RLE转换为png掩码:<br/> </strong>掩码以游程编码(RLE)格式给出。我们必须把RLE转换成巴布亚新几内亚的面具。组织者给出的下面的函数将RLE转换成面具。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="3f19" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">什么是游程编码？<br/>游程编码(RLE) </strong>是一种非常简单的数据压缩形式，其中数据流作为输入给出(即“AAABBCCCC”)，输出是一行中连续数据值的计数序列(即“3A2B4C”)。这种类型的数据压缩是无损的，这意味着在解压缩时，所有原始数据将在解码时恢复。它在编码(压缩)和解码(解压缩)方面的简单性是该算法最吸引人的特征之一。<br/>在RLE编码格式中，奇数位置表示出现的次数，其右侧的偶数位置表示值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mk"><img src="../Images/85017db8ad18504fc0f5eaf86ae9879b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1202/format:webp/1*9Ud_eh6I4GHk-Jq5vnOPpw.jpeg"/></div></figure><h1 id="cb98" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">13.深度学习模型:</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/6f30c186b4fb38dc8bcaa39731cc8ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6kPY6W1V7VGeVCWp6hpIdQ.jpeg"/></div></div></figure><p id="3e9e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> a)分类模型:</strong>首先我要用解码后的图像和它们对应的标签为分类模型建立一个数据管道。下面是分类模型的数据管道的代码片段。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="d03d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我将使用VGG19架构和预训练的imagenet权重来创建我的分类模型。我将VGG19模型的所有图层设置为“可训练=假”。我也尝试了VGG16，但是使用VGG16得到了更好的召回值。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="4d48" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我将编译和训练这个模型，并使用检查点保存最佳模型。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="05b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从tensorboard获得的图形如下所示。</p><div class="jd je jf jg fd ab cb"><figure class="lt jh ml lv lw lx ly paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/d8ea0889a38b803daaf206e55d06279b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*UIe8SDYum23DmdnFNs52Mg.jpeg"/></div></figure><figure class="lt jh mm lv lw lx ly paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/d9a4f929c7fae782da30c3c4bea8155f.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*eutcXxUKaqBx467bpF83UA.jpeg"/></div></figure></div><p id="bf46" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我们从图中看到的，最好的验证召回发生在第7个时期。使用模型检查点为此保存权重。</p><p id="85b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">前面说过，我也试过VGG16。以下是两种型号的对比。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mn"><img src="../Images/97b786c837df44cd583608e2ea38d289.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*IDlf3b44JBrhB5me72HQ9A.jpeg"/></div></figure><p id="22ee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从上表中，我们可以看到，与vgg16相比，vgg19的召回率更高。</p><p id="349e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在定义一个函数，使用这个分类模型来预测验证数据的分类标签。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">预测类别标签和绘制混淆矩阵的功能</figcaption></figure><p id="8515" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们必须检查从0.1到0.9范围内的哪个阈值给出最佳预测。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="8994" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从上面代码片段的输出中，我发现threshold=0.3在所有参数方面给出了最好的结果。该阈值的混淆矩阵绘制如下。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mo"><img src="../Images/870f77ffefd33f591fd1a539e9ba4512.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IdqKIV8Z3dr4dkQheIN4pA.jpeg"/></div></div></figure><p id="1b71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是分类模型中不同类别标签的预测概率分布。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mp"><img src="../Images/b02b1e319c3388c5d14ba360bb4eaa55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oIXsbGaDOnFDVxNqntbC4A.jpeg"/></div></div></figure><p id="b170" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">观察到在正类标签和负类标签的概率分数之间有很大的重叠。</p><p id="73d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> b)语义分割模型:</strong>语义分割模型仅建立在阳性气胸数据及其相应的掩模上。与分类模型相似，我也必须为细分模型构建数据管道。下面是代码片段。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="fa0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我使用了UNET架构来完成这个语义分割任务。我用预先训练的DenseNet121主干替换了UNET模型的编码器部分，并保留了相同的解码器部分。下面是代码片段。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mq"><img src="../Images/3ab138d6e704259d2af1f91c6bac78af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RvXkxYBWiUgsgHqI5ESecQ.jpeg"/></div></div></figure><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="1ef8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">定义回调并编译和训练模型。此外，使用检查点保存最佳模型。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><p id="f3cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是从tensorboard收到的IOU分数和损失的图表。</p><div class="jd je jf jg fd ab cb"><figure class="lt jh mr lv lw lx ly paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/4669c4d994e11dc0a1838ae20b22aedb.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*nd4scWMCmlPdpv8Dkae8lA.jpeg"/></div></figure><figure class="lt jh ms lv lw lx ly paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><img src="../Images/a07fd2a2dc0d24db5b1281b9cf5b547d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*MlGHk44BxIkRUfrfnmGyvg.jpeg"/></div></figure></div><p id="1db2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最佳验证分数=0.3066，在时期17接收。使用检查点保存权重以备将来使用。</p><p id="2283" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用上述模型显示一些图像及其相应的原始和预测掩模。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mt"><img src="../Images/f3b6df49da2cb37e3be2035a1c055715.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2A1vP3GcS7HQfhM4pn4P8Q.jpeg"/></div></div></figure><p id="ad95" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是iou评分分布。对于所有预言的面具。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mu"><img src="../Images/ab84bdfcd49618e61c952ffc438ed771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9WFiMch9XQLoor-L6fJsAw.jpeg"/></div></div></figure><p id="86ee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">观察:<br/> </strong> a)大约有200张图像的iou得分小于0.1。<br/> b)我们需要用更多iou分数非常低的相似图像来训练模型，以便模型可以更好地学习。</p><h1 id="7ce8" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">14.最终数据管道:</h1><p id="774f" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">在最终的数据管道中，我们给出x射线图像的图像路径作为输入。这个函数负责所有的数据预处理工作，并显示图像和预测的遮罩。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">掩模预测的最终流水线</figcaption></figure><p id="83e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是从最终管道接收到的一些样本预测，给定图像路径作为输入。</p><p id="5ebe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当分类模型给出否定结果时，它仅显示标题为“该图像不包含气胸”的图像。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mv"><img src="../Images/66cb6d019807de91e596171a25ecc000.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*6blJR0mPbApCtpeoPwHTYw.jpeg"/></div></figure><p id="b4cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当分类模型给出肯定结果时，图像通过分割模型，并且分割模型预测掩模。图像和面罩一起显示，标题为“此图像包含气胸”。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mw"><img src="../Images/9ff8593d955a8ca0f6fc62f70efd8c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fhH9KCm-6fEkjLIqEihdKg.jpeg"/></div></div></figure><h1 id="06ea" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">15.误差分析:</h1><p id="d88b" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">让我们对分类和分割模型进行一些误差分析。以便我们在未来的型号中改进性能。</p><p id="8e05" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> a)分类模型:<br/> </strong>找出<strong class="ig hi">假阴性</strong>点并显示其中几个。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mx"><img src="../Images/376f47396178be19d23a833c3bc6affb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iOnP8opCPoOKShcMzxWjbQ.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated"><strong class="bd jv">假阴性</strong></figcaption></figure><p id="be6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结论:<br/> </strong> 1。<strong class="ig hi"> </strong>概率分值很低(接近零)的假阴性点被完全错误分类。为了解决这个问题，我们需要对这些数据进行过采样，以便模型可以从这些相似的图像中学习。<br/> 2。假阴性点，其概率分数小于阈值，但具有稍高的值(接近阈值)，即使这些点被错误地分类，这也可以通过进一步训练我们的模型来修复。</p><p id="3093" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">找出<strong class="ig hi">假阳性</strong>点并显示其中几个。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es my"><img src="../Images/8d11688458ff7d88690db680fc4ddcaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n8yIF0etWdmqdRRZsK_YUA.jpeg"/></div></div></figure><p id="a1c4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结论:<br/> </strong> 1。概率得分较高(接近1)的假阳性点被完全错误地分类。我们需要对这些数据进行过采样，并训练我们的模型以获得更好的结果。<br/> 2。概率分数低于(接近阈值)但高于阈值的假阳性点，即使这些点被错误分类，这也可以通过进一步训练我们的模型来修复。</p><p id="b3d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> b)分割模型:<br/> </strong>首先存储每幅图像对应的预测掩膜的iou得分。然后，根据iou得分按降序对数据帧进行排序。从数据帧顶部显示一些图像及其原始和预测掩码，即具有最佳iou分数的图像。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mb mc l"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mz"><img src="../Images/924d10c933f56d6277e37b8f66409b8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0B5pGAyVw03oAJKrwmV1YA.jpeg"/></div></div></figure><p id="8cb4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从数据帧底部显示一些图像及其原始和预测掩码，即iou分数非常低。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es na"><img src="../Images/93d93ae6d7e5404998fb975ec7004e6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sN3rx0bt27DEoeI0C_V94A.jpeg"/></div></div></figure><p id="ff85" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结论:</strong>iou分数小于0.1的图像生成的结果非常差。</p><h1 id="06f4" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">16.未来工作:</h1><ol class=""><li id="7c4a" class="nb nc hh ig b ih kr il ks ip nd it ne ix nf jb ng nh ni nj bi translated">由于没有好的计算资源，我不能为更多的时期训练我的模型。如果对它进行更多时期的训练，我们将获得更好的预测。</li><li id="248d" class="nb nc hh ig b ih nk il nl ip nm it nn ix no jb ng nh ni nj bi translated">通过进行误差分析，我们已经过滤了分类模型的假阴性和假阳性预测的图像。如果我们对这些图像进行过采样，以便模型可以了解更多信息，我们可能会获得更好的结果。</li><li id="3b52" class="nb nc hh ig b ih nk il nl ip nm it nn ix no jb ng nh ni nj bi translated">对于分割模型，我也过滤掉了iou分数非常低的图像。如果对这些图像进行过采样并重新训练模型，我们可能会得到更好的结果。</li></ol><h1 id="addb" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">17.LinkedIn和GitHub存储库:</h1><p id="9056" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated"><em class="np">LinkedIn:</em><a class="ae js" href="https://www.linkedin.com/in/anik-manik-aa1594a4/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/anik-manik-aa1594a4/</a><br/><em class="np">GitHub:</em><a class="ae js" href="https://github.com/anikmanik04/SIIM-ACR-Pneumothorax-Segmentation" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/anikmanik 04/SIIM-ACR-气胸-分割</a></p><h1 id="88e5" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">18.参考资料:</h1><ol class=""><li id="bca5" class="nb nc hh ig b ih kr il ks ip nd it ne ix nf jb ng nh ni nj bi translated">语义图像分割概述<a class="ae js" href="https://www.jeremyjordan.me/semantic-segmentation/" rel="noopener ugc nofollow" target="_blank">https://www.jeremyjordan.me/semantic-segmentation/</a></li><li id="2663" class="nb nc hh ig b ih nk il nl ip nm it nn ix no jb ng nh ni nj bi translated">U-Net:用于生物医学图像分割的卷积网络<br/><a class="ae js" href="https://www.semanticscholar.org/paper/U-Net%3A-Convolutional-Networks-for-Biomedical-Image-Ronneberger-Fischer/6364fdaa0a0eccd823a779fcdd489173f938e91a" rel="noopener ugc nofollow" target="_blank">https://www . semantic scholar . org/paper/U-Net % 3A-卷积网络-用于生物医学图像-Ronneberger-Fischer/6364 fdaa 0a 0 eccd 823 a 779 fcdd 489173 f 938 e 91 a</a></li><li id="5120" class="nb nc hh ig b ih nk il nl ip nm it nn ix no jb ng nh ni nj bi translated">评估你的语义分割模型的度量<br/><a class="ae js" href="https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2#:~:text=The%20Intersection%2DOver%2DUnion%20(,segmentation%E2%80%A6%20and%20for%20good%20reason.&amp;text=For%20binary%20(two%20classes)%20or,each%20class%20and%20averaging%20them." rel="noopener" target="_blank">https://towards data science . com/metrics-to-Evaluate-your-Semantic-Segmentation-Model-6 BCB 99639 aa 2 #:~:text = The % 20 intersection % 2d over % 2d union % 20(，Segmentation % E2 % 80% A6 % 20和%20for%20good%20reason。&amp; text=For%20binary%20(两个% 20class % 20and，每个% 20 class % 20和% 20averaging % 20them。</a></li><li id="69a2" class="nb nc hh ig b ih nk il nl ip nm it nn ix no jb ng nh ni nj bi translated">解码医学影像DICOM文件<br/><a class="ae js" href="https://www.tensorflow.org/io/tutorials/dicom" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/io/tutorials/dicom</a></li><li id="36cd" class="nb nc hh ig b ih nk il nl ip nm it nn ix no jb ng nh ni nj bi translated"><a class="ae js" href="http://www.appliedaicourse.com" rel="noopener ugc nofollow" target="_blank">www.appliedaicourse.com</a></li></ol></div></div>    
</body>
</html>