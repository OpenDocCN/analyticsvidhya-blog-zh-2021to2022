<html>
<head>
<title>Tutorial to Deploy Object Detection on Raspberry Pi using Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Tensorflow在Raspberry Pi上部署对象检测的教程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tutorial-to-deploy-object-detection-on-raspberry-pi-using-tensorflow-7ebd3e968566?source=collection_archive---------0-----------------------#2021-08-13">https://medium.com/analytics-vidhya/tutorial-to-deploy-object-detection-on-raspberry-pi-using-tensorflow-7ebd3e968566?source=collection_archive---------0-----------------------#2021-08-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ae4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Raspberry Pi是一款小型单板电脑，可以用来做实际项目。一个有趣的特点是，它有自己的Pi摄像头插槽，可以很容易地安装。因此，一个项目，如部署对象检测模型到董事会将是可怕的。</p><p id="18d1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">目标检测是一种计算机视觉技术，可以对图像或视频中的目标进行定位和分类。我们可以看到图像中每个感兴趣对象周围的边界框，并为它们分配一个类别标签。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/59bdfd7272035f5d17c168e268053a9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ObAho8BoA9nUNqW7HcB0iQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><em class="jt">图片1来源:https://www . v7labs . com/blog/object-detection-guide</em></figcaption></figure><p id="5602" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本教程可以应用于您自己图像数据集。在整个教程中，我将使用我的回收项目。图像数据集有6类，分别是塑料、玻璃、纸张、纸板、金属和垃圾。</p><p id="33cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这些帖子结束时，您将能够:</p><ol class=""><li id="d471" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">为实时检测收集良好的数据集</li></ol><p id="9eb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.Google COLAB中使用Tensorflow的列车目标检测模型</p><p id="0e5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.在Raspberry Pi上部署对象检测</p><p id="9211" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用谷歌COLAB来训练模型，并将其保存到。tflite将其部署在Raspberry Pi上。所以，系好安全带，让我们开始迷你项目。</p><p id="d5ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1。图像数据集</strong></p><p id="694e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个使用Raspberry Pi的目标检测项目，我们需要采集模拟真实场景的图像数据集。因此，利用Pi摄像机采集回收物品的图像。我们可以像图片2一样在每张图片上放一个项目，或者像下面的图片3一样在同一张照片上放所有项目。</p><p id="c465" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1.1采集图像数据集</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kd"><img src="../Images/38a594b5e8cf1716ff17ae7b6cad6090.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*ehk6htFBtgfYJ3s-NsoRjg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片2</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ke"><img src="../Images/51f2281602c3e7efe876fdd767245cfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/format:webp/1*YFk_eeXGJkUzpenun3qI7A.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图3</figcaption></figure><p id="9639" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们应该为每门课收集足够的图像。我们也可以在一个图像中混合物品的类别，比如在一个图像中混合塑料和纸。在这里，我用Pi相机拍摄了我的6类回收物品的500张照片。用相同的名字和不同的号码保存每个图像。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kf"><img src="../Images/e052dcc88ca5d68f84eb2ca102e5dbf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:690/format:webp/1*axxIutz0LuucbLH6_sn83Q.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图像4图像数据集的名称</figcaption></figure><p id="7bbb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1.2调整图像大小</strong></p><p id="8b94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">重命名图像后，我们应该调整图像的大小，因为它通常太大，无法进行训练和测试。我们可以用resizer.py。</p><div class="kg kh ez fb ki kj"><a href="https://github.com/Aida81/Recycle-Item-Detection/blob/main/resizer.py" rel="noopener  ugc nofollow" target="_blank"><div class="kk ab dw"><div class="kl ab km cl cj kn"><h2 class="bd hj fi z dy ko ea eb kp ed ef hh bi translated">主Aida81/Recycle-Item-Detection处的Recycle-Item-Detection/resizer . py</h2><div class="kq l"><h3 class="bd b fi z dy ko ea eb kp ed ef dx translated">用TensorFlow API为Raspberry Pi训练一个对象检测模型</h3></div><div class="kr l"><p class="bd b fp z dy ko ea eb kp ed ef dx translated">github.com</p></div></div><div class="ks l"><div class="kt l ku kv kw ks kx jn kj"/></div></div></a></div><p id="7a38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1.3注释图像</strong></p><p id="f86f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于对象检测，我们需要我们的包围盒来分类我们的类。因此，我们需要使用注释工具来注释图像。我选择Classifai应用程序来注释我的图像。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ky"><img src="../Images/a0589b0180b54fc783666cbaadc96826.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*voYlO5iv8b4PNAAE8EfXpA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图5 Classifai应用程序主页</figcaption></figure><p id="82ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有一个Youtube视频，你可以很容易地安装Classifai应用程序。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="kz la l"/></div></figure><p id="9da7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于标签列表文件，我们很容易在记事本中列出所有的类。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lb"><img src="../Images/82e325ab21cfdb6ea01ccec7c252f751.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*PrCDzSxbpTrG_S60dfAR_w.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图6:你应该为类列表保存标签列表的结构。</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lc"><img src="../Images/ed0c9b150f3476964e5f7207181612e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E8W0SLHfGp81lihorA6RHw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图7:注释图像数据对我来说很累但是很有趣！</figcaption></figure><p id="e6b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于对象检测，单击“绘制矩形”按钮，并在图像上感兴趣的区域绘制矩形。如果你有很多图像和类，这个过程需要时间。</p><p id="9249" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在所有的标签完成后，我们必须保存标签。对于这个项目，我们应该批量保存为<strong class="ih hj"> "Pascal VOC" </strong>，因为我们需要<strong class="ih hj"> .xml. </strong>格式的标签</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ld"><img src="../Images/2fc9a36c591dca56273cfbdf8a4fab7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*phrqzPhJ0-ve_GMqkVxq_g.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图8:选择“批量保存”一次保存所有内容。</figcaption></figure><p id="f4da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">的。每个图像的xml文件应该保存在它们图像的同一个文件夹中，如下图9所示。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es le"><img src="../Images/ea26a8374505430e0bef8868e0cd51a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mg3-nzmCoLutU8O4pO6GzQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图9</figcaption></figure><p id="b633" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1.3拆分数据集</strong></p><p id="b587" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为我们想要训练和测试图像数据集，所以我们应该将它分成80–20份。将图像保存在测试文件夹和训练文件夹中。确保。每个图像的xml文件与图像放在一起。</p><p id="c01a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 1.4预处理图像数据集</strong></p><p id="39c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将把数据集分成两个阶段。首先，从。xml文件转换为. csv。csv到tfrecord。我们为什么要这样做？这是因为Tensorflow接受TFRecords形式的数据，TF records是8位整数二进制文件，计算成本较低。</p><p id="acda" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将图像数据集从xml转换为csv和。tfrecord表单，我们可以遵循<a class="ae lf" href="https://github.com/Aida81/datasets" rel="noopener ugc nofollow" target="_blank"> Github中的步骤。</a>压缩Github上的数据集，用于Google Colab的培训。以下图的形式保存你的文件。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lg"><img src="../Images/4bb4614e5de0c05192b76516dd077855.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/1*JM3Ox6hDoZBfuSfXt0JvRA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">我们应该压缩数据集github的文件结构</figcaption></figure></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><p id="e2e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2。安装</strong></p><p id="fba9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">打开新的Google COLAB，使用您的Google电子邮件登录。</p><p id="96be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.1张量流<strong class="ih hj"/></p><p id="cc14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Tensorflow GPU v1.13正在使用，因此我们应该卸载当前的Tensorflow，然后安装我们需要的版本。</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="d05d" class="lt lu hi lp b fi lv lw l lx ly">!pip uninstall tensorflow<br/>!pip install tensorflow-gpu==1.13.2</span></pre><p id="9ddc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.2验证</strong> <strong class="ih hj">已安装的张量流</strong></p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="1064" class="lt lu hi lp b fi lv lw l lx ly">import tensorflow as tf<br/>print (tf.__version__)</span></pre><p id="6e14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果单元的输出是1.13.2，那么我们可以进行下一步。</p><p id="f13b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.3 Python </strong></p><p id="14da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">查看python版本，本教程应该是Python 3.7.11。</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="2717" class="lt lu hi lp b fi lv lw l lx ly">!python --version</span></pre><p id="2bbf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.4安装到谷歌驱动</strong></p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="0077" class="lt lu hi lp b fi lv lw l lx ly">from google.colab import drive<br/>drive.mount (‘/content/gdrive’)</span></pre><p id="3da8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该单元将请求授权码安装在您的Google Drive上，您可以通过该单元给出的链接轻松复制该授权码。</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="faa3" class="lt lu hi lp b fi lv lw l lx ly">!pwd #to show the current directory</span></pre><p id="2cfb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出应该是“/content”。你也可以看到Google Colab的左侧是你的Gdrive文件，如下图10所示。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lz"><img src="../Images/8ef82edf8baa225098190b03f195438c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GXS99AVg0xZxiZgNI0q-Fg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图10:Google Colab的右侧显示了“gdrive”文件夹下Google Drive的内容</figcaption></figure><p id="64f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.5从Tensorflow Github下载物体检测模型</strong></p><p id="1749" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来下载包含对象检测模型示例的模型档案。我们需要专门使用1.13版本来匹配我们刚刚安装的Tensorflow版本</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="35d9" class="lt lu hi lp b fi lv lw l lx ly"># Get Tensorflow from GitHub and unzip it<br/>!cd /content/gdrive<br/>!mkdir tensorflow1<br/>!cd /content/gdrive/tensorflow1<br/>!wget <a class="ae lf" href="https://github.com/tensorflow/models/archive/r1.13.0.zip" rel="noopener ugc nofollow" target="_blank">https://github.com/tensorflow/models/archive/r1.13.0.zip</a><br/>!unzip -q ./r1.13.0.zip<br/>!mv models-r1.13.0/ tensorflow1/models/<br/>!rm r1.13.0.zip</span></pre><p id="63e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.6库和环境设置</strong></p><p id="524c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">构建并安装运行object_detection示例代码所需的库</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="705b" class="lt lu hi lp b fi lv lw l lx ly"># Build and Install Tensorflow<br/>!python /content/tensorflow1/models/research/setup.py build<br/>!python /content/tensorflow1/models/research/setup.py install</span></pre><p id="db6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">转到/research文件夹，构建原型供以后使用</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="92ac" class="lt lu hi lp b fi lv lw l lx ly"># Go into research/ DIR of Tensorflow<br/>%cd /content/tensorflow1/models/research/</span><span id="63b3" class="lt lu hi lp b fi ma lw l lx ly"># Build protos!<br/>!protoc object_detection/protos/*.proto — python_out=.</span></pre><p id="78b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">设置PYTHONPATH环境变量</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="82e3" class="lt lu hi lp b fi lv lw l lx ly">%set_env PYTHONPATH=/content/tensorflow1/models:/content/tensorflow1/models/research:/content/tensorflow1/models/research/slim:/content/tensorflow1/models:/content/tensorflow1/models/research/object_detection</span><span id="2946" class="lt lu hi lp b fi ma lw l lx ly">%cd object_detection # Go into object_detection/ DIR of Tensorflow</span></pre><p id="db21" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果想知道当前colab会话还剩多少时间，请运行此命令</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="b72f" class="lt lu hi lp b fi lv lw l lx ly">import time, psutil<br/>Start = time.time()- psutil.boot_time()<br/>Left= 12*3600 - Start<br/>print('Time remaining for this session is: ', Left/3600)</span></pre></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><p id="b513" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 3。型号</strong></p><p id="f0da" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下载预训练的量化MobileNet V2可可模型。您将需要量化模型，以便在Raspberry Pi上进行更快的计算。</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="1191" class="lt lu hi lp b fi lv lw l lx ly"># Now get SSD mobilenet model from GitHub</span><span id="f03e" class="lt lu hi lp b fi ma lw l lx ly">!wget <a class="ae lf" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz" rel="noopener ugc nofollow" target="_blank">http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz</a><br/>!tar -xf ./ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz<br/>!rm ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03.tar.gz</span></pre><p id="56be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下载后，我们在GitHub的同一个repo中创建另一个名为“training”的文件夹，其中有4个文件:</p><ol class=""><li id="39dd" class="ju jv hi ih b ii ij im in iq jw iu jx iy jy jc jz ka kb kc bi translated">labelmap.pbtxt</li><li id="7d21" class="ju jv hi ih b ii mb im mc iq md iu me iy mf jc jz ka kb kc bi translated">SSD _ mobilenet _ v2 _ quantified _ 300 x300 _ coco . config</li><li id="b897" class="ju jv hi ih b ii mb im mc iq md iu me iy mf jc jz ka kb kc bi translated">测试.记录</li><li id="137a" class="ju jv hi ih b ii mb im mc iq md iu me iy mf jc jz ka kb kc bi translated">火车.记录</li></ol><p id="0503" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下载我们之前做的github的回购。在这里复制你的github的链接。</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="b5a5" class="lt lu hi lp b fi lv lw l lx ly">! git clone <a class="ae lf" href="https://github.com/Aida81/datasets.git" rel="noopener ugc nofollow" target="_blank">https://github.com/Aida81/datasets.git</a></span></pre><p id="766d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据SSD _ mobilenet _ v1 _ quantified _ 300 x300 _ coco . config中的数据集路径和类更改几行</p><p id="5d7d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第9行</strong>:<em class="mg">num _ classes:6 #您的图像数据集的类别号</em></p><p id="22e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第156行</strong>:<em class="mg">fine _ tune _ check point:" SSD _ mobilenet _ v2 _ quantified _ 300 x300 _ coco _ 2019 _ 01 _ 03/model . ckpt " #预训练模型提取文件路径</em></p><p id="3724" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第175行</strong> : <em class="mg">训练输入路径:"/content/tensor flow 1/models/research/object _ detection/datasets/training/train . record " #训练TFRecord文件路径</em></p><p id="ea00" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第187行</strong> : <em class="mg">评估输入路径:"/content/tensor flow 1/models/research/object _ detection/datasets/training/test . record " #测试TFRecord文件路径</em></p><p id="2205" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">Line 177&amp;191</strong>:<em class="mg">label _ map _ Path:"/content/tensor flow 1/models/research/object _ detection/datasets/training/label map . Pb txt " #标签地图文件的路径</em></p><p id="0107" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">*对于我们文件的路径，我们可以从Google COLAB的左侧看到并复制路径</p><p id="2d85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建文件夹来保存测试和训练图像</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="903d" class="lt lu hi lp b fi lv lw l lx ly">!mkdir images</span></pre><p id="fc8e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">将train.zip文件复制到/images目录中，解压缩该文件，然后删除该zip文件</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="ec43" class="lt lu hi lp b fi lv lw l lx ly">#copy the tensorflow train.py example from the legacy folder into the main object detection_folder</span><span id="242a" class="lt lu hi lp b fi ma lw l lx ly">!cp /content/tensorflow1/models/research/object_detection/legacy/train.py /content/tensorflow1/models/research/object_detection/</span></pre><p id="7985" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4。该训练了！</strong></p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="1ebc" class="lt lu hi lp b fi lv lw l lx ly"># Run the training!!!</span><span id="5047" class="lt lu hi lp b fi ma lw l lx ly">!python train.py --logtostderr --train_dir=training/ --pipeline_config_path=/content/tensorflow1/models/research/object_detection/datasets/training/ssd_mobilenet_v2_quantized_300x300_coco.config</span><span id="5209" class="lt lu hi lp b fi ma lw l lx ly"># verify that the files indicated in the config file are where you say (test.record and train.record especially)</span></pre><p id="2151" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练完成后，我们需要知道下几个步骤的最新检查点的数字。从training文件夹中的文件来看，我们要查找的编号如下所示:model.ckpt-4696.index</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="efaa" class="lt lu hi lp b fi lv lw l lx ly">ls -al training</span></pre><p id="2fcc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可选:压缩培训文件夹并下载，以防您想在其他时间重新开始培训</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="b3ea" class="lt lu hi lp b fi lv lw l lx ly">### OPTIONAL, if you want to continue training sometimes later ###</span><span id="636a" class="lt lu hi lp b fi ma lw l lx ly"># Zip the training folder and download locally, so we can continue in another session if required</span><span id="6254" class="lt lu hi lp b fi ma lw l lx ly">!zip -r 'training2784.zip' ./training</span><span id="5dbf" class="lt lu hi lp b fi ma lw l lx ly">%cd /content/tensorflow1/models/research/object_detection</span><span id="5061" class="lt lu hi lp b fi ma lw l lx ly">!python export_inference_graph.py --input_type image_tensor --pipeline_config_path /content/tensorflow1/models/research/object_detection/training/pipeline.config --trained_checkpoint_prefix training/model.ckpt-2784 --output_directory trained_inference_graph/</span></pre><p id="74c1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦您的模型训练开始，您应该会看到如下所示的输出:</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="0fa0" class="lt lu hi lp b fi lv lw l lx ly">INFO:tensorflow:global step 126: loss = 3.4387 (4.261 sec/step)</span><span id="00ed" class="lt lu hi lp b fi ma lw l lx ly">INFO:tensorflow:global step 127: loss = 3.2278 (4.213 sec/step)</span><span id="ea4a" class="lt lu hi lp b fi ma lw l lx ly">INFO:tensorflow:global step 128: loss = 3.2878 (4.200 sec/step)</span><span id="e970" class="lt lu hi lp b fi ma lw l lx ly">INFO:tensorflow:global step 129: loss = 2.7067 (4.132 sec/step)</span><span id="2d4a" class="lt lu hi lp b fi ma lw l lx ly">INFO:tensorflow:global step 130: loss = 2.6300 (4.413 sec/step)</span><span id="e681" class="lt lu hi lp b fi ma lw l lx ly">INFO:tensorflow:global step 131: loss = 2.9574 (4.504 sec/step)</span><span id="f238" class="lt lu hi lp b fi ma lw l lx ly">INFO:tensorflow:global step 132: loss = 2.8398 (4.507 sec/step)</span><span id="c5e1" class="lt lu hi lp b fi ma lw l lx ly">INFO:tensorflow:global step 133: loss = 2.9006 (4.498 sec/step)</span><span id="a2f4" class="lt lu hi lp b fi ma lw l lx ly">INFO:tensorflow:global step 134: loss = 2.7963 (4.459 sec/step)</span></pre><p id="a8ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每1000步保存一个新的检查点文件。(这些检查点可用于恢复训练进度并继续模型训练)</p><p id="d802" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练模型直到损失不断在0.3以下为宜！如果您没有取得好的结果，您可以继续训练模型(检查点将允许您恢复训练进度)，直到您获得满意的结果！</p><p id="87f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 6。创建freezed _ inference _ graph . Pb</strong></p><p id="707a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个冻结的推理图可以在各种各样的机器上使用，在你创建一个之后，你可以在COLAB中使用接下来的步骤来测试它，或者你可以上传你自己的到<em class="mg"> /test_images </em>文件夹。</p><p id="0a3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您将需要该命令中最新训练检查点的编号，因此请确保您已经在前面的步骤中找到了它。在培训文件夹中查找最新的步骤编号，并将参数中的编号替换为文件夹中的步骤编号:</p><p id="00b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="mg">—trained _ check point _ prefix training/model . ckpt-* * 13144 * *</em></p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="40f0" class="lt lu hi lp b fi lv lw l lx ly">!mkdir inference_graph</span><span id="a5a4" class="lt lu hi lp b fi ma lw l lx ly"># export .pd file for windows</span><span id="ddc9" class="lt lu hi lp b fi ma lw l lx ly">!python export_inference_graph.py --input_type image_tensor --pipeline_config_path=/content/tensorflow1/models/research/object_detection/training/pipeline.config --trained_checkpoint_prefix training/model.ckpt-2784 --output_directory inference_graph</span></pre><p id="2efb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">压缩inference_graph文件夹，并备份到GDrive，这样我们就可以在windows上使用它进行正常的预测</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="8f00" class="lt lu hi lp b fi lv lw l lx ly">!zip -r 'inference_graph2784-1.zip' ./inference_graph</span></pre><p id="0a85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 7。为树莓Pi准备模型</strong></p><p id="e3f9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，您需要创建。pb文件设置，然后将该文件转换为. tflite。</p><p id="6479" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.1从上次保存的检查点创建tflite_graph.pb文件。</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="f1bb" class="lt lu hi lp b fi lv lw l lx ly">%cd /content/tensorflow1/models/research/object_detection/</span><span id="d4a8" class="lt lu hi lp b fi ma lw l lx ly"># Create TFLite_model folder<br/>!mkdir TFLite_model</span></pre><p id="c765" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的代码将使用最新的检查点生成tflite_graph.pb文件(根据training文件夹中的最新文件设置trained_checkpoint_prefix)。请确保在培训文件夹中查找编号最大的检查点，并将“model.ckpt-13144”替换为最新检查点的编号，如“model . ckpt-{您的数值}”。完成后，运行代码。</p><p id="e9a6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您需要在下面的命令中调整的参数如下所示:</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="8c40" class="lt lu hi lp b fi lv lw l lx ly"><em class="mg">— trained_checkpoint_prefix=/content/tensorflow1/models/research object_detection/training/model.ckpt-13144</em></span></pre><p id="79e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是13144号码需要来自您的/training目录中的文件</p><p id="bdba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">冻结TFLite推理图，以便在RPI上使用</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="8120" class="lt lu hi lp b fi lv lw l lx ly">!python export_tflite_ssd_graph.py --pipeline_config_path=/content/tensorflow1/models/research/object_detection/training/pipeline.config --trained_checkpoint_prefix=/content/tensorflow1/models/research/object_detection/training/model.ckpt-2784 --output_directory=/content/tensorflow1/models/research/object_detection/TFLite_model --add_postprocessing_op=true</span></pre><p id="35b6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">7.2转换。pb文件到TFLite，以便在Raspberry Pi上使用</p><p id="59f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">detect.tflite将用于Raspberry Pi，因为它已经被转换为tflite格式</p><pre class="je jf jg jh fd lo lp lq lr aw ls bi"><span id="2e57" class="lt lu hi lp b fi lv lw l lx ly"># CONVERT USING TOCO</span><span id="7c62" class="lt lu hi lp b fi ma lw l lx ly">!rm ./TFLite_model/detect.tflite</span><span id="ebca" class="lt lu hi lp b fi ma lw l lx ly">!toco --graph_def_file=/content/tensorflow1/models/research/object_detection/TFLite_model/tflite_graph.pb --output_file=/content/tensorflow1/models/research/object_detection/TFLite_model/detect.tflite --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_dev_values=128 --change_concat_input_ranges=false --allow_custom_ops --input_shapes=1,300,300,3 --enable_v1_converter</span></pre><p id="6eab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，您需要知道detect.tflite在哪里，以便您可以在Raspberry Pi上部署它。</p><p id="895e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lf" href="https://www.digikey.my/en/maker/projects/how-to-perform-object-detection-with-tensorflow-lite-on-raspberry-pi/b929e1519c7c43d5b2c6f89984883588" rel="noopener ugc nofollow" target="_blank">跟随本教程尝试如何演示PiCamera来检测物体。</a></p><p id="c92e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们应该用经过训练的detect.file更改Raspberry Pi文件夹上的detect.file，以便它可以检测我们自己的图像数据集。</p><p id="624b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我的演示。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="mh la l"/></div></figure><p id="72d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如你所看到的，使用Raspberry Pi的缺点是fps不到1 ps，这清楚地表明了延迟。因此，您可以添加其他设备，如英特尔m ovidius VPUs，它们能够高效地支持要求苛刻的<strong class="ih hj">计算机视觉和边缘人工智能工作负载</strong>。</p></div></div>    
</body>
</html>