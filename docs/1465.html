<html>
<head>
<title>Web Scraping (HTML parsing and JSON API) using Scrapy Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Scrapy Python的Web抓取(HTML解析和JSON API)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scrapping-html-parsing-and-json-api-using-python-spider-scrapy-1bc68142a49d?source=collection_archive---------2-----------------------#2021-03-03">https://medium.com/analytics-vidhya/web-scrapping-html-parsing-and-json-api-using-python-spider-scrapy-1bc68142a49d?source=collection_archive---------2-----------------------#2021-03-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="57c7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">简介</strong></h1><p id="1e9d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">网络抓取是一种从网站提取数据的技术。很多工具都可以用来刮一个网站。现在我想解释我们如何使用scrapy python从网站中提取数据。<br/>现在我们将使用来自https://www.jobstreet.vn/j?sp=search<a class="ae kb" href="https://www.jobstreet.vn/j?sp=search&amp;q=C%C3%B4ng+ngh%E1%BB%87+th%C3%B4ng+tin&amp;l" rel="noopener ugc nofollow" target="_blank"><strong class="jf hj">的scrapy数据&amp;q = C % C3 % B4ng+NGH % E1 % BB % 87+th % C3 % B4ng+tin&amp;l</strong></a>。</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es kc"><img src="../Images/ecd7237628b4be332c24dbe8c8db8645.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RI1zJy98UZbzacF7DpfNpA.png"/></div></div></figure><p id="d7e2" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">我们将采取每个职位的URL，如<strong class="jf hj"> Giang vien…</strong>、<strong class="jf hj">仁安vien … </strong>等等。之后，我们可能需要从每个页面中提取数据。</p><h1 id="c144" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">要求</strong></h1><ol class=""><li id="0d4b" class="kt ku hi jf b jg jh jk jl jo kv js kw jw kx ka ky kz la lb bi translated">必须了解关于刺儿头的理论(<a class="ae kb" href="https://docs.scrapy.org/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">https://docs.scrapy.org/en/latest/index.html</a>)。</li><li id="eb22" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated">必须了解python编程语言(尤其是OOP理论)。</li><li id="b47f" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated">当然，我们需要一个已经安装在你的PC/笔记本电脑上的代码编辑器和python。</li><li id="c10b" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated">在这种情况下，浏览器是Google Chrome，因此本文中提到的选项在Google Chrome上都是可用的。</li></ol><h1 id="7407" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">你将学到什么</strong></h1><ol class=""><li id="3ab4" class="kt ku hi jf b jg jh jk jl jo kv js kw jw kx ka ky kz la lb bi translated">使用spider scrapy的网络爬行技术。</li><li id="ff1c" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated">基于HTML解析方法的抓取技术。</li><li id="ce6b" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated">JSON API的抓取技术。</li><li id="add3" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka ky kz la lb bi translated">终端芯片调试技术。</li></ol><h1 id="84fc" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">项目的步骤</strong></h1><p id="b11f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">下面是这个项目的抓取步骤。</p><ul class=""><li id="7bd4" class="kt ku hi jf b jg ko jk kp jo lh js li jw lj ka lk kz la lb bi translated">你必须先读完这篇文章，然后在技术上做练习。</li><li id="27ec" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lk kz la lb bi translated">抓取主页，并获得所有职位的网址。</li><li id="c8cd" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lk kz la lb bi translated">抓取所有的网址页面。</li><li id="5a81" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lk kz la lb bi translated">抓取带有广告张贴标签的页面上的文本。</li><li id="3fbc" class="kt ku hi jf b jg lc jk ld jo le js lf jw lg ka lk kz la lb bi translated">抓取带有非广告文章标签的页面上的文本。</li></ul><p id="a374" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">主页面上的职位名称分为两类，有<strong class="jf hj">广告-职位</strong>和<strong class="jf hj">非广告-职位</strong>。嗯，广告职位是有赞助商的职位名称和他们每个人的广告标志。</p><p id="287a" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">这才是重点！我们可以使用HTML解析方法从<strong class="jf hj">非广告发布</strong>中抓取数据。但是它并不适用于<strong class="jf hj"> ads-post </strong>，因为在这种情况下，来自<strong class="jf hj"> ads-post </strong>的数据只能使用JSON API方法获得。</p><p id="21bb" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">在这种情况下，我假设你之前已经看过或者理解过刺儿头理论<a class="ae kb" href="https://docs.scrapy.org/en/latest/index.html" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="69e0" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">为环境做准备</strong></h1><p id="548b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">首先，我们必须创建一个项目正在处理的新文件夹。例如，我的新文件夹的名称是<strong class="jf hj"> myscrapproject </strong>。<br/>打开我们的终端，键入:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="6f9a" class="lq ig hi lm b fi lr ls l lt lu">mkdir myscrapproject</span></pre><p id="0eb7" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">然后键入以切换到目标目录:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="0143" class="lq ig hi lm b fi lr ls l lt lu">cd myscrapproject</span></pre><p id="1b8b" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">在这种情况下，我假设python虚拟环境已经安装在您的PC上。如果您的电脑上没有安装python虚拟环境，您可以搜索关于安装python虚拟环境的教程。然后创建一个新的虚拟环境。</p><p id="b400" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">例如，我有一个名为<strong class="jf hj"> scrapy_env </strong>的新虚拟环境。我们可以键入:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="d803" class="lq ig hi lm b fi lr ls l lt lu">python3 -m venv scrapy_env</span></pre><p id="801b" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">然后我们必须激活虚拟:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="edb0" class="lq ig hi lm b fi lr ls l lt lu">source scrapy_env/bin/activate</span></pre><p id="0c32" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">所以我们可以看到虚拟已经被激活了。现在，安装scrapy:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="bf51" class="lq ig hi lm b fi lr ls l lt lu">pip install scrapy</span></pre><p id="4e7b" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">让我们创建一个新的scrapy项目来代表我们的项目。例如，我们新的scrapy项目的名称是<strong class="jf hj"> jobstreetvn </strong>。</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="ebef" class="lq ig hi lm b fi lr ls l lt lu">scrapy startproject jobstreetvn</span></pre><p id="6ef0" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">然后键入:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="013e" class="lq ig hi lm b fi lr ls l lt lu">cd jobstreetvn</span></pre><p id="1215" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">而现在，目录已经使用然后最小化终端。从而打开VSCode或另一个代码编辑器。将文件夹jobstreetvn和其中的所有文件导入代码编辑器。</p><p id="cd04" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">然后我们必须创建一个包含<strong class="jf hj">的新文件。py </strong>扩展名在<strong class="jf hj">蜘蛛</strong>文件夹中。例如，我们的新文件是<strong class="jf hj"> posts_spider.py </strong>。<br/>然后在那里创建如下代码:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="ca22" class="lq ig hi lm b fi lr ls l lt lu">import scrapy #to import the scrapy module<br/>import json #to import the JSON module</span></pre><h1 id="6ccc" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak"> HTML解析方法</strong></h1><p id="983e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">(对于详细的步骤，在这种情况下，您可以在这之后的<strong class="jf hj">从HTML </strong>部分中看到。向下滚动。)<br/>既然我们选择获取每个职位的链接的步骤是获取URL，那么我们就必须获取主页面上每个职位的HTML代码。</p><p id="9a13" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">我们可以通过在主页面上点击右键来检查元素，然后在Google Chrome上选择inspect元素(或者按Ctrl+Shift+I)。我们已经看到了主页上所有数据的HTML代码。</p><p id="8e1e" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">在这种情况下，我们必须通过从页面中选取元素来获取每个职位的HTML代码。<br/>让我们点击:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es lv"><img src="../Images/1261609ad84067cb93ff68429dabc4b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:52/format:webp/1*-vwyRJmbHaOQqDP0hx42dA.png"/></div></div></figure><p id="ae6a" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">然后在那里选择一个职位名称(这一步我们必须点击带有<strong class="jf hj">非广告职位</strong>标签的名称)，然后点击如下:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es lw"><img src="../Images/b363d57fbc1612bb5b2a8a72c300b96c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*a5PX1jsAvzez7jUOZf8zhg.png"/></div></div></figure><p id="64f5" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">在inspect元素端，我们将得到HTML代码。之后，我们必须为那里的每个职称选择父母元素代码。此外，我们可以检查表示父元素代码的类。</p><p id="39a5" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">现在我们得到了名为<strong class="jf hj"> job-item </strong>的类，带有一个<strong class="jf hj"> &lt;和一个&gt; </strong>元素。在scrapy脚本的一个规则中，我们必须键入使用的类，例如<strong class="jf hj"> a.job-item </strong>，它代表所有带有<strong class="jf hj">非广告发布</strong>标签的职位。</p><p id="1f07" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">只是提醒一下，对于详细的步骤，在这种情况下，你可以在这之后的<strong class="jf hj">从HTML </strong>获取文本部分看到。<br/>所以，代码是:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es lx"><img src="../Images/f3a8fd782be4ac1772c2a2f9b75a09f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aHBR2ZE4RtjB3JDmDgE0Mw.png"/></div></div></figure><p id="e234" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">现在，打开终端(停留在jobstreetvn目录)。让我们按类型检查代码的结果:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="d01b" class="lq ig hi lm b fi lr ls l lt lu">scrapy crawl posts -o mainpage.json</span></pre><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es ly"><img src="../Images/8d369a9c41ab8b5bb6bcaa19e3844422.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XfMUtp8QRIrSxan1N0wZYg.png"/></div></div></figure><p id="5005" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">现在，我们可以在代码编辑器中检查结果。在代码编辑器中打开文件夹，搜索名为<strong class="jf hj"> mainpage.json </strong>的文件。<br/>让我们看看！嘣！</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es lz"><img src="../Images/3f348e16ba1752a5f72e42aed70f55e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LafOApvyYi_kr9z6UcqTVQ.png"/></div></div></figure><p id="838d" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">我们可以在那里看到10个网址和职位。但是等等。为什么只抓取了10个网址？而主页上有15个职位。是的，因为只有10个职位带有<strong class="jf hj">非广告职位</strong>标签，5个职位带有广告职位。</p><p id="5f2e" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">因此，<strong class="jf hj"> post_spider.py </strong>中的代码现在只能使用<strong class="jf hj">非广告帖子</strong>获取职位的URL。其他的呢(T9广告贴T10标签)？</p><h1 id="ffb7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak"> JSON API </strong></h1><p id="bbcd" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在这种情况下，我们可以通过JSON API解析获得带有广告发布标签的职位的URL。</p><p id="648f" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">(对于这部分，我就不做详细描述/解释了。如果有任何问题，请发邮件至ma.arryanda@gmail.com。</p><p id="2907" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">现在，为了获得主页面中广告张贴标签的URL，我们必须拥有名为<a class="ae kb" href="https://jupiter.jora.com/api/v1/jobs?keywords=C%C3%B4ng%20ngh%E1%BB%87%20th%C3%B4ng%20tin&amp;page_num={page_number}&amp;session_id=1f4498b9c6f2ebda3cd5dcdf8ef6b15f&amp;search_id=3yAkpixVHSHokFUnNESz-1f4498b9c6f2ebda3cd5dcdf8ef6b15f-X86gxLy3TuLx42PSU59a&amp;session_type=web&amp;user_id=3yAkpixVHSHokFUnNESz&amp;logged_user=false&amp;mobile=false&amp;site_id=1&amp;country=VN&amp;host=https://jupiter.jora.com&amp;full_text_only_search=true&amp;ads_per_page=5&amp;callback=_jsonp_0" rel="noopener ugc nofollow" target="_blank"><strong class="jf hj">https://jupiter.jora.com/api/v1/jobs?的URL链接关键词= C % C3 % B4ng % 20 NGH % E1 % BB % 87% 20% C3 % B4ng % 20 tin&amp;page _ num = { page _ number }&amp;session _ id = 1 f 4498 b 9 C 6 F2 ebda 3c D5 dcdf 8 ef 6 b 15 f&amp;search _ id = 3 yakpixvhshokfunnesz-1 f 4498 b 9 C 6 F2 ebda 3c D5 dcdf 8 ef 6b 15 f-x86 gxly 3 tulx 42 PSU 59 a&amp;</strong></a></p><p id="6fbd" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">因此，我们可以通过实际检查元素(在主页上，右键单击并选择inspect选项)来获得广告帖子的URL。在inspect element端，选择network选项卡，并重新加载/刷新页面。然后选择API链接(jobs？关键词=……..)如下图:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es ma"><img src="../Images/8b92390be1034973eebf5476f52f9b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*44tHIEZdoKGnaPYq5fIs4w.png"/></div></figure><p id="e9be" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">并复制链接地址(右键单击-&gt;复制链接地址)并将其粘贴到窗口的选项卡上。我们来看下图:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es mb"><img src="../Images/852d3e107303b52e2e5639f6137cc5fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8szzTu-uyaO875TXtvAQNg.png"/></div></div></figure><p id="0a47" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">上图是关于所有广告的字典。如果我们检查URL，我们可以看到关于代表页码的网站的<strong class="jf hj"> page_number </strong>。而每页的广告张贴数量是五个。</p><h1 id="e55f" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">从HTML获取文本</h1><p id="862d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在这一节中，我们将学习如何从每个废弃的页面中获取文本，我将只解释一种情况。例如，现在我们尝试如何在主页上获得URL的CSS响应。如果我们检查报废的代码，那么我们可以看到URL的CSS响应是<strong class="jf hj">(“。job-item ::attr(href)") </strong>。那么如何获得呢？</p><p id="99bf" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">我们去<a class="ae kb" href="https://www.jobstreet.vn/j?sp=search&amp;q=C%C3%B4ng+ngh%E1%BB%87+th%C3%B4ng+tin&amp;l" rel="noopener ugc nofollow" target="_blank">T3】https://www.jobstreet.vn/j?sp=search&amp;q = C % C3 % B4ng+NGH % E1 % BB % 87+th % C3 % B4ng+tin&amp;lT5】。然后右键单击并选择inspect选项，按Ctrl+Shift+C选择页面上的一个元素。</a></p><p id="b51d" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">之后，我们点击其中一个职位。(记住！这个步骤只适用于非广告文章，不适用于广告文章。)</p><p id="9efe" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">然后，我们可以点击没有广告标签的职位。例如，让我们点击名为<strong class="jf hj">韩尹渭渭健的职位…..</strong>如下图:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es mc"><img src="../Images/a0e479ff32da9002aa135264f2aac7ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zwBb9oyP5hXK30u2dQ8fIA.png"/></div></div></figure><p id="c8bc" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">现在我们可以看到，职位已经被点击，有一个HTML元素，即h3.job-title.heading-large。-无边界底部在那里。然后检查元素侧边栏，并对下图进行同样的操作:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es md"><img src="../Images/211045ba212ee92d3ba8419c41c8f664.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*llJes6W9a9FjJye2mxFbgQ.png"/></div></figure><p id="1fc5" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">上图向我们解释了如何通过查找所需的父元素来获取职位的元素。</p><p id="051e" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">例如，<strong class="jf hj">韩尹渭渭剑指…..</strong>有元素，即<strong class="jf hj"> h3.job-title.heading-large。-无边距底部</strong>与上图相同。这意味着我们只能在名为<strong class="jf hj">韩尹渭渭健的职位中获得一个职位的元素…..</strong>。但是等等，不要忘了有非广告职位标签的职位数量。</p><p id="4487" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">主页上有10个职位。因此，我们必须找出父元素，因为我们已经得到了职称的子元素。现在，让我们检查上面的图像。</p><p id="5b90" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">正如我们所知，具有名为<strong class="jf hj">job-title heading-large-no-margin-bottom</strong>的类的h3元素是div元素的子元素，div元素具有名为<strong class="jf hj"> job-item-top-container </strong>的类。同时，具有名为<strong class="jf hj"> job-item-top-container </strong>的类的div元素是一个仅表示一个职位及其相关信息的元素。</p><p id="e449" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">因此，我们必须寻找一个元素，它的类名代表所有非广告文章的职位。</p><p id="7540" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">如果我们向上滚动到图片的顶部，会出现一个元素，它有一个名为<strong class="jf hj"> job-item </strong>的类。似乎我们已经找到了所需的母公司元素，它代表了所有职位的要求。</p><p id="6dd1" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">现在，我们有了作为CSS响应的类名，用于获取所有带有非广告文章标签的工作标题的URL(它有10个URL)。</p><p id="1194" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">因为我们知道获取CSS响应文本的步骤是通过在最后一个命令中为每个CSS响应添加<strong class="jf hj">……text</strong>，现在我们必须在最后一个命令中添加<strong class="jf hj">……attr(href)</strong>来获取CSS响应的URL。</p><h1 id="fa55" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">获取下一页分页HTML的URL</h1><p id="31ba" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">本节解释了我们如何通过查看CSS响应的必需元素来获取下一个页面URL。无论如何，第一步与前一节中获取文本的步骤没有什么不同。我们必须从每个页面中寻找一个表示下一页分页的元素。</p><p id="a8a7" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">例如，我们必须只在第一页尝试。下图解释了下一页分页的元素:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es me"><img src="../Images/2187ee646bef77e8775e9c5ee59e32db.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*vmkiM6XJ3V4yHsLcfQ1mbQ.png"/></div></figure><p id="401b" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">下一页的标记在下面(它位于底部页面区域):</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es mf"><img src="../Images/40adecbf2eb9aa08f4b0dc135d2c3435.png" data-original-src="https://miro.medium.com/v2/resize:fit:242/format:webp/1*TvkY6hQuX-UaxeCaaIaykw.png"/></div></figure><p id="db52" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">根据图片，现在我们知道下一页分页有一个名为<strong class="jf hj">下一页按钮</strong>的元素类。所以，代码是:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="aa68" class="lq ig hi lm b fi lr ls l lt lu">next_page = response.css("a.next-page-button::attr(href)").get()</span></pre><h1 id="bfbb" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">如何在终端中进行刺儿式调试？</strong></h1><p id="37c9" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">此外，我们必须采用该技术来获取我们必须拥有的项目的CSS响应。例如，我们在这里取了许多情况中的一个来调试它。</p><p id="f1cd" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">现在，作为试验，我们将从下一页分页<strong class="jf hj">得到CSS响应</strong>，因为<strong class="jf hj"> </strong>上一节已经解释过了。</p><p id="4944" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">因此，打开终端，如下图所示:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div class="er es mg"><img src="../Images/f5ef7cd38a79506b3dbb61926e0cae02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*UghsLH3pEA_8F-g48Himcg.png"/></div></figure><p id="be7d" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">那么我们必须键入:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="58ce" class="lq ig hi lm b fi lr ls l lt lu">scrapy shell "<a class="ae kb" href="https://www.jobstreet.vn/j?sp=search&amp;q=C%C3%B4ng+ngh%E1%BB%87+th%C3%B4ng+tin&amp;l" rel="noopener ugc nofollow" target="_blank">https://www.jobstreet.vn/j?sp=search&amp;q=C%C3%B4ng+ngh%E1%BB%87+th%C3%B4ng+tin&amp;l</a>"</span></pre><p id="c295" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">如果成功，会出现如下图所示的情况:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es mh"><img src="../Images/506fd3adfc7c991bb00cc286c6414a5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ktL4cBmhMa4LCFEQ6Qs7RA.png"/></div></div></figure><p id="92cc" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">然后，我们必须键入CSS响应代码，如下所示:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="fcff" class="lq ig hi lm b fi lr ls l lt lu">response.css("a.next-page-button::attr(href)").get()</span></pre><p id="ed71" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">如果成功，我们将具备如下条件:</p><figure class="kd ke kf kg fd kh er es paragraph-image"><div role="button" tabindex="0" class="ki kj di kk bf kl"><div class="er es mi"><img src="../Images/63ce137e61e41a209df665b96dd1190e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RvoRPkFBwtxszvy6QlGe4A.png"/></div></div></figure><p id="2f5f" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">恭喜你！！！我们得到了诀窍。所以我们必须为这个项目中需要的所有变量或项目做同样的技巧。</p><h1 id="bc00" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">结论</strong></h1><p id="c503" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">由于我们已经在第一页上获得了所有的URL，这意味着我们也可以从所有页面上获得所有的URL。因此，抓取所有页面的代码如下:</p><pre class="kd ke kf kg fd ll lm ln lo aw lp bi"><span id="1537" class="lq ig hi lm b fi lr ls l lt lu">import scrapy<br/>import json</span><span id="354c" class="lq ig hi lm b fi mj ls l lt lu">class PostsSpider(scrapy.Spider):<br/>    name = "posts"</span><span id="95f5" class="lq ig hi lm b fi mj ls l lt lu">start_urls = {<br/>        "<a class="ae kb" href="https://www.jobstreet.vn/j?sp=search&amp;q=C%C3%B4ng+ngh%E1%BB%87+th%C3%B4ng+tin&amp;l" rel="noopener ugc nofollow" target="_blank">https://www.jobstreet.vn/j?sp=search&amp;q=C%C3%B4ng+ngh%E1%BB%87+th%C3%B4ng+tin&amp;l</a>"<br/>    }<br/>    <br/>    #NON ADS<br/>    def parse_item(self, response):<br/>        item = {}<br/>        company_name1 = response.css("#company-location-container &gt; span.company::text").get()<br/>        company_name2 = response.xpath("//*[<a class="ae kb" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>='job-description-container']/div/div/p[17]/b/text()").get()<br/>        company_name3 = response.css("#job-description-container &gt; div &gt; div &gt; strong ::text").get()<br/>        company_ads = response.css(".job-title::text").get()<br/>        if company_name1:<br/>            #no ads<br/>            #top<br/>            item["type"] = "no ads",<br/>            item["jobtitle"] = response.css("h3.job-title.heading-xxlarge ::text").get(),<br/>            item["company_name"] = company_name1,<br/>            item["location"] = response.css("#company-location-container &gt; span.location ::text").get(),<br/>            item["site"] = response.css("#job-meta &gt; span.site ::text").get(),<br/>            #desc<br/>            item["desc"] = ''.join(response.css("#job-description-container ::text").getall()),<br/>        elif company_name2:#company in bottom<br/>            #no ads<br/>            #top<br/>            item["type"] = "no ads, company name at the bottom side",<br/>            item["jobtitle"] = response.css("h3.job-title.heading-xxlarge ::text").get(),<br/>            item["company_name"] = response.xpath("//*[<a class="ae kb" href="http://twitter.com/id" rel="noopener ugc nofollow" target="_blank">@id</a>='job-description-container']/div/div/p[17]/b/text()").get(),<br/>            item["location"] = response.css("div #company-location-container &gt; span.location ::text").get(),<br/>            item["site"] = response.css("div #job-meta &gt; span.site ::text").get(),<br/>            #desc<br/>            item["desc"] = ''.join(response.css("#job-description-container ::text").getall())<br/>        else: #no description<br/>            item["type"] = "no ads, no desc",<br/>            item["jobtitle"] = response.css("h3.job-title.heading-xxlarge ::text").get(),<br/>            item["company_name"] = company_name3<br/>            item["location"] = response.css("#company-location-container &gt; span.location ::text").get(),<br/>            item["site"] = response.css("#job-meta &gt; span.site ::text").get(),<br/>            item["desc"] = "no desc"<br/>        return item <br/>    <br/>    #ADS<br/>    def parse_item_ads(self, response):<br/>        item={}<br/>        company_ads = response.css(".job-title::text").get()<br/>        if company_ads:<br/>            item["type"] = "ads"<br/>            item["jobtitle"] = response.css(".job-title::text").get()<br/>            item["company_name"] = company_ads<br/>            item["location"] = response.css(".location::text").get()<br/>            item["site"] = response.css(".site::text").get()<br/>            item["desc"] = ''.join(response.css("#job-description-container ::text").getall())<br/>        return item</span><span id="22b7" class="lq ig hi lm b fi mj ls l lt lu">def parse_item_json(self, response):<br/>        text_clean = response.text.replace("/**/_jsonp_0(", "")<br/>        text_clean = text_clean.replace(")", "")<br/>        result_json = json.loads(text_clean)<br/>        for data in result_json['ads']:<br/>            url = data['url']<br/>            yield scrapy.Request(url = url, callback = self.parse_item_ads)<br/>          <br/>    def parse(self, response):<br/>        page_number = 1<br/>        for post in response.css('a.job-item'):<br/>            data = {<br/>                #total = 15, ads = 5, non ads = 10<br/>                #non ads<br/>                "url" : post.css(".job-item ::attr(href)").get()<br/>            }<br/>            linkads = f"<a class="ae kb" href="https://jupiter.jora.com/api/v1/jobs?keywords=C%C3%B4ng%20ngh%E1%BB%87%20th%C3%B4ng%20tin&amp;page_num={page_number}&amp;session_id=1f4498b9c6f2ebda3cd5dcdf8ef6b15f&amp;search_id=3yAkpixVHSHokFUnNESz-1f4498b9c6f2ebda3cd5dcdf8ef6b15f-X86gxLy3TuLx42PSU59a&amp;session_type=web&amp;user_id=3yAkpixVHSHokFUnNESz&amp;logged_user=false&amp;mobile=false&amp;site_id=1&amp;country=VN&amp;host=https://jupiter.jora.com&amp;full_text_only_search=true&amp;ads_per_page=5&amp;callback=_jsonp_0" rel="noopener ugc nofollow" target="_blank">https://jupiter.jora.com/api/v1/jobs?keywords=C%C3%B4ng%20ngh%E1%BB%87%20th%C3%B4ng%20tin&amp;page_num={page_number}&amp;session_id=1f4498b9c6f2ebda3cd5dcdf8ef6b15f&amp;search_id=3yAkpixVHSHokFUnNESz-1f4498b9c6f2ebda3cd5dcdf8ef6b15f-X86gxLy3TuLx42PSU59a&amp;session_type=web&amp;user_id=3yAkpixVHSHokFUnNESz&amp;logged_user=false&amp;mobile=false&amp;site_id=1&amp;country=VN&amp;host=https://jupiter.jora.com&amp;full_text_only_search=true&amp;ads_per_page=5&amp;callback=_jsonp_0</a>"<br/>            link = "<a class="ae kb" href="https://www.jobstreet.vn/" rel="noopener ugc nofollow" target="_blank">https://www.jobstreet.vn/</a>" + data.get("url")<br/>            page_number +=1<br/>            if link is not None:<br/>                yield scrapy.Request(url = link, callback = self.parse_item)<br/>            yield scrapy.Request(url = linkads, callback = self.parse_item_json)</span><span id="67f2" class="lq ig hi lm b fi mj ls l lt lu">next_page = response.css("a.next-page-button::attr(href)").get()<br/>        if next_page is not None:<br/>            next_page = response.urljoin(next_page)<br/>        yield scrapy.Request(next_page, callback=self.parse)</span></pre><p id="89c1" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">不要忘记如何获得每个条目的CSS响应的步骤。我们可以通过检查inspect元素并检查所需文本的HTML代码来获得它。然后我们必须在终端中调试它们。</p><p id="aa42" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">(对于这部分，我就不做详细描述/解释了。如果有任何问题，你可以发电子邮件到ma.arryanda@gmail.com找我)</p><p id="afd3" class="pw-post-body-paragraph jd je hi jf b jg ko ji jj jk kp jm jn jo kq jq jr js kr ju jv jw ks jy jz ka hb bi translated">编码快乐！</p></div></div>    
</body>
</html>