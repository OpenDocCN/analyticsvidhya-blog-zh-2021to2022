<html>
<head>
<title>Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs by Deepmind. Explained!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">感知者IO:deep mind结构化输入输出的通用架构。解释过了！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/perceiver-io-a-general-architecture-for-structured-inputs-outputs-4ad669315e7f?source=collection_archive---------3-----------------------#2021-08-08">https://medium.com/analytics-vidhya/perceiver-io-a-general-architecture-for-structured-inputs-outputs-4ad669315e7f?source=collection_archive---------3-----------------------#2021-08-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="a921" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">还提供了一个视频讲解器来理解感知者IO的想法</h2></div><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="jc jd l"/></div></figure></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="0c9d" class="jl jm hi bd jn jo jp jq jr js jt ju jv io jw ip jx ir jy is jz iu ka iv kb kc bi translated"><strong class="ak">简介</strong></h1><p id="0b85" class="pw-post-body-paragraph kd ke hi kf b kg kh ij ki kj kk im kl km kn ko kp kq kr ks kt ku kv kw kx ky hb bi translated">Deepmind刚刚推出了<a class="ae kz" href="https://deepmind.com/research/open-source/perceiver-IO" rel="noopener ugc nofollow" target="_blank">感知者IO </a>，这是一个结构化输入&amp;输出的通用架构。原始感知者的想法是它提供了</p><blockquote class="la lb lc"><p id="cdfb" class="kd ke ld kf b kg le ij ki kj lf im kl lg lh ko kp li lj ks kt lk ll kw kx ky hb bi translated">一种利用变压器架构的通用算法，它还解决了由于注意机制而出现的变压器的二次时间和空间复杂度。</p></blockquote><p id="59f9" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated"><a class="ae kz" href="https://arxiv.org/abs/2107.14795https://arxiv.org/abs/2107.14795" rel="noopener ugc nofollow" target="_blank">感知者IO </a>扩展了<a class="ae kz" href="https://arxiv.org/abs/2103.03206" rel="noopener ugc nofollow" target="_blank">原始感知者</a>，其中架构的输出也可以扩展到任意大小的输出值。因此，他们创建了一种通用算法，可以将任何大小的输入输入到变压器注意块中，还可以根据需要提供所需的输出形状。首先。我们先来了解一下原变压器架构中的问题。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lm"><img src="../Images/11247e28b7f3fbb0cb12589bb3b879ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gHAgiyDicFQVeeWHCwoCwA.png"/></div></div><figcaption class="lt lu et er es lv lw bd b be z dx translated">左侧，广义感知者模型可以接受任何类型/大小的输入，但只能接受简单的输出。感知者IO现在也可以提供输出，而不管输入的大小。</figcaption></figure></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="6885" class="jl jm hi bd jn jo jp jq jr js jt ju jv io jw ip jx ir jy is jz iu ka iv kb kc bi translated">变压器中的问题</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lx"><img src="../Images/aea1d760f5a2529857a26faa14cc8c74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*LplKPXLQJ-Q8pALS"/></div></figure><p id="4d55" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">让我们了解一下transformer中的语言翻译任务。现在，一般来说，Transformer工作得最好，因为它可以一次获取大量的输入序列值，这在我们的算法需要引用其他单词进行上下文时很有帮助。</p><p id="6fe5" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">因此，为了实现对上下文的深入理解，每个单词都与其他每个单词进行映射，以获得更多的理解。</p><p id="d3bf" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">在一般的变压器中，我们的第一个输入数据通过前馈层经过<strong class="kf hj">多头注意力</strong>层。在<strong class="kf hj">多头关注</strong>中会有多个<strong class="kf hj">自我关注层。</strong></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es ly"><img src="../Images/d4956c1d283d26727c24374d7adef846.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Dm3vlTFjlXgHtANQ"/></div></div></figure><p id="f9b0" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">在<strong class="kf hj">自我关注层中，</strong>输入中的每个元素都与输入中的所有其他单词相关联。对于语言任务，如果输入序列中有M个单词，那么由于自我注意，空间复杂度变成二次的。</p><p id="0619" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">为什么会这样？我们来详细看看自我关注。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lz"><img src="../Images/0862302b2430bb4282054ff894598edd.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*K7Td5HBWASnlOaNmWd-vcg.png"/></div></figure><p id="8828" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">因此，在自我关注内部，我们将输入提供给<strong class="kf hj">三个不同的完全连接的层</strong>，以创建查询关键字和值向量。查询和关键字经历<strong class="kf hj">点积矩阵乘法</strong>以产生评分矩阵。得分矩阵决定了一个单词在其他单词上的关注程度。然后，我们添加softmax以获得最高的概率值，这有助于我们的模型提供更多的信心来关注哪些单词。然后乘以值向量，得到输出向量。</p><p id="9721" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">由于 <strong class="kf hj">查询和</strong>键之间的<strong class="kf hj">乘法，当输入增加时，一般关注的变形金刚立即在空间中向上射出。</strong></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ma"><img src="../Images/ab749adbb7492fb944676c21217b6bcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*KAdNdOHiThLEL_OTEF5Cgw.png"/></div></figure><p id="9ba8" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">对于语言任务来说，这没什么大不了的，因为最多输入1000个左右的序列。然而，当考虑<strong class="kf hj">图像时，我们的输入序列将是图像</strong>中的所有像素。对于一个256x256的简单图像，我们的像素大约是62，500，这是我们的输入序列，现在我们的<strong class="kf hj">空间复杂度是65536x65536 </strong>。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mb"><img src="../Images/716ebec8e4257cb61498ad35094ec5a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rs2mNgvEeLq2ywkyW5Vl7A.png"/></div></div></figure><p id="60cb" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">几种方法来提供替代解决方案，如<a class="ae kz" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"> VIT变形金刚</a>，其中<strong class="kf hj">图像已经被分成批次</strong>然后馈送给它们，然而它仍然没有解决我们的二次复杂度。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mc"><img src="../Images/5927dc1e2fd40be8d829cde0bfde52be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2DAuxm0i-BzqQFbK"/></div></div></figure></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="4905" class="jl jm hi bd jn jo jp jq jr js jt ju jv io jw ip jx ir jy is jz iu ka iv kb kc bi translated"><strong class="ak">原始感知纸</strong></h1><p id="727f" class="pw-post-body-paragraph kd ke hi kf b kg kh ij ki kj kk im kl km kn ko kp kq kr ks kt ku kv kw kx ky hb bi translated">现在，感知建筑通常试图将这种空间复杂性降低到一个极限，这样它就不应该是二次的。为了解决这个问题，他们在输入序列和多头注意力之间增加了一个<strong class="kf hj">交叉注意力</strong>层。</p><p id="e86a" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">那么什么是交叉注意呢？</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es md"><img src="../Images/c4341fb2040b0e6eb793d5350713efc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rGYAir6VG38qbDRoJgOS5w.png"/></div></div></figure><p id="2acb" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">简单地说，我们在查询和关键字之间执行矩阵乘法，其中两者的大小都是MxM，其中m是输入序列，在交叉注意中，我们的查询的大小是N，其中N&lt; M。我们已经在语言翻译转换器架构中看到了这种交叉注意，其中我们的编码器与解码器执行交叉注意。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es me"><img src="../Images/ee706be9e55309e8e00db067fb7e51d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lKhP_x5KSFzSaRzbTNBtyw.png"/></div></div></figure><p id="ea3c" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">这里，如果你看到我们的编码器序列很大，但我们的解码器不是。一个潜在的数组，作为数据流的<strong class="kf hj">分支流入我们的多头注意力</strong>。现在，首先，我们的<strong class="kf hj">潜在空间将从所有输入序列中仅查询几个输入序列</strong>，然而，现在在下一步中，我们的输入序列再次被我们的潜在数组查询。现在，如果你明白它就像一个RNN架构，重要的特性被移到下一个步骤，权重在它们之间共享。由于这种潜在的数组瓶颈，该论文提到这种架构可以处理任何类型的输入序列，如从文本到图像到视频，甚至到单词云。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mf"><img src="../Images/5567c55b771bfd2f1efb72a3f79c22b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gYZO4AqmVbP17nq7"/></div></div></figure></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="4819" class="jl jm hi bd jn jo jp jq jr js jt ju jv io jw ip jx ir jy is jz iu ka iv kb kc bi translated">感知者IO</h1><p id="c958" class="pw-post-body-paragraph kd ke hi kf b kg kh ij ki kj kk im kl km kn ko kp kq kr ks kt ku kv kw kx ky hb bi translated">基于之前deep mind共享的感知者架构，他们对算法进行了增压，在解码器的最后一层添加了<strong class="kf hj">交叉注意力机制。</strong></p><p id="454c" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">因此，现在这种交叉注意力使用查询系统将编码器的潜在映射到任意大小和结构的输出，该查询系统可以通过使用对期望的输出元素唯一的查询特征向量简单地<strong class="kf hj">查询潜在数组来灵活地指定广泛领域上的输出所需的语义。</strong></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mg"><img src="../Images/74db56ddb1dc30fdab4f94e4331eace5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Q-305_RMAzQ7EFWw"/></div></div></figure><p id="d9b3" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">换句话说，</p><blockquote class="la lb lc"><p id="94c7" class="kd ke ld kf b kg le ij ki kj lf im kl lg lh ko kp li lj ks kt lk ll kw kx ky hb bi translated">我们定义一个查询数组，其元素数量与期望的输出相同。查询可以是手工设计的、学习的嵌入，或者输入的简单函数。他们关注患者以产生期望形状的输出阵列。</p></blockquote><p id="c725" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">编码器和解码器都接受两个输入数组，第一个用作模块的键和值网络的输入，第二个用作模块的查询网络的输入。模块的输出具有与查询输入相同的索引维度(即，相同数量的元素):这允许编码器和解码器模块产生不同大小的输出。</p><p id="5314" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">为了捕获输出空间的结构，我们必须确保这个查询包含适当的信息。这意味着字节的信息查询应该反映下游任务，并且理想地捕获输出中所需的任何结构。这可能包括图像中的空间位置或序列中输出单词的位置。</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="6e97" class="jl jm hi bd jn jo jp jq jr js jt ju jv io jw ip jx ir jy is jz iu ka iv kb kc bi translated">代码示例</h1><p id="d7f7" class="pw-post-body-paragraph kd ke hi kf b kg kh ij ki kj kk im kl km kn ko kp kq kr ks kt ku kv kw kx ky hb bi translated">代码示例已经收录在下面的GitHub URL中，您也可以在colab笔记本中查看。</p><div class="mh mi ez fb mj mk"><a href="https://github.com/2796gaurav/code_examples/tree/main/Perceiver" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hj fi z dy mp ea eb mq ed ef hh bi translated">code _ examples/感知者at main 2796gaurav/code_examples</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">这是一个由deepmind分享的colab示例，我已经对其进行了修改，以便能够通过google访问…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">github.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my lr mk"/></div></div></a></div></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><p id="8511" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">如果你喜欢这个内容并且想要支持它，你可以喜欢，评论或者分享这个博客的<a class="ae kz" href="https://www.youtube.com/watch?v=AS1Sh-KuNzs" rel="noopener ugc nofollow" target="_blank">视频</a>。</p><p id="0896" class="pw-post-body-paragraph kd ke hi kf b kg le ij ki kj lf im kl km lh ko kp kq lj ks kt ku ll kw kx ky hb bi translated">感谢阅读，</p><blockquote class="la lb lc"><p id="be7a" class="kd ke ld kf b kg le ij ki kj lf im kl lg lh ko kp li lj ks kt lk ll kw kx ky hb bi translated">你可以在社交媒体上关注我，了解更多内容。</p><p id="cd91" class="kd ke ld kf b kg le ij ki kj lf im kl lg lh ko kp li lj ks kt lk ll kw kx ky hb bi translated"><a class="ae kz" href="https://in.linkedin.com/in/gauravc2708" rel="noopener ugc nofollow" target="_blank">领英</a></p><p id="3be0" class="kd ke ld kf b kg le ij ki kj lf im kl lg lh ko kp li lj ks kt lk ll kw kx ky hb bi translated"><a class="ae kz" href="https://twitter.com/2796gaurav" rel="noopener ugc nofollow" target="_blank">推特</a></p></blockquote></div></div>    
</body>
</html>