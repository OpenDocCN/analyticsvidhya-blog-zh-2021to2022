<html>
<head>
<title>Analyzing IMDb’s Top 250 movies: Part 2; Extract Useful Datasets</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分析IMDb电影250强:第二部分:提取有用的数据集</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/analyzing-imdbs-top-250-movies-part-2-extract-useful-datasets-e17f7ba15563?source=collection_archive---------12-----------------------#2021-07-09">https://medium.com/analytics-vidhya/analyzing-imdbs-top-250-movies-part-2-extract-useful-datasets-e17f7ba15563?source=collection_archive---------12-----------------------#2021-07-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="081a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从IMDb 250强电影数据框架中提取有用信息</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/dc5ddc83e03b79bfa23268dd0c368382.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TwYiSWOoOxQ3E6n1"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">Avel Chuklanov 在<a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="7a52" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章是我分析<a class="ae js" href="https://www.imdb.com/chart/top" rel="noopener ugc nofollow" target="_blank">IMDb 250强电影</a>之旅的第二部分。在<a class="ae js" rel="noopener" href="/analytics-vidhya/analyzing-imdbs-top-250-movies-part-1-let-scrape-some-data-a422adc3eb8d">第一部分</a>；早在一月份，我经历了如何从收视率最高的电影中搜集IMDb排行榜的数据，并从中创建一个广泛的数据框架。可悲的是，生活挡住了我的去路，直到现在我都无法回到过去。所以，我关于不对第1部分中的数据做任何事情的玩笑实现了😝</p><p id="6fa4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">无论如何，在这一部分，我将回顾我是如何从主数据框架中提取信息并创建有用的数据集的。这将允许我策划和分析这些电影，并帮助我理解<strong class="ig hi"> <em class="jt">决定一部电影是否成功的因素是什么？</em>T11】</strong></p><blockquote class="ju jv jw"><p id="eecb" class="ie if jt ig b ih ii ij ik il im in io jx iq ir is jy iu iv iw jz iy iz ja jb ha bi translated">同样，对于那些不想通读全文而只是对代码感兴趣的人来说，这里有到Python Jupiter笔记本的<a class="ae js" href="https://github.com/SDhanush163/NoMoIMDb/blob/main/imdb-data-analytics-extractor.ipynb" rel="noopener ugc nofollow" target="_blank"> Github链接</a>。如果你喜欢，就把它丢给a⭐️。</p></blockquote><h1 id="8789" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">在我们开始提取数据之前</h1><p id="6eb4" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">原始数据帧包含每部电影的30多个唯一数据点。这包括名称、评级和发行年份等细节；电影制作细节，如制作公司、导演、编剧和明星；它的预算细节，语言，流派，等等。</p><p id="c980" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我开始提取数据集之前，为了让我的生活更轻松，我选择将电影分成几十年。用一行代码就可以很容易地将它添加到数据帧中；将year列中的值除以底数，然后乘以10。</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="309e" class="li kb hh le b fi lj lk l ll lm"><strong class="le hi">movie_data['decade']</strong> = ((movie_data['year'] // 10).astype(int) * 10)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ln"><img src="../Images/df098ec5e4845da64439a34a7a5b6525.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/1*rb6Q8Sj0VMOiZgIJrHvTsw.gif"/></div></figure><p id="7327" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我选择按年代对电影进行分组，背后有一个很好的理由。有几个字段，如电影的数量，评级等。我想比较一下世界反应时。假设数据只包含250个不同的点，发布年份从1921年到2020年，在最坏的情况下，我可能会得到过于平坦的数据，其中很多年份都没有或只有一个数据点。</p><blockquote class="ju jv jw"><p id="0829" class="ie if jt ig b ih ii ij ik il im in io jx iq ir is jy iu iv iw jz iy iz ja jb ha bi translated">注:十年从定义十年的年份开始。因此，假设2010年从2010年开始，到2019年结束</p></blockquote><h1 id="4526" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">让我们开始提取📁</h1><p id="edad" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">如前所述，我已经列出了几个领域，我相信这些领域会提供有用的信息。我感兴趣的另一种比较是分类数据的比较。概括地说，我将提取过程分为两个部分:</p><ol class=""><li id="3f17" class="lo lp hh ig b ih ii il im ip lq it lr ix ls jb lt lu lv lw bi translated">为基于时间的比较提取数据集。</li><li id="015e" class="lo lp hh ig b ih lx il ly ip lz it ma ix mb jb lt lu lv lw bi translated">分类数据集的提取。</li></ol><h2 id="44f5" class="li kb hh bd kc mc md me kg mf mg mh kk ip mi mj ko it mk ml ks ix mm mn kw mo bi translated">用于基于时间的比较的数据集提取⏰</h2><p id="a2a5" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">第一个也是最容易提取的数据集是每十年的电影数量。现在，您可能会认为我需要某种计数器来计算每个特定十年的电影数量，然后根据该十年存储它们。是的，这是实现它的一种方式。但是让我告诉你如何用一种更简单的方法来实现。</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="5259" class="li kb hh le b fi lj lk l ll lm"><strong class="le hi">no_movies_per_decade</strong> = pd.DataFrame({<br/>   "decade" : movie_data['decade'].value_counts().index,<br/>   "movies" : movie_data['decade'].value_counts()<br/>}).sort_values('decade').reset_index(drop = True)</span><span id="eb8a" class="li kb hh le b fi mp lk l ll lm">no_movies_per_decade_json = no_movies_per_decade.to_dict('records')</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mq"><img src="../Images/5559c15249de4fbd1b2f68808a24dab9.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/1*b0xjOF8CYezVQ94Li03tDw.gif"/></div></figure><p id="e708" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如他们所说，“这是非常基本的，亲爱的。”你看，我不需要把每部电影都与一个独特的十年相对照。“十年”字段为我做了这件事。我所要做的就是计算每个十年重复多少次，瞧，我得到了我想要的结果。此外，代码中的最后一行是将数据集从Pandas DataFrame转换为JSON数组。</p><p id="08ab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我想提取的下一组数据集是每十年电影获得的平均评分和投票。在这一点上，需要注意的是，虽然pandas可以隐式地识别数值和非数值，但是它在执行这种识别时的智能程度非常有限。因此，虽然它正确地将评级标识为<code class="du mr ms mt le b">float64</code>，但投票被标识为<code class="du mr ms mt le b">object</code>，这意味着在计算平均值之前，我必须将它们转换为<code class="du mr ms mt le b">int</code>。</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="761c" class="li kb hh le b fi lj lk l ll lm"><strong class="le hi">movie_rating_per_decade </strong>= pd.DataFrame({<br/>   "decade" : movie_data['decade'].value_counts().index,<br/>   "mean_rating" : None<br/>}).sort_values('decade').reset_index(drop = True)</span><span id="fca6" class="li kb hh le b fi mp lk l ll lm"><em class="jt">for</em> i <em class="jt">in</em> range(len(movie_rating_per_decade)):<br/>   decade_filter = movie_data['decade'] == <br/>                   movie_rating_per_decade.iloc[i,0]<br/>   filtered_movies = movie_data[decade_filter]<br/>   movie_rating_per_decade.iloc[i,1] = <br/>                   round(filtered_movies['rating'].mean(), 3)</span></pre><p id="dbcd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">提取每十年电影平均收视率的过程非常简单。我从一个包含每个独特十年和平均评级栏的数据框架开始。但是，在数据框架定义期间，我没有向“平均评级”列添加任何值。对于这个专栏，我将筛选特定十年的电影，然后从这些筛选出的电影中，找到这十年的平均评级。</p><p id="8938" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">好了，现在让我们来处理一下投票被识别为对象而不是整数的小烦恼。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ln"><img src="../Images/80957ca805197f4cd840f0cf0c052ef5.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/1*kT0NFq-dUqaiAVCTG5DHxA.gif"/></div></figure><p id="a72f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">老实说，解决方案非常简单，应该早点解决。我所要做的就是用一个简单的lambda过滤投票列中的值，只允许数字。类似<code class="du mr ms mt le b">int(‘’.join(filter(lambda x : x.isdigit(), movies_data.iloc[i,6] )))</code>的东西</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="60ca" class="li kb hh le b fi lj lk l ll lm">decade_to_vote =  pd.DataFrame({<br/>   'decade' : movie_data['decade'].values,<br/>   'votes' : movie_data['vote_count'].values<br/>})</span><span id="442a" class="li kb hh le b fi mp lk l ll lm"><em class="jt">for</em> i <em class="jt">in</em> range(len(decade_to_vote)):<br/>   decade_to_vote.iloc[i,1] = int(''.join(filter(lambda x : x.isdigit(), decade_to_vote.iloc[i,1] )))</span><span id="dc04" class="li kb hh le b fi mp lk l ll lm"><em class="jt">for</em> i <em class="jt">in</em> range(len(movie_votes_per_decade)):<br/>   decade_filter = decade_to_vote['decade'] == <br/>                   movie_votes_per_decade.iloc[i,0]<br/>   filtered_votes = decade_to_vote[decade_filter]<br/>   movie_votes_per_decade.iloc[i,1] = <br/>                   round(filtered_votes['votes'].mean(), 3)</span></pre><p id="5ead" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里，我添加了一点额外的逻辑来帮助我提取数据集。首先，我添加了一个DataFrame来分别获取Decade和vote列。然后，我执行了类型转换和过滤，类似于这个数据帧上的评级。</p><p id="052a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我想创建的最后一个数据集涉及票房数据。这意味着预算，全球，美国的总收入，以及在美国的开幕周。检索它们与我创建平均投票数据集所做的是一样的，但是这里不是有一列，而是有4列。</p><blockquote class="ju jv jw"><p id="fdba" class="ie if jt ig b ih ii ij ik il im in io jx iq ir is jy iu iv iw jz iy iz ja jb ha bi translated">我知道我必须将这四个字段转换成整数，因为我选择了包含它们的货币符号。</p></blockquote><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ln"><img src="../Images/1590bd7211729b3d620bc4393286bcda.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/1*RIMI6vSoY5GKLHg5KclqFg.gif"/></div></figure><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="b97b" class="li kb hh le b fi lj lk l ll lm">movie_budget_per_decade = pd.DataFrame({<br/>   "decade" : movie_data['decade'].value_counts().index,<br/>   "mean_budget" : None,<br/>   "mean_gross_worldwide" : None,<br/>   "mean_gross_usa": None,<br/>   "mean_opening_week_usa":None<br/>}).sort_values('decade').reset_index(drop = True</span></pre><p id="2db1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这意味着数据帧看起来像这样。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mu"><img src="../Images/6681bdfadae4bfddf206b5f0ee065b9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*62YTruSOGQAEZaX4Idzjxw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">每十年票房详情</figcaption></figure><h2 id="a56a" class="li kb hh bd kc mc md me kg mf mg mh kk ip mi mj ko it mk ml ks ix mm mn kw mo bi translated">分类数据集及其处理方法</h2><p id="22cb" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">我感兴趣的列包含非有序分类数据。看到这一点，许多人可能会选择对数据进行编码，然后处理这一大堆蠕虫。如果以前没有人说过，让我第一个告诉你，你不必每次遇到分类数据都执行编码。不需要对数据进行编码就可以直接获得大量信息。</p><p id="2030" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我向您展示为什么<code class="du mr ms mt le b">Pandas</code>是处理数据的首选库，以及它如何能够大大简化我的生活。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mv"><img src="../Images/aa99907e18cc57e66c7a927ef67d3ec1.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/1*qtKj6W6luJv9wEyobcxglw.gif"/></div></figure><ol class=""><li id="f4bb" class="lo lp hh ig b ih ii il im ip lq it lr ix ls jb lt lu lv lw bi translated"><code class="du mr ms mt le b">value_counts()</code>是Pandas提供的一种方法，它返回一个包含唯一值计数的序列。它完全简化了唯一值的计数。您不再需要执行一次性编码，然后计算出现次数。<code class="du mr ms mt le b">Pandas</code>那就去办吧。</li><li id="4d2d" class="lo lp hh ig b ih lx il ly ip lz it ma ix mb jb lt lu lv lw bi translated"><code class="du mr ms mt le b">Pandas</code>有多种方法，如<code class="du mr ms mt le b">isnull(), notnull(), dropna()</code>等。，它可以帮助我们直接从数据帧中找到并处理丢失的数据。</li></ol><h2 id="4f44" class="li kb hh bd kc mc md me kg mf mg mh kk ip mi mj ko it mk ml ks ix mm mn kw mo bi translated">🧮分类数据集的提取</h2><p id="daf9" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">对于分类数据，我希望获得两个主要指标，每个唯一点的出现次数，以及与之相关的平均IMDB评分。至于我对哪些数据感兴趣；我想提取一些与电影相关的细节和一些一般的细节。这些是:</p><ol class=""><li id="d32b" class="lo lp hh ig b ih ii il im ip lq it lr ix ls jb lt lu lv lw bi translated">导演、制作公司、审查等级和类型。</li><li id="86f8" class="lo lp hh ig b ih lx il ly ip lz it ma ix mb jb lt lu lv lw bi translated">使用的语言和电影拍摄的国家。</li></ol><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="cf17" class="li kb hh le b fi lj lk l ll lm">director_data = pd.DataFrame({<br/>   'director' : movie_data['director'].value_counts().index,<br/>   'count' : movie_data['director'].value_counts(),<br/>   'mean_imdb_rating' : None<br/>}).sort_values('director').reset_index(drop = True)</span></pre><p id="94d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于每个数据集，过程是相同的。首先，我创建了一个数据框架，其中包含指数、计数和一个IMDb平均评级字段。<code class="du mr ms mt le b">value_counts()</code>方法让我可以轻松获得每个数据点的索引和计数。计算平均IMDb评分的过程类似于我之前写的。</p><p id="587a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，对于没有值的字段，如第二、第三和第四语言等。，我选择将这些字段转换成<code class="du mr ms mt le b">NaN</code>，然后使用Pandas提供的方法<code class="du mr ms mt le b">dropna()</code>删除它们。</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="3901" class="li kb hh le b fi lj lk l ll lm">secondary_language_data['language'].replace(' ', np.nan, inplace=True)</span><span id="12aa" class="li kb hh le b fi mp lk l ll lm">secondary_language_data.dropna(subset=['language'], inplace=True)</span></pre><p id="74a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以最后，提取分类数据的整个代码<em class="jt">(记住它们都遵循或多或少相同的前提)</em>看起来像这样:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="a89f" class="li kb hh le b fi lj lk l ll lm"><strong class="le hi">primary_language_data</strong> = pd.DataFrame({<br/>   'language' : movie_data['language_1'].value_counts().index,<br/>   'count' : movie_data['language_1'].value_counts(),<br/>   'mean_imdb_rating' : None<br/>}).sort_values('language').reset_index(drop = True)</span><span id="4a4b" class="li kb hh le b fi mp lk l ll lm">primary_language_data['language'].replace(' ', np.nan, inplace=True)<br/>primary_language_data.dropna(subset=['language'], inplace=True)</span><span id="6c7e" class="li kb hh le b fi mp lk l ll lm"><em class="jt">for</em> i <em class="jt">in</em> range(len(primary_language_data)):<br/>   language_filter = movie_data['language_1'] == <br/>                     primary_language_data.iloc[i,0]<br/>   filtered_movies = movie_data[language_filter]<br/>   primary_language_data.iloc[i,2] = <br/>                     round(filtered_movies['rating'].mean(), 3)</span><span id="6d00" class="li kb hh le b fi mp lk l ll lm"><strong class="le hi">primary_language_data_json</strong>= primary_language_data.to_dict('records')</span></pre><p id="ab8b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">提取了我想要的所有数据集后，最后一步是将它们保存为所需的格式，以便我可以绘制和分析数据。与第1部分类似，我将所有数据集保存在一个JSON对象中，并将每个数据帧保存为一个CSV文件。我不打算在这里重复我是如何拯救他们的，因为我已经在这里解释过<a class="ae js" rel="noopener" href="/analytics-vidhya/analyzing-imdbs-top-250-movies-part-1-let-scrape-some-data-a422adc3eb8d#4090"/>。</p><p id="2e56" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">好了，我旅程的第二部分到此结束。剩下的就是绘制和分析数据。当我完成分析后，我会尽快公布结果。与此同时，我希望您喜欢并找到一些有用的信息，以便提取有用的数据。我也希望我能够提供一些关于熊猫作为一个数据操作库有多强大的提示。</p><p id="e380" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样，完整的代码可以在GitHub的Python Jupyter笔记本<a class="ae js" href="https://github.com/SDhanush163/NoMoIMDb/blob/main/imdb-data-analytics-extractor.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>获得。如果你喜欢，就把它丢给⭐️。如果您对此有任何问题、疑问或想法，请随时👏并评论。谢谢！</p></div><div class="ab cl mw mx go my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="ha hb hc hd he"><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es nd"><img src="../Images/7ea767a7c32cac525b6d2827e8037f76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_LJJlJgbRLbDPgyX"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">皮特·佩德罗萨在<a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure></div></div>    
</body>
</html>