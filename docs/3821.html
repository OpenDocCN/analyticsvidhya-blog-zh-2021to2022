<html>
<head>
<title>Data Science 101:- Web Scraping</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学101:-网络搜集</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-science-101-web-scraping-67c3615dbbc4?source=collection_archive---------3-----------------------#2021-07-29">https://medium.com/analytics-vidhya/data-science-101-web-scraping-67c3615dbbc4?source=collection_archive---------3-----------------------#2021-07-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="c34b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用python通过web报废收集数据</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/15c06dc55d83a8dcd2b625f70cc031be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_htPcgL2a81qoYCxSVeqMA.png"/></div></div></figure><h1 id="24d7" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">介绍</h1><p id="e2b2" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">你好。数据科学只有在有数据的情况下才有可能，而在现实世界中，数据并不容易获得。你必须去追求它。这就是为什么网络抓取对数据科学非常重要。</p><p id="1744" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文将介绍如何利用Python库，如<a class="ae kr" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">【美汤】</strong> </a> <strong class="ig hi"> </strong>和<strong class="ig hi"> </strong> <a class="ae kr" href="https://pandas.pydata.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> pandas </strong> </a>从web上获取相关信息并执行Web抓取。对于那些想要完整代码的人，我在文章末尾添加了GitHub资源库链接。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ks"><img src="../Images/24864b6c115dcd1312ad192e5d1b81ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4RIXfWCSrDsagQWHil5unw.jpeg"/></div></div></figure><h1 id="a571" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">什么是网页抓取？</h1><p id="ecc0" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">与漫长而繁琐的手动获取数据的过程不同，Web抓取使用智能自动化方法在更短的时间内获取数千甚至数百万的数据集。它为您提供了一种自动访问结构化web数据的技术。</p><p id="a271" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">网页抓取的过程可以大致分为三个步骤:</p><ol class=""><li id="c011" class="kt ku hh ig b ih ii il im ip kv it kw ix kx jb ky kz la lb bi translated">理解并检查网页，找到与我们想要的信息相关的HTML标记。</li><li id="fdb9" class="kt ku hh ig b ih lc il ld ip le it lf ix lg jb ky kz la lb bi translated">使用Beautiful Soup、Selenium和/或其他Python库来抓取HTML页面。</li><li id="453b" class="kt ku hh ig b ih lc il ld ip le it lf ix lg jb ky kz la lb bi translated">处理收集到的数据，使其成为我们需要的形式。</li></ol><blockquote class="lh li lj"><p id="43c8" class="ie if lk ig b ih ii ij ik il im in io ll iq ir is lm iu iv iw ln iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">用于网页抓取的库</em> </strong></p></blockquote><p id="12bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了用Python实现web抓取，必须包含以下几个库</p><ol class=""><li id="0748" class="kt ku hh ig b ih ii il im ip kv it kw ix kx jb ky kz la lb bi translated"><strong class="ig hi">美汤</strong>:用于将HTML和XML文件中的数据拉出来。它从页面源代码中创建了一个解析树，可用于以层次化和可读性更强的方式提取数据。</li><li id="534d" class="kt ku hh ig b ih lc il ld ip le it lf ix lg jb ky kz la lb bi translated"><strong class="ig hi"> Pandas: </strong> Pandas允许从各种文件格式导入数据，如逗号分隔值、JSON、SQL、Microsoft Excel。Pandas允许各种数据操作，如合并、整形、选择、数据清理和数据辩论功能。</li><li id="a8ff" class="kt ku hh ig b ih lc il ld ip le it lf ix lg jb ky kz la lb bi translated"><strong class="ig hi">请求:</strong>它允许你轻松发送HTTP/1.1请求，并且不需要手动添加查询字符串到你的URL，或者对你的文章数据进行格式编码。</li></ol><h1 id="0bfa" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">先说我们的例子。</h1><p id="8a3b" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">准备执行网页抓取。按照步骤获取您的数据。</p><h1 id="9d96" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤1:选择您想要从中抓取数据的URL</h1><p id="b1c1" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">在这里，我将抓取IMDb网站，提取最受欢迎的电影，它们的名称，年份和IMDb评级。同样的网址是<a class="ae kr" href="https://www.imdb.com/chart/tvmeter/?ref_=nv_tvv_mptv" rel="noopener ugc nofollow" target="_blank">https://www.imdb.com/chart/</a>电影计量器。</p><h1 id="d46b" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤2:检查页面</h1><p id="6015" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">这一步包括调查网页的HTML。要检查哪些标签包含我们的信息，请在浏览器中右键单击该元素，然后选择“Inspect”。数据通常嵌套在标签中。因此，我们检查页面，找出所需数据嵌套在哪个标签下。</p><h1 id="f3d6" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤3:找到要提取的数据</h1><p id="dd24" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">在这个例子中，我将提取最受欢迎的电影的标题、上映年份和IMDb评分。在这种情况下，表中的相关信息与标签<code class="du lo lp lq lr b">&lt;td&gt;</code>相关联。使用标签，我们的主要抓取库可以在整个抓取过程中有效地定位和解析信息。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ls"><img src="../Images/bd4a880bd6515f9bd2a9f0a746d0df6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5eRlzfUkQa228X1G1PNhbw.png"/></div></div></figure><h1 id="d9c3" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤4:编写python代码</h1><p id="6e89" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">让我们从创建一个Python文件开始。在这里，我使用了谷歌Colab。您可以使用任何Python IDE。</p><p id="41a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">导入所需的python库:</p><pre class="jd je jf jg fd lt lr lu lv aw lw bi"><span id="574b" class="lx jp hh lr b fi ly lz l ma mb">import requests<br/>from bs4 import BeautifulSoup<br/>import pandas as pd</span></pre><p id="9598" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">创建空数组来存储抓取的数据。</p><pre class="jd je jf jg fd lt lr lu lv aw lw bi"><span id="1bb8" class="lx jp hh lr b fi ly lz l ma mb">Title=[]  #List to store title of most popular movies<br/>Year=[]   #List to store releasing year of each movies<br/>Rating=[] #List to store ratings of each movies</span></pre><p id="7043" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，打开URL并从网站中提取数据。使用请求库，向网页发出请求并获取其HTML。上面的代码将网页的HTML内容存储到一个<code class="du lo lp lq lr b">BeautifulSoup</code>对象中。使用Beautiful Soup的Find和Find All函数，我们可以很容易地将所需的信息存储在变量中。最后，将数据追加到先前创建的空数组中。你完了！</p><pre class="jd je jf jg fd lt lr lu lv aw lw bi"><span id="e4fb" class="lx jp hh lr b fi ly lz l ma mb">url = "<a class="ae kr" href="https://www.imdb.com/chart/moviemeter" rel="noopener ugc nofollow" target="_blank">https://www.imdb.com/chart/moviemeter</a>"</span><span id="abf1" class="lx jp hh lr b fi mc lz l ma mb">#Make a request to the web page and gets it's HTML<br/>content = requests.get(url).content</span><span id="b67d" class="lx jp hh lr b fi mc lz l ma mb">#Store the HTML page in 'soup', a BeautifulSoup object<br/>soup = BeautifulSoup(content, "html.parser")</span><span id="b2bf" class="lx jp hh lr b fi mc lz l ma mb">for i in soup.find("tbody", {"class":"lister-list"}).find_all("tr"):<br/>    h = i.find("td",{"class":"titleColumn"})<br/>    title = h.find("a", href=True)<br/>    year = i.find("span",{"class":"secondaryInfo"})<br/>    rating = i.find("td",{"class":"ratingColumn imdbRating"})<br/>    <br/>    Title.append(title.text) <br/>    Year.append(year.text)<br/>    Rating.append(rating.text.strip("\n"))</span></pre><h1 id="fed7" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">第5步:以逗号分隔的值存储抓取的数据(CSV格式)</h1><p id="bfc4" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">现在，使用导入的Pandas库，创建一个数据帧，其中的数据以结构化的方式存储，并导出为所需的文件格式。在这里，我已经导出了数据。csv格式。</p><pre class="jd je jf jg fd lt lr lu lv aw lw bi"><span id="2eaf" class="lx jp hh lr b fi ly lz l ma mb">df = pd.DataFrame({'Most Popular Movies' : Title,'Year' : Year,'Rating' : Rating})<br/>df.to_csv('IMDb.csv', index=False, encoding='utf-8')#read the data stored in IMBd.csv file<br/>data = pd.read_csv('IMDb.csv')</span></pre><h1 id="be7a" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">步骤6:运行您的代码</h1><p id="bf08" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">您可以在IMDb.csv文件中查看所有抓取的数据，如下所示。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es md"><img src="../Images/eb0fe2543674d5db0470904cf3ac901a.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*pGnVv7AobK2nMZU0uzkD7Q.png"/></div></div><figcaption class="me mf et er es mg mh bd b be z dx translated">存储在IMDb.csv文件中的抓取数据</figcaption></figure><blockquote class="lh li lj"><p id="0863" class="ie if lk ig b ih ii ij ik il im in io ll iq ir is lm iu iv iw ln iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">结论:</em> </strong></p></blockquote><p id="ae22" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以通过使用web scrapping库(如beautiful soup、scrappy等)从网页中获取任何数据。在转换成pandas后，我们可以对该数据应用所有Pandas函数。</p><p id="7a40" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">更多关于<strong class="ig hi">熊猫</strong>功能<a class="ae kr" href="https://pandas.pydata.org/pandas-docs/stable/reference/general_functions.html" rel="noopener ugc nofollow" target="_blank">在这里。</a></p><p id="3088" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">更多关于<strong class="ig hi">美汤</strong> <a class="ae kr" href="https://beautiful-soup-4.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank">在这里。</a></p><p id="3725" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就是这样。希望这篇博客对你有所帮助。查看我的<a class="ae kr" href="https://github.com/d2001patel/Data-Science" rel="noopener ugc nofollow" target="_blank"> GitHub </a>档案中的全部代码。</p><blockquote class="lh li lj"><p id="f978" class="ie if lk ig b ih ii ij ik il im in io ll iq ir is lm iu iv iw ln iy iz ja jb ha bi translated"><strong class="ig hi">领英:</strong></p></blockquote><div class="mi mj ez fb mk ml"><a href="https://www.linkedin.com/in/darshil-patel-80a728199/" rel="noopener  ugc nofollow" target="_blank"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hi fi z dy mq ea eb mr ed ef hg bi translated">Darshil Patel -软件工程师实习生-scan point Geomatics Ltd | LinkedIn</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">查看达尔希尔·帕特尔在全球最大的职业社区LinkedIn上的个人资料。达尔希尔有2份工作列在…</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">www.linkedin.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz jm ml"/></div></div></a></div></div></div>    
</body>
</html>