<html>
<head>
<title>Training a Custom Object Detection Model With Yolo-V5</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Yolo-V5训练自定义对象检测模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/training-a-custom-object-detection-model-with-yolo-v5-aa9974c07088?source=collection_archive---------0-----------------------#2021-01-01">https://medium.com/analytics-vidhya/training-a-custom-object-detection-model-with-yolo-v5-aa9974c07088?source=collection_archive---------0-----------------------#2021-01-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/8a076831198f817cad6b981ff352a8eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cqf_w3I8rmEfsog9_M4zWA.png"/></div></div></figure><p id="fe17" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">目标检测是计算机视觉中的一项任务，其重点是检测图像/视频中的目标。</p><p id="cfaa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有各种对象检测算法，如YOLO(你只看一次)，单镜头检测器(SSD)，更快的R-CNN，梯度方向直方图(HOG)等。</p><p id="0e68" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在本文中，我们将使用Yolo-V5来训练我们的自定义对象检测模型。YOLO是最著名的目标检测模型之一。</p><p id="4eb4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">YOLO-V5的1.0版本于2020年5月27日由<a class="ae jo" href="https://github.com/ultralytics" rel="noopener ugc nofollow" target="_blank"> Utralytics </a>的创始人&amp;CEO<a class="ae jo" href="https://www.linkedin.com/in/glenn-jocher" rel="noopener ugc nofollow" target="_blank">格伦·约彻</a>发布。它是用PyTorch写的，可以在<a class="ae jo" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> Github </a>上下载。</p><h2 id="2fa5" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated"><strong class="ak">先决条件</strong></h2><p id="50eb" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">有深度学习计算机视觉的基础知识就好。以及如何在Google Colab环境下工作。</p><h2 id="b582" class="jp jq hi bd jr js jt ju jv jw jx jy jz jb ka kb kc jf kd ke kf jj kg kh ki kj bi translated">本教程涵盖的步骤</h2><p id="a662" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">要训练我们自己的自定义对象检测器，请遵循以下步骤</p><ul class=""><li id="e9ee" class="kp kq hi is b it iu ix iy jb kr jf ks jj kt jn ku kv kw kx bi translated">准备数据集</li><li id="722e" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">环境设置:安装YOLOv5依赖项</li><li id="9a50" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">设置数据和目录</li><li id="0fe8" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">为培训建立YAML档案</li><li id="bdce" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">训练模型</li><li id="6342" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">评估模型</li><li id="1aca" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">可视化训练数据</li><li id="3885" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">在测试图像上运行推理</li><li id="0a97" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">导出权重文件以备后用</li></ul><h1 id="931a" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">准备数据集</h1><p id="5fa7" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">我们将使用<a class="ae jo" href="https://public.roboflow.com/object-detection/aquarium" rel="noopener ugc nofollow" target="_blank"> <strong class="is hj">水族馆数据集</strong> </a>，它在<a class="ae jo" href="https://public.roboflow.com/object-detection" rel="noopener ugc nofollow" target="_blank"> Roboflow公共对象检测数据集</a>中可用。你可以查看那里更多的数据集。</p><p id="dac1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">水族馆数据集由638幅图像组成。这些图像已经被Roboflow团队标记了。它有7类，如鱼，水母，企鹅，鲨鱼，海雀，黄貂鱼和海星，大多数图像包含多个边界框。</p><p id="1e41" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要下载数据集，您需要首先创建一个roboflow帐户。非常简单容易。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/42c39a570231b9b15c99fcd90ce5898b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SCY870BMPNewUZ3MGOMihg.png"/></div></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">资料来源:https://public.roboflow.com/object-detection/aquarium</figcaption></figure><p id="2ae9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你想使用自己的图像，你可以使用标注工具，如<a class="ae jo" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"> LabelImg </a>、<a class="ae jo" href="https://github.com/openvinotoolkit/cvat" rel="noopener ugc nofollow" target="_blank"> CVAT </a>或者你可以尝试任何大规模的解决方案，如scale或AWS Ground Truth。</p><p id="f718" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当您为自己添加注释时，请确保遵循最佳实践。查看此<a class="ae jo" href="https://nanonets.github.io/tutorials-page/docs/annotate" rel="noopener ugc nofollow" target="_blank">链接</a>了解更多详情。</p><p id="f2b4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">准备好数据集后，我们就可以设置环境并训练数据集了。</p><h1 id="edfe" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">环境设置</h1><p id="06b0" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">这是我笔记本的链接:<a class="ae jo" href="https://colab.research.google.com/drive/16QCaYzTuHCOF9CQLQYmGNxmtY1xKAIdn?usp=sharing" rel="noopener ugc nofollow" target="_blank">谷歌实验室</a></p><p id="c13f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你需要一个谷歌账户才能使用谷歌Colab。您可以使用我的笔记本进行培训，也可以创建自己的笔记本并跟随学习。</p><p id="ffeb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在Google Colab中，你将获得12小时的免费GPU。如果您在Colab中使用新笔记本，请将运行时会话更改为GPU。</p><p id="7f47" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果您打算使用我的笔记本，请确保文件→在您的驱动器中保存一份副本。然后，您将能够编辑代码。</p><p id="d8a9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">安装依赖关系</strong></p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="94b3" class="jp jq hi me b fi mi mj l mk ml">!git clone https://github.com/ultralytics/yolov5  # clone repo!pip install -U -r yolov5/requirements.txt  # install dependencies</span></pre><p id="7b42" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">不知何故，PyTorch版本与GPU不兼容，所以我安装了PyTorch的另一个版本</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="25da" class="jp jq hi me b fi mi mj l mk ml">#installing for google colab GPU use</span><span id="cca2" class="jp jq hi me b fi mm mj l mk ml">!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f <a class="ae jo" href="https://download.pytorch.org/whl/torch_stable.html" rel="noopener ugc nofollow" target="_blank">https://download.pytorch.org/whl/torch_stable.html</a><br/></span></pre><p id="d6d2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi">.</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="bb85" class="jp jq hi me b fi mi mj l mk ml">%cd /content/yolov5<br/>!ls</span></pre><p id="cca6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以导入，看看我们Google Colab提供的GPU规范。</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="d470" class="jp jq hi me b fi mi mj l mk ml">import torch</span><span id="be68" class="jp jq hi me b fi mm mj l mk ml">from IPython.display import Image  # for displaying images</span><span id="5258" class="jp jq hi me b fi mm mj l mk ml">from utils.google_utils import gdrive_download  # for downloading models/datasets</span><span id="8d2f" class="jp jq hi me b fi mm mj l mk ml">print('Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))<br/></span></pre><p id="000f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是我得到的</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="fac9" class="jp jq hi me b fi mi mj l mk ml">Using torch 1.6.0+cu101 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15079MB, multi_processor_count=40)</span></pre><p id="a19d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Google Colab预装了Cuda和Torch以及其他一些依赖项。如果你计划在本地培训，那么你必须自己设置Cuda和依赖关系。我以后肯定会做一个关于它的教程。</p><h1 id="381f" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">设置数据和目录</h1><p id="d3a3" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">环境设置完成后。我们可以将数据集导入colab。由于我正在使用我将要下载的Roboflow数据集，如果你打算使用你自己的数据集，你可以使用Google Drive导入它。</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="177b" class="jp jq hi me b fi mi mj l mk ml"># You need to sign up in roboflow to get the key and then you can use the dataset</span><span id="02e0" class="jp jq hi me b fi mm mj l mk ml">!curl -L “https://public.roboflow.com/ds/PUT YOUR OWN KEY HERE” &gt; roboflow.zip; unzip roboflow.zip; rm roboflow.zip</span></pre><p id="2ef1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将下载数据，解压缩并保存在yolov5目录中。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/0c3820d65ff6d871a3fbb8583e1aaa65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mqGSVF2Hr9eSJH-fh6u4dw.png"/></div></div></figure><p id="98a3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">项目文件夹结构</strong></p><figure class="lv lw lx ly fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/bbde02f5bc0a5eab5bc3ddd81493f2e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*o61Ydwo-W0UTviM_p9uBWw.png"/></div></figure><h1 id="5107" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">为培训建立YAML档案</h1><p id="587e" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">为了训练一个YOLO-V5模型，我们需要两个YAML文件。</p><p id="b013" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第一个YAML明确指出:</p><ul class=""><li id="992e" class="kp kq hi is b it iu ix iy jb kr jf ks jj kt jn ku kv kw kx bi translated">我们的培训和验证数据在哪里</li><li id="6097" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">我们想要检测的类的数量</li><li id="d22c" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">以及对应于这些类别的名称</li></ul><p id="b2a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们的这个YAML看起来像这样:</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="13eb" class="jp jq hi me b fi mi mj l mk ml">train: ./train/images <br/>val: ./valid/images  </span><span id="9131" class="jp jq hi me b fi mm mj l mk ml">nc: 7 <br/>names: ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']</span></pre><p id="b2b3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第二个YAML是指定整个模型配置。如果您愿意，可以在这一步更改网络架构，但我们将使用默认架构。</p><p id="883d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们称之为<code class="du mp mq mr me b">custom_yolov5s.yaml</code>的YAML:</p><figure class="lv lw lx ly fd ij"><div class="bz dy l di"><div class="ms mt l"/></div></figure><p id="f014" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以把YAML文件放在任何我们想要的地方，因为我们可以在以后引用文件路径。但是将它放在YoloV5目录中是一个好主意。</p><h1 id="1974" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">训练模型</h1><p id="d692" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">配置完成后，我们可以开始我们的培训。</p><p id="e834" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们可以指定多个超参数，它们是:</p><ul class=""><li id="65c9" class="kp kq hi is b it iu ix iy jb kr jf ks jj kt jn ku kv kw kx bi translated"><strong class="is hj"> img: </strong>定义输入图像尺寸</li><li id="6a76" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><strong class="is hj">批量:</strong>确定批量大小</li><li id="1f4a" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><strong class="is hj">时期:</strong>定义训练时期的数量。</li><li id="c3f8" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><strong class="is hj">数据:</strong>设置我们YAML文件的路径</li><li id="5425" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><strong class="is hj"> cfg: </strong>指定我们的模型配置</li><li id="ea3b" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><strong class="is hj">权重:</strong>指定权重的自定义路径</li><li id="72ea" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><strong class="is hj">名称:</strong>结果名称</li><li id="6b26" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><strong class="is hj"> nosave: </strong>仅保存最后一个检查点</li><li id="b2cf" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><strong class="is hj">缓存:</strong>缓存图像以加快训练速度</li></ul><p id="a301" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们需要指定上面创建的两个YAML文件的路径。</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="260f" class="jp jq hi me b fi mi mj l mk ml"><br/>%cd /content/yolov5/</span><span id="3a48" class="jp jq hi me b fi mm mj l mk ml">!python train.py --img 416 --batch 80 --epochs 100 --data './data.yaml' --cfg ./models/custom_yolov5s.yaml --weights ''</span></pre><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/6d48f8edd6734f8b6dc6ec8bddfe5204.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*dOzYusJMMAy766JT1QPGnQ.gif"/></div></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">培养</figcaption></figure><p id="8817" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用100个epochs，训练在35分钟内完成。</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mv"><img src="../Images/2158311e972a793cc2f4ed10f276fee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZtvE6f_rqG-0l2fc866wxg.png"/></div></div></figure><h1 id="6aa6" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">评估模型</h1><p id="2a23" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">当我们训练时，训练损失和表现指标被保存到Tensorboard和上面定义的带有<strong class="is hj"> — name </strong>标志的日志文件中。在我们的例子中，我们将其命名为<code class="du mp mq mr me b">yolov5s_results</code>。(如果没有给出名称，则默认为<code class="du mp mq mr me b">results.txt</code>。)训练完成后，结果文件被绘制为png。</p><p id="915e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">部分完成的<code class="du mp mq mr me b">results.txt</code>文件可以用<code class="du mp mq mr me b">from utils.utils import plot_results; plot_results()</code>出图。</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="5071" class="jp jq hi me b fi mi mj l mk ml"># Start tensorboard<br/># Launch after you have started training to all the graphs needed for inspection<br/># logs save in the folder "runs"</span><span id="f178" class="jp jq hi me b fi mm mj l mk ml">%load_ext tensorboard<br/>%tensorboard --logdir /content/yolov5/runs</span></pre><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mw"><img src="../Images/3b30e9a98f2b29f8c6b4bca66ea3b425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*H7YQvi6jiEDOBdKVj1o75Q.png"/></div></div></figure><h1 id="25aa" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">可视化训练数据</h1><p id="32cf" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">训练开始后，查看<code class="du mp mq mr me b">train*.jpg</code>图像，查看训练图像、标签和增强效果。我们可以可视化地面实况训练数据，以及地面实况、增强数据。</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="e2a2" class="jp jq hi me b fi mi mj l mk ml"># first, display our ground truth data<br/># The ground truth [Train data] is available in jpg file at location /content/yolov5/runs/train/exp2/test_batch0_labels.jpg<br/></span><span id="5c87" class="jp jq hi me b fi mm mj l mk ml">print("GROUND TRUTH TRAINING DATA:")<br/>Image(filename='/content/yolov5/runs/train/exp2/test_batch0_labels.jpg', width=900)</span></pre><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mx"><img src="../Images/93a4bb395d3382035cbb209bdb9d56e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JvWJw09FBkZ27i3PY2_a1g.png"/></div></div></figure><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="eb0d" class="jp jq hi me b fi mi mj l mk ml"># print out an augmented training example<br/># Below is the augmented training data.<br/># NOTE: The dataset already contains the augmented data with annotations, so that you dont have to do it.</span><span id="0dba" class="jp jq hi me b fi mm mj l mk ml">print("GROUND TRUTH AUGMENTED TRAINING DATA:")<br/>Image(filename='/content/yolov5/runs/train/exp2/train_batch0.jpg', width=900)</span></pre><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mx"><img src="../Images/383ba503815fdb64b38749cb20962bc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JzuN94gto3d0Si1_lDplAA.png"/></div></div></figure><h1 id="16b0" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">运行推理</h1><p id="4814" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">使用训练后保存的最终训练权重，我们可以运行我们的推断</p><p id="7215" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">权重文件夹</strong></p><figure class="lv lw lx ly fd ij er es paragraph-image"><div class="er es my"><img src="../Images/fe4c24cacdd1dafcf1d45df12448d1a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*NjH-Z26sbfkLA4H1-63qJA.png"/></div></figure><p id="a658" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">要运行模型推理，我们可以使用下面的命令。</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="715d" class="jp jq hi me b fi mi mj l mk ml"># use the best weights!<br/># Final weights will be by-default stored at /content/yolov5/runs/train/exp2/weights/best.pt</span><span id="7300" class="jp jq hi me b fi mm mj l mk ml">%cd /content/yolov5/</span><span id="3328" class="jp jq hi me b fi mm mj l mk ml">!python detect.py --weights<br/>/content/yolov5/runs/train/exp2/weights/best.pt --img 416 --conf 0.4 --source ./test/images</span></pre><ul class=""><li id="a139" class="kp kq hi is b it iu ix iy jb kr jf ks jj kt jn ku kv kw kx bi translated">—来源:输入图像目录或单个图像路径或视频路径</li><li id="fd52" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">-权重:训练模型路径</li><li id="c751" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated">— conf:置信度阈值</li></ul><p id="c671" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这将处理输入并将输出存储在我们的推理目录中。</p><p id="8e00" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是一些输出图像:</p><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mz"><img src="../Images/7b2bde05fcfeef33432347c0ce7083b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aUHDgsewTLtl4pP98rskNA.png"/></div></div></figure><figure class="lv lw lx ly fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es na"><img src="../Images/aacc5835ba980b3df691249687af2ae9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jy6bq-oODi0dXuRKJQectg.png"/></div></div></figure><h1 id="1a6d" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">导出重量以备后用</h1><p id="93cd" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">现在我们已经成功地训练了我们的定制模型。我们可以下载重量文件，并将其保存在本地目录或Google Drive中。</p><p id="0f48" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为此，我们导入一个Google Drive模块，然后将它们发送出去</p><pre class="lv lw lx ly fd md me mf mg aw mh bi"><span id="e871" class="jp jq hi me b fi mi mj l mk ml">from google.colab import drive<br/>drive.mount('/content/gdrive')</span><span id="1980" class="jp jq hi me b fi mm mj l mk ml">%cp /content/yolov5/runs/train/exp2/weights/best.pt /content/gdrive/My\ Drive</span></pre><h1 id="3ac3" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">结论</h1><p id="23e9" class="pw-post-body-paragraph iq ir hi is b it kk iv iw ix kl iz ja jb km jd je jf kn jh ji jj ko jl jm jn hb bi translated">我希望你能够跟得上，并且能够成功地训练。</p><p id="28b2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我已经将笔记本、配置文件和重量上传到我的Github存储库中。你可以在这里查看<a class="ae jo" href="https://github.com/TheCaffeineDev/YoloV5-Custom-Object-Detection" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="88a7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你有任何问题、建议或批评，可以通过<a class="ae jo" href="https://twitter.com/thecaffeinedev" rel="noopener ugc nofollow" target="_blank"> Twitter </a>或通过我的<a class="ae jo" href="mailto:thedlmonk@gmail.com" rel="noopener ugc nofollow" target="_blank">邮件</a>联系我。请随时联系我。</p><h1 id="eb3f" class="ld jq hi bd jr le lf lg jv lh li lj jz lk ll lm kc ln lo lp kf lq lr ls ki lt bi translated">参考资料:</h1><ul class=""><li id="fd1f" class="kp kq hi is b it kk ix kl jb nb jf nc jj nd jn ku kv kw kx bi translated">官方回购:<a class="ae jo" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">https://github.com/ultralytics/yolov5</a></li><li id="4276" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><a class="ae jo" href="https://public.roboflow.com/object-detection/aquarium" rel="noopener ugc nofollow" target="_blank"> Roboflow数据集</a></li><li id="a28a" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><a class="ae jo" href="https://colab.research.google.com/drive/16QCaYzTuHCOF9CQLQYmGNxmtY1xKAIdn?usp=sharing" rel="noopener ugc nofollow" target="_blank">我的Colab笔记本</a></li><li id="e015" class="kp kq hi is b it ky ix kz jb la jf lb jj lc jn ku kv kw kx bi translated"><a class="ae jo" href="https://blog.roboflow.com/how-to-train-yolov5-on-a-custom-dataset/" rel="noopener ugc nofollow" target="_blank"> Roboflow博客</a></li></ul></div></div>    
</body>
</html>