<html>
<head>
<title>DIY Gradient Descending Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DIY梯度下降线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/diy-gradient-descending-linear-regression-b49b24735498?source=collection_archive---------4-----------------------#2022-02-10">https://medium.com/analytics-vidhya/diy-gradient-descending-linear-regression-b49b24735498?source=collection_archive---------4-----------------------#2022-02-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="09fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你为什么要创建一个机器学习模块，而这个模块很可能几年前就已经完成了，而且做得更好？嗯，我不知道你怎么想，但是我有我的理由，我要和那些感兴趣的人分享。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/c480aeac4744221b2bdab73151d1f448.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D5COtQSzX4sjovQJ0nTVvw.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx">Image by <a class="ae js" href="https://pixabay.com/users/cdd20-1193381/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=6507041" rel="noopener ugc nofollow" target="_blank">愚木混株 Cdd20</a> from <a class="ae js" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=6507041" rel="noopener ugc nofollow" target="_blank">Pixabay</a></figcaption></figure></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><p id="818c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，新年快乐(阳历/阴历，你的选择)！其次，我知道我还欠关于网络社会纪律的文章的第二部分，我为它的巨大延迟道歉——但有些事情值得等待(虽然不一定是这篇文章，但有些事情)。第三点:</p><p id="9d54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最近参与制作Python模块。与其说是为了效率——可能只是为了任何问题，已经开发出了质量控制更好、处理效率更高、功能更先进的模块——不如说是为了学习新事物。通过“事物”，我认为我们可以区分三个主要领域。</p><ol class=""><li id="ddd9" class="ka kb hh ig b ih ii il im ip kc it kd ix ke jb kf kg kh ki bi translated">首先是学习你想要包装的概念。如果这个概念对一个人来说是新的，显然，有很多东西需要学习。但是，即使这个概念已经为人所知，把它做成一个模块也需要更严格、更系统地接触——尤其是抽象的——主题。这就引出了第二点。</li><li id="aadb" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb kf kg kh ki bi translated">在精神上/口头上概念化是一回事，但将它概念化为一段代码完全是另一回事。在这样做的时候，人们必须考虑现实世界概念的关系和应用，然后考虑如何将这些关系和用例翻译成具有独特方法、实体和限制的编程语言——以及工具。</li><li id="d8b3" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb kf kg kh ki bi translated">最后，学习如何创建一个模块，它的内容是什么，有什么要求，有什么好处等等。测试它是如何工作的。此外，模块如何可能被其他用户利用(或滥用)——并记录下来。</li></ol><p id="fe54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，如果这一切听起来令人兴奋，我将详细说明我如何在Python中创建我自己的线性回归模块的上述步骤。</p><h1 id="9809" class="ko kp hh bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">这个概念</h1><p id="a30b" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">我创建的线性回归模块是基于梯度下降的。为此目的使用它显然是不正统的；然而，也很有教育意义。当然，这不是我的天才想出的主意，但我读了一篇关于机器学习大师的<a class="ae js" href="https://machinelearningmastery.com/linear-regression-tutorial-using-gradient-descent-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">文章，激起了我的好奇心(所以，非常非常感谢你，赞扬并感谢</a><a class="ae js" href="https://machinelearningmastery.com/about/" rel="noopener ugc nofollow" target="_blank">杰森</a>一直创造出如此优质的内容)。</p><p id="19c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">坦率地说，梯度下降的细节对我来说是新的。我知道大致的想法，但不知道它的基本机制是如何工作的——而且仍然相当轻蔑。无论哪种情况，普通用例中的概念都非常简单。你需要四样东西:一个预测，你试图预测的实际值，一个惩罚系数(学习率)和迭代。</p><p id="da08" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们所做的是计算误差，即基于一些模型参数的预测值和实际值之间的差异。然后，使用这个误差，更新模型<em class="lr">权重</em>——每个参数对结果的贡献大小——作为当前参数和误差的差乘以学习速率。</p><p id="3eeb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">或者:</p><blockquote class="ls"><p id="2f1f" class="lt lu hh bd lv lw lx ly lz ma mb jb dx translated"><em class="mc">权重(n+1) =权重(n) ⎯学习率*误差</em></p></blockquote><p id="2072" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">那就是:</p><blockquote class="ls"><p id="0453" class="lt lu hh bd lv lw lx ly lz ma mb jb dx translated"><em class="mc">权重(n+1) =权重(n) ⎯学习率*(模型(n)(X) ⎯ y) </em></p></blockquote><p id="ec5a" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">其中<em class="lr">权重(n) </em>馈入<em class="lr">模型(n) </em>，然后<em class="lr">权重(n+1) </em>馈入<em class="lr">模型(n+1)</em>——当然。在线性回归的情况下，参数是截距和可变系数。对于集合中的每个数据点，将重复更新这些权重的过程——一个完整的更新周期称为一个时期。</p><p id="9abc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，这听起来不错，但是让我们用Python来实现它。</p><h1 id="e7b1" class="ko kp hh bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">简单线性回归</h1><p id="b746" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">作为热身，让我们考虑一下简单的线性回归算法是什么样子的。即，仅使用一个独立预测器的模型:</p><blockquote class="ls"><p id="8613" class="lt lu hh bd lv lw lx ly lz ma mb jb dx translated">模型=截距+系数*变量</p></blockquote><p id="d7d5" class="pw-post-body-paragraph ie if hh ig b ih md ij ik il me in io ip mf ir is it mg iv iw ix mh iz ja jb ha bi translated">因此，我们将有两个权重，一个用于<em class="lr">截距</em>，一个用于<em class="lr">系数</em>。因为这些通常用希腊字母beta表示，所以我用<em class="lr"> w_b0 </em>表示截距，用<em class="lr"> w_b1 </em>表示系数，而<em class="lr"> alpha </em>表示学习率:</p><pre class="jd je jf jg fd mi mj mk ml aw mm bi"><span id="3df4" class="mn kp hh mj b fi mo mp l mq mr">w_b0 = [0]<br/>w_b1 = [0]<br/>errs = []<br/>alpha = 0.01</span><span id="7eca" class="mn kp hh mj b fi ms mp l mq mr">for n in range(len(data['X'])):<br/>    error = (w_b0[-1] + w_b1[-1] * data['X'][n]) - data['y'][n]<br/>    errs.append(error)<br/>    w_b0.append(w_b0[-1] - alpha * error)<br/>    w_b1.append(w_b1[-1] - alpha * error * data['X'][n])</span></pre><p id="e0a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当然，我们不需要列出以前的重量甚至误差，但有趣的是观察这些数字如何变化。如果我们让X和y是:</p><pre class="jd je jf jg fd mi mj mk ml aw mm bi"><span id="e907" class="mn kp hh mj b fi mo mp l mq mr">data = {'X': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],<br/>        'y': [1, 3, 2, 3, 5, 4, 8, 8, 7, 9]}</span></pre><p id="033a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后我们通过数据运行我们的算法四次，我们得到以下预测:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mt"><img src="../Images/51b0d02bedf6ae6075890f9424e6d92b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YKyicT9K9im7A4yp9K-LLw.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">Matplotlib主宰着这一天</figcaption></figure><p id="131e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当然，我们也可以计划我们的错误。理想情况下，它们会以某种古怪的方式接近0:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mu"><img src="../Images/9a36dd8e6fd4233ad1f49b2aeadcefa8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wglZgzA2CS2dDpTtM1RGOA.jpeg"/></div></div></figure><p id="3f50" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以看到，该图相当具有周期性，这是因为我们遍历了10个不同的数据点，并在每个周期中独立计算它们的误差。因此，该模式每10步重复一次。令人放心的是，它似乎停滞在0左右。</p><p id="3fd1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是我可以告诉你我已经让你厌烦了，所以让我们进入下一个阶段吧…顶楼！</p><h1 id="4f1c" class="ko kp hh bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">多元线性回归</h1><p id="5bb8" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">还有其他好玩的东西。那么，这里和简单的线性回归有什么不同呢？只是现在我们可以有一个以上的预测者。因此，我们的模型公式应该是这样的:</p><p id="4e18" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lr">模型= Int+Coef(1)* Var(1)+Coef(2)* Var(2)+…+Coef(n)* Var(n)</em></p><p id="1669" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里明显的问题是，我们可能不一定知道我们得到多少输入变量。在这一点上，我还认为该模块应该被广泛使用，因此应该采用numpy数组和矩阵而不是列表。通过这种推理，我没有为每个变量的权重创建一个“容器”,而是将所有值存储在一个数组中。由于初始权重为0，我使用了numpy的<code class="du mv mw mx mj b">zeros()</code>函数。我同样使用了<code class="du mv mw mx mj b">empty()</code>函数来为我的错误生成容器:</p><pre class="jd je jf jg fd mi mj mk ml aw mm bi"><span id="a0f2" class="mn kp hh mj b fi mo mp l mq mr">w_b0 = 0<br/>w_bn = np.zeros(X.shape[1])<br/>errs = np.empty(0)</span></pre><p id="983c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中X是预测值的输入。因为它是一种<code class="du mv mw mx mj b">numpy.ndarray</code>格式，我们可以使用它的<code class="du mv mw mx mj b">.shape</code>属性来获得权重数组的适当长度。我们也把这次拦截称为<code class="du mv mw mx mj b">w_b0</code>。</p><p id="e671" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在需要做的就是将前面的公式推广到任意长度的变量上——以一种numpy兼容的方式:</p><pre class="jd je jf jg fd mi mj mk ml aw mm bi"><span id="c79e" class="mn kp hh mj b fi mo mp l mq mr">for n in range(epochs): # going through n epochs<br/>    for m in range(y.shape[0]): # for m data points</span><span id="341f" class="mn kp hh mj b fi ms mp l mq mr">    ## we calculate the error based on current weights<br/>    error = (<br/>             w_b0 +<br/>             sum([(w_bn[i] * X[m, i]) for i in range(X.shape[1])])<br/>             ) - y[m]</span><span id="3e62" class="mn kp hh mj b fi ms mp l mq mr">    ## we add the current error score to the error list (errs)<br/>    errs = np.append(errs, error)</span><span id="4823" class="mn kp hh mj b fi ms mp l mq mr">    ## we update the intercept<br/>    w_b0 = (w_b0 - learning_rate * error)</span><span id="386f" class="mn kp hh mj b fi ms mp l mq mr">    ## for each predictor, we update the coefficient<br/>    for x in range(X.shape[1]):<br/>        w_bn[x] = (w_bn[x] - learning_rate * error * X[m][x])</span></pre><p id="20f9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">计算<code class="du mv mw mx mj b">error</code>的<code class="du mv mw mx mj b">sum()</code>部分只是使用列表理解的线性回归公式的<em class="lr">Coef(1)* Var(1)+…+Coef(n)* Var(n)</em>部分。在底线上，我们现在需要X的2个指数，因为它是多个不同变量的矩阵。因此，对于每个y值，我们遍历x中的所有预测变量。</p><p id="ad04" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这确实是该模块的核心。截距和系数保存为模型对象的属性，可用于预测:</p><pre class="jd je jf jg fd mi mj mk ml aw mm bi"><span id="da96" class="mn kp hh mj b fi mo mp l mq mr">np.array(<br/>         [<br/>          (<br/>           self.intercept +<br/>           sum(<br/>               [<br/>                X[m, n] * self.coefficients[n] for n in<br/>                range(X.shape[1])<br/>                ]<br/>               )<br/>           )<br/>           for m in range(X.shape[0])<br/>          ]<br/>         )</span></pre><p id="d38b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中<code class="du mv mw mx mj b">sum()</code>语句再次对应于<em class="lr">Coef(1)* Var(1)+…+Coef(n)* Var(n)</em>，最外层的列表理解是迭代所有不同的观察。</p><h2 id="52bf" class="mn kp hh bd kq my mz na ku nb nc nd ky ip ne nf lc it ng nh lg ix ni nj lk nk bi translated">一些不错的额外服务</h2><p id="e0a6" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">虽然拟合模型和预测结果已经很简单了，但我还是想加入更多可以说是有用的——也可以说是放错了地方的——附加组件。由于代码相当简单，并且可以在m <a class="ae js" href="https://github.com/aarroonn22/gdlr" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得，所以我在这里不再赘述，只列出特性:</p><ul class=""><li id="f2be" class="ka kb hh ig b ih ii il im ip kc it kd ix ke jb nl kg kh ki bi translated">基于不同聚合方法计算最佳历元</li><li id="93f2" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb nl kg kh ki bi translated">MAE、MSE、RMSE和R分数</li><li id="5694" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb nl kg kh ki bi translated">基于不同聚合指标或原始错误分数的内置错误图</li></ul><p id="8893" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我还要补充一点，也许这个项目的这一部分最有趣的方面是构建模块。我试图模仿<a class="ae js" href="https://scikit-learn.org/" rel="noopener ugc nofollow" target="_blank"> scikit-learn </a>的目录和模块结构——我将让您来判断我做得有多好。</p><h1 id="ac14" class="ko kp hh bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">让我们炸东西吧！</h1><p id="32f5" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">嗯，我们可能没有那么激进，但是我真的想演示一下这个模块是如何完成这篇文章的。因此，我将做一个简单的拟合，将分数与<a class="ae js" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html" rel="noopener ugc nofollow" target="_blank"> scikit-learn的线性回归模型</a>进行比较，并展示所有花哨的功能——ayy！</p><p id="5b10" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于这个实验，我将使用<a class="ae js" href="https://seaborn.pydata.org/generated/seaborn.load_dataset.html" rel="noopener ugc nofollow" target="_blank"> seaborn的penguin数据集</a>，并使用<code class="du mv mw mx mj b">flipper_length_mm</code>、<code class="du mv mw mx mj b">bill_length_mm</code>和<code class="du mv mw mx mj b">bill_depth_mm</code>来预测<code class="du mv mw mx mj b">body_mass_g</code>(尽管存在多重共线性的可能性，但话又说回来，我们在这里是要把事情搞大)。简单可视化的数据如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es nm"><img src="../Images/9ad59c932e327d61d1e45a82233ff7a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4CtoIQoqjP1OGNnvW03dkQ.jpeg"/></div></div></figure><p id="5f96" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我还决定用20%的测试集和142的随机状态来执行一个训练测试分割。然后我为scikit-learn的版本安装了两个型号<code class="du mv mw mx mj b">lr_sk</code>，为我的版本安装了<code class="du mv mw mx mj b">lr_gd</code>。</p><pre class="jd je jf jg fd mi mj mk ml aw mm bi"><span id="6601" class="mn kp hh mj b fi mo mp l mq mr">lr_sk.fit(X_train, y_train)<br/>lr_gd.fit(X_train, y_train, learning_rate = 0.000006, epochs = 150)</span></pre><p id="6532" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于学习率，我手动调整了一些值——有些真的爆炸了(万岁)——以找到一个或多或少的最优值。根据所有MAE、MSE和RMSE度量，最后一个产生了最好的误差。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es nn"><img src="../Images/25757891d480e37b54e836bf58441445.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bUclisAG7GV9722B01qz0w.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">使用RMSE作为聚集度量的模型的错误图</figcaption></figure><p id="e109" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后我将这两个模型进行了对比。毫不奇怪，Scikit-learn比我的DIY模块做得好得多，但重要的是意图。</p><p id="133d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在火车上，我听到了鼓声:</p><ul class=""><li id="bfbd" class="ka kb hh ig b ih ii il im ip kc it kd ix ke jb nl kg kh ki bi translated">sci kit-learn:MAE:302.1—RMSE:384.7—R:0.756</li><li id="6a2b" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb nl kg kh ki bi translated">我的版本:梅伊:359.1 — RMSE: 448.6 — R : 0.668</li></ul><p id="ce90" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在测试装置上:</p><ul class=""><li id="c969" class="ka kb hh ig b ih ii il im ip kc it kd ix ke jb nl kg kh ki bi translated">sci kit-learn:MAE:346.1—RMSE:416.1—R:0.784(？！)</li><li id="8e08" class="ka kb hh ig b ih kj il kk ip kl it km ix kn jb nl kg kh ki bi translated">我的版本:梅伊:454.1 — RMSE: 523.9 — R : 0.658</li></ul><p id="371a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但至少我使用了自己内置的方法来得到我的分数。为了结束这篇文章，这里有一个漂亮的图表，显示了两个模型(蓝色DIY版本，橙色-sci kit-learn版本)对训练和测试数据的预测。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es no"><img src="../Images/dad4cc74c3ad82f1f5dbded9ac7adc0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Dr-JZ4-bBz3V-6fPRoCPag.jpeg"/></div></div></figure><p id="c25b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这就是你自己的整洁紧凑的机器学习模块。总而言之，这很有趣，10分之10会推荐。</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><p id="2f09" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lr">一如既往，非常感谢你坚持到最后——如果你还在的话。我真的很感激你，希望我能招待你一会儿。</em></p></div></div>    
</body>
</html>