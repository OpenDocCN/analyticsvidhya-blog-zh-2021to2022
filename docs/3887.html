<html>
<head>
<title>Applying Computer Vision Techniques on a Kaggle dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Kaggle数据集上应用计算机视觉技术</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/applying-computer-vision-techniques-on-a-kaggle-dataset-ba6d3fb8cc52?source=collection_archive---------3-----------------------#2021-08-05">https://medium.com/analytics-vidhya/applying-computer-vision-techniques-on-a-kaggle-dataset-ba6d3fb8cc52?source=collection_archive---------3-----------------------#2021-08-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/340b2f5a43e7baad5f2292f6cabc70ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uUv3yOK8z9TbG8Dz_gHwXw.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">*图片由Unsplash/ Sean Lim提供</figcaption></figure><p id="c821" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们现在有丰富的数据资源来满足我们对学习的渴望。这些数据以不同的形式、包装和交付方式出现。我们在之前的博客中使用了多种方法:</p><ul class=""><li id="960d" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq jw jx jy jz bi translated">一个中等大小的玩具数据集来自Fast.ai库<a class="ae ka" href="https://becominghuman.ai/testing-the-waters-of-deep-learning-8d687b21bb92" rel="noopener ugc nofollow" target="_blank">这里</a>，</li><li id="8409" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated">Fast.ai库中的大型玩具数据集<a class="ae ka" rel="noopener" href="/@yrodriguezmd/developing-a-taste-for-deep-learning-241cabb43277">这里</a>，</li><li id="c854" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated">在此导出外部数据集<a class="ae ka" href="https://becominghuman.ai/starting-the-dive-into-deep-learning-c57c987cc390" rel="noopener ugc nofollow" target="_blank">，</a></li><li id="4948" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated">通过网络抓取创建我们自己的数据集<a class="ae ka" href="https://becominghuman.ai/feeding-frenzy-in-deep-learning-3e4408bf3170" rel="noopener ugc nofollow" target="_blank">这里</a>。</li></ul><p id="1eca" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">从Kaggle获取数据并不像我最初认为的那样是一种轻松的下载-上传方法。我能够找到正确的公式，并决定将数据集应用于深度学习。</p><p id="f9de" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">对于这个小型项目，我们将展示:</p><p id="dd88" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">A.如何在Colab中使用Kaggle数据集，以及</p><p id="2ba9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">B.如何使用Fast.ai FastBook 第七课<a class="ae ka" href="https://colab.research.google.com/github/fastai/fastbook/blob/master/07_sizing_and_tta.ipynb" rel="noopener ugc nofollow" target="_blank">中描述的标准化、调整大小和测试时间增强计算机视觉技术。</a></p><p id="753b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">所以，打开Kaggle，和我一起探索吧！</p><p id="f3bb" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="kg"> A .在Colab </em> </strong>中使用Kaggle数据集</p><ol class=""><li id="db4a" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq kh jx jy jz bi translated"><strong class="iv hi">在Kaggle中选择一个数据集。</strong></li></ol><p id="38ce" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">a.如果您还没有帐户，请创建一个。这是免费的，处理速度很快。</p><p id="f05f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">b.探索您感兴趣的数据集/竞赛。本博客涉及<a class="ae ka" href="https://www.kaggle.com/gpiosenka/100-bird-species" rel="noopener ugc nofollow" target="_blank">计算机视觉/鸟类图像分类</a>。</p><p id="735d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">c.为每个类选择一个至少包含20幅影像的数据集。否则，您可能会遇到错误。</p><p id="2460" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">d.我已经能够使用。jpg和。图像的png格式。如果遇到格式。tfrec，查找原始数据集的链接。</p><p id="4fa5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">e.请在设置前完成此操作。如果您在设置时分心，您的笔记本电脑运行可能会中断，您将需要重新运行。</p><p id="365d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg">注意</em>:你可以在Colab中看到Kaggle数据集的列表，但是，最初的内容检查最好在Kaggle网站上完成。</p><p id="bdb8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 2。设置。</strong></p><p id="8e93" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">a.<em class="kg">笔记本</em></p><p id="fdc9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">你可以在Kaggle里运行一个笔记本。但是，对于这次运行，我们将在Colab中进行。如果你是Colab的新手，请<a class="ae ka" href="https://becominghuman.ai/feeding-frenzy-in-deep-learning-3e4408bf3170" rel="noopener ugc nofollow" target="_blank">在这里看步骤1a-b</a>。</p><p id="afff" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">如果选择了大数据集，我建议使用GPU和高RAM运行时间。</p><p id="b3bd" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg"> b .安装和进口</em></p><p id="5815" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">一. Fast.ai库的一般设置。</p><p id="c124" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在Colab笔记本中，运行以下命令:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="a525" class="kr ks hh kn b fi kt ku l kv kw">!pip install -Uqq fastbook<br/>import fastbook<br/>fastbook.setup_book()<br/>from fastbook import *<br/>#!pip install fastai -U  # unhash if this is your first use<br/>import fastai<br/>from fastai.vision.all import *</span></pre><p id="0afc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">二。使用Kaggle数据集的特定设置。</p><ul class=""><li id="9dfb" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq jw jx jy jz bi translated">在Kaggle页面中，打开您的“帐户”。</li></ul><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es kx"><img src="../Images/972d25b44586f502cf50b7088b682705.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*QC-63iBdcgDOAKbTWEwDQA.png"/></div></figure><ul class=""><li id="0ab8" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq jw jx jy jz bi translated">创建新的API令牌。</li></ul><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es ky"><img src="../Images/430b6964d0f0cb4524694f4fa647e4a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*yujQe1ld4z4DJnE2J6y0mA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">*这会给你一个. json文件。</figcaption></figure><ul class=""><li id="cca9" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq jw jx jy jz bi translated">在您的Colab笔记本中，安装kaggle并上传API Token/ kaggle json文件。</li></ul><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="79c1" class="kr ks hh kn b fi kt ku l kv kw">!pip install -q kaggle<br/>from google.colab import files<br/>files.upload()</span></pre><ul class=""><li id="80de" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq jw jx jy jz bi translated">创建kaggle目录并启用访问。</li></ul><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="b94a" class="kr ks hh kn b fi kt ku l kv kw">!mkdir ~/.kaggle<br/>!cp kaggle.json ~/.kaggle/</span><span id="b7dd" class="kr ks hh kn b fi kz ku l kv kw">!chmod 600 ~/.kaggle/kaggle.json</span></pre><p id="462b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 3。收集您的数据。</strong></p><p id="ec79" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg"> a .下载的代码格式。</em></p><ul class=""><li id="84b3" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq jw jx jy jz bi translated">！卡格尔</li><li id="850a" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated"><em class="kg">数据集</em>或<em class="kg">竞赛</em>(即在Kaggle中，你的集合是来自数据集还是竞赛板块？)</li><li id="cb44" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated">下载</li><li id="eb5b" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated">小路</li></ul><p id="10d4" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">对于路径，请使用kaggle.com后面的url部分。例如:</p><p id="dafa" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这里使用的Kaggle数据集可以在<em class="kg">数据集</em>集合中找到，url是:<a class="ae ka" href="https://www.kaggle.com/gpiosenka/100-bird-species" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/gpiosenka/100-bird-species</a>。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="6181" class="kr ks hh kn b fi kt ku l kv kw">!kaggle datasets download 'gpiosenka/100-bird-species/train'</span></pre><p id="2d12" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我指定了train，但是它还是下载了train和验证集。</p><p id="f4f1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg"> b .从下载的zip文件中获取单个文件，并在完成后删除zip文件。</em></p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="8f8d" class="kr ks hh kn b fi kt ku l kv kw">!unzip \*zip &amp;&amp; rm *.zip</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es la"><img src="../Images/4c4b4a7d70d743bf72ce5b1a9feb150f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*GVMA9EdTrW0HjUc-KAHW7g.png"/></div></figure><p id="34b4" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg"> c .指定路径。</em></p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="65e2" class="kr ks hh kn b fi kt ku l kv kw">train_path = 'birds_rev2/train'</span></pre><p id="b318" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">就是这样！不需要创建数据帧或进行任何其他预处理。</p><p id="9a4b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="kg"> B .先进成像技术的例子。</em> </strong></p><p id="dfe8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">如果您想了解成像转换的介绍或复习，请<a class="ae ka" rel="noopener" href="/@yrodriguezmd/developing-a-taste-for-deep-learning-241cabb43277">参考该资源</a>。您可以使用您在这里下载的相同数据集，只需稍作修改:从步骤3开始，使用(train_path)而不是(path/'images ')。</p><p id="3668" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们将看看标准化、调整大小和测试大小增加如何影响从非预训练模型发展而来的学习者的准确性。有关更详细的描述，请参考此处的<a class="ae ka" href="https://colab.research.google.com/github/fastai/fastbook/blob/master/07_sizing_and_tta.ipynb" rel="noopener ugc nofollow" target="_blank">和</a>。</p><ol class=""><li id="b827" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq kh jx jy jz bi translated"><strong class="iv hi">基线模型</strong></li></ol><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="193a" class="kr ks hh kn b fi kt ku l kv kw">dblock = DataBlock(<br/>    (ImageBlock(), CategoryBlock()),<br/>    get_items = get_image_files,<br/>    get_y = parent_label,<br/>    splitter = RandomSplitter(seed=42),<br/>    item_tfms = Resize(460),<br/>    batch_tfms = aug_transforms(size=224))<br/>dls = dblock.dataloaders(train_path)<br/>dls.train.show_batch()</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lb"><img src="../Images/1cd73b3871895d68b29a5f2feaf96f42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*aNMwqN6tmxH4EvdE3hQksw.png"/></div></figure><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="163a" class="kr ks hh kn b fi kt ku l kv kw">dls.train.show_batch(unique=True)</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lc"><img src="../Images/617c3bba633fddff2b498eacca67ed67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*8wn0yokd18zakTeWA28Isw.png"/></div></figure><p id="ce9d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们可以欣赏一些基线转换，如裁剪，L-R方向和光线强度。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="4fa6" class="kr ks hh kn b fi kt ku l kv kw">model = xresnet50(n_out = dls.c)<br/>learn_base = Learner(dls, model, loss_func = CrossEntropyLossFlat(),<br/>                     metrics = accuracy)<br/>learn_base.fit_one_cycle(5, 3e-3)</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es ld"><img src="../Images/a335cf6df30f3ddfb2de87188ca7b90d.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*9gPaludiUxSr1YQ7ibO4qg.png"/></div></figure><ul class=""><li id="6d91" class="jr js hh iv b iw ix ja jb je jt ji ju jm jv jq jw jx jy jz bi translated"><a class="ae ka" href="https://docs.fast.ai/learner.html#Learner" rel="noopener ugc nofollow" target="_blank"> Learner </a>是Fast.ai中组装数据、模型和训练的代码类。</li><li id="c2a3" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated"><a class="ae ka" href="https://docs.fast.ai/vision.models.xresnet.html" rel="noopener ugc nofollow" target="_blank"> Xresnet </a>是一个顺序的、非预训练的神经网络。</li><li id="f03b" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated"><a class="ae ka" href="https://github.com/fastai/fastai/blob/master/fastai/vision/models/xresnet.py#L22" rel="noopener ugc nofollow" target="_blank"> n_out </a> = dls.c表示类别或标签的数量。</li><li id="e00f" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated"><a class="ae ka" href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#CrossEntropyLoss" rel="noopener ugc nofollow" target="_blank">交叉熵损失</a>是模型能够学习的计算。它来源于类别的预测概率。概率值的范围从0到1。当这些值被转换为<a class="ae ka" href="https://machinelearningmastery.com/cross-entropy-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">交叉熵</a>时，接近0的概率(非常差的预测)变得更加明显，因此受到更多惩罚。</li><li id="f1fa" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated"><a class="ae ka" href="https://docs.fast.ai/losses.html" rel="noopener ugc nofollow" target="_blank">交叉熵损失平</a>是对交叉熵损失的重组，以方便处理。</li><li id="08d0" class="jr js hh iv b iw kb ja kc je kd ji ke jm kf jq jw jx jy jz bi translated">虽然计算机需要损失提供的梯度信息，但人类的解释更适合于精度度量。</li></ul><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="eebc" class="kr ks hh kn b fi kt ku l kv kw">learn_base.lr_find()</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es le"><img src="../Images/02cda7eaff9f6b1754ff42e142e4ec45.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*Buwja2b17Rg_L8BES1DDEw.png"/></div></figure><p id="1a88" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们的基线学习率是0.003，根据lr_find保持这个比率是合理的。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="cb20" class="kr ks hh kn b fi kt ku l kv kw">learn_base.show_results()</span></pre><p id="0b5d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">可视化一些基线结果:</p><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lf"><img src="../Images/a68514a32cc529e5da7b17bcc51febb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*GwCoL74zKaTow-vzK6W1vw.png"/></div></figure><p id="8abe" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">顶部标签是实际值，底部标签是预测值。如果您想了解如何区分标签(实际与预测)，请参考<a class="ae ka" href="https://becominghuman.ai/feeding-frenzy-in-deep-learning-3e4408bf3170" rel="noopener ugc nofollow" target="_blank">步骤6.a此处</a>。</p><p id="a575" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">快速的网络搜索可以给我们一些比较的图像来理解学习者不正确的预测。</p><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lg"><img src="../Images/b312bc1cba0e34d92ba3f3d7fe59c46b.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*o6EQPV4SSiBOSHQAJZiapQ.png"/></div></figure><p id="495d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg">解释</em>:使用交叉熵损失和0.003的学习率，从零开始训练的基线模型在5个时期的学习后给出了82%的准确度。</p><p id="e201" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 2。应用规范化转换。</strong></p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="89f1" class="kr ks hh kn b fi kt ku l kv kw">dblock = DataBlock(<br/>      (ImageBlock, CategoryBlock),<br/>      get_items = get_image_files,<br/>      get_y = parent_label,<br/>      item_tfms = Resize(460),<br/>      batch_tfms = [*aug_transforms(size=224),<br/>                    Normalize.from_stats(*imagenet_stats)]) #<br/>dls_norm = dblock.dataloaders(train_path, bs=64)</span></pre><p id="c9a0" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">让我们浏览一下样本数据，看看数字层面的变化:</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="b26e" class="kr ks hh kn b fi kt ku l kv kw">x, y = dls.one_batch()          # baseline<br/>xn, yn = dls_norm.one_batch()   # normalized</span></pre><p id="25fa" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">基线和标准化的x和y具有相同的形状:64个批次项目，3个RGB通道，以及我们指定的224 x 224像素大小。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="f40d" class="kr ks hh kn b fi kt ku l kv kw">print('Non-normalized tensors:', x[0][0][0][:10])<br/>print('Mean:',x.mean(dim = [0,2,3]))<br/>print('Std:', x.std(dim = [0,2,3]))</span><span id="7c03" class="kr ks hh kn b fi kz ku l kv kw">print('Normalized tensors:', xn[0][0][0][:10])<br/>print('Mean:',xn.mean(dim = [0,2,3]))<br/>print('Std:', xn.std(dim = [0,2,3]))</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lh"><img src="../Images/17dab320dbfe11e1d901a841f0c1bec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/format:webp/1*GJNs0bq2CkBCsyugKEarXA.png"/></div></figure><p id="e330" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">规范化允许将不同的值集合放在相同的范围内，以便进行比较。组平均值为0，标准偏差为1。</p><p id="ac6c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">随着数字的变化，让我们来想象一下效果:</p><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es li"><img src="../Images/702040133c4ecb6d57e3bafb441cfc29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*p-MQL98MbshFt3-bvkPIMw.png"/></div></figure><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="43b8" class="kr ks hh kn b fi kt ku l kv kw">model = xresnet50(n_out = dls_norm.c)<br/>learn_norm = Learner(dls_norm, model, loss_func =    CrossEntropyLossFlat(), metrics = accuracy)<br/>learn_norm.fit_one_cycle(5, 3e-3)</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lj"><img src="../Images/6f77fa47ce063527467a6bd71bd99986.png" data-original-src="https://miro.medium.com/v2/resize:fit:792/format:webp/1*o7USzlUaBRB9enrLnCBVug.png"/></div></figure><p id="caae" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">标准化仅产生了最小的改进，可能是因为图像已经相对相似。</p><p id="5b1b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">可视化一些结果:</p><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/d5b2fb2d0ff8a7049ed31f6b5efa7f8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*Zgo6xx4X1bqDispd1dh8hA.png"/></div></figure><p id="89bc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">将被错误分类的鸟类与网上的一些资源进行比较，可以发现造成混淆的一些可能原因，尤其是主色和整体形状。</p><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es ll"><img src="../Images/9ba54f55af7041c63a802a0ba3e9dfe1.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*ZWFMt8GEqpDZ2TN5shO50Q.png"/></div></figure><p id="307d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg">解释</em>:使用交叉熵损失和0.003的学习率，从零开始训练的标准化模型在5个时期的学习后给出83%的准确度。</p><p id="aaef" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 3。应用渐进尺寸</strong></p><p id="3536" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">从一个小尺寸的图像开始训练。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="ada2" class="kr ks hh kn b fi kt ku l kv kw">dblock = DataBlock(<br/>      (ImageBlock, CategoryBlock),<br/>      get_items = get_image_files,<br/>      get_y = parent_label,<br/>      item_tfms = Resize(460),<br/>      batch_tfms = aug_transforms(size=128)) # start small<br/>dls_128 = dblock.dataloaders(train_path, bs=64)</span><span id="5905" class="kr ks hh kn b fi kz ku l kv kw">model = xresnet50(n_out = dls_128.c)<br/>learn_128 = Learner(dls_128, model,<br/>                    loss_func = CrossEntropyLossFlat(),<br/>                    metrics = accuracy)<br/>learn_128.fit_one_cycle(2, 3e-3)</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lm"><img src="../Images/93cd2edc434ae1ddd291d3bdc794d9b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*r7R42m90CQNaQeLbixsR7A.png"/></div></figure><p id="9ea5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">进展到更大尺寸的图像。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="82b8" class="kr ks hh kn b fi kt ku l kv kw">dblock = DataBlock(<br/>      (ImageBlock, CategoryBlock),<br/>      get_items = get_image_files,<br/>      get_y = parent_label,<br/>      item_tfms = Resize(460),<br/>      batch_tfms = aug_transforms(size=224)) # bigger<br/>dls_224 = dblock.dataloaders(train_path, bs=64)</span></pre><p id="84d0" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">并将新的dls应用于先前训练过的学习者。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="3f4c" class="kr ks hh kn b fi kt ku l kv kw">learn_128.dls = dls_224<br/>learn_128.fit_one_cycle(3, 3e-3)</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es ln"><img src="../Images/7594b95521b0b8dcf17008b4bac5ca78.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*pip1iDmBAFTm_i9z_s-fag.png"/></div></figure><p id="1e93" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们可以看到，小规模的初始训练和逐步扩大的训练导致了比基线稍好的准确度(84.1%比82.3%)。小尺寸图像的运行速度快了一倍(2分钟对4分钟)。</p><p id="6ef5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg">解释</em>:在使用交叉熵损失和0.003的学习率的5个时期的学习之后，从零开始训练的尺寸调整模型给出了84%的准确度。它还能稍微加快训练速度。</p><p id="ccb9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 4。使用测试时间增加(TTA)。</strong></p><p id="1a4b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">验证集图像通常经过中心裁剪。不用说，这种默认技术会丢失一些信息。TTA通过从原始图像的多个区域进行裁剪来解决这个问题。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="21ea" class="kr ks hh kn b fi kt ku l kv kw"># using the baseline dblock and dls<br/>model = xresnet50(n_out = dls.c)<br/>learn = Learner(dls, model,<br/>                loss_func = CrossEntropyLossFlat(),<br/>                metrics = accuracy)</span><span id="59d4" class="kr ks hh kn b fi kz ku l kv kw">learn.fit_one_cycle(5, 3e-3)</span><span id="17c8" class="kr ks hh kn b fi kz ku l kv kw">preds, targs = learn.tta()<br/>accuracy(preds, targs).item()</span></pre><p id="db04" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">从基线0.8251开始，结果精度为0.8277。</p><p id="70f8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg">解释</em>:TTA步骤提供了基线模型0.2-0.3%的精度改进。</p><p id="408e" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 5。结合这些先进的转换技术。</strong></p><p id="ebbe" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">对于我们的最终建模，我们将利用渐进的规模，从128到224。我们将使用fine_tune，默认情况下它执行规范化。我们将把TTA应用到学习者身上。</p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="35b7" class="kr ks hh kn b fi kt ku l kv kw">dblock = DataBlock(<br/> (ImageBlock, CategoryBlock),<br/> get_items = get_image_files,<br/> get_y = parent_label,<br/> item_tfms = Resize(460),<br/> batch_tfms = aug_transforms(size=128))  #<br/> <br/>dls_128 = dblock.dataloaders(train_path, bs=64)</span><span id="2424" class="kr ks hh kn b fi kz ku l kv kw">model = xresnet50(n_out = dls_128.c)<br/>learn_ = Learner(dls_128, model,<br/>                    loss_func = CrossEntropyLossFlat(),<br/>                    metrics = accuracy)<br/>learn_.fit_one_cycle(2, 3e-3)</span><span id="34ff" class="kr ks hh kn b fi kz ku l kv kw">dblock = DataBlock(<br/>      (ImageBlock, CategoryBlock),<br/>      get_items = get_image_files,<br/>      get_y = parent_label,<br/>      item_tfms = Resize(460),<br/>      batch_tfms = aug_transforms(size=224))   #<br/>dls_224 = dblock.dataloaders(train_path, bs=64)</span><span id="6308" class="kr ks hh kn b fi kz ku l kv kw">learn_.dls = dls_224<br/>learn_.fine_tune(3, 3e-3)  #</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lm"><img src="../Images/4ead461ab735929a206cba23b62d9493.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*W-4UAgo6pRnpbAL0XdbvOQ.png"/></div></figure><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="79f4" class="kr ks hh kn b fi kt ku l kv kw">interp = ClassificationInterpretation.from_learner(learn_)<br/>interp.most_confused(min_val = 5)</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/cdf78333c1cba4a62eea2788e02b85d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*HUewFkNaEkopFcj90iiMEQ.png"/></div></figure><p id="938c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了进行比较，我们可以说大多数人也会发现这些图像很难区分。</p><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/7ff56bbc07587d248a14c586dc53aa43.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*ri3xR32h40cxVKPw2suibw.png"/></div></figure><p id="7825" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg">解释</em>:使用交叉熵损失和0.003的学习率，在5个时期的学习之后，从零开始训练并使用渐进调整大小、归一化和TTA的最终模型给出了85%的准确度。对于一般的鸟类分类方案，错误分类被认为是合理的。需要区分物种的学术论文可能会受益于更多的历元运行和使用<a class="ae ka" rel="noopener" href="/@yrodriguezmd/developing-a-taste-for-deep-learning-241cabb43277">区分学习率</a>。</p><p id="a75c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 6。让我们来玩吧！</strong></p><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="36b0" class="kr ks hh kn b fi kt ku l kv kw">btn_upload = widgets.FileUpload()<br/>btn_upload</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/c1a2b87fbf47b783d9a1edffe68d747b.png" data-original-src="https://miro.medium.com/v2/resize:fit:314/format:webp/1*FKCakGlXanJdkocQZVzyfQ.png"/></div></figure><pre class="ki kj kk kl fd km kn ko kp aw kq bi"><span id="657f" class="kr ks hh kn b fi kt ku l kv kw">img = PILImage.create(btn_upload.data[-1])<br/>out_pl = widgets.Output()<br/>out_pl.clear_output()<br/>with out_pl: display(img.to_thumb(250))<br/>pred, pred_idx, probs = learn_.predict(img) # rev<br/>lbl_pred = widgets.Label()<br/>lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'<br/>btn_run = widgets.Button(description = 'Classify')<br/>btn_run</span><span id="9e43" class="kr ks hh kn b fi kz ku l kv kw">def on_click_classify(change):<br/>  img= PILImage.create(btn_upload.data[-1])<br/>  out_pl.clear_output()<br/>  with out_pl: display(img.to_thumb(200))<br/>  pred, pred_idx, probs = learn_.predict(img) #rev<br/>  lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:0.4f}'</span><span id="b2d2" class="kr ks hh kn b fi kz ku l kv kw">btn_run.on_click(on_click_classify)<br/>btn_upload = widgets.FileUpload()</span><span id="1be1" class="kr ks hh kn b fi kz ku l kv kw">from ipywidgets import *<br/>VBox([widgets.Label('Select the bird you want to identify!'),<br/>      btn_upload, btn_run, out_pl, lbl_pred])</span></pre><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/e34ef1faff9904a85f993dee7e357e60.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*LkakI7m4EPJDKGBRKaYvyw.png"/></div></figure><p id="f8dc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">让我们看看如果甘道夫是一只鸟，他会是什么样子——</p><figure class="ki kj kk kl fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/277afe17de5addc2770b2c6f3b1f1cde.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*P-aLvoH5d2MjtcJPY3tLSA.png"/></div></figure><p id="62d0" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">足够接近:0)</p><p id="6e11" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="kg">总结:</em> </strong></p><p id="60e6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们能够利用Colab笔记本中的Kaggle数据集。我们使用非预训练模型应用了高级计算机视觉转换，并在验证集上实现了85%的准确率。</p><p id="0b7e" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我希望你和我一样开心！</p><p id="7b67" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="kg">玛丽亚</em></p><p id="ab90" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在LinkedIn上与我联系:<a class="ae ka" href="https://www.linkedin.com/in/rodriguez-maria/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/rodriguez-maria/</a></p><p id="1b87" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">或者在推特上关注我:<a class="ae ka" href="https://twitter.com/Maria_Rod_Data" rel="noopener ugc nofollow" target="_blank">https://twitter.com/Maria_Rod_Data</a></p></div></div>    
</body>
</html>