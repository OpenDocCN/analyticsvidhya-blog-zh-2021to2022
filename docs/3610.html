<html>
<head>
<title>Datasets for Machine Learning in Autonomous Vehicles</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自动驾驶汽车中机器学习的数据集</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/datasets-for-machine-learning-in-autonomous-vehicles-dd13bae5925b?source=collection_archive---------0-----------------------#2021-07-13">https://medium.com/analytics-vidhya/datasets-for-machine-learning-in-autonomous-vehicles-dd13bae5925b?source=collection_archive---------0-----------------------#2021-07-13</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="ea0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">具有多种传感器形式(激光雷达、雷达、立体摄像机、热感摄像机等)的数据集。)</p><figure class="je jf jg jh fd ji er es paragraph-image"><a href="https://www.freepik.com/vectors/car"><div class="er es jd"><img src="../Images/19099593e29964f1f4021c913e3aa16c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PUmWi-cAmoC0m8RAhpa5Fg.jpeg"/></div></a><figcaption class="jl jm et er es jn jo bd b be z dx translated">由upklyak创建的汽车矢量—<a class="ae jp" href="http://www.freepik.com" rel="noopener ugc nofollow" target="_blank">www.freepik.com</a></figcaption></figure><p id="9803" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自主车辆中使用了各种各样的传感器。传感模式的多样性有助于不同的天气条件。以下是最新发布的自动驾驶数据集的流行列表。</p><p id="e38a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jq">注:</em> </strong> <em class="jq">由于每隔几个月就会有新的数据集发布，如果有流行的数据集发布，我会每个月更新这个页面。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="29d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong>:ONCE Dataset(<strong class="ih hj">O</strong>ne milli<strong class="ih hj">N</strong>s<strong class="ih hj">C</strong>en<strong class="ih hj">E</strong>s)-华为公司</p><p id="51d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2021年</p><p id="629a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像头、激光雷达</p><p id="b171" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:中国</p><p id="7545" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:一次(一百万场景)数据集可用于自动驾驶场景下的3D物体检测。ONCE数据集由100万个激光雷达场景和700万个相应的相机图像组成。这些数据选自144个驾驶小时，比现有最大的3D自动驾驶数据集(如nuScenes和Waymo)长20倍，并且是在一系列不同地区、时段和天气条件下收集的。它有5类15k完全注释的场景(汽车，公共汽车，卡车，行人，自行车)。在ONCE数据集中，对于每个标记和未标记的场景，有3个天气条件，即晴天、多云、雨天和4个时间段，即上午、中午、下午、晚上。对于每个场景，信息(即天气、时间段、时间戳、姿势、校准、注释)都在单个JSON文件中。</p><p id="c347" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://once-for-auto-driving.github.io/" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/2106.11037.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="58e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong>:多功能一体机(AIODrive)</p><p id="d49c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2020年</p><p id="27ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:相机、激光雷达、雷达</p><p id="6c2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">记录区</strong> : NA</p><p id="376c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:高密度远程点云的大规模综合感知数据集。这是一个大规模的<strong class="ih hj">合成数据集</strong>，提供了全面的传感器、注释和环境变化。它有</p><ol class=""><li id="d75d" class="js jt hi ih b ii ij im in iq ju iu jv iy jw jc jx jy jz ka bi translated">八种传感器模式(RGB、立体、深度、激光雷达、SPAD-激光雷达、雷达、IMU、GPS)</li><li id="594a" class="js jt hi ih b ii kb im kc iq kd iu ke iy kf jc jx jy jz ka bi translated">所有主流感知任务的注释(例如，检测、跟踪、轨迹预测、分割、深度估计)</li><li id="e368" class="js jt hi ih b ii kb im kc iq kd iu ke iy kf jc jx jy jz ka bi translated">罕见的驾驶场景，如不利的天气和照明、拥挤的场景、高速驾驶、违反交通规则和事故</li></ol><p id="0886" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它拥有用于激光雷达和SPAD-LiDAR传感器的高密度远程点云，比威力登-64密度大十倍，传感范围大。</p><p id="ed5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="http://www.aiodrive.org/download.html" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://www.xinshuoweng.com/papers/AIODrive/arXiv.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="790d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong>:福特多AV季节性数据集</p><p id="a829" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2020年</p><p id="3f13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机、激光雷达</p><p id="5e27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制区域</strong>:美国(密歇根州)</p><p id="b2f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:多代理季节性数据集由福特自动驾驶汽车车队在2017-18年期间的不同日期和时间收集。这些车辆在密歇根州的一条路线上人工驾驶，包括各种驾驶场景，包括底特律机场、高速公路、市中心、大学校园和郊区。该数据集具有在动态城市环境中经历的天气、照明、建筑和交通状况的季节性变化。</p><p id="5c62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://avdata.ford.com/downloads/default.aspx" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/2003.07969.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="1b9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong>:自动驾驶的密集深度(DDAD)——丰田研究所</p><p id="6015" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2020年</p><p id="15e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机、激光雷达</p><p id="7477" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:美国(旧金山、湾区、剑桥、底特律、安阿伯)和日本(东京、台场)</p><p id="af64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong> : DDAD是TRI(丰田研究所)推出的一款全新自动驾驶基准，用于在充满挑战和多样化的城市条件下进行长距离(最远250米)和密集深度估计。它包含单目视频和精确的地面真实深度(跨越360度的完整视野)，这些数据是由安装在跨洲行驶的自动驾驶汽车上的高密度激光雷达生成的。</p><p id="cc08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://github.com/TRI-ML/DDAD/blob/master/README.md" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/1905.02693.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="d1e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : PandaSet</p><p id="3cb6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2020年</p><p id="d6ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:相机、激光雷达</p><p id="60dc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:美国(旧金山，El Camino Real从帕洛阿尔托到圣马特奥)</p><p id="c12f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong> : PandaSet结合了何塞同类最佳的激光雷达传感器和Scale AI的高质量数据标注。PandaSet的特点是使用具有类似图像分辨率的前向激光雷达(PandarGT)和机械旋转激光雷达(Pandar64)收集数据。所收集的数据用长方体和分割标注(比例3D传感器融合分割)的组合来标注。</p><p id="4a38" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://scale.com/open-datasets/pandaset" rel="noopener ugc nofollow" target="_blank">数据集</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="7bf0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong>:加拿大恶劣驾驶条件(CADC)</p><p id="b361" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2020年</p><p id="9e90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机、激光雷达</p><p id="3977" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:加拿大(滑铁卢)</p><p id="852f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:加拿大不利驾驶条件(CADC)数据集由autonomouse自动驾驶汽车平台收集，基于改装的林肯MKZ。该数据集于冬季在加拿大滑铁卢地区收集，是首个专门关注不利驾驶条件的自动驾驶汽车数据集。它包含7，000帧通过8台相机(Ximea MQ013CG-E2)、激光雷达(VLP-32C)和GNSS+INS系统(Novatel OEM638)在各种冬季天气条件下收集的注释数据。传感器是时间同步的，并用数据集中包含的内部和外部校准进行校准。Scale AI已经提供了表示3D对象检测和跟踪的地面真相的激光雷达帧注释。</p><p id="9f72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="http://cadcd.uwaterloo.ca/" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/2001.10117" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="6b2a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : A2D2:奥迪自动驾驶数据集</p><p id="f704" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2020年</p><p id="38cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像头、激光雷达、总线数据</p><p id="cba2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制区域</strong>:德国(盖默尔斯海姆、慕尼黑和因戈尔施塔特)</p><p id="bbd2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:数据集由同时记录的图像和3D点云，以及3D包围盒、语义分割、实例分割和从汽车总线提取的数据组成。传感器套件由六个摄像头和五个激光雷达单元组成，提供360度全方位覆盖。记录的数据是时间同步的并且相互记录。该数据集具有2D语义分割、3D点云、3D边界框和车辆总线数据。所有传感器信号都以UTC格式打上时间戳。</p><p id="aaf4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://www.a2d2.audi/a2d2/en.html" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/2004.06320" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="fd98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong>:一个*3D数据集</p><p id="5034" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2019年</p><p id="4f97" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机、激光雷达</p><p id="0478" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:新加坡</p><p id="233a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:a* 3D数据集由RGB图像和激光雷达数据组成，具有场景、时间和天气的显著多样性。该数据集由高密度图像(比开创性的KITTI数据集多10倍)、严重遮挡、大量夜间帧(是场景数据集的3倍)组成，解决了现有数据集的差距，将自动驾驶研究的任务边界推向了更具挑战性的高度多样化的环境。数据收集覆盖整个新加坡，包括高速公路、邻近道路、隧道、市区、郊区、工业区、HDB停车场、海岸线等。</p><p id="2bc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://github.com/I2RDL2/ASTAR-3D" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/1909.07541.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="7506" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">姓名</strong>:欧洲城市人(ECP)</p><p id="05e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2019年</p><p id="944e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机、激光雷达</p><p id="f7d8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:欧洲(12个国家的31个城市)</p><p id="299c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:euro city Persons数据集提供了大量关于城市交通场景中行人、骑自行车者和其他骑车者的高度多样化、精确和详细的注释。该数据集的图像是在12个欧洲国家的31个城市的移动车辆上收集的。EuroCity Persons在超过47300张图片中人工标记了超过238200个人实例，比之前用于基准测试的个人数据集大了近一个数量级。该数据集还包含大量的个人取向注释(超过211200个)。</p><p id="6e88" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://eurocity-dataset.tudelft.nl/eval/overview/home" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://ieeexplore.ieee.org/document/8634919" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="7b61" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong>:牛津机器人汽车数据集</p><p id="cbcb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2019和2016</p><p id="0bb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong> : <strong class="ih hj"> 2019 </strong> - <strong class="ih hj"> </strong>相机、雷达、激光雷达。<strong class="ih hj"> 2016 </strong> -相机、激光雷达</p><p id="b71e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制区域</strong>:英国(牛津)</p><p id="58a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong> : <strong class="ih hj"> 2019 </strong> -牛津雷达机器人汽车数据集可用于使用毫米波FMCW扫描雷达数据研究场景理解。目标应用是自动驾驶汽车，这种模式对雾、雨、雪或镜头眩光等环境条件具有鲁棒性，这些环境条件通常会挑战视觉和激光雷达等其他传感器模式。这些数据是在2019年1月收集的，经过了32次牛津市中心路线的穿越，在城市驾驶中总共行驶了280公里。它包括各种天气、交通和照明条件。</p><p id="d847" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">2016</strong>——最初发布的数据集包括超过20 TB的车载单目和立体图像、2d和3D激光雷达，以及在英国牛津驾驶一年收集的惯性和GPS数据。在此期间，对一条10公里长的路线进行了100多次穿越，以捕捉一定时间范围内的场景变化，从24天/夜照明周期到长期季节变化。</p><p id="97aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载及论文</strong> : <a class="ae jp" href="https://oxford-robotics-institute.github.io/radar-robotcar-dataset/" rel="noopener ugc nofollow" target="_blank"> 2019年数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/1909.01300.pdf" rel="noopener ugc nofollow" target="_blank"> 2019年论文</a>，<a class="ae jp" href="https://robotcar-dataset.robots.ox.ac.uk/" rel="noopener ugc nofollow" target="_blank"> 2016年数据集</a>，<a class="ae jp" href="https://robotcar-dataset.robots.ox.ac.uk/images/robotcar_ijrr.pdf" rel="noopener ugc nofollow" target="_blank"> 2016年论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="20aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : Waymo开放数据集</p><p id="c697" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">发布年份</strong> : 2021年和2019年</p><p id="9a34" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像头、激光雷达</p><p id="053c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:美国(旧金山、山景城、洛杉矶、底特律、西雅图、凤凰城)</p><p id="c67d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:way mo开放数据集于2019年8月首次推出，其感知数据集包含1950个细分市场的高分辨率传感器数据和标签。2021年3月，扩展了Waymo开放数据集，使其还包括一个运动数据集，该数据集包含103，354个分段的对象轨迹和相应的3D地图。Waymo开放数据集包括各种各样的环境、对象和天气条件(市区、郊区、白天、夜间、行人、骑自行车的人、建筑、各种天气)。</p><p id="c4f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载及论文</strong> : <a class="ae jp" href="https://www.waymo.com/open" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/abs/2104.10133" rel="noopener ugc nofollow" target="_blank"> 2021年论文</a>，<a class="ae jp" href="https://arxiv.org/pdf/1912.04838.pdf" rel="noopener ugc nofollow" target="_blank"> 2019年论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="c915" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong>:Lyft 5级数据集</p><p id="9308" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2019年</p><p id="0bf6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像头、激光雷达、雷达</p><p id="a4aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:美国(帕洛阿尔托)</p><p id="13ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:该数据集可用于超过1000小时数据的运动预测。这是由一支由20辆自动驾驶汽车组成的车队在加利福尼亚州帕洛阿尔托的一条固定路线上收集的，历时四个月。它由170，000个场景组成，每个场景长25秒，捕捉自动驾驶系统的感知输出，这些输出编码了附近车辆、骑自行车者和行人随着时间推移的精确位置和运动。在此基础上，数据集包含一个高清语义地图，其中有15，242个标记元素和该地区的高清鸟瞰图。数据集包括一个高清语义地图，以提供关于交通代理及其运动的上下文。该地图包含4000多个手动注释的语义元素，包括车道段、人行横道、停车标志、停车区、减速带和减速带。数据集包括来自真实世界场景的元素，包括车辆、行人、十字路口和多车道交通。</p><p id="d00e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://level5.lyft.com/dataset/" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://tinyurl.com/lyft-prediction-dataset" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="c90d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : Argoverse</p><p id="863a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2019年</p><p id="bd3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机、激光雷达</p><p id="1632" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:美国(匹兹堡，迈阿密)</p><p id="60f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong> : Argoverse是由匹兹堡和迈阿密的一支自动驾驶汽车车队收集的。Argoverse 3D追踪数据集包括来自7个具有重叠视野的相机的360度图像、来自远程激光雷达的3D点云、6自由度姿态和3D轨迹注释。它提供了面向前方的立体图像。Argoverse运动预测数据集包括超过300，000个5秒的跟踪场景，其中特定车辆被识别用于轨迹预测。Argoverse是第一个包含“高清地图”的自动驾驶汽车数据集，其中有290公里的地图车道，带有几何和语义元数据。它提供了关于道路基础设施和交通规则的丰富语义信息。</p><p id="a37d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://www.argoverse.org/data.html" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/1911.02620" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="fcf8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : nuScenes数据集</p><p id="9ce7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2019年</p><p id="eb1c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:相机、激光雷达、雷达</p><p id="3eac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:美国(波士顿)、新加坡</p><p id="2583" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong> : nuTonomy场景(nuScenes)携带完全自主的车辆传感器套件:6个摄像头，5个雷达和1个激光雷达，所有这些都具有完整的360度视野。nuScenes由1000个场景组成，每个场景20秒长，并完全标注了23个类别和8个属性的3D边界框。它的注释数量是开创性的KITTI数据集的7倍，图像数量是其100倍。数据来自波士顿(海港和南波士顿)和新加坡(一北、荷兰村和皇后镇)，这两个城市以其密集的交通和极具挑战性的驾驶环境而闻名。就植被、建筑物、车辆、道路标记以及右行和左行交通而言，不同地点之间存在差异。</p><p id="50f2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://www.nuscenes.org/download" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/1903.11027" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="39c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : BLVD:打造大规模5D自动驾驶语义标杆</p><p id="617e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2019年</p><p id="648e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机、3D激光雷达</p><p id="8b08" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:中国(常熟)</p><p id="bd92" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong> : BLVD，大型5D语义基准，旨在为动态4D(3D+时态)跟踪、5D(4D+交互)交互事件识别、意图预测等任务提供平台。BLVD数据集包含从中国江苏省常熟市(中国智能车辆测试中心(IVPCC)所在地)提取的12万帧的654个高分辨率视频剪辑。RGB数据和3D点云的帧速率为10 fps/秒。对所有帧进行完全注释，总共产生249，129个3D注释，4，902个用于跟踪的独立个体，总长度为214，922点，6，004个用于5D交互事件识别的有效片段，以及4，900个用于5D意图预测的个体。根据对象密度(低和高)和光照条件(白天和夜间)，这些任务包含在四种场景中。</p><p id="69fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://github.com/VCCIV/BLVD/" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/1903.06405" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="469e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : H3D - Honda 3D数据集</p><p id="2150" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2019年</p><p id="f783" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机、激光雷达</p><p id="8df7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:美国(旧金山)</p><p id="5d39" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:本田研究所3D数据集(H3D)，使用3D激光雷达扫描仪收集的大规模全环绕3D多目标检测和跟踪数据集。H3D由160个拥挤且高度互动的交通场景组成，在27，721帧中总共有100万个标记实例。凭借独特的数据集大小、丰富的注释和复杂的场景，H3Dis聚集在一起，激发了对全环绕3D多对象检测和跟踪的研究。它是从HDD数据集收集的，HDD数据集是在旧金山湾区收集的大规模自然主义驾驶数据集。H3D包括1)完整的360度激光雷达数据集(来自威力登-64的密集点云)2) 160个拥挤且高度互动的交通场景3) 1，071，302个3D边界框标签4) 8类常见的交通参与者(每隔2Hz手动注释并对10 Hz数据进行线性传播)9)基于仅3D检测和跟踪算法的最先进算法的基准测试。</p><p id="a32e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://usa.honda-ri.com/h3d" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/1903.01568" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="c3e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong>:阿波罗景观</p><p id="7589" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2019年</p><p id="35b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机、激光雷达</p><p id="6333" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:中国</p><p id="55fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong> : ApolloScape包含更大更丰富的标注，包括每个站点的整体语义密集点云、立体、逐像素语义标注、车道标志标注、实例分割、3D汽车实例、来自多个站点、城市和白天的各种驾驶视频中每一帧的高精度定位。数据集包含140，000+带车道注释的注释图像。对于3D对象检测，它在6K+点云中标注对象的3D边界框。它由中国4个地区在不同天气条件下的数据组成。</p><p id="7d20" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="http://apolloscape.auto/index.html" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://arxiv.org/pdf/1803.06184" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="aa25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : DBNet</p><p id="cd2d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2018年</p><p id="76ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机、激光雷达</p><p id="066a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:中国</p><p id="b403" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong> : DBNet是一个用于驾驶行为研究的大规模数据集。它包括对齐的视频、点云、GPS和驾驶员行为(速度和车轮)，可以捕捉1000公里的真实世界驾驶数据。激光雷达视频数据集提供了由威力登激光扫描的大规模高质量点云、由仪表板摄像机记录的视频以及标准驾驶员行为。</p><p id="aed8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="http://www.dbehavior.net/" rel="noopener ugc nofollow" target="_blank">数据集</a>，<a class="ae jp" href="https://openaccess.thecvf.com/content_cvpr_2018/CameraReady/1645.pdf" rel="noopener ugc nofollow" target="_blank">论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="486c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : KAIST多光谱数据集(2018)和KAIST多光谱行人数据集(2015)</p><p id="e8e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">发布年份</strong> : 2018年和2015年</p><p id="e820" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong> : 2018 - <strong class="ih hj">摄像头</strong>(视觉和<strong class="ih hj">热</strong>)，激光雷达。<strong class="ih hj"> 2015 </strong> -摄像机(视觉和<strong class="ih hj">热</strong></p><p id="e612" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">录制地区</strong>:南韩(首尔)</p><p id="1746" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong> : <strong class="ih hj"> 2018 </strong>:数据集除了提供精细时间段(日出、清晨、午后、日落、夜晚、黎明)外，还提供了在粗略时间段(白天和黑夜)捕捉到的世界的不同视角。对于自治系统的全天感知，可以使用热成像相机。为实现这一目标，开发了一个多传感器平台，支持使用共校准RGB/热感相机、RGB立体摄像机、3d激光雷达和惯性传感器(GPS/IMU)以及相关校准技术。</p><p id="4050" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2015 </strong>:多光谱行人数据集，提供由基于分束器的特殊硬件捕获的对齐良好的彩色-热图像对。色热数据集与先前基于颜色的数据集一样大，并提供密集的注释，包括时间对应。通过这个数据集，该团队引入了多光谱ACF，这是聚合通道特征(ACF)的一种扩展，可同时处理彩色-热图像对。多光谱ACF将ACF的平均漏检率降低了15%。</p><p id="a1f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载及论文</strong> : <a class="ae jp" href="http://multispectral.kaist.ac.kr" rel="noopener ugc nofollow" target="_blank"> 2018数据集</a>，<a class="ae jp" href="https://doi.org/10.1109/TITS.2018.2791533" rel="noopener ugc nofollow" target="_blank"> 2018论文</a>，<a class="ae jp" href="https://www-users.cs.umn.edu/~jsyoon/JaeShin_homepage/kaist_multispectral.pdf" rel="noopener ugc nofollow" target="_blank"> 2018论文下载选项-2 </a>，<a class="ae jp" href="https://soonminhwang.github.io/rgbt-ped-detection/" rel="noopener ugc nofollow" target="_blank"> 2015数据集</a>，<a class="ae jp" href="https://openaccess.thecvf.com/content_cvpr_2015/papers/Hwang_Multispectral_Pedestrian_Detection_2015_CVPR_paper.pdf" rel="noopener ugc nofollow" target="_blank"> 2015论文</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="a39a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : FLIR ADAS数据集</p><p id="00c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">出版年份</strong> : 2018</p><p id="867f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:摄像机(视觉和<strong class="ih hj">热</strong>)</p><p id="c734" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">记录区域</strong>:美国(圣巴巴拉)</p><p id="0798" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">描述</strong>:该数据集以1万多幅白天和夜晚场景中人、车、其他车辆、自行车和狗的热图像注释汇编为特色。它主要拍摄于美国加利福尼亚州圣巴巴拉的街道和高速公路上，白天和晚上天空晴朗。热图像的注释基于COCO注释方案。但是，相应的可见图像不存在注释。</p><p id="3581" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载和论文</strong> : <a class="ae jp" href="https://www.flir.com/oem/adas/adas-dataset-form/" rel="noopener ugc nofollow" target="_blank">数据集</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="2582" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">名称</strong> : KITTI</p><p id="e122" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">发表年份</strong> : 2015、2013、2012</p><p id="18c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">传感器类型</strong>:相机、激光雷达</p><p id="5ae0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">记录区</strong>:德国(卡尔斯鲁厄)</p><p id="dcc1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">说明</strong>:对于立体、光流、视觉里程计、三维物体检测、三维跟踪等任务，配备一辆标准旅行车，配备两台高分辨率彩色、灰度摄像机。精确的地面实况由威力登激光扫描仪和全球定位系统提供。数据集是通过在中等规模的卡尔斯鲁厄市、农村地区和高速公路上行驶来获取的。每个图像中最多可看到15辆汽车和30名行人，此外还提供了原始格式的所有数据，以及为每个任务提取的基准。</p><p id="9eca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集下载及论文</strong> : <a class="ae jp" href="http://www.cvlibs.net/datasets/kitti/" rel="noopener ugc nofollow" target="_blank">数据集</a>、<a class="ae jp" href="https://doi.org/10.1109/CVPR.2012.6248074" rel="noopener ugc nofollow" target="_blank"> 2012年论文</a>、<a class="ae jp" href="http://www.cvlibs.net/publications/Geiger2012CVPR.pdf" rel="noopener ugc nofollow" target="_blank"> 2012年论文下载选项-2 </a>、<a class="ae jp" href="https://doi.org/10.1177/0278364913491297" rel="noopener ugc nofollow" target="_blank"> 2013年论文-1 </a>、<a class="ae jp" href="http://www.cvlibs.net/publications/Geiger2013IJRR.pdf" rel="noopener ugc nofollow" target="_blank"> 2013年论文-1下载选项-2 </a>、<a class="ae jp" href="https://doi.org/10.1109/ITSC.2013.6728473" rel="noopener ugc nofollow" target="_blank"> 2013年论文-2 </a>、<a class="ae jp" href="http://www.cvlibs.net/publications/Fritsch2013ITSC.pdf" rel="noopener ugc nofollow" target="_blank"> 2013年论文-2下载选项-2【T32</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jr"><img src="../Images/9fca9660dd9c9b6226285c62645855f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*tnvZQevRkV0kL0uMI6OAFQ.png"/></div></figure><p id="0d85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">感谢</strong>阅读！请👏如果你喜欢这个帖子，请<strong class="ih hj">关注我</strong>，因为它<strong class="ih hj">鼓励我</strong>写更多！</p></div></div>    
</body>
</html>