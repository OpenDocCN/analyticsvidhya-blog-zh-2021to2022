<html>
<head>
<title>Training Neural Network for Sentiment Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于情感分析的训练神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/training-neural-network-for-sentiment-analysis-57cbe85442ab?source=collection_archive---------11-----------------------#2021-03-23">https://medium.com/analytics-vidhya/training-neural-network-for-sentiment-analysis-57cbe85442ab?source=collection_archive---------11-----------------------#2021-03-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="704f" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">基于客户评论，逐步预测对亚马逊Alexa产品的看法(正面或负面)。</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/4e334e5fcaea2a419dc2d0c9940b15a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o3fvm0jRlj19Ou_L7zKnRw.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">图片由<a class="ae jm" href="https://pixabay.com/users/kevinking-289243/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=423857" rel="noopener ugc nofollow" target="_blank">凯文·金</a>从<a class="ae jm" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=423857" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>拍摄</figcaption></figure><p id="10ca" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi kj translated"><span class="l kk kl km bm kn ko kp kq kr di">我</span>一直着迷于这样一个想法，一台机器如何能够读取顾客给出的<strong class="jp hi">评论</strong>并<strong class="jp hi">将</strong>分类为<strong class="jp hi">正面</strong>或<strong class="jp hi">负面</strong>以及许多其他问题，比如-</p><h2 id="b077" class="ks kt hh bd ku kv kw kx ky kz la lb lc jw ld le lf ka lg lh li ke lj lk ll lm bi translated">清洗数据需要什么样的预处理才能让机器看得懂？</h2><blockquote class="ln lo lp"><p id="84c7" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">如何删除标点符号和HTML标签？？</p><p id="7498" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">小写和大写字母的混合会混淆机器学习算法吗？</p><p id="912a" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">如何删除不增加任何价值的重复单词，如“a，an，and，the”。？</p><p id="212b" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">如何移除表情符号<em class="hh">😅？</em></p></blockquote><p id="1130" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">当我解决一个'<strong class="jp hi">亚马逊</strong> <strong class="jp hi"> Alexa情绪分析问题</strong>时，所有上述问题都得到了回答，该问题根据使用过<strong class="jp hi"> Alexa </strong>的特定变体(如<em class="lq">炭布、黑点、胡桃木饰面</em>)的各种客户给出的<strong class="jp hi">评论</strong>来预测情绪是<strong class="jp hi">正面</strong>还是<strong class="jp hi">负面</strong></p></div><div class="ab cl lu lv go lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ha hb hc hd he"><h1 id="a891" class="mb kt hh bd ku mc md me ky mf mg mh lc in mi io lf iq mj ir li it mk iu ll ml bi translated">对我有什么好处？</h1><p id="9ea8" class="pw-post-body-paragraph jn jo hh jp b jq mm ii js jt mn il jv jw mo jy jz ka mp kc kd ke mq kg kh ki ha bi translated">情绪分析问题的端到端解决方案，即根据自由文本<strong class="jp hi">评论</strong>或<strong class="jp hi">亚马逊Alexa </strong>的客户反馈，预测情绪是<strong class="jp hi">正面</strong>还是<strong class="jp hi">负面</strong></p><blockquote class="ln lo lp"><p id="eec1" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">完整的Python代码可以在我的<a class="ae jm" href="https://github.com/rahul-pednekar/NLP-Sentiment-Analysis-Alexa/blob/main/nlp-alexa-with-93-accuracy.ipynb" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi"> GitHub </strong> </a>资源库中找到。</p></blockquote><h1 id="526f" class="mb kt hh bd ku mc mr me ky mf ms mh lc in mt io lf iq mu ir li it mv iu ll ml bi translated">要使用哪个数据集？</h1><p id="867b" class="pw-post-body-paragraph jn jo hh jp b jq mm ii js jt mn il jv jw mo jy jz ka mp kc kd ke mq kg kh ki ha bi translated">我们将使用来自<a class="ae jm" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi"> Kaggle </strong> </a>的<strong class="jp hi">亚马逊Alexa评论</strong>数据集，可以从<a class="ae jm" href="https://www.kaggle.com/sid321axn/amazon-alexa-reviews" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">这里</strong> </a>下载</p><h2 id="16b3" class="ks kt hh bd ku kv kw kx ky kz la lb lc jw ld le lf ka lg lh li ke lj lk ll lm bi translated">关于数据</h2><blockquote class="ln lo lp"><p id="c02e" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">该数据集包括近3000条亚马逊客户评论(输入文本)、星级、评论日期、各种亚马逊Alexa产品的变体和反馈，如Alexa Echo、Echo dots、Alexa Firesticks等。</p></blockquote><h1 id="c836" class="mb kt hh bd ku mc mr me ky mf ms mh lc in mt io lf iq mu ir li it mv iu ll ml bi translated">先看数据</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mw"><img src="../Images/4ca7a1f46e2f349f709dfc95273078d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bYL3yRXxFEOqHUjwdLhNqA.png"/></div></div></figure><p id="eef5" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">总共有5列—</p><ol class=""><li id="6bf5" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki nc nd ne nf bi translated">等级:唯一值为(1，2，3，4，5) ' <strong class="jp hi"> 1' </strong>最低等级，'<strong class="jp hi"> 5' </strong>最高等级</li><li id="7a94" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki nc nd ne nf bi translated">日期:给出反馈的日期</li><li id="a2a4" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki nc nd ne nf bi translated">变体:有16个唯一值。几个例子:白色加，木炭织物等</li><li id="f28b" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki nc nd ne nf bi translated">已核实_评论:客户在自由文本中给出的实际<strong class="jp hi">评论</strong>——正面或负面</li><li id="b4c2" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki nc nd ne nf bi translated">反馈(<strong class="jp hi">预测</strong>的目标变量) :唯一值‘1’(<strong class="jp hi">快乐客户</strong>)或‘0’(<strong class="jp hi">悲伤客户</strong>)</li></ol><p id="0da9" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">总结</strong> —基于<strong class="jp hi">‘已验证_评论’</strong>列，我们需要预测<strong class="jp hi">反馈</strong>列(即反馈是<strong class="jp hi">‘1’</strong>(即正面)还是<strong class="jp hi">0</strong>’(即负面))</p></div><div class="ab cl lu lv go lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ha hb hc hd he"><h1 id="52fe" class="mb kt hh bd ku mc md me ky mf mg mh lc in mi io lf iq mj ir li it mk iu ll ml bi translated">方法:</h1><p id="f035" class="pw-post-body-paragraph jn jo hh jp b jq mm ii js jt mn il jv jw mo jy jz ka mp kc kd ke mq kg kh ki ha bi translated">让我们把这个问题分成4个简单的步骤</p><ol class=""><li id="c7b8" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki nc nd ne nf bi translated">可视化数据并得出推论(EDA)</li><li id="9490" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki nc nd ne nf bi translated">数据清理</li><li id="e683" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki nc nd ne nf bi translated">模型建立和预测</li><li id="fce2" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki nc nd ne nf bi translated">总结和总结</li></ol><p id="be7d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">我的首选工具</strong> : Python 3.8和Jupyter笔记本</p><h2 id="15a7" class="ks kt hh bd ku kv kw kx ky kz la lb lc jw ld le lf ka lg lh li ke lj lk ll lm bi translated">所以让我们开始吧！！</h2></div><div class="ab cl lu lv go lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ha hb hc hd he"><h1 id="5184" class="mb kt hh bd ku mc md me ky mf mg mh lc in mi io lf iq mj ir li it mk iu ll ml bi translated">第一步:可视化数据并得出推论(EDA)</h1><ul class=""><li id="497c" class="mx my hh jp b jq mm jt mn jw nl ka nm ke nn ki no nd ne nf bi translated">让我们计算每篇评论的长度，并做出推论</li></ul><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nr"><img src="../Images/0b968fb263f97f1b9d0fd575391899d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ccQNY5I-TR48OWDKH4PhpQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">评分=5的评论数量最高，长度为1955(0-199)</figcaption></figure><ul class=""><li id="bb37" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated"><em class="lq">探究</em> <strong class="jp hi"> <em class="lq">长度</em></strong><em class="lq"/><strong class="jp hi"><em class="lq">评审</em> </strong> <em class="lq">如何随着</em> <strong class="jp hi"> <em class="lq">评级</em> </strong> <em class="lq">与</em> <strong class="jp hi"> <em class="lq">色相=反馈</em> </strong></li></ul><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ns"><img src="../Images/81260738a7c36a535c869eaa126509a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0I-u8LqT-G_fp4m3HQ8A5w.png"/></div></div></figure><p id="a618" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">上图证实了-</p><blockquote class="ln lo lp"><p id="7759" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">反馈=1对应于等级3、4、5(分别为好、更好、最好)</p><p id="19d2" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">反馈=0对应于评分1，2(分别为最差、差)</p><p id="b205" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">'<strong class="jp hi"> feedback=0 </strong>'的平均长度高于'<strong class="jp hi"> feedback=1 </strong> ' ( <strong class="jp hi">不满意的人比满意的人更有可能写出冗长的评论<em class="hh">😃</em> </strong>)</p><p id="2565" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">与其他人(评分1-4)相比，高度满意的人(评分=5)写得最少</p><p id="1037" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">评分= 2的产品评论最长</p></blockquote><ul class=""><li id="6c8e" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated"><em class="lq">探究</em> <strong class="jp hi"> <em class="lq">长度</em></strong><strong class="jp hi"><em class="lq">回顾</em> </strong> <em class="lq">如何根据</em> <strong class="jp hi"> <em class="lq">变化</em> </strong> <em class="lq">与</em> <strong class="jp hi"> <em class="lq">色相=反馈</em> </strong></li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nt"><img src="../Images/6e9b808c609619a7f1110130556b71b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v9-n-YLUJonrXrC6znHe7Q.png"/></div></div></figure><blockquote class="ln lo lp"><p id="a4a8" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">一般来说，反馈=0(即负面评价)的评价时间长度要比反馈=1(即正面评价)的长</p><p id="740f" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">如果反馈=0，则“黑色秀”、“黑色加”和“白色加”的审核时间更长</p><p id="5c28" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">对于“胡桃木饰面”和“橡木饰面”，反馈=0</p></blockquote><ul class=""><li id="542a" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">让我们通过评级来确定最佳和最差产品</li></ul><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nu"><img src="../Images/118c16b3fff6097ac810cea27975aeca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RmalRH80IYZ981f5MIMh4g.png"/></div></div></figure><blockquote class="ln lo lp"><p id="a76d" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">最佳产品:胡桃木饰面和橡木饰面只有5分</p><p id="c3e5" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">最差产品:白色，因为等级1、2和3的密度更大</p></blockquote></div><div class="ab cl lu lv go lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ha hb hc hd he"><h1 id="2e7e" class="mb kt hh bd ku mc md me ky mf mg mh lc in mi io lf iq mj ir li it mk iu ll ml bi translated">步骤2:数据清理</h1><blockquote class="ln lo lp"><p id="557c" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">让我们清理数据(例如，转换成小写，删除标点符号，HTML标签等)</p></blockquote><ul class=""><li id="e9d5" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">将所有评论转换为小写</li></ul><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nv"><img src="../Images/f57304bd007c956089a22163c9e73424.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y7st2BCNTCiIOMsj2AmKXw.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">大写到小写转换</figcaption></figure><ul class=""><li id="0112" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">使用BeautifulSoup库删除HTML标签</li></ul><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nw"><img src="../Images/5b71f4a757d473454641456473cd0f3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tkgrxPCV2gtSumRXV-lQ3A.png"/></div></div></figure><ul class=""><li id="3a22" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">删除停用词和标点符号</li></ul><h2 id="a0b5" class="ks kt hh bd ku kv kw kx ky kz la lb lc jw ld le lf ka lg lh li ke lj lk ll lm bi translated">什么是停用词？</h2><blockquote class="ln lo lp"><p id="4f7d" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">停用词是最常见的词(“the”、“is”、“in”、“for”、“where”、“when”、“to”、“at”等)。)在任何自然语言中。为了分析文本数据和构建自然语言处理模型，这些停用词可能不会给文档的含义增加太多价值，因此需要被移除。</p></blockquote><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nx"><img src="../Images/d64f8ee43f7b8aa9fba1ef942511a4a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WFWJaToPEHsc3K9FMu4w6Q.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">示例—从第3行中，删除了“a”</figcaption></figure><ul class=""><li id="71af" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">让我们对数据进行词汇化</li></ul><h2 id="01cd" class="ks kt hh bd ku kv kw kx ky kz la lb lc jw ld le lf ka lg lh li ke lj lk ll lm bi translated">什么是词汇化？</h2><blockquote class="ln lo lp"><p id="b971" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated"><em class="hh">把任何一种词转换成它的基根模式的方法叫做词元化。</em></p><p id="bd66" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">词汇化的例子:</p><p id="fe9c" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">1.玩:玩<br/> 2。爱过:爱<br/> 3。更好:好</p></blockquote><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ny"><img src="../Images/63f98b1c03b39dd17a7dcdd219ef52f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_iZSE4b42iliM7AdRJSxeg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">例如:第2行—“loved”变成了“love”</figcaption></figure><blockquote class="ln lo lp"><p id="ad52" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">这就是清理数据所需的全部内容。让我们用干净的数据来可视化单词云</p></blockquote><h2 id="4971" class="ks kt hh bd ku kv kw kx ky kz la lb lc jw ld le lf ka lg lh li ke lj lk ll lm bi translated">好评如潮的Wordcloud</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nz"><img src="../Images/f97f5f38ee3bdf38fe899cc8542c2672.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GGitnr1z_1B2vegwij3-LA.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">我们可以看到积极的词汇，如爱，伟大，真棒，易于使用，完美</figcaption></figure><h2 id="e2f0" class="ks kt hh bd ku kv kw kx ky kz la lb lc jw ld le lf ka lg lh li ke lj lk ll lm bi translated">带有负面评论的Wordcloud</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es oa"><img src="../Images/f47bb827e5b30a5dace0b8b9dafe5fb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4OblUmjBAGJu0KYZFhvJtg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">我们可以用消极的词，比如失望、可怜、糟糕</figcaption></figure></div><div class="ab cl lu lv go lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ha hb hc hd he"><h1 id="8883" class="mb kt hh bd ku mc md me ky mf mg mh lc in mi io lf iq mj ir li it mk iu ll ml bi translated">第三步:模型建立和预测</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/d931b7bf6c035465234d50f264748294.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JbKSzrMQoN9_sTSiCjD6-A.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">图片来自<a class="ae jm" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3829057" rel="noopener ugc nofollow" target="_blank"> Pixabay </a>的<a class="ae jm" href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3829057" rel="noopener ugc nofollow" target="_blank"> Gerd Altmann </a></figcaption></figure><blockquote class="ln lo lp"><p id="b61f" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">正面评价总数:2893，负面评价总数:257</p><p id="e81d" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated"><strong class="jp hi">准备训练和测试数据集</strong></p><p id="1d7c" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">反馈=1:总共2893条评论</p><p id="b225" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">我们可以将第一个2025(70%)用于训练，剩下的868(30%)用于测试。即2893=2025+868</p><p id="d8c1" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">反馈=0:共257条评论</p><p id="2df7" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">我们可以将前180(70%)用于训练，剩余的77(30%)用于测试，即257=180+77</p></blockquote><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><h2 id="13f8" class="ks kt hh bd ku kv kw kx ky kz la lb lc jw ld le lf ka lg lh li ke lj lk ll lm bi translated">用Tensorflow和Keras构建深度学习模型</h2><ul class=""><li id="82d3" class="mx my hh jp b jq mm jt mn jw nl ka nm ke nn ki no nd ne nf bi translated">将数据符号化</li></ul><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">将数据符号化</figcaption></figure><ul class=""><li id="645e" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">准备深度学习模型</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/9b609e6a739f30ead53db57295deddb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fCrLegDP0_i-SVcCCpEJPg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">图片由<a class="ae jm" href="https://pixabay.com/users/ahmedgad-9403351/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3637503" rel="noopener ugc nofollow" target="_blank"> Ahmed Gad </a>提供，来自<a class="ae jm" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3637503" rel="noopener ugc nofollow" target="_blank"> Pixabay </a></figcaption></figure><blockquote class="ln lo lp"><p id="783b" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">让我们使用<strong class="jp hi">神经网络</strong>的第一层中的<strong class="jp hi"> 256个神经元</strong>和第二层中的<strong class="jp hi"> 128个神经元</strong>指定input_shape =总字数<br/>我们将使用激活函数作为<strong class="jp hi"> relu </strong> <br/>以及两层中的<strong class="jp hi">批处理规范化函数</strong><br/>添加一个<strong class="jp hi">丢弃层</strong>以丢弃第一层中50%的神经元和第二层中50%的神经元</p></blockquote><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><ul class=""><li id="bf4c" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">编译模型</li></ul><blockquote class="ln lo lp"><p id="2ddb" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">由于这是一个二进制分类问题，我们用“二进制交叉熵”作为损失函数</p><p id="6968" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">作为优化者的亚当</p><p id="676d" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated">准确性评估指标</p></blockquote><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><ul class=""><li id="ae3d" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">拟合模型并运行20个时期</li></ul><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><ul class=""><li id="1ecf" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">评估模型</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ob"><img src="../Images/4ca53863c4df7ed770ea9abd6cfd4899.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QvEvnlFnpm4rRyisGKJvlw.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">模型预测的验证准确率为93%</figcaption></figure><ul class=""><li id="4d42" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">让我们绘制培训/验证准确性图表和损失图表</li></ul><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="np nq l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es oc"><img src="../Images/04fc7b959016c23564dc8595ac3367c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hO24fOfC0wUqZ758ewGQLQ.png"/></div></div></figure><ul class=""><li id="f745" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki no nd ne nf bi translated">让我们评估混淆矩阵</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es od"><img src="../Images/ffd9eb333f3c7f584c75db842d63321d.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*4jFGoPcNqi7SIOMDkzo8Ww.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">混淆矩阵</figcaption></figure></div><div class="ab cl lu lv go lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="ha hb hc hd he"><h1 id="2823" class="mb kt hh bd ku mc md me ky mf mg mh lc in mi io lf iq mj ir li it mk iu ll ml bi translated">第4步:结论和要点</h1><ul class=""><li id="beb0" class="mx my hh jp b jq mm jt mn jw nl ka nm ke nn ki no nd ne nf bi translated">模型达到了<strong class="jp hi"> 93% </strong>的预测精度</li><li id="6c65" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki no nd ne nf bi translated">人工神经网络能够正确地预测868个正面评论中866个，错误地预测2个评论</li><li id="d65d" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki no nd ne nf bi translated">然而，它只能正确预测77篇评论中的13篇负面评论，而错误预测64篇评论</li><li id="7869" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki no nd ne nf bi translated">主要原因是我们的数据不平衡，即<strong class="jp hi"> 92% </strong> (2893/3150)的评论是正面的，而<strong class="jp hi"> 8% </strong> (257/3150)的评论是负面的</li><li id="e2e0" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki no nd ne nf bi translated">使用过采样和欠采样技术，如<strong class="jp hi"> SMOTE </strong>(合成少数过采样技术)或<strong class="jp hi">随机过/欠采样</strong>，可以进一步提高精度</li></ul><p id="870d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这是我们讨论过的内容</p><ol class=""><li id="e1aa" class="mx my hh jp b jq jr jt ju jw mz ka na ke nb ki nc nd ne nf bi translated">如何使用NLTK工具包清理自由文本数据</li><li id="2daf" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki nc nd ne nf bi translated">如何标记数据</li><li id="8fa8" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki nc nd ne nf bi translated">如何建立一个简单的人工神经网络</li><li id="2ef9" class="mx my hh jp b jq ng jt nh jw ni ka nj ke nk ki nc nd ne nf bi translated">如何预测和验证预测</li></ol><p id="e773" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">干杯，感谢阅读！😃</p><p id="45db" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">您可以在我的Github资源库中找到完整的Python代码。</p><div class="oe of ez fb og oh"><a href="https://github.com/rahul-pednekar/NLP-Sentiment-Analysis-Alexa/" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab dw"><div class="oj ab ok cl cj ol"><h2 class="bd hi fi z dy om ea eb on ed ef hg bi translated">Rahul-pednekar/NLP-情感分析-Alexa</h2><div class="oo l"><h3 class="bd b fi z dy om ea eb on ed ef dx translated">用于情感分析的训练神经网络</h3></div><div class="op l"><p class="bd b fp z dy om ea eb on ed ef dx translated">github.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov jg oh"/></div></div></a></div><blockquote class="ln lo lp"><p id="34a2" class="jn jo lq jp b jq jr ii js jt ju il jv lr jx jy jz ls kb kc kd lt kf kg kh ki ha bi translated"><em class="hh">如有任何疑问，请随时联系我</em><a class="ae jm" href="https://www.linkedin.com/in/pednekar-rahul/" rel="noopener ugc nofollow" target="_blank"><strong class="jp hi"><em class="hh">LinkedIn</em></strong></a><em class="hh">&amp;我很乐意提供支持。</em></p></blockquote><p id="60fc" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lq">跟我连线上</em><a class="ae jm" href="https://www.linkedin.com/in/pednekar-rahul/" rel="noopener ugc nofollow" target="_blank"><em class="lq">LinkedIn</em></a><em class="lq"/><a class="ae jm" rel="noopener" href="/@rahul.pednekar"><em class="lq">中</em> </a> <em class="lq">和</em> <a class="ae jm" href="https://www.kaggle.com/rahulpednekar" rel="noopener ugc nofollow" target="_blank"> <em class="lq"> Kaggle </em> </a></p></div></div>    
</body>
</html>