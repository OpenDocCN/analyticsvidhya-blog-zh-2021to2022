<html>
<head>
<title>A Super Simple Explanation to Regression Trees and Random Forest Regressors</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">回归树和随机森林回归子的简单解释</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-super-simple-explanation-to-regression-trees-and-random-forest-regressors-91f27957f688?source=collection_archive---------10-----------------------#2021-04-18">https://medium.com/analytics-vidhya/a-super-simple-explanation-to-regression-trees-and-random-forest-regressors-91f27957f688?source=collection_archive---------10-----------------------#2021-04-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="c850" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">目标</strong></h1><p id="9f1c" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">通过这篇文章，我试图实现的是对基本ML概念的全面介绍(希望能发展成一个完整的系列)。在可能的范围内，这些概念将通过在Python上进行的和/或手工制作的玩具示例来说明。我的主要信息来源(和灵感)是非常有趣、非常博学的乔希·斯塔默。</p><h1 id="04cc" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">观众</strong></h1><p id="89ea" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">任何数据科学新手/对ML基础感到生疏。</p><h1 id="3bdf" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">什么是回归树(又名。决策树回归器)？</strong></h1><p id="0da6" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">回归树是一种非常直观和简单的算法，用于处理具有连续Y变量的问题。</p><h1 id="dedb" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">他们可以使用哪些类型的数据作为特征？</strong></h1><ul class=""><li id="e39d" class="ka kb hh je b jf jg jj jk jn kc jr kd jv ke jz kf kg kh ki bi translated">数字的</li><li id="925e" class="ka kb hh je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki bi translated">分类<br/> -二进制<br/> -多类</li></ul><h1 id="3337" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">玩具示例</strong></h1><p id="0ca4" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在这个玩具示例中，我们试图根据年收入来预测预期寿命。为了简单起见，我们只有一个连续的X变量。如果你想知道如何处理分类变量，你可以查看<a class="ae ko" href="https://lnkd.in/g8kyvcU" rel="noopener ugc nofollow" target="_blank">一个对决策树分类器</a>的超级简单的解释，它有详细的手工计算。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es kp"><img src="../Images/37f179326fd7a0bbbf9da04ed91bab0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*zhBbOK_x56cQbBwgmMD4Ag.png"/></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es kx"><img src="../Images/1cbdf6991e62b27503e6d850e01138a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*rl62x4UfoHHwNk45ee-oKg.png"/></div></figure><p id="7079" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">显然，线性回归在这里不起作用。看起来年收入的增加只会在一定程度上导致预期寿命的增加，之后预期寿命开始下降。倒U形比直线更适合这个数据。</p><p id="faaa" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">那么回归树是如何计算出在哪里进行分割的呢？</p><p id="a187" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated"><strong class="je hi">第一步。对X变量(收入)进行升序排序。</strong> <br/>已经做了。</p><p id="84fe" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated"><strong class="je hi">第二步。求后续x之间的平均值。</strong> <br/>这些均值是分割的潜在阈值。因此，在本例中，我们不需要进行三次以上的拆分来进行最终预测。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es ld"><img src="../Images/ee248cca88d553ea8448482fb81b2850.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*7IlVp4M1lMm-hvgRjH8dRw.png"/></div></figure><p id="762b" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">如果你读过<a class="ae ko" href="https://lnkd.in/g8kyvcU" rel="noopener ugc nofollow" target="_blank">对决策树分类器</a>的一个超级简单的解释，那么步骤1 &amp; 2你会很熟悉。</p><p id="8e34" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated"><strong class="je hi">第三步。计算对应于x中每个分裂的平均Ys(预期寿命)和误差平方和(SSEs)。</strong></p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es le"><img src="../Images/3a8fde0340d5ac5224319c982a0fe617.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*oTcsz_s61thxnYwkbT9N8w.png"/></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lf"><img src="../Images/b74a2444f92560925fb1d1e383b983d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*FFYlyOTQVJln5afI3JxBnA.png"/></div></figure><p id="cf8d" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated"><em class="lg">在X=6.75上拆分:</em></p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lh"><img src="../Images/31d342e02410f997ecf4981e39f3dfc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*NftjHKJQB8LDMM_mhV_rNg.png"/></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es li"><img src="../Images/a9fee64e6b02f05f9a76638378c7be12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*TT5xm2RSaIhyStyNFod_zQ.png"/></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lj"><img src="../Images/38064b6d5dc25129a968cea15f3cc693.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*3GHvCEQ8ybOGJi1jteo40A.png"/></div></figure><p id="8737" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated"><em class="lg">在X=7.5上拆分:</em></p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lk"><img src="../Images/bb7130c70fca92079300fcefef907d04.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*mOMGuion57OolEXpZTVe_w.png"/></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es ll"><img src="../Images/77139abffe8a887c8173be0e7188c253.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*135B8BJC72y24p53ifUhHg.png"/></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lm"><img src="../Images/6bb06a8b32ac49b0f7b2e1650e891f4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*N3eTv5GwgzdjiipT1zMt3w.png"/></div></figure><p id="2ef8" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated"><em class="lg">在X=8.25上拆分:</em></p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es ln"><img src="../Images/d2ec4237f43a9eaa8ac3779c7ac4e3be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*YafChHvmtRA2oEE27IhvYg.png"/></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lo"><img src="../Images/00dbe3da4376968b170ed042e44743fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*8eopmkYRWbSWQQCvd5jzPg.png"/></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lp"><img src="../Images/12839236f1f5ac934829a0226dfff4e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*PtqtUG0iLN7GKgHfyudbfQ.png"/></div></figure><p id="63c2" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">显然，X = 8.25时的分割导致最低的SSE (=50)，因此这将是分割的第一个阈值。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lq"><img src="../Images/6ceaf017d7c67531465a75d1a9877e53.png" data-original-src="https://miro.medium.com/v2/resize:fit:914/format:webp/1*kn0SF-BX4igzaDN4iznXuw.png"/></div></figure><p id="16bd" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">我们看到图中的节点和树叶也提到了MSE，所以让我们快速看一下这是怎么回事。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lr"><img src="../Images/95ac9af431632558e283e80b2520035d.png" data-original-src="https://miro.medium.com/v2/resize:fit:438/format:webp/1*ZlaHJCYCuzR6y6Cpo3iMxg.png"/></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lf"><img src="../Images/b74a2444f92560925fb1d1e383b983d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*FFYlyOTQVJln5afI3JxBnA.png"/></div></figure><p id="fea7" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">当我们在节点上时，我们还没有做任何分割。在这一点上，天真的预测是平均预期寿命= (75 + 85 + 80 + 67)/4 = 76.75。</p><p id="ae5a" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">与这一天真的预测相对应，所有观测值的MSE为:</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ls"><img src="../Images/9f626a5d3c57f55da652e2d7e14a4506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AIOeUDsYKnXWmlBTaEbEeQ.png"/></div></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lx"><img src="../Images/609e323a6578db55164610a7ee748adb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yOuZLikJjqyPqNWzEkMKEw.png"/></div></div></figure><p id="5b8f" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">分割后，树叶中的MSE为:</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ly"><img src="../Images/7bdd7bf2ad825d6b62253c288baea8e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*70km4aj_SpYwBY5yY2KhUw.png"/></div></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es lz"><img src="../Images/10f5d47a3d185c8120546a5f9b40a9ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VAmF4hyuTKA16G4yYk-ZSg.png"/></div></div></figure><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es ma"><img src="../Images/911cce0870863c8eb5a8c7f9141b57b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*iu0rjacC5rfWikKjiufGEg.png"/></div></figure><p id="ae26" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated"><strong class="je hi">第三步。对每一片叶子分别重复步骤2，直到我们建立起一个完整的决策树。</strong></p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es mb"><img src="../Images/afd74ac89810bceada1c36ce4d6a4ff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*oawMIvPJZO30VwFcXid44w.png"/></div></figure><p id="47e3" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">因为我们没有限制我们的树的长度，它做出完美的预测，所以每片叶子的MSE是0。</p><h1 id="e611" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">随机森林回归量</h1><p id="8d1f" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">事情是这样的。乍一看，这似乎是一个适合任何具有连续因变量的数据的出色算法，但事实证明，决策树非常容易过度拟合(它们非常适合训练数据，但不太适合测试数据)。为了缓解这个问题，我们可以建立随机森林。关于随机森林如何工作的详细讨论，请阅读<a class="ae ko" href="https://lnkd.in/gXKc3EE" rel="noopener ugc nofollow" target="_blank">对随机森林分类器的超级简单解释</a>。随机森林分类器和随机森林回归器之间有两个确切的区别:</p><ol class=""><li id="5404" class="ka kb hh je b jf ky jj kz jn mc jr md jv me jz mf kg kh ki bi translated"><strong class="je hi">决定拆分的方式。</strong>在随机森林分类器中，分裂基于熵，而在随机森林回归器中，分裂基于MSE。</li><li id="4f10" class="ka kb hh je b jf kj jj kk jn kl jr km jv kn jz mf kg kh ki bi translated"><strong class="je hi">聚合方法</strong>。在分类问题中，随机森林采用所谓的“多数投票”,其中对跨树观察最常见的预测是观察的最终预测。另一方面，在回归问题中，跨树预测的平均值将是观测值的最终预测值。</li></ol><p id="932f" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">这些计算的乏味真的让人欣赏这些算法在Python上工作的速度，不是吗？您可以在:<a class="ae ko" href="https://github.com/sreevidyaraman/Regression-Tree" rel="noopener ugc nofollow" target="_blank">https://github.com/sreevidyaraman/Regression-Tree</a>找到构建和可视化回归树的代码。</p><p id="7eec" class="pw-post-body-paragraph jc jd hh je b jf ky jh ji jj kz jl jm jn la jp jq jr lb jt ju jv lc jx jy jz ha bi translated">[1]对于那些不喜欢线性回归的人来说，你并不孤单。我有经济学硕士学位，但线性回归仍然会让我出错。但是我很快会写一篇关于它的文章，它会澄清围绕这个话题的许多困惑。但就目前而言，你知道线性回归在这里不起作用就足够了，因为收入和预期寿命之间的关系不是线性的。</p><h1 id="c547" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">参考</h1><p id="248e" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">[1] Starmer，与Josh一起进行StatQuest。<em class="lg">回归树木，解释清楚！！！</em> YouTube，2019年8月20日，<a class="ae ko" href="https://www.youtube.com/watch?v=g9c66TUylZ4." rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=g9c66TUylZ4.</a></p></div></div>    
</body>
</html>