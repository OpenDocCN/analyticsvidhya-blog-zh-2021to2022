# å“ªç§æœºå™¨å­¦ä¹ æ¨¡å‹æœ€é€‚åˆé¢„æµ‹å“ªäº›è‚¡ç¥¨å€¼å¾—ä¹°ï¼Ÿ

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/showdown-which-machine-learning-model-is-the-best-for-predicting-which-stocks-are-worth-buying-2516de68d34f?source=collection_archive---------5----------------------->

![](img/eb23c86dbf9f6ca11d965f2ec284759e.png)

èµ„æ–™æ¥æº:wccftech

**æŒ‡å¯¼é—®é¢˜:** *å“ªç§æœºå™¨å­¦ä¹ æ¨¡å‹æœ€é€‚åˆé¢„æµ‹å“ªäº›è‚¡ç¥¨å€¼å¾—ä¹°å…¥ï¼Ÿ*

## æ•°æ®é›†æè¿°

å¯¹äºè¿™ä¸ªåˆ†æï¼Œæˆ‘å°†ä½¿ç”¨æ¥è‡ª Kaggle çš„[â€œç¾å›½è‚¡ç¥¨ 200+é‡‘èæŒ‡æ ‡(2018)â€æ•°æ®é›†ã€‚](https://www.kaggle.com/cnic92/200-financial-indicators-of-us-stocks-20142018)

è¯¥æ•°æ®é›†åŒ…å« 2018 å¹´ç¾å›½è‚¡å¸‚çš„æ•°æ®ã€‚å®ƒåŒ…å« 200 å¤šä¸ªè´¢åŠ¡æŒ‡æ ‡ï¼Œè¿™äº›æŒ‡æ ‡é€šå¸¸å‡ºç°åœ¨æ¯ä¸ªä¸Šå¸‚å…¬å¸æ¯å¹´å‘å¸ƒçš„ 10-K æ–‡ä»¶ä¸­ï¼Œæ¶‰åŠè¶…è¿‡ 4k åªè‚¡ç¥¨ã€‚æœ€åä¸€åˆ—â€œç±»åˆ«â€åˆ—å‡ºäº†æ¯åªè‚¡ç¥¨çš„äºŒè¿›åˆ¶åˆ†ç±»ã€‚å¦‚æœ class = 1ï¼Œé‚£ä¹ˆè‚¡ç¥¨çš„ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”åœ¨é‚£ä¸€å¹´ä¹‹åä¸Šå‡ï¼›å¦‚æœ class = 0ï¼Œé‚£ä¹ˆè‚¡ç¥¨çš„ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”åœ¨é‚£ä¸€å¹´ä¹‹åä¸‹é™ã€‚è¿™ä¸ªâ€œç±»åˆ«â€æ å¯ä»¥ç”¨æ¥è¡¡é‡è‚¡ç¥¨æ˜¯å¦å€¼å¾—è´­ä¹°ã€‚

# ğŸ•µï¸â€â™€ï¸æ•°æ®å‹˜æ¢å…¬å¸

ä¸ºäº†ç»™æˆ‘çš„æ¨¡å‹é€‰æ‹©æä¾›ä¿¡æ¯ï¼Œæˆ‘å°†é¦–å…ˆç ”ç©¶æˆ‘çš„æ•°æ®ã€‚

## **æ•°æ®é›†æ¦‚è¿°**

```
df.info()
```

![](img/40e4cdbb2a200180a16eca48e16edd47.png)

**å›¾ 1** :æ•°æ®é›†ä¿¡æ¯

## **å…³è”çƒ­å›¾**

```
fig, ax = plt.subplots(figsize=(20,15))
sns.heatmap(df.corr(), annot=False, cmap='YlGnBu', vmin=-1, vmax=1, center=0, ax=ax)
plt.show()
```

![](img/827a21e915d7059e6f72e42fa7651703.png)

**å›¾ 2:** æ˜¾ç¤ºæ•°æ®é›†ä¸­è¦ç´ ä¹‹é—´ç›¸å…³æ€§çš„çƒ­å›¾

**ç›¸å…³è¡¨**

```
corr = df.corr().abs()
s = corr.unstack()
so = s.sort_values(kind="quicksort")
print(so[-4470:-4460])
```

![](img/da3e25de971a941d838473cc59e8361d.png)

**è¡¨ 1:** æ˜¾ç¤ºå…·æœ‰æœ€é«˜ç›¸å…³æ€§çš„ç‰¹å¾å’Œå®ƒä»¬å„è‡ªçš„ç›¸å…³ç³»æ•°çš„è¡¨

## **æ¢ç´¢â€œç±»â€åŠŸèƒ½**

**ç­çº§è®¡æ•°æ å‰§æƒ…**

```
classes = df['Class'].value_counts()
class_len = len(classes)
sns.set_style("darkgrid")
sns.barplot(np.arange(class_len), classes)
plt.title('Class Count', fontsize=18)
plt.show()
```

![](img/bf1d58e77a2b99d2f7fb2ec83570a6b9.png)

**å›¾ 3:** æ˜¾ç¤ºæ•°æ®é›†â€œç±»â€ç‰¹å¾ä¸­çš„å€¼å’Œè¿™äº›å€¼çš„è®¡æ•°çš„æ¡å½¢å›¾

**è®¡ç®—â€œç±»â€ä¸­ç©ºå€¼çš„æ•°é‡**

```
print("Number of null values in 'Class':", df['Class'].isnull().sum())
```

![](img/2525c5a8054dd41b569f89caccb526fc.png)

**å›¾ 4:** æ˜¾ç¤ºäº†â€œç±»â€ç‰¹å¾ä¸­ç©ºå€¼çš„æ•°é‡

è¿™ä¸€æ¢ç´¢æ­ç¤ºäº†ä¸¤ä¸ªä¸»è¦å‘ç°:

1.  å¦‚*å›¾ 1* æ‰€ç¤ºï¼Œè¯¥æ•°æ®é›†å…·æœ‰å¤§é‡çš„ç‰¹å¾(223)å’Œæ¡ç›®(4392)ï¼Œå› æ­¤æˆ‘å°†é€‰æ‹©èƒ½å¤Ÿæ”¯æŒè¯¥æ•°æ®é›†å¤§å°çš„æ¨¡å‹
2.  â€œç±»â€ç‰¹å¾æ˜¯äºŒè¿›åˆ¶çš„ï¼Œå®ƒä¸æ˜¯ 0 å°±æ˜¯ 1 ( *å›¾ 3* )ã€‚å¯¹äºä»»ä½•è¡Œï¼Œå®ƒä¹Ÿä¸ä¼šä¸¢å¤±ï¼Œè¿™æ„å‘³ç€æ¯åªè‚¡ç¥¨éƒ½è¢«èµ‹äºˆ 0 æˆ– 1 å€¼(*å›¾ 4* )ã€‚è¿™è¯å®äº†æˆ‘å¯ä»¥å°†â€œClassâ€ä½œä¸ºç›®æ ‡å˜é‡æ¥ä½¿ç”¨è¿™ä¸ªæ•°æ®é›†çš„åˆ†ç±»æ¨¡å‹ã€‚

åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘å°†é€‰æ‹©ä½¿ç”¨èƒ½å¤Ÿå¤„ç†å¤§å‹æ•°æ®é›†çš„åˆ†ç±»æ¨¡å‹æ¥åˆ†æè¿™ä¸ªæ•°æ®é›†ã€‚

# æ•°æ®æ¸…ç†å’Œå‡†å¤‡ğŸ›

## å°†â€œæ‰‡åŒºâ€åˆ—è½¬æ¢ä¸ºè™šæ‹Ÿå€¼

â€œéƒ¨é—¨â€ç‰¹å¾æè¿°å…¬å¸æ˜¯ä»€ä¹ˆéƒ¨é—¨çš„ä¸€éƒ¨åˆ†ï¼›ä¾‹å¦‚:åŒ»ç–—ä¿å¥ã€ç§‘æŠ€ã€èƒ½æºã€æˆ¿åœ°äº§ç­‰ã€‚ä¸ºäº†èƒ½å¤Ÿåœ¨æˆ‘çš„æ¨¡å‹ä¸­é›†æˆâ€œSectorâ€ç‰¹æ€§ï¼Œæˆ‘å°†æŠŠè¿™ä¸ªåˆ—è½¬æ¢æˆè™šæ‹Ÿå€¼ã€‚

```
dummy = pd.get_dummies(df['Sector'])
dummy.head()
```

ç„¶åï¼Œæˆ‘å¯ä»¥ä»æ•°æ®æ¡†ä¸­åˆ é™¤åŸå§‹çš„â€œæ‰‡åŒºâ€è¦ç´ ï¼Œå¹¶ç”¨æ–°çš„è™šæ‹Ÿå€¼åˆ—æ›¿æ¢å®ƒã€‚

```
df = df.drop('Sector', axis=1)
df1 = pd.concat([dummy, df], axis=1)
```

## **å¤„ç†ç¼ºå¤±å€¼**

è¿™ä¸ªæ•°æ®é›†æœ‰å¤šå°‘ä¸ªç¼ºå¤±å€¼ï¼Ÿ

```
print("Total number of null values:", df1.isnull().sum(axis = 1).sum())
```

![](img/31051fbcef53a61edce2cf3967d4a2b8.png)

æ˜¾ç„¶ï¼Œè¿™ä¸ªæ•°æ®é›†æœ‰éœ€è¦å¤„ç†çš„ç¼ºå¤±å€¼ã€‚ä½†æ˜¯ï¼Œåœ¨æˆ‘è¿™æ ·åšä¹‹å‰ï¼Œæˆ‘æƒ³ä½¿ç”¨çƒ­å›¾æ¥äº†è§£ä¸€ä¸‹è¿™ä¸ªç¼ºå¤±å€¼çš„åˆ†å¸ƒæƒ…å†µã€‚

```
plt.figure(figsize = (40,10))
sns.heatmap(df1.isnull(), yticklabels=False)
```

![](img/6cff1802a1c9874457758df5914eb83d.png)

**å›¾ 5:** æ˜¾ç¤ºæ•°æ®é›†ä¸­æ‰€æœ‰è¦ç´ çš„ç©ºå€¼åˆ†å¸ƒçš„çƒ­å›¾

ä»*å›¾ 5* ä¸­ï¼Œæˆ‘å·²ç»å¯ä»¥çœ‹å‡ºæœ‰ä¸€äº›ç‰¹å¾çš„ç¼ºå¤±å€¼ç™¾åˆ†æ¯”éå¸¸é«˜ã€‚ä¸ºäº†æŸ¥çœ‹ä¸¢å¤±å€¼æœ€å¤šçš„è¦ç´ ä»¥åŠä¸¢å¤±å€¼çš„ç™¾åˆ†æ¯”æ˜¯å¦é«˜åˆ°å€¼å¾—ç§»é™¤è¯¥è¦ç´ ï¼Œæˆ‘å°†å¯¹æ¯ä¸ªè¦ç´ çš„ç©ºå€¼æ±‚å’Œï¼Œå°†è¿™äº›æ•°æ®æ”¾å…¥æ•°æ®æ¡†ä¸­ï¼ŒæŒ‰é™åºå¯¹æ•°æ®æ¡†è¿›è¡Œæ’åºï¼Œå¹¶æ‰“å°å‰ 20 ä¸ªå€¼ã€‚æˆ‘è¿˜å°†æ‰¾åˆ°è¿™äº›ç‰¹å¾çš„ç©ºå€¼çš„ç™¾åˆ†æ¯”ã€‚

```
col_len = df1.shape[0]null_df = df1.isnull().sum().sort_values(ascending=False).head(20)
null_df = null_df.to_frame()
null_df.rename(columns={0:"Null Count"}, inplace=True)
null_df['Percentage Null'] = ((null_df["Null Count"] / col_len)*100)print(null_df)
```

![](img/d920d11a794b14af3f5b0bd34f1bfcac.png)

**è¡¨ 2:** æ•°æ®å¸§ä¸­å…·æœ‰æœ€é«˜ç©ºå€¼è®¡æ•°çš„äºŒåä¸ªç‰¹å¾åŠå…¶å„è‡ªç¼ºå¤±å€¼çš„ç™¾åˆ†æ¯”

åŠŸèƒ½â€œcashConversionCycleâ€å’Œâ€œoperatingCycleâ€çš„ç©ºå€¼ç™¾åˆ†æ¯”éå¸¸é«˜ã€‚å»ºè®®ç§»é™¤ç¼ºå¤±å€¼è¶…è¿‡ 70â€“75%çš„ä»»ä½•è¦ç´ ï¼›ç”±äºè¿™ä¸¤åˆ—æœ‰è¶…è¿‡ 99%çš„ç©ºå€¼ï¼Œå®ƒä»¬å°†è¢«åˆ é™¤ã€‚

```
df1 = df1.drop('cashConversionCycle', axis=1)
df1 = df1.drop('operatingCycle', axis=1)
```

è¿˜å‰©ä¸‹å¤§é‡çš„ç©ºå€¼ï¼›ä½†æ˜¯ï¼Œæˆ‘å·²ç»ç§»é™¤äº†ç¼ºå¤±å€¼ç™¾åˆ†æ¯”å¤§åˆ°å€¼å¾—ç§»é™¤çš„è¦ç´ ã€‚å› ä¸ºåˆ é™¤æ›´å¤šçš„ç‰¹æ€§ä¸æ˜¯æœ€å¥½çš„é€‰æ‹©ï¼Œæ‰€ä»¥æˆ‘å°†ä½¿ç”¨ Scikit-learn KNNImputerï¼Œå®ƒä½¿ç”¨ k-Nearest Neighbors æ–¹æ³•æ¥å¡«å……ä¸¢å¤±çš„å€¼ã€‚

```
imputer = KNNImputer(n_neighbors=2)
df_filled = imputer.fit_transform(df1)
```

ç°åœ¨ï¼Œæ‰€æœ‰ç¼ºå¤±çš„å€¼éƒ½å·²å¡«å……ï¼Œæˆ‘å¯ä»¥å°†æ•°æ®æ”¾å…¥æ¨¡å‹ä¸­ã€‚

# æ¨¡å‹ğŸ“ˆ

```
X = df1.drop('Class',axis=1)
y = df1.loc[:,'Class'].valuesX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
```

åœ¨ç¡®å®šæˆ‘çš„ç›®æ ‡å˜é‡å¹¶å°†æˆ‘çš„æ•°æ®åˆ†æˆè®­ç»ƒå’Œæµ‹è¯•ä¹‹åï¼Œæˆ‘å¯ä»¥å¼€å§‹æ„å»ºæˆ‘çš„æ¨¡å‹ã€‚

## å†³ç­–å›¾è¡¨

**ä½¿ç”¨å†³ç­–æ ‘çš„ç†ç”±:**æˆ‘é€‰æ‹©å†³ç­–æ ‘ä½œä¸ºæˆ‘çš„æ¨¡å‹ä¹‹ä¸€ï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿåœ¨ä¸åŒçš„åˆ†ç±»é˜¶æ®µä½¿ç”¨ä¸åŒçš„ç‰¹å¾å­é›†å’Œå†³ç­–è§„åˆ™ã€‚è™½ç„¶å†³ç­–æ ‘é€šå¸¸å®¹æ˜“è¿‡åº¦æ‹Ÿåˆï¼Œä½†æˆ‘å¸Œæœ›é€šè¿‡ä¿®å‰ªæ¥å‡è½»è¿™ç§æƒ…å†µã€‚

```
dt = DecisionTreeClassifier(criterion='entropy', random_state=0, max_depth=10)
dt.fit(X_train, y_train)
y_pred = dt.predict(X_test)
acc_testing = accuracy_score(y_pred, y_test)print("Accuracy = ",acc_testing)
```

ç»“æœ:**ç²¾åº¦= 0.6641379310344827**

## éšæœºæ£®æ—æ¨¡å‹

**ä½¿ç”¨éšæœºæ£®æ—æ¨¡å‹çš„ç†ç”±:**ä¼—æ‰€å‘¨çŸ¥ï¼Œéšæœºæ£®æ—æ¨¡å‹å¯ä»¥å¾ˆå¥½åœ°å¤„ç†å¤§é‡æ•°æ®ï¼Œè¿™æœ‰åˆ©äºæ­¤åˆ†æï¼Œå› ä¸ºæ•°æ®é›†éå¸¸å¤§ã€‚å®ƒä»¬ä¹Ÿä¸å®¹æ˜“åœ¨åˆ†ç±»ä¸­è¿‡åº¦æ‹Ÿåˆï¼Œå› ä¸ºå®ƒä»¬åªè€ƒè™‘ç‰¹å¾çš„å­é›†ï¼Œå¹¶ä¸”æ¨¡å‹çš„æœ€ç»ˆç»“æœä¾èµ–äºæ‰€æœ‰çš„æ ‘ã€‚

```
from sklearn.metrics import recall_score
from sklearn.ensemble import RandomForestClassifiermodel_rf = RandomForestClassifier(n_estimators=100, random_state=42)model_rf.fit(X_train, y_train)predict_rf = model_rf.predict(X_test)recall_rf = recall_score(y_test, predict_rf, pos_label=1.0)precision_rf = precision_score(y_test, predict_rf, pos_label=1.0)print(' Accuracy = ', precision_rf)
```

ç»“æœ:**ç²¾åº¦= 0.7627551020408163**

## é€»è¾‘å›å½’

**ä½¿ç”¨é€»è¾‘å›å½’çš„ç†ç”±:**æˆ‘é€‰æ‹©äº†é€»è¾‘å›å½’ä½œä¸ºæˆ‘çš„æ¨¡å‹ä¹‹ä¸€ï¼Œå› ä¸ºå®ƒåœ¨åˆ†ç±»æ–¹é¢éå¸¸æœ‰æ•ˆï¼Œè€Œä¸”å®ç°èµ·æ¥éå¸¸ç®€å•ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™ä¸ªæ•°æ®æ¡†æ¶æ¯”é€šå¸¸ç”¨äºé€»è¾‘å›å½’çš„è¦å¤§ï¼Œä½†æ˜¯æˆ‘å¯ä»¥é€šè¿‡å¢åŠ â€œmax_iterâ€æ¥ä½¿æˆ‘çš„æ¨¡å‹é€‚åº”è¿™ä¸ªæƒ…å†µã€‚æˆ‘ä¹Ÿå°†ä½¿ç”¨ L2 æ­£è§„åŒ–ï¼Œä»¥å¸®åŠ©é˜²æ­¢è¿‡åº¦æ‹Ÿåˆã€‚

```
model = LogisticRegression(max_iter=500000000, penalty='l2', solver='liblinear')model.fit(X_train, y_train)y_pred = model.predict(X_test)log_acc = accuracy_score(y_test, y_pred)print('Accuracy =', log_acc)
```

ç»“æœ:**ç²¾åº¦= 0.6793103448275862**

## XGBoost

**ä½¿ç”¨ XGBoost çš„ç†ç”±:**å‡ºäºå„ç§åŸå› ï¼Œæˆ‘é€‰æ‹©äº†ä¸€ä¸ª XGBoost åˆ†ç±»å™¨ä½œä¸ºæˆ‘çš„æ¨¡å‹ä¹‹ä¸€:

*   ä¼—æ‰€å‘¨çŸ¥ï¼Œå®ƒå…·æœ‰å‡ºè‰²çš„é€Ÿåº¦å’Œæ€§èƒ½
*   å®ƒæœ‰å„ç§å„æ ·çš„è°ƒè°å‚æ•°
*   å…¶æ ¸å¿ƒç®—æ³•æ˜¯å¯å¹¶è¡Œçš„
*   åœ¨å¤šç§æœºå™¨å­¦ä¹ åŸºå‡†æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºæ¯”å…¶ä»– ML æ–¹æ³•æ›´å¥½çš„æ€§èƒ½

```
xgb_model = XGBClassifier(objective="binary:logistic", random_state=2020, learning_rate=0.1)xgb_model.fit(X_train, y_train)y_pred = xgb_model.predict(X_test)xgb_acc = accuracy_score(y_test, y_pred)print("Accuracy = ", xgb_acc )
```

ç»“æœ:**ç²¾åº¦= 0.7282758620689656**

## è£…è¢‹åˆ†çº§æœº

**ä½¿ç”¨ Bagging åˆ†ç±»å™¨çš„ç†ç”±:**æˆ‘çš„è®¸å¤šæ¨¡å‹éƒ½ä½¿ç”¨å†³ç­–æ ‘ã€‚ä¸å¹¸çš„æ˜¯ï¼Œå†³ç­–æ ‘å®¹æ˜“è¿‡åº¦æ‹Ÿåˆã€‚æ­¤å¤–ï¼Œå†³ç­–æ ‘é€šå¸¸ä¸ç¨³å®šï¼Œè¿™æ„å‘³ç€å³ä½¿è®­ç»ƒæ•°æ®ä¸­éå¸¸å°çš„å˜åŒ–ä¹Ÿä¼šå¯¼è‡´éå¸¸ä¸åŒçš„å†³ç­–æ ‘æ¨¡å‹ã€‚

ç„¶è€Œï¼Œæ ¹æ®æˆ‘çš„ *ITP 449:æœºå™¨å­¦ä¹ çš„åº”ç”¨*è¯¾å ‚ç¬”è®°:â€œåŸºäºæ ‘çš„ Bagging é›†æˆé€šè¿‡å°†æ¯æ£µæ ‘æ‹Ÿåˆåˆ°è®­ç»ƒæ•°æ®çš„ä¸åŒå¼•å¯¼æ ·æœ¬ä¸Šæ¥åˆ©ç”¨è¿™äº›ç¼ºç‚¹ã€‚ç”±äºå†³ç­–æ ‘çš„ä¸ç¨³å®šæ€§è´¨ï¼Œä½¿æ¯æ£µæ ‘è¿‡åº¦é€‚åº”å…¶ç‰¹å®šçš„è‡ªä¸¾æ ·æœ¬å°†å¯¼è‡´å…·æœ‰ä¸åŒæ ‘é›†åˆçš„é›†åˆã€‚è™½ç„¶æ¯æ£µå•ç‹¬çš„æ ‘éƒ½è¿‡åº¦æ‹Ÿåˆäº†å®ƒç”¨æ¥è®­ç»ƒçš„æ•°æ®ï¼Œä½†ç”±äºè¿™äº›ä¸åŒçš„æ ‘ï¼Œæ•´ä½“çš„æ–¹å·®å‡å°‘äº†ã€‚â€

```
model_bagging = BaggingClassifier(DecisionTreeClassifier(), n_estimators = 10, random_state = 42)model_bagging.fit(X_train, y_train)pred_bagging = model_bagging.predict(X_test)bagging_acc = accuracy_score(y_test, pred_bagging)print(' Accuracy = ', bagging_acc)
```

ç»“æœ:**ç²¾åº¦= 0.6841379310344827**

## æŠ•ç¥¨ç»„åˆ

**ä½¿ç”¨æŠ•ç¥¨é›†æˆçš„ç†ç”±:**æˆ‘é€‰æ‹©æŠ•ç¥¨é›†æˆä½œä¸ºæˆ‘çš„æ¨¡å‹ä¹‹ä¸€ï¼Œå› ä¸ºè¯¥æ¨¡å‹ç»“åˆäº†å¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ï¼Œä»è€Œæœ‰åŠ©äºæé«˜é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

```
rfClf = RandomForestClassifier(max_depth = 10, n_estimators=200, random_state=0)
dtcClf = DecisionTreeClassifier(max_depth = 10)
logClf = LogisticRegression(max_iter=500000000, penalty='l2', solver='liblinear')
xgbClf = XGBClassifier()clf2 = VotingClassifier(estimators = [('rf',rfClf), ('dt',dtcClf), ('xgb',xgbClf), ('log', logClf)], voting='soft')
clf2.fit(X_train, y_train)
clf2_pred = clf2.predict(X_test)recall_voting = recall_score(y_test, clf2_pred, average="binary", pos_label=1.0)precision_voting = precision_score(y_test, clf2_pred, pos_label=1.0)vote_acc = accuracy_score(y_test, clf2_pred)print('Accuracy score', vote_acc)
```

ç»“æœ:**ç²¾åº¦= 0.7151724137931035**

# å‹å·é€‰æ‹©ğŸ“Š

ä¸ºäº†æ¯”è¾ƒæ¯ä¸ªåˆ†ç±»å™¨çš„å‡†ç¡®æ€§å¹¶æ¨æ–­å‡ºæœ€å‡†ç¡®çš„ä¸€ä¸ªï¼Œæˆ‘å°†åœ¨ä¸€ä¸ªå¸¦æ ‡ç­¾çš„æ¡å½¢å›¾ä¸Šç»˜åˆ¶æ¯ä¸ªåˆ†ç±»å™¨çš„å‡†ç¡®æ€§ã€‚

```
plt.style.use('ggplot')data = {'Classifier':  ["DecisionTreeClassifier", "RandomForestClassifier", "Logistic Regression", "XGBoost", "Bagging Classifier", "Voting Ensemble"],'Acc': [acc_testing, precision_rf, log_acc, xgb_acc, bagging_acc, vote_acc ],}for count, el in enumerate(data['Acc']):
   data['Acc'][count] = el * 100acc_data = pd.DataFrame (data, columns = ['Classifier','Acc'])g = sns.barplot(x='Classifier', y='Acc', data=acc_data)
plt.xticks(rotation=45)
plt.ylabel('Accuracy %')
plt.title('Classifier Accuracy')for p in g.patches:
    g.annotate(format(p.get_height(), '.1f'),(p.get_x() +          p.get_width() / 2., p.get_height()),ha = 'center', va = 'center', xytext = (0, 9), textcoords = 'offset points')plt.show()
```

![](img/015f0b9d1bbf73b429786645fc1d2de2.png)

**å›¾ 5:** æ¯ä¸ªåˆ†ç±»å™¨çš„å‡†ç¡®åº¦ç™¾åˆ†æ¯”

éšæœºæ£®æ—åˆ†ç±»å™¨å…·æœ‰æœ€é«˜çš„å‡†ç¡®åº¦% (76.3)ï¼Œå…¶æ¬¡æ˜¯ XGBosst (72.8)å’ŒæŠ•ç¥¨é›†æˆ(71.5)ã€‚ä¸ºäº†ç¡®ä¿éšæœºæ£®æ—åˆ†ç±»å™¨å®é™…ä¸Šæ˜¯æœ€æœ‰å¸Œæœ›çš„æ¨¡å‹ï¼Œè€Œä¸æ˜¯ç®€å•åœ°è¿‡åº¦æ‹Ÿåˆï¼Œæˆ‘å°†å¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œäº¤å‰éªŒè¯ã€‚

**éšæœºæ£®æ—åˆ†ç±»å™¨çš„äº¤å‰éªŒè¯**

```
rfc_cv = RandomForestClassifier(n_estimators=100, random_state=42)scores = cross_val_score(rfc_cv, X_train, y_train, cv=10, scoring = "accuracy")print("Scores:", scores)
print("Mean:", scores.mean())
print("Standard Deviation:", scores.std())rfc_cv_mean = scores.mean()
```

![](img/14a7fbef250bee23659d016cad13d160.png)

**XGBoost åˆ†ç±»å™¨çš„äº¤å‰éªŒè¯**

```
xgb_cv = XGBClassifier(objective="binary:logistic", random_state=2020, learning_rate=0.1)scores = cross_val_score(xgb_cv, X_train, y_train, cv=10, scoring = "accuracy")print("Scores:", scores)
print("Mean:", scores.mean())
print("Standard Deviation:", scores.std())xgb_cv_mean = scores.mean()
```

![](img/7dcc5a3d4ae9defd5ba013ed40729f32.png)

**æŠ•ç¥¨ç»„åˆçš„äº¤å‰éªŒè¯**

```
rfClf = RandomForestClassifier(max_depth = 10, n_estimators=200, random_state=0)
dtcClf = DecisionTreeClassifier(max_depth = 10)
logClf = LogisticRegression(max_iter=500000000, penalty='l2', solver='liblinear')
xgbClf = XGBClassifier()clf2 = VotingClassifier(estimators = [('rf',rfClf), ('dt',dtcClf), ('xgb',xgbClf), ('log', logClf)], voting='soft')vote_cv = XGBClassifier(objective="binary:logistic", random_state=2020, learning_rate=0.1)
scores = cross_val_score(vote_cv, X_train, y_train, cv=10, scoring = "accuracy")print("Scores:", scores)
print("Mean:", scores.mean())
print("Standard Deviation:", scores.std())vote_cv_mean = scores.mean()
```

![](img/eb4a11e773d67ffd0c4331e66662519d.png)

**å„æ¨¡å‹é—´äº¤å‰éªŒè¯åˆ†æ•°çš„æ¯”è¾ƒ**

```
data1 = {'Classifier':  ["RandomForestClassifier","XGBoost", "Voting Ensemble"],'Cross Validation Score': [rfc_cv_mean, xgb_cv_mean, vote_cv_mean],}cv_data = pd.DataFrame (data1, columns = ['Classifier','Cross Validation Score'])cv_data.sort_values(by='Cross Validation Score', ascending=False)
```

![](img/18c2fdce2fc3e7e1c234a5141c184ef5.png)

**è¡¨ 3:** ä»¥é™åºæ˜¾ç¤ºæ¯ä¸ªåˆ†ç±»å™¨çš„äº¤å‰éªŒè¯åˆ†æ•°

æ ¹æ®*è¡¨ 3* ï¼Œéšæœºæ£®æ—åˆ†ç±»å™¨å…·æœ‰æœ€é«˜çš„äº¤å‰éªŒè¯åˆ†æ•°ä»¥åŠæœ€é«˜çš„å‡†ç¡®æ€§ï¼›å› æ­¤ï¼Œæˆ‘å°†é€‰æ‹©å®ƒä½œä¸ºæˆ‘çš„æœ€ç»ˆæ¨¡å‹ã€‚

## æ¨¡å‹å¾®è°ƒ

ä¸ºäº†å¾®è°ƒæˆ‘çš„æ¨¡å‹ï¼Œæˆ‘å°†ä½¿ç”¨ Scikit-learn çš„ GridSearchCV æ¥ä¼˜åŒ–æˆ‘çš„æ¨¡å‹çš„è¶…å‚æ•°ã€‚

```
from sklearn.model_selection import GridSearchCVparam_grid = {'max_depth': [10, None],'n_estimators': [10, 50, 200],'random_state':[0, 42, None]}grid = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 2,n_jobs=-1)grid.fit(X_train, y_train)grid_predictions = grid.predict(X_test)print(classification_report(y_test, grid_predictions))print(grid.best_params_)
```

![](img/a8c81e8cf801a81c541ded578596dc5d.png)

å›¾ 6

Scikit-learn çš„ GridSearchCV æ¨èä»¥ä¸‹è¶…å‚æ•°:

*   max_depth = 10
*   n _ ä¼°è®¡å€¼= 200
*   éšæœºçŠ¶æ€= 0

å› æ­¤ï¼Œæˆ‘å°†ç”¨è¿™äº›è¶…å‚æ•°åˆ›å»ºä¸€ä¸ªæ–°çš„éšæœºæ£®æ—åˆ†ç±»å™¨ã€‚

```
after_cv_rf = RandomForestClassifier(max_depth = 10, n_estimators = 200, random_state = 0)
after_cv_rf.fit(X_train, y_train)
after_cv_predict = model_rf.predict(X_test)
recall_cv = recall_score(y_test, after_cv_predict, pos_label=1.0)
aftercv_precision_rf = precision_score(y_test, after_cv_predict, pos_label=1.0)print('Accuracy = ', aftercv_precision_rf)aftercv_rfc_cv = RandomForestClassifier(max_depth = 10, n_estimators = 200, random_state = 0)
scores = cross_val_score(aftercv_rfc_cv, X_train, y_train, cv=10, scoring = "accuracy")aftercv_cv_mean = scores.mean()print("Mean cross-validation score = ", scores.mean())
```

![](img/8a3b54d424a34ca6c4424662f2af2804.png)

ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬æ•´åˆåœ¨ä¸€èµ·:

```
data2 = {"Before Cross-validation":  [precision_rf,rfc_cv_mean ], "After Cross-validation": [aftercv_precision_rf, aftercv_cv_mean], "Type": ["Accuracy Score", "Mean Cross-validation Score"]}final_df = pd.DataFrame (data2, columns = ["Type", "Before Cross-validation","After Cross-validation"])final_df.set_index("Type")
final_df.head()
```

![](img/3d56619989bf5c217ce844fc87f9d24e.png)

**è¡¨ 4:** å¯¹æ¯”äº¤å‰éªŒè¯å‰åçš„å‡†ç¡®åº¦å¾—åˆ†å’Œå¹³å‡äº¤å‰éªŒè¯å¾—åˆ†

è™½ç„¶æ¨¡å‹çš„å‡†ç¡®æ€§å¾—åˆ†æ²¡æœ‰å¢åŠ ï¼Œä½†å…¶å¹³å‡äº¤å‰éªŒè¯å¾—åˆ†å¢åŠ äº†ï¼Œè¿™æ„å‘³ç€æ¨¡å‹ç”±äºè¶…å‚æ•°ä¼˜åŒ–è€Œå¾—åˆ°äº†æ”¹å–„(*è¡¨ 4* )ã€‚

## ğŸ§™â€â™€ï¸æœ€ç»ˆåˆ¤å†³:

**éšæœºæ£®æ—æ¨¡å‹å…·æœ‰ 76.2%çš„å‡†ç¡®ç‡å’Œ 73.1%çš„äº¤å‰éªŒè¯åˆ†æ•°ï¼Œæ˜¯é¢„æµ‹å“ªäº›è‚¡ç¥¨å€¼å¾—è´­ä¹°çš„æœ€ä½³æœºå™¨å­¦ä¹ æ¨¡å‹**ğŸ‰*(è‡³å°‘å¯¹äºè¿™ä¸ªæ•°æ®é›†)*

# ğŸé¢å¤–æ”¶è·:ä¸€äº›è§è§£

## ç‰¹å¾é‡è¦æ€§

![](img/4b57c0129fc942cac51bdcd89ad1b89e.png)

**å›¾ 7:** æ ¹æ®æˆ‘ä»¬çš„éšæœºæ£®æ—æ¨¡å‹ï¼Œé¢„æµ‹è‚¡ç¥¨â€œç±»åˆ«â€çš„åä¸ªæœ€é‡è¦çš„ç‰¹å¾

æ ¹æ®*å›¾ 7* ï¼Œåœ¨è¯¥æ¨¡å‹ä¸­ï¼Œä»¥ä¸‹ç‰¹å¾åœ¨é¢„æµ‹è‚¡ç¥¨æ˜¯å¦å€¼å¾—å–å‡ºæ—¶æœ€ä¸ºé‡è¦:

1.  **æœ‰å½¢èµ„äº§ä»·å€¼:**â€œæ˜¯å…¬å¸ç»è¥ä¸­ä½¿ç”¨çš„æœ‰å½¢çš„ã€å¯è®¡é‡çš„èµ„äº§ã€‚è´¢äº§ã€å‚æˆ¿å’Œè®¾å¤‡ç­‰èµ„äº§æ˜¯æœ‰å½¢èµ„äº§ã€‚å®ƒä»¬ä¸ºå…¬å¸æä¾›ç”Ÿäº§å•†å“å’ŒæœåŠ¡çš„æ‰‹æ®µï¼Œä»è€Œæ„æˆäº†å…¬å¸ä¸šåŠ¡çš„æ”¯æŸ±ã€‚ç„¶è€Œï¼Œç”±äºæœ‰å½¢èµ„äº§æ˜¯æœ‰å½¢èµ„äº§ï¼Œè‡ªç„¶å‘ç”Ÿçš„äº‹æ•…ä¼šæŸåæœ‰å½¢èµ„äº§ã€‚â€(é€šè¿‡ Investopedia)
2.  **æ”¶ç›Šæ”¶ç›Šç‡:**â€œæŒ‡æœ€è¿‘ 12 ä¸ªæœˆçš„æ¯è‚¡æ”¶ç›Šé™¤ä»¥å½“å‰æ¯è‚¡å¸‚ä»·ã€‚æ”¶ç›Šæ”¶ç›Šç‡(å¸‚ç›ˆç‡çš„å€’æ•°)æ˜¾ç¤ºçš„æ˜¯å…¬å¸æ¯è‚¡æ”¶ç›Šçš„ç™¾åˆ†æ¯”ã€‚â€(é€šè¿‡ Investopedia)
3.  **æ€»èµ„äº§:**â€œä¸ªäººã€å…¬å¸æˆ–å›½å®¶æ‹¥æœ‰æˆ–æ§åˆ¶çš„å…·æœ‰ç»æµä»·å€¼çš„èµ„æºçš„æ€»å’Œï¼Œé¢„æœŸå®ƒå°†æä¾›æœªæ¥çš„åˆ©ç›Šã€‚â€(é€šè¿‡ Investopedia)

## è¡Œä¸šæ´å¯Ÿ

![](img/ce4a2bb6d8ea0706d4aa66a5a5ed0c6b.png)![](img/893841053f8afe23e068f63cef5a7d2c.png)

**å›¾ 8** :ç»Ÿè®¡æ•°æ®é›†ä¸­æ¯ä¸ªæ¿å—çš„è‚¡ç¥¨æ•°é‡ã€‚**å›¾ 9:** æ¯ä¸ªæ‰‡åŒºä¸­â€œ0â€å’Œâ€œ1â€è®¡æ•°çš„å †ç§¯æ¡å½¢å›¾ã€‚

ä»*å›¾ 8 å’Œå›¾ 9* ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ•°æ®é›†ä¸­æœ€å—æ¬¢è¿çš„è¡Œä¸šå¦‚ä¸‹:

1.  é‡‘èæœåŠ¡
2.  å«ç”Ÿä¿å¥
3.  æŠ€æœ¯ã€‚

è€Œæ•°æ®é›†ä¸­æœ€ä¸å—æ¬¢è¿çš„éƒ¨é—¨å¦‚ä¸‹:

1.  é€šä¿¡æœåŠ¡
2.  å…¬ç”¨äº‹ä¸š
3.  æ¶ˆè´¹è€…é˜²å¾¡

![](img/a358b8a21e014b5223d55b7946cfb040.png)

**å›¾ 10:** æ¯ä¸ªæ‰‡åŒºçš„â€œ0â€å’Œâ€œ1â€è®¡æ•°çš„åˆ†ç±»å›¾ã€‚

ä»*å›¾ 10* ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æ¯è‚¡å€¼å¾—è´­ä¹°è‚¡ç¥¨æ¯”ä¾‹æœ€é«˜çš„è¡Œä¸šå¦‚ä¸‹:

1.  é‡‘èæœåŠ¡
2.  æˆ¿åœ°äº§
3.  å·¥ä¸š