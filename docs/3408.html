<html>
<head>
<title>Hyperparameter Tuning using Keras Tuner</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras调谐器进行超参数调谐</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hyperparameter-tuning-using-keras-tuner-72a8cb394d0f?source=collection_archive---------7-----------------------#2021-06-29">https://medium.com/analytics-vidhya/hyperparameter-tuning-using-keras-tuner-72a8cb394d0f?source=collection_archive---------7-----------------------#2021-06-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="bc8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">任何深度学习模型最关键的部分是找到超参数的值，这将产生具有高精度的模型。</p><p id="0d0c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">学习速率、批量大小、层中神经元的数量是模型超参数的一些常见示例。<a class="ae jc" rel="noopener" href="/analytics-vidhya/deep-learning-the-summarized-way-part-1-23e2eee01ddd">查看我的文章</a>了解更多关于超参数的知识，以及模型参数和超参数的区别。</p><h1 id="f446" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">手动调优过程是如何工作的？</h1><p id="178c" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">为了执行超参数调整，您从分配给您的超参数的一些初始值开始(根据经验，您将能够找出一些好的初始值)。一旦分配了粗略的值，您就可以训练您的模型，并根据准确性和损失结果，调整模型超参数。手动重复这个过程，直到发现模型精度很高。</p><h1 id="eb9d" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">那么，我们如何才能使这变得简单呢？</h1><p id="8ab9" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">上述过程非常耗时，坦率地说，有点烦人。这就是“<strong class="ig hi"> <em class="kg"> Keras Tuner </em> </strong>”出现的原因，Keras提供了一个实用程序来自行处理所有这些繁琐的过程。</p><p id="0d6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">调谐器希望用户为每个超参数提供特定的值。假设用户想要实验值为0.1、0.05、0.5的学习率，以及值为16、32、64的第一层中的节点数。所以调优器会创建一个(0.1，16)、(0.1，32)、(0.1，64)、(0.05，16)的组合……然后尝试找到每个组合的模型性能。一旦所有的组合和试验完成，调谐器打印出最佳性能的参数值。Tuner如何创建这种组合是基于我们要求Tuner选择的策略(网格搜索或随机或贝叶斯)。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es kh"><img src="../Images/7a7918f7434aabf2d6256095ec0edaf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UtLOPN6bA3PJz7AlnAb1fQ.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">Tuner如何为不同的超参数创建组合值。圆点代表超参数值的特定组合。左图:网格搜索，右图:随机搜索[图片<a class="ae jc" href="https://fiennyangeln.github.io/papers/docs/hyperparameter-tuning/" rel="noopener ugc nofollow" target="_blank">来源链接</a></figcaption></figure><blockquote class="kx ky kz"><p id="6af3" class="ie if kg ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">作为用户，您只需要为您的超参数定义一组值，并将其提供给Tuner，该实用程序将提供您需要用来获得高精度模型的最佳超参数组合。</p></blockquote><p id="ef06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，该实用程序不会为您创建模型架构，它只会为给定的模型(作为输入)找到最佳的超参数值。另外，请注意，随着调谐器参数的增加，可能的组合也会增加，从而导致调谐时间增加。因此，明智地选择您想要调整的参数。</p></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><h1 id="17da" class="jd je hh bd jf jg lk ji jj jk ll jm jn jo lm jq jr js ln ju jv jw lo jy jz ka bi translated">怎么做到的？</h1><p id="b3c7" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">和我所有的文章一样，我将用Kaggle 上我的笔记本<a class="ae jc" href="https://www.kaggle.com/pdhruv93/fire-detector" rel="noopener ugc nofollow" target="_blank">中的示例代码来解释Tuner实用程序。请检查笔记本以便跟进。</a></p><p id="d814" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第一部分标记了必要的导入，后面是一些全局变量声明。这里一个新的和重要的声明是<em class="kg"> EARLY_STOPPING_PATIENCE </em>，它表示如果经过这么多代之后精度没有提高，Tuner将中断当前的试验并继续下一个试验以节省资源。下一节“使ImageDataGenerator兼容目录”与Tuner无关，它用于使数据集与ImageDataGenerator兼容。我们导入我们的数据集，在下一节中应用增强，所以没有什么新奇的东西。</p><p id="77d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来是我们定义模型架构的主要部分，我称之为第一步。</p></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><h1 id="4aec" class="jd je hh bd jf jg lk ji jj jk ll jm jn jo lm jq jr js ln ju jv jw lo jy jz ka bi translated">步骤1:定义模型架构</h1><p id="0d3c" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们定义了一个定制函数，通过参数化我们想要调整的模型超参数来构建我们的模型架构。构建模型架构的代码与前面的代码基本相同，只是任何超参数(您希望调整的)都被视为一个<em class="kg">调谐器变量。</em></p><p id="d8e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设我们想要调整Conv2D层中的滤波器数量，下面是传统代码的样子:</p><pre class="ki kj kk kl fd lp lq lr ls aw lt bi"><span id="e6f7" class="lu je hh lq b fi lv lw l lx ly">model.add(Conv2D(32 ,(3, 3), padding="same", input_shape=(128, 128, 3)))</span></pre><p id="5f8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，我们已经明确地将该层中的过滤器数量定义为32。使用调谐器，我们可以参数化这个变量。代码将是这样的:</p><pre class="ki kj kk kl fd lp lq lr ls aw lt bi"><span id="47b7" class="lu je hh lq b fi lv lw l lx ly">model.add(Conv2D(tuner.Int("conv1", min_value=32, max_value=96, step=32),(3, 3), padding="same", input_shape=(128, 128, 3)))</span></pre><p id="b6b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们用表情调谐器替换了32。Int("conv1 "，最小值=32，最大值=96，步长=32)。</p><p id="a472" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">conv1是我们用来表示该超参数(该层中滤波器的数量)的变量的名称。我们允许该超参数的值范围是[32，96]和32的步长。</p><p id="c95a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看另一个例子。我们想要调整模型的学习率。这是我们编写传统代码的方式:</p><pre class="ki kj kk kl fd lp lq lr ls aw lt bi"><span id="9cea" class="lu je hh lq b fi lv lw l lx ly">lr = 0.1</span></pre><p id="45b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是我们将调谐器对象用于该变量的方式:</p><pre class="ki kj kk kl fd lp lq lr ls aw lt bi"><span id="d6f1" class="lu je hh lq b fi lv lw l lx ly">lr = tuner.Choice("learning_rate", values=[1e-1, 1e-2, 1e-3])</span></pre><p id="3d8a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这样，我们可以参数化我们的模型超参数并构建模型。然后，这个模型被传递给Tuner对象(下一步),以找到最佳的超参数集。</p></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><h1 id="9965" class="jd je hh bd jf jg lk ji jj jk ll jm jn jo lm jq jr js ln ju jv jw lo jy jz ka bi translated">步骤2:创建调谐器对象</h1><p id="c321" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们创建一个模型对象并传递<em class="kg"> build_model </em>(我们在上面创建的函数)。每次运行深度学习模型时，初始化和更新都是随机的。所以<em class="kg">种子</em>值允许模型有一些恒定的起点。该目录是Tuner用来生成任何临时文件或某些存储的输出目录。</p><pre class="ki kj kk kl fd lp lq lr ls aw lt bi"><span id="7282" class="lu je hh lq b fi lv lw l lx ly">tuner = kt.Hyperband(build_model, objective="val_accuracy", max_epochs=EPOCHS, factor=3, seed=42, directory='./', project_name='my_hyperband_tuner')</span></pre><p id="e046" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里需要注意的是<em class="kg">kt . hyperband。</em>这是我们希望Tuner使用的组合策略。我已经在上面简要描述了组合策略。其他选项有<em class="kg"> kt。卡帕头RandomSearch。Bayesian优化</em>但是我不会在这篇文章中详细讨论这些。</p></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><h1 id="1dfa" class="jd je hh bd jf jg lk ji jj jk ll jm jn jo lm jq jr js ln ju jv jw lo jy jz ka bi translated">第三步:搜索最佳超参数</h1><p id="9095" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">最后也是最有趣的部分是，Tuner实用程序开始搜索超参数的最佳值。这是您开始搜索的方式:</p><pre class="ki kj kk kl fd lp lq lr ls aw lt bi"><span id="40e1" class="lu je hh lq b fi lv lw l lx ly">tuner.search(train_generator, validation_data=test_generator, batch_size=BATCH_SIZE, callbacks=[earlyStopper], epochs=EPOCHS)</span></pre><p id="0556" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果精确度在特定时期后没有增加，则<em class="kg"> earlyStopper </em>回调负责中断当前试验的执行。您可以这样定义回调:</p><pre class="ki kj kk kl fd lp lq lr ls aw lt bi"><span id="cc9b" class="lu je hh lq b fi lv lw l lx ly">earlyStopper = EarlyStopping(monitor="val_loss", patience=EARLY_STOPPING_PATIENCE, restore_best_weights=True)</span></pre><p id="29dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们已经在全局变量中声明了<em class="kg"> EARLY_STOPPING_PATIENCE </em>。</p></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><h1 id="ff40" class="jd je hh bd jf jg lk ji jj jk ll jm jn jo lm jq jr js ln ju jv jw lo jy jz ka bi translated">输出</h1><p id="38e2" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">搜索开始后，调谐器将根据定义的策略创建超参数值的组合。会有多次试验(我找不到一种方法来检查会有多少次试验)。整个过程是自动化的，在这个过程中你不需要做什么，但是完成这个搜索过程需要很多时间，所以耐心地坐着，让它完成。</p><p id="02b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是搜索过程的输出示例:</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kn ko di kp bf kq"><div class="er es lz"><img src="../Images/72668aceaf16fa5a4a45586fadb48c8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_nGQYyMj0Pynj311CTNKLQ.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">搜索过程中的输出示例</figcaption></figure><blockquote class="kx ky kz"><p id="e8c1" class="ie if kg ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">您会注意到，某些超参数的最佳值在所有试验中几乎是相同的。例如，如果您选择尝试0.1、0.01、0.05的学习率，并且您注意到所有尝试的最佳值总是0.1，我建议停止搜索过程并删除学习率的其他值。这是因为其他值(0.01，0.05)在搜索过程中不必要地增加了组合，因此增加了搜索时间。</p></blockquote><p id="3b72" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦搜索过程完成，并且获得了超参数的最优值，您就可以使用这些最终值创建模型，并期望得到一个性能良好的模型。</p></div><div class="ab cl ld le go lf" role="separator"><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li lj"/><span class="lg bw bk lh li"/></div><div class="ha hb hc hd he"><h1 id="000f" class="jd je hh bd jf jg lk ji jj jk ll jm jn jo lm jq jr js ln ju jv jw lo jy jz ka bi translated">最后的话</h1><p id="b734" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">在了解这个工具之前，我一直认为需要有一些更好的方法来寻找最优超参数。感谢来自<a class="ae jc" href="https://www.pyimagesearch.com/" rel="noopener ugc nofollow" target="_blank"> PyImagesearch </a>的Adrian Rosebrock博士，我是从他的文章中知道这个工具的。这个实用程序肯定要花很多时间来寻找最佳值，但是请考虑一下您要消除的试错和手工疲劳。除非你是某种专家，能够在不到10次的试验中找出最佳值(这是非常罕见的)，否则我强烈推荐使用这种方法来节省你的努力。</p></div></div>    
</body>
</html>