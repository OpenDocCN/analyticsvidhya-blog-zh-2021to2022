# 使用 Transformer 增强通话记录文本

> 原文：<https://medium.com/analytics-vidhya/call-transcripts-text-enhancement-using-transformer-27611d4ff9f9?source=collection_archive---------2----------------------->

主要有两种拼写和语法错误。一种情况是单词在字典之外，而在另一种情况下，输入的单词是有效的条目，但与上下文无关。已经探索了许多算法来解决“超出字典”的错误，而仍然需要大量的研究工作来满意地解决“超出上下文”的错误。在这篇文章中，我们将主要关注“脱离上下文”的拼写错误，以及单词列表而不是完整的文本。

# **应用程序**

在开始之前，我想指出下面提到的算法的各种用例，其中涉及到人类对话，例如:

1.  **呼叫中心音频转文本文字记录** —多个行业记录他们的呼叫中心管理人员的对话，以衡量他们客户的满意度，并通过为他们的客户分配适当的资源来提高他们的运营效率
2.  **播客抄本** —播客音频文件被转换成文本以理解对话，从而帮助获得更好的搜索结果，并根据向观众提供的播客建议提取主题
3.  **音频增强** —音频质量可以通过以下方式增强:首先将其转换为文本，然后使用 NLP 算法增强文本，再将这些文本转换回音频文件

在大多数使用案例中，音频文件被转换为文本，以供进一步分析和提取关键信息，如谈话主题和发言者的情绪，帮助组织做出与其产品、销售、收入等相关的决策。

![](img/e4e468f8e06cccf968d7cad0569b37a3.png)

# **内容:**

*   问题陈述和挑战
*   文本准备
*   模型开发和算法
*   结论
*   局限性和前进方向

# **问题陈述&挑战**

一般来说，我们通常会获得句子或段落来增强和删除所有的语法和拼写错误，但如果我们只是获得一个单词列表、它们的置信度得分和时间戳，并且列表中不包含用于分隔句子的分隔符，会怎么样呢？通常的拼写校正算法(基于字典和基于上下文的算法)是否有效？我不这么认为。原因:基于字典的算法会失败，因为它不可能包含全球使用的所有英语单词，而上下文算法会失败，因为从单个单词接收的上下文不够。

> 输入单词列表示例:["ssss "、" hello "、" sir "、" zzzz "、" me "、" name "、" is "、" amanda "、" hi "、" may "、" I "、" know "、" your "、" name "、" and "、" busy "、" nest "、" id "、" please "、" hi "、" amanda "、" my "、" na "、" iz "、" george "、" and "、" my "、" business "、" id "、" is "、" aew231qa"]
> 
> 增强文字:“先生你好，我叫阿曼达。我可以知道你的名字和商业 id 吗？你好，阿曼达，我叫乔治，我的业务 id 是 aew231qa "

那么，我们应该如何处理这类问题呢？

我们需要首先使用单词列表和它们各自的时间戳来构建段落。一旦我们获得了完整的文本，我们需要通过开发一个算法来分离出句子(记住，我们没有分隔符来轻松地分离句子)。在我们能够重建段落之后，下一个任务将是通过使用它们的置信度分数或一些其他算法(例如，单词标记算法)来找出不正确的单词。一旦我们得到这些不正确的单词，我们可以使用上下文模型检索潜在的更正，并根据我们试图解决的问题陈述选择最佳选项。

# **文本准备**

使用单词列表及其时间戳构建段落似乎是一项简单的任务，但当列表来自实时呼叫中心记录时，这就变得具有挑战性。为什么？

1.  由于转录本中引入的背景噪声(例如，“ssss”、“zzzz”)
2.  由于音频质量和网络问题(例如，“我的”变成了“我”，“姓名”变成了“不适用”)。
3.  通常，两个或更多的说话者同时说话，他们所说的话的时间戳变得混乱，并且很难区分出说话者

为了应对这些挑战并成功构建段落，我们遵循以下步骤:

1.  根据时间戳对单词进行排序，并用空格将这些单词连接起来
2.  从新创建的文本中删除随机单词和字符(例如，“ssss”)
3.  放置分隔符(“.”)在扬声器 1 的末尾和扬声器 2 的开头
4.  使用下一句预测查找下一句是否在前一句之后(NSP)
5.  如果当前短语的字数太低，则将该短语与先前的说话者短语组合。例如，

> Words = ["Can "，" you "，" tell "，" your "，" name "，" my "，" name "，" please "，" is "，" George"]
> 
> 扬声器标志= ["扬声器 1 "、"扬声器 1 "、"扬声器 1 "、"扬声器 1 "、"扬声器 1 "、"扬声器 2 "、"扬声器 2 "、"扬声器 1 "、"扬声器 2"]
> 
> 输出单词= ["可以"、"你"、"告诉"、"你的"、"名字"、"请"、"我的"、"名字"、"是"、"乔治"]

一旦我们从单词列表中获得文本，我们就开发了一种基于神经网络的算法来识别语句的正确结尾。例如，

> 输入文本:“您能告诉我您的姓名和地址吗？我叫乔治，来自伦敦
> 
> 输出文本:“您能告诉我您的姓名和地址吗？我的名字是乔治**。**我来自伦敦”

在上面的例子中，模型成功地分离出了句子*、“我叫乔治”和“我来自伦敦”。*请查看下面的链接，其中一个开源库做了同样的事情:

[https://github.com/notAI-tech/deepsegment](https://github.com/notAI-tech/deepsegment)

在我们构建输入文本之后，我们在文本准备部分的最终目标是从输入数据中识别相关的拼写错误的单词。为了实现这一点，我们使用每个单词的置信度得分，并基于置信度得分阈值将单词分类为不正确的。此外，我们还训练了一个 NLP 模型，根据上下文将每个单词标记为正确或不正确。一旦我们识别出所有这些不正确的单词，我们就屏蔽这些单词，以便变压器模型进行预测。

# **模型开发&算法**

![](img/340c70b0d540e531238a7a8c06f8b2d8.png)

你所需要的只是关注。神经信息处理系统进展。2017.

在这一节中，我们在训练样本上使用拥抱人脸库，通过填充蒙版任务对 transformer 模型进行了微调，以便对模型进行特定领域的理解。为了评估，我们提取了每个拼写错误的单词的前 10 个模型预测，并使用语音相似性方法来获得错误单词与其前 10 个模型预测之间的相似性。具有最高平均语音相似度和模型置信度得分的预测被选为正确的单词，并在转录本中被替换为不正确的单词。

![](img/9626ad96d442f0ba1a1cb00d5c45a517.png)

【https://en.wikipedia.org/wiki/Homonym 号

选择语音相似性方法来滤除模型预测的原因是由于在音频到文本呼叫抄本中，大多数拼写错误的单词将是同音字。大多数基于变换器的算法将偏向于训练样本，并且对于新的看不见的样本，仅仅依赖于模型预测和它的置信度分数将不是正确的方法。

查看 finetune 的链接，并在语言建模任务中使用 transformer 模型以及语音相似性:

[](https://huggingface.co/transformers/notebooks.html) [## 🤗变形金刚笔记本

### PyTorch 和 TensorFlow 2.0 的最先进的自然语言处理。变形金刚提供了成千上万的…

huggingface.co](https://huggingface.co/transformers/notebooks.html) [](https://huggingface.co/facebook/bart-large) [## Facebook/Bart-大拥抱脸

### BART 模型预先接受了英语语言培训。本文介绍了 BART:去噪序列到序列…

huggingface.co](https://huggingface.co/facebook/bart-large) [](https://github.com/chrislit/abydos) [## GitHub - chrislit/abydos:用于 Python 的 Abydos NLP/IR 库

### 代码质量贡献 PyPI conda-forge Abydos 是一个语音算法，字符串距离测量和…

github.com](https://github.com/chrislit/abydos) 

# **结论**

上述拼写校正模型完全基于自我监督的学习方法，而不需要任何标记的数据集。想法很简单，当在超过 10 万个包括拼写错误的单词的对话的大数据样本上训练模型时，基于注意力的变压器模型将能够过滤掉噪音，并且应该只学习正确的上下文信息。

# **局限&前进**

上述方法几乎没有缺点，仍然需要解决。这些限制是:

*   该算法将不能校正被分成多个较小单词的单词。例如，如果“transformer”变成了“trans formal”，那么模型将不能将其校正为“transformer”。
*   该算法不能成功地纠正所有专有名词

敬请关注，了解我们在日常工作中使用的不同方法。在 Linkedin 上关注我来互动和分享想法:[https://www.linkedin.com/in/mdsharique0107/](https://www.linkedin.com/in/mdsharique0107/)