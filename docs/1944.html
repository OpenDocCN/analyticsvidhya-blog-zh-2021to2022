<html>
<head>
<title>An overview and Implementation of the methods of ESRGAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ESRGAN方法的概述和实现</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-esrgan-improves-super-resolution-performance-15de91d77ada?source=collection_archive---------4-----------------------#2021-03-28">https://medium.com/analytics-vidhya/how-esrgan-improves-super-resolution-performance-15de91d77ada?source=collection_archive---------4-----------------------#2021-03-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/a1617cd81b6f3f20efd757b9bcf11a2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NlLqF1TmLHChjmT8HLwtig.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">SR与SRGAN的性能比较</figcaption></figure><h1 id="57d3" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">方法概述</h1><p id="03ad" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">我们将总结ESRGAN(增强型超分辨率生成对抗网络)[1]的关键概念以及本文中提出的提高单幅图像超分辨率的感知质量的方法。该文件提出了以下技术:</p><ul class=""><li id="81e0" class="kp kq hh jt b ju kr jy ks kc kt kg ku kk kv ko kw kx ky kz bi translated">根据EDSR[4]的观察结果，使用RRDB(残差密集块中的残差)改进模型架构，无需批量标准化。</li><li id="1802" class="kp kq hh jt b ju la jy lb kc lc kg ld kk le ko kw kx ky kz bi translated">使用RaGAN(相对论性GAN)[3]相对损失，而不是之前用于对抗性损失的交叉熵损失。</li><li id="bdf1" class="kp kq hh jt b ju la jy lb kc lc kg ld kk le ko kw kx ky kz bi translated">通过比较激活前的VGG层，改善SRGAN[2]的感知VGG损失。</li></ul><p id="e5fc" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">ESRGAN的完整实施和培训可以在<a class="ae li" href="https://colab.research.google.com/drive/1rmwJrrHB8L7m1RmSUQhmbfy1iS09gLmO?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="a4f3" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">模型架构</h1><h2 id="9bad" class="lj iu hh bd iv lk ll lm iz ln lo lp jd kc lq lr jh kg ls lt jl kk lu lv jp lw bi translated">RRDB(残余致密岩块中的残余)</h2><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lx"><img src="../Images/1aadd705f4b9d50a2d00f8056752866a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B9RkEu-z7hRkbpEGt_gPxA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">左:斯尔甘残余地块/右:RRDB地块</figcaption></figure><p id="3bdc" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">ESRGAN遵循SRGAN的基线ResNet风格架构，但用RRDB块替换了残差块。RRDB街区受到DenseNet架构的启发，将剩余街区内的所有层直接相互连接起来(见右图)。我们可以通过将前一层输出的级联数组馈送到下一个卷积来实现类似于DenseNet的RRDB模块。下面的代码实现了RRDB块。</p><figure class="ly lz ma mb fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="c118" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">ESRGAN发生器模型与SRGAN发生器完全相同，只是对残差块进行了修改。所以我们可以简单的冻结SRGAN模型实现，只改变残差块。我们还将残差缩放应用于残差块的输出。</p><figure class="ly lz ma mb fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es me"><img src="../Images/f1cce5eea02c21d024a35d67a9d1879d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Nd-txanCqO4LuU2275Vhnw.png"/></div></div></figure><p id="7e45" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">作者引用“在不同的面向PSNR的任务中，包括SR和去模糊，去除BN层已经被证明可以提高性能和降低计算复杂度。”，并因此移除每个残余块中的批量归一化层。这是因为对于每个图像以及测试图像，每个层的统计数据都非常不同。这违背了BN的假设，即训练/测试图像的特征是相似的，因此使用测试集的训练数据的统计。上图显示了添加BN时经常出现的不必要的批量归一化伪像。</p><p id="431c" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">此外，作者试验了几种技术来提高性能，并采用残差缩放和较小的参数初始化。残差缩放是乘法残差缩放是在添加到主模块之前，将范围[0，1]中的参数β乘以残差输出的过程。本文采用β=0.2。</p><h1 id="7c24" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">损失函数的改进</h1><h2 id="5523" class="lj iu hh bd iv lk ll lm iz ln lo lp jd kc lq lr jh kg ls lt jl kk lu lv jp lw bi translated">拉甘相对论损耗</h2><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mf"><img src="../Images/41f8cfaf64cbd0ac07f19e3b758979c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Ag-A0Nu32Iu1NFbnNNLtA.png"/></div></div></figure><p id="3f96" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">相对论损失通过修改鉴别器来预测Xr比Xf更真实的概率，从而测量图像之间的“相对”真实性。作者认为，这种对鉴别器角色的修改“显示出有利于学习更清晰的边缘和更详细的纹理”，但指标(FID/IS)在论文中没有测量。下图比较了结果(第3次和第4次)。我认为这是本文中的一个缺陷，即本文中的感知指数仅在人类意见调查中测量，因此没有被用于调整超参数和模型设置。拉甘损失实现如下。</p><figure class="ly lz ma mb fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mg"><img src="../Images/c04ce92bbf3e0fd9a7c60662ea710e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TSEh4zY9CQyAFLZbSQ1elw.png"/></div></div></figure><h2 id="77dc" class="lj iu hh bd iv lk ll lm iz ln lo lp jd kc lq lr jh kg ls lt jl kk lu lv jp lw bi translated">修正的VGG损失</h2><p id="48e6" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">作者认为，信号大多在激活功能后消失。例如，在vgg 19–54层之后，图像“狒狒”的激活神经元的平均百分比仅为11.17%。因此，作者比较了ReLU激活前的特征，以测量VGG损失。由于ReLU激活函数被嵌入在Conv层内，这种修改的VGG损失是通过手动应用卷积运算并在最终层添加偏置权重来实现的。以下代码将按照本文中的意图对VGG网络进行切片，并且VGG损失被计算为训练期间HR和SR图像的MSE。</p><figure class="ly lz ma mb fd ii"><div class="bz dy l di"><div class="mc md l"/></div></figure><div class="ly lz ma mb fd ab cb"><figure class="mh ii mi mj mk ml mm paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/57ee87ff97dbe2bf1a8a3a2cd5ef4396.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*pMNgaY5WcUrcHgtwFbCV_w.png"/></div></figure><figure class="mh ii mn mj mk ml mm paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/19fcaa3354cb02bff38cb47debb11874.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*4heO1N2dOen8zjcMwxoGWQ.png"/></div></figure></div><p id="bf26" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">这两个模型的结果基本相同，除了由于ReLU激活导致负值消失。正如本文所讨论的，ReLU函数杀死了中间层的很大一部分。</p><h2 id="ac62" class="lj iu hh bd iv lk ll lm iz ln lo lp jd kc lq lr jh kg ls lt jl kk lu lv jp lw bi translated">完全损失</h2><p id="7e00" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">总损失定义为三种损失的总和。每个重量的超参数设置为λ= 5×103，η= 1×102。与SRGAN不同，本文将L1损失与VGG感知损失相加。</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div class="er es mo"><img src="../Images/637ad622e972b1e9632918a3ddf76d27.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/1*V_qcJow5udPEj2UOrMs5_Q.png"/></div></figure><h1 id="0015" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">结论</h1><p id="b247" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">我们回顾了ESRGAN提出的提高超分辨率性能的方法。在感知质量方面，ESRGAN似乎优于所有其他模型，但在实时性能和超参数调整方面，似乎仍有进一步改进的空间。虽然IS/FID不是测量感知图像质量的完美指标，但如果在比较不同模型配置时将这些指标作为辅助信息给出，可能会有所帮助。</p><p id="4d37" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">我们将以更多的ESRGAN输出的例子来结束这篇文章。</p><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mp"><img src="../Images/fb6b1e5834ddfb5cf34ef92d1aa7ecf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m2I30jG-cizYQzQhx3REoA.png"/></div></div></figure><figure class="ly lz ma mb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mq"><img src="../Images/b4a50aea706b9dec8f477922f42ad85c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UjMafMCkNFAgSQFeuKi72Q.png"/></div></div></figure><h1 id="1982" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">参考</h1><p id="28b5" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">[1]王，，等.“Esrgan:增强的超分辨率生成对抗网络”欧洲计算机视觉会议(ECCV)研讨会会议录。2018.</p><p id="e227" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">[2] Ledig，Christian等，“使用生成式对抗网络的照片级单幅图像超分辨率”<em class="mr">IEEE计算机视觉和模式识别会议论文集</em>。2017.</p><p id="8ebc" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">[3]若利科尔-马蒂诺，亚历克西亚。"相对论鉴别器:标准氮化镓中缺失的关键元素."<em class="mr"> arXiv预印本arXiv:1807.00734 </em> (2018)。</p><p id="e40d" class="pw-post-body-paragraph jr js hh jt b ju kr jw jx jy ks ka kb kc lf ke kf kg lg ki kj kk lh km kn ko ha bi translated">[4] Lim，Bee等，“用于单幅图像超分辨率的增强深度残差网络”IEEE计算机视觉和模式识别研讨会会议录。2017.</p></div></div>    
</body>
</html>