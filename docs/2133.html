<html>
<head>
<title>Observations on Extreme Super-Resolution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于极端超分辨率的观察</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/observations-on-extreme-super-resolution-ec016f8d1e57?source=collection_archive---------8-----------------------#2021-04-06">https://medium.com/analytics-vidhya/observations-on-extreme-super-resolution-ec016f8d1e57?source=collection_archive---------8-----------------------#2021-04-06</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="f32a" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="2f97" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">正如我们在本帖的<a class="ae ka" rel="noopener" href="/analytics-vidhya/an-overview-of-ntire-2020-extreme-super-resolution-challenge-c69b4daf41fd">中回顾的NTIRE 2020挑战极限超分辨率，我们有一个非常大的缩放因子(x16)。参与这项挑战的团队提出了各种模型架构和缩放方法。一些团队通过使用SR-fitted模型而不是VGG网络对感知损失进行了微小的修改。</a></p><p id="b9f9" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">不幸的是，问题远未解决。正如我们在下图中看到的，一些方法成功地重建了高分辨率纹理信息，但无法生成具有空间信息的真实结构。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/5edff8938447c8b1cb6e123f4dc384b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*joBEpcW5pUWoSnKf.png"/></div></div></figure><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/226bfdd6f10254aac7435a34ab029f61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QXU86fbraeESN4DX.png"/></div></div></figure><h1 id="1f0e" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">对该方法的意见</h1><p id="4334" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我认为极限心率与经典的x4问题有很大的不同，在x4问题中，我们得到了一些可信的信息，这些信息可以在重建心率图像时参考。我们必须从原始HR图像的0.39%(1/16x16)恢复图像。因此，我认为这个问题更接近于“条件图像生成”,而不是以前的SR方法。</p><p id="7585" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">关注感知质量的先前的SR方法，例如SRGAN、EnchanceNet和ESRGAN，使用混合损失，该混合损失将逐像素损失、感知损失和对抗损失相加。一个问题是，这需要在对抗性损失和内容损失之间进行权衡，因为这些损失根本上彼此不一致。</p><p id="cb3f" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">最近的模型充分执行了这种权衡，并生成了视觉上令人愉悦的超分辨率图像。然而，在极端的SR中，我们必须在权衡过程中处理感知和对抗损失，同时最小化内容损失的影响，以确保SR图像是LR图像的副本。这可能很容易通过调整超参数来实现更好的折衷，或者可能需要对算法和评估度量进行根本性的改变。</p><h1 id="b827" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">渐进式增长？StyleGAN？</h1><p id="1826" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">与此同时，论文“为提高质量、稳定性和变化性而渐进增长gan”中提出的管道似乎适用于极端SR。我们可以将发电机的渐进增长视为对前一阶段输出的超解析。</p><p id="3f67" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">由于已知渐进生长可提高GAN训练的稳定性，因此当对发生器使用更注重GAN的方法时，它也可能有助于预期的不稳定性。</p><p id="27c5" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">我们也可以使用改进的StyleGAN论文中提出的想法。通过向中间层引入像素噪声，网络可以向图像提供随机变化，以减轻来自鉴别器的压力，从而生成新的图像。</p><p id="ba01" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">总的来说，我认为必须引入更注重GAN的方法来提高图像的感知质量，因为像素级内容损失无法为高质量图像生成提供有意义的指导。</p></div></div>    
</body>
</html>