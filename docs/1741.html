<html>
<head>
<title>Fundamentals Of Machine Learning part 2- Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习基础第2部分-线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/fundamentals-of-machine-learning-part-2-linear-regression-b7f87d804028?source=collection_archive---------16-----------------------#2021-03-15">https://medium.com/analytics-vidhya/fundamentals-of-machine-learning-part-2-linear-regression-b7f87d804028?source=collection_archive---------16-----------------------#2021-03-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="f8d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们将从头开始使用sklearn库实现线性回归。如果你还没有看第一篇文章，点击这个链接来获得机器学习的概述:-<a class="ae jc" href="https://akprpa.medium.com/fundamentals-of-machine-learning-part-1-23b7931c67ae" rel="noopener">https://akprpa . medium . com/fundamentals-of-Machine-Learning-part-1-23b 7931 c 67 AE</a></p><p id="9b7b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我们之前提到的，线性回归是一种监督学习算法，用于预测连续值。我们之所以称之为线性，是因为它试图在被称为<strong class="ig hi">【X】</strong>的<strong class="ig hi">自变量</strong>和<strong class="ig hi">因变量</strong><strong class="ig hi">【Y】</strong>之间找到一个线性关系。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/bf0594b1339481758c2ea12ab2370287.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vxCO9nhcksY-Hlqvrz6ovw.jpeg"/></div></div></figure><p id="9bc0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设我们有一个数据集，其中“X”为<strong class="ig hi">“房屋大小”</strong>，而“Y”为<strong class="ig hi">“估计价格”</strong>，那么学习模型将尝试找到一个<strong class="ig hi">“假设”</strong>或者简单地说，X和Y之间的映射。因此，如果我们想要进行新的预测，我们可以将房屋大小输入到假设<strong class="ig hi">“h”</strong>中，并可以获得一个估计价格。对于这个只有一个特征的简单模型，假设<strong class="ig hi">“h”</strong>可以表示为:-</p><h2 id="f783" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated"><strong class="ak"> h(X) = θ0 + θ1*X </strong></h2><p id="fec2" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">由于我们只有一个特征，我们称之为<strong class="ig hi">“一元线性回归”</strong>。但是我们可以有一个以上的特征这些被称为<strong class="ig hi">【多元线性回归】</strong>。例如:-</p><h2 id="9e8a" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">h(X)=θ0 + θ1X1 +θ2X2 +…。+θnXn</h2><h2 id="ca94" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">h(X)=θ0+∑θiXi(I = 1至i=n)</h2><p id="911f" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">当我们进行预测时，我们希望选择“θ”使得<strong class="ig hi"> h(X)≈Y </strong>用于训练示例。</p><h2 id="cd6e" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">成本函数:-</h2><p id="772d" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">我们希望最小化预测值和实际值之间的差异，因此不断更新“参数θ”非常重要，这样我们就可以得到一条拟合线，并获得最佳值，从而最小化预测值和实际值之间的误差。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kp"><img src="../Images/af5bd36b61e07be3780c673ff11a0b6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*zf9FIcCNPcMvxJDmFrWN6Q.jpeg"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">我们的目的是减少这种表达。这里n = #训练数据，y =真实值，pred=预测值。</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ku"><img src="../Images/1fb9456dd211fb0e69bcd5c3ed258ae5.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/1*tGhNGRoAkSEpWgAdNvNmLg.jpeg"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">成本函数J</figcaption></figure><p id="2956" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个表达式称为成本函数(J ),它是预测值和实际值之间的<strong class="ig hi">“平方误差”</strong>。</p><h2 id="aefd" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">梯度下降:-</h2><p id="b625" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">为了降低成本，函数模型使用了一种非常特殊的算法，称为“梯度下降”，其思想非常简单，用零或随机值初始化参数，并迭代地尝试更新这些值并降低成本函数。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kv"><img src="../Images/7f67e3db614a0f77b01b74ecf4e3c068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*rwrpJa9DpH3uZvYN3of0Fg.jpeg"/></div></figure><p id="5015" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> θ - &gt;【参数】</strong></p><p id="5c8a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">选择θ以获得更稳健的预测。</p><p id="1384" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> m- &gt; #训练示例</strong></p><p id="c857" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> X- &gt;“输入”/“功能”</strong></p><p id="9712" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> Y- &gt;【输出】</strong></p><p id="ed27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> n- &gt; #特性</strong></p><p id="8729" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> α - &gt;学习率</strong></p><p id="99cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> Alpha(α) </strong>或<strong class="ig hi">学习率是一个超参数</strong>。我们需要明智地选择它，因为如果我们保持它太小，因为它需要一些时间来收敛，我们不能保持它太大，因为它开始超调。通常<strong class="ig hi"> α=0.01 </strong>或者根据你的型号你可以尝试加倍。</p><p id="629f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它也被称为<strong class="ig hi">“批次梯度下降”</strong>，因为我们一起处理整个批次。如果我们逐个例子地处理梯度下降，我们称之为<strong class="ig hi">“随机梯度下降”</strong>。</p><p id="b35e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">线性回归是一个被称为<strong class="ig hi">广义线性模型(GLM) </strong>的大型模型的特例。通过使用最能描述为训练模型而给出的数据或标签的分布类型，GLMs可用于构建回归和分类问题的模型。</p><h2 id="b114" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated"><strong class="ak">假设:- </strong></h2><p id="1de6" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">以下是线性回归模型对应用该模型的数据集做出的基本假设</p><p id="c076" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 1。线性关系</strong>:-响应和特征变量之间的关系应该是线性的。可以使用散点图测试线性假设。如下所示，第一张图表示线性相关变量，而第二张图和第三张图中的变量很可能是非线性的。因此，第一张图将使用线性回归给出更好的预测。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kw"><img src="../Images/438b0fcc55e7c269af17bb5d22b73556.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f35WRY-ehGDhjAb6vGdHMA.png"/></div></div></figure><p id="cd01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。很少或没有多重共线性</strong>:假设数据中很少或没有多重共线性。当要素(或独立变量)彼此不独立时，会出现多重共线性。</p><p id="a93d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。很少或没有自相关</strong>:另一个假设是数据中很少或没有自相关。当残差不是相互独立的时，就会出现自相关。</p><p id="1b85" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 4。同方差</strong>:同方差描述了一种情况，其中误差项(即自变量和因变量之间关系的“噪声”或随机扰动)在所有自变量的值上都是相同的。如下所示，图1具有同方差性，而图2具有异方差性。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kx"><img src="../Images/77376fa2ab66d99025503ea84091f323.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*gpl3YIuESAb52F7O8mVMyg.png"/></div></figure><h2 id="c2d6" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">实施:-</h2><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ky kz l"/></div></figure><h2 id="deb7" class="jp jq hh bd jr js jt ju jv jw jx jy jz ip ka kb kc it kd ke kf ix kg kh ki kj bi translated">正规方程:-</h2><p id="3575" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated"><strong class="ig hi">正规方程</strong>是一种使用最小二乘成本函数进行线性回归的分析方法。我们可以不用<strong class="ig hi">梯度下降</strong>直接求出θ的值。当处理具有小要素的数据集时，采用这种方法是一种有效且省时的方法。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es la"><img src="../Images/e558d824ef2268f39bc9a38bf279bc13.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/1*w6M0avkhKBzm15aH65ZL-w.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">正规方程</figcaption></figure><p id="123f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用此公式，我们可以一次性获得参数θ，但有一些注意事项，我们只能将它应用于线性回归，它不适用于任何其他算法，并且<strong class="ig hi"> X转置和X </strong>的乘积必须是可逆的，否则它将不起作用。</p></div></div>    
</body>
</html>