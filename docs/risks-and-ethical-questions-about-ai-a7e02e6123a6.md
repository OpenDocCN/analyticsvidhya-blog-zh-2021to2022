# 人工智能的风险和伦理问题

> 原文：<https://medium.com/analytics-vidhya/risks-and-ethical-questions-about-ai-a7e02e6123a6?source=collection_archive---------4----------------------->

![](img/a88879438d21ca0d08b372d76d8472bc.png)

我们生活在一个日益受到人工智能冲击和影响的世界。它的影响是惊人的；无论是艺术一代，诗歌一代，在比赛中击败人类，驾驶汽车等等。

强大的力量也伴随着巨大的风险，我们应该承认，需要对这项技术带来的风险和伦理问题给予适当的关注。在这里，我列出了媒体、政府和学术机构已经开始讨论的一些事情:

**大型语言模型**

机器从人类生成数据和内容中学习。人类有偏见，这也是机器可以学习的。随着大型语言模型成为主流，人们可能担心大规模产生具有人类水平质量的错误信息。由于 LLM 的质量、可能为企业提供的价值以及易用性，LLM 构成了更大的威胁，因此需要关注“应该使用什么样的训练数据”

**虚假内容创作**

![](img/520dcb6d1da3e97c38bddda330f503a6.png)

如果你不能从真实的图像、视频和文本中破译赝品，会发生什么？或者当你没有意识到电话另一端的人是人还是语音模仿机器人时会发生什么？政府已经开始意识到这一威胁，但是学术机构和组织还需要做更多的工作。过去的美国总统竞选是对这一现实的一个警醒

**强大的巨兽**

今天，少数商业驱动的企业掌握着人工智能领域最先进发展的关键。技术本身是他们的关键优势和利润来源。在这些企业中，假设社会公益决策将胜过商业商品决策，这显然令人担忧。以及我们对它的控制结构。

**战争影响**

![](img/05c22e55bbd09f8c7692e80e1738e65f.png)

这已经发生了，最近有消息称伊朗首席核科学家被坐在远处的狙击手用人工智能辅助步枪打死。([https://www . nytimes . com/2021/09/18/world/middle east/Iran-nuclear-fakhrizadeh-assessment-Israel . html](https://www.nytimes.com/2021/09/18/world/middleeast/iran-nuclear-fakhrizadeh-assassination-israel.html))。对于富裕国家和富裕的恐怖组织来说，这种低生命风险的选择会成为主流吗？总的来说，这项技术会被用来做好事吗？还是我们会制造一场更隐蔽的战争！

**可解释的人工智能**

机器做出的任何错误或正确的决定都应该有一个解释，尤其是当这个决定影响到人类的时候。

*   如果贷款被拒绝，模型应该解释原因，就像银行家一样。
*   如果一张人类的照片被归类为猴子，应该有一个解释和可能的修正范围
*   如果一份简历扫描仪只显示了护士的女性特征，而没有男性特征，这应该是“可以解释的”和“可以纠正的”
*   正如《福布斯》所言，“你真的会允许一个人类司机撞你的车，而当你问他们为什么这么做时，他们却没有答案吗？你当然不会。我们也不应该接受机器的这种做法！”

**权力饥渴 AI:**

根据这个[博客](https://www.technologyreview.com/2019/06/06/239031/training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-lifetimes/)，一个大型人工智能模型一生中可以产生相当于五辆汽车的碳足迹。因此，从环境影响的角度来看，它可能与石油相似？这种环境影响目前还不是焦点，但随着许多组织走上这条道路，肯定需要引起注意。

除此之外，还有其他关于的伦理讨论和辩论

*   失业风险
*   机器决策
*   机器创造的财富的分配
*   奇点的概念，和

最后: **AI 终结者！！陪审团出来了**:)