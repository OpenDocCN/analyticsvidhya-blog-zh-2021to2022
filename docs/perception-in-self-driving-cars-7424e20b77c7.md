# 自动驾驶汽车中的感知

> 原文：<https://medium.com/analytics-vidhya/perception-in-self-driving-cars-7424e20b77c7?source=collection_archive---------5----------------------->

自动驾驶汽车的感知无非是汽车如何感知周围的环境。这是最重要和最复杂的事情。对人类来说，感知我们周围的环境是一项非常艰巨的任务，因为我们有眼睛、耳朵等，还有人类的智慧，但对汽车来说，这是最困难和复杂的任务。所以在这篇文章中，我们将看到汽车是如何感知它所行驶的世界的。

![](img/1cc535ce8bb4c355caf21f0a36d09c3e.png)

在我们讨论汽车之前，我们先看看人类是如何感知世界的。我们人类有眼睛来观察环境，我们有耳朵，鼻子，战术传感器，内部传感器可以测量肌肉的偏转通过这些传感器我们可以感知我们周围的环境。通过所有这些传感器，我们可以做多种事情，这是所有可能的大脑。我们的大脑不断处理数据。我们大脑的绝大部分专用于感知，即视觉感知和潜意识，这样我们才能知道自己在世界的哪个位置。当来到汽车时，他们有一些不同的传感器，他们有摄像头而不是眼睛，他们还有一些神奇的传感器，如雷达和激光雷达，可以帮助测量原始距离。所以这些传感器不是知道我面前的东西，而是以厘米为单位告诉我精确的距离。因此，这里涉及的复杂任务是从传感器中获取**大量数据**，并使用计算机智能来评估数据，使其有意义。

![](img/a9aed39090a72893267ae8a8792a912f.png)

**计算机视觉:**计算机视觉技术主要用于观察和理解世界。作为人类，我们可以自动识别物体、图像以及这些物体之间的关系。但是对于计算机来说，图像只是红、绿、蓝颜色值的集合。这些图像的深度是三个堆叠的二维层。

自动驾驶汽车有四个感知世界的核心任务

> **1。探测**-意思是找出物体在环境中的确切位置。
> 
> **2。分类**-表示对象的确切内容。
> 
> **3。跟踪**-观察其他车辆、行人等移动物体
> 
> **4。分割**-将图像中的每个像素与示意图类别进行匹配，例如道路、天空、车辆。

![](img/456d53149b8741d47e5e4db773541046.png)

**什么是机器学习如何在自动驾驶汽车中使用？**

机器学习是计算机科学的一个领域，它使用特殊的算法来训练计算机从数据中学习。这种学习通常存储在一种称为模型的数据结构中。模型有很多种，事实上，模型是一种数据结构，可以理解并预测世界。机器学习在 20 世纪 70 年代之前就已经出现了，但在过去的 20 年里，由于计算机硬件的大量发展，它才出现。例如，医生在医疗诊断中使用 ml 来辅助。

**不同类型的机器学习有**

![](img/52320b51674c888a1afa5cc6ca6dd1e0.png)

**1)监督机器学习:**这些算法使用训练数据集进行学习。他们不断学习，直到达到期望的水平，保证最小的错误。监督最大似然算法可以进一步分为分类、回归和降维算法。

**2)无监督机器学习:**无监督学习相比监督学习，允许用户执行更复杂的处理任务。虽然，与其他自然学习方法相比，无监督学习可能更不可预测。

**3)半监督机器学习**:它是监督学习和非监督学习的结合。它使用少量的标记数据和大量的未标记数据，提供了无监督和有监督学习的优点，同时避免了寻找大量标记数据的挑战。这意味着您可以训练模型来标记数据，而不必使用那么多已标记的训练数据。

**4)强化学习:**强化学习(RL)是机器学习的一个领域，涉及智能代理应该如何在环境中采取行动，以最大化累积奖励的概念。强化学习是与监督学习和非监督学习并列的三种基本机器学习范式之一。

![](img/a17d01d538753c20f69eb18a9f961ff3.png)

自动驾驶汽车机器学习算法一般分为四类:

**1)回归算法**

回归算法明确用于预测事件。贝叶斯回归、神经网络回归和决策树回归是自动驾驶汽车中使用的三种主要回归算法。

在回归分析中，估计两个或多个变量之间的关系，并在不同的尺度上比较变量的影响。回归分析主要依赖于三个核心指标:

*   独立变量的数量
*   因变量的类型
*   回归线的形状。

回归算法使用环境的重复方面来形成特定图像和图像内特定对象的位置之间的关系的统计模型。统计模型可以通过图像采样提供快速的在线检测。渐渐地，它可以扩展到学习其他物体，而不需要大量的人工干预。

**2)模式识别算法(分类)**

通常，高级驾驶辅助系统(ADAS)获得的图像充满了来自周围环境的一系列数据。需要对这些数据进行过滤，以识别包含特定类别对象的相关图像。这就是模式识别算法进入的地方。

也称为数据简化算法，模式识别算法旨在排除不寻常的数据点。在对对象进行分类之前，识别数据集中的模式是一个重要的步骤。

这些算法通过检测物体边缘，并将线段和圆弧拟合到边缘，来帮助过滤通过传感器获得的数据。模式识别算法以许多不同的方式将线段和圆弧结合起来，以形成识别物体的最终特征。

具有梯度方向直方图(HOG)的支持向量机(SVM)、主成分分析(PCA)、贝叶斯决策规则和 k-最近邻(KNN)是自动驾驶汽车中最常用的模式识别算法。

**3)聚类算法**

聚类算法擅长从数据点中发现结构。可能会发生 ADAS 获得的图像不清晰的情况，也可能会发生分类算法未能识别某个对象，从而无法对其进行分类并向系统报告。

这可能是由于图像的分辨率非常低或数据点非常少。在这种情况下，系统很难检测和定位周围的物体。

聚类算法定义了问题的类别和方法的类别。通常，聚类技术是使用基于质心和分层建模方法建立的。所有聚类技术都侧重于利用数据中的固有结构，以最佳方式将数据组织到具有最大共性的组中。

K-means 和多类神经网络是自动驾驶汽车中使用最广泛的两种聚类算法。

**4)决策矩阵算法**

决策矩阵算法主要用于决策制定。它们被设计用于系统地识别、分析和评定价值集和其中的信息之间的关系的性能。自动驾驶汽车中使用最广泛的决策矩阵算法是梯度推进(GDM)和 AdaBoosting。

**自动驾驶汽车中的神经网络:**

汽车中使用的人工神经网络受到组成人类神经系统的生物神经元的启发。我们的生物神经元连接在一起，形成神经元网络或神经网络。以类似的方式，我们可以连接人工神经元层，以创建用于机器学习的神经网络。人工神经网络是一种从数据中学习复杂模式的工具。神经网络由大量神经元组成，就像我们身体神经系统中的神经元一样，人工神经元负责传递和处理信息。这些神经元也是要训练的。我们可以用这些神经元来识别这些图像，无论它们是黑是白，是大是小。我们还可以区分汽车、行人、红绿灯，甚至电线杆。

![](img/fbeb09fd1c5c8909a895ec4b06725bd0.png)

# 雷达和激光雷达

汽车中的激光雷达已经存在多年了。你可以在自适应巡航控制、盲点警告、碰撞警告和防撞系统中找到它们。尽管雷达是一项成熟的技术，但它仍在不断改进，以使其更加强大。其他传感器通过计算两个读数之间的差异来测量速度，而雷达使用一种叫做多普勒效应的东西来直接测量速度。多普勒效应根据物体是远离你还是靠近你来测量雷达波的频率变化。这有点像消防车的警笛会根据消防车是远离你还是靠近你而发出不同的声音。多普勒效应对于传感器融合非常重要，因为它将速度作为一个独立的测量参数，使融合算法收敛得更快。通过生成环境的雷达图，雷达还可以用于定位。因为雷达波会被坚硬的表面反射，所以它们可以在没有直接飞行路线的情况下对物体进行测量。雷达可以看到其他车辆的下方，并发现否则会被遮挡的建筑物和物体。在汽车上的所有传感器中，雷达受雨或雾的影响最小，并且可以有大约 150 度的宽视野，或 200 多米的远距离。与激光雷达和相机相比，雷达的分辨率较低。尤其是垂直方向，分辨率非常有限。较低的分辨率也意味着静态物体的反射会引起问题。例如，街道上的井盖或汽水罐可能具有高雷达反射率，即使它们相对较小。这就是所谓的雷达杂波，这就是为什么目前的汽车雷达通常忽略静态物体。

![](img/ec87c101dcc9d72a333d426b27e3ce89.png)

L iDAR 代表光探测和测距，就像雷达代表无线电探测和测距一样。与使用无线电波的雷达不同，激光雷达使用红外激光束来确定传感器和附近物体之间的距离。目前大多数激光雷达使用 900 纳米波长范围内的光，尽管一些激光雷达使用更长的波长，在雨和雾中表现更好。在目前的激光雷达中，一个旋转的转环扫描激光束穿过视场。激光是脉冲的，脉冲被物体反射。这些反射会返回代表这些对象的点云。激光雷达比雷达具有更高的空间分辨率，因为激光光束更集中，垂直方向上的扫描层数更多，并且每层的激光雷达点密度更高。当代的激光雷达不能直接测量物体的速度。并且必须依靠两次或更多次扫描之间的不同位置。激光雷达也更容易受到天气条件和传感器上灰尘的影响，这需要保持清洁。它们也比其他传感器体积大得多，因此更难集成，除非人们只想在车顶安装一个大扫描仪。

![](img/a00efad994c62227f3947c2cdfd257c4.png)

**相机 vs 激光雷达 vs 雷达**

![](img/bed7769a335380dd741f935bd9bbc16e.png)

通过上面的图像，我们可以说每个传感器都有一些限制，这取决于不同的条件。这就需要对这些传感器的数据进行融合，得到准确的结果。为了融合传感器，我们使用了**卡尔曼滤波算法。**

**卡尔曼滤波算法:**卡尔曼滤波算法是一个两步估计问题。第一步是预测状态，第二步是更新测量值。这是预测和更新步骤的无限循环。

![](img/f4f2d5102aa93e3a6efeac317d06490d.png)

# 体系结构

感知模块的总体架构如下所示:

![](img/8d6062e7989da3d1f59fda2e386e8e24.png)

详细的感知模块如下所示:

![](img/2dc0bdcd6deec238fbce474e0f5e2b6b.png)

> **感知模块输入为**:

*   128 通道激光雷达数据
*   16 通道激光雷达数据
*   雷达数据
*   图像数据
*   雷达传感器校准的外部参数(来自 YAML 文件)
*   前置摄像头校准的外部和内部参数(来自 YAML 文件)
*   主车辆的速度和角速度

> **感知模块输出为:**

*   三维障碍跟踪航向，速度和分类信息。
*   交通灯检测和识别的输出。

> 我认为这篇文章提供了一些关于自动驾驶汽车感知的信息。如果你想要我更多关于自动驾驶汽车的文章，这里有链接

[](https://illuri-sandeep5454.medium.com/localization-in-self-driving-cars-a4260e5fa964) [## 自动驾驶汽车的本地化

### 定位是自动驾驶汽车如何知道自己在世界上的位置。在日常生活中，我们使用手机 GPS 来定位…

illuri-sandeep5454.medium.com](https://illuri-sandeep5454.medium.com/localization-in-self-driving-cars-a4260e5fa964) [](https://illuri-sandeep5454.medium.com/self-driving-cars-intro-6831192cd95d) [## 自动驾驶汽车简介

### 什么是自动驾驶汽车？

illuri-sandeep5454.medium.com](https://illuri-sandeep5454.medium.com/self-driving-cars-intro-6831192cd95d)