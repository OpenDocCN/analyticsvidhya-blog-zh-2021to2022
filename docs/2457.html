<html>
<head>
<title>Image Captioning using Encoder-Attention-Decoder technologies of Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的编码器-注意力-解码器技术的图像字幕</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/image-captioning-using-encoder-attention-decoder-technologies-of-deep-learning-c3443505eb85?source=collection_archive---------8-----------------------#2021-04-25">https://medium.com/analytics-vidhya/image-captioning-using-encoder-attention-decoder-technologies-of-deep-learning-c3443505eb85?source=collection_archive---------8-----------------------#2021-04-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><blockquote class="ie if ig"><p id="98be" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">今天我们将学习如何解决著名的为图像添加字幕的深度学习问题。在讨论解决方案之前，请确保你们对<strong class="ik hi"> <em class="hh">编码器-解码器架构</em> </strong>和什么是<strong class="ik hi">注意有基本的了解。</strong> PS:如果你没有这些方面的知识，随时可以从各种网上资源中一窥端倪。</p></blockquote><p id="d5c6" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">让我们先通过想象我得到的一些最终结果来引起你的兴趣。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es jj"><img src="../Images/6a806600fb0b4b8909a63f447917104b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*YWdNFYEuZoOVQt8wwflv5A.png"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated">预测描述:一只棕色的狗在浅水区<end/></figcaption></figure><p id="6d9c" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">令人惊讶的是，在插入这张图片后，媒体问我关于标题的问题，我只是复制粘贴标题😌我的模型预测的。这里字幕以一个<end>标记结束，这是解码器停止在这个<end>标记后生成文本所必需的。</end></end></p><blockquote class="ie if ig"><p id="84ed" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">我要提出的架构的动机，摘自<a class="ae jv" href="https://arxiv.org/pdf/1502.03044.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ik hi"> <em class="hh">展示、出席、讲述:视觉注意的神经图像字幕生成</em> </strong> </a> <strong class="ik hi"> <em class="hh">。</em> </strong>我将使用<em class="hh">软关注</em>与<em class="hh"> VGG-16编码器</em>和<em class="hh"> GRU (RNN变种)</em>层进行解码。</p></blockquote></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><p id="24f4" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">让我们深入到编码部分；</p><blockquote class="ie if ig"><p id="cabf" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">导入库</p></blockquote><pre class="jk jl jm jn fd kd ke kf kg aw kh bi"><span id="d32e" class="ki kj hh ke b fi kk kl l km kn">!pip install nltk==3.5<br/>from nltk.translate.meteor_score import meteor_score<br/>from nltk.translate.bleu_score import sentence_bleu<br/>import random<br/>from sklearn.model_selection import train_test_split<br/>import datetime<br/>import time<br/>from PIL import Image<br/>import collections<br/>import random<br/>from keras.models import load_model<br/>import os<br/>import cv2<br/>import matplotlib.pyplot as plt<br/>import joblib<br/>import pandas as pd<br/>import tensorflow as tf<br/>from tensorflow import keras<br/>from keras.applications.vgg16 import VGG16<br/>from keras.applications.vgg19 import VGG19<br/>from keras.models import Model<br/>import numpy as np<br/>import nltk<br/>nltk.download('stopwords')<br/>nltk.download('wordnet')<br/>nltk.download('words')<br/>from nltk.corpus import words<br/>from nltk.corpus import stopwords<br/>from nltk.stem.porter import PorterStemmer<br/>from nltk.stem import WordNetLemmatizer<br/>from keras.preprocessing.text import Tokenizer<br/>from keras.preprocessing.sequence import pad_sequences</span></pre><blockquote class="ie if ig"><p id="23c7" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">预处理</p></blockquote><p id="36ee" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">预处理部分完全取决于你所拥有的数据，一般来说对于预处理，要注意以下几个关键点:</p><ol class=""><li id="40fe" class="ko kp hh ik b il im ip iq jg kq jh kr ji ks jf kt ku kv kw bi translated">将您所有的培训、验证和测试数据存储在一个文件夹中。此外，在这个文件夹中，您可以有不同的文件夹用于训练、验证和测试图像。</li><li id="ae4d" class="ko kp hh ik b il kx ip ky jg kz jh la ji lb jf kt ku kv kw bi translated">您必须有训练图像标题。</li><li id="5422" class="ko kp hh ik b il kx ip ky jg kz jh la ji lb jf kt ku kv kw bi translated">预处理之后，必须有一个包含所有图像路径的字典作为键，这些图像的标题作为值。</li></ol><p id="e012" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">注意:如果单个图像有多个标题，请将其存储在具有相应图像路径的列表中。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lc"><img src="../Images/c4e6c5eb1488a25b4deaac23aa312412.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tqkt9BiMIR-uj7XROnINuQ.png"/></div></div><figcaption class="jr js et er es jt ju bd b be z dx translated">字典示例</figcaption></figure><blockquote class="ie if ig"><p id="011c" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">最后，为了方便起见，我还会提供github的链接。</p></blockquote><p id="ce6d" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">经过预处理后，我们必须将数据加载到张量中进行训练。预处理和数据加载是特定的，将数据转换为数据。无论如何，我会在Github repo中提供我的数据文件夹。</p><h1 id="c099" class="lh kj hh bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">编码器-注意-解码器(显示出席告诉)</h1><pre class="jk jl jm jn fd kd ke kf kg aw kh bi"><span id="6cd5" class="ki kj hh ke b fi kk kl l km kn"># Setting hyper-parameters for models</span><span id="ca35" class="ki kj hh ke b fi me kl l km kn">BATCH_SIZE = 64<br/>BUFFER_SIZE = 1000<br/>embedding_dim = 256<br/>units = 512<br/>vocab_size = top_k + 1<br/>num_steps = len(img_name_train) // BATCH_SIZE<br/>features_shape = 2048<br/>attention_features_shape = 49</span></pre><p id="743e" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">现在让我们创建编码器、解码器和注意力的类别。</p><blockquote class="ie if ig"><p id="b01d" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">编码器类别</p></blockquote><pre class="jk jl jm jn fd kd ke kf kg aw kh bi"><span id="c01c" class="ki kj hh ke b fi kk kl l km kn">class CNN_Encoder(tf.keras.Model):</span><span id="302f" class="ki kj hh ke b fi me kl l km kn">   def __init__(self, embedding_dim):<br/>      super(CNN_Encoder, self).__init__()<br/>      self.fc = tf.keras.layers.Dense(embedding_dim)<br/>   <br/>   def call(self, x): <br/>      x = self.fc(x)<br/>      x = tf.nn.relu(x) <br/>      return x</span></pre><blockquote class="ie if ig"><p id="10ff" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">注意类</p></blockquote><pre class="jk jl jm jn fd kd ke kf kg aw kh bi"><span id="f283" class="ki kj hh ke b fi kk kl l km kn">class BahdanauAttention(tf.keras.Model): #Soft Attention<br/>  def __init__(self, units):<br/>    super(BahdanauAttention, self).__init__()<br/>    self.W1 = tf.keras.layers.Dense(units)<br/>    self.W2 = tf.keras.layers.Dense(units)<br/>    self.V = tf.keras.layers.Dense(1)</span><span id="b486" class="ki kj hh ke b fi me kl l km kn">  def call(self, features, hidden):<br/>    hidden_with_time_axis = tf.expand_dims(hidden, 1)</span><span id="d622" class="ki kj hh ke b fi me kl l km kn">    attention_hidden_layer = (tf.nn.tanh(self.W1(features) +         <br/>                              self.W2(hidden_with_time_axis)))</span><span id="20a8" class="ki kj hh ke b fi me kl l km kn">    score = self.V(attention_hidden_layer)<br/>    attention_weights = tf.nn.softmax(score, axis=1)</span><span id="e5c0" class="ki kj hh ke b fi me kl l km kn">    context_vector = attention_weights * features<br/>    context_vector = tf.reduce_sum(context_vector, axis=1)</span><span id="e39e" class="ki kj hh ke b fi me kl l km kn">    return context_vector, attention_weights</span></pre><blockquote class="ie if ig"><p id="cff7" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">解码器类别</p></blockquote><pre class="jk jl jm jn fd kd ke kf kg aw kh bi"><span id="2f85" class="ki kj hh ke b fi kk kl l km kn">class RNN_Decoder(tf.keras.Model):<br/>  def __init__(self, embedding_dim, units, vocab_size):<br/>    super(RNN_Decoder, self).__init__()<br/>    self.units = units<br/>    self.embedding = tf.keras.layers.Embedding(vocab_size,    embedding_dim)<br/>    <br/>    self.gru = tf.keras.layers.GRU(self.units,<br/>                                   return_sequences=True,<br/>                                   return_state=True,                       recurrent_initializer=’glorot_uniform’)<br/>    <br/>    self.fc1 = tf.keras.layers.Dense(self.units)<br/>    self.fc2 = tf.keras.layers.Dense(vocab_size)<br/>    self.attention = BahdanauAttention(self.units)</span><span id="53b7" class="ki kj hh ke b fi me kl l km kn">  def call(self, x, features, hidden):<br/>    context_vector, attention_weights = self.attention(features, hidden)</span><span id="b063" class="ki kj hh ke b fi me kl l km kn">    x = self.embedding(x)<br/>    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)<br/>    output, state = self.gru(x)<br/>    x = self.fc1(output)<br/>    x = tf.reshape(x, (-1, x.shape[2])) <br/>    x = self.fc2(x)</span><span id="d19a" class="ki kj hh ke b fi me kl l km kn">    return x, state, attention_weights</span><span id="fda9" class="ki kj hh ke b fi me kl l km kn">  def reset_state(self, batch_size):<br/>    return tf.zeros((batch_size, self.units))</span></pre><blockquote class="ie if ig"><p id="4efb" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">为了使用所有这些体系结构，我们必须编写一个训练函数来有效地训练模型:</p></blockquote><pre class="jk jl jm jn fd kd ke kf kg aw kh bi"><span id="bc73" class="ki kj hh ke b fi kk kl l km kn"># defining loss function, optimizer, </span><span id="37f6" class="ki kj hh ke b fi me kl l km kn">encoder = CNN_Encoder(embedding_dim)<br/>decoder = RNN_Decoder(embedding_dim, units, vocab_size)</span><span id="639e" class="ki kj hh ke b fi me kl l km kn">optimizer = tf.keras.optimizers.Adam()<br/>loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=’none’)</span><span id="5857" class="ki kj hh ke b fi me kl l km kn">def loss_function(real, pred):</span><span id="9002" class="ki kj hh ke b fi me kl l km kn">  mask = tf.math.logical_not(tf.math.equal(real, 0))<br/>  loss_ = loss_object(real, pred)</span><span id="5567" class="ki kj hh ke b fi me kl l km kn">  mask = tf.cast(mask, dtype=loss_.dtype)<br/>  loss_ *= mask</span><span id="fcd3" class="ki kj hh ke b fi me kl l km kn">  return tf.reduce_mean(loss_)</span></pre><blockquote class="ie if ig"><p id="e3f2" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">培训功能</p></blockquote><pre class="jk jl jm jn fd kd ke kf kg aw kh bi"><span id="185f" class="ki kj hh ke b fi kk kl l km kn">@tf.function<br/>def train_step(img_tensor, target):</span><span id="968f" class="ki kj hh ke b fi me kl l km kn">  loss = 0<br/>  hidden = decoder.reset_state(batch_size=target.shape[0])<br/>  dec_input = tf.expand_dims([tokenizer.word_index[‘&lt;start&gt;’]] * target.shape[0], 1)</span><span id="5c14" class="ki kj hh ke b fi me kl l km kn">  with tf.GradientTape() as tape:</span><span id="983b" class="ki kj hh ke b fi me kl l km kn">    features = encoder(img_tensor)<br/>    for i in range(1, target.shape[1]):</span><span id="c872" class="ki kj hh ke b fi me kl l km kn">      predictions, hidden, _ = decoder(dec_input, features, hidden)<br/>      loss += loss_function(target[:, i], predictions)</span><span id="baf0" class="ki kj hh ke b fi me kl l km kn">      dec_input = tf.expand_dims(target[:, i], 1)</span><span id="bafe" class="ki kj hh ke b fi me kl l km kn">  total_loss = (loss / int(target.shape[1]))</span><span id="8706" class="ki kj hh ke b fi me kl l km kn">  trainable_variables = encoder.trainable_variables +<br/>                        decoder.trainable_variables</span><span id="3490" class="ki kj hh ke b fi me kl l km kn">  gradients = tape.gradient(loss, trainable_variables)</span><span id="5145" class="ki kj hh ke b fi me kl l km kn">  optimizer.apply_gradients(zip(gradients, trainable_variables))</span><span id="963e" class="ki kj hh ke b fi me kl l km kn">  return loss, total_loss</span></pre><blockquote class="ie if ig"><p id="cbbd" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">呼叫列车功能</p></blockquote><pre class="jk jl jm jn fd kd ke kf kg aw kh bi"><span id="61ff" class="ki kj hh ke b fi kk kl l km kn">def train_data(dataset, EPOCHS=10):</span><span id="4a1e" class="ki kj hh ke b fi me kl l km kn">  loss_plot = []<br/>  <br/>  for epoch in range(EPOCHS):<br/>    start_time = time.time()<br/>    total_loss = 0</span><span id="e7f9" class="ki kj hh ke b fi me kl l km kn">    for (batch, (img_tensor, target)) in enumerate(dataset):</span><span id="b423" class="ki kj hh ke b fi me kl l km kn">      batch_loss, t_loss = train_step(img_tensor, target)<br/>      total_loss += t_loss</span><span id="b89b" class="ki kj hh ke b fi me kl l km kn">      if batch % 100 == 0:<br/>        average_batch_loss = batch_loss.numpy()/int(target.shape[1])</span><span id="b789" class="ki kj hh ke b fi me kl l km kn">    loss_plot.append(total_loss / num_steps)<br/>    end_time = time.time()<br/>    print(‘Epoch {0:d}/{1:d}’.format(epoch+1, EPOCHS), “: {0:.3f}sec”.format((end_time — start_time)))<br/>    print(‘===============&gt; train-loss=%.3f’ % (total_loss/num_steps))<br/>  <br/>  return loss_plot</span></pre><p id="93a1" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">对于训练，只需调用train_data()，如下图:</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es mf"><img src="../Images/237d5ae2e262e37a77fa0a1465030018.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*OrFChhyIkfm019S_o0PQjQ.png"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated">呼叫列车功能</figcaption></figure><p id="8334" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">如果你活到现在…..伟大的😎</p><p id="abec" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">您的编码器和解码器模型已经创建，现在我们可以进行一些评估。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es mg"><img src="../Images/44db5a53994845380016650e733ff345.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*hWkAwID3g8r9_M2I6bS9cQ.png"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated">评估功能</figcaption></figure><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es mg"><img src="../Images/f7f54b34c065c4d23dc9127b130ef66a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1256/format:webp/1*2ahtSnMlWicI4e_OzazFug.png"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated">绘制注意力权重</figcaption></figure><p id="d4b8" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">这些函数将在输入图像和标题文本上绘制注意力权重。</p><blockquote class="ie if ig"><p id="2f53" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">上面给出了一个预测字幕的例子，让我们对同一幅图像的注意力权重进行可视化</p></blockquote><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es mh"><img src="../Images/158f92ddf52ead0f54ab4f380aad275d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*2WcbTMvXuOefCY11q25yBA.png"/></div><figcaption class="jr js et er es jt ju bd b be z dx translated">白色方框表示注意力权重。该模型分配给该图像用于预测字幕。</figcaption></figure><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es mi"><img src="../Images/3acfb638776c48b9effb6d6e7f7d821e.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*yLtGgVTky4JgC4ldssA3Ag.png"/></div></figure><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es mj"><img src="../Images/692c9a002acb3fa86d81ba0d9a144277.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q5LX6-6-kGRjGxOIf_wr0Q.png"/></div></div></figure><p id="d93f" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jg iu iv iw jh iy iz ja ji jc jd je jf ha bi translated">就到此为止吧！人们也可以检查BLEU分数或流星，但那是不太感兴趣的，如果你也想学习编码它们，只需关注我的<strong class="ik hi"> <em class="ij"> GitHub回购链接是</em> </strong> <a class="ae jv" href="https://github.com/deepankarkansal/Image-Captioning" rel="noopener ugc nofollow" target="_blank"> <strong class="ik hi"> <em class="ij">这里</em> </strong> </a> <strong class="ik hi"> <em class="ij">。</em>T13】</strong></p><blockquote class="ie if ig"><p id="36fb" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">代码实现:<a class="ae jv" href="https://www.linkedin.com/in/palak-2810-tiwari/" rel="noopener ugc nofollow" target="_blank"> <strong class="ik hi"> <em class="hh">帕拉克提瓦里</em> </strong> </a>，<a class="ae jv" href="https://www.linkedin.com/in/deepankar-kansal-255911152/" rel="noopener ugc nofollow" target="_blank"> <strong class="ik hi"> <em class="hh">迪潘卡尔坎萨尔</em> </strong> </a></p></blockquote><h1 id="5261" class="lh kj hh bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated"><strong class="ak"> <em class="mk">参考文献</em> </strong></h1><ol class=""><li id="84b0" class="ko kp hh ik b il ml ip mm jg mn jh mo ji mp jf kt ku kv kw bi translated"><a class="ae jv" href="https://arxiv.org/pdf/1502.03044.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ik hi"> <em class="ij">展示、出席、讲述:视觉注意的神经图像字幕生成</em> </strong> </a></li><li id="4f04" class="ko kp hh ik b il kx ip ky jg kz jh la ji lb jf kt ku kv kw bi translated"><a class="ae jv" href="https://arxiv.org/pdf/1808.02401.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ik hi"> <em class="ij">用深度神经网络构建编解码器:走向现实</em> </strong> </a></li></ol></div></div>    
</body>
</html>