<html>
<head>
<title>Experiments In Machine Learning To Cope-Up With Overfitting and Underfitting</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中应对过拟合和欠拟合的实验</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-experiments-for-making-model-the-right-fit-21218941c569?source=collection_archive---------23-----------------------#2021-01-12">https://medium.com/analytics-vidhya/machine-learning-experiments-for-making-model-the-right-fit-21218941c569?source=collection_archive---------23-----------------------#2021-01-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/d4325f1616ce94a70e0109bbff5b81a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*9GbCwrXLjkQ_6oLt4e3iXQ.png"/></div></figure><p id="b8f5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">假设您的数据通过使用以下技术之一进行了适当的缩放:标准化，其中缩放值以平均值为中心，具有单位标准偏差。这意味着属性的平均值为零，并且结果分布有一个单位标准偏差。归一化，其中值被移动和重新缩放，使得它们最终的范围在0和1之间，这也称为最小-最大缩放。</p><p id="0eb8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">当该模型以完全相同的方式以最高精度对训练和测试数据进行操作时，它被认为是准确的。性能不佳的原因是机器学习模型中的数据过拟合或欠拟合。</p><blockquote class="jj jk jl"><p id="3fb1" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated"><strong class="in hi">训练时的高方差</strong>表示模型显示“<strong class="in hi">欠拟合</strong>”。<strong class="in hi">模型不偏向训练数据</strong>，因此，不能很好地拟合数据点，从而在训练数据中产生高方差。</p></blockquote><p id="ba70" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">【问】如何处理这个问题？</strong>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【1】如果呢？—增加训练样本的数量(行)</strong></p><p id="d2d4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">否</strong>，如果模型有问题，增加训练数据可能无济于事。这可能再次增加训练误差。_________________________________________________________________</p><p id="e3d5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">【2】如果呢？—向训练数据添加更多特征(列)</strong></p><p id="ef7e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，如果你的模型更加重视训练时已经使用的不相关的特性，增加更多的特性可能会有帮助。已经存在的数据特征信息量不足，因此要么替换它们，要么添加更多相关的特征</p><p id="bbb0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【3】如果呢？—重新清理数据</strong></p><p id="6fd0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，拥有干净的数据将最终提高整体生产力，并为决策提供最高质量的信息。删除错误在某些情况下总是有帮助的，例如当多个源构成单个数据集时。_________________________________________________________________</p><p id="3a5d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">【4】如果呢？—增加算法的能力</strong></p><p id="2422" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，我们可以通过内核化来提高算法或模型的能力，或者我们可以用另一个非常适合训练数据的强大模型来替换一个模型。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【5】如果呢？—异常值分析</strong></p><p id="0f1e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是</strong>，异常值是指数据点的值太高或太低，以至于它们不属于数据集其余部分的一般分布，因此最好进行异常值检测，除非您的模型能够稳健地处理异常值。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【6】如果呢？—应用增压</strong></p><p id="0546" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，增强会增加模型的复杂性，因此有助于减少偏差。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【7】如果呢？—装袋</strong></p><p id="47e2" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">否</strong>，如果我们在测试期间观察到任何高方差，装袋会减少方差，因此这可能没有帮助。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【8】如果呢？—在模型训练前应用测井转换</strong></p><p id="e1f5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">可能是<strong class="in hi">是</strong>，如果我们的数据是高度倾斜的，我们应用“对数变换”使其呈正态分布，这可能会减少训练时的方差，但可能没有帮助。因为有时在对数据执行“对数转换”后，如果将它与未转换的数据进行比较，标准统计测试的结果是不相关的。大多数研究人员不处理偏斜数据，但他们在计算非标准化或非标准化数据中的距离时，会应用独立于分布的新方法，如GEE(广义估计方程)或Malhanobis距离。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【9】如果呢？—应用SMOTE生成更多数据样本</strong></p><p id="7fb7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">可能是<strong class="in hi">是</strong>，正如我们所讨论的，添加更多的数据可能没有帮助，但是如果我们通过添加更多的合成数据点来恢复异常值，使数据无异常值，SMOTE可能会有帮助。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【10】如果呢？—正则化参数的减少</strong></p><p id="7d8b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，如果我们引入更多的正则化，它将增加更多的偏差，这可能导致欠拟合，但正则化参数的减少可能有助于偏差的减少，因此将减少欠拟合。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【11】如果呢？—在神经网络中引入退学者</strong></p><p id="e0ef" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">否</strong>，在欠拟合的情况下，跳过一些概率为P的神经元将无济于事，因为这将降低模型复杂性，并将在训练中引入更多偏差。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【12】如果呢？—增加交叉验证的倍数</strong></p><p id="5a74" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">否</strong>，如果您的模型不合适，并且您在交叉验证中应用了更多的折叠，那么它可能没有帮助，因为它只会在训练模型时增加数据点，而不会增加模型的特征数量或能力。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【13】如果呢？—我们训练模型的时间更长</strong></p><p id="ad54" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">可能是<strong class="in hi">是的</strong>，因为欠拟合意味着模型复杂度更低，训练时间更长有助于学习更复杂的模式。在深度学习方面尤其如此。_________________________________________________________________</p></div><div class="ab cl jq jr go js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="ha hb hc hd he"><blockquote class="jj jk jl"><p id="4534" class="il im jm in b io ip iq ir is it iu iv jn ix iy iz jo jb jc jd jp jf jg jh ji ha bi translated"><strong class="in hi">测试</strong>新数据点时的高方差表示模型显示“<strong class="in hi">过度拟合</strong>”为训练数据的<strong class="in hi">低方差，但测试时的高方差。该模型偏向于训练数据，因此不能很好地拟合数据点，从而在测试数据中产生高方差。</strong></p></blockquote><p id="762e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">【问】如何处理这个问题？</strong>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【1】如果呢？—增加训练样本的数量</strong></p><p id="8849" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，有可能我们的模型是根据有限的数据训练的，因此显示过度拟合。增加模式训练样本将是有帮助的。在大多数情况下，<strong class="in hi">数据越多通常越好</strong>。<strong class="in hi">过度拟合</strong>本质上是学习出现在你的训练数据中的虚假相关性，而不是在现实世界中。增加数据集的大小应该会减少这些虚假的相关性，并提高学习者的表现。增加更多的例子可以增加多样性。它减少了泛化误差，因为你的模型通过更多的例子训练变得更加通用。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【2】如果呢？—向训练数据添加更多特征</strong></p><p id="2192" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">否</strong>，模型过度拟合意味着它没有很好地理解训练数据。我们必须减少特征的数量以减少过度拟合。我们可以使用不同的特征选择方法来找出哪些特征实际上与模型相关。同样，在移除多重共线性后减少一些要素也会有所帮助。添加更多的输入要素或列可能会增加过度拟合，因为更多的要素可能是不相关的或多余的，并且有更多的机会使模型变得复杂以适应手头的示例。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【3】如果呢？—重新清理数据</strong></p><p id="242e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，重新清理数据是一个很好的选择，过拟合的一个原因也可能是数据不纯造成的。如果出现过拟合，我们需要清理数据。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【4】如果呢？—增加算法的能力</strong></p><p id="1857" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">不</strong>，有可能模型变得更加复杂，很好地处理训练数据，却不能很好地处理测试数据。因此，我们必须降低模型复杂性，而不是增加模型复杂性_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">[5]如果...会怎样？—异常值分析</strong></p><p id="869d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，这是一个主观性很强的问题，要看用什么模型。如果你使用线性回归，离群值肯定会影响你的回归线。如果你用的是KNN，那也一样。SVM更好地处理异常值。因此，主动规范化您的数据始终是一个很好的做法。在大多数情况下，这将避免您由于离群值的存在而过度拟合您的模型。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【6】如果呢？—降低模型复杂性</strong></p><p id="dead" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是</strong>，降低模型的容量会降低模型过度拟合训练数据集的可能性，达到不再过度拟合的程度。一个神经网络模型的能力，它的复杂性，是由它的节点和层的结构以及它的权重的参数决定的。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【7】如果呢？—增压</strong></p><p id="8cbc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">否</strong>，增强会增加模型的复杂性，因此无助于减少过拟合。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【8】如果呢？—装袋</strong></p><p id="014b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，装袋减少了方差，因此可能会增加偏差以减少过度拟合。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【9】如果呢？—应用SMOTE生成更多数据样本</strong></p><p id="e413" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">可能是<strong class="in hi">是</strong>，正如我们所讨论的，添加更多的数据可能没有帮助，但是如果我们通过添加更多的合成数据点来恢复异常值，使数据无异常值，SMOTE可能会有帮助。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【10】如果呢？—正则化参数的减少</strong></p><p id="48fd" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">否</strong>，我们必须增加正则化参数以增加一点偏差并减少过拟合。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【11】如果呢？—在神经网络中引入辍学</strong></p><p id="76b5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是</strong>，在过拟合的情况下，跳过一些概率为P的神经元将有助于降低模型复杂度，并将在训练中引入更多偏差。有时减少过度拟合可能是有帮助的。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【12】如果呢？—增加交叉验证的倍数</strong></p><p id="908d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，如果你的模型过度拟合，我们在交叉验证中应用了更多的折叠，那么这将是有帮助的，因为这将增加训练模型时的数据点。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【13】如果呢？—减少多重共线性</strong></p><p id="a367" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的</strong>，与<strong class="in hi">高度多重共线性</strong>相关的另一个问题是，输入数据的微小变化<strong class="in hi">会导致模型的</strong>较大变化，甚至导致参数估计符号的变化。这种数据冗余的主要危险是在回归分析模型中<strong class="in hi">过度拟合</strong>。因此，降低多重共线性会有所帮助。_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<strong class="in hi">【14】如果呢？—使用软边界分类器</strong></p><p id="843b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">是的，</strong>使用<a class="ae jx" href="https://towardsdatascience.com/support-vector-machines-soft-margin-formulation-and-kernel-trick-4c9729dc8efe#:~:text=This%20idea%20is%20based%20on,modifying%20the%20objective%20of%20SVM." rel="noopener" target="_blank">软边距分类器</a>而不是SVM <strong class="in hi"> </strong>允许SVM犯一定数量的错误，并保持尽可能宽的边距，以便其他点仍然可以被正确分类。_________________________________________________________________</p></div><div class="ab cl jq jr go js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="ha hb hc hd he"><p id="1742" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">【问】ROC</strong><a class="ae jx" href="https://www.youtube.com/watch?v=4jRBRDbJemM" rel="noopener ugc nofollow" target="_blank"><strong class="in hi"/></a><strong class="in hi"/>(受试者工作特性曲线)<strong class="in hi"/><a class="ae jx" href="https://www.youtube.com/watch?v=4jRBRDbJemM" rel="noopener ugc nofollow" target="_blank"><strong class="in hi">AUC</strong></a><strong class="in hi"/>【曲线下面积】<strong class="in hi">与欠拟合和过拟合有什么关系？</strong></p><p id="820e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">除非您对最佳分类器的效率有所了解，否则仅训练集上的最终模型的ROC曲线(或AUC)不会提供任何信息。根据定义，训练集不能用于测试过拟合/欠拟合，因为它不能计算模型的泛化效率。但是，比较训练集和验证集的ROC曲线会有所帮助。当差异很大时，训练和验证指标之间的差距大小是过度拟合的指示，当没有差距时则显示拟合不足。任何介于两者之间的东西都是可以解释的，但是一个好的模型应该会产生一个小的差距。</p><p id="75ff" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">ROC曲线应通过计算曲线之间的区域来确定，以确定训练和验证之间的距离。请记住，AUC差异并不衡量相同的金额。<br/>在学习过程中，跟踪ROC曲线和差距将提供额外的数据，因为您可以看到差距大小的进展。</p><p id="4caf" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">比方说，<strong class="in hi">测试=验证集</strong></p><p id="0a4d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> [1]如果——AUC(测试)&lt; AUC(训练)</strong></p><ul class=""><li id="3f9e" class="jy jz hh in b io ip is it iw ka ja kb je kc ji kd ke kf kg bi translated">模型仅为训练数据学习，因此显示过度拟合</li><li id="373c" class="jy jz hh in b io kh is ki iw kj ja kk je kl ji kd ke kf kg bi translated">高测试方差</li><li id="9f98" class="jy jz hh in b io kh is ki iw kj ja kk je kl ji kd ke kf kg bi translated">添加比培训特征更多的培训数据</li><li id="07b2" class="jy jz hh in b io kh is ki iw kj ja kk je kl ji kd ke kf kg bi translated">将交叉验证的折叠次数从n次增加到n+k次，这样更多的数据将进入训练部分</li></ul><p id="6c2d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">【2】如果呢？—如果AUC(测试)&gt; AUC(训练)</strong></p><ul class=""><li id="9f1f" class="jy jz hh in b io ip is it iw ka ja kb je kc ji kd ke kf kg bi translated">添加比培训数据更多的培训功能</li><li id="49b2" class="jy jz hh in b io kh is ki iw kj ja kk je kl ji kd ke kf kg bi translated">把更多的功能，因为有一些信息泄漏的可能性。</li></ul><p id="8743" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">很多款都是错的，但是简单款<em class="jm">更错</em>！没错，奥卡姆是科学界最被滥用的剃刀。除非你把你的模型正则化，否则你会过度拟合你的模型。正则化可以防止模型参数变化过快，因此它们不太愿意匹配数据特性，而更容易专注于其中持久的结构。在线性模型中，它的工作原理是众所周知的，但在神经网络中却鲜为人知。但所有的直觉都是一样的:通过使模型足够灵活以捕捉和规范复杂的结构，让数据自己说话！</p></div></div>    
</body>
</html>