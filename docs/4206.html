<html>
<head>
<title>Effects of Image Augmentation on Model performance</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">图像增强对模型性能的影响</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/effects-of-image-augmentation-on-model-performance-3f8effbf54e5?source=collection_archive---------4-----------------------#2021-09-08">https://medium.com/analytics-vidhya/effects-of-image-augmentation-on-model-performance-3f8effbf54e5?source=collection_archive---------4-----------------------#2021-09-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/212313eb68159a405fb2f5d0d44a454a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9osAJWRJ-9gQNJYzipCclQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1723677%2F5042f32b75cd19ad71d5a35c5587ae79%2FScreen%20Shot%202020-02-24%20at%2011.32.02%20AM.png?generation=1582572736200811&amp;alt=media" rel="noopener ugc nofollow" target="_blank">https://www.googleapis.com</a></figcaption></figure><p id="b4eb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这篇博客是<strong class="ix hj">关于形象提升的2部分博客系列</strong>的<strong class="ix hj">B部分</strong>。它分为:-</p><p id="a925" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">部分A :介绍图像增强，各种增强技术，以及通过可用库的实现。</p><p id="809c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">B部分</strong>:建立并训练PyTorch模型，分析使用图像增强对性能的影响。</p><h1 id="51db" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">介绍</h1><p id="ff17" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">最近，深度学习在机器学习(ML)和深度神经网络(DNN)领域发展迅速。卷积神经网络(CNN)主要用于图像分析和分类目的。尽管取得了巨大的成就和前景，深度神经网络和伴随的学习算法仍有一些缺点和挑战需要解决。</p><p id="cd0b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这些网络严重依赖于大型数据集来提供良好的结果，并在真实世界的一般环境中工作(在野外)。不幸的是，在许多应用中，访问大数据是困难的，例如医学图像分析等。因此我们需要像图像增强这样的技术。</p><p id="3ae5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">图像增强可以描述为生成新图像来训练我们的深度学习模型的过程。这些新图像是使用已经可用的数据集创建的，因此我们不必手动收集它们。这是在假设可以通过增强技术从原始数据集中提取更多特征的情况下完成的。</p><h1 id="43fe" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">构建PyTorch模型</h1><p id="7810" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">我们将在PyTorch中训练一个简单的图像分类模型(如果你是新手，请参考<a class="ae iu" rel="noopener" href="/swlh/image-classification-tutorials-in-pytorch-transfer-learning-19ebc329e200">和</a>),以比较添加多种图像增强技术后的结果。为了保持简单和快速，我们使用了Resnet 18模型。我们将使用包含20个花卉类别的<a class="ae iu" href="https://www.kaggle.com/c/flower-classification-with-tpus/" rel="noopener ugc nofollow" target="_blank">数据集</a>，下面附上一些样本:</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es kw"><img src="../Images/32f52a41ae89e9ad810fa05f6d203ddf.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*xvIUPOKtP7j0gpDBI6iC9A.png"/></div></figure><p id="8555" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了显示图像增强对模型的影响，我们将使用不同的图像增强技术多次训练相同的模型，并将比较每个模型的测试精度。我们将训练4个不同的模型，1个没有增强，3个模型有不同的图像增强技术。</p><p id="479a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还附加了代码来训练模型，您可以使用它来复制结果。如果您已经习惯于在pytorch中训练图像分类模型，可以跳过阅读这些代码片段。</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h2 id="f52f" class="ld ju hi bd jv le lf lg jz lh li lj kd jg lk ll kh jk lm ln kl jo lo lp kp lq bi translated">加载数据</h2><p id="0b2a" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">这里您将使用<code class="du lr ls lt lu b">torchvision</code>来加载数据。数据应该放在笔记本旁边，否则，你可以在这里下载。数据集分为三个部分，即培训、验证和测试。</p><p id="1533" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">预训练的网络(Resnet18)在ImageNet数据集上训练，其中每个颜色通道被单独标准化。对于所有三个集合，我们需要将图像的平均值和标准偏差标准化为网络训练的内容。对于平均值，它是<code class="du lr ls lt lu b">[0.485, 0.456, 0.406]</code>，对于标准偏差，它是从ImageNet图像中推断出来的<code class="du lr ls lt lu b">[0.229, 0.224, 0.]</code>。这将确保每个颜色通道以0为中心，范围从-1到1。</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h2 id="ed30" class="ld ju hi bd jv le lf lg jz lh li lj kd jg lk ll kh jk lm ln kl jo lo lp kp lq bi translated">标签映射</h2><p id="8a67" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">我们还需要使用文件<code class="du lr ls lt lu b">flower_to_name.json</code>加载从类别标签到类别名称的映射。这是一个JSON对象，我们可以用<code class="du lr ls lt lu b"><a class="ae iu" href="https://docs.python.org/2/library/json.html" rel="noopener ugc nofollow" target="_blank">json</a></code> <a class="ae iu" href="https://docs.python.org/2/library/json.html" rel="noopener ugc nofollow" target="_blank"> </a>模块读取。这将给我们一个字典映射，整数编码的类别到花的实际名称。</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h2 id="9cad" class="ld ju hi bd jv le lf lg jz lh li lj kd jg lk ll kh jk lm ln kl jo lo lp kp lq bi translated">构建和训练分类器</h2><p id="2238" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">既然数据已经为训练做好了准备，就该构建和训练分类器了。像往常一样，你应该使用一个预先训练好的模型<code class="du lr ls lt lu b">torchvision.models</code>来获取图像特征。使用先前获得的那些特征来构建和训练新的前馈分类器。</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="cd33" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用线性输出20和softmax函数(与要分类的类别数相同)构建自定义分类器</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="cf93" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">定义测量验证损失和准确度的函数。</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="2f45" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">根据验证数据训练和测试我们的模型，以检查它的执行情况。</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h2 id="3fc6" class="ld ju hi bd jv le lf lg jz lh li lj kd jg lk ll kh jk lm ln kl jo lo lp kp lq bi translated">测试您的网络</h2><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><h1 id="4964" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">使用图像增强</h1><p id="c616" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">现在应用图像增强，我们必须编辑我们的转换对象。我们将创建一个应用各种增强(如随机旋转，颜色抖动，水平翻转等)的合成变换。</p><blockquote class="lv lw lx"><p id="fe01" class="iv iw ly ix b iy iz ja jb jc jd je jf lz jh ji jj ma jl jm jn mb jp jq jr js hb bi translated">关于各种图像增强技术，请参考本博客的第一部分。</p></blockquote><p id="e7b2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将在3个单独的集合中应用图像增强，并将比较结果，这些集合可以在下面看到。所有3个集合都具有随机调整大小的裁剪、ToTensor和Normalize common，它们不完全是增强技术，因为我们应该将相同维度的图像馈送到我们的神经网络，我们应该调整图像的大小或获取特定维度的裁剪，Normalize函数用于将图像在-1到1之间进行归一化，并将PIL图像张量转换为torch张量。所有这些步骤都是必要的。</p><p id="0493" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">类型I增强:</strong>首先，我们向训练集添加随机水平翻转变换，然后将其提供给模型并训练模型。</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="0a3d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第二类增强:</strong>然后我们继续给当前的变换对象添加一个系数为(p=0.5)的随机旋转。</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="84c8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">第三类增强:</strong>对于模型中的最后一个变化，使用颜色抖动增强技术向数据集添加一个变换。</p><figure class="kx ky kz la fd ij"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="1191" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如上所述进行修改后，分别运行整个代码，再次训练Resent18模型。</p><h1 id="ec6d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">结果</h1><p id="2c23" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">现在的主要目标是观察是否有任何差异发生由于图像增强。比较我们在上面构建和训练的所有模型的性能。</p><p id="ed27" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下面我们可以通过图来直观地看到结果。</p><p id="14f0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">第一个图描绘了每个时期所有模型的验证准确性。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/9fdc72dac9d567d02e64555ae4a6b591.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*kGjEwN4kOE4fl5bo5BApww.png"/></div></figure><p id="b829" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">下图显示了每个模型的测试精度，这是判断一个模型的主要标准。</p><figure class="kx ky kz la fd ij er es paragraph-image"><div class="er es md"><img src="../Images/8576b8e6c02e0a9bffd97b082af91f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*vQpFDbQSwR8euy0CS82fKA.png"/></div></figure><p id="262c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以清楚地得出结论，通过对我们的Pytorch图像分类模型实施图像增强，提高了准确性，这是使用增强技术的主要优点，这也减少了过拟合，使得模型对真实世界场景更鲁棒。</p><h1 id="3a5a" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">选择合适的增强技术的基本准则</h1><p id="a81e" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">选择应用图像增强技术可能是一项具有挑战性和忙乱的任务。增强技术完全取决于我们使用的数据集，应用图像增强技术背后的主要思想是调整图像，并确保调整后的图像看起来仍然是测试场景中可能出现的东西。例如，我们不能在本博客中使用的数据集上应用垂直翻转，但是垂直翻转可以用于卫星图像，其中翻转图像不会使图像变得虚假。此外，由于所有增强技术都是按顺序应用的，有时当所有增强技术一起应用时，它们的组合效果会产生人工图像，因此在开始训练之前，您应该尝试可视化少数应用了所有增强技术的样本。</p><p id="6aa8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">还有一件事要记住，当应用空间增强时，如果你正在处理对象检测、语义分割等问题，你也应该改变标签。在图像分类的情况下，由于标签只是图像上的一个标签，它不会影响标签，但在对象检测的情况下，我们需要根据我们应用的空间增强技术来改变框。如果我们水平翻转图像，我们也需要翻转盒子。</p><h1 id="e97d" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">摘要</h1><p id="bf5a" class="pw-post-body-paragraph iv iw hi ix b iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo kv jq jr js hb bi translated">这就是当我们缺乏训练数据时，我们如何使用图像增强技术。</p><ol class=""><li id="f4c3" class="me mf hi ix b iy iz jc jd jg mg jk mh jo mi js mj mk ml mm bi translated">我们学习了如何旋转、移动、改变颜色模式和翻转图像。我们学习并讨论了选择合适的增强技术的基本准则，以及这些技术的实际应用。</li><li id="11d3" class="me mf hi ix b iy mn jc mo jg mp jk mq jo mr js mj mk ml mm bi translated">使用图像增强，我们可以提高我们的模型效率，即使训练数据集更少或更差。</li></ol><blockquote class="lv lw lx"><p id="356e" class="iv iw ly ix b iy iz ja jb jc jd je jf lz jh ji jj ma jl jm jn mb jp jq jr js hb bi translated">感谢你的贡献。</p></blockquote><h1 id="b6d8" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">参考</h1><ol class=""><li id="a687" class="me mf hi ix b iy kr jc ks jg ms jk mt jo mu js mj mk ml mm bi translated">https://pytorch.org/docs/stable/index.html<a class="ae iu" href="https://pytorch.org/docs/stable/index.html" rel="noopener ugc nofollow" target="_blank"/></li><li id="ba64" class="me mf hi ix b iy mn jc mo jg mp jk mq jo mr js mj mk ml mm bi translated">【http://cs231n.stanford.edu/reports/2017/pdfs/300.pdf T4】</li><li id="3091" class="me mf hi ix b iy mn jc mo jg mp jk mq jo mr js mj mk ml mm bi translated"><a class="ae iu" href="https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2019/12/image-augmentation-deep-learning-py torch/</a></li><li id="338c" class="me mf hi ix b iy mn jc mo jg mp jk mq jo mr js mj mk ml mm bi translated"><a class="ae iu" href="https://www.kaggle.com/c/flower-classification-with-tpus/" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/flower-classification-with-tpus/</a></li><li id="f1ef" class="me mf hi ix b iy mn jc mo jg mp jk mq jo mr js mj mk ml mm bi translated"><a class="ae iu" href="https://github.com/LeanManager/PyTorch_Image_Classifier" rel="noopener ugc nofollow" target="_blank">https://github.com/LeanManager/PyTorch_Image_Classifier</a></li></ol></div></div>    
</body>
</html>