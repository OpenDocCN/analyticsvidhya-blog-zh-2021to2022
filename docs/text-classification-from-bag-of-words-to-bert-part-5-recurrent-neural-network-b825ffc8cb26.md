# æ–‡æœ¬åˆ†ç±»â€”ä»è¯è¢‹åˆ° BERT â€”ç¬¬äº”éƒ¨åˆ†(é€’å½’ç¥ç»ç½‘ç»œ)

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/text-classification-from-bag-of-words-to-bert-part-5-recurrent-neural-network-b825ffc8cb26?source=collection_archive---------5----------------------->

![](img/ba1a45d449a4bfae6e65344a227d8acc.png)

åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šç”±[Tine ivani](https://unsplash.com/@tine999?utm_source=medium&utm_medium=referral)æ‹æ‘„çš„ç…§ç‰‡

è¿™ä¸ªæ•…äº‹æ˜¯ä¸€ç³»åˆ—æ–‡æœ¬åˆ†ç±»çš„ä¸€éƒ¨åˆ†â€”â€”ä»è¯è¢‹åˆ° BERT åœ¨åä¸ºâ€œ [*æœ‰æ¯’è¯„è®ºåˆ†ç±»æŒ‘æˆ˜â€*](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) ***çš„ Kaggle æ¯”èµ›ä¸Šå®æ–½å¤šç§æ–¹æ³•ã€‚*** åœ¨è¿™åœºæ¯”èµ›ä¸­ï¼Œæˆ‘ä»¬é¢ä¸´çš„æŒ‘æˆ˜æ˜¯å»ºç«‹ä¸€ä¸ªå¤šå¤´æ¨¡å‹ï¼Œèƒ½å¤Ÿæ£€æµ‹ä¸åŒç±»å‹çš„æ¯’æ€§ï¼Œå¦‚*å¨èƒã€æ·«ç§½ã€ä¾®è¾±å’ŒåŸºäºèº«ä»½çš„ä»‡æ¨ã€‚å¦‚æœä½ è¿˜æ²¡çœ‹è¿‡ä¹‹å‰çš„æŠ¥é“ï¼Œé‚£å°±å»çœ‹çœ‹å§*

[ç¬¬ä¸€éƒ¨åˆ†(BagOfWords)](https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-1e628a2dd4c9)

[ç¬¬äºŒéƒ¨åˆ†(Word2Vec)](https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-part-2-word2vec-35c8c3b34ee3)

[ç¬¬ä¸‰éƒ¨åˆ†(å¿«é€Ÿæ–‡æœ¬)](https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-part-3-fasttext-8313e7a14fce)

[ç¬¬å››éƒ¨åˆ†(å·ç§¯ç¥ç»ç½‘ç»œ)](https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-part-4-convolutional-neural-network-53aa63941ade)

åœ¨æ›´æ—©çš„æ•…äº‹ä¸­([ç¬¬ 4 éƒ¨åˆ†(å·ç§¯ç¥ç»ç½‘ç»œ)](https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-part-4-convolutional-neural-network-53aa63941ade))ï¼Œæˆ‘ä»¬ä½¿ç”¨ Keras åº“(TensorFlow ä¸Šçš„ä¸€ä¸ªåŒ…è£…å™¨)ä¸ºè¾“å‡ºå˜é‡â€”â€”æœ‰æ¯’ã€ä¸¥é‡æœ‰æ¯’ã€æ·«ç§½ã€å¨èƒã€ä¾®è¾±ã€èº«ä»½ä»‡æ¨â€”â€”çš„å¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»åˆ›å»ºä¸€ç»´ CNNã€‚

åœ¨è¿™ä¸€æ¬¡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç›¸åŒçš„ Keras åº“æ¥åˆ›å»ºé•¿çŸ­æœŸè®°å¿†(LSTM ),è¿™æ˜¯å¯¹ç”¨äºå¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»çš„å¸¸è§„ rnn çš„æ”¹è¿›ã€‚æˆ‘ä»¬å°†é¦–å…ˆé€šè¿‡å¯¹ RNNs å’Œ LSTM å¦‚ä½•å·¥ä½œçš„ä¸€ç‚¹ç›´è§‰ï¼Œç„¶åä½¿ç”¨ç”¨äºå¤šæ ‡ç­¾åˆ†ç±»çš„æœ€å°åŒ–å•è¾“å‡ºå±‚(å…·æœ‰ 6 ä¸ªç¥ç»å…ƒ)æ¥å®ç°å®ƒ(è€Œä¸æ˜¯ä¸ºæ¯ç§ç±»å‹çš„æ¯’æ€§åˆ›å»º 6 ä¸ªå•ç‹¬çš„ç½‘ç»œæˆ–åˆ›å»ºå…·æœ‰ 6 ä¸ªè¾“å‡ºå±‚çš„å¤šè¾“å‡ºå±‚ç½‘ç»œ)ã€‚æˆ‘ä»¬å°†åªä½¿ç”¨ä¸€ä¸ª LSTM å±‚ï¼Œåœ¨ä¸€ä¸ªæ—¶æœŸå†…ï¼Œå®ƒåœ¨æ’è¡Œæ¦œä¸Šç»™å‡ºäº†å¤§çº¦ 96 AUC

# ç›´è§‰

## æˆ‘ä»¬ä¸ºä»€ä¹ˆéœ€è¦æ³¨å†ŒæŠ¤å£«ï¼Ÿ

åœ¨ä¼ ç»Ÿçš„ç¥ç»ç½‘ç»œä¸­ï¼Œæˆ‘ä»¬å‡è®¾æ‰€æœ‰çš„è¾“å…¥(å’Œè¾“å‡º)éƒ½æ˜¯ç›¸äº’ç‹¬ç«‹çš„ã€‚å®ƒä»¬ä¸å…±äº«åœ¨æ–‡æœ¬çš„ä¸åŒä½ç½®å­¦åˆ°çš„ç‰¹å¾ã€‚å¯¹äºåºåˆ—ä¿¡æ¯(å¦‚æ–‡æœ¬æ•°æ®æˆ–æ—¶åºæ•°æ®)æ¥è¯´ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªé—®é¢˜ï¼Œå› ä¸ºæ¯ä¸ªå®ä¾‹éƒ½ä¾èµ–äºå‰ä¸€ä¸ªå®ä¾‹ã€‚rnn è¢«ç§°ä¸ºé€’å½’çš„ï¼Œå› ä¸ºå®ƒä»¬å¯¹åºåˆ—çš„æ¯ä¸ªå…ƒç´ æ‰§è¡Œç›¸åŒçš„ä»»åŠ¡ï¼Œè¾“å‡ºä¾èµ–äºå…ˆå‰çš„è®¡ç®—ã€‚å¦ä¸€ç§æ€è€ƒ rnn çš„æ–¹å¼æ˜¯ï¼Œå®ƒä»¬æœ‰ä¸€ä¸ªâ€œè®°å¿†â€ï¼Œå¯ä»¥æ•è·åˆ°ç›®å‰ä¸ºæ­¢å·²ç»è®¡ç®—è¿‡çš„ä¿¡æ¯ã€‚

![](img/acfc7e5053290aab3992d265ef1f3c8b.png)

[https://Stanford . edu/~ shervine/teaching/cs-230/cheat sheet-recurrent-neural-networks](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)

## **æ— çº¿ç½‘ç»œçš„æ¶æ„æ˜¯ä»€ä¹ˆï¼Ÿ**

RNN çš„æ•´ä½“æ¶æ„å–å†³äºæ‰‹å¤´çš„ä»»åŠ¡ã€‚å¯¹äºè¿™ä¸ªåˆ†ç±»ä»»åŠ¡ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç¬¬ä¸‰ç§æ–¹æ³•:å¤šå¯¹ä¸€ã€‚ä½†æ˜¯å‡ºäºç›´è§‰çš„ç›®çš„ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ç¬¬äº”ä¸ªï¼Œå®ƒæ˜¯ RNNs çš„ä¸€ä¸ªæ›´ä¸€èˆ¬åŒ–çš„ç¬¦å·ã€‚å¦‚æœæˆ‘ä»¬çŸ¥é“ç¬¬äº”è®°è°±æ³•æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œé‚£ä¹ˆåªéœ€æ”¹å˜ä¸€å°éƒ¨åˆ†å°±å¯ä»¥äº†ã€‚

![](img/52245d449ed0f23766504fbd987aed1c.png)

[https://www . di . ens . fr/~ le large/dldiy/slides/lecture _ 8/images/rnn _ variants _ 4 . png](https://www.di.ens.fr/~lelarge/dldiy/slides/lecture_8/images/rnn_variants_4.png)

è¾“å…¥å‘é‡ç”¨çº¢è‰²è¡¨ç¤ºï¼Œè¾“å‡ºå‘é‡ç”¨è“è‰²è¡¨ç¤ºï¼Œç»¿è‰²å‘é‡è¡¨ç¤º RNN çŠ¶æ€ã€‚ä»å·¦åˆ°å³:(1)æ²¡æœ‰ RNN çš„æ™®é€šå¤„ç†æ¨¡å¼(ä¾‹å¦‚å›¾åƒåˆ†ç±»)(2)åºåˆ—è¾“å‡º(ä¾‹å¦‚å›¾åƒå­—å¹•)(3)åºåˆ—è¾“å…¥(ä¾‹å¦‚æƒ…æ„Ÿåˆ†æ)(4)åºåˆ—è¾“å…¥å’Œåºåˆ—è¾“å‡º(ä¾‹å¦‚æœºå™¨ç¿»è¯‘)(5)åŒæ­¥åºåˆ—è¾“å…¥å’Œè¾“å‡º(ä¾‹å¦‚è§†é¢‘åˆ†ç±»â€”â€”æ ‡è®°è§†é¢‘çš„æ¯ä¸€å¸§)

![](img/e78014fd18f7f81290702694649d8c9f.png)

RNNs ä¸­çš„å‰å‘å’Œåå‘ä¼ æ’­([http://www . wild ml . com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-RNNs/](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/))

## ä»€ä¹ˆæ˜¯æ¶ˆå¤±æ¸å˜ï¼Ÿ

æ¶ˆå¤±æ¢¯åº¦é—®é¢˜å‡ºç°åœ¨éå¸¸æ·±çš„ç¥ç»ç½‘ç»œä¸­ï¼Œé€šå¸¸æ˜¯ rnnï¼Œå…¶ä½¿ç”¨æ¢¯åº¦è¶‹äºå°(åœ¨ 0-1 çš„èŒƒå›´å†…)çš„æ¿€æ´»å‡½æ•°ã€‚å› ä¸ºè¿™äº›å°æ¢¯åº¦åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ä¼šæˆå€å¢åŠ ï¼Œæ‰€ä»¥å®ƒä»¬å¾€å¾€ä¼šåœ¨æ‰€æœ‰å±‚ä¸­â€œæ¶ˆå¤±â€æˆ–å‡å°‘åˆ° 0ï¼Œä»è€Œé˜»æ­¢ç½‘ç»œå­¦ä¹ é•¿ç¨‹ç›¸å…³æ€§ã€‚éšç€åºåˆ—å˜é•¿ï¼Œä¼ é€’åˆ°å…ˆå‰çŠ¶æ€çš„æ¢¯åº¦/å¯¼æ•°å˜å¾—è¶Šæ¥è¶Šå°ã€‚è¿™ä¸ªé—®é¢˜æœ‰å¾ˆå¤šè§£å†³æ–¹æ³•ã€‚å…¶ä¸­ä¹‹ä¸€æ˜¯ä½¿ç”¨ä¸€ç§å«åš LSTMs çš„å˜ç§ã€‚

## ä»€ä¹ˆæ˜¯ LSTMï¼Ÿ

é•¿çŸ­æœŸè®°å¿†ç½‘ç»œâ€”â€”é€šå¸¸ç®€ç§°ä¸ºâ€œlstmâ€â€”â€”æ˜¯ä¸€ç§ç‰¹æ®Šçš„ RNNï¼Œèƒ½å¤Ÿå­¦ä¹ é•¿æœŸä¾èµ–æ€§ã€‚æ‰€æœ‰çš„ rnn éƒ½å…·æœ‰ç¥ç»ç½‘ç»œé‡å¤æ¨¡å—é“¾çš„å½¢å¼ã€‚LSTM ä¹Ÿæœ‰è¿™ç§é“¾çŠ¶ç»“æ„ï¼Œä½†æˆ‘ä»¬æ²¡æœ‰éšè—å±‚ï¼Œè€Œæ˜¯æœ‰ä¸€ç§å«åš LSTM å•å…ƒçš„ä¸œè¥¿ï¼Œæˆ‘ä»¬è¿˜æœ‰å¦ä¸€ç§è¿æ¥ï¼Œå®ƒè´¯ç©¿æ‰€æœ‰æ—¶é—´æ­¥éª¤å’Œéšè—çŠ¶æ€ã€‚è¿™å°±æ˜¯æ‰€è°“çš„â€œå•å…ƒçŠ¶æ€â€å‘é‡ï¼Œå¯ä»¥æ ¹æ®éœ€è¦ä»å…¶ä¸­æ£€ç´¢å’Œåˆ é™¤ä¿¡æ¯ã€‚

![](img/81e858f4d38e52c11d70530d4ceabc84.png)

[http://colah.github.io/posts/2015-08-Understanding-LSTMs/](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)

è®©æˆ‘ä»¬çœ‹çœ‹è¿™ 6 ä¸ªæ­¥éª¤:

1.  è¿™æ˜¯**é—å¿˜é—¨**ï¼Œå®ƒè´Ÿè´£é—å¿˜å¤šå°‘ï¼Œç”±äºå®ƒé€šè¿‡ä¸€ä¸ª sigmoid å‡½æ•°ï¼Œå®ƒå°†ç»™å‡º 0 åˆ° 1 çš„å€¼ï¼Œè¿™æ˜¯ä»å…ˆå‰å•å…ƒçŠ¶æ€ä¿ç•™çš„å­˜å‚¨é‡
2.  è¿™æ˜¯**è¾“å…¥é—¨**ï¼Œå®ƒè´Ÿè´£å‘å•å…ƒçŠ¶æ€æ·»åŠ å¤šå°‘æ–°ä¿¡æ¯ã€‚ç±»ä¼¼äºé—å¿˜é—¨ï¼Œè¿™ä¹Ÿå°†ç»™å‡º 0 åˆ° 1 çš„å€¼ï¼Œè¿™æ˜¯è¦æ·»åŠ çš„æ–°å†…å­˜é‡
3.  è¿™æ˜¯æ–°çš„å€™é€‰å‘é‡/å•å…ƒçŠ¶æ€çš„åˆ›å»º
4.  è¿™æ˜¯æ›´æ–°å•å…ƒçŠ¶æ€çš„åœ°æ–¹ï¼Œè¯¥å•å…ƒçŠ¶æ€æ˜¯å…ˆå‰å•å…ƒçŠ¶æ€å’Œå½“å‰å•å…ƒçŠ¶æ€çš„ç»„åˆï¼Œåˆ†åˆ«ä½¿ç”¨**é—å¿˜é—¨**å’Œ**è¾“å…¥é—¨**æ§åˆ¶æ¯ä¸ªå•å…ƒçŠ¶æ€çš„è´¡çŒ®ã€‚
5.  è¿™æ˜¯**è¾“å‡ºé—¨**,å…¶è´Ÿè´£åœ¨å…·æœ‰ 0 å’Œ 1 ä¹‹é—´çš„å€¼çš„éšè—çŠ¶æ€ä¸­è®°å¿†æ›´æ–°çš„å•å…ƒçŠ¶æ€çš„å“ªä¸€éƒ¨åˆ†
6.  è¿™æ˜¯æ›´æ–°åçš„éšè—çŠ¶æ€ï¼Œå°†ä½œä¸ºä¸‹ä¸€ä¸ªå•å…ƒçš„è¾“å…¥ï¼Œå¹¶åŸºäºç”±**è¾“å‡ºé—¨**æ§åˆ¶çš„å½“å‰å•å…ƒçŠ¶æ€

## LSTM å¦‚ä½•è§£å†³æ¶ˆå¤±æ¢¯åº¦ï¼Ÿ

*   LSTM æ¶æ„ä½¿å¾— RNN æ›´å®¹æ˜“åœ¨å¤šä¸ªæ—¶é—´æ­¥é•¿ä¸Šä¿å­˜ä¿¡æ¯ï¼Œä¾‹å¦‚ï¼Œå¦‚æœé—å¿˜é—¨è¢«è®¾ç½®ä¸ºåœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿ä¸Šè®°ä½æ‰€æœ‰å†…å®¹ï¼Œåˆ™å•å…ƒä¸­çš„ä¿¡æ¯è¢«æ— é™æœŸä¿å­˜ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œé¦™è‰ RNN æ›´éš¾å­¦ä¹ ä¸€ä¸ªé€’å½’çš„æƒé‡çŸ©é˜µï¼Œä»¥éšè—çŠ¶æ€ä¿å­˜ä¿¡æ¯
*   LSTM å¹¶ä¸ä¿è¯æ²¡æœ‰æ¶ˆå¤±/çˆ†ç‚¸æ¢¯åº¦ï¼Œä½†å®ƒç¡®å®ä¸ºæ¨¡å‹å­¦ä¹ é•¿è·ç¦»ä¾èµ–æ€§æä¾›äº†ä¸€ç§æ›´ç®€å•çš„æ–¹æ³•

åœ¨å˜å½¢é‡‘åˆšè¯ç”Ÿä¹‹å‰ï¼ŒLSTMs ç»Ÿæ²»ç€ NLP çš„ä¸–ç•Œã€‚å³ä½¿åœ¨ä»Šå¤©ï¼Œå®ƒä»è¢«å¹¿æ³›ä½¿ç”¨

2015 å¹´ï¼Œè°·æ­Œåœ¨è°·æ­Œè¯­éŸ³ä¸­ä½¿ç”¨äº† LSTMï¼Œè¿™å°†è½¬å½•é”™è¯¯å‡å°‘äº† 49%ã€‚

2016 å¹´ï¼Œè°·æ­Œä½¿ç”¨ LSTM åœ¨ Allo conversation åº”ç”¨ç¨‹åºä¸­å»ºè®®æ¶ˆæ¯ã€‚è°·æ­Œä½¿ç”¨ LSTMs è¿›è¡Œè°·æ­Œç¿»è¯‘ï¼Œå‡å°‘äº† 60%çš„ç¿»è¯‘é”™è¯¯ã€‚è‹¹æœå®£å¸ƒï¼Œå°†å¼€å§‹åœ¨ iPhone å’Œ Siri ä¸­ä½¿ç”¨ quick type LSTMã€‚äºšé©¬é€Šå‘å¸ƒäº†æ³¢åˆ©ï¼ŒAlexa èƒŒåçš„å£°éŸ³ï¼Œä½¿ç”¨åŒå‘ LSTMã€‚

2017 å¹´ï¼Œè„¸ä¹¦æ¯å¤©ä½¿ç”¨ LSTMs è¿›è¡Œçº¦ 45 äº¿æ¬¡è‡ªåŠ¨ç¿»è¯‘

è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ï¼Œè®©æˆ‘ä»¬æ·±å…¥ä»£ç ğŸ‘¨â€ğŸ’»å¯¹äºå¯¹å®Œæ•´ä»£ç æ„Ÿå…´è¶£çš„äººæ¥è¯´ï¼Œè¿™é‡Œæ˜¯å®ƒç°åœ¨çš„

# å±¥è¡Œ

## 1.è¯»å–æ•°æ®é›†

![](img/90759cb3db6cdcb6e9cf373b4502526b.png)

æé†’ä¸€ä¸‹ï¼Œè¿™æ˜¯è®­ç»ƒæ•°æ®çš„æ ·å­

## 2.æ–‡æœ¬é¢„å¤„ç†

LSTM æ¨¡å‹çš„é¢„å¤„ç†ä¸ CNN éå¸¸ç›¸ä¼¼ã€‚

```
*#Initializing the class*
tokenizer = Tokenizer(num_words = MAX_NUM_WORDS)
*#Updates internal vocabulary based on a list of texts.*
tokenizer.fit_on_texts(train_texts)
*#Transforms each text in texts to a sequence of integers.*
train_sequences = tokenizer.texts_to_sequences(train_texts)
test_sequences = tokenizer.texts_to_sequences(test_texts)
word_index = tokenizer.word_index
print("Length of word Index:", len(word_index))
print("First 5 elements in the word_index dictionary:", dict(list(word_index.items())[0: 5]) )
print("First comment text in training set:**\n**", train_sequences[0])*#Pad tokenized sequences*
trainvalid_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)
test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)
print("Shape of padded sequence list:**\n**", trainvalid_data.shape)
print("First comment text in training set - 0 for padding - only last 50 sequences as the rest are paddings:**\n**", trainvalid_data[0][-50:])
```

![](img/35e1f27aae4d72f17e801e04d7cc30e0.png)

**é¡¶éƒ¨**:åŸå­—ç¬¦ä¸²**ä¸­é—´**:æ ‡è®°æ–‡æœ¬**åº•éƒ¨**:å¡«å……æ–‡æœ¬

æˆ‘ä»¬ä½¿ç”¨ Keras ä¸­çš„ Tokenizer ç±»ï¼Œé€šè¿‡åŸºäºé¢‘ç‡å°†æ¯ä¸ªå•è¯æ˜ å°„åˆ°ä¸€ä¸ªæ•°å­—ï¼Œå°†å­—ç¬¦ä¸²æ ‡è®°ä¸ºä¸€ä¸ªæ•°å­—åºåˆ—ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨ Keras ä¸­çš„ pad_sequences å¡«å……æ ‡è®°åŒ–çš„æ•´æ•°åºåˆ—ï¼Œä½¿æ‰€æœ‰åºåˆ—çš„å¤§å°ç›¸åŒï¼Œä»¥ä¾¿è¿›è¡ŒçŸ¢é‡åŒ–è®¡ç®—ã€‚æˆ‘å»ºè®®ä»”ç»†é˜…è¯»[ç¬”è®°æœ¬](https://www.kaggle.com/anirbansen3027/jtcc-cnn#3.-Text-Preprocessing)ã€‚

*æˆ‘ä»¬å°†æŒ‰ç…§è¿™äº›æ­¥éª¤ä½¿ç”¨ LSTM è¿›è¡Œå¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»:* **è¾“å…¥å­—ç¬¦ä¸²- >æ ‡è®°åŒ–- >å¡«å……- >åµŒå…¥- > LSTM - >åˆ†ç±»å™¨**

## 3.å®šä¹‰å¤šæ ‡ç­¾ LSTM æ¨¡å‹

åœ¨ Keras ä¸­ï¼Œå®šä¹‰æ¨¡å‹æœ€ç®€å•çš„æ–¹æ³•æ˜¯å¯åŠ¨ä¸€ä¸ªé¡ºåºæ¨¡å‹ç±»ï¼Œå¹¶ä¸æ–­æ·»åŠ æ‰€éœ€çš„å±‚ã€‚åœ¨è¿™ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹ä¸­ï¼Œä½¿ç”¨äº†ä¸€ä¸ªç§°ä¸ºâ€œä¸‹é™â€çš„æ–°å‚æ•°:

**å‰”é™¤:**å‰”é™¤æ˜¯ä¸€ç§è§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜çš„æŠ€æœ¯ã€‚å…³é”®æ€æƒ³æ˜¯åœ¨è®­ç»ƒæœŸé—´ä»ç¥ç»ç½‘ç»œä¸­éšæœºä¸¢å¼ƒå•å…ƒ(è¿åŒå®ƒä»¬çš„è¿æ¥)ã€‚è¿™å¯ä»¥é˜²æ­¢å•ä½ä¹‹é—´è¿‡åº¦çš„ç›¸äº’é€‚åº”ã€‚å¼•å…¥è¯¥è¶…å‚æ•°æ˜¯ä¸ºäº†æŒ‡å®šè¯¥å±‚çš„è¾“å‡ºè¢«ä¸¢å¼ƒçš„æ¦‚ç‡ã€‚

**å¾ªç¯ä¸¢å¤±**å±è”½(æˆ–â€œä¸¢å¼ƒâ€)å¾ªç¯å•å…ƒä¹‹é—´çš„è¿æ¥ã€‚

**é‡è¦æç¤º:ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œ**

å¯¹äº**äºŒè¿›åˆ¶**åˆ†ç±»ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ 1 ä¸ªè¾“å‡ºå•å…ƒï¼Œåœ¨è¾“å‡ºå±‚ä½¿ç”¨ sigmoid æ¿€æ´»å¹¶ä½¿ç”¨äºŒè¿›åˆ¶äº¤å‰ç†µæŸå¤±

å¯¹äº**å¤šç±»**åˆ†ç±»ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ N ä¸ªè¾“å‡ºå•å…ƒï¼Œåœ¨è¾“å‡ºå±‚ä½¿ç”¨ softmax æ¿€æ´»ï¼Œå¹¶ä½¿ç”¨åˆ†ç±»äº¤å‰ç†µæŸå¤±

å¯¹äº**å¤šæ ‡ç­¾**åˆ†ç±»ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ N ä¸ªè¾“å‡ºå•å…ƒï¼Œåœ¨è¾“å‡ºå±‚ä½¿ç”¨ sigmoid æ¿€æ´»å¹¶ä½¿ç”¨äºŒè¿›åˆ¶äº¤å‰ç†µæŸå¤±

![](img/faec5d370b0241661fca3dca908522df.png)

```
rnn_model = Sequential()
rnn_model.add(Embedding(MAX_NUM_WORDS, 128))
rnn_model.add(LSTM(units = 128, dropout = 0.2, recurrent_dropout = 0.2))
rnn_model.add(Dense(units = 6, activation = 'sigmoid'))
print(rnn_model.summary()
```

## 5.ç¼–è¯‘å’Œè®­ç»ƒ LSTM æ¨¡å‹

ç¼–è¯‘å’Œè®­ç»ƒ/æ‹Ÿåˆä»£ç ä¹Ÿä¸ CNN æ¨¡å‹éå¸¸ç›¸ä¼¼ã€‚åœ¨å¼€å§‹è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹å…¶è¿›è¡Œé…ç½®ã€‚æˆ‘ä»¬éœ€è¦æåˆ°æŸå¤±å‡½æ•°ï¼Œå®ƒå°†ç”¨äºè®¡ç®—æ¯æ¬¡è¿­ä»£çš„è¯¯å·®ï¼Œä¼˜åŒ–å™¨å°†æŒ‡å®šå¦‚ä½•æ›´æ–°æƒé‡ï¼Œä»¥åŠæ¨¡å‹åœ¨è®­ç»ƒå’Œæµ‹è¯•æœŸé—´è¯„ä¼°çš„æŒ‡æ ‡ã€‚æˆ‘åœ¨ä¹‹å‰çš„åšå®¢([ç¬¬å››éƒ¨åˆ†(å·ç§¯ç¥ç»ç½‘ç»œ)](https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-part-4-convolutional-neural-network-53aa63941ade))ä¸­å·²ç»æ·±å…¥è®¨è®ºäº†è®­ç»ƒå‚æ•°

```
*#Configures the model for training.*
rnn_model.compile(loss = "binary_crossentropy", optimizer = "adam", metrics = ["AUC"])
*#Split the dataset into train and validation set for training and evaludating the model*
X_train, X_val, y_train, y_val = train_test_split(trainvalid_data, train_labels, shuffle = True, random_state = 123)
print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)
*#Trains the model for a fixed number of epochs (iterations on a dataset)*
history = rnn_model.fit(X_train, y_train, batch_size = 128, epochs = 1, validation_data = (X_val, y_val))
```

![](img/1b4a2053bc3733a6af55c93ee046ab57.png)

Val_AUC ä»…åœ¨ä¸€ä¸ªæ—¶æœŸå†…ä¸º 0.98ï¼Œå…·æœ‰å•ä¸ª LSTM å±‚å¹¶ä¸”å‡ ä¹æ²¡æœ‰è°ƒè°

## 5.æ”¹è¿›çš„ç»“æœå’ŒèŒƒå›´

![](img/913c79309f7bf20b1dd4b9d8422afa0e.png)

Kaggle æ’è¡Œæ¦œåˆ†æ•°(ç›¸å½“æƒŠäººçš„ä¸€ä¸ªæ—¶ä»£å§ï¼Ÿ)

*   å †å  1 ä¸ªä»¥ä¸Šçš„ LSTM å±‚
*   æ—¶æœŸã€å­¦ä¹ ç‡ã€æ‰¹é‡å¤§å°ã€æå‰åœæ­¢çš„è¶…å‚æ•°è°ƒæ•´

è¿™æ˜¯å…³äº LSTMs çš„ã€‚ä¸‹ä¸€ä¸ªå°†æ˜¯å…³äºå¼ºå¤§çš„ BERTï¼Œå®ƒæ˜¯å»ºç«‹åœ¨å˜å‹å™¨ç½‘ç»œä¸Šçš„ï¼Œç›®å‰æ­£ç»Ÿæ²»ç€ NLP çš„ä¸–ç•Œã€‚åŒæ ·ï¼Œè¿™ä¸ªåšå®¢çš„å…¨éƒ¨ä»£ç éƒ½åœ¨è¿™é‡Œ[(è¿™é‡Œ)](https://www.kaggle.com/anirbansen3027/jtcc-multilabel-lstm-keras)ã€‚è¯·ä»¥å›ç­”å’Œé¼“æŒçš„å½¢å¼æä¾›æ‚¨çš„åé¦ˆ:)