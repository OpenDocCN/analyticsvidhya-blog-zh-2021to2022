<html>
<head>
<title>Building a lane detection system</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建车道检测系统</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-a-lane-detection-system-f7a727c6694?source=collection_archive---------0-----------------------#2021-04-29">https://medium.com/analytics-vidhya/building-a-lane-detection-system-f7a727c6694?source=collection_archive---------0-----------------------#2021-04-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0030" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用Python 3和OpenCV</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/bec319120f4e0b9efd3847e4251966a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*b5ptHu0y7wUeMddy"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://unsplash.com/photos/rafblRbne3o" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="b3ef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本教程中，我们将学习如何使用计算机视觉技术建立一个跟踪道路车道的软件管道。</p><div class="ju jv ez fb jw jx"><a href="https://github.com/Arun-purakkatt/medium_repo" rel="noopener  ugc nofollow" target="_blank"><div class="jy ab dw"><div class="jz ab ka cl cj kb"><h2 class="bd hj fi z dy kc ea eb kd ed ef hh bi translated">Arun-purakkatt/medium_repo</h2><div class="ke l"><h3 class="bd b fi z dy kc ea eb kd ed ef dx translated">中型博客-机器学习、深度学习、数据科学- Arun-purakkatt/medium_repo</h3></div><div class="kf l"><p class="bd b fp z dy kc ea eb kd ed ef dx translated">github.com</p></div></div><div class="kg l"><div class="kh l ki kj kk kg kl jn jx"/></div></div></a></div><p id="7817" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="km">道路车道检测面临挑战？</em> </strong></p><p id="70df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">道路上显示车道位置的线条是我们不断的参考。我们使用基于canny检测器-Hough变换的车道检测。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kn"><img src="../Images/8baa459d7f1773fb99ee790d1648b745.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*KBucsrAbr-sD8iskk3uDEQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Canny-Hough检测器工艺流程</figcaption></figure><p id="aa90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图是我们管线的概述。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ko"><img src="../Images/3a93f3624e6d5d3377d0f07323f03a97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*etnxAMFn1wKBviuL.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Canny-Hough检测系统概观</figcaption></figure></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><p id="9fc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">方法:</strong></p><p id="730c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Canny边缘检测器需要灰度图像，因此我们需要将图像转换成灰度图像。我们将3个通道的像素值(红色、绿色和蓝色)合并成一个通道，像素值范围为[0，255]。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kw"><img src="../Images/3450c1bf8a1fdc583ba68d13f68ca8ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*clw6Ag-gHDtCEf69rSMoVA.png"/></div></figure><p id="2fbd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的灰度图像上创建高斯模糊，这不是强制性的，因为canny detector会为我们做这一步。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kx"><img src="../Images/bd856e6ab9ab29bebaeaa8f6bd13c020.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*TpqAX_KgfdpNkLNfToCcDg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">高斯模糊</figcaption></figure><p id="9ce2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们了解一下canny边缘检测器，你可以在这里找到详细的文档<a class="ae jt" href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html#canny" rel="noopener ugc nofollow" target="_blank"/>。下面是代码片段。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ky"><img src="../Images/77f2054ac74da3443a2accc35f665b5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*9i7x9ild9YfP7vvCLDH9Vw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Canny边缘检测器</figcaption></figure><p id="d412" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过阅读几篇文章，我发现，这些预处理步骤中的每一步都依赖于数据集。</p><p id="dc58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">车道线总是黄白相间的。黄色在RGB空间中可能是一种难以分离的颜色，所以让我们将其转换为<a class="ae jt" href="https://en.wikipedia.org/wiki/HSL_and_HSV" rel="noopener ugc nofollow" target="_blank">色调值饱和度</a>或HSV颜色空间。你可以通过谷歌搜索找到黄色值的目标范围。下面是我用过的。接下来，我们将对原始RGB <code class="du kz la lb lc b">image</code>应用遮罩，以返回我们感兴趣的像素。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ld"><img src="../Images/2a784f8f62baf51becd277e14a9a8368.png" data-original-src="https://miro.medium.com/v2/resize:fit:1224/format:webp/1*Dz4ldMzCItsJxuzTCqXttQ.png"/></div></figure></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><p id="2b28" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">设置环境</strong></p><p id="85e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">确保您已经安装了opencv。安装numpy和matplotlib库，因为我们在处理时需要它们。</p><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="7378" class="li lj hi lc b fi lk ll l lm ln">pip install opencv-python</span></pre><p id="2069" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">导入库</strong></p><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="6b83" class="li lj hi lc b fi lk ll l lm ln"><strong class="lc hj">import</strong> <strong class="lc hj">cv2</strong><br/><strong class="lc hj">import</strong> <strong class="lc hj">matplotlib.pyplot</strong> <strong class="lc hj">as</strong> <strong class="lc hj">plt</strong><br/><strong class="lc hj">import</strong> <strong class="lc hj">numpy</strong> <strong class="lc hj">as</strong> <strong class="lc hj">np</strong></span></pre><p id="460b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">图像预处理</strong></p><p id="aad5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">灰度图像:灰度图像的复杂度低于彩色图像。我们可以谈论图像的许多特征，亮度、对比度、边缘、形状、轮廓、纹理、透视、阴影等等，而不涉及颜色。在提出灰度图像模型后，它可以扩展到彩色图像。</p><p id="04c5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">高斯滤波器</strong>:高斯滤波器的目的是减少图像中的噪声。我们这样做是因为Canny中的梯度对噪声非常敏感，所以我们希望尽可能消除噪声。</p><p id="7198" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="km"> cv2。高斯-布朗参数:img，ksize，sigma </em></p><p id="7095" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">img:我们要拍的照片</p><p id="0b72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ksize:我们对图像进行卷积的kerenel的维度。</p><p id="4dba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">sigma:定义沿x轴的标准偏差。</p><p id="7412" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> canny-edge detection </strong>:基本思想是检测亮度的急剧变化，如从黑到白、从白到黑&amp;将其定义为边缘。降噪，强度梯度，非最大值抑制，滞后阈值。它有3个参数。</p><ul class=""><li id="fb29" class="lo lp hi ih b ii ij im in iq lq iu lr iy ls jc lt lu lv lw bi translated"><em class="km"> img </em>参数定义了我们将要检测边缘的图像。</li><li id="69cd" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated"><em class="km">阈值-1 </em>参数过滤低于该数字的所有渐变(它们不被视为边缘)。</li><li id="e3a8" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated"><em class="km"> threshold-2 </em>参数决定了一个边沿的有效值。</li><li id="92d1" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">如果连接到高于<em class="km">阈值-2 </em>的另一个梯度，则两个阈值之间的任何梯度都将被考虑。</li></ul><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="ae8e" class="li lj hi lc b fi lk ll l lm ln">#convert into grey scale image<br/>def grey(image):<br/>  image=np.asarray(image)<br/>  return cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)</span><span id="e33c" class="li lj hi lc b fi mc ll l lm ln">#Gaussian blur to reduce noise and smoothen the image<br/>def gauss(image):<br/>  return cv2.GaussianBlur(image,(5,5),0)</span><span id="1556" class="li lj hi lc b fi mc ll l lm ln">#Canny edge detection<br/>def canny(image):<br/>    edges = cv2.Canny(image,50,150)<br/>    return edges</span></pre><p id="f49c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这就是我们的图像经过精明的边缘检测后的样子。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es md"><img src="../Images/30d032e527ed9692028c127891032952.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*i-G3Cfqedbj5KM-K.jpeg"/></div></div></figure><p id="98d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以我们可以看到它包含了我们图像中的所有边缘&amp;我们应该隔离车道线的边缘。</p><p id="1c31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">既然我们已经定义了图像中的所有边缘，我们需要隔离与车道线对应的边缘。这就是我们要做的。</p><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="5798" class="li lj hi lc b fi lk ll l lm ln"><strong class="lc hj">def</strong> region(image):<br/>    height, width = image.shape<br/>    triangle = np.array([<br/>                       [(100, height), (475, 325), (width, height)]<br/>                       ])<br/>    <br/>    mask = np.zeros_like(image)<br/>    <br/>    mask = cv2.fillPoly(mask, triangle, 255)<br/>    mask = cv2.bitwise_and(image, mask)<br/>    <strong class="lc hj">return</strong> mask</span></pre><p id="900e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该功能将隔离图像中车道线所在的特定硬编码区域。它接受一个参数，Canny图像，并输出隔离区域。</p><p id="d2e0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在第1行，我们将使用numpy.shape函数提取图像尺寸。<br/>在第2–4行，我们将定义一个三角形的尺寸，这是我们想要隔离的区域。<br/>在第5行和第6行，我们将创建一个黑色平面，然后用第2行定义的尺寸定义一个白色三角形。<br/>在第7行，我们将执行按位and运算，这允许我们隔离与车道线对应的边。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es me"><img src="../Images/375c5d484889521baaaeb40bf5be3dbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*U4jr2dtZwX7kDKYY.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">仅输出隔离区域中的边缘。其他的都被忽略了</figcaption></figure><p id="b19a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">霍夫线变换:</p><p id="35b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这一行代码是整个算法的核心。这就是所谓的霍夫变换，将孤立区域中的白色像素簇转化为实际的线条。</p><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="49af" class="li lj hi lc b fi lk ll l lm ln">lines = cv2.HoughLinesP(isolated, rho=2, theta=np.pi/180, threshold=100, np.array([]), minLineLength=40, maxLineGap=5)</span></pre><p id="fdbb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参数1:孤立梯度<br/>参数2和3:定义面元大小，2是rho的值，np.pi/180是θ的值<br/>参数4:每个面元被认为是一条线所需的最小交点(在我们的例子中，它有100个交点)<br/>参数5:占位符数组<br/>参数6:最小线长度<br/>参数7:最大线间隙</p><p id="23cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">优化和显示线条</p><p id="678d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了平均这些线，我们将定义一个名为“平均”的函数。</p><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="98d4" class="li lj hi lc b fi lk ll l lm ln">def average(image, lines):<br/>    left = []<br/>    right = []<br/>    for line in lines:<br/>        print(line)<br/>        x1, y1, x2, y2 = line.reshape(4)<br/>        parameters = np.polyfit((x1, x2), (y1, y2), 1)<br/>        slope = parameters[0]<br/>        y_int = parameters[1]<br/>        if slope &lt; 0:<br/>            left.append((slope, y_int))<br/>        else:<br/>            right.append((slope, y_int))</span></pre><p id="1a84" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该功能将<em class="km"> cv2中的线平均化。HoughLinesP </em>功能。它将找到左边和右边线段的平均斜率和y截距，并输出两条实线(一条在左边，另一条在右边)。</p><p id="646e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<em class="km"> cv2的输出中。HoughLinesP </em>函数，每个线段有2个坐标:一个表示线的起点，另一个标记线的终点。使用这些坐标，我们将计算每条线段的斜率和y轴截距。</p><p id="e8ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，我们将收集所有线段的斜率，并将每个线段分类到对应于左线或右线的列表中(负斜率=左线，正斜率=右线)。</p><ul class=""><li id="008d" class="lo lp hi ih b ii ij im in iq lq iu lr iy ls jc lt lu lv lw bi translated">第4行:循环遍历该行数组</li><li id="283e" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第5行:从每个线段中提取2个点的(x，y)值</li><li id="0b3e" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第6–9行:确定每条线段的斜率和y截距。</li><li id="20cd" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第10–13行:将负斜率添加到左侧线的列表中，将正斜率添加到右侧线的列表中。</li></ul><p id="086f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">注意:通常，正斜率=左线，负斜率=右线，但是在我们的例子中，图像的y轴是反转的，这就是斜率反转的原因(OpenCV中的所有图像都有反转的y轴)。</p><p id="f587" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们必须从两个列表中取斜率和y截距的平均值。</p><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="243a" class="li lj hi lc b fi lk ll l lm ln">    right_avg = np.average(right, axis=0)<br/>    left_avg = np.average(left, axis=0)<br/>    left_line = make_points(image, left_avg)<br/>    right_line = make_points(image, right_avg)<br/>    return np.array([left_line, right_line])</span></pre><ul class=""><li id="0ee9" class="lo lp hi ih b ii ij im in iq lq iu lr iy ls jc lt lu lv lw bi translated">第1–2行:取两个列表(左侧和右侧)中所有线段的平均值。</li><li id="fd10" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第3–4行:计算每条线的起点和终点。(我们将在下一节定义make_points函数)</li><li id="7116" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第5行:输出每行的2个坐标</li></ul><p id="5549" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们有了两个列表的平均斜率和y轴截距，让我们定义两个列表的起点和终点。</p><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="33cd" class="li lj hi lc b fi lk ll l lm ln">def make_points(image, average): <br/> slope, y_int = average <br/> y1 = image.shape[0]<br/> y2 = int(y1 * (3/5))<br/> x1 = int((y1 — y_int) // slope)<br/> x2 = int((y2 — y_int) // slope)<br/> return np.array([x1, y1, x2, y2])</span></pre><p id="b672" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个函数有两个参数，一个是车道线的图像，一个是车道线的平均斜率和y_int的列表，并输出每条车道线的起点和终点。</p><ul class=""><li id="f1db" class="lo lp hi ih b ii ij im in iq lq iu lr iy ls jc lt lu lv lw bi translated">第1行:定义函数</li><li id="44c6" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第2行:获得平均斜率和y截距</li><li id="b81a" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第3–4行:定义线条的高度(左右两边都一样)</li><li id="1e12" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第5–6行:通过重新排列一条线的方程，从<em class="km"> y=mx+b </em>到<em class="km"> x = (y-b) / m </em>计算<em class="km"> x </em>坐标</li><li id="933c" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第7行:输出坐标集</li></ul><p id="5f24" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">更详细地说，在第1行，我们使用<em class="km"> y1 </em>值作为图像的高度。这是因为在OpenCV中，y轴是反的，所以0在顶部，图像的高度在原点(参考下图)。</p><p id="0335" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，在第2行，我们将<em class="km"> y1 </em>乘以3/5。这是因为我们希望直线从原点(<em class="km"> y1 </em>)开始，并在图像上方2/5处结束(因为y轴是2/5，而不是从0向上3/5，我们看到从最大高度向下2/5)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mf"><img src="../Images/cda8f1845a974fa6776872fb17d4ebf3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f2kJ3A70kW6Y7EXO.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">应用于左线的make_points函数的可视化示例</figcaption></figure><p id="3fe4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是，该函数不显示线条，它只计算显示这些线条所需的点数。接下来，我们要创建一个函数，用这些点组成线条。</p><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="b36a" class="li lj hi lc b fi lk ll l lm ln">def display_lines(image, lines):<br/> lines_image = np.zeros_like(image)<br/> if lines is not None:<br/>   for line in lines:<br/>     x1, y1, x2, y2 = line<br/>     cv2.line(lines_image, (x1, y1), (x2, y2), (255, 0, 0), 10)<br/> return lines_image</span></pre><p id="338a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该函数接受两个参数:我们想要显示线条的图像和从<em class="km">平均</em>函数输出的车道线。</p><ul class=""><li id="c5b8" class="lo lp hi ih b ii ij im in iq lq iu lr iy ls jc lt lu lv lw bi translated">第2行:创建一个涂黑的图像，尺寸与原始图像相同</li><li id="a3d9" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第3行:确保包含行点的列表不是空的</li><li id="2904" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第4–5行:遍历列表，提取两对(x，y)坐标</li><li id="f0d4" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第6行:创建线条并粘贴到涂黑的图像上</li><li id="393e" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc lt lu lv lw bi translated">第7行:输出带有线条的黑色图像</li></ul><p id="6db0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可能想知道，为什么我们不把这些线条附加到真实的图像上，而不是黑色的图像上。嗯，原始图像有点太亮了，所以如果我们将它变暗一点，以便更清楚地看到车道线就好了(是的，我知道，这没什么大不了的，但找到使算法更好的方法总是好的)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mg"><img src="../Images/f3cd45c3f919668ded02e30466b5911f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yuiDQ_aUcqdUXaRL.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">左:直接向图像添加行。右图:使用cv2.addWeighted函数</figcaption></figure><p id="3dee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">左:直接向图像添加行。右图:使用cv2.addWeighted函数</p><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="f14f" class="li lj hi lc b fi lk ll l lm ln">lanes = cv2.addWeighted(copy, 0.8, black_lines, 1, 1)</span></pre><p id="7c4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该函数为实际图像中的每个像素赋予0.8的权重，使它们略暗(每个像素乘以0.8)。同样，我们将权重1赋予所有车道线的涂黑图像，因此其中的所有像素保持相同的强度，使其突出。</p><pre class="je jf jg jh fd le lc lf lg aw lh bi"><span id="312e" class="li lj hi lc b fi lk ll l lm ln">copy = np.copy(image1)<br/>grey = grey(copy)<br/>gaus = gauss(grey)<br/>edges = canny(gaus,50,150)<br/>isolated = region(edges)lines = cv2.HoughLinesP(isolated, 2, np.pi/180, 100, np.array([]), minLineLength=40, maxLineGap=5)<br/>averaged_lines = average(copy, lines)<br/>black_lines = display_lines(copy, averaged_lines)<br/>lanes = cv2.addWeighted(copy, 0.8, black_lines, 1, 1)<br/>cv2.imshow("lanes", lanes)<br/>cv2.waitKey(0)</span></pre><p id="405e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们简单地调用我们之前定义的所有函数，然后在第12行输出结果。<em class="km"> cv2.waitKey </em>函数用于告诉程序图像显示多长时间。我们将“0”传递给该函数，这意味着它将等待，直到按下一个键来关闭输出窗口。</p><p id="971c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是输出的样子</p><p id="2d9f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们简单地调用我们之前定义的所有函数，然后在第12行输出结果。<em class="km"> cv2.waitKey </em>函数用于告诉程序图像显示多长时间。我们将“0”传递给该函数，这意味着它将等待，直到按下一个键来关闭输出窗口。</p><p id="1bcc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是输出的样子</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mh"><img src="../Images/80d4685e08c4c23b1c6542f5e4655da5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aJieS5N25i8YJhP-.png"/></div></div></figure></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><p id="75eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请在<a class="ae jt" href="https://github.com/Arun-purakkatt/medium_repo" rel="noopener ugc nofollow" target="_blank"> <em class="km"> Github </em> </a>笔记本上查看完整代码，在 链接<em class="km"> </em> <a class="ae jt" href="https://www.linkedin.com/in/arun-purakkatt-mba-m-tech-31429367/" rel="noopener ugc nofollow" target="_blank"> <em class="km">上与我保持联系。</em></a></p></div><div class="ab cl kp kq gp kr" role="separator"><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku kv"/><span class="ks bw bk kt ku"/></div><div class="hb hc hd he hf"><p id="f2ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">参考文献:</strong></p><ol class=""><li id="ede8" class="lo lp hi ih b ii ij im in iq lq iu lr iy ls jc mi lu lv lw bi translated"><a class="ae jt" href="https://www.youtube.com/watch?v=eLTLtUVuuy4" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=eLTLtUVuuy4</a></li><li id="3c17" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc mi lu lv lw bi translated"><a class="ae jt" href="https://towardsdatascience.com/a-deep-dive-into-lane-detection-with-hough-transform-8f90fdd1322f" rel="noopener" target="_blank">https://towards data science . com/a-deep-dive-into-lane-detection-with-Hough-transform-8f 90 FDD 1322 f</a></li><li id="60bc" class="lo lp hi ih b ii lx im ly iq lz iu ma iy mb jc mi lu lv lw bi translated"><a class="ae jt" href="https://towardsdatascience.com/tutorial-build-a-lane-detector-679fd8953132" rel="noopener" target="_blank">https://towards data science . com/tutorial-build-a-lane-detector-679 FD 8953132</a></li></ol></div></div>    
</body>
</html>