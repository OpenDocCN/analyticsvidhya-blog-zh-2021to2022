<html>
<head>
<title>VAE in no time</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">很快就到VAE了</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/vae-in-no-time-8084158ce66d?source=collection_archive---------7-----------------------#2021-05-19">https://medium.com/analytics-vidhya/vae-in-no-time-8084158ce66d?source=collection_archive---------7-----------------------#2021-05-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="458d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">参观:<a class="ae jc" href="https://amitnikhade.com/" rel="noopener ugc nofollow" target="_blank">amitnikhade.com</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/c815f750dc464a9c5c634090b4304028.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eK_U1EfFWj9NbbZ1nY6nrA.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jc" href="https://unsplash.com/photos/R9rFKy_AVbw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditShareLink" rel="noopener ugc nofollow" target="_blank">演职员表</a></figcaption></figure><p id="c3d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="jt ju ge" href="https://medium.com/u/8cc2ede908a6?source=post_page-----8084158ce66d--------------------------------" rel="noopener" target="_blank"> <em class="jv"> theamitnikhade </em> </a></p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h1 id="e8fd" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">快速浏览变型自动编码器(VAE)</h1><p id="b58c" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">最近，<a class="ae jc" href="https://developers.google.com/machine-learning/gan/generative#:~:text=A%20generative%20model%20includes%20the,to%20a%20sequence%20of%20words." rel="noopener ugc nofollow" target="_blank">生成模型</a>因其最先进的性能获得了巨大的关注，因此在市场上获得了巨大的重要性，并被广泛使用。变分自动编码器是用于学习潜在表示的深度学习技术，它们是无监督学习的最好方法之一。VAE在生成各种数据方面取得了非凡的成果。</p><h1 id="bca4" class="kd ke hh bd kf kg lg ki kj kk lh km kn ko li kq kr ks lj ku kv kw lk ky kz la bi translated">自动编码器(AE)一览</h1><p id="ab9b" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">Autoencoder包括编码器、解码器和瓶颈。编码器简单地将输入转换为瓶颈中最低维度的数字表示，以吸收其显著特征，解码器从几乎类似于输入的表示中重建回输出。</p><p id="57b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自动编码器旨在最小化重建损失。<a class="ae jc" href="https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">重建损失</a>是原始数据和重建数据之间的差异。</p><p id="6048" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">L <a class="ae jc" href="https://afteracademy.com/blog/what-are-l1-and-l2-loss-functions" rel="noopener ugc nofollow" target="_blank"> 2损失函数</a>用于计算AE中的损失。即真实值和预测值之间所有平方差的总和。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ll"><img src="../Images/efa6d60b82d9e75dd34906e7d2fa6002.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/0*rx7mE5vwK_osf9WB.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">l2损失</figcaption></figure><p id="c013" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自动编码器的应用包括<a class="ae jc" href="https://towardsdatascience.com/introduction-to-image-denoising-3e269f176483" rel="noopener" target="_blank">去噪</a>、<a class="ae jc" href="https://machinelearningmastery.com/dimensionality-reduction-for-machine-learning/#:~:text=Dimensionality%20reduction%20refers%20to%20techniques%20for%20reducing%20the,input%20variables%20in%20training%20data.&amp;text=Fewer%20input%20dimensions%20often%20mean,to%20as%20degrees%20of%20freedom." rel="noopener ugc nofollow" target="_blank">降维</a>等。</p><h1 id="ebb7" class="kd ke hh bd kf kg lg ki kj kk lh km kn ko li kq kr ks lj ku kv kw lk ky kz la bi translated">变化的自动编码器一览</h1><p id="c5e3" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">VAE也是一种自动编码器，它不仅可以重构输出，还可以生成新的内容。明确地说，VAE是一个生成模型，而自动编码器不是。自动编码器通过最小化从输入和重建图像计算的<em class="jv">重建损失</em>来学习将输入转换为某种向量表示，另一方面，VAE通过最小化重建以及<a class="ae jc" href="https://machinelearningmastery.com/divergence-between-probability-distributions/#:~:text=KL%20divergence%20can%20be%20calculated,x)%20%2F%20P(x))" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="jv"> KL发散损失</em> </strong> </a>来生成输出，发散损失是实际和观察到的概率分布之间的差异，它是对称分数以及两个概率分布之间的距离度量，根据VAE，它告诉学习的分布是否离正态分布不远<a class="ae jc" href="https://www.mathsisfun.com/data/standard-normal-distribution.html" rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lm"><img src="../Images/597e9dcbdabdd33fbff6deb52f856064.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*wlEwQYtbsgGPQUCIO_KUaA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">k-l散度</figcaption></figure><p id="83dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以上就是<strong class="ig hi"> <em class="jv"> k-l </em> </strong>空间上分布<strong class="ig hi"> <em class="jv"> P </em> </strong>和<strong class="ig hi"> <em class="jv"> Q </em> </strong>之间的散度<em class="jv"> χ </em></p><p id="4f6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jv">变分自动编码器可以被定义为这样一种自动编码器，其训练被正则化以避免过拟合问题，并且它确保潜在空间吸收产生一些独特和独特结果的丰硕结果。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ln"><img src="../Images/63bc39b6a47ae4e53df28bb8145f24de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*5RtBZE-Tm6VzKdcuPuYZxQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图1.1 VAE建筑</figcaption></figure><p id="a1a6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">变分自动编码器由编码器、解码器和损失函数组成。编码器和解码器是简单的神经网络。当输入数据X通过编码器时，编码器输出潜在状态分布( <a class="ae jc" href="https://byjus.com/jee/mean-and-variance/#:~:text=Mean%20and%20variance%20is%20a,observation%20are%20scattered%20and%20distributed." rel="noopener ugc nofollow" target="_blank"> <em class="jv">均值</em> <strong class="ig hi"> μ </strong> <em class="jv">，方差</em> <strong class="ig hi"> σ </strong> </a> <em class="jv">)，从中采样一个矢量</em> <strong class="ig hi"> <em class="jv"> Z </em> </strong> <em class="jv">)。我们总是假设潜在分布总是高斯分布。输入的</em> <strong class="ig hi"> <em class="jv"> x </em> </strong> <em class="jv">被编码器压缩成更小的尺寸。这通常被称为瓶颈或潜在空间。从中随机抽取一些数据，通过</em> <a class="ae jc" href="https://brilliant.org/wiki/backpropagation/#:~:text=Backpropagation%2C%20short%20for%20%22backward%20propagation,to%20the%20neural%20network's%20weights." rel="noopener ugc nofollow" target="_blank"> <em class="jv">反向传播</em> </a> <em class="jv">对样本进行解码，得到一个新的生成变量。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lo"><img src="../Images/fc5f17109f1309d2dc81665944214a5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/0*BKcQFSUTqDwZg9M3.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">高斯(正态)分布<a class="ae jc" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwiki.analytica.com%2Findex.php%3Ftitle%3DNormal_distribution&amp;psig=AOvVaw0jUMrhalIkqubJpybG9tfQ&amp;ust=1621535823275000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCIi26uqx1vACFQAAAAAdAAAAABAD" rel="noopener ugc nofollow" target="_blank">【来源】</a></figcaption></figure><h1 id="85ba" class="kd ke hh bd kf kg lg ki kj kk lh km kn ko li kq kr ks lj ku kv kw lk ky kz la bi translated">重新参数化技巧</h1><p id="f1cb" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">在分布被抛出编码器之后，样本由随机节点选择，这使得反向传播不可能。我们需要反向传播编码器-解码器模型以使其学习。为了克服反向传播，我们使用带有均值和方差的ε(<strong class="ig hi">ε</strong>)来保持随机性。所以，我们也可以选择一个随机样本，学习潜在的分布状态。在迭代期间，ε保持随机样本，并且编码器输出的参数被更新。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lp"><img src="../Images/59176d2718a7adfe09b72be8e85cdc4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*5Jidw49wWUPiqhd9VoTrTg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图1.2 [ <a class="ae jc" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Ftowardsdatascience.com%2Freparameterization-trick-126062cfd3c3&amp;psig=AOvVaw303cuxrTo2DRaFVa7ag4ZA&amp;ust=1621536311382000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCNCd09Cz1vACFQAAAAAdAAAAABAD" rel="noopener ugc nofollow" target="_blank">来源</a> ]</figcaption></figure><p id="11e7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在分布被抛出编码器之后，样本由随机节点选择，这使得反向传播不可能。我们需要反向传播编码器-解码器模型以使其学习。为了克服反向传播，我们使用带有均值和方差的ε(<strong class="ig hi">ε</strong>)来保持随机性。所以，我们也可以选择一个随机样本，学习潜在的分布状态。在迭代期间，ε保持随机样本，并且编码器输出的参数被更新。</p><h1 id="47d7" class="kd ke hh bd kf kg lg ki kj kk lh km kn ko li kq kr ks lj ku kv kw lk ky kz la bi translated">履行</h1><p id="3ad2" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">让我们试着用PyTorch用<a class="ae jc" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST数据</a>在我们的代码中实现VAE。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lq"><img src="../Images/a67e2e77b8ae0217492e88890c6ec81f.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/0*GtYskBlGj_q4cMzi.gif"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">【<a class="ae jc" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.pinterest.com%2Fpin%2F567523990538356835%2F&amp;psig=AOvVaw2Iu9WO9036SzZyOInsl6nM&amp;ust=1621536019984000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCIjkpeuy1vACFQAAAAAdAAAAABAD" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="80b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">用Torchvision安装PyTorch</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="4f94" class="lw ke hh ls b fi lx ly l lz ma">#command line</span><span id="7164" class="lw ke hh ls b fi mb ly l lz ma">&gt;&gt; pip3 install pip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio===0.7.2 -f <a class="ae jc" href="https://download.pytorch.org/whl/torch_stable.html" rel="noopener ugc nofollow" target="_blank">https://download.pytorch.org/whl/torch_stable.html</a></span><span id="6ce2" class="lw ke hh ls b fi mb ly l lz ma">&gt;&gt; pip3 install numpy</span></pre><p id="bd26" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">导入库</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="7bca" class="lw ke hh ls b fi lx ly l lz ma">import torchvision.transforms as transforms</span><span id="7067" class="lw ke hh ls b fi mb ly l lz ma">import torchvision<br/><br/>from torchvision.utils import save_image</span><span id="7041" class="lw ke hh ls b fi mb ly l lz ma">from torch.utils.data import DataLoader</span><span id="10a0" class="lw ke hh ls b fi mb ly l lz ma">import torch</span><span id="f837" class="lw ke hh ls b fi mb ly l lz ma">import numpy as np</span><span id="d08f" class="lw ke hh ls b fi mb ly l lz ma">import torch.nn as nn</span><span id="0b29" class="lw ke hh ls b fi mb ly l lz ma">import torch.optim as optim</span></pre><p id="da08" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">准备数据</strong></p><p id="ceea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用的是MNIST数据集，因此我们将通过将其大小调整为32x32并转换为张量来对其进行转换。使用有史以来最好的PyTorch数据加载器(每批64个)准备好数据</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="58b2" class="lw ke hh ls b fi lx ly l lz ma">transform = transforms.Compose([</span><span id="d6c3" class="lw ke hh ls b fi mb ly l lz ma">transforms.Resize((32,32)),</span><span id="1247" class="lw ke hh ls b fi mb ly l lz ma">transforms.ToTensor(),</span><span id="7c5d" class="lw ke hh ls b fi mb ly l lz ma">])</span><span id="f8a1" class="lw ke hh ls b fi mb ly l lz ma">trainset = torchvision.datasets.MNIST(</span><span id="0c5c" class="lw ke hh ls b fi mb ly l lz ma">root='./', train=True, download=True, transform=transform</span><span id="e57b" class="lw ke hh ls b fi mb ly l lz ma">)</span><span id="9e5f" class="lw ke hh ls b fi mb ly l lz ma">trainloader = DataLoader(</span><span id="67c5" class="lw ke hh ls b fi mb ly l lz ma">trainset, batch_size=64, shuffle=True</span><span id="c06b" class="lw ke hh ls b fi mb ly l lz ma">)</span><span id="1732" class="lw ke hh ls b fi mb ly l lz ma">testset = torchvision.datasets.MNIST(</span><span id="ed39" class="lw ke hh ls b fi mb ly l lz ma">root='./', train=False, download=True, transform=transform</span><span id="4e71" class="lw ke hh ls b fi mb ly l lz ma">)<br/></span></pre><p id="eb48" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">MNIST图像有一个28x28像素的单通道。</p><p id="06fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据我们的要求定义要使用的设备</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="3296" class="lw ke hh ls b fi lx ly l lz ma">dev = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")</span></pre><p id="7d39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">定义损失函数</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="d9e0" class="lw ke hh ls b fi lx ly l lz ma">def final_loss(bce_loss, mu, logvar):</span><span id="b454" class="lw ke hh ls b fi mb ly l lz ma">    BCE = bce_loss <br/>    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())<br/>    return BCE + KLD</span></pre><p id="2124" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">损失是<a class="ae jc" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" rel="noopener ugc nofollow" target="_blank"> Kullback-Leibler散度</a>和<a class="ae jc" href="https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a" rel="noopener" target="_blank">二元交叉熵</a>的总和</p><p id="f0ea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">定义参数</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="c4e5" class="lw ke hh ls b fi lx ly l lz ma">z_dim =20</span><span id="8a7a" class="lw ke hh ls b fi mb ly l lz ma">lr = 0.001</span><span id="b7ee" class="lw ke hh ls b fi mb ly l lz ma">criterion = nn.BCELoss(reduction='sum')</span><span id="2c25" class="lw ke hh ls b fi mb ly l lz ma">epochs = 1</span><span id="f785" class="lw ke hh ls b fi mb ly l lz ma">batch_size = 64</span></pre><p id="da40" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">创建可变自动编码器模型</strong></p><p id="77cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">编码器由<a class="ae jc" href="https://en.wikipedia.org/wiki/Convolution#:~:text=In%20mathematics%20(in%20particular%2C%20functional,the%20process%20of%20computing%20it." rel="noopener ugc nofollow" target="_blank">卷积</a>、<a class="ae jc" href="https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/" rel="noopener ugc nofollow" target="_blank">批量归一化</a>层和<a class="ae jc" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">泄漏relu组成。</a>编码器的输出是均值向量和标准差向量。</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="c7b3" class="lw ke hh ls b fi lx ly l lz ma"><strong class="ls hi">class</strong> VAE(nn.Module):<br/>    <strong class="ls hi">def</strong> __init__(self):<br/>        super(VAE, self).__init__()</span><span id="ea93" class="lw ke hh ls b fi mb ly l lz ma"><em class="jv">        #encoder</em></span><span id="dbbf" class="lw ke hh ls b fi mb ly l lz ma">        self.conv1 <strong class="ls hi">=</strong> nn.Conv2d(1 ,8 ,4 ,stride <strong class="ls hi">=</strong>2 ,padding <strong class="ls hi">=</strong>1 )</span><span id="0d86" class="lw ke hh ls b fi mb ly l lz ma">        self.BN1 <strong class="ls hi">=</strong> nn.BatchNorm2d(8)</span><span id="f979" class="lw ke hh ls b fi mb ly l lz ma">        self.af1 <strong class="ls hi">=</strong> nn.LeakyReLU()</span><span id="b795" class="lw ke hh ls b fi mb ly l lz ma">        self.conv2 <strong class="ls hi">=</strong> nn.Conv2d(8 ,16 ,4 ,stride <strong class="ls hi">=</strong>2 ,padding <strong class="ls hi">=</strong> 1)</span><span id="8201" class="lw ke hh ls b fi mb ly l lz ma">        self.BN2 <strong class="ls hi">=</strong> nn.BatchNorm2d(16)</span><span id="9702" class="lw ke hh ls b fi mb ly l lz ma">        self.af2 <strong class="ls hi">=</strong> nn.LeakyReLU()</span><span id="37df" class="lw ke hh ls b fi mb ly l lz ma">        self.conv3 <strong class="ls hi">=</strong> nn.Conv2d(16 ,32 ,4 ,stride <strong class="ls hi">=</strong>2 ,padding <strong class="ls hi">=</strong> 1)</span><span id="67da" class="lw ke hh ls b fi mb ly l lz ma">        self.BN3 <strong class="ls hi">=</strong> nn.BatchNorm2d(32)</span><span id="13f1" class="lw ke hh ls b fi mb ly l lz ma">        self.af3 <strong class="ls hi">=</strong> nn.LeakyReLU()</span><span id="dfad" class="lw ke hh ls b fi mb ly l lz ma">        self.conv4 <strong class="ls hi">=</strong> nn.Conv2d(32 ,64 ,4 ,stride <strong class="ls hi">=</strong>2 ,padding <strong class="ls hi">=</strong> 0)</span><span id="585e" class="lw ke hh ls b fi mb ly l lz ma">        self.BN4 <strong class="ls hi">=</strong> nn.BatchNorm2d(64)<br/>        <br/>        self.af4 <strong class="ls hi">=</strong> nn.LeakyReLU()</span></pre><p id="1769" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">提供平均值和对数方差值的全连接层(<strong class="ig hi">瓶颈部分</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="5d85" class="lw ke hh ls b fi lx ly l lz ma">       self.fc1 <strong class="ls hi">=</strong> nn.Linear(64,128)</span><span id="e60f" class="lw ke hh ls b fi mb ly l lz ma">       self.fc_mu <strong class="ls hi">=</strong> nn.Linear(128, z_dim)</span><span id="27ab" class="lw ke hh ls b fi mb ly l lz ma">       self.fca1 <strong class="ls hi">=</strong> nn.LeakyReLU()</span><span id="75c8" class="lw ke hh ls b fi mb ly l lz ma">       self.fcd1 <strong class="ls hi">=</strong> nn.Dropout(0.2)</span><span id="45cd" class="lw ke hh ls b fi mb ly l lz ma">       self.fc_log_var<strong class="ls hi">=</strong> nn.Linear(128, z_dim)</span><span id="5e58" class="lw ke hh ls b fi mb ly l lz ma">       self.fca2 <strong class="ls hi">=</strong> nn.LeakyReLU()</span><span id="c815" class="lw ke hh ls b fi mb ly l lz ma">       self.fcd2 <strong class="ls hi">=</strong> nn.Dropout(0.2)</span></pre><p id="4099" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">解码器只是重构采样的潜在向量表示，并产生原始表示的新变体。</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="f871" class="lw ke hh ls b fi lx ly l lz ma">​</span><span id="b8ce" class="lw ke hh ls b fi mb ly l lz ma">       self.fc2 <strong class="ls hi">=</strong> nn.Linear(z_dim, 64)</span><span id="f3e4" class="lw ke hh ls b fi mb ly l lz ma">       self.da1 <strong class="ls hi">=</strong> nn.LeakyReLU()</span><span id="6945" class="lw ke hh ls b fi mb ly l lz ma">       self.dd1 <strong class="ls hi">=</strong> nn.Dropout(0.2)</span><span id="f866" class="lw ke hh ls b fi mb ly l lz ma">​</span><span id="a9ae" class="lw ke hh ls b fi mb ly l lz ma">       self.deu1 <strong class="ls hi">=</strong> nn.UpsamplingNearest2d(scale_factor<strong class="ls hi">=</strong>2)</span><span id="a7a8" class="lw ke hh ls b fi mb ly l lz ma">       self.dec1 <strong class="ls hi">=</strong> nn.ConvTranspose2d(64 ,64 ,4 ,stride <strong class="ls hi">=</strong>2 ,<br/>                   padding <strong class="ls hi">=</strong> 0)</span><span id="c5a7" class="lw ke hh ls b fi mb ly l lz ma">       self.deb1 <strong class="ls hi">=</strong> nn.BatchNorm2d(64)</span><span id="f35c" class="lw ke hh ls b fi mb ly l lz ma">       self.dea1 <strong class="ls hi">=</strong> nn.LeakyReLU()</span><span id="3688" class="lw ke hh ls b fi mb ly l lz ma">       self.deu2 <strong class="ls hi">=</strong> nn.UpsamplingNearest2d(scale_factor<strong class="ls hi">=</strong>2)</span><span id="1bef" class="lw ke hh ls b fi mb ly l lz ma">       self.dec2 <strong class="ls hi">=</strong> nn.ConvTranspose2d(64 ,32 ,4 ,stride <strong class="ls hi">=</strong>2 ,<br/>                   padding <strong class="ls hi">=</strong> 1)</span><span id="873c" class="lw ke hh ls b fi mb ly l lz ma">       self.deb2 <strong class="ls hi">=</strong> nn.BatchNorm2d(32)</span><span id="78ca" class="lw ke hh ls b fi mb ly l lz ma">       self.dea2 <strong class="ls hi">=</strong> nn.LeakyReLU()</span><span id="f6cf" class="lw ke hh ls b fi mb ly l lz ma">       self.deu3 <strong class="ls hi">=</strong> nn.UpsamplingNearest2d(scale_factor<strong class="ls hi">=</strong>2)</span><span id="b5c7" class="lw ke hh ls b fi mb ly l lz ma">       self.dec3 <strong class="ls hi">=</strong> nn.ConvTranspose2d(32 ,16 ,4 ,stride <strong class="ls hi">=</strong>2 ,<br/>                   padding <strong class="ls hi">=</strong> 1)</span><span id="0864" class="lw ke hh ls b fi mb ly l lz ma">       self.deb3 <strong class="ls hi">=</strong> nn.BatchNorm2d(16)</span><span id="e7d7" class="lw ke hh ls b fi mb ly l lz ma">       self.dea3 <strong class="ls hi">=</strong> nn.LeakyReLU()</span><span id="573a" class="lw ke hh ls b fi mb ly l lz ma">       self.deu4 <strong class="ls hi">=</strong> nn.UpsamplingNearest2d(scale_factor<strong class="ls hi">=</strong>2)</span><span id="3501" class="lw ke hh ls b fi mb ly l lz ma">       self.dec4 <strong class="ls hi">=</strong> nn.ConvTranspose2d(16 ,1 ,4 ,stride <strong class="ls hi">=</strong>2 ,<br/>                   padding <strong class="ls hi">=</strong> 1)</span><span id="2cef" class="lw ke hh ls b fi mb ly l lz ma">       self.dea4 <strong class="ls hi">=</strong> nn.Sigmoid()</span><span id="b993" class="lw ke hh ls b fi mb ly l lz ma">​</span></pre><p id="1e9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">随机向量是从平均向量和标准偏差中抽样出来的。通过应用<a class="ae jc" href="https://machinelearningmastery.com/upsampling-and-transpose-convolution-layers-for-generative-adversarial-networks/" rel="noopener ugc nofollow" target="_blank">上采样和转换图层</a>进一步重建，我使用了上采样和转换图层，得到了更好的结果。</p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="a013" class="lw ke hh ls b fi lx ly l lz ma"><strong class="ls hi">def</strong> sampling(self, mu, log_var):</span><span id="2b55" class="lw ke hh ls b fi mb ly l lz ma">    std <strong class="ls hi">=</strong> torch.exp(log_var <strong class="ls hi">/</strong> 2)</span><span id="a0d7" class="lw ke hh ls b fi mb ly l lz ma">    epsilon <strong class="ls hi">=</strong> torch.randn_like(std)</span><span id="ba6e" class="lw ke hh ls b fi mb ly l lz ma"><strong class="ls hi">    return</strong> mu <strong class="ls hi">+</strong> epsilon <strong class="ls hi">*</strong> std​</span><span id="383e" class="lw ke hh ls b fi mb ly l lz ma"><strong class="ls hi">def</strong> forward(self, x):</span><span id="80ae" class="lw ke hh ls b fi mb ly l lz ma"><em class="jv">    #creating encoder</em></span><span id="62e6" class="lw ke hh ls b fi mb ly l lz ma">    X <strong class="ls hi">=</strong> self.conv1(x)</span><span id="bb37" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.BN1(X)</span><span id="e5ca" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.af1(x)</span><span id="496e" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.conv2(x)</span><span id="e600" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.BN2(x)</span><span id="014f" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.af2(x)</span><span id="a250" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.conv3(x)</span><span id="a3b2" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.BN3(x)</span><span id="2484" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.af3(x)</span><span id="5d95" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.conv4(x)</span><span id="dc16" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.BN4(x)</span><span id="7cea" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.af4(x)</span><span id="6252" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> x.view(x.size()[0], <strong class="ls hi">-</strong>1)</span><span id="66b3" class="lw ke hh ls b fi mb ly l lz ma">    x <strong class="ls hi">=</strong> self.fc1(x)</span><span id="2541" class="lw ke hh ls b fi mb ly l lz ma">    mu <strong class="ls hi">=</strong> self.fc_mu(x)</span><span id="0a26" class="lw ke hh ls b fi mb ly l lz ma">    mu <strong class="ls hi">=</strong> self.fca1(mu)</span><span id="e9ea" class="lw ke hh ls b fi mb ly l lz ma">    mu <strong class="ls hi">=</strong> self.fcd1(mu)</span><span id="e8f9" class="lw ke hh ls b fi mb ly l lz ma">    log_var <strong class="ls hi">=</strong> self.fc_log_var(x)</span><span id="947d" class="lw ke hh ls b fi mb ly l lz ma">    log_var <strong class="ls hi">=</strong> self.fca2(log_var)</span><span id="c770" class="lw ke hh ls b fi mb ly l lz ma">    log_var <strong class="ls hi">=</strong> self.fcd2(log_var)</span><span id="e1da" class="lw ke hh ls b fi mb ly l lz ma"><em class="jv">    #creating sampling</em></span><span id="ce61" class="lw ke hh ls b fi mb ly l lz ma">    z <strong class="ls hi">=</strong> self.fc2(self.sampling(mu, log_var))</span><span id="1660" class="lw ke hh ls b fi mb ly l lz ma">    z <strong class="ls hi">=</strong> self.da1(z)</span><span id="7e5c" class="lw ke hh ls b fi mb ly l lz ma">    z <strong class="ls hi">=</strong> self.dd1(z)</span><span id="696d" class="lw ke hh ls b fi mb ly l lz ma">    z <strong class="ls hi">=</strong> z.view(<strong class="ls hi">-</strong>1,64,1,1)</span><span id="a7bf" class="lw ke hh ls b fi mb ly l lz ma"><em class="jv">    #creating decoder</em></span><span id="4edb" class="lw ke hh ls b fi mb ly l lz ma">    d <strong class="ls hi">=</strong> self.dec1(z)</span><span id="89e3" class="lw ke hh ls b fi mb ly l lz ma">    d <strong class="ls hi">=</strong> self.deb1(d)</span><span id="44ff" class="lw ke hh ls b fi mb ly l lz ma">    d <strong class="ls hi">=</strong> self.dea1(d)</span><span id="3b70" class="lw ke hh ls b fi mb ly l lz ma">    d <strong class="ls hi">=</strong> self.dec2(d)</span><span id="437f" class="lw ke hh ls b fi mb ly l lz ma">    d <strong class="ls hi">=</strong> self.deb2(d)</span><span id="22ac" class="lw ke hh ls b fi mb ly l lz ma">    d <strong class="ls hi">=</strong> self.dea2(d)</span><span id="aecf" class="lw ke hh ls b fi mb ly l lz ma">    d <strong class="ls hi">=</strong> self.dec3(d)</span><span id="ce8f" class="lw ke hh ls b fi mb ly l lz ma">    d <strong class="ls hi">=</strong> self.deb3(d)</span><span id="02d3" class="lw ke hh ls b fi mb ly l lz ma">    d <strong class="ls hi">=</strong> self.dea3(d)</span><span id="d018" class="lw ke hh ls b fi mb ly l lz ma">    d <strong class="ls hi">=</strong> self.dec4(d)</span><span id="f960" class="lw ke hh ls b fi mb ly l lz ma">    recontruction <strong class="ls hi">=</strong> self.dea4(d)</span><span id="e7f2" class="lw ke hh ls b fi mb ly l lz ma"><strong class="ls hi">    return</strong> recontruction, mu, log_var<br/></span></pre><p id="45f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">配置设备</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="1e76" class="lw ke hh ls b fi lx ly l lz ma">device = dev<br/>model = VAE().to(device)</span></pre><p id="9516" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">定义优化器</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="27be" class="lw ke hh ls b fi lx ly l lz ma">optimizer = optim.Adam(model.parameters(), lr=lr)</span></pre><p id="216b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">开始训练</strong></p><pre class="je jf jg jh fd lr ls lt lu aw lv bi"><span id="ebfb" class="lw ke hh ls b fi lx ly l lz ma">grid_images = []<br/>train_loss = []<br/>valid_loss = []<br/></span><span id="4d9f" class="lw ke hh ls b fi mb ly l lz ma"><br/>def validate(model, dataloader, dataset, device, criterion):<br/>    model.eval()<br/>    running_loss = 0.0<br/>    counter = 0<br/>    with torch.no_grad():<br/>        for i, data in tqdm(enumerate(dataloader),   total=int(len(dataset)/batch_size)):<br/>            counter += 1<br/>            data= data[0]<br/>            data = data.to(device)<br/>            reconstruction, mu, logvar = model(data)<br/>            bce_loss = criterion(reconstruction, data)<br/>            loss = final_loss(bce_loss, mu, logvar)<br/>            running_loss += loss.item()<br/>        <br/>            # save the last batch input and output of every epoch<br/>            if i == int(len(dataset)/batch_size) - 1:<br/>                recon_images = reconstruction<br/>    val_loss = running_loss / counter<br/>    return val_loss, recon_images</span><span id="aa6c" class="lw ke hh ls b fi mb ly l lz ma">def train(model, dataloader, dataset, device, optimizer, criterion):<br/>    model.train()<br/>    running_loss = 0.0<br/>    counter = 0<br/>    for i, data in tqdm(enumerate(dataloader), total=int(len(dataset)/batch_size)):<br/>        counter += 1<br/>        data = data[0]<br/>        data = data.to(device)<br/>        optimizer.zero_grad()<br/>        reconstruction, mu, logvar = model(data)<br/>        bce_loss = criterion(reconstruction, data)<br/>        loss = final_loss(bce_loss, mu, logvar)<br/>        loss.backward()<br/>        running_loss += loss.item()<br/>        optimizer.step()<br/>    train_loss = running_loss / counter <br/>    return train_loss</span><span id="9b4e" class="lw ke hh ls b fi mb ly l lz ma">count = 0<br/>for epoch in range(epochs):<br/>    count = count+1<br/>    if count == epochs:<br/>    train_epoch_loss = train(<br/>        model, trainloader, trainset, device, optimizer, criterion<br/>    )<br/>    valid_epoch_loss, recon_images = validate(<br/>        model, testloader, testset, device, criterion<br/>    )<br/>    train_loss.append(train_epoch_loss)<br/>    valid_loss.append(valid_epoch_loss)<br/>    <br/>    save_image(recon_images.cpu(), f"./output{epoch}.jpg")</span><span id="49cd" class="lw ke hh ls b fi mb ly l lz ma">    image_grid = make_grid(recon_images.detach().cpu())<br/>    grid_images.append(image_grid)</span><span id="2237" class="lw ke hh ls b fi mb ly l lz ma">    print(f"Train Loss: {train_epoch_loss:.4f}")<br/>    print(f"Val Loss: {valid_epoch_loss:.4f}")<br/></span></pre><p id="1e9f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，我们的模型被训练，我们的重建图像被保存到定义的路径中。下图是我经过5个历元后得到的重建图像。</p><h2 id="ca4e" class="lw ke hh bd kf mc md me kj mf mg mh kn ip mi mj kr it mk ml kv ix mm mn kz mo bi translated">模型预测法</h2><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mp"><img src="../Images/139abcca191a26d65bae3d5e5cbde018.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/0*JWwIch2eMFzVHcJG"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图P1</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mp"><img src="../Images/f31c6f27744e0fd9a4f2f8eb98dc8aaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:548/0*HqlyeLhJswr1WlEl"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图P2</figcaption></figure><h2 id="e8a4" class="lw ke hh bd kf mc md me kj mf mg mh kn ip mi mj kr it mk ml kv ix mm mn kz mo bi translated">尝试的事情</h2><p id="5d8c" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">尝试使用您自己定制的图像数据重建图像。希望你可以得到一些令人惊讶的结果，只是尝试超调模型与不同的组合。尝试增加纪元的数量。尝试玩Z dim，学习率，卷积层，步幅，等等。</p><h2 id="c380" class="lw ke hh bd kf mc md me kj mf mg mh kn ip mi mj kr it mk ml kv ix mm mn kz mo bi translated">结论</h2><blockquote class="mq mr ms"><p id="2daf" class="ie if jv ig b ih ii ij ik il im in io mt iq ir is mu iu iv iw mv iy iz ja jb ha bi translated">如果使用大量数据和适当的计算能力，VAE可以做得更多。</p></blockquote></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><h2 id="8e6c" class="lw ke hh bd kf mc md me kj mf mg mh kn ip mi mj kr it mk ml kv ix mm mn kz mo bi translated">参考</h2><div class="mw mx ez fb my mz"><a href="https://arxiv.org/abs/1312.6114" rel="noopener  ugc nofollow" target="_blank"><div class="na ab dw"><div class="nb ab nc cl cj nd"><h2 class="bd hi fi z dy ne ea eb nf ed ef hg bi translated">自动编码变分贝叶斯</h2><div class="ng l"><h3 class="bd b fi z dy ne ea eb nf ed ef dx translated">我们如何在有向概率模型中进行有效的推理和学习，在连续的…</h3></div><div class="nh l"><p class="bd b fp z dy ne ea eb nf ed ef dx translated">arxiv.org</p></div></div></div></a></div><div class="mw mx ez fb my mz"><a href="https://arxiv.org/abs/1906.02691" rel="noopener  ugc nofollow" target="_blank"><div class="na ab dw"><div class="nb ab nc cl cj nd"><h2 class="bd hi fi z dy ne ea eb nf ed ef hg bi translated">变分自动编码器简介</h2><div class="ng l"><h3 class="bd b fi z dy ne ea eb nf ed ef dx translated">变分自动编码器提供了一个学习深层潜变量模型和相应的原理框架</h3></div><div class="nh l"><p class="bd b fp z dy ne ea eb nf ed ef dx translated">arxiv.org</p></div></div></div></a></div><div class="mw mx ez fb my mz"><a rel="noopener follow" target="_blank" href="/vitrox-publication/generative-modeling-with-variational-auto-encoder-vae-fc449be9890e"><div class="na ab dw"><div class="nb ab nc cl cj nd"><h2 class="bd hi fi z dy ne ea eb nf ed ef hg bi translated">带有可变自动编码器的创成式建模(VAE)</h2><div class="ng l"><h3 class="bd b fi z dy ne ea eb nf ed ef dx translated">理解变分自动编码器背后的直觉(VAE)</h3></div><div class="nh l"><p class="bd b fp z dy ne ea eb nf ed ef dx translated">medium.com</p></div></div><div class="ni l"><div class="nj l nk nl nm ni nn jn mz"/></div></div></a></div></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><p id="4b20" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我的GitHub:<a class="ae jc" href="https://github.com/AmitNikhade/VAE_RCimages/blob/master/src/Model/model.py" rel="noopener ugc nofollow" target="_blank">https://github.com/AmitNikhade</a></p><p id="be3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">链接到代码:<a class="ae jc" href="https://github.com/AmitNikhade/VAE_RCimages/blob/master/src/Model/model.py" rel="noopener ugc nofollow" target="_blank">https://github.com/AmitNikhade/VAE_RCimages</a></p><p id="ae60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在LinkedIn上关注我</p><p id="d09a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你喜欢这个解释并认为它有用，请鼓掌。谢了。</p></div></div>    
</body>
</html>