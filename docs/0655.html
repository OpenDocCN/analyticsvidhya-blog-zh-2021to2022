<html>
<head>
<title>Web Scrapping</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Web报废</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scrapping-21c4a572a197?source=collection_archive---------26-----------------------#2021-01-25">https://medium.com/analytics-vidhya/web-scrapping-21c4a572a197?source=collection_archive---------26-----------------------#2021-01-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="aea0" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">介绍</h2></div><p id="d9ed" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Web报废是用于从网站提取数据的数据报废。这是一个从不同站点或单个站点提取数据的自动化过程。Web报废包括两个主要方面:</p><p id="ac87" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">1)抓取:</p><p id="a2f7" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">它下载一个页面，并在需要时从中提取数据。这就像当我们使用浏览器时，它会下载网页。</p><p id="c81a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">2)提取:</p><p id="2151" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">提取就像从网页中获取数据一样。</p><p id="6855" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Web报废用于:</p><p id="1556" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">1)从网站上删除数据</p><p id="3d47" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">2)网络和数据挖掘等等</p><h2 id="7ee5" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">IMDB数据报废</h2><p id="c0e3" class="pw-post-body-paragraph iw ix hh iy b iz kn ii jb jc ko il je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">让我们把手弄脏吧…</p><p id="3452" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，让我们导入我们需要的库</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="d807" class="js jt hh kx b fi lb lc l ld le">import re<br/>import requests<br/>from bs4 import  BeautifulSoup<br/>from collections import Counter</span></pre><p id="2d03" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">re:用于正则表达式<br/>请求:用于发送HTTP请求<br/>计数器:用于计数<br/> BeautifulSoup:用于提取数据的主库。</p><p id="4025" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们瞄准我们的目标网站。并从网站获取数据。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="0680" class="js jt hh kx b fi lb lc l ld le">url= "https://www.imdb.com/india/top-rated-indian-                   movies/?sort=ir,desc&amp;mode=simple&amp;page=1"<br/>response = requests.get(url)<br/>soup = BeautifulSoup(response.text,features="html.parser")</span></pre><p id="fdb7" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">URL:存储IMDB站点的链接<br/>响应:从站点<br/>获取页面soup:包含该页面的所有内容。以后可以用它来提取数据。</p><p id="f0b9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们提取数据。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="4084" class="js jt hh kx b fi lb lc l ld le">crew = [a.attrs.get("title")for a in soup.select('td.titleColumn            a')]<br/>title=[ b.attrs.get('alt')for b in soup.select('td.posterColumn              img') ]<br/>ratings=([float(b.attrs.get('data-value')) for b in                  soup.select('td.posterColumn span[name=ir]')])<br/>rel_year=[]<br/>year = [ soup.find_all('span',class_='secondaryInfo')]<br/>for i in year[0]:<br/>rel_year.append(str(i.text).strip('()'))</span></pre><p id="8a9f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">crew:这里，我们使用综合列表来迭代带有类名titleColumn的<table> <td>属性，以提取crew。</td></table></p><p id="a886" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Title:在这里，我们使用综合列表来迭代类名为posterColumn的<table> <td>属性，以提取标题。</td></table></p><p id="5acb" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Ratings:这里，我们使用comprehensive list迭代<table> <td>属性来提取评级。</td></table></p><p id="934b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Year:存储<span>中的year属性，类名为secondaryInfo。</span></p><p id="886b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Rel_year:只是从year中删除'()'</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="c81f" class="js jt hh kx b fi lb lc l ld le">movie_detail = {}<br/>cnt=0<br/>movie_list=[]<br/>for cast,titles,rel,rate in zip(crew,title,rel_year,ratings):<br/>cnt=cnt+1<br/>movie_detail={<br/>"Rank":cnt,<br/>"Title":titles,<br/>"ReleaseDate":rel,<br/>"Ratings":rate,<br/>"Cast":cast<br/>}<br/>movie_list.append(movie_detail)</span></pre><p id="0131" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个代码块，压缩我们所有的变量，将它们绑定到一个字典中，然后将它追加到一个列表中。这使得我们的列表充满了我们的数据。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="bb9a" class="js jt hh kx b fi lb lc l ld le">def successfulYear():<br/>year_count = []<br/>for i in movie_list:<br/>year_count.append(i["ReleaseDate"])<br/>year_count = dict(Counter(year_count))<br/>print("-----------------Most Successful Year of Indian Cinema        According To IMBD--------------------",sep="\n")<br/>print()<br/>totalShare=0.0<br/>totalCount=0<br/>for i in year_count.keys():<br/>percent = (year_count[i]/len(movie_list))*100<br/>print('\t\t\t\t\t\tRelease Year\t Count\t Share(%)')<br/>if year_count[i]&gt;9:<br/>print('\t\t\t\t\t\t',i,"\t\t\t",year_count[i],"\t\t","{:.2f}".form   at(percent))<br/>totalCount = totalCount + year_count[i]<br/>totalShare = totalShare + percent<br/>else:<br/>print('\t\t\t\t\t\t',i, "\t\t\t", year_count[i],         "\t\t\t", "{:.2f}".format(percent))<br/>totalCount = totalCount + year_count[i]<br/>totalShare = totalShare + percent<br/>print("Total number of movies \t\t ",totalCount," Total Number of share ","{:.0f}".format(totalShare))</span></pre><p id="9866" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">此功能有助于确定哪一年的电影发行数量最多，以便确定哪一年的电影发行数量最多并显示出来。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="af23" class="js jt hh kx b fi lb lc l ld le">def favDirector():<br/>director=[]<br/>actor=[]<br/>for i in movie_list:<br/>cast_crew=[str(i["Cast"]).split(',')]<br/>for i in cast_crew:<br/>director.append(str(i[0]).strip(' (dir.)'))<br/>actor.append(str(i[1]).lstrip(' '))<br/>actor.append(str(i[2]).lstrip(' '))<br/>print("-------------------List of Top Director in Descending Order---- ----------")<br/>print(Counter(director))<br/>print("-------------------List of Top Actors/Actress in Descending      Order--------------")<br/>print(Counter(actor))</span></pre><p id="2a57" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个代码块有助于查看哪个导演发行的电影数量最多或者更成功。</p><pre class="ks kt ku kv fd kw kx ky kz aw la bi"><span id="9e5a" class="js jt hh kx b fi lb lc l ld le">successfulYear()<br/>print('----------------------------------------')<br/>favDirector()</span></pre><h2 id="3e6d" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">结论</h2><p id="103d" class="pw-post-body-paragraph iw ix hh iy b iz kn ii jb jc ko il je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">所以这都是关于网络废弃和网络废弃的一个小项目。</p><p id="060b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae lf" href="https://github.com/ParthNipunDave/WebScrapping" rel="noopener ugc nofollow" target="_blank">点击此处</a>获取该项目的GitHub链接</p></div></div>    
</body>
</html>