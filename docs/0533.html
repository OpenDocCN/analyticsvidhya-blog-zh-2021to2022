<html>
<head>
<title>Analyzing IMDb’s Top 250 movies: Part 1; Let scrape some data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分析IMDb电影250强:第一部分:让我们收集一些数据</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/analyzing-imdbs-top-250-movies-part-1-let-scrape-some-data-a422adc3eb8d?source=collection_archive---------3-----------------------#2021-01-20">https://medium.com/analytics-vidhya/analyzing-imdbs-top-250-movies-part-1-let-scrape-some-data-a422adc3eb8d?source=collection_archive---------3-----------------------#2021-01-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="6a69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">网页抓取IMDb前250部电影的数据，对数据进行统计分析</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/2fb5163784cd899930811136e81ebef9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*O5D3RNKuPBzHiuWN"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">丹尼斯·简斯在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</figcaption></figure><h1 id="1ebc" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">介绍📔</h1><p id="5117" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">上个月，当我们和一个朋友出去喝几杯时，我们开始讨论今年上映的许多电影，就像在这种情况下人们会做的那样。在我们冒险看电影的过程中，我被朋友问我的一个问题引起了兴趣；</p><blockquote class="kx ky kz"><p id="b44d" class="if ig la ih b ii ij ik il im in io ip lb ir is it lc iv iw ix ld iz ja jb jc hb bi translated"><strong class="ih hj">什么因素决定一部电影是否成功？</strong></p></blockquote><p id="f9f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这引起了我足够的兴趣，以至于我想对这些电影进行统计分析。得益于<a class="ae jt" href="https://www.imdb.com/" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"/></a><strong class="ih hj"/>(互联网电影数据库)，获取电影数据相当容易。顺便提一下，值得一提的是IMDb提供了一个相当庞大的数据字典，有将近700万个标题。但是这是一个我不想打开的难题(我以后会深入研究它，但至少不是现在)。这里，我将使用IMDb排行榜中排名最高的电影(IMDb前250)。</p><h1 id="69fe" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">让我们收集数据🔍</h1><p id="76a6" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">分析IMDb 250强数据的第一步是从网站上抓取数据，并从中创建一个合理的数据集。Python为我提供了一些有用的包，如<a class="ae jt" href="https://pypi.org/project/beautifulsoup4/" rel="noopener ugc nofollow" target="_blank"><em class="la">beautiful soup</em></a><em class="la"/>和<a class="ae jt" href="https://pypi.org/project/requests/" rel="noopener ugc nofollow" target="_blank"><em class="la">Requests</em></a><em class="la"/>，让我可以轻松地从这些电影中抓取有用的数据。让我们首先分析页面及其底层HTML代码，以获得所需的数据。</p><blockquote class="kx ky kz"><p id="255e" class="if ig la ih b ii ij ik il im in io ip lb ir is it lc iv iw ix ld iz ja jb jc hb bi translated">对于那些不想了解整个网络废弃过程的人来说。这里是<a class="ae jt" href="https://github.com/SDhanush163/NoMoIMDb/blob/main/imdb-data-processing.ipynb" rel="noopener ugc nofollow" target="_blank"> Github链接</a>到Python Jupyter笔记本。(<em class="hi">如果你觉得有用就去做⭐️吧💛)</em></p></blockquote><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es le"><img src="../Images/04359d432680c28c9804a5bdd5a02150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pG27IpJ8ZvxF1TZy0Mwjjw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">imdb.com/chart/top的IMDb顶级电影(<a class="ae jt" href="https://www.imdb.com/chart/top" rel="noopener ugc nofollow" target="_blank">)和相应的源代码</a></figcaption></figure><p id="28ac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该页面包括显示前250部电影的表格。表格中的每一行都包含这部电影的海报、它的排名和标题，以及它的IMDb评分(它还有一些其他列，但这些是我感兴趣的)。电影的标题是一个超链接，将我们带到特定电影的详细信息页面。我感兴趣的就是这个链接。一旦有了这些链接，我就可以深入到每部电影的各个页面，获得更多的数据。</p><pre class="je jf jg jh fd lf lg lh li aw lj bi"><span id="938d" class="lk jv hi lg b fi ll lm l ln lo">url = 'https://www.imdb.com/chart/top'<br/>url_text = requests.get(url).text<br/>soup = BeautifulSoup(url_text, 'html.parser'</span><span id="5922" class="lk jv hi lg b fi lp lm l ln lo">template = 'https://www.imdb.com%s'<br/><strong class="lg hj">title_links </strong>= [template % a.attrs.get('href') <em class="la">for</em> a <em class="la">in </em>url_soup.select( 'td.titleColumn a' )]</span></pre><p id="9b01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过这个简单的代码，我获得了所有电影的链接。现在只需要浏览每一页(当然是用for循环)并收集我需要的数据。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/b787367c157acd5d67825dc9c9e7a551.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gD7Ok6KQpnhpPDPALPb7aQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://www.imdb.com/title/tt0111161/" rel="noopener ugc nofollow" target="_blank">《肖申克的救赎》</a>展示div的电影页面</figcaption></figure><p id="5863" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在来谈谈整个web报废操作的主要内容。第一组也是最重要的一组数据来自标题栏。所有这些数据都打包在一个类名为<code class="du lr ls lt lg b">title_bar_wrapper</code>的div中。</p><p id="b50b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="la">由此，我们可以导出以下字段:</em></p><p id="0a1d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">🚀电影名称<br/>🚀发布日期和年份<br/>🚀IMDb电影分级<br/>🚀审查委员会对电影的评价(U，U/A，R等。)<br/>🚀其总运行时间<br/>🚀它的类型</p><pre class="je jf jg jh fd lf lg lh li aw lj bi"><span id="b9db" class="lk jv hi lg b fi ll lm l ln lo"><strong class="lg hj">movie_name</strong> = (page_soup.find("div",{ "class":"title_wrapper" }).get_text( strip=True ).split('|')[0]).split('(')[0]</span><span id="843a" class="lk jv hi lg b fi lp lm l ln lo"><strong class="lg hj">year </strong>= ((page_soup.find("div",{ "class":"title_wrapper" }).get_text( strip=True ).split('|')[0]).split('(')[1]).split(')')[0]</span><span id="3487" class="lk jv hi lg b fi lp lm l ln lo"><strong class="lg hj">rating </strong>= page_soup.find("span",{"itemprop":"ratingValue"}).text<br/><strong class="lg hj">vote_count </strong>= page_soup.find("span",{"itemprop":"ratingCount"}).text</span><span id="81d7" class="lk jv hi lg b fi lp lm l ln lo">subtext= page_soup.find("div",{ "class":"subtext" }).get_text( strip=True ).split('|' )</span></pre><p id="ab71" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的代码把上面提到的所有字段和潜台词都刮了。潜台词包含其余的数据。但是有一个问题，很少有电影被审查委员会分级。当电影未分级时，潜台词数组没有它的字段。所以我想出了下面的代码来解决这个问题。当电影未分级时，潜台词数组没有它的字段。因此，在这种情况下，我只是给这些电影增加了一个名为<code class="du lr ls lt lg b">No Rating</code>的审查评级。</p><pre class="je jf jg jh fd lf lg lh li aw lj bi"><span id="020d" class="lk jv hi lg b fi ll lm l ln lo"><em class="la">if</em> len(subtext) &lt; 4:<br/>   <em class="la"># Setting values when the movie is unrated<br/>   </em><strong class="lg hj">censor_rating </strong>= "No rating"<br/>   <strong class="lg hj">movie_length </strong>= subtext[0]</span><span id="9453" class="lk jv hi lg b fi lp lm l ln lo"><strong class="lg hj">genre_list </strong>= subtext[1].split(',')<br/>   <em class="la">while</em> len(genre_list) &lt; 4: <br/>      genre_list.append(' ')</span><span id="89db" class="lk jv hi lg b fi lp lm l ln lo">release_date_and_country = subtext[2].split('(')<br/>   <strong class="lg hj">release_date </strong>= release_date_and_country[0]</span><span id="f4fc" class="lk jv hi lg b fi lp lm l ln lo"><em class="la">else</em>:<br/>   <strong class="lg hj">censor_rating </strong>= subtext[0]<br/>   <strong class="lg hj">movie_length </strong>= subtext[1]<br/>   <br/>   <strong class="lg hj">genre_list </strong>= subtext[2].split(',')<br/>   <em class="la">while</em> len(genre_list) &lt; 4: <br/>      genre_list.append(' ')</span><span id="6079" class="lk jv hi lg b fi lp lm l ln lo">release_date_and_country = subtext[3].split('(')<br/>   <strong class="lg hj">release_date </strong>= release_date_and_country[0]</span></pre><p id="3406" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在海报、视频和电影图片的下面，是我能收集到的下一组数据点；剧情概要(<em class="la">我真的没有这个打算。我现在只是把它拼凑起来，因为如果我决定用它来执行NLP或其他什么的话，我就懒得做了</em>、电影导演的名字、电影的编剧以及电影中的主要明星。情节摘要更容易，因为它可以从类名为<code class="du lr ls lt lg b">summary_text</code>的div中的文本中提取。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lq"><img src="../Images/7e45109f9c9a89372026b9b2b6254935.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i2jcabu2U0JLKidk_vcK3g.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">电影《肖申克的救赎》的剧情概要和其他与剧情相关的演职员表</figcaption></figure><p id="9f64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">删除其余的细节会稍微棘手一些。其他三个细节都用类名<code class="du lr ls lt lg b">credit_summary_item</code>包装在一个单独的div中。这意味着我必须找到一种方法，将它们作为一个单一的对象，然后将它们分开。这就是BeautifulSoup的<code class="du lr ls lt lg b">find_all()</code>方法派上用场的地方。这让我可以一次刮下所有的div，并把它们列成一个清单。一旦我有了这个列表，我可以从列表中弹出每一个，就这样，我得到了我想要的数据。</p><pre class="je jf jg jh fd lf lg lh li aw lj bi"><span id="9396" class="lk jv hi lg b fi ll lm l ln lo"><strong class="lg hj"># Getting the movie summary</strong><br/><strong class="lg hj">summary </strong>= page_soup.find("div", {"class":"summary_text"}).get_text( strip=True ).strip()</span><span id="5b86" class="lk jv hi lg b fi lp lm l ln lo"><strong class="lg hj"># Getting the credits for the director and writers</strong><br/>credit_summary = []</span><span id="ea5a" class="lk jv hi lg b fi lp lm l ln lo">for summary_item in page_soup.find_all("div",{ "class" : "credit_summary_item" }):<br/>   credit_summary.append(re.split( ',|:|\|' ,summary_item.get_text( strip=True )))</span><span id="6860" class="lk jv hi lg b fi lp lm l ln lo"><strong class="lg hj">stars </strong>= credit_summary.pop()[1:4]<br/><strong class="lg hj">writers </strong>= credit_summary.pop()[1:3]<br/><strong class="lg hj">director </strong>= credit_summary.pop()[1:]</span><span id="c1c4" class="lk jv hi lg b fi lp lm l ln lo">while len(stars) &lt; 3:<br/>   stars.append(" ")</span><span id="8f4c" class="lk jv hi lg b fi lp lm l ln lo">while len(writers) &lt; 2: <br/>   writers.append(" ")</span><span id="a9ca" class="lk jv hi lg b fi lp lm l ln lo">writer_1, writer_2 = writers<br/>writer_1 = writer_1.split('(')[0]<br/>writer_2 = writer_2.split('(')[0]</span></pre><p id="44b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我感兴趣的最后一个部分是页面底部的数据量极大的部分，称为电影细节。该部分包含大量数据点，例如</p><p id="242f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">🚀电影拍摄的国家。<br/>🚀电影中使用的语言。<br/>🚀票房详情。<br/>🚀制作公司的详细信息和其他类似的详细信息。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lu"><img src="../Images/f4921981b9aa0772b922a3b8a2f9e67c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ydKtD7ZOOEnLyRCNKiwvlg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">电影详情<a class="ae jt" href="https://www.imdb.com/title/tt0111161/" rel="noopener ugc nofollow" target="_blank">肖申克的救赎</a></figcaption></figure><p id="56d2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，这一部分也和包含导演、编剧和明星的部分有着同样的困境；因为它们都在不同的div中，有相同的类名<code class="du lr ls lt lg b">txt-block</code>。因此，虽然使用前面的方法可能有效，但我发现更好的解决方法是使用字典并将所有这些HTML资源存储在这个字典中。这样，我可以很容易地使用提供的名称获得我正在寻找的数据，处理它，并获得我想要的数据点。在这种情况下，这是一种更好的方法，因为我有许多具有相同类名的字段，并且我需要其中的几个数据点。</p><pre class="je jf jg jh fd lf lg lh li aw lj bi"><span id="c647" class="lk jv hi lg b fi ll lm l ln lo">box_office_details = []<br/>box_office_dictionary = {'Country':'','Language':'','Budget':'', 'Opening Weekend USA':'','Gross USA':'','Cumulative Worldwide Gross':'','Production Co':''}</span><span id="2bcb" class="lk jv hi lg b fi lp lm l ln lo"><em class="la">for</em> details <em class="la">in</em> page_soup.find_all("div",{"class":"txt-block"}):<br/>   detail = details.get_text(strip=True).split(':')</span><span id="c06b" class="lk jv hi lg b fi lp lm l ln lo"><em class="la">if</em> detail[0] in box_office_dictionary:<br/>    box_office_details.append(detail)</span><span id="82e5" class="lk jv hi lg b fi lp lm l ln lo"><em class="la">for</em> detail <em class="la">in</em> box_office_details:<br/>   <em class="la">if</em> detail[0] in box_office_dictionary:<br/>      box_office_dictionary.update({detail[0] : detail[1]})</span><span id="e08f" class="lk jv hi lg b fi lp lm l ln lo"><strong class="lg hj">country </strong>= box_office_dictionary['Country'].split("|")<br/><em class="la">while</em> len(country) &lt; 4: <br/>   country.append(' ')</span><span id="45c3" class="lk jv hi lg b fi lp lm l ln lo"><strong class="lg hj">language</strong> = box_office_dictionary['Language'].split("|")<br/><em class="la">while</em> len(language) &lt; 5: <br/>   language.append(' ')</span><span id="3959" class="lk jv hi lg b fi lp lm l ln lo"><strong class="lg hj">budget </strong>= box_office_dictionary['Budget'].split('(')[0]<br/><strong class="lg hj">opening_week_usa </strong>= ','.join((box_office_dictionary['Opening Weekend USA'].split(' ')[0]).split(',')[:-1])<br/><strong class="lg hj">gross_usa </strong>= box_office_dictionary['Gross USA']<br/><strong class="lg hj">gross_worldwide </strong>= box_office_dictionary['Cumulative Worldwide Gross'].split(' ')[0]</span><span id="c7db" class="lk jv hi lg b fi lp lm l ln lo"><strong class="lg hj">production_list </strong>= box_office_dictionary['Production Co'].split('See more')[0]<br/><strong class="lg hj">production </strong>= production_list.split(',')<br/><em class="la">while</em> len(production) &lt; 4: <br/>   production.append(" ")</span></pre><h1 id="4090" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">保存数据💾</h1><p id="a981" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">万岁。我终于从这些电影中搜集到了所有的数据。现在我可以把这些数据存储在某个地方，然后不用它做任何事情…我只是在开玩笑(在我的博客中使用幽默——✅😆).我想以两种形式存储数据；作为JSON对象和DataFrame。DataFrame允许我使用Python轻松地提取我需要的特性和相关性，并将这些数据存储为JSON对象将使其他编程语言使用这些数据变得容易。所以让我们从简单的开始。</p><h2 id="e288" class="lk jv hi bd jw lv lw lx ka ly lz ma ke iq mb mc ki iu md me km iy mf mg kq mh bi translated">1.存储为JSON对象</h2><p id="dc6d" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">现在我已经收集了所有我想要的数据，我创建了一个包含这些数据点的字典，并用它创建了一个列表，为所有250部电影创建了一个电影细节数组。</p><pre class="je jf jg jh fd lf lg lh li aw lj bi"><span id="d600" class="lk jv hi lg b fi ll lm l ln lo">imdb_movie_list = []</span><span id="4165" class="lk jv hi lg b fi lp lm l ln lo"><strong class="lg hj"><em class="la">... #For loop<br/></em>movie_dict</strong> = { 'ranking': i+1, 'movie_name': movie_name, 'url': page_url, 'year': year, 'rating': rating, 'vote_count': vote_count, 'summary': summary, 'production': production, 'director': director, 'writers': [writer_1, writer_2], 'stars': stars, 'genres': genre_list, 'release_date': release_date, 'censor_rating': censor_rating, 'movie_length': movie_length, 'country': country, 'language': language, 'budget': budget, 'gross_worldwide': gross_worldwide, 'gross_usa': gross_usa,'opening_week_usa': opening_week_usa}<br/><strong class="lg hj"><em class="la">... #For loop ends here</em></strong></span><span id="43ec" class="lk jv hi lg b fi lp lm l ln lo">imdb_movie_list.append(movie_dict)</span></pre><p id="fdae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我还在混合中添加了一个时间戳，这样我就可以跟踪我下一次抓取数据的时间，为了将它存储为一个JSON对象，我使用Python的包<code class="du lr ls lt lg b">json</code>并将数据转储到<code class="du lr ls lt lg b">imdb_movies_data.json</code>文件中。</p><pre class="je jf jg jh fd lf lg lh li aw lj bi"><span id="304c" class="lk jv hi lg b fi ll lm l ln lo">timestamp =  datetime.now().strftime('%Y-%m-%dT%H:%M:%S.%f')<br/><strong class="lg hj">imdb_list </strong>= {<br/>   "timestamp" : timestamp,<br/>   "imdb_movies" : imdb_movie_list<br/>}</span><span id="94f2" class="lk jv hi lg b fi lp lm l ln lo"><em class="la">with</em> open('imdb_movies_data.json', 'w') <em class="la">as</em> file:<br/>   json.dump(imdb_list, file)</span></pre><h2 id="ccf9" class="lk jv hi bd jw lv lw lx ka ly lz ma ke iq mb mc ki iu md me km iy mf mg kq mh bi translated">2.将数据帧存储到CSV中</h2><p id="0ca6" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">Pandas DataFrame是一种数据结构，包含带有相应标签的二维数据。它比表格或电子表格更快、更容易使用、更强大，因为它们是Python和NumPy生态系统不可或缺的一部分。在外部，我可以将数据帧保存为CSV(逗号分隔值)文件，供以后随时使用。</p><p id="4509" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我需要创建数据帧。我选择用属性列表来设置列。我有33列，并将某些属性分成多列，而不是将它们保存为列表对象。这将减少我的工作量，当我不得不从这个属性集中提取数据时。</p><pre class="je jf jg jh fd lf lg lh li aw lj bi"><span id="ce23" class="lk jv hi lg b fi ll lm l ln lo">dataframe_columns = [ 'ranking', 'movie_name', 'url', 'year', 'rating', 'vote_count', 'summary', 'production_1', 'production_2', 'production_3', 'director', 'writer_1', 'writer_2', 'star_1', 'star_2', 'star_3', 'genre_1', 'genre_2', 'genre_3', 'genre_4','release_date', 'censor_rating', 'movie_length', 'country_1', 'country_2', 'country_3', 'country_4', 'language_1', 'language_2', 'language_3', 'language_4', 'language_5', 'budget', 'gross_worldwide', 'gross_usa','opening_week_usa']</span><span id="d1f4" class="lk jv hi lg b fi lp lm l ln lo">dataframe = pd.DataFrame(columns=dataframe_columns)</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mi"><img src="../Images/caacea603b9efdfeecede2d70d421207.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Ipx1HdSmL0LmnTZ-4P-Fg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">使用列表设置列的空数据帧</figcaption></figure><p id="4d9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建数据帧的最后一步是存储数据。这很容易实现，因为我已经聪明地将所有数据存储在所有电影的字典列表中。我现在要做的就是遍历列表，将字典设置到相应的列。</p><pre class="je jf jg jh fd lf lg lh li aw lj bi"><span id="c285" class="lk jv hi lg b fi ll lm l ln lo">for i in range(0, len(imdb_movie_list)):<br/> dataframe.at[i,'ranking'] = imdb_movie_list[i]['ranking']<br/> dataframe.at[i,'movie_name'] = imdb_movie_list[i]['movie_name']<br/> dataframe.at[i,'url'] = imdb_movie_list[i]['url']<br/> dataframe.at[i,'year'] = imdb_movie_list[i]['year']<br/> dataframe.at[i,'rating'] = imdb_movie_list[i]['rating']<br/> dataframe.at[i,'vote_count'] = imdb_movie_list[i]['vote_count']<br/> dataframe.at[i,'summary'] = imdb_movie_list[i]['summary']</span><span id="84c8" class="lk jv hi lg b fi lp lm l ln lo">dataframe.at[i,'production_1']= imdb_movie_list[i]['production'][0]<br/> dataframe.at[i,'production_2']= imdb_movie_list[i]['production'][1]<br/> dataframe.at[i,'production_3']= imdb_movie_list[i]['production'][2]<br/> <br/> dataframe.at[i,'director'] = imdb_movie_list[i]['director'][0]<br/> dataframe.at[i,'writer_1'] = imdb_movie_list[i]['writers'][0]<br/> dataframe.at[i,'writer_2'] = imdb_movie_list[i]['writers'][1]<br/> dataframe.at[i, 'star_1'] = imdb_movie_list[i]['stars'][0]<br/> dataframe.at[i, 'star_2'] = imdb_movie_list[i]['stars'][1]<br/> dataframe.at[i, 'star_3'] = imdb_movie_list[i]['stars'][2]</span><span id="c215" class="lk jv hi lg b fi lp lm l ln lo">dataframe.at[i,'genre_1'] = imdb_movie_list[i]['genres'][0]<br/> dataframe.at[i,'genre_2'] = imdb_movie_list[i]['genres'][1]<br/> dataframe.at[i,'genre_3'] = imdb_movie_list[i]['genres'][2]<br/> dataframe.at[i,'genre_4'] = imdb_movie_list[i]['genres'][3]</span><span id="3a8e" class="lk jv hi lg b fi lp lm l ln lo">dataframe.at[i,'release_date'] = imdb_movie_list[i]['release_date']<br/> dataframe.at[i,'censor_rating'] = imdb_movie_list[i]['censor_rating']<br/> dataframe.at[i,'movie_length'] = imdb_movie_list[i]['movie_length']</span><span id="67e7" class="lk jv hi lg b fi lp lm l ln lo">dataframe.at[i,'country_1'] = imdb_movie_list[i]['country'][0]<br/> dataframe.at[i,'country_2'] = imdb_movie_list[i]['country'][1]<br/> dataframe.at[i,'country_3'] = imdb_movie_list[i]['country'][2]<br/> dataframe.at[i,'country_4'] = imdb_movie_list[i]['country'][3]</span><span id="54eb" class="lk jv hi lg b fi lp lm l ln lo">dataframe.at[i,'language_1'] = imdb_movie_list[i]['language'][0]<br/> dataframe.at[i,'language_2'] = imdb_movie_list[i]['language'][1]<br/> dataframe.at[i,'language_3'] = imdb_movie_list[i]['language'][2]<br/> dataframe.at[i,'language_4'] = imdb_movie_list[i]['language'][3]<br/> dataframe.at[i,'language_5'] = imdb_movie_list[i]['language'][4]</span><span id="3eaa" class="lk jv hi lg b fi lp lm l ln lo">dataframe.at[i,'budget'] = imdb_movie_list[i]['budget']<br/> dataframe.at[i,'gross_worldwide'] = imdb_movie_list[i]['gross_worldwide']<br/> dataframe.at[i,'gross_usa'] = imdb_movie_list[i]['gross_usa']<br/> dataframe.at[i,'opening_week_usa'] = imdb_movie_list[i]['opening_week_usa']</span><span id="44f7" class="lk jv hi lg b fi lp lm l ln lo">dataframe = dataframe.set_index(['ranking'], drop=False)</span><span id="07fa" class="lk jv hi lg b fi lp lm l ln lo">dataframe.to_csv('imdb_movies_data.csv')</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mj"><img src="../Images/39c881881e164524bfbfe114bc076a89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eyGERUzarAQebc__jMuCOA.png"/></div></div></figure><p id="8727" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是我对IMDb 250强电影分析的第一部分。收集了所有这些数据后，接下来是提取我喜欢的数据集，并对它们进行统计分析。一旦分析完成，我将与你分享我的所有发现。</p><p id="8954" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">同样，完整的代码可以在Python Jupyter Notebook的GitHub上<a class="ae jt" href="https://github.com/SDhanush163/NoMoIMDb/blob/main/imdb-data-processing.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>获得。如果你喜欢，就把它丢给⭐️。</p><p id="ba52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望您喜欢并从这篇文章中学到一些关于收集数据的有趣的东西。谢谢你陪我走过这段旅程。如果您对此有任何问题、疑问或想法，请随时👏并评论。谢谢！</p></div><div class="ab cl mk ml gp mm" role="separator"><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp mq"/><span class="mn bw bk mo mp"/></div><div class="hb hc hd he hf"><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mr"><img src="../Images/ed6ab48771ef8d86dd8d15784eab1e24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xvQoQkquloHgU_mH"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">照片由<a class="ae jt" href="https://unsplash.com/@priscilladupreez?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">普里西拉·杜·普里兹</a>在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure></div></div>    
</body>
</html>