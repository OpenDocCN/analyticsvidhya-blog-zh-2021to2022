<html>
<head>
<title>Regression Analysis in 1 minute</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">1分钟内的回归分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/regression-analysis-90d2944f7ecb?source=collection_archive---------27-----------------------#2021-01-25">https://medium.com/analytics-vidhya/regression-analysis-90d2944f7ecb?source=collection_archive---------27-----------------------#2021-01-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/aaebc4e188a24bea502d3438296d7450.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F4JzgiTIUfFePLBj4A_JPw.jpeg"/></div></div></figure><p id="8f11" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">回归分析是一种测量或估计变量之间关系的技术。</p><p id="0ccc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">回归分析根据自变量的值提供因变量<strong class="ir hi">的估计值。</strong></p><p id="c4ac" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">回归线描述了存在于<strong class="ir hi"> x </strong>和<strong class="ir hi"> y </strong>之间的平均关系。</p><blockquote class="jn jo jp"><p id="805a" class="ip iq jq ir b is it iu iv iw ix iy iz jr jb jc jd js jf jg jh jt jj jk jl jm ha bi translated"><strong class="ir hi">相关分析和回归分析的区别</strong></p></blockquote><ol class=""><li id="bd39" class="ju jv hh ir b is it iw ix ja jw je jx ji jy jm jz ka kb kc bi translated"><strong class="ir hi">相关系数</strong>是对<strong class="ir hi"> x </strong>和<strong class="ir hi"> y </strong>之间 <strong class="ir hi">共变异性</strong>程度的<strong class="ir hi">度量，而<strong class="ir hi">回归分析</strong>的目的是研究</strong>的<strong class="ir hi">性质。</strong></li><li id="50d4" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated">在<strong class="ir hi">相关性分析</strong>中<strong class="ir hi"> rₓᵧ或rᵧₓ都是对称的(rₓᵧ=rᵧₓ) </strong>。在<strong class="ir hi">回归分析中，bₓᵧ和bᵧₓ </strong>是<strong class="ir hi">不对称(bₓᵧ =/= bᵧₓ) </strong>。</li><li id="9078" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated">在<strong class="ir hi">相关性分析</strong>中，我们不能说<strong class="ir hi">一个变量是“原因”</strong>而<strong class="ir hi">另一个是“结果”</strong>，但是在<strong class="ir hi">回归分析</strong>中，可以研究<strong class="ir hi">因果关系</strong>。</li><li id="7bd4" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated">相关性分析中可能存在<strong class="ir hi">无意义相关性</strong>与<strong class="ir hi">无实际相关性</strong><em class="jq">收入增加和体重增加的例子。</em>回归分析上没有这些东西。</li><li id="0834" class="ju jv hh ir b is kd iw ke ja kf je kg ji kh jm jz ka kb kc bi translated"><strong class="ir hi">相关系数</strong>是<strong class="ir hi">独立于原点和标度</strong>的变化。<strong class="ir hi">回归系数</strong>与原点变化无关，而<strong class="ir hi">与标度无关。</strong></li></ol><blockquote class="jn jo jp"><p id="ae7c" class="ip iq jq ir b is it iu iv iw ix iy iz jr jb jc jd js jf jg jh jt jj jk jl jm ha bi translated"><strong class="ir hi">相似之处</strong></p></blockquote><p id="f3f9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">相关系数(r)和回归系数(bₓᵧ和bᵧₓ)总是具有相同的符号。</p></div></div>    
</body>
</html>