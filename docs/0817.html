<html>
<head>
<title>A Comparative Study of Classification Techniques using R packages on Medical Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">医学数据R包分类技术的比较研究</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-study-on-performance-of-classification-techniques-on-medical-data-using-r-packages-a892157d8da4?source=collection_archive---------18-----------------------#2021-02-01">https://medium.com/analytics-vidhya/a-study-on-performance-of-classification-techniques-on-medical-data-using-r-packages-a892157d8da4?source=collection_archive---------18-----------------------#2021-02-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/581d72f3a17b3c0e1ea46bd86b28e6c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hnYD7Nw7lI_f9Ui3SIUCfA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">米利安·耶西耶在<a class="ae it" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="73c5" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated"><strong class="ak">简介</strong></h1><p id="a1a4" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">医疗保健信息系统捕获数据库中的数据，用于研究和分析。数据量的增长使得传统的手动研究分析效率低下。这导致了健康研究中自动决策支持系统的发展。为了这个目的，许多计算机化数据分析的方法已经被考虑和检验。数据挖掘的主要目的是帮助决策者理解不同情况下的特征，并通过分析可用数据来预测未来事件。众多数据挖掘技术之一是<strong class="ju hi">分类</strong>方法。</p><p id="1e17" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><a class="ae it" href="https://machinelearningmastery.com/types-of-classification-in-machine-learning/" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hi">分类</strong> </a> <strong class="ju hi">将数据集中的每个成员识别到预定义的一组类或组中</strong>。分类是发现将数据项映射到几个预定义类别之一的学习函数。虽然数据挖掘传统上与从大量数据中提取知识有关，但现实世界中的数据挖掘技术面临着从较小的数据集中提取知识的问题。基于数据集和分类方法的集合，数据挖掘器面临两个问题。第一个问题是为一个给定的数据集归纳出最准确的模型，第二个问题是在看不见的数据上具有所提出的模型的真正准确性。有不同的分类器可用，选择最准确的<a class="ae it" href="https://dzone.com/articles/introduction-to-classification-algorithms" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hi">分类器</strong> </a>是一个基本问题。但是，在较小的数据集中实现较高的准确性存在问题，这可以通过使用k折叠交叉验证来实现。因此，本工作研究了k在交叉验证中的影响，以在<strong class="ju hi"><em class="kv"/></strong>乳腺癌和<strong class="ju hi"> <em class="kv">皮马印度</em> </strong> <strong class="ju hi"> <em class="kv">糖尿病</em> </strong>数据集分类中获得更好的结果。</p></div><div class="ab cl kw kx go ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ha hb hc hd he"><h1 id="c3ef" class="iu iv hh bd iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn lh jp jq jr bi translated"><strong class="ak">方法和材料</strong></h1><p id="7ee6" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated"><strong class="ju hi"> <em class="kv">乳腺癌</em> </strong>数据集包含由九个属性表征的699个实例。<strong class="ju hi"> <em class="kv">皮马印第安人糖尿病</em> </strong>有768个实例，由八个特征描述，用于预测糖尿病的存在或不存在。这些模型在<a class="ae it" href="https://www.r-project.org/" rel="noopener ugc nofollow" target="_blank"> R </a>中可用，这是一个在GNU GPL下授权的开源软件。</p><p id="7788" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">K-fold用于测量<a class="ae it" href="https://en.wikipedia.org/wiki/Predictive_modelling" rel="noopener ugc nofollow" target="_blank">预测模型</a>的准确性。在k重交叉验证方法中，原始样本被分成k个大小相等的子集。在k个子集中，保留一个子集作为测试模型的验证数据，剩余的k-1个子集用作训练数据。其中一个子集用作测试集，其他k-1个子集聚集在一起形成训练集。然后计算所有k次试验的平均准确度。使用k-fold交叉验证的优点是测试整个数据集。</p><p id="1162" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">在本研究中，使用3重、5重和10重交叉验证将数据分为两类，即<strong class="ju hi">训练</strong>和<strong class="ju hi">测试</strong>。在每个k-fold中完成训练集之后，生成一个模型，基于该模型测试测试集。我们研究的数据集<strong class="ju hi"> <em class="kv">乳腺癌</em> </strong>和<strong class="ju hi"> <em class="kv">皮马印第安人糖尿病</em> </strong>均取自<strong class="ju hi"><em class="kv"/></strong><a class="ae it" href="https://cran.r-project.org/package=mlbench" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi"><em class="kv">ml bench</em></strong></a><strong class="ju hi"><em class="kv"/></strong>包。下表1简要描述了研究中使用的分类器。</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es li"><img src="../Images/b30aaafbf87ad77e39929a6ff0aeb71e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cItRO6534x9rPe5dk96h4A.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated"><strong class="bd iw">表1:使用的机器学习模型</strong></figcaption></figure></div><div class="ab cl kw kx go ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ha hb hc hd he"><h1 id="90c7" class="iu iv hh bd iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn lh jp jq jr bi translated">分类和回归技术</h1><p id="d7b3" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">分类和回归树技术使用带有预先分配的类别的历史数据来生成决策树。然后用它对新数据进行分类。决策树是通过将训练结果迭代地分成子组或树部分来从训练数据构建的。对于每个内部树节点，根据特征值设置划分条件。该算法试图找到产生最“纯”的数据细分的分裂，即分裂产生最能区分观察值的子组。CART中构建决策树使用的杂质(或纯度)度量是<strong class="ju hi"> </strong> <a class="ae it" href="https://en.wikipedia.org/wiki/Gini_coefficient" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hi">基尼指数</strong> </a>。</p><p id="8d99" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">节点<em class="kv"> t处的基尼指数g (t) </em>定义如下:</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es ln"><img src="../Images/f5696bbbf63cfde28bfde92a5b3ce85e.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*z-civeepvt8Cha1Qty1iDQ.png"/></div></figure><p id="5c12" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">上式中<strong class="ju hi"> <em class="kv">，I，j </em> </strong>为目标变量的类别，<strong class="ju hi">【πⱼ】</strong><em class="kv">，</em> <strong class="ju hi"> <em class="kv"> j </em> </strong>为类别的先验概率<strong class="ju hi"> <em class="kv"> j </em> </strong>，<strong class="ju hi"> <em class="kv"> Nⱼ </em> </strong>为根节点中类别的样本数。此外，基尼指数用于在树生长期间寻找分裂的改进，只有在节点t和根节点中具有分裂预测值有效值的那些记录用于分别计算<em class="kv"/><strong class="ju hi">【nⱼ(t】</strong><strong class="ju hi"><em class="kv">【nⱼ】</em></strong>。基尼指数的方程式也可以写成:</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/d435d3bcb85a220246565d92f1ab802d.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/1*aHRovdwgnwAfyHoZ5T2nug.png"/></div></figure><p id="f91c" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">决策树算法为数据生成一个简单易懂的模型。通过从树根开始，然后迭代地向下移动与观察特征匹配的分支，从模型中为新的观察做出预测。最终，我们到达了树的一个叶子节点。叶节点标有我们将要预测的类。决策树对噪声很敏感，因此训练数据中微小的变化会导致不同的决策树，并产生不期望的结果。购物车算法通过<strong class="ju hi"><em class="kv"/></strong><a class="ae it" href="https://cran.r-project.org/web/packages/rpart/" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi"><em class="kv">rpart</em></strong></a><strong class="ju hi"><em class="kv"/></strong>包实现。</p><p id="24b9" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">讨论</strong>:决策树容易理解和解释；布尔逻辑可以解释分类和回归结果；无论数据集的大小如何，它们都易于实现，并且可以处理属性值类型(数值型、分类型)的可变性。然而，构造最优决策树的问题是NP完全的。与单个决策树相关联的另一个问题是，它们往往难以适应和概括。决策树的集成通过在构建个体树和创建一组这样的随机化树时引入随机性元素来减轻过度拟合。</p><h1 id="fc35" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">条件推理树</h1><p id="775c" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">Hothron等人介绍了一种对rpart方法的改进，用于构建决策树，称为条件推理树。条件推理树通过使用统计p值来解决rpart的过拟合和变量选择偏差。<br/><a class="ae it" href="https://www.rdocumentation.org/packages/partykit/versions/1.1-1/topics/ctree" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi">算法</strong> </a>可以概括为三个步骤:</p><ol class=""><li id="8957" class="lp lq hh ju b jv kq jz kr kd lr kh ls kl lt kp lu lv lw lx bi translated"><strong class="ju hi">检验任何解释变量和响应之间的独立性的全局零假设。</strong> <br/> (a) <em class="kv">停止如果这个假设不能被拒绝(p &gt; 0.05)。</em> <br/> (b) <em class="kv">否则选择与<br/>响应关联最强的输入变量。这种关联是通过与单个输入变量和响应的部分零假设测试相对应的p值来衡量的。</em></li><li id="12b3" class="lp lq hh ju b jv ly jz lz kd ma kh mb kl mc kp lu lv lw lx bi translated"><strong class="ju hi">在选择的输入变量中执行二进制分割。为了在选定的输入变量中找到最佳的二进制分割，该算法使用排列测试。默认停止标准确保包含少于20个观测值的组不会被拆分，并且拆分后的组将包含至少7个观测值。</strong></li><li id="8980" class="lp lq hh ju b jv ly jz lz kd ma kh mb kl mc kp lu lv lw lx bi translated"><strong class="ju hi">反复重复步骤1)和2 ),直到达到停止标准。</strong></li></ol><p id="5749" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">讨论</strong>:条件推理树提供了一些优于传统方法(如CART)的优势。首先，变量选择是无偏的。第二，人们不必为了避免过度拟合而修剪结果。第三，该算法还提供了p值，显示人们对每一次分裂的信心程度。为了获得p值，它使用置换。条件推理树算法通过<a class="ae it" href="https://rdrr.io/cran/party/man/ctree.html" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi"><em class="kv">ctree</em></strong></a><strong class="ju hi"/>R包实现。</p><h1 id="ad8c" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">随机森林</h1><p id="2dc7" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">随机森林是一种流行和通用的预测模型。它的算法是基于决策树的。随机森林方法通过在所谓的集成分类器中嵌入大量决策树来提高决策树的稳定性和准确性。例如，随机森林可能包含100棵决策树。每个决策树都是在来自训练集的引导样本上训练的。通过让所有决策树创建一个预测并进行平均或多数投票来获得预测。将此过程应用于决策模型被称为<a class="ae it" href="https://machinelearningmastery.com/bagging-and-random-forest-ensemble-algorithms-for-machine-learning/" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hi">打包</strong> </a>。它可以提高稳定性和准确性。R "<a class="ae it" href="https://cran.r-project.org/web/packages/randomForest/index.html" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi"><em class="kv">Random Forest</em></strong></a><strong class="ju hi"><em class="kv">"</em></strong>包中使用的创建随机森林的算法实现如下。</p><ol class=""><li id="53dd" class="lp lq hh ju b jv kq jz kr kd lr kh ls kl lt kp lu lv lw lx bi translated">预定义数量的决策树被训练。</li><li id="14ab" class="lp lq hh ju b jv ly jz lz kd ma kh mb kl mc kp lu lv lw lx bi translated"><strong class="ju hi">对于每一棵树，从训练集中抽取一个引导样本。然后在引导样本上训练该树，在每次分裂时仅从固定数量的随机选择的特征中进行选择。</strong></li><li id="f361" class="lp lq hh ju b jv ly jz lz kd ma kh mb kl mc kp lu lv lw lx bi translated"><strong class="ju hi">可以从随机森林中做出预测，方法是向所有单独的决策树提供新的测试观察，然后平均它们的预测或进行多数投票。</strong></li></ol><p id="d698" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">信息增益</strong>用于根据目标概念确定属性分离训练数据的程度。它基于信息论中常用的一种度量方法，即熵。用布尔目标概念在训练数据S的集合上定义，<em class="kv"> S </em> 的<strong class="ju hi">熵被定义为:</strong></p><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es md"><img src="../Images/a5f33e0242249d0b3c82ce208e3bb196.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*drIwyv4UharWNJmdQFjgkA.png"/></div></figure><p id="a521" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">其中p₊是s中正面例子的比例，p₋是反面例子的比例。根据属性a，信息增益是在划分集合S的实例时熵的预期减少。其定义如下</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es me"><img src="../Images/7f055713f884e9dfd4cba2ccd03bdf3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*Ftq8AK7nS6bZrLPz5xAwOw.png"/></div></figure><p id="3072" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">其中<em class="kv">值(A) </em>是属性a的所有可能值的集合，Sᵥ是s中属性a的值为v的示例的子集。等式中的第一项是原始数据集的熵。第二项描述了使用属性a对数据集进行分区后数据集的熵。它只不过是每个子集Sᵥ的熵之和，这些熵是根据属于该子集的示例数量进行加权的。</p><p id="0a5f" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">讨论</strong>:它不需要输入准备，执行隐式特征选择，并且在较大数据集上高效运行。已经观察到随机森林对于一些具有噪声分类的数据集过度拟合。随机森林算法的主要限制是，大量的树可能会使算法在实时预测时变慢。</p><h1 id="57b1" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">C50</h1><p id="ec35" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">C50算法是C4.5算法的扩展。C50模型的工作原理是基于给出最大信息增益的场来分割样本。由第一次分割定义的每个子样本然后基于不同的字段再次分割。该过程重复进行，直到子样本不能被进一步分割。最后，审查最底层的分割，那些对模型的价值没有显著贡献的分割将被删除或删减。该算法通过<a class="ae it" href="https://cran.r-project.org/package=C50" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi"><em class="kv">C50</em></strong></a><strong class="ju hi"><em class="kv"/></strong>R包实现。</p><p id="5db9" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">讨论</strong> : C5.0处理数据集中的多值属性和缺失属性。数据的微小变化会导致不同的决策树(尤其是当变量的值彼此接近时)。在小规模的训练集上效果不是很好。<a class="ae it" href="https://en.wikipedia.org/wiki/Ross_Quinlan" rel="noopener ugc nofollow" target="_blank">的优势</a>是几个数量级的速度，内存效率，更小的决策树，加速，对不同属性加权的能力，以及筛选。</p><h1 id="680b" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">朴素贝叶斯</h1><p id="dbbb" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">朴素贝叶斯分类器基于贝叶斯定理，并假设预测器之间相互独立。朴素贝叶斯模型易于构建，没有复杂的迭代参数估计，这使得它对非常大的数据集特别有用。尽管简单，朴素贝叶斯分类器通常表现得令人惊讶地好，并被广泛使用，因为它通常优于更复杂的分类方法。贝叶斯定理提供了一种计算后验概率的方法，<strong class="ju hi"> <em class="kv"> P(c|x) </em> </strong>，从<strong class="ju hi"> <em class="kv"> P(c) </em> </strong>，<strong class="ju hi"> <em class="kv"> P(x) </em> </strong>，<strong class="ju hi"> <em class="kv"> P(x|c) </em> </strong>。朴素贝叶斯分类器假设预测值对给定类的影响独立于其他预测值。这种假设被称为类条件独立性。</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es mf"><img src="../Images/c259f5a5aca0152c5a4cad28850a60c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*g1JOb8MFb9CjnzP2F9voWQ.png"/></div></figure><p id="6e71" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">其中<strong class="ju hi"> <em class="kv"> P(c|x) </em> </strong>为一类给定预测器的后验概率，<strong class="ju hi"> <em class="kv"> P(x|c) </em> </strong>为似然，即一个预测器给定类的概率，<strong class="ju hi"> <em class="kv"> P(c) </em> </strong>为该类的先验概率，<strong class="ju hi"> <em class="kv"> P(x) </em> </strong>为预测器的先验概率。一个简单的贝叶斯分类器由两部分组成。第一个分量g是有向非循环图(DAG ),其顶点对应于随机变量<strong class="ju hi"> <em class="kv"> X ₁，..，X ₙ </em> </strong>。第二个分量θ描述了每个变量的条件分布，给出了它在g中的双亲。</p><p id="5eeb" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">讨论</strong>:尽管有很强的特征独立性假设，朴素贝叶斯分类器有几个特性使它出奇的好。训练一个模型需要少量的数据。它具有快速的建模能力和评分能力，可用于二分类和多分类问题。这是一个稳定的算法，因为训练数据的小变化不会使模型发生大的变化。</p><h1 id="e1c4" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">XGBoost</h1><p id="1e6b" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">XGBoost是“极端梯度推进”的缩写。这是一个梯度推进决策树的实现。Boosting分类器属于集成模型；基本思想是聚合数百个不太精确的基于树的模型，以形成一个非常精确的模型。该模型通常在每一步迭代生成一个新的基于树的模型。模型按顺序添加，直到不能再进一步改进。该算法通过<strong class="ju hi"><em class="kv"/></strong><a class="ae it" href="https://cran.r-project.org/package=xgboost" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi"><em class="kv">xgboost</em></strong></a><strong class="ju hi"><em class="kv"/></strong>R包实现。</p><p id="f98a" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">讨论</strong>:增加新的弱学习器，修正所有之前树的残差。这产生了更强大的预测建模算法，可能比随机森林更强大。</p></div><div class="ab cl kw kx go ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ha hb hc hd he"><h1 id="07a8" class="iu iv hh bd iw ix ld iz ja jb le jd je jf lf jh ji jj lg jl jm jn lh jp jq jr bi translated">性能赋值</h1><p id="bea7" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">在这一部分中，我们分析了所有六个机器学习模型在训练和测试数据集上的预测结果。在本研究中，我们使用了<strong class="ju hi">三重</strong>、<strong class="ju hi">五重</strong>和<strong class="ju hi">十重</strong>交叉验证技术来研究绩效指标。从准确性、敏感性和特异性方面对性能指标进行评估。使用混淆矩阵来评估这些度量。混淆矩阵包括关于由分类器应用的实际和预测分类的信息。一个<strong class="ju hi">真阳性(TP) </strong>结果表示一个实例被正确地分类到那个类，而<strong class="ju hi">假阴性(FN) </strong>表示一个实例被错误地分类到那个类。<strong class="ju hi">真阴性(TN) </strong>表示从类中正确拒绝的实例的数量，而<strong class="ju hi">假阳性(FP) </strong>是从类中错误拒绝的实例的数量。</p><p id="9492" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">准确度</strong>定义为正确分类的病例数之比，等于TP和TN之和除以病例总数。</p><p id="e760" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">灵敏度</strong>指正确分类的阳性率，等于TP除以TP和FN之和。灵敏度可以被称为真阳性率。</p><p id="bfab" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">特异性</strong>指正确分类阴性的比率，等于TN与TN和FP之和的比值。</p><p id="e433" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">因此，通过计算其准确性、敏感性和特异性来评估分类器。</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es li"><img src="../Images/8c80f9c88f53825e9e517ac4ac31709a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3ErIAEAf85jkSPw8srEefA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated"><strong class="bd iw">表2:六个机器学习模型的平均准确率</strong></figcaption></figure><figure class="lj lk ll lm fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es li"><img src="../Images/f5a4e329481a9d439d8dc3b2d3e77a98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ap3pzfaS5Qf16sIwHIze7Q.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated"><strong class="bd iw">表3:六种机器学习模型的平均敏感度</strong></figcaption></figure><figure class="lj lk ll lm fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es li"><img src="../Images/6884a51831cd3db0b9e56d75ff20b964.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nhpLukpqgyolkrfYa9fQMw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated"><strong class="bd iw">表4:六种机器学习模型的平均特异性</strong></figcaption></figure><h1 id="be9c" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">我们的结果</h1><p id="2c67" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">在本节中，我们分析了所有六个机器学习模型在<strong class="ju hi"><em class="kv"/></strong>乳腺癌和<strong class="ju hi"> <em class="kv">皮马印第安人糖尿病</em> </strong>数据集上的预测结果。不同分类器之间的准确度比较如表2所示。对于<strong class="ju hi"> <em class="kv">乳腺癌</em> </strong>数据集，<strong class="ju hi"> <em class="kv"> xgboost </em> </strong>模型优于其他机器学习模型。<strong class="ju hi"> <em class="kv"> xgboost </em> </strong>'模型在10重交叉验证中达到了<strong class="ju hi"> <em class="kv"> 98.53% </em> </strong>的准确率。对于<strong class="ju hi"> <em class="kv">皮马印第安人糖尿病</em> </strong>数据集，<strong class="ju hi"> <em class="kv"> xgboost </em> </strong>在10重交叉验证中达到最高准确率<strong class="ju hi"><em class="kv"/></strong>77.78%。因此，我们可以得出结论，就预测精度而言，在六种不同的机器学习技术中，'<strong class="ju hi"> <em class="kv"> xgboost </em> </strong>'模型是更好的选择。</p><h1 id="27b4" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">最后的想法</h1><p id="c9ac" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">本文对六种不同的机器学习模型进行了比较研究。研究结果证实了<strong class="ju hi"><em class="kv">【xgboost</em></strong>】技术比其他分类器产生更好的结果。k重交叉验证用于衡量不同机器学习模型的鲁棒性。据观察，在<strong class="ju hi"><em class="kv">【3重】、5重</em> </strong>和<strong class="ju hi"> <em class="kv"> 10重</em> </strong>交叉验证技术<strong class="ju hi"><em class="kv">【xgboost】</em></strong>技术在准确性方面优于其他分类器。此外，我们试图评估k的影响，并发现有时增加或减少k值时精度水平保持不变。因此，我们可以得出结论，增加或减少k值不会增强结果。它仅仅增加了计算成本。</p></div><div class="ab cl kw kx go ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ha hb hc hd he"><p id="6d5f" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">感谢阅读！</strong></p><p id="3226" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">如果你觉得这篇文章有帮助，那么请把它发给其他人。</p><p id="3174" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">https://youtu.be/OSwuhYfMwWY ✅learn过着社交焦虑的生活⇾ <a class="ae it" href="https://www.youtube.com/watch?v=OSwuhYfMwWY&amp;t=0s" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>