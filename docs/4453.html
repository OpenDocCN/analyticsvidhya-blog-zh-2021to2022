<html>
<head>
<title>Multivariate Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">多元线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/multivariate-linear-regression-1c06b12cb982?source=collection_archive---------3-----------------------#2021-10-17">https://medium.com/analytics-vidhya/multivariate-linear-regression-1c06b12cb982?source=collection_archive---------3-----------------------#2021-10-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="5d47" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">真实世界的数据集总是有多个变量或要素。当一个回归问题的结果有一个以上的特征/变量要考虑时，就称为多元回归。</p><p id="10eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">单个变量的假设函数是，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/9e60d92f3003b55949b958de2f872719.png" data-original-src="https://miro.medium.com/v2/resize:fit:402/format:webp/0*Er1ITPUzx8SKekA6.png"/></div></div></figure><p id="8a50" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在多变量n的情况下，x变成一个向量或包含n个变量作为向量元素的列。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jo"><img src="../Images/e7e7fa9e29fd8c1590468b0e2956f690.png" data-original-src="https://miro.medium.com/v2/resize:fit:224/format:webp/0*vap3J-00FbnvapoU.png"/></div></figure><p id="f84d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于n个特征，参数也变成向量，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jp"><img src="../Images/b0990bee7df74ffdc95cb3d80ae20e51.png" data-original-src="https://miro.medium.com/v2/resize:fit:212/format:webp/0*Lpo6ihIoo6bq3EFa.png"/></div></figure><p id="9913" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">多变量的假设函数，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jq"><img src="../Images/040b6f0f077a69bfe3c80c922ffaab8e.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/0*NkUTD8l6OEkkT-mP.png"/></div></figure><p id="edbf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了方便起见，我们添加了x的第零个特征，它总是1。因此，假设函数变成了，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jr"><img src="../Images/02edfff4f32305c01f2611200fada202.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/0*LoH43oxswmDn4cQ7.png"/></div></figure><p id="5a75" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在向量形式中，假设函数可以写成:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es js"><img src="../Images/2a91001f5d4f988920f1c3bf31b1f5a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/0*2jspggCONATKU3j4.png"/></div></figure><h1 id="55c8" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">多变量梯度下降</h1><p id="5763" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">使用该算法可以找到多个变量的梯度下降，</p><blockquote class="kw kx ky"><p id="1fd9" class="ie if kz ig b ih ii ij ik il im in io la iq ir is lb iu iv iw lc iy iz ja jb ha bi translated">重复直到收敛:</p></blockquote><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ld"><img src="../Images/a409326cc478df603212b30cc0a5059f.png" data-original-src="https://miro.medium.com/v2/resize:fit:724/format:webp/0*jm4WlnoMBIIKEP3v.png"/></div></figure><p id="1d01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">并同时更新，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es le"><img src="../Images/ec37818af9b022bfe8bf4ffeb16e8324.png" data-original-src="https://miro.medium.com/v2/resize:fit:506/format:webp/0*VGH9Dv8PX66dZu_p.png"/></div></figure><h2 id="fa43" class="lf ju hh bd jv lg lh li jz lj lk ll kd ip lm ln kh it lo lp kl ix lq lr kp ls bi translated">如何检查梯度下降是否工作正常？</h2><p id="1999" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">获得梯度下降的迭代可以因问题而异。一些可能需要很少的迭代次数来达到全局最小值，而一些可能需要大量的迭代。</p><p id="1c34" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了检查它们是否正常工作，计算梯度下降，并在图表上绘制特定参数值的损失函数值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lt"><img src="../Images/af9e5f05bb1e7b9ef46a8d95e320c1a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*abgGKIzCeVDulKw0G_mg_g.png"/></div></figure><p id="a70f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果梯度下降正常工作，那么损失函数的值应该随着每次迭代而减小。</p><p id="c1c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果图看起来随着迭代次数的增加而增加，那么梯度下降没有按预期工作。在这种情况下，我们必须选择较小的alpha值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lt"><img src="../Images/a6a115a78d0cefa64d18a552defc2a53.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*raCQIZdR_69s63Y7kDz8fw.png"/></div></figure><p id="4da9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有时，随着迭代，图可能会重复地减少和增加。这种情况还表明alpha值很高，我们必须降低alpha值，这样参数才会收敛。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lu"><img src="../Images/1d8091b4263965677aa7480a2a65a18b.png" data-original-src="https://miro.medium.com/v2/resize:fit:730/format:webp/1*szTTpK_Cdw7y0bIOCIckvQ.png"/></div></figure><p id="027c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了得到最佳的阿尔法值，我们可以绘制一系列阿尔法值的梯度下降图。无论哪个值导致损失函数快速下降，我们都可以最终确定α的值。</p><p id="e3d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">除了这种方法，我们还可以使用自动收敛测试来检查损失函数是否收敛。选择比如0.001的阈值，并且如果损失函数的减少小于阈值，那么我们可以假设该函数是收敛的。但在实践中，很难选择阈值，以前的方法很好地找到梯度下降的效率。</p><h2 id="8d81" class="lf ju hh bd jv lg lh li jz lj lk ll kd ip lm ln kh it lo lp kl ix lq lr kp ls bi translated">特征缩放</h2><p id="cd0a" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">假设我们有一个介于范围(0-5000)之间的特征x1和一个介于范围(1 -10)之间的特征x2。如果我们对此函数进行梯度下降，cos函数将具有高瘦轮廓(如果在轮廓图中表示)。从函数上的任何一点达到全局最小值都要花很多时间。</p><p id="bceb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将要素的值除以其值的范围(要素的最大值-要素的最小值)是一种缩放方法。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lv"><img src="../Images/8dcdf50d2709c6d76d08e2fe7837f4de.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/0*DoaX3_10XGdQvEbC.png"/></div></figure><p id="286d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一般来说，我们可以将每个特性放在2到6个值之间的范围内，或者任何值之间的范围内。举个例子，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lw"><img src="../Images/fad7571bf096469eea7ca9018870a838.png" data-original-src="https://miro.medium.com/v2/resize:fit:374/format:webp/0*lYZ6mbw_xbzJUo9N.png"/></div></figure><h2 id="82f4" class="lf ju hh bd jv lg lh li jz lj lk ll kd ip lm ln kh it lo lp kl ix lq lr kp ls bi translated">均值归一化</h2><p id="5aaa" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">一种缩放方法，其中用x_i和特征x的平均值之差替换xi。这使得特征的平均值约为零。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lx"><img src="../Images/a48dc94a993fa75dda6b17bbb848c8d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/0*hrvS8Ckz390LqjBw.png"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lv"><img src="../Images/aea2ace317ce90d702c64cdd1a00e68d.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/0*U1K_3WRoxBrXnndJ.png"/></div></figure><h2 id="9981" class="lf ju hh bd jv lg lh li jz lj lk ll kd ip lm ln kh it lo lp kl ix lq lr kp ls bi translated">特征和多项式回归</h2><p id="ec15" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">我们不必强制使用所有给定的特性。根据我们的问题陈述，我们总是可以忽略一些特性或添加新特性(可以是其他特性的组合)。</p><p id="90b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">类似地，我们不必对数据拟合直线，因为实际输出可能不在一条直线上。我们可以用多项式函数来更好地拟合数据集。</p><p id="aaa5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">直线拟合，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ly"><img src="../Images/e33b316fd8307624b224eb2f03d6416c.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/0*MEfdFNqD_idvw4AU.png"/></div></figure><p id="5bc3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以在现有特征的基础上创建新的特征，例如，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lz"><img src="../Images/665f125a4a8539e037be0c2a47fef3e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/0*op9935hh7fAghD6O.png"/></div></figure><p id="ffa3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如前所述，我们可以尝试不同的多项式函数来更好地拟合数据，并将它们进行比较，看哪一个拟合得最好。</p><p id="5c02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">二次拟合，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lz"><img src="../Images/83885a8573bfe191d554f4bada450598.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/0*EGYPFq_tRrzJYOl5.png"/></div></figure><p id="4d8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">三次拟合，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ma"><img src="../Images/438ac9eb0d8cc83369dc3aec539855fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/0*aSrygi1FjgEi1_qb.png"/></div></figure><p id="5ff8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">平方根拟合，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mb"><img src="../Images/0a569082592f27edc39ab9f65ef7dea2.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/0*ZiS0oQsbFZnuLrYk.png"/></div></figure><p id="790d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">应用这些多项式函数时，重要的是特性的值应在较小的范围内。因此，必须小心地进行特征缩放。</p><h1 id="6eac" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">正态方程</h1><p id="9134" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">梯度下降法是寻找损失函数最小的最低参数值的方法之一。参数值在每次迭代中都会改变，直到识别出全局最小值。正规方程试图寻找最少的参数值，而不需要连续迭代。</p><p id="7f79" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一般来说，让我们考虑一个数学二次函数。我们通过使它等于零来求解这个函数。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mc"><img src="../Images/f3192e4a2506a1229254a39a1d830844.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/0*IzVUvhiXpSzzWGT8.png"/></div></figure><p id="8cfd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">类似地，在正规方程中，我们取损失函数的偏导数，对于每个参数将其赋值为零，并求解每个参数。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es md"><img src="../Images/8114074e2efa22532797f99a84a45fe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/0*wAd6wkbl1diCBNQT.png"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es me"><img src="../Images/e07301b7eae002f1318aec3c7622ac8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:316/format:webp/0*9MTU61RCboZ-T_iq.png"/></div></figure><p id="3a41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过使用微积分求解，我们可以得到最小值，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mf"><img src="../Images/baa03bf3b5d370d6b50918c3616569bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/0*H6RUASb8deKNcp9Q.png"/></div></figure><p id="01f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在哪里，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mg"><img src="../Images/312933d181b7fe8520492f4758e43363.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/0*sBq56uxHPHwjbZSX.png"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mh"><img src="../Images/6fdc4d0cd01851e1c308f3c685da5a5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:216/format:webp/0*G_3XvIzUpUb_R7Ih.png"/></div></figure><p id="8010" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们使用正规方程方法，就没有必要执行特征缩放来将特征值的范围缩小到几个值以内。</p><p id="ec8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当比较正规方程和梯度下降时，</p><ul class=""><li id="a0d5" class="mi mj hh ig b ih ii il im ip mk it ml ix mm jb mn mo mp mq bi translated">我们不必选择学习率α，并在正规方程中进行大量迭代。因此，它节省了大量的时间和复杂性。</li><li id="d7bd" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb mn mo mp mq bi translated">但是梯度下降适用于大量的要素。而如果n较大，则计算正规方程较慢，并且成本几乎为零，</li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mw"><img src="../Images/b99a069c852d4ba46dc5981b40494bbe.png" data-original-src="https://miro.medium.com/v2/resize:fit:138/format:webp/0*4LjfyS8kAzrn-_ej.png"/></div></figure><p id="38ba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因为我们需要计算，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mx"><img src="../Images/32343bdc0b0185b8f5443dc7462cdfee.png" data-original-src="https://miro.medium.com/v2/resize:fit:228/format:webp/0*0EM13Kut2EZPUXYL.png"/></div></figure><p id="fefd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">实际上，如果特征的数量超过10，000，那么我们可以考虑转移到梯度下降。</p><h2 id="b19f" class="lf ju hh bd jv lg lh li jz lj lk ll kd ip lm ln kh it lo lp kl ix lq lr kp ls bi translated">正规方程与不可逆性</h2><p id="c8db" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">当我们通过使用正规方程方法找到最小参数值来计算最小损失函数时，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es my"><img src="../Images/54228859c5a6440e45f08df3bdcffac3.png" data-original-src="https://miro.medium.com/v2/resize:fit:458/format:webp/0*Cxa-2ijKQI20JJgP.png"/></div></figure><p id="403b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有时，如果结果值是奇异矩阵或退化矩阵，则X的逆(转置)是不可能的。为了解决这种情况，我们不得不采取伪逆。<strong class="ig hi">伪逆</strong>可以通过用奇异值分解(SVD)方法分解所得的不可逆矩阵来获得。</p><p id="7f00" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还可以通过找出其奇异性背后的原因，将不可逆的结式矩阵转换为可逆矩阵。</p><ul class=""><li id="2799" class="mi mj hh ig b ih ii il im ip mk it ml ix mm jb mn mo mp mq bi translated">有时可能存在冗余特征，使得矩阵线性相关。我们可以删除或更改这些功能。</li><li id="3609" class="mi mj hh ig b ih mr il ms ip mt it mu ix mv jb mn mo mp mq bi translated">有时可能有太多的特征(训练数据的数量可能小于或等于特征的数量)。在这种情况下，我们可以删除一些特征。</li></ul></div><div class="ab cl mz na go nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="ha hb hc hd he"><p id="b755" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="kz">注:本文是</em><a class="ae ng" href="https://github.com/swaathi317/30DaysOfData" rel="noopener ugc nofollow" target="_blank"><em class="kz"># 30 daysofdata</em></a><em class="kz">的一部分，文章内容是我自己从</em> <a class="ae ng" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank"> <em class="kz"> Andrew NG机器学习课程</em> </a> <em class="kz">中的笔记。</em></p></div></div>    
</body>
</html>