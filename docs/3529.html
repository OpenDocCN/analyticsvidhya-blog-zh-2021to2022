<html>
<head>
<title>Data-Preprocessing: Begin before you think you’re ready…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据预处理:在你认为自己准备好之前就开始…</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-preprocessing-begin-before-you-think-youre-ready-8f090987425e?source=collection_archive---------3-----------------------#2021-07-07">https://medium.com/analytics-vidhya/data-preprocessing-begin-before-you-think-youre-ready-8f090987425e?source=collection_archive---------3-----------------------#2021-07-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/3d9deaadc2b77a74e2812fd65a5cfb9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vDBDb1aNmoOVP1BTLs0OkQ.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">照片由<a class="ae it" href="https://www.pexels.com/photo/black-claw-hammer-on-brown-wooden-plank-209235/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">像素</a>的<a class="ae it" href="https://www.pexels.com/@pixabay?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>拍摄</figcaption></figure><p id="9649" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi js translated"><span class="l jt ju jv bm jw jx jy jz ka di"> D </span>数据预处理是所有机器学习模型建立的基础，也就是说，为了获得最佳结果，我们的数据完整性最好比混凝土更强。</p><p id="c2cc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这并不是说它是大计划中的一个重要“步骤”，但是，它更多的是对机器学习算法的语言的解释，语言既可以是障碍，也很可能是障碍的打破者，请放心，数据预处理是后者。</p><p id="b51d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">简而言之，为了让我们的算法工作，我们需要以一种可以计算的格式输入数据，就像计算机用二进制语言操作一样，这有点像我们要做的，把不利类型的数据变成1和0，我的朋友……1和0。<br/>这还不是全部，还需要替换或删除缺失值，将数据拆分为训练和测试，最后，仅在拆分后扩展功能。</p><p id="3991" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="kb">在这篇文章结束时，你将已经清理了一个数据集，为进一步的分析做好了准备……</em></p></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><h1 id="e223" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated"><strong class="ak">我们从导入先决条件库开始… </strong></h1><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="21a5" class="lq kk hh lm b fi lr ls l lt lu">import numpy as np<br/>import pandas as pd</span></pre><p id="80f1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae it" href="https://numpy.org/doc/" rel="noopener ugc nofollow" target="_blank"> NumPy </a>，这样我们就可以使用数组，<a class="ae it" href="https://pandas.pydata.org/docs/" rel="noopener ugc nofollow" target="_blank"> Pandas </a>，这样我们就可以导入数据集并使用特征矩阵和目标变量。</p><h2 id="28e9" class="lq kk hh bd kl lv lw lx kp ly lz ma kt jf mb mc kx jj md me lb jn mf mg lf mh bi translated">导入数据集和第一印象…</h2><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="be21" class="lq kk hh lm b fi lr ls l lt lu">df = pd.read_csv('Data.csv')<br/>df</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mi"><img src="../Images/636a1534cd1a046b13cf63267cda01e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*541mU6kFYSYLIeYGkpfz4A.png"/></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="2259" class="lq kk hh lm b fi lr ls l lt lu">df.info()</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mj"><img src="../Images/0b12cc942b328004eed04883e2b493be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*APOYFEGbqet5fjwrJVCVMg.png"/></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="78d1" class="lq kk hh lm b fi lr ls l lt lu">df.nunique()</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mk"><img src="../Images/7433623c8283c20e88ad1438bc321387.png" data-original-src="https://miro.medium.com/v2/resize:fit:816/format:webp/1*Vj7AuVLFUCjtkFEVdue5Bg.png"/></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="20ec" class="lq kk hh lm b fi lr ls l lt lu">df.describe()</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es ml"><img src="../Images/421d10bfd1f91b38b08e624974548bf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*dc1e865muby8vzckJmoUUQ.png"/></div></figure><p id="f09c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以立即注意到“国家”特性不是一个数值，有3个唯一的国家(编码)。<br/>purchased变量也是如此，它也是我们的目标变量，二进制输出，但仍然是字符串。<br/>特征“年龄”在27–48的范围内，而“薪水”在48000–83000的范围内(特征缩放)。<br/>还有最明显的一个，NaN值(缺失值)。</p></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><h1 id="c410" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated"><strong class="ak">分离从属和独立特征… </strong></h1><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="3db1" class="lq kk hh lm b fi lr ls l lt lu">X = df.iloc[:, :-1].to_numpy() # to_numpy for further operations<br/>y = df.iloc[:, -1].to_numpy()</span><span id="62fb" class="lq kk hh lm b fi mm ls l lt lu">print(X)</span><span id="4756" class="lq kk hh lm b fi mm ls l lt lu">print(y)</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mn"><img src="../Images/9f75462b9c0edaf820d78bd98dec5245.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*vH9-m780Sktc3OeH7LWHkg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">打印(x)</figcaption></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mo"><img src="../Images/8e6042439ff4d29d10c8bf3711217318.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*3BTczWqIYc8IKyO3bdq4Fg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">打印(y)</figcaption></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mp"><img src="../Images/fe46b55b95ac7a854d2201a18b0a5f6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*K1ibIoR_Ivlqd-LjCM0xzw.png"/></div></figure><p id="5c4a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，通过<a class="ae it" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html" rel="noopener ugc nofollow" target="_blank"> iloc [] </a>方法，我们要求捕获除最后一行之外的所有行和所有列，将它们全部转换为NumPy数组，并将其存储在变量“X”中。</p><p id="432d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">类似地，“y”包含所有行，只包含最后一列。</p></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><h1 id="ffa7" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated"><strong class="ak">现在我们填补空白……(缺失值)</strong></h1><p id="5db5" class="pw-post-body-paragraph iu iv hh iw b ix mq iz ja jb mr jd je jf ms jh ji jj mt jl jm jn mu jp jq jr ha bi translated">在训练机器学习模型时，缺失值不是好兆头，就像，根本不是(除了朴素贝叶斯和基于树的算法)，所以我们必须以某种方式处理它们。</p><p id="216e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们<em class="kb">可以</em>通过使用<a class="ae it" href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html" rel="noopener ugc nofollow" target="_blank"> dropna () </a>方法简单地删除那些困扰我们的行，但是有时候你可以通过用合适的有意义的东西替换丢失的值来充分利用数据。</p><p id="2423" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以使用<a class="ae it" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html" rel="noopener ugc nofollow" target="_blank"> fillna () </a>或<a class="ae it" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.interpolate.html" rel="noopener ugc nofollow" target="_blank">插值</a>函数，甚至一个外部库来实现这一点，只要选择一个最适合你的方法，并坚持下去。</p><p id="8e06" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">外部库方式听起来很有趣，我们就这样吧…</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="a922" class="lq kk hh lm b fi lr ls l lt lu">from sklearn.impute import SimpleImputer</span></pre><p id="f2d5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，我们正在从估算模块的<a class="ae it" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> sklearn </a> (Scikit learn)库中访问一个名为<a class="ae it" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" rel="noopener ugc nofollow" target="_blank">simple input</a>的类。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="f1e4" class="lq kk hh lm b fi lr ls l lt lu">impute_er = SimpleImputer(missing_values = np.nan, strategy = 'mean')</span></pre><p id="3a53" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">就像它在面向对象编程中的工作方式一样，我们制作了一个SimpleImputer类的实例/对象。<br/>第一个自变量是目标，第二个自变量是替代。</p><p id="5cd1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">目前，我们使用相应值的平均值，其他选项包括最频繁、常数和中值，这些都是不言自明的。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="8ec7" class="lq kk hh lm b fi lr ls l lt lu">X[:, 1:3] = impute_er.fit_transform(X[:, 1:3])<br/>print(X)</span></pre><p id="0c5e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">拟合方法将连接到要素矩阵，而变换方法将替换这些值。<br/>输出如预期，感觉内容多一点。</p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es mv"><img src="../Images/def5d1fcf3f690e11787fe27a8772f69.png" data-original-src="https://miro.medium.com/v2/resize:fit:738/format:webp/1*db3d0Y3J12KGlwmhLgnd3g.png"/></div></figure></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><h1 id="27ff" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated"><strong class="ak">语言障碍……</strong></h1><p id="729e" class="pw-post-body-paragraph iu iv hh iw b ix mq iz ja jb mr jd je jf ms jh ji jj mt jl jm jn mu jp jq jr ha bi translated">我们知道我们为什么要这样做(因为机器学习模型不能处理字符串)，但事情是这样的，如果我们用0代表法国，1代表西班牙，2代表德国对“国家”特征进行编码，模型将“认为”德国与其他国家相比具有更大的价值，这根本不是真的，除非我们谈论的是足球(德国4次世界杯，法国2次，西班牙1次)。</p><p id="18ad" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">前面提到的方法被称为标签编码，当有一个层次结构时，如高级&gt;初级&gt;助理，这种方法很有用。</p><p id="e5fd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">一个热编码将帮助我们解决当前的困境，它可以生成与类别数量一样多的独立列，在我们的例子中，这意味着3列，每列表示0代表假，1代表真。</p><blockquote class="mw mx my"><p id="805e" class="iu iv kb iw b ix iy iz ja jb jc jd je mz jg jh ji na jk jl jm nb jo jp jq jr ha bi translated">附注…我们将删除三列中的一列，以避免<a class="ae it" href="https://www.investopedia.com/terms/m/multicollinearity.asp#:~:text=Multicollinearity%20is%20the%20occurrence%20of,in%20a%20multiple%20regression%20model.&amp;text=In%20general%2C%20multicollinearity%20can%20lead,independent%20variables%20in%20a%20model." rel="noopener ugc nofollow" target="_blank">多重共线性</a>。</p></blockquote><p id="dd9b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">一种方法是使用<a class="ae it" href="https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html" rel="noopener ugc nofollow" target="_blank"> pd.get_dummies() </a>方法，它可以直接在数据框上工作，但我们将继续使用一些外部库(<a class="ae it" href="https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html" rel="noopener ugc nofollow" target="_blank"> ColumnTransformer </a>)来处理我们的特征矩阵。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="67bc" class="lq kk hh lm b fi lr ls l lt lu">#Class<br/>from sklearn.compose import ColumnTransformer<br/>from sklearn.preprocessing import OneHotEncoder</span><span id="66be" class="lq kk hh lm b fi mm ls l lt lu">#Object<br/>CT_obj = ColumnTransformer( transformers = [('encoder', OneHotEncoder(drop = 'first'), [0])], remainder = 'passthrough')</span><span id="51b8" class="lq kk hh lm b fi mm ls l lt lu"># Connecting and replacing<br/>X = np.array(CT_obj.fit_transform(X))</span><span id="c536" class="lq kk hh lm b fi mm ls l lt lu">print(X)</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es nc"><img src="../Images/b2c05bce4aaa3ce44bf4bdea767133f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*oG8qcjE93GOnfNTFvydgpA.png"/></div></figure><p id="cd40" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="kb"> drop = "first" </em>，删除由“Country”特征构成的三列中的一列，以避免多重共线性，以及，<br/><em class="kb">remainder = " pass through "</em>参数，以保留我们未对其执行热编码的其余特征。<br/>至于我们的目标特性，让我们使用标签编码器，只是为了获得其代码的要点…</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="082f" class="lq kk hh lm b fi lr ls l lt lu">#Class<br/>from sklearn.preprocessing import LabelEncoder</span><span id="498c" class="lq kk hh lm b fi mm ls l lt lu">#Object<br/>LE_obj = LabelEncoder()</span><span id="021c" class="lq kk hh lm b fi mm ls l lt lu"># Connecting and replacing<br/>y = LE_obj.fit_transform(y)</span><span id="4d72" class="lq kk hh lm b fi mm ls l lt lu">print(y)</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es nd"><img src="../Images/864a05c9da1d7770fac7d3a7e23fb4cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*TXqgl8Fg7c2laJ9nIfr14w.png"/></div></figure><h2 id="334d" class="lq kk hh bd kl lv lw lx kp ly lz ma kt jf mb mc kx jj md me lb jn mf mg lf mh bi translated">何时使用LabelEncoder或OneHotEncoder。</h2><p id="2a47" class="pw-post-body-paragraph iu iv hh iw b ix mq iz ja jb mr jd je jf ms jh ji jj mt jl jm jn mu jp jq jr ha bi translated">底线，在处理序数特征(层次结构)时使用LabelEncoder，有很多类别(我们在一个二进制特征上使用它来熟悉代码)。</p><p id="ca85" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">OneHotEncoder当没有层次结构但我们还是想把那些类分开，而类的数量又太少的时候。</p></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><h1 id="8eed" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated"><strong class="ak">将数据分为训练和测试… </strong></h1><p id="f3a7" class="pw-post-body-paragraph iu iv hh iw b ix mq iz ja jb mr jd je jf ms jh ji jj mt jl jm jn mu jp jq jr ha bi translated">为什么？…以便我们可以评估模型的性能，并且更容易确定模型估计值的接近程度。</p><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="8eec" class="lq kk hh lm b fi lr ls l lt lu">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)</span><span id="07cb" class="lq kk hh lm b fi mm ls l lt lu">print(X_train)</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es ne"><img src="../Images/ae4ce50330f32f0666229974acd025ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:946/format:webp/1*IcYzlW9juO9tVWJ1Vo8W7w.png"/></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="8bee" class="lq kk hh lm b fi lr ls l lt lu">print(X_test)</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es nf"><img src="../Images/85a64e90107089031c7b793c76b3ba19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*qqgpoMGdTLMbEOL1a5PxPA.png"/></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="9356" class="lq kk hh lm b fi lr ls l lt lu">print(y_train)</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es ng"><img src="../Images/89bffcfa0b110623b73d12cfbc08b354.png" data-original-src="https://miro.medium.com/v2/resize:fit:624/format:webp/1*K1tUL0ifE-6gMQPsytcy7Q.png"/></div></figure><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="c9be" class="lq kk hh lm b fi lr ls l lt lu">print(y_test)</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es nh"><img src="../Images/f20e2043c0f74059ad5d3862b9c17e2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:280/format:webp/1*ViPhSuttKef2GKwK-A6_kQ.png"/></div></figure></div><div class="ab cl kc kd go ke" role="separator"><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh ki"/><span class="kf bw bk kg kh"/></div><div class="ha hb hc hd he"><h1 id="97e7" class="kj kk hh bd kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg bi translated"><strong class="ak">特征缩放</strong></h1><p id="17c9" class="pw-post-body-paragraph iu iv hh iw b ix mq iz ja jb mr jd je jf ms jh ji jj mt jl jm jn mu jp jq jr ha bi translated">并非所有的机器学习模型(如多元线性回归)都需要这一点，但有时我们需要相同尺度上的所有特征(如KNN等基于距离的算法)，以便我们可以避免少数特征优于其他特征，或者换句话说，少数特征在最终结果中具有更大的权重，从而导致忽略较小尺度上的特征。</p><p id="50ef" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">你必须明白的是，我们只在数据的训练/测试分割之后<strong class="iw hi">进行缩放是有原因的。</strong></p><p id="daa0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="kb">两种主要的特征缩放技术</em></p><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es ni"><img src="../Images/92100064c399c921b650c34f71a935f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/format:webp/1*4Hry7ma5q2npcvUrAuacVQ.png"/></div></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es nj"><img src="../Images/7e97a8717c3b11ea0b46d71a56777b48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1020/format:webp/1*PQl6hy5cxFn6PMCADyHOlw.png"/></div></figure><p id="b896" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，假设我们使用的是<a class="ae it" href="https://scikit-learn.org/stable/modules/preprocessing.html" rel="noopener ugc nofollow" target="_blank">标准化</a>方法，“X”将是数据集中的值，“平均值(X)”和“标准差(X)”是不言自明的，即它将是特定列(特征)的平均值和标准差。</p><p id="d238" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">测试集应该是全新的值，用于预测我们已经知道答案的结果。</p><p id="9714" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">“全新”是关键词，所以当我们扩展特性时，我们不可能包括测试集，因为标准差的值会不同。<br/>这就是为什么我们只在训练测试分裂后才缩放我们的特征</p><p id="b1f7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">一般来说，标准化工作得很好，其值大约在-3到+3的范围内。<br/> <a class="ae it" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html" rel="noopener ugc nofollow" target="_blank">归一化</a>在大多数特征呈正态分布(钟形曲线)时效果很好，并且输出在-1到1的范围内。</p><blockquote class="mw mx my"><p id="85cd" class="iu iv kb iw b ix iy iz ja jb jc jd je mz jg jh ji na jk jl jm nb jo jp jq jr ha bi translated">另外，如果你想知道，我们没有对One hot encoded列应用功能缩放，因为这将使它失去作为特定类(德国、法国、西班牙)的指示器的价值。</p></blockquote><pre class="lh li lj lk fd ll lm ln lo aw lp bi"><span id="e001" class="lq kk hh lm b fi lr ls l lt lu">from sklearn.preprocessing import StandardScaler</span><span id="9156" class="lq kk hh lm b fi mm ls l lt lu">scale_obj = StandardScaler()</span><span id="a26c" class="lq kk hh lm b fi mm ls l lt lu">X_train[:, 2:] = scale_obj.fit_transform(X_train[:, 2:])</span><span id="33f2" class="lq kk hh lm b fi mm ls l lt lu">X_test[:, 2:] = scale_obj.transform(X_test[: , 2:])</span><span id="4ec1" class="lq kk hh lm b fi mm ls l lt lu">print(X_train)</span><span id="a5d0" class="lq kk hh lm b fi mm ls l lt lu">print(X_test)</span></pre><figure class="lh li lj lk fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nk"><img src="../Images/e0a7f64bffadd85be7439a413ce6be5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PflJZe2HgBScMruMNDqSLQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">打印(X_train)</figcaption></figure><figure class="lh li lj lk fd ii er es paragraph-image"><div class="er es nl"><img src="../Images/9f0a9552dc8dc3bfde4481fdfd942b66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/1*xQMj_2NKGWgBqggXLajuYw.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">打印(X _测试)</figcaption></figure><p id="6415" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">你会注意到我们只应用了<em class="kb">。使用测试集转换</em>,如果我们在测试集上使用<em class="kb"> fit_transform </em>,定标器值会有所不同，即测试集值的标准偏差会被使用，而不是训练集的标准偏差，我们需要为我们的模型保持相同的定标器，这就是为什么只有<em class="kb">。转换</em>我们也使用训练集的定标器来转换测试集中的值。</p><h1 id="036e" class="kj kk hh bd kl km nm ko kp kq nn ks kt ku no kw kx ky np la lb lc nq le lf lg bi translated"><strong class="ak">结论</strong></h1><p id="22d8" class="pw-post-body-paragraph iu iv hh iw b ix mq iz ja jb mr jd je jf ms jh ji jj mt jl jm jn mu jp jq jr ha bi translated">数据预处理是一门艺术，真正的数据科学家的价值不仅在于解决扔给你的业务问题，还在于知道何时使用什么工具，并为有意义的叙述准备一个序幕。</p><figure class="lh li lj lk fd ii"><div class="bz dy l di"><div class="nr ns l"/></div></figure></div></div>    
</body>
</html>