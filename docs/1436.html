<html>
<head>
<title>Non-Linear Regression Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">非线性回归分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/non-linear-regression-analysis-e150447ac1a3?source=collection_archive---------0-----------------------#2021-03-02">https://medium.com/analytics-vidhya/non-linear-regression-analysis-e150447ac1a3?source=collection_archive---------0-----------------------#2021-03-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/c5eb8de6fd47ba8e58632679c47b5d49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hccTducJo17wcYBGazQwag.jpeg"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">图片来源:作者</figcaption></figure><div class=""/></div><div class="ab cl iu iv gp iw" role="separator"><span class="ix bw bk iy iz ja"/><span class="ix bw bk iy iz ja"/><span class="ix bw bk iy iz"/></div><div class="hb hc hd he hf"><h1 id="c280" class="jb jc hx bd jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy bi translated">介绍</h1><p id="adf1" class="pw-post-body-paragraph jz ka hx kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi kx translated"><span class="l ky kz la bm lb lc ld le lf di">如果</span>数据显示曲线趋势，那么<strong class="kb hy">线性回归</strong>与<strong class="kb hy">非线性回归</strong>相比不会产生非常准确的结果，因为顾名思义，<strong class="kb hy">线性回归</strong>假定<strong class="kb hy">数据</strong>是<strong class="kb hy">线性的</strong>。让我们学习一下<strong class="kb hy">非线性回归</strong>并在<strong class="kb hy"> python </strong>中应用一个例子。在这本笔记本中，我们将一个<strong class="kb hy">非线性模型</strong>拟合到与1960年至2014年中国GDP相对应的<strong class="kb hy">数据点</strong>。</p><h1 id="7dc1" class="jb jc hx bd jd je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy bi translated">导入所需的库</h1><pre class="ll lm ln lo fd lp lq lr ls aw lt bi"><span id="cea2" class="lu jc hx lq b fi lv lw l lx ly"># Basic Data Science libraries<em class="lz"><br/></em><strong class="lq hy">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>%matplotlib inline</strong></span><span id="bcaa" class="lu jc hx lq b fi ma lw l lx ly"><strong class="lq hy">sns.set()</strong></span></pre><blockquote class="mb mc md"><p id="f8bb" class="jz ka lz kb b kc me ke kf kg mf ki kj mg mh km kn mi mj kq kr mk ml ku kv kw hb bi translated">虽然线性回归很好地解决了许多问题，但它不能用于所有数据集。首先回忆一下<strong class="kb hy">线性回归</strong>如何对数据集建模。它模拟了一个<strong class="kb hy">因变量</strong>变量<strong class="kb hy"> <em class="hx"> y </em> </strong>和一个<strong class="kb hy">自变量</strong>变量<strong class="kb hy"> <em class="hx"> x </em> </strong>之间的<strong class="kb hy">线性关系。它有一个简单的1次方程，例如<strong class="kb hy"> y = 2𝑥 + 3 </strong>。</strong></p></blockquote><pre class="ll lm ln lo fd lp lq lr ls aw lt bi"><span id="df85" class="lu jc hx lq b fi lv lw l lx ly"><strong class="lq hy">x = np.arange(-5.0, 5.0, 0.1)<br/></strong>#You can adjust the slope and intercept to verify the changes in the graph.<br/><strong class="lq hy">y = 2*(x) + 3<br/>y_noise = 2 * np.random.normal(size=x.size)<br/>ydata = y + y_noise<br/>plt.figure(figsize=(8,6))<br/>plt.plot(x, ydata,  'bo')<br/>plt.plot(x,y, 'r') <br/>plt.ylabel('Dependent Variable')<br/>plt.xlabel('Indepdendent Variable')<br/>plt.show()</strong></span></pre><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es mm"><img src="../Images/2f1ab5e1d15c5c4edb8a40463a23e68f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*jr0mGkTbRtMpP49c19FJZg.png"/></div></figure><p id="e6e3" class="pw-post-body-paragraph jz ka hx kb b kc me ke kf kg mf ki kj kk mh km kn ko mj kq kr ks ml ku kv kw hb bi translated"><strong class="kb hy">非线性回归</strong>是<strong class="kb hy">独立</strong>变量<strong class="kb hy"> 𝑥 </strong>和<strong class="kb hy">因变量</strong>𝑦之间的关系，这导致了<strong class="kb hy">非线性函数模型化</strong>数据。本质上任何不是<strong class="kb hy">线性</strong>的关系都可以称为<strong class="kb hy">非线性</strong>，通常用<strong class="kb hy"> 𝑘 </strong>度的<strong class="kb hy">多项式</strong>表示(最大功率<strong class="kb hy"> 𝑥 </strong>)。</p><blockquote class="mb mc md"><p id="b12c" class="jz ka lz kb b kc me ke kf kg mf ki kj mg mh km kn mi mj kq kr mk ml ku kv kw hb bi translated"><strong class="kb hy"> 𝑦 =𝑎x +𝑏𝑥 +𝑐𝑥+𝑑 </strong></p></blockquote><p id="d62c" class="pw-post-body-paragraph jz ka hx kb b kc me ke kf kg mf ki kj kk mh km kn ko mj kq kr ks ml ku kv kw hb bi translated"><strong class="kb hy">非线性</strong>函数可以有类似于<strong class="kb hy">指数</strong>、<strong class="kb hy">对数</strong>、<strong class="kb hy">分数</strong>等元素。例如:</p><blockquote class="mb mc md"><p id="8a62" class="jz ka lz kb b kc me ke kf kg mf ki kj mg mh km kn mi mj kq kr mk ml ku kv kw hb bi translated"><strong class="kb hy"> 𝑦=log(𝑥) </strong></p></blockquote><p id="6a50" class="pw-post-body-paragraph jz ka hx kb b kc me ke kf kg mf ki kj kk mh km kn ko mj kq kr ks ml ku kv kw hb bi translated">甚至更复杂，例如:</p><blockquote class="mb mc md"><p id="f2f9" class="jz ka lz kb b kc me ke kf kg mf ki kj mg mh km kn mi mj kq kr mk ml ku kv kw hb bi translated"><strong class="kb hy"> 𝑦=log(𝑎𝑥 +𝑏𝑥 +𝑐𝑥+𝑑) </strong></p></blockquote><p id="c314" class="pw-post-body-paragraph jz ka hx kb b kc me ke kf kg mf ki kj kk mh km kn ko mj kq kr ks ml ku kv kw hb bi translated">让我们来看看一个<strong class="kb hy">三次</strong>函数的图形。</p><pre class="ll lm ln lo fd lp lq lr ls aw lt bi"><span id="3c45" class="lu jc hx lq b fi lv lw l lx ly"><strong class="lq hy">x = np.arange(-5.0, 5.0, 0.1)<br/></strong>#You can adjust the slope and intercept to verify the changes in the graph<br/><strong class="lq hy">y = 1*(x**3) + 1*(x**2) + 1*x + 3<br/>y_noise = 20 * np.random.normal(size=x.size)<br/>ydata = y + y_noise<br/>plt.plot(x, ydata,  'bo')<br/>plt.plot(x,y, 'r') <br/>plt.ylabel('Dependent Variable')<br/>plt.xlabel('Indepdendent Variable')<br/>plt.show()</strong></span></pre><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es mn"><img src="../Images/382709007a069205442060882abf4715.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*mIFxOiWX6UQrNQciLw2gfg.png"/></div></figure><blockquote class="mb mc md"><p id="8d29" class="jz ka lz kb b kc me ke kf kg mf ki kj mg mh km kn mi mj kq kr mk ml ku kv kw hb bi translated">可以看到，这个函数有<strong class="kb hy"> <em class="hx"> 𝑥 </em> </strong>和<strong class="kb hy"> <em class="hx"> 𝑥 </em> </strong>作为<strong class="kb hy">独立</strong>变量。此外，该函数的图形不是在<strong class="kb hy"> 2D </strong>平面上的直线。所以这是一个<strong class="kb hy">非线性函数</strong>。</p></blockquote><h1 id="4a77" class="jb jc hx bd jd je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy bi translated">非线性回归示例</h1><p id="50d9" class="pw-post-body-paragraph jz ka hx kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">举个例子，我们将尝试用一个非线性模型来拟合1960年至2014年中国GDP的数据点。我们下载了一个有两列的数据集，第一列是1960年到2014年之间的一年，第二列是中国在那一年以美元计算的相应年度国内生产总值。</p><pre class="ll lm ln lo fd lp lq lr ls aw lt bi"><span id="14e9" class="lu jc hx lq b fi lv lw l lx ly"><strong class="lq hy">import numpy as np<br/>import pandas as pd</strong></span><span id="c42d" class="lu jc hx lq b fi ma lw l lx ly">#downloading dataset<br/><strong class="lq hy">!wget -nv -O china_gdp.csv </strong><a class="ae mo" href="https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/china_gdp.csv" rel="noopener ugc nofollow" target="_blank"><strong class="lq hy">https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/china_gdp.csv</strong></a><strong class="lq hy"><br/>    <br/>df = pd.read_csv("china_gdp.csv")<br/>df.head(10)</strong></span></pre><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mp"><img src="../Images/483c25057b75923abb35dbd5eb085632.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v8UOz6IG4YYRViaN7Eglvg.png"/></div></div></figure><h1 id="82ee" class="jb jc hx bd jd je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy bi translated">绘制数据集</h1><p id="2b61" class="pw-post-body-paragraph jz ka hx kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">这是数据点的样子。它看起来有点像逻辑函数或指数函数。开始时增长缓慢，从2005年开始，增长非常显著。最后，它在2010年代略有减速。</p><pre class="ll lm ln lo fd lp lq lr ls aw lt bi"><span id="2110" class="lu jc hx lq b fi lv lw l lx ly"><strong class="lq hy">plt.figure(figsize=(8,5))<br/>x_data, y_data = (df["Year"].values, df["Value"].values)<br/>plt.plot(x_data, y_data, 'ro')<br/>plt.ylabel('GDP')<br/>plt.xlabel('Year')<br/>plt.show()</strong></span></pre><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es mq"><img src="../Images/758978f2f728061ffc1af8ff6a00fa9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*uBtG4AzRukjv7Fg0eiisHA.png"/></div></figure><h1 id="b328" class="jb jc hx bd jd je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy bi translated">选择模型</h1><blockquote class="mb mc md"><p id="7213" class="jz ka lz kb b kc me ke kf kg mf ki kj mg mh km kn mi mj kq kr mk ml ku kv kw hb bi translated">从对该图的初步观察，我们确定逻辑函数可以是一个很好的近似，因为它具有从缓慢增长开始，在中间增长，然后在最后再次下降的特性；如下图所示:</p></blockquote><pre class="ll lm ln lo fd lp lq lr ls aw lt bi"><span id="f6d0" class="lu jc hx lq b fi lv lw l lx ly"><strong class="lq hy">X = np.arange(-5.0, 5.0, 0.1)<br/>Y = 1.0 / (1.0 + np.exp(-X))</strong></span><span id="e5f0" class="lu jc hx lq b fi ma lw l lx ly"><strong class="lq hy">plt.plot(X,Y) <br/>plt.ylabel('Dependent Variable')<br/>plt.xlabel('Indepdendent Variable')<br/>plt.show()</strong></span></pre><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es mq"><img src="../Images/6c52dba65e9f3cadaa70556bff50248e.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*g6m0kqsEK5bdLB4HKqEIQA.png"/></div></figure><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mr"><img src="../Images/d50802e5e07178a29f60f8f50f26ff49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*prOURZZamtYGyhGzWIMMTw.png"/></div></div></figure><h1 id="5d2e" class="jb jc hx bd jd je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy bi translated">构建模型</h1><p id="1788" class="pw-post-body-paragraph jz ka hx kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">现在，让我们构建我们的回归模型并初始化它的参数。</p><pre class="ll lm ln lo fd lp lq lr ls aw lt bi"><span id="9a0c" class="lu jc hx lq b fi lv lw l lx ly"><strong class="lq hy">def sigmoid(x, Beta_1, Beta_2):<br/>     y = 1 / (1 + np.exp(-Beta_1*(x-Beta_2)))<br/>     return y</strong></span><span id="fead" class="lu jc hx lq b fi ma lw l lx ly"><strong class="lq hy">beta_1 = 0.10<br/>beta_2 = 1990.0</strong></span><span id="81e0" class="lu jc hx lq b fi ma lw l lx ly">#logistic function<br/><strong class="lq hy">Y_pred = sigmoid(x_data, beta_1 , beta_2)</strong></span><span id="c108" class="lu jc hx lq b fi ma lw l lx ly"><strong class="lq hy">#plot initial prediction against datapoints<br/>plt.plot(x_data, Y_pred*15000000000000.)<br/>plt.plot(x_data, y_data, 'ro'</strong></span></pre><figure class="ll lm ln lo fd hk er es paragraph-image"><div class="er es ms"><img src="../Images/c7f46e6a57fbd8240750fc0b2a1a67d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*A44fRkKY51jH0i-ypa5KSg.png"/></div></figure><p id="1c99" class="pw-post-body-paragraph jz ka hx kb b kc me ke kf kg mf ki kj kk mh km kn ko mj kq kr ks ml ku kv kw hb bi translated">我们在这里的任务是为我们的<strong class="kb hy">模型</strong>找到<strong class="kb hy">最佳参数</strong>。让我们先把<strong class="kb hy">正常化</strong>我们的<em class="lz"> </em> <strong class="kb hy"> <em class="lz"> x </em> </strong>和<strong class="kb hy"> <em class="lz"> y </em> </strong>:</p><h2 id="e5aa" class="lu jc hx bd jd mt mu mv jh mw mx my jl kk mz na jp ko nb nc jt ks nd ne jx nf bi translated">我们如何为拟合线找到最佳参数？</h2><p id="671d" class="pw-post-body-paragraph jz ka hx kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">我们可以使用<strong class="kb hy"> curve_fit </strong>，它使用非线性最小二乘法来拟合我们的<strong class="kb hy"> sigmoid函数</strong>到数据。使<strong class="kb hy"> sigmoid(xdata，*popt) </strong> - <strong class="kb hy"> ydata </strong>的残差平方和最小的参数的最佳值。popt是我们优化的参数。</p><pre class="ll lm ln lo fd lp lq lr ls aw lt bi"><span id="5588" class="lu jc hx lq b fi lv lw l lx ly"># Lets normalize our data<br/><strong class="lq hy">xdata =x_data/max(x_data)<br/>ydata =y_data/max(y_data)</strong></span><span id="7ab0" class="lu jc hx lq b fi ma lw l lx ly"><strong class="lq hy">from scipy.optimize import curve_fit<br/>popt, pcov = curve_fit(sigmoid, xdata, ydata)</strong></span><span id="89e2" class="lu jc hx lq b fi ma lw l lx ly"># Now we plot our resulting regression model.<br/><strong class="lq hy">x = np.linspace(1960, 2015, 55)<br/>x = x/max(x)<br/>plt.figure(figsize=(8,5))<br/>y = sigmoid(x, *popt)<br/>plt.plot(xdata, ydata, 'ro', label='data')<br/>plt.plot(x,y, linewidth=3.0, label='fit')<br/>plt.legend(loc='best')<br/>plt.ylabel('GDP')<br/>plt.xlabel('Year')<br/>plt.show()</strong></span></pre><figure class="ll lm ln lo fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ng"><img src="../Images/5586c01a20bb92357010c2e78feb0a59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_lvC0rd13UCCWioWRB1nlg.png"/></div></div></figure><h1 id="59be" class="jb jc hx bd jd je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy bi translated"><strong class="ak">我们模型的计算精度？</strong></h1><pre class="ll lm ln lo fd lp lq lr ls aw lt bi"><span id="1529" class="lu jc hx lq b fi lv lw l lx ly"># split data into train/test<br/><strong class="lq hy">msk = np.random.rand(len(df)) &lt; 0.8<br/>train_x = xdata[msk]<br/>test_x = xdata[~msk]<br/>train_y = ydata[msk]<br/>test_y = ydata[~msk]</strong></span><span id="c46b" class="lu jc hx lq b fi ma lw l lx ly"># build the model using train set<br/><strong class="lq hy">popt, pcov = curve_fit(sigmoid, train_x, train_y)</strong></span><span id="e464" class="lu jc hx lq b fi ma lw l lx ly"># predict using test set<br/><strong class="lq hy">y_hat = sigmoid(test_x, *popt)</strong></span><span id="0ee8" class="lu jc hx lq b fi ma lw l lx ly"># evaluation<br/><strong class="lq hy">print("Mean absolute error: %.2f" % np.mean(np.absolute(y_hat - test_y)))<br/>print("Residual sum of squares (MSE): %.2f" % np.mean((y_hat - test_y) ** 2))<br/>from sklearn.metrics import r2_score<br/>print("R2-score: %.2f" % r2_score(y_hat , test_y)</strong></span></pre><blockquote class="mb mc md"><p id="2bcc" class="jz ka lz kb b kc me ke kf kg mf ki kj mg mh km kn mi mj kq kr mk ml ku kv kw hb bi translated"><strong class="kb hy">平均绝对误差:0.05 <br/>残差平方和(MSE): 0.00 <br/> R2评分:0.95 </strong></p></blockquote><h1 id="bb7e" class="jb jc hx bd jd je lg jg jh ji lh jk jl jm li jo jp jq lj js jt ju lk jw jx jy bi translated">感谢阅读</h1><p id="da76" class="pw-post-body-paragraph jz ka hx kb b kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw hb bi translated">更多此类内容<a class="ae mo" rel="noopener" href="/@kalamanoj989">点击此处</a>并关注我。</p></div></div>    
</body>
</html>