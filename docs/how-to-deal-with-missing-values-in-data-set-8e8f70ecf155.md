# å¦‚ä½•å¤„ç†ä¸€ä¸ªæ•°æ®é›†ä¸­çš„ç¼ºå¤±å€¼ï¼Ÿ

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/how-to-deal-with-missing-values-in-data-set-8e8f70ecf155?source=collection_archive---------8----------------------->

ç°å®ä¸–ç•Œçš„æ•°æ®é›†ç”±ç¼ºå¤±å€¼ç»„æˆï¼Œæ•°æ®ç§‘å­¦å®¶èŠ±è´¹å¤§é‡æ—¶é—´è¿›è¡Œæ•°æ®å‡†å¤‡ï¼ŒåŒ…æ‹¬æ•°æ®æ¸…ç†ã€‚ç¼ºå°‘å€¼å¯èƒ½æ˜¯æœªè®°å½•çš„è§‚å¯Ÿç»“æœæˆ–æ•°æ®æŸåçš„ç»“æœã€‚

**ç¼ºå¤±æ•°æ®çš„ç±»å‹**

*   éšæœºç¼ºå¤±(MAR)-è¿™æ„å‘³ç€ç¼ºå¤±å€¼çš„æ¯”ä¾‹ä¸è§‚å¯Ÿæ•°æ®ä¹‹é—´å­˜åœ¨å…³ç³»ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸‹å›¾ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°é‡Œç¨‹åˆ—ä¸­ç¼ºå¤±å€¼çš„æ¯”ä¾‹ä¸æ±½è½¦çš„åˆ¶é€ å¹´ä»½ç›¸å…³ã€‚å› æ­¤ï¼Œå¯ä»¥ä½¿ç”¨å…¶ä»–ç‰¹å¾æ¥é¢„æµ‹æ•°æ®é›†ä¸­è¿™ç§ç±»å‹çš„ç¼ºå¤±å€¼ã€‚

![](img/48a20b28a421702d164503c3411e9e4e.png)

ç¼ºå¤±å€¼ç™¾åˆ†æ¯”ä¸æ±½è½¦åˆ¶é€ å¹´ä»½çš„å…³ç³»ã€‚

*   å®Œå…¨éšæœºç¼ºå¤±(means è¿™æ„å‘³ç€ç¼ºå¤±å€¼çš„æ¯”ä¾‹ä¸æ•°æ®ä¸­çš„ä»»ä½•è§‚å¯Ÿæ— å…³ã€‚ä¾‹å¦‚ï¼Œç”µå­ç§¤ç”µæ± æ²¡ç”µäº†ï¼Œå› æ­¤ä¼šä¸¢å¤±ä¸€äº›æ•°æ®ã€‚
*   ééšæœºç¼ºå¤±(MNAR)-è¿™æ„å‘³ç€ç¼ºå¤±çš„æ•°æ®ä¸æˆ‘ä»¬æœªçŸ¥çš„å› ç´ æœ‰å…³ã€‚ä¾‹å¦‚ï¼Œç§°é‡ç§¤æœºæ¢°è£…ç½®å¯èƒ½ä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œç£¨æŸï¼Œä»è€Œéšç€æ—¶é—´çš„æ¨ç§»äº§ç”Ÿæ›´å¤šçš„ç¼ºå¤±å€¼ï¼Œä½†æˆ‘ä»¬å¯èƒ½ä¸ä¼šæ³¨æ„åˆ°åŒæ ·çš„æƒ…å†µã€‚å¦‚æœæˆ‘ä»¬æœ‰ MNAR ä¸¢å¤±æœºåˆ¶ï¼Œæˆ‘ä»¬éœ€è¦ç†è§£ä¸ºä»€ä¹ˆæ•°æ®ä¸¢å¤±ï¼Œè€Œä¸æ˜¯ç›´æ¥å½’å’äºå®ƒä»¬ã€‚

**åœ¨ Python ä¸­æ£€æµ‹ç¼ºå¤±å€¼**

ç¼ºå¤±å€¼çš„å½¢å¼å¯ä»¥æ˜¯ç©ºå­—ç¬¦ä¸²ã€NAã€N/A æˆ– Noneã€‚python ä¸­çš„ Pandas å°†æ•°æ®ä¸­çš„æ‰€æœ‰ NA æˆ–ç©ºç™½å€¼æ ‡è¯†ä¸º NaN å€¼ã€‚ä½†æ˜¯ï¼Œå®ƒä¸è¯†åˆ« naï¼Œï¼Ÿå¯ä½¿ç”¨ **df.isnull()** å‘½ä»¤æ£€æµ‹æ•°æ®é›†ä¸­çš„ NA æˆ–ç©ºç™½å€¼æ ¼å¼ã€‚å½“æ•°æ®ä¸­å­˜åœ¨ç¼ºå¤±å€¼æ—¶ï¼Œæ­¤æ–¹æ³•è¿”å›å¸ƒå°”å“åº” Trueã€‚

ä½†æ˜¯ï¼Œæœ‰æ—¶å¯èƒ½ä¼šå‡ºç°æ•°æ®ä¸­ç¼ºå¤±å€¼çš„æ ¼å¼ä¸åŒçš„æƒ…å†µã€‚ä¾‹å¦‚ï¼ŒæŸä¸€åˆ—ç¼ºå°‘ n/aã€_ _ æˆ– na æ ¼å¼çš„å€¼ã€‚åœ¨å¯¼å…¥æ•°æ®æ—¶ï¼Œpandas æ£€æµ‹æ•°æ®é›†ä¸­éæ ‡å‡†æ ¼å¼çš„ç¼ºå¤±å€¼çš„ä¸€ä¸ªç®€å•æ–¹æ³•æ˜¯å°†æ‰€æœ‰ç±»å‹çš„ç¼ºå¤±å€¼ä½œä¸ºä¸€ä¸ªåˆ—è¡¨ã€‚

```
missing_values = ["n/a", "na", " _ _"]
df = pd.read_csv("loan data.csv", na_values = missing_values)
```

åœ¨æ•°æ®é›†ä¸­ **df.isnull()ã€‚sum()** å‘½ä»¤ç”¨äºæŸ¥æ‰¾æ•°æ®ä¸­æ¯ä¸ªç‰¹å¾ç¼ºå¤±å€¼çš„æ€»æ•°ã€‚

**åœ¨ Python ä¸­å¯è§†åŒ–ç¼ºå¤±å€¼**

å¯è§†åŒ–ç¼ºå¤±å€¼ä½¿åˆ†æå¸ˆèƒ½å¤Ÿå¾ˆå¥½åœ°ç†è§£æ•°æ®é›†ä¸­ NaN å€¼çš„åˆ†å¸ƒã€‚

```
# Import the library
pip install missingno
import missingno as msno
# Visualize the missing values using a matrix 
msno.matrix(df)
```

![](img/fe3b6125d1a98efa6cfaf78729449a67.png)

`AAWhiteSt-4`å’Œ`SulphidityL-4 columns`çš„å¤±è¸ªæ¨¡å¼ç›¸ä¼¼

æ¯åˆ—ä¸­ç¼ºå¤±å€¼çš„è®¡æ•°ç”¨æ¡å½¢å›¾è¡¨ç¤ºã€‚

```
# Visualize missing values as a bar chartmsno.bar(df)
```

![](img/b07466d5bddcff1b28506459c1d0fc97.png)

çƒ­å›¾è¡¨ç¤ºæ¯åˆ—ä¸­ç¼ºå¤±å€¼ä¹‹é—´çš„ç›¸å…³æ€§ã€‚
å¯¹åº”äº-1 çš„å€¼è¡¨ç¤ºæ•°æ®é›†ä¸­çš„å˜é‡ A å¯¼è‡´å…¶å˜é‡ b ä¸­çš„å€¼ç¼ºå¤±

```
msno.heatmap(df)
```

![](img/16e1d6d5f0f9870786a8f26ad726f129.png)

**å¤„ç†ç¼ºå¤±å€¼çš„æ–¹æ³•**

**1 åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„åˆ—å’Œè¡Œ**

åˆ é™¤ MCAR æ•°æ®ä¸­åŒ…å«ç¼ºå¤±å€¼çš„åˆ—å’Œè¡Œã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•çš„é—®é¢˜æ˜¯ä¿¡æ¯çš„ä¸¢å¤±ã€‚å¦‚æœæ•°æ®ä¸­ç¼ºå¤±å€¼çš„æ•°é‡è¶…è¿‡ 70â€“75 %,å»ºè®®åˆ é™¤ç‰¹å®šçš„åˆ—ã€‚æ­¤å¤–ï¼Œå½“æˆ‘ä»¬æœ‰å¤§å‹æ•°æ®é›†æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥åˆ é™¤åŒ…å«ç©ºå€¼çš„è¡Œã€‚ä½†æ˜¯ï¼Œå¦‚æœæ•°æ®é›†ä¸­ç¼ºå¤±å€¼çš„ç™¾åˆ†æ¯”å¤§äº 30 %,åˆ™ä¸å»ºè®®è¿™æ ·åšã€‚

```
#Drop the rows with at least one element missing
df.dropna(inplace = True)# Drop the rows with all the elements missing
df.dropna(how='all',inplace = True)# Drop the rows with missing values greater than two
df.dropna(thresh=2, inplace = True)# Drop the rows with at least one missing value in the columns specified in the subset function
df.dropna(subset=['age', 'fare'])# Drop the columns with at least one missing value
df.dropna(axis= 1 , inplace = True)# Drop the columns containing all the elements missing
df.dropna(axis= 'columns',how = 'all', inplace = True)
```

**2 ç”¨å¹³å‡å€¼ã€ä¸­å€¼å’Œä¼—æ•°è¾“å…¥æ•°æ®ä¸­çš„ç¼ºå¤±å€¼**

æˆ‘ä»¬å¯ä»¥ç”¨ç‰¹å®šç‰¹å¾çš„å¹³å‡å€¼ã€ä¸­å€¼æˆ–ä¼—æ•°æ¥æ›¿æ¢æ•°æ®é›†ä¸­çš„ç¼ºå¤±å€¼ï¼Œä½†è¿™ç§æ–¹æ³•ä¼šå¯¼è‡´ä½ä¼°æ–¹å·®ï¼Œå¹¶ä¼šå¢åŠ æ•°æ®ä¸­çš„åå·®ã€‚å½“æ•°æ®é‡å¾ˆå°æ—¶ï¼Œè¿™ç§æ–¹æ³•æ˜¯ç†æƒ³çš„ï¼Œå› ä¸ºå®ƒæœ‰åŠ©äºé˜²æ­¢ä¿¡æ¯ä¸¢å¤±ï¼Œä½†åœ¨ python ä¸­è¿›è¡Œå‡å€¼æˆ–ä¸­å€¼æ’è¡¥æ—¶ï¼Œå®ƒæ²¡æœ‰è€ƒè™‘å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ç§å•å˜é‡æ–¹æ³•ã€‚

ä¾‹å¦‚ï¼Œåœ¨åŒ…å«â€œå¹´é¾„â€å’Œâ€œè´¹ç”¨â€åˆ—çš„æ•°æ®é›†ä¸­ï¼Œå¹´é¾„ç‰¹å¾ä¸­æœ‰ç¼ºå¤±å€¼ã€‚å¦‚æœæˆ‘ä»¬ç”¨å¹³å‡å¹´é¾„æ¥ä¼°ç®—ç¼ºå¤±å€¼ï¼Œé‚£ä¹ˆç”±äºå¹´é¾„å’Œç¥¨ä»·ç‰¹å¾ä¹‹é—´çš„æ­£ç›¸å…³ï¼Œå¯èƒ½ä¼šå¯¼è‡´åå·®å¢åŠ ã€‚

```
from sklearn.impute import SimpleImputer
mean_imp = SimpleImputer( strategy='mean') 
# For Mode replace strategy with most_frequent
# For Median replace strategy with Medianmean_imp.fit(train)
train_df = mean_imp.transform(train)
```

å¦‚æœæˆ‘ä»¬å¸Œæœ›æ•°æ®é¦–å…ˆè¢«å¤„ç†ä¸ºç¼ºå¤±å€¼ï¼Œç„¶åç”±æˆ‘ä»¬çš„æ¨¡å‹ä½¿ç”¨ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç®¡é“ï¼Œå› ä¸ºè¿™å¯ä»¥é˜²æ­¢æ•°æ®æ³„æ¼ã€‚

```
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
# define the imputer
imputer = SimpleImputer(strategy='mean')
# define the model
lda = LinearDiscriminantAnalysis()
# define the modeling pipeline
pipeline = Pipeline(steps=[('imputer', imputer),('model', lda)])
# define the cross validation procedure
kfold = KFold(n_splits=3, shuffle=True, random_state=1)
# evaluate the model
result = cross_val_score(pipeline, X, y, cv=kfold, scoring='accuracy')
```

**3 ä½¿ç”¨ k-NN çš„æ’è¡¥**

*k* æœ€è¿‘é‚»æ˜¯ä¸€ç§ç®—æ³•ï¼Œå…¶ä¸­æ–°ç‚¹æ ¹æ®å…¶ä¸è®­ç»ƒæ•°æ®é›†ä¸­çš„ç‚¹çš„ç›¸ä¼¼æ€§è¢«åˆ†é…ä¸€ä¸ªå€¼ã€‚è¿™ç§æ–¹æ³•å¯ä»¥é€šè¿‡ä¸ç¼ºå¤±æ•°æ®ç›¸é‚»çš„éç¼ºå¤±å€¼æ¥ä¼°ç®—æ¯ä¸ªç‰¹å¾çš„ç¼ºå¤±å€¼ã€‚æ ¹æ®æ•°æ®é›†çš„ä¸åŒï¼Œå®ƒå¯ä»¥æä¾›æ¯”ä¼—æ•°ã€ä¸­ä½æ•°æˆ–å¹³å‡æ•°æ’è¡¥æ›´å‡†ç¡®çš„ç»“æœã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•åœ¨è®¡ç®—ä¸Šæ˜¯æ˜‚è´µçš„ï¼Œå› ä¸ºæ•´ä¸ªè®­ç»ƒæ•°æ®é›†è¢«å­˜å‚¨åœ¨å­˜å‚¨å™¨ä¸­ï¼Œå¹¶ä¸”ä¸ SVM ä¸åŒï¼Œå®ƒå¯¹æ•°æ®ä¸­çš„å¼‚å¸¸å€¼æ•æ„Ÿã€‚

```
from sklearn.impute import KNNImputer
# define imputer
imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')
# fit on the data set
imputer.fit(X)
# fit on the data set
imputer.fit(X)
# transform the data set
Xtrans = imputer.transform(X)
```

**4 é“¾å¼æ–¹ç¨‹å¤šé‡æ’è¡¥(å°é¼ )**

MICE æ˜¯ä¸€ç§å¤šé‡æ’è¡¥æŠ€æœ¯ï¼Œç”¨ MAR ç¼ºå¤±æœºåˆ¶æ¥ä»£æ›¿æ•°æ®é›†ä¸­çš„ç¼ºå¤±å€¼ã€‚å®ƒä½¿ç”¨æ•°æ®ä¸­çš„å…¶ä»–ç‰¹å¾ä¸ºæ¯ä¸ªç¼ºå¤±å€¼åšå‡ºæœ€ä½³é¢„æµ‹ã€‚åœ¨è¯¥ç®—æ³•ä¸­ï¼Œæ¯ä¸ªç¼ºå¤±å€¼éƒ½æ˜¯æ ¹æ®æ•°æ®ä¸­çš„è§‚å¯Ÿå€¼å»ºæ¨¡çš„ã€‚è¦äº†è§£å…³äº MICE ç®—æ³•çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹â€œ [*MICE ç®—æ³•ä»¥ä¼°ç®—æ•°æ®é›†ä¸­çš„ç¼ºå¤±å€¼*](/swlh/mice-algorithm-to-impute-missing-values-in-a-dataset-c55d555b6fbe) â€ã€‚è¯¥ç®—æ³•å¯ä»¥ä½¿ç”¨ Scikit-learn è¿­ä»£ä¼°ç®—å™¨æ¥å®ç°ã€‚

```
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
```

åœ¨æ­¤ä¹‹åï¼Œæˆ‘ä»¬å°†å‘ç° X ä¸­çš„å€¼æ˜¯å¦‚ä½•ç›¸äº’å…³è”çš„ï¼Œä»¥å†³å®šä½¿ç”¨å“ªç§ç®—æ³•æ¥ä¼°ç®—ç©ºå€¼ã€‚

```
X.corr()
lr  = LinearRegression()
imp = IterativeImputer(estimator = lr ,verbose = 2 ,max_iter = 30,tol = 1e-10,order = 'roman')
imp.fit(X)
imp.transform(X)
```

**ç»“è®º**

ç”±äºç¼ºå°‘å®Œæ•´çš„ä¿¡æ¯ï¼Œç¼ºå¤±æ•°æ®å¯èƒ½ä¼šå¯¼è‡´æ— æ•ˆçš„ç»“æœã€‚å®ƒä»¬è¢«å¤„ç†ä¸ºåœ¨ç”±ç¼ºå¤±å€¼ç»„æˆçš„æ•°æ®é›†ä¸Šè®­ç»ƒ ML æ¨¡å‹ä¼šå¯¼è‡´é”™è¯¯ï¼Œå› ä¸º python åº“(åŒ…æ‹¬ Scikit learn)ä¸æ”¯æŒå®ƒä»¬ã€‚
ç‚¹å‡»ğŸ’šå¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ã€‚æœ‰é—®é¢˜å¯ä»¥å†™åœ¨ä¸‹é¢çš„è¯„è®ºåŒºï¼Œæˆ‘ä¼šå°½åŠ›è§£ç­”ã€‚