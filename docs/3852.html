<html>
<head>
<title>Sparse R-CNN: the New Detector Type</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">稀疏R-CNN:新的检测器类型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sparse-r-cnn-the-new-detector-type-799ce31fb403?source=collection_archive---------6-----------------------#2021-08-01">https://medium.com/analytics-vidhya/sparse-r-cnn-the-new-detector-type-799ce31fb403?source=collection_archive---------6-----------------------#2021-08-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="8532" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">今天我们将讨论一种由四个机构的研究人员提出的<a class="ae jc" href="https://arxiv.org/abs/2011.12450" rel="noopener ugc nofollow" target="_blank">方法</a>，其中一个机构是字节跳动人工智能实验室(以其抖音应用而闻名)。他们为我们提供了一种新方法，称为稀疏R-CNN(不要与稀疏R-CNN混淆，稀疏R-CNN在3D计算机视觉任务中使用稀疏卷积，如<a class="ae jc" href="http://kaldir.vc.in.tum.de/scannet_benchmark/" rel="noopener ugc nofollow" target="_blank">、</a>，它在对象检测中实现了接近最先进的性能，并使用完全稀疏和可学习的边界框生成</p><h1 id="02e7" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">相关著作</h1><p id="3f58" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">让我们从现有检测方法的简要概述开始。</p><h2 id="5730" class="kg je hh bd jf kh ki kj jj kk kl km jn ip kn ko jr it kp kq jv ix kr ks jz kt bi translated">密集方法</h2><p id="2fa4" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">广泛使用的管道之一是一级检测器，<br/>以单次方式直接预测密集覆盖空间位置、比例和纵横比<br/>的锚盒<br/>的标签和位置。例如<a class="ae jc" href="https://arxiv.org/abs/1512.02325" rel="noopener ugc nofollow" target="_blank"> SSD </a>或者<a class="ae jc" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank"> YOLO </a>。</p><p id="e8b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们考虑一下YOLO算法。最终，它旨在预测图像上对象的类别和指定对象位置的边界框。每个边界框可以用四个描述符来描述:</p><ol class=""><li id="af92" class="ku kv hh ig b ih ii il im ip kw it kx ix ky jb kz la lb lc bi translated">边框中心(<strong class="ig hi"> <em class="ld"> bx，by </em> </strong>)</li><li id="b4ce" class="ku kv hh ig b ih le il lf ip lg it lh ix li jb kz la lb lc bi translated">宽度(<strong class="ig hi"> <em class="ld">宽度</em> </strong>)</li><li id="0ce2" class="ku kv hh ig b ih le il lf ip lg it lh ix li jb kz la lb lc bi translated">高度(<strong class="ig hi"> <em class="ld"> bh </em> </strong>)</li><li id="78c4" class="ku kv hh ig b ih le il lf ip lg it lh ix li jb kz la lb lc bi translated">值<strong class="ig hi"> <em class="ld"> c </em> </strong>对应一类物体(如:汽车、红绿灯等。).</li></ol><p id="a5cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另外我们还要预测<strong class="ig hi"> <em class="ld"> pc </em> </strong>值，也就是包围盒中有物体的概率。</p><p id="6c1d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一种<strong class="ig hi">密集方法</strong>，因为它不是在给定图像中搜索可能包含对象的感兴趣区域。相反，YOLO使用19×19的网格将图像分割成单元。但是一般来说，一级检测器可以产生<strong class="ig hi"> W </strong> × <strong class="ig hi"> H </strong>个单元，每个像素一个。每个单元负责预测<strong class="ig hi"> <em class="ld"> k </em> </strong>边界框(在这个例子中<strong class="ig hi"> k </strong>被选为5)。因此，对于一幅图像，我们得到大量的<strong class="ig hi">W</strong>×<strong class="ig hi">H</strong>×<strong class="ig hi">k</strong>边界框。</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="er es lj"><img src="../Images/dd62118ff111e62e29e6c0fd2e2baa27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*E_uZnnXb9L-9j9J6.png"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">对于网格中的每个单元格和每个bbox，产生上述值(<a class="ae jc" href="https://appsilon.com/object-detection-yolo-algorithm/" rel="noopener ugc nofollow" target="_blank">源</a>)</figcaption></figure><h2 id="8680" class="kg je hh bd jf kh ki kj jj kk kl km jn ip kn ko jr it kp kq jv ix kr ks jz kt bi translated">密集到稀疏方法</h2><p id="a573" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">有两级检测器，搭载在使用RPN生成的密集建议上，如<a class="ae jc" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">更快的R-CNN </a>论文提出的。这些探测器多年来一直主导着现代物体探测。</p><p id="73e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用RPN，它从密集区域候选中获得一个稀疏的前景建议框集，然后细化每个建议的位置，<br/>预测其特定类别。</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es lz"><img src="../Images/a727a08557329923aaec174865771f54.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/0*aO0pY2fo9osCJ5j6.png"/></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">(<a class="ae jc" href="https://arxiv.org/pdf/1506.01497.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="b7cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以与一级检测器中类似的方式获得建议，但是它不是直接预测目标的类别，而是预测目标概率。然后，第二阶段通过目标过滤和重叠分数包围盒来预测类别。</p><h2 id="9317" class="kg je hh bd jf kh ki kj jj kk kl km jn ip kn ko jr it kp kq jv ix kr ks jz kt bi translated">稀疏方法</h2><p id="200c" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">本文作者将其新的稀疏R-CNN范式归类为现有对象检测器范式的扩展，该范式包括从完全密集到密集到稀疏，以及导致完全稀疏的新步骤。</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="er es ma"><img src="../Images/8cb5db63c693dae306779545eeacac4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3arT86nO50INZzu84-TQUg.png"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">模型架构比较(<a class="ae jc" href="https://arxiv.org/pdf/2011.12450.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="cb06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在审阅的论文中，避免使用RPN，代之以一小组建议框(例如每张图片100个)。这些框是使用网络的可学习的<em class="ld">建议框</em>部分和<em class="ld">建议特征</em>部分获得的。前者预测每个建议的<em class="ld"> 4 </em>值<em class="ld"> (x，y，h，w) </em>，后者预测每个bbox内容的长度为256的潜在表示向量。学习到的建议框被用作一个合理的统计量来执行随后的提炼步骤，并且学习到的建议特征被用于引入注意机制。这种机制与DETR论文中使用的机制非常相似。这种操作是在动态实例交互头中执行的，我们将在下一节中介绍。</p><h1 id="f4e6" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">建议的模型特征</h1><p id="3534" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">顾名思义，这个模型是端到端的。建筑很优雅。它包括从图像中获取特征的基于FPN的主干、上面提到的可学习的<em class="ld">建议框</em>和<em class="ld">建议特征</em>以及动态实例交互头，这是对本文的神经网络架构的主要贡献。</p><h2 id="bad0" class="kg je hh bd jf kh ki kj jj kk kl km jn ip kn ko jr it kp kq jv ix kr ks jz kt bi translated">动态实例交互头</h2><p id="2da8" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">给定<em class="ld"> N个</em>提议框，稀疏R-CNN首先利用RoIAlign操作<br/>为用提议边界框定义的每个区域从主干提取特征。每个RoI特征被馈送到其自己的专用头部中，用于对象定位和分类，其中每个头部以特定的可学习提议特征为条件。</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div class="er es mb"><img src="../Images/abf267ee398799aff365214419e9fbfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1346/format:webp/1*wWvhsOw1lIi_Z0Zi6SEldg.png"/></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">动态模块(<a class="ae jc" href="https://arxiv.org/pdf/2011.12450.pdf" rel="noopener ugc nofollow" target="_blank">源</a>)</figcaption></figure><p id="0440" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">提议特征被用作卷积的权重，在上面的图像中，它们被称为“参数”RoI特征通过<br/>处理这个生成的卷积来获得最终的特征。以这种<br/>方式，那些具有最多前景信息的箱对最终的对象定位和分类产生影响。自我注意模块被嵌入到动态头中，以推理对象之间的关系，并通过这种卷积影响预测。</p><h1 id="a73e" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">主要结果</h1><p id="3e09" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">作者提供了几个显示新方法性能的比较表。在ResNet50和ResNet100的两个变体中，将稀疏R-CNN与RetinaNet、更快R-CNN和DETR进行比较。</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="er es mc"><img src="../Images/e26535e14398a7849bb95fc1098aa5d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wsG3UceZi9moRunnJMjtpg.png"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">模特表演(<a class="ae jc" href="https://arxiv.org/pdf/2011.12450.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="6fbf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里我们可以看到，在R50和R100中，稀疏R-CNN的性能优于RetinaNet和更快的R-CNN，但其性能与基于DETR的架构非常相似。</p><p id="4873" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据作者，DETR模型实际上是密集到稀疏模型，因为它利用一组稀疏的对象查询来与全局(密集)图像特征交互。因此，与DETR相比，这篇文章很新颖。</p><figure class="lk ll lm ln fd lo er es paragraph-image"><div role="button" tabindex="0" class="lp lq di lr bf ls"><div class="er es md"><img src="../Images/0aff11542c29d098f184ce13a82f6772.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-nG3eh2gkDTAlGCToHKmlw.png"/></div></div><figcaption class="lv lw et er es lx ly bd b be z dx translated">定性分析(<a class="ae jc" href="https://arxiv.org/pdf/2011.12450.pdf" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="6b24" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在图像上，您可以看到COCO数据集上模型推断定性结果。在第一列中示出了已学习的提议框，它们是针对任何新图像预测的。在接下来的专栏中，您可以看到从提案中提炼出来的最终结果。它们因迭代学习过程的不同阶段而不同。</p><h1 id="c4cb" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">给我看看代码！</h1><p id="9779" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">最后，我想说的是，在2020年，我们会看到很多将变形金刚应用于图像的论文。变形金刚已经在自然语言处理领域证明了自己的价值，现在也逐渐进入图像处理领域。这篇论文向我们展示了使用变压器可以创建快速单级检波器，其性能在质量方面可与目前最好的两级检波器相媲美。</p><p id="b56c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以在作者的代码中找到关于实现的所有细节，这些代码基于费尔的DETR和detectron2代码库:<a class="ae jc" href="https://github.com/PeizeSun/SparseR-CNN" rel="noopener ugc nofollow" target="_blank">https://github.com/PeizeSun/SparseR-CNN</a></p><h1 id="c030" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">参考</h1><p id="26b7" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">[1]更快的R-CNN:用区域提议网络实现实时目标检测<a class="ae jc" href="https://arxiv.org/abs/1506.01497" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.01497</a></p><p id="bf6a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2]https://appsilon.com/object-detection-yolo-algorithm/<a class="ae jc" href="https://appsilon.com/object-detection-yolo-algorithm/" rel="noopener ugc nofollow" target="_blank">YOLO算法和YOLO目标检测简介</a></p><p id="36ee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[3]稀疏R-CNN:具有可学建议的端到端对象检测<a class="ae jc" href="https://arxiv.org/abs/2011.12450" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2011.12450</a></p></div></div>    
</body>
</html>