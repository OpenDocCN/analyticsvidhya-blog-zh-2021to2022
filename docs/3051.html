<html>
<head>
<title>Backyard Bird Classification with Fast AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于快速人工智能的后院鸟类分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/backyard-bird-classification-with-fast-ai-280dd140e32f?source=collection_archive---------9-----------------------#2021-05-31">https://medium.com/analytics-vidhya/backyard-bird-classification-with-fast-ai-280dd140e32f?source=collection_archive---------9-----------------------#2021-05-31</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/23b9331f32acefc8051f73f14d37b703.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f8gvZHlskEUZo8j5Tt1RBQ.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">两只哀悼的鸽子出去吃早餐</figcaption></figure><p id="a584" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">每天早上，在我家，我们把食物放在后院的鸟窝里。在过去的几个星期里，我注意到许多新的鸟类来这里觅食，我认为这将是一个有趣的项目，可以确切地看到哪些类型的鸟类正在来访。</p><p id="c1f3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为此，我使用Fast AI的库训练了一个神经网络。这是我第一次用神经网络做实验，我玩得很开心。我强烈建议有兴趣的人尝试一下。我们现在可以轻而易举地训练神经网络来完成细粒度的分类，这是令人震惊的。我将在下面详细介绍我使用的整个过程和我的发现，以供任何想自己尝试或根据自己的用例修改它们的人参考。</p><h1 id="be43" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">快速人工智能</h1><p id="ac91" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">在我深入研究代码和流程之前，我想回顾一下我们将在整个项目中使用的主要工具。第一个是快速人工智能。Fast AI是一个深度学习库，它简化了精确快速神经网络的训练。在这篇文章的过程中，有许多实例表明该库在加速训练高度精确的神经网络的过程中大放异彩。在制作模型的每一步，开发人员似乎都广泛考虑了用户的体验。结果用上了Fast AI也是一件乐事。</p><h1 id="4428" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">残差神经网络</h1><p id="7732" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">残差神经网络是2015年由、何、、、任和在论文<a class="ae ku" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">中介绍的一种特定类型的神经网络。</a></p><p id="ac7e" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">残差神经网络被创建来解决消失梯度和爆炸梯度的问题。消失和爆炸渐变的问题如下。神经网络由层组成，层数代表网络的深度。因此，深度成为影响性能的重要参数。在寻求创造更好的网络的过程中，出现了一个问题:创造更好的网络的解决方案是否增加了更多的层，从而增加了更多的深度？</p><p id="085b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">当这个想法被测试时，神经网络经常会到达停滞点(消失梯度)或不稳定点，在那里模型不能收敛到最优解(爆炸梯度)。</p><p id="c83d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了解决这个问题，该论文描述了一种神经网络的体系结构，其中在层间使用跳跃连接。这些跳过连接允许模型中的较深层了解很少。通常，如果保持层不变是有益的，则通过跳过连接学习的函数将类似于相同函数的概念。identity函数返回与作为输入接收的值相同的值。这将导致更深层次的变化最小或没有变化，从而解决消失和爆炸梯度的问题。Yannic Kilcher 的一个<a class="ae ku" href="https://www.youtube.com/watch?v=GWt6Fu05voI" rel="noopener ugc nofollow" target="_blank">视频很好地描述了这种架构背后的深入解释。总的来说，跳过连接允许通过不强迫后面的层继续学习来训练更深的网络。</a></p><h1 id="1576" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">迁移学习</h1><p id="49a9" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">快速人工智能提供的神经网络训练速度部分是由于迁移学习的概念。在迁移学习中，预先训练的模型被用来解决一个新的但相关的问题。</p><p id="9a74" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">传统的学习模式如下。我们有可能是但不限于图像像素、数字数据或分类数据的特征。我们也有一个目标，对应于我们试图预测的一些特征。例如，目标是图像中显示的动物的猫和狗的图像。使用这些特征和目标，可以为手头的任务从头开始训练模型。</p><p id="63cb" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">迁移学习允许使用预先训练好的神经网络作为新任务的起点。以上面的狗和猫为例，假设有一个用许多动物作为其特征训练的模型，而不管特征空间中是否包括狗和猫。然后，我们将能够使用这个预训练的模型，并重新训练一些最后的层，以完成识别狗和猫的新任务。</p><p id="87cf" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">当没有足够的标记数据来训练特定任务的模型时，以及当模型需要快速训练时，迁移学习特别有用。考虑到这一点，使用迁移学习可以达到最先进的结果是非同寻常的。</p><h1 id="e7b3" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">构建数据集</h1><p id="6362" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">在训练我的神经网络之前，我首先必须建立一个数据集，以便神经网络可以学习不同种类的鸟类。这个数据集将由两个主要部分组成:一幅鸟的图像和图像中鸟的种类的文本标签。</p><p id="d293" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了决定我应该让我的神经网络意识到什么物种，我首先必须获得一些关于我居住的城市的当地鸟类的知识。为了做到这一点，我去了几个当地的观鸟网站，并开始收集我所在城市常见的鸟类物种。通过这种方式，我可以缩小鸟类的范围，并选择哪些种类来训练我的模型。</p><p id="4c85" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在我有了物种清单，我准备开始收集一些图片。创建基于图像的数据集的一种快速简单的方法是使用Google Images。从Google Images下载图片的方法有很多:Python脚本、浏览器JavaScript控制台和浏览器扩展。我收集图像的过程如下:</p><ol class=""><li id="25da" class="kv kw hh iv b iw ix ja jb je kx ji ky jm kz jq la lb lc ld bi translated">为您的浏览器下载一个扩展，允许您从Google Images下载图像。</li><li id="f1fd" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">搜索您想要查找图像的特定主题。在我们的情况下，这将是一个特殊的物种，如“蓝鸟”。</li><li id="deef" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">滚动到屏幕上图像的一个好的部分。值得注意的是，您选择的图像越好，您以后必须手动删除的图像就越少。</li><li id="1c6b" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">使用扩展下载图像。我为每个物种下载了25到30张图片，但是根据你的应用和结果，你可能想增加这个数字。我第一次尝试使用10到15张图片时，效果并不好。图像的增加极大地帮助了我的模型。</li><li id="cda2" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">按主题对图片进行分类。在本例中，我为数据集创建了一个文件夹，并为鸟类创建了子文件夹。</li><li id="969a" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">对每个主题重复此过程。在我的案例中，我为我所有的物种重复了这一点。</li><li id="9c71" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq la lb lc ld bi translated">使用Fast AI中的“验证图像”命令来确保每个图像都可以打开。</li></ol><p id="6252" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在此过程结束时，数据集应该类似于下图中的结构。</p><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es lj"><img src="../Images/f0187ce913deb2e9d2c2fe16662d2fde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*iCN1yKnpTEhHOxXFtJu2fQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">查看主数据集文件内部——按物种排序，每个文件夹包含物种的图像</figcaption></figure><h1 id="6393" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">训练模型</h1><p id="7211" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">随着数据集的建立，是时候训练模型了。我们将从读入上面创建的数据集开始。</p><p id="ce4f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">快速AI读取数据集中的ImageDataLoaders函数。由于数据集是按物种而不是训练测试分割的，我提供了一个验证百分比。这个百分比是应该保留下来用于检查模型性能的数据部分。以下命令调整图像的大小，使每个图像的大小一致。最后，图像数据被归一化。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="85f7" class="lt js hh lp b fi lu lv l lw lx">data = ImageDataLoaders.from_folder(path, valid_pct=0.2,item_tfms=[Resize(460)], batch_tfms=[*aug_transforms(size=224), Normalize.from_stats(*imagenet_stats)])</span></pre><p id="bb2a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了确保我们的数据集被正确读入，可以使用show_batch命令来显示带标签的数据集的一部分。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="efbe" class="lt js hh lp b fi lu lv l lw lx">data.show_batch()</span></pre><p id="f227" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">确认数据集看起来不错后，就该初始化和训练模型了。我们将使用ResNet34来训练我们的模型，resnet 34是由34层组成的残差神经网络。下面的第一行代码通过接收我们在上面创建的数据对象、模型类型和度量类型来初始化我们的模型，以评估模型的执行情况。第二行代码训练我们的模型，并接受参数n_epoch，它告诉模型要执行多少次训练迭代，或者更具体地说是随机梯度过程。第三行代码简单地保存了我们的模型，这样，如果我们想在代码中进一步恢复或调用这个特定的模型，我们可以这样做。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="693e" class="lt js hh lp b fi lu lv l lw lx">learn = cnn_learner(data, models.resnet34, metrics = error_rate) learn.fit_one_cycle(n_epoch=4)<br/>learn.save('stage1')</span></pre><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es ly"><img src="../Images/c96ce0b7b38a35717eeec6ae155be31f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*bl_k_2GXvDfhpzzzBjSWQQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">第一轮培训的结果</figcaption></figure><p id="6e46" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们前4次迭代的结果如上所示。在4个时期之后，我能够降低到大约0.29的错误率。尽管结果模型在4个时期内有了显著改善，但错误率仍然很高。为了更好地判断我的模型所处的位置，我查看了Fast AI社区中一些与我的相似的图像分类项目。</p><p id="f461" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了降低错误率，我试图优化学习率。学习率过高或过低都会损害模型。大的学习率会阻止模型收敛到最优解，而小的学习率会导致训练过早停止。因此，找到最佳学习速度的解决方案通常是尝试不同的速度。幸运的是，Fast AI有一个函数可以做到这一点，如下面的代码所示。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="db80" class="lt js hh lp b fi lu lv l lw lx">learn.unfreeze()<br/>learn.lr_find()</span></pre><p id="b30a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">第一行代码“解冻”了初始化的模型。当模型被“冻结”时，除了神经网络的最后一层之外，禁止对每一层进行修改。这背后的动机可以追溯到上面提到的迁移学习。为了利用预训练的模型，我们不想篡改早期层的学习。第二行代码以非常低的学习率开始训练一个模型。然后，学习率在许多时间间隔内增加，直到非常高。在每个时间间隔，记录损失并绘制在下图中。执行这一图表背后的直觉是，为了找到更优的学习率，要进行一些猜测。看这张图时，找到一个有陡峭下坡的区域是很重要的。如果图形有多个，尝试两个区域会有帮助。</p><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lz"><img src="../Images/9c5191451c6edea94716cad235ceff62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*dGx3Z43N5rq7rpwoysV65g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">损失对学习率图，以找到学习率的最佳切片</figcaption></figure><p id="de00" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">如上所示，我的特定模型的图表在1e-4和1e-3之间有一个明显的向下陡峭斜坡区域。使用这个范围，我现在指定最大学习率来训练我的模型。切片函数允许模型将1e-4用作第一层的速率，将1e-3用作最后一层的速率。然后，中间的每一层将在所提供的范围之间等距分布学习速率。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="91e9" class="lt js hh lp b fi lu lv l lw lx">learn.fit_one_cycle(4, lr_max=slice(1e-4,1e-3))<br/>learn.save('stage2')</span></pre><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es ma"><img src="../Images/b7795da495f7f6d66da4b822769f446d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*eXBUX6f3l5m1SgRcwNmVgw.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">第二轮培训的结果</figcaption></figure><p id="6963" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在优化学习率之后，我们的4个时期的结果对模型的错误率有显著影响。我可以将错误率从之前的0.29降低到0.04。同样令人惊奇的是我们能够训练这个模型的时间。在几分钟之内，我们就能够创建一个精度约为0.95的模型。</p><h1 id="0ff8" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">洞察力</h1><p id="38c9" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">我主要通过两种方式进一步改进我的模型:混淆矩阵和顶部损失。</p><p id="8007" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">混淆矩阵是一种很好的方法，可以用来查看模型的表现如何，以及模型在哪些地方可能总是分类错误。在某些情况下，混淆矩阵也可以显示可容忍的误差。如果两只鸟非常相似，这可能揭示出模型中的误差源不是一个更大的缺陷。在我的案例中，蓝松鸦和靛蓝彩旗从某些角度来看非常相似，因此，我可以证明为什么模型会出错。所以，矩阵让我在某种意义上更深入地挖掘模型的错误率。</p><p id="00ff" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们可以使用下面的命令集来输出混淆矩阵。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="1d1d" class="lt js hh lp b fi lu lv l lw lx">interp = ClassificationInterpretation.from_learner(learn)<br/>fig = interp.plot_confusion_matrix(figsize=(10,15))</span></pre><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mb"><img src="../Images/e77264d9170dedd5c823362801b42fee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AkJfvNsIs8uBoD-1AosH6A.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">最终模型的混淆矩阵</figcaption></figure><p id="b401" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了更清楚地了解情况，我们可以展示模型的最高损失。模型的最高亏损代表了模型最有信心同时也是错误的地方。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="3226" class="lt js hh lp b fi lu lv l lw lx">interp.plot_top_losses(9, figsize=(15,11))</span></pre><p id="95fd" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在我的案例中，看着最大的损失，向我展示了一些模型最明显的错误是由于给它的图像。例如，我放了一张包含两种不同鸟类的图片。这导致我的模型识别出图片中不正确的鸟。我继续从数据集中删除了这些图像。</p><h1 id="5fd1" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">观鸟</h1><p id="9cef" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">现在是有趣的部分！我花了一上午的时间给所有吃早餐的鸟拍照，并且能够很有把握地识别出每一只鸟的种类。</p><p id="a97e" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了对我拍摄的照片进行预测，我首先必须导出模型。导出模型会创建一个pickle文件，该文件可以部署到其他地方，也可以在以后加载回来。我加载回导出的模型，因为我仍然在我的笔记本上工作。这允许我调用predict方法，并将预测标签的图像路径提供给模型。下面的第二个代码块只是根据输入到模型中的图片来创建预测标签的可视化。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="179f" class="lt js hh lp b fi lu lv l lw lx">learn.export()<br/>model_inf = load_learner('path_to_export/export.pkl')<br/>pred_class = model_inf.predict('path_to_img/img_name.JPG')</span><span id="d476" class="lt js hh lp b fi mc lv l lw lx">testimg1 = Image.open('path_to_img/img_name.JPG')<br/>print(pred_class[0])<br/>plt.imshow(testimg1)<br/>plt.axis('off')<br/>plt.show()</span></pre><div class="lk ll lm ln fd ab cb"><figure class="md ii me mf mg mh mi paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/a8269c88d136febc02f77ef2c941d347.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*FhqHEd7k9hviBujSv-6J9w.png"/></div></figure><figure class="md ii mj mf mg mh mi paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/64ecc72aac579ab75140036b1562ed09.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*ghzwprOOkk6HMpKOWzw8mw.png"/></div></figure><figure class="md ii mk mf mg mh mi paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/d66ce29ff4fa375adf812f520074d7c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*chQpVPjxurq7nu3vkzEs0Q.png"/></div></figure></div><div class="ab cb"><figure class="md ii ml mf mg mh mi paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/a7c99db9f3c8866755418132634ebec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*rxgJb9So6fdv4Mf-20IQpQ.png"/></div></figure><figure class="md ii mm mf mg mh mi paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/117b1d6f49172ec016d45b01a138aa48.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*bNRhK-g2a6Y0S3obI_Ekww.png"/></div></figure><figure class="md ii mn mf mg mh mi paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/a2aec3a8887ef9f18b70fcf9d47ae898.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*nnvATNaH8QEJq94wKpdV5A.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx mo di mp mq translated">使用训练好的模型预测在我家后院发现的鸟类种类</figcaption></figure></div></div><div class="ab cl mr ms go mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="ha hb hc hd he"><p id="59c8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">我发现有用的链接:</strong></p><ul class=""><li id="8ac1" class="kv kw hh iv b iw ix ja jb je kx ji ky jm kz jq my lb lc ld bi translated">【休斯顿最佳鸟类——鸟类友好社区(birdfriendlyhouston.org)<a class="ae ku" href="http://www.birdfriendlyhouston.org/birding/top-birds/" rel="noopener ugc nofollow" target="_blank"/></li><li id="1420" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq my lb lc ld bi translated"><a class="ae ku" href="https://ruder.io/transfer-learning/index.html#whatistransferlearning" rel="noopener ugc nofollow" target="_blank">迁移学习——机器学习的下一个前沿(ruder.io) </a></li><li id="3acb" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq my lb lc ld bi translated"><a class="ae ku" href="https://forums.fast.ai/" rel="noopener ugc nofollow" target="_blank">深度学习课程论坛(fast.ai) </a></li><li id="261f" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq my lb lc ld bi translated"><a class="ae ku" href="https://www.freecodecamp.org/news/deep-learning-with-fastai/" rel="noopener ugc nofollow" target="_blank">深度学习教程——如何用fast . ai(freecodecamp.org)训练和部署深度学习模型</a></li><li id="3937" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq my lb lc ld bi translated"><a class="ae ku" href="https://forums.fast.ai/t/why-do-we-need-to-unfreeze-the-learner-everytime-before-retarining-even-if-learn-fit-one-cycle-works-fine-without-learn-unfreeze/41614/5" rel="noopener ugc nofollow" target="_blank">即使learn.fit_one_cycle()没有learn.unfreeze() —第一部分(2019) —深度学习课程论坛(fast.ai) </a>为什么每次重新训练前我们都需要解冻学习者</li><li id="b1b7" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq my lb lc ld bi translated"><a class="ae ku" href="https://course.fast.ai/start_colab" rel="noopener ugc nofollow" target="_blank">使用Colab |面向编码人员的实用深度学习(fast.ai) </a></li><li id="db25" class="kv kw hh iv b iw le ja lf je lg ji lh jm li jq my lb lc ld bi translated"><a class="ae ku" href="https://www.youtube.com/watch?v=GWt6Fu05voI" rel="noopener ugc nofollow" target="_blank">【经典】图像识别的深度残差学习(论文讲解)——YouTube</a></li></ul></div></div>    
</body>
</html>