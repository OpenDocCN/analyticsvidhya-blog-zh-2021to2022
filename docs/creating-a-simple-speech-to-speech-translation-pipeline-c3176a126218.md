# 创建简单的语音到语音翻译管道

> 原文：<https://medium.com/analytics-vidhya/creating-a-simple-speech-to-speech-translation-pipeline-c3176a126218?source=collection_archive---------7----------------------->

![](img/4930dbfa23a5f61c95332acd1bba7883.png)

我当传教士时的一些最好的朋友(没错，我就是最右边那个呆瓜)

> 使用 microsoft azure 服务，我们将创建以下管道:

1.  自动语音识别
2.  机器翻译
3.  文本到语音转换
4.  (可选)使用神经语音来改善输出语音

我想说其他语言的愿望是在我 18 岁去加纳阿克拉生活时产生的。我是耶稣基督后期圣徒教会的传教士，奉召为我在那里遇到的人服务。在加纳，有 50 多种语言被认可，在我居住的地方(我搬了四次家)，有 3 到 4 种主要语言被使用。我想和这些超级伟大的人联系并为他们服务，所以我尽我所能去学习他们的语言。

自从我回来已经差不多 6 年了，我正在学习机器翻译，并希望第一次尝试为我说的像 Twi 一样的语言做机器翻译。本文不是这些努力，而是对机器翻译感兴趣的人的一个起点。

这不是一篇深入研究或从头开始的文章。这展示了如何以一种基本的方式使用一些非常强大的工具，只是让你开始。这些大部分都可以在微软自己的 azure 语音服务快速入门或者 pyaudio 文档中找到。

说实话，我对微软 azure 印象非常深刻。在我参加的一个机器翻译课程中，我们发现对于几种语言(可能更多，但我们没有测试所有语言)来说，它的准确性超过了谷歌翻译(主要通过 bleu 分数测试)。此外，TTS 允许您改善声音，这是一个很大的乐趣！

让我们从代码开始，对正在发生的事情有一个基本的了解。

# 自动语音识别(Automatic Speech Recognition)

自动语音识别需要相当认真的工作。如果你想使用一个稍微暴露一点的例子，你可以尝试使用 [pyaudio](http://people.csail.mit.edu/hubert/pyaudio/) 。它们非常适合做实验。让我给你看一个例子，然后是微软的，你可以决定你想继续进行。

上面的这个文件可以让你录制和收听。wav 文件。这很好，因为你可以看到更多的幕后发生的事情。有很多精彩的文章和著作可以更好地解释这一点，我不会在这里花时间。需要注意的一个小技术问题是，如果你在 mac 上使用 vs 代码，并且你试图调用 record，你的麦克风不会打开。试试[这个如果是那种情况](https://github.com/microsoft/vscode/issues/95062#issuecomment-751241372)。

现在我们来看看 azure 的 ASR。要设置你的语音服务，你至少需要一个免费的 azure 账户(为了测试这个已经足够了)。一旦你做到了这一点，进入[这里](https://portal.azure.com/#create/hub)，搜索“演讲”并点击“创建”。除了选择您的套餐和价格之外，您无需在此处进行任何更改。

一旦它完成设置，前往资源并单击左边的“密钥和端点”以获得您的两个密钥中的一个，并将其复制到下面的“yourkeyhere”位置。

嘣！现在你可以把你的演讲转录成文本了！在一家价值数十亿美元的公司的支持下，它非常准确。

您可以调用这个类，创建一个 simpleASR 变量，然后调用 from_mic()或 from_file(filename)就可以了。🥲

# 机器翻译

机器翻译，这本身就是一个巨大的研究领域，但那是你生活中另一段时间的讨论。非常酷的是，我们可以对非常强大的 NMT 进行训练和微调，它可以帮助我们开始我们的 MT 之旅。因此，目前，我们不会从头开始构建 NMT，而是将重点放在使用 azure 的语音 MT 上。这需要一个“翻译”资源，你可以像设置 ASR 一样设置它。当它完成设置时，提醒您等待，以便您稍后可以找到它(我犯了这个错误，花了很长时间想知道它去了哪里，结果不得不再次创建)。

一旦您有了 api 密匙，下面的代码将帮助您开始。

一个非常基本的函数，它接受一个短语列表，并返回给你已经翻译的文本。这将从主文件中调用。但是首先我们将完成组件的构造。

# 自文本至语音的转换

文本到语音转换是一个非常有趣的部分，尤其是如果你继续选择第四种。你也许可以使用你原来的语音 api 键，但是你需要有一个[特定区域区域设置](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/regions#standard-and-neural-voices)来使用神经语音。您可以在该链接中找到您的最佳区域，并在创建该语音资源时进行设置。

现在说说代码:

这个类给了你写文件和/或说话的能力，包括一些定制。to_file_with_ssml 和 speak_custom 函数都使用神经语音。我肯定会尝试两者来看看有什么不同！

## 组合管道

现在把所有这些放在一起，一个简单的文件帮助我们轻松地调用每个服务。有些部分已经被注释掉了，你可以试着看看 pyaudio 是如何工作的，以及其他选项带来的变化。

你会注意到你可以使用 pyaudio 数据和你的微软 asr 或者仅仅使用 asr.py 类来记录，两者都可以！你可能也注意到了一些西班牙达莉亚 some 的电话。这就引出了神经声音。

## 神经声音

微软正在研究神经语音。你甚至可以创建一个自定义的声音并添加到其中(不过现在你可能需要[很多资源](https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/how-to-custom-voice))。他们已经存在的是很多好玩的东西。这里有一个简单的例子，一个 SSML 文件，你可以用它来增强你的西班牙语翻译。

我建议两者都试试，看看有什么不同，甚至尝试另一种西班牙语的声音，如“Jorge”。

此外，如果你想更进一步，继续阅读他们的文档，看看如何添加停顿，变调和赋予声音情感！

这就对了。一个基本的 STS 管道供您使用。我没有使用微软现有的语音到语音管道的原因之一是，模块化的构建允许那些想要做出改变或使用定制管道组件的人自由地这样做。另外，如果这是您的第一次，设置管道的每个部分有助于更全面地了解正在发生的事情。

享受翻译！下一步可以尝试用一个类似 bleu 的分数来评估翻译(NLTK 和 sacrebleu 可以帮助你)。然后试着看看在去掉微软组件的情况下，你自己能在这条管道上实现什么。

至于我上面提到的工作，我目前正在从事低资源语言 NMT，特别是英语-Twi 翻译项目。如果你想加入或看看发生了什么，让我知道，玩得开心！