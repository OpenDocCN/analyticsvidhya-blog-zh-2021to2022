<html>
<head>
<title>How weights are initialized in Neural networks (Quick Revision)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在神经网络中初始化权重(快速修订版)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-weights-are-initialized-in-neural-networks-quick-revision-adceac6c3cc9?source=collection_archive---------8-----------------------#2021-10-04">https://medium.com/analytics-vidhya/how-weights-are-initialized-in-neural-networks-quick-revision-adceac6c3cc9?source=collection_archive---------8-----------------------#2021-10-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="0c3e" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi translated"><em class="jd">改变深度学习轨迹的关键因素</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/5aed04d3b9f307f9a38374a6465bea8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*XSxaTe8VJJ31Useb"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">照片由<a class="ae ju" href="https://unsplash.com/@itfeelslikefilm?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">🇸🇮·扬科·菲利</a>在<a class="ae ju" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="7c5b" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi jv translated">神经网络是现代深度学习的基本概念之一。本文仅涵盖神经网络初始化的方式和原因，因此我假设您了解神经网络的基本知识(<em class="jd">特别是前向传播和反向传播概念</em>)。</p><blockquote class="ke kf kg"><p id="518d" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc ha bi translated">那么，什么是初始化呢？</p></blockquote><p id="51d5" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi translated">初始化是一种给神经元初始权重的方法，通过这些技术，我们可以在训练模型之前分配随机值，而不是零和常量值。</p><blockquote class="ke kf kg"><p id="b8c8" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc ha bi translated"><strong class="ih hi">我们为什么需要它？</strong></p></blockquote><p id="1aaa" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi translated">当我们不知道为什么要使用它时，使用它又有什么意义呢？使用它的主要原因有三个。</p><ol class=""><li id="7cf5" class="kk kl hh ih b ii ij im in iq km iu kn iy ko jc kp kq kr ks bi translated">原因之一是它可以避免训练后期的<strong class="ih hi">消失、爆炸渐变问题</strong>。消失梯度问题是指当权重在训练过程中不变时出现的问题(<em class="jd">出现在权重被初始化为远小于1 </em>)。爆炸梯度问题是指当权重持续快速增加时出现的问题(<em class="jd">当权重初始化大于1 </em>时出现)</li><li id="49ef" class="kk kl hh ih b ii kt im ku iq kv iu kw iy kx jc kp kq kr ks bi translated">另一个原因是它可以加快训练过程，因为它可以通过优化初始化学习得更快。</li></ol><blockquote class="ke kf kg"><p id="767f" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc ha bi translated">它有哪些类型？如何/何时使用？</p></blockquote><p id="8801" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi translated">主要有三种类型的权重初始化，它们在实际应用中非常有效。</p><ol class=""><li id="0d17" class="kk kl hh ih b ii ij im in iq km iu kn iy ko jc kp kq kr ks bi translated">均匀分布</li><li id="9e11" class="kk kl hh ih b ii kt im ku iq kv iu kw iy kx jc kp kq kr ks bi translated">泽维尔/戈拉特分布</li><li id="80fa" class="kk kl hh ih b ii kt im ku iq kv iu kw iy kx jc kp kq kr ks bi translated">He初始化</li></ol></div><div class="ab cl ky kz go la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ha hb hc hd he"><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lf"><img src="../Images/918a5864af1c1f435dbd6442115085d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*r9ODgxpbnSywAc6-MTmzEA.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">图1 —一个神经元的示意图，fan_in表示输入层的数量，fan_out表示输出层的数量</figcaption></figure><h1 id="2d91" class="lg lh hh bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md bi translated">均匀分布</h1><p id="afdd" class="pw-post-body-paragraph if ig hh ih b ii me ik il im mf io ip iq mg is it iu mh iw ix iy mi ja jb jc ha bi translated">是一种初始化，其中权重是均匀分布的。计算初始重量范围的公式如下</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="mj mk l"/></div></figure></div><div class="ab cl ky kz go la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ha hb hc hd he"><h1 id="8c3d" class="lg lh hh bd li lj ml ll lm ln mm lp lq lr mn lt lu lv mo lx ly lz mp mb mc md bi translated">Xavier / Gorat初始化</h1><p id="75ea" class="pw-post-body-paragraph if ig hh ih b ii me ik il im mf io ip iq mg is it iu mh iw ix iy mi ja jb jc ha bi translated">对于使用Sigmoid，Tanh作为激活函数的<strong class="ih hi">神经网络来说，这种初始化被证明非常好。大体上有两种类型，</strong></p><blockquote class="ke kf kg"><p id="17b5" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc ha bi translated">泽维尔师范</p></blockquote><p id="699e" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi translated">权重值由平均值和标准偏差为零的<strong class="ih hi">正态分布</strong>分配</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="mj mk l"/></div></figure><blockquote class="ke kf kg"><p id="7bd0" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc ha bi translated">泽维尔制服</p></blockquote><p id="3770" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi translated">权重值由具有以下公式的均匀分布分配</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="mj mk l"/></div></figure></div><div class="ab cl ky kz go la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ha hb hc hd he"><h1 id="d414" class="lg lh hh bd li lj ml ll lm ln mm lp lq lr mn lt lu lv mo lx ly lz mp mb mc md bi translated">He初始化</h1><p id="21af" class="pw-post-body-paragraph if ig hh ih b ii me ik il im mf io ip iq mg is it iu mh iw ix iy mi ja jb jc ha bi translated">这种初始化对于使用ReLU作为激活函数的<strong class="ih hi">神经网络来说是很好的。大体上有两种类型，</strong></p><blockquote class="ke kf kg"><p id="fdf9" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc ha bi translated">何制服</p></blockquote><p id="1a6c" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi translated">权重值由具有以下公式的均匀分布分配</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="mj mk l"/></div></figure><blockquote class="ke kf kg"><p id="1d05" class="if ig jd ih b ii ij ik il im in io ip kh ir is it ki iv iw ix kj iz ja jb jc ha bi translated">他正常吗</p></blockquote><p id="ee77" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi translated">权重值由平均值为零且标准偏差为的正态分布分配</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="mj mk l"/></div></figure><p id="03b4" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi translated">耶！就这样，我们已经学习/快速复习了神经网络初始化背后的公式和概念。同样，如果你想详细了解这一点，我推荐你阅读<a class="ae ju" href="https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/#:~:text=The%20normalized%20xavier%20initialization%20method,number%20of%20outputs%20from%20the" rel="noopener ugc nofollow" target="_blank">这</a>，你可以在这里想象<a class="ae ju" href="https://www.deeplearning.ai/ai-notes/initialization/" rel="noopener ugc nofollow" target="_blank">的概念。<br/>感谢您的阅读！</a></p><p id="364f" class="pw-post-body-paragraph if ig hh ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc ha bi translated">下次见…</p></div></div>    
</body>
</html>