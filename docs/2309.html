<html>
<head>
<title>Airflow, Spark &amp; S3, stitching it all together</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">气流、火花和S3，将它们缝合在一起</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/airflow-spark-s3-stitching-it-all-together-1acbfba67e33?source=collection_archive---------3-----------------------#2021-04-18">https://medium.com/analytics-vidhya/airflow-spark-s3-stitching-it-all-together-1acbfba67e33?source=collection_archive---------3-----------------------#2021-04-18</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/155713cd9f8db1c3f0deb6ccc5772891.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TEfXPKRMwQ5A66W6GAR--Q.png"/></div></div></figure><p id="77a0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我的上一篇文章<em class="jo">、</em>中，我描述了建立自己的spark集群(在AWS中)和从边缘节点提交集群中的Spark作业(在AWS中)的许多方法之一。然而，我们都知道业务需求如何很快超过手动运行作业的能力，我们最终寻求开发数据管道。</p><p id="9796" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这篇文章将一步一步地帮助建立一个管道，从边缘节点到spark集群自动运行spark作业，所有这些都在AWS中完成。我希望这篇文章对初学者和中间用户有所帮助，但是专家(和中间用户)会知道更多的方法来编排这样的管道。</p><p id="7c05" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这篇文章的内容不应该作为设置生产管道的指南，但是，它可以作为设置开发/测试管道的指南，同时生产基础设施准备好安全性、高可用性和其他最佳实践。</p><p id="3526" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">前言说够了，让我们直接开始吧。</p><p id="1e21" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">先决条件:</p><ol class=""><li id="4365" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">如果你还不知道气流的基本原理，请浏览一下。</li><li id="dceb" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">一个活动的S3存储桶，里面有一些数据。</li><li id="ee33" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">确保您已经按照我上一篇文章中的描述设置了EMR集群和边缘节点。</li></ol><div class="kd ke ez fb kf kg"><a href="https://ganguly-04.medium.com/commissioning-emr-spark-cluster-in-aws-and-accessing-it-via-an-edge-node-63a5f1e47d8b" rel="noopener follow" target="_blank"><div class="kh ab dw"><div class="ki ab kj cl cj kk"><h2 class="bd hj fi z dy kl ea eb km ed ef hh bi translated">在AWS中调试EMR Spark集群并通过边缘节点访问它</h2><div class="kn l"><h3 class="bd b fi z dy kl ea eb km ed ef dx translated">在我作为一名数据工程师的旅程中，当大数据炒作达到白热化时，我遇到了spark(它仍然很高…</h3></div><div class="ko l"><p class="bd b fp z dy kl ea eb km ed ef dx translated">ganguly-04.medium.com</p></div></div><div class="kp l"><div class="kq l kr ks kt kp ku io kg"/></div></div></a></div><p id="fe90" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦先决条件到位，我们需要考虑下一步。您需要一个编排工具来根据您的业务需求以特定的频率自动运行spark作业。我们从现有的各种选项中选择了气流，因此我们的下一步是在边缘节点中安装气流</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><p id="1fbf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在详细介绍airflow安装之前，我们需要考虑airflow的一个基本需求，即保存airflow元数据和所有作业信息(日志等)的数据库。).尽管airflow预装了sqlite作为数据库，但它不支持并行作业执行，因此我们不能在大多数用例中使用它。</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><p id="6a1d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">第一步，我们将在AWS中设置一个MySQL RDS实例</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lc"><img src="../Images/9087aa8587bff8c18273e13b41f47dc8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*n-MEaevRCOIl-o0a0v9Udg.png"/></div></div></figure><p id="f10f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在AWS中，选择RDS作为服务，然后在下一页中单击“创建数据库”。然后按照下面的截图选择剩余的选项</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/a8fe08eb8df20b23b02f68c32588f33e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bTmc91cJ8F30RpHi5Ix5hg.png"/></div></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/a52f5b7a6959747430bbd15b545bd68a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AkCZAN0id7f-WZyhwlVHmA.png"/></div></div></figure><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/26f44f70255df772b22de76df3c7289e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GdcCE1mRJMnQ_A2deKVRmA.png"/></div></div></figure><p id="c5de" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请记下您在此处提供的凭据，因为在设置airflow时将需要这些凭据。保持所有其他选项不变，直到您到达下面的屏幕(向下滚动)</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/d331afff8ff58e9f7bf5c3f98ea233ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7_dU1oPjpmjDei7EA8agmg.png"/></div></div></figure><p id="1af4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">请注意，我已经选择了EMR Master的安全组作为VPC安全组以及默认的安全组。这对于允许边缘节点(将在此建立气流)和RDS之间的通信至关重要</p><p id="5dce" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">展开“附加配置”并确保端口为3306。进一步向下滚动，展开下一个“附加配置”。输入您选择的数据库名称，并记下该名称，在气流设置过程中也会用到它</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ll"><img src="../Images/3528b96462c813e1531c7c2d8c7ae0fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I3_jgwtpz3UHwjLeHDY_BQ.png"/></div></div></figure><p id="151a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">其他一切保持原样，然后点击“创建数据库”。当AWS花自己的时间建立MySQL数据库时，请保持冷静</p><p id="abad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据库启动并运行后，单击数据库标识符</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/f0f04706546de9f4f76e6b95710acbe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nys5nAh3Zth2e5rWX0REwA.png"/></div></div></figure><p id="c3ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在下一个屏幕中，记下<code class="du ln lo lp lq b">End Point</code>，这将是数据库主机</p><figure class="ld le lf lg fd ij er es paragraph-image"><div class="er es lr"><img src="../Images/c5e630a37320cae0b4eadf3e29347dc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*WnqUMg6mOC4uvvpq3YpwEw.png"/></div></figure><p id="9922" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来向下滚动以查看安全组，并单击默认组。我们必须允许从边缘节点到此数据库的入站流量</p><p id="7c5d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">点击<code class="du ln lo lp lq b">Edit Inbound Rules</code>,然后添加以下内容(边缘节点的公共IP应该放在空白处)</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/d586e8b7b8313dd063a02f190b8801e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NyB0Ld7KCgwAHt9s4R0wqw.png"/></div></div></figure><p id="1b8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">击中<code class="du ln lo lp lq b">Save rules</code></p><p id="a460" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们测试一下我们是否可以从边缘节点连接到数据库。执行以下步骤对此进行检查</p><p id="6ea1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">SSH进入边缘节点(咄！显而易见)，然后运行下面的命令</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="4507" class="lx ly hi lq b fi lz ma l mb mc">mysql -h <a class="ae md" href="mailto:admin_airflow@database-2.cltwfil64t5z.us-west-2.rds.amazonaws.com" rel="noopener ugc nofollow" target="_blank">&lt;</a>&lt;the end point that you noted during the RDS setup&gt;&gt; -u &lt;&lt;username that you gave in the RDS setup&gt;&gt; -p &lt;&lt;the database name that you gave in the RDS setup&gt;&gt; </span><span id="fefb" class="lx ly hi lq b fi me ma l mb mc">(then enter password on prompt)</span></pre><p id="851c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">你现在应该可以看到mysql提示符了，在mysql提示符下运行下面的命令。这将确保airflow在元数据设置期间获得必要的字符支持(不运行这将使airflow db初始化失败)</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="5e2a" class="lx ly hi lq b fi lz ma l mb mc">alter database &lt;&lt;the database name that you gave in the RDS setup&gt;&gt; CHARACTER SET utf8 COLLATE utf8_unicode_ci;</span></pre><p id="768e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，您的数据库已经设置好支持airflow安装和后续作业执行。</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><p id="73ba" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">数据库创建完成后，我们现在开始安装airflow。我们将安装气流2.0，而不是最新版本2.0.1。这样选择的原因是，如果EC2实例(在我们的例子中是边缘节点)中安装的sqlite版本小于3.15，airflow 2.0.1会出现硬故障。问题是，尽管您不打算使用sqlite，但由于这一硬故障，您将无法启动和运行airflow主目录，并且如果没有设置主目录，您将无法更改airflow配置，因为您将无法访问airflow.cfg文件。</p><p id="9bda" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">如果你知道任何其他方法来规避这个问题，请告诉我。现在，我们将避免气流2.0.1</p><p id="9f7b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，让我们通过SSH进入边缘节点，并执行以下步骤来设置气流</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><p id="dfc4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先检查python和pip版本</p><p id="d8bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du ln lo lp lq b">python --version</code></p><p id="ab8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du ln lo lp lq b">pip --version</code></p><p id="984c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">升级pip版本</p><p id="0929" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du ln lo lp lq b">curl -O <a class="ae md" href="https://bootstrap.pypa.io/get-pip.py" rel="noopener ugc nofollow" target="_blank">https://bootstrap.pypa.io/get-pip.py</a></code></p><p id="85a3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du ln lo lp lq b">python3 get-pip.py --user</code></p><p id="c551" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">声明我们将用于发出airflow 2.0.0安装命令的变量</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="2383" class="lx ly hi lq b fi lz ma l mb mc">AIRFLOW_VERSION=2.0.0</span><span id="1c5e" class="lx ly hi lq b fi me ma l mb mc">PYTHON_VERSION="$(python --version | cut -d " " -f 2 | cut -d "." -f 1-2)"</span><span id="e28f" class="lx ly hi lq b fi me ma l mb mc">CONSTRAINT_URL="<a class="ae md" href="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt</a>"</span></pre><p id="65f1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">安装airflow(注意，我已经在安装过程中包含了额外的包，您现在可以避免，只需从命令中去掉[amazon]部分)</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="f38d" class="lx ly hi lq b fi lz ma l mb mc">pip install "apache-airflow[amazon]==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"</span></pre><p id="f0aa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在我们检查安装</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="e1d4" class="lx ly hi lq b fi lz ma l mb mc">PATH=$PATH:~/.local/bin</span><span id="9605" class="lx ly hi lq b fi me ma l mb mc">airflow version</span></pre><p id="e173" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后一个命令应该显示airflow 2.0.0(如果在安装过程中没有出现任何问题，我不希望出现任何问题)</p><p id="cad9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在到了我们需要初始化数据库的部分(这是选择2.0.0为我们节省时间的地方)。运行以下命令</p><p id="611b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><code class="du ln lo lp lq b">airflow db init</code></p><p id="0512" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这使得airflow为我们设置了sqlite db，并为我们提供了airflow主目录，进入该目录并打开<code class="du ln lo lp lq b">airflow.cfg</code>文件</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="4ae5" class="lx ly hi lq b fi lz ma l mb mc">cd ~/airflow</span><span id="e2c9" class="lx ly hi lq b fi me ma l mb mc">vim airflow.cfg</span></pre><p id="6a8f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">搜索<code class="du ln lo lp lq b">sql_alchemy_conn</code>的条目，修改如下</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="09f4" class="lx ly hi lq b fi lz ma l mb mc">sql_alchemy_conn = mysql://&lt;&lt;username that you gave in the RDS setup&gt;&gt;:<a class="ae md" href="mailto:admin_airflow@database-2.cltwfil64t5z.us-west-2.rds.amazonaws.com" rel="noopener ugc nofollow" target="_blank">&lt;&lt;</a>password that you gave in the RDS setup<a class="ae md" href="mailto:admin_airflow@database-2.cltwfil64t5z.us-west-2.rds.amazonaws.com" rel="noopener ugc nofollow" target="_blank">&gt;&gt;@&lt;</a>&lt;the end point that you noted during the RDS setup&gt;&gt;:3306/&lt;&lt;the database name that you gave in the RDS setup&gt;&gt;</span></pre><p id="24b0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">接下来将executor更改为LocalExecutor，这一更改将允许我们在out airflow DAGs中实现作业并行性</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="72ba" class="lx ly hi lq b fi lz ma l mb mc">executor = LocalExecutor</span></pre><p id="749a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">再次运行数据库初始化，让气流重新指向MySQL数据库</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="69bc" class="lx ly hi lq b fi lz ma l mb mc">airflow db init</span></pre><p id="9c58" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在您已经设置好了，启动airflow服务器和调度程序</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="b946" class="lx ly hi lq b fi lz ma l mb mc">airflow webserver -D -p 8080<br/>airflow scheduler -D</span></pre><p id="9b59" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">创建一个用户进入气流图形用户界面</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="6fb3" class="lx ly hi lq b fi lz ma l mb mc">airflow users create --username CaptainAmerica --firstname Captain --lastname America --role Admin --email <a class="ae md" href="mailto:ganguly.04@gmail.com" rel="noopener ugc nofollow" target="_blank">n</a>osuchemail@nowhere.com</span></pre><p id="bc9e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">键入您选择的密码并记住它，将需要此凭证来进入GUI</p><p id="0932" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，您应该能够看到Airflow 2.0.0闪亮的新GUI了</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mf"><img src="../Images/2d723ea731ec8cf0456ee5aff572483c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RsKXkWj5qpiEHf1kFKhsOQ.png"/></div></div></figure></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><p id="d1fc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在你努力工作了这么久之后，现在是收获回报的时候了。我们现在只需要一个DAG和一个spark脚本来读写我们的S3存储桶</p><p id="8e71" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于我的帖子，我有以下内容。第一个是我的管道的输出，第二个是源</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mg"><img src="../Images/e844e43ce14c5aed44ee3e150e2c2b60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rHLhr9KOEakttSakzNUrDw.png"/></div></div></figure><p id="4996" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">让我们编写一个样本spark脚本，它从桶中读取数据，执行简单的转换/过滤，然后写回到桶中</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="e8f6" class="lx ly hi lq b fi lz ma l mb mc">## We will name this script as testEMRtoS3Conn.py<br/>import pyspark<br/>from pyspark import SparkConf, SparkContext</span><span id="e560" class="lx ly hi lq b fi me ma l mb mc">conf = SparkConf().setAppName('FirstSparkApp').setMaster('yarn')<br/>sc = SparkContext(conf=conf)</span><span id="3e29" class="lx ly hi lq b fi me ma l mb mc">from pyspark.sql import SQLContext, HiveContext, SparkSession<br/>spark = SparkSession.builder.appName('FirstSparkApp').getOrCreate()</span><span id="2d18" class="lx ly hi lq b fi me ma l mb mc">my_first_dframe = spark.read.option("header",True).csv("s3://yourBucketName/netflix_titles.csv")<br/><br/>my_first_dframe_filtered = my_first_dframe.filter(my_first_dframe['country']=='Brazil')<br/><br/>my_first_dframe_filtered.write.option("header",True).csv("s3://yourBucketName/netflix_titles_from_brazil.csv")</span></pre><p id="cd5c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了提交这个脚本，我们将编写一个包装器外壳脚本</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="08de" class="lx ly hi lq b fi lz ma l mb mc">### Let's name the script as testEMRtoS3Conn_pyWrapper.sh<br/>#!/bin/sh<br/>  <br/>echo "calling spark script"</span><span id="0e11" class="lx ly hi lq b fi me ma l mb mc">export HADOOP_USER_NAME=hdfs</span><span id="d2cc" class="lx ly hi lq b fi me ma l mb mc">spark-submit --driver-memory 2g --executor-memory 2g --executor-cores 2 --num-executors 2 --deploy-mode cluster testEMRtoS3Conn.py</span></pre><p id="300c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">最后，我们将创作DAG</p><pre class="ld le lf lg fd lt lq lu lv aw lw bi"><span id="31ab" class="lx ly hi lq b fi lz ma l mb mc">### We will name the DAG as edgeToEMRandS3<br/>from datetime import timedelta</span><span id="86f3" class="lx ly hi lq b fi me ma l mb mc">from airflow import DAG<br/>from airflow.operators.bash import BashOperator<br/>from airflow.operators.dummy import DummyOperator<br/>from airflow.utils.dates import days_ago</span><span id="f734" class="lx ly hi lq b fi me ma l mb mc">args = {<br/>    'owner': 'airflow',<br/>}</span><span id="5697" class="lx ly hi lq b fi me ma l mb mc">dag = DAG(<br/>    dag_id='edgeToEMRandS3',<br/>    default_args=args,<br/>    schedule_interval=None,<br/>    start_date=days_ago(2),<br/>    dagrun_timeout=timedelta(minutes=60),<br/>    tags=['somethingForYouToFindYourDAG']<br/>    #params={"example_key": "example_value"},<br/>)</span><span id="2ac7" class="lx ly hi lq b fi me ma l mb mc">run_this_first = DummyOperator(<br/>    task_id='run_this_first',<br/>    dag=dag,<br/>)</span><span id="e6d2" class="lx ly hi lq b fi me ma l mb mc">now_run_spark_job = BashOperator(<br/>    task_id='now_run_spark_job',<br/>    bash_command='bash /home/ec2-user/airflow/scripts/testEMRtoS3Conn_pyWrapper.sh ',<br/>    dag=dag,<br/>)</span><span id="2097" class="lx ly hi lq b fi me ma l mb mc">run_this_first &gt;&gt; now_run_spark_job</span></pre><p id="f376" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">给气流调度程序一些时间来刷新DAGbag，然后您的DAG应该会显示在GUI中(请注意，在我的屏幕截图中，它显示为绿色，因为我已经成功运行了DAG)</p><figure class="ld le lf lg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mh"><img src="../Images/9c1df0210eed168194c76715ead393ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3NmFTStVSwnEHnyj8BEwlQ.png"/></div></div></figure><p id="bcaa" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">运行DAG，一旦成功完成，您应该能够在S3存储桶中获得输出</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><p id="af27" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">希望这篇文章能帮你节省一些时间来启动和运行你的数据管道。</p></div></div>    
</body>
</html>