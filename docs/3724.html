<html>
<head>
<title>What do you mean by Forward Propagation in ANN? 🤔</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人工神经网络中的前向传播是什么意思？🤔</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/what-do-you-mean-by-forward-propagation-in-ann-9a89c80dac1b?source=collection_archive---------5-----------------------#2021-07-20">https://medium.com/analytics-vidhya/what-do-you-mean-by-forward-propagation-in-ann-9a89c80dac1b?source=collection_archive---------5-----------------------#2021-07-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1a2edb7ef065692092c20b18f4d9c7f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ch84bzLWU9y-v09KrMcdgQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">这些重量代表了举重运动员和他的能力之间的联系…</figcaption></figure><p id="b20b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">基础优先！！！🤠</p><ol class=""><li id="ea8e" class="js jt hi iw b ix iy jb jc jf ju jj jv jn jw jr jx jy jz ka bi translated"><strong class="iw hj">什么是神经元？</strong></li></ol><ul class=""><li id="6e5f" class="js jt hi iw b ix iy jb jc jf ju jj jv jn jw jr kb jy jz ka bi translated"><strong class="iw hj">神经元</strong>(也称为神经元或神经细胞)是大脑和神经系统的基本单位，这些细胞负责从外部世界接收感官输入，向我们的肌肉发送运动命令，并在其间的每一步转换和传递电信号。</li></ul><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es kc"><img src="../Images/54ceb179bd99971e241b2acdc4c94e5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*uHIKrL8tApkTVfAYSZImNw.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图2:一个生物神经元</figcaption></figure><p id="0392" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">生物神经元从“树突”获得各种输入，然后在细胞核中对每个神经元的权重和输入进行求和，并加上偏差。</p><p id="e77a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj"> 2。什么是人工神经网络(ANN)？</strong></p><ul class=""><li id="efe1" class="js jt hi iw b ix iy jb jc jf ju jj jv jn jw jr kb jy jz ka bi translated">人工神经网络是受构成动物大脑的生物神经网络启发的计算系统。</li><li id="c681" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr kb jy jz ka bi translated">人工神经网络是基于称为人工神经元的连接单元或节点的集合，它松散地模拟生物大脑中的神经元。</li></ul><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es km"><img src="../Images/47dcac9846601d984a05107beccc1c60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HZyeJWx9Zg9DsnIAbuJ8UQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图1:人工神经网络概述</figcaption></figure><p id="beb2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">从神经元和人工神经网络的定义中，我们知道一些术语，如输入、输入层、权值、隐含层、输出层和输出。</p><h2 id="4da0" class="kn ko hi bd kp kq kr ks kt ku kv kw kx jf ky kz la jj lb lc ld jn le lf lg lh bi translated">让我们学一些人工神经网络，</h2><p id="5df2" class="pw-post-body-paragraph iu iv hi iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr hb bi translated">在此之前，我们定义一些<strong class="iw hj">简化假设:</strong></p><ol class=""><li id="4280" class="js jt hi iw b ix iy jb jc jf ju jj jv jn jw jr jx jy jz ka bi translated">神经元按层排列，层按顺序排列。</li><li id="4fbd" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr jx jy jz ka bi translated">同一层内的神经元之间不传递信息。</li><li id="50be" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr jx jy jz ka bi translated">所有数据/信息通过输入层进入，信息/输出由输出层输出。</li><li id="c62a" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr jx jy jz ka bi translated">层“l”中的所有神经元都连接到层“l+1”中的所有神经元。</li><li id="c673" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr jx jy jz ka bi translated">神经网络中的每个互连都有与之关联的权重，每个神经元都有与之关联的偏差。</li><li id="15c0" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr jx jy jz ka bi translated">特定层中的所有神经元使用相同的激活函数。</li></ol><h2 id="1460" class="kn ko hi bd kp kq kr ks kt ku kv kw kx jf ky kz la jj lb lc ld jn le lf lg lh bi translated">—为了演示，</h2><p id="2ff8" class="pw-post-body-paragraph iu iv hi iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr hb bi translated">我使用一个简单的神经网络进行二元分类，在输入层有三个神经元，在隐藏层有一个神经元，在输出层有一个神经元，所以我的人工神经网络看起来像这样...</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ln"><img src="../Images/9f53f039ed6777cd259d8a3dd6e81bcf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gVtZeJ09kjmlFtL0lj_OjQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图3:演示人工神经网络(二元分类)</figcaption></figure><h2 id="63df" class="kn ko hi bd kp kq kr ks kt ku kv kw kx jf ky kz la jj lb lc ld jn le lf lg lh bi translated">神经元的‣数:</h2><p id="fc71" class="pw-post-body-paragraph iu iv hi iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr hb bi translated">现在，你会问我，你是如何将这些层中的神经元数量作为三个输入，一个隐藏，一个输出。</p><ul class=""><li id="ea91" class="js jt hi iw b ix iy jb jc jf ju jj jv jn jw jr kb jy jz ka bi translated">因此，在定义输入层神经元时，考虑神经元的<strong class="iw hj">数量=数据集中的列数。</strong></li><li id="7a8a" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr kb jy jz ka bi translated">通过使用<strong class="iw hj">超优化技术</strong>，我们将发现隐藏层中神经元的数量。</li><li id="93b5" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr kb jy jz ka bi translated">我们需要来自<strong class="iw hj">二进制分类的两个输出中的一个，因此一个神经元</strong>，如果它是一个<strong class="iw hj">多类分类</strong>我们将采用，<strong class="iw hj">神经元的数量=输出层中的类的数量。</strong></li></ul><h2 id="5d4a" class="kn ko hi bd kp kq kr ks kt ku kv kw kx jf ky kz la jj lb lc ld jn le lf lg lh bi translated">‣重量符号:</h2><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es lo"><img src="../Images/aad396a5c2ce6ef98a28d40145621e9d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*x0cGG-K8Ww7yaDV2DGbCVg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图4:权重符号</figcaption></figure><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es lp"><img src="../Images/a7a63ea3338d15ae4c4bfa5f6dd5ef3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*AEoIUBe5zEIiPXWB1w0OyQ.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图4.1:重量连接理解</figcaption></figure><p id="becb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这就是通常描述重量符号的方式…</p><p id="69db" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">回想一下线性回归、逻辑回归、支持向量机等模型。对它们的系数进行训练，即训练是为了找到系数的最佳值以最小化某个成本函数。</p><p id="3d93" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">神经网络根据权重和偏差进行训练，权重和偏差是网络的参数。</p><p id="cfdd" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">人工神经网络的超参数或学习算法是在一组固定的超参数上训练的——<em class="lq">层数，输入层的神经元数，隐藏层和输出层</em>。</strong></p><h2 id="e075" class="kn ko hi bd kp kq kr ks kt ku kv kw kx jf ky kz la jj lb lc ld jn le lf lg lh bi translated">‣神经元结构:</h2><p id="3f49" class="pw-post-body-paragraph iu iv hi iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr hb bi translated">从图1:人工神经网络概述，我们有，</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/3509d7b9e506cd1e1907c2dd44be2459.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xb3XIJK8abOpg9gHjZ-x7w.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图5:神经元结构</figcaption></figure><p id="196b" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，从图3:演示安，</p><ul class=""><li id="d0d5" class="js jt hi iw b ix iy jb jc jf ju jj jv jn jw jr kb jy jz ka bi translated">我们将有三个输入，我们将提供给神经元。</li><li id="001d" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr kb jy jz ka bi translated">步骤-1，<strong class="iw hj"> y </strong> = <strong class="iw hj">权重和输入的乘积求和，然后将偏差加到权重和输入的乘积上。</strong></li><li id="2acb" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr kb jy jz ka bi translated">然后，步骤2，值<strong class="iw hj"> y被馈送到激活函数，该函数给出神经元的输出值(z)。</strong></li><li id="64ff" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr kb jy jz ka bi translated">类似地，<strong class="iw hj">信息/输出值(z) </strong>作为输入被馈送到<strong class="iw hj">下一层神经元，</strong>直到输出层。</li></ul><h2 id="82b5" class="kn ko hi bd kp kq kr ks kt ku kv kw kx jf ky kz la jj lb lc ld jn le lf lg lh bi translated">‣ <strong class="ak">激活功能:</strong></h2><p id="d764" class="pw-post-body-paragraph iu iv hi iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr hb bi translated">我们正在处理一个二元分类问题，因此对于分类，我们将使用Sigmoid函数。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es ls"><img src="../Images/df08127bb817a008fe9254bed63573e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*cN0McK0qEBKgCnkFpdS4Rg.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">图6: Sigmoid函数</figcaption></figure><h2 id="bf11" class="kn ko hi bd kp kq kr ks kt ku kv kw kx jf ky kz la jj lb lc ld jn le lf lg lh bi translated">‣损失函数:</h2><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/e674264b6ab3959f4909173314451ca0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*herTluRZv7FlFfbtgpw8nw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">图7:二进制分类错误</figcaption></figure><p id="922a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">分类中的损失函数，这里是二元交叉熵。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/50ed51daddab72ee9de178510583e657.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*lD56U9diP14QqtxLzbQkNA.png"/></div></figure><p id="a4e6" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对于二元分类，我们有y = 0或y = 1。</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div class="er es lv"><img src="../Images/d173aec95451e58a12c4f58569eb2adc.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/1*B1WlYmfQ8AXsT4hKSeN4Lg.png"/></div></figure><p id="bd35" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">y_pred由sigmoid函数计算，</p><figure class="kd ke kf kg fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lw"><img src="../Images/fb1cf1a28f2e28fa3df7c5ddfe8e08f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BUERhrmp7Bl3Q-i1CaTE_Q.png"/></div></div></figure><h2 id="a862" class="kn ko hi bd kp kq kr ks kt ku kv kw kx jf ky kz la jj lb lc ld jn le lf lg lh bi translated">这是网络的前向传播。</h2><p id="6e47" class="pw-post-body-paragraph iu iv hi iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr hb bi translated">简单地说，前向传播意味着我们只在一个方向上移动(向前)，从神经网络的输入到输出。</p><p id="83b0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在下一篇博客中，我们将了解带反向传播的神经网络训练。</p><h1 id="c7ac" class="lx ko hi bd kp ly lz ma kt mb mc md kx me mf mg la mh mi mj ld mk ml mm lg mn bi translated">总结:</h1><ol class=""><li id="1094" class="js jt hi iw b ix li jb lj jf mo jj mp jn mq jr jx jy jz ka bi translated">计算，Z =总和[(权重*输入)+偏差]。</li><li id="73f7" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr jx jy jz ka bi translated">选择激活函数=用于二元分类sigmoid函数。</li><li id="715a" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr jx jy jz ka bi translated">代入“Z”的值，我们会得到y_pred。</li><li id="3cae" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr jx jy jz ka bi translated">利用二元交叉熵计算损失。</li></ol><p id="0a19" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">这里，我们学习了人工神经网络的前向传播，接下来我们将学习反向传播。</p><p id="1800" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">随着人工神经网络的前向传播和后向传播，我们还需要学习其他激活函数，后向传播中的链规则，消失梯度问题，爆炸梯度问题，丢失，正则化，权重初始化，优化器，损失函数。我们将逐一介绍。</p><h2 id="3bdc" class="kn ko hi bd kp kq kr ks kt ku kv kw kx jf ky kz la jj lb lc ld jn le lf lg lh bi translated">参考资料:</h2><ul class=""><li id="d67f" class="js jt hi iw b ix li jb lj jf mo jj mp jn mq jr kb jy jz ka bi translated"><a class="ae mr" href="https://en.wikipedia.org/wiki/Artificial_neural_network" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Artificial_neural_network</a></li><li id="424d" class="js jt hi iw b ix kh jb ki jf kj jj kk jn kl jr kb jy jz ka bi translated"><a class="ae mr" href="https://krisbolton.com/a-quick-introduction-to-artificial-neural-networks-part-1" rel="noopener ugc nofollow" target="_blank">https://Kris Bolton . com/a-人工神经网络快速介绍-第一部分</a></li></ul></div></div>    
</body>
</html>