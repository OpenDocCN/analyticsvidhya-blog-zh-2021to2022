<html>
<head>
<title>Explain ML models : SHAP Library</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">解释ML模型:SHAP图书馆</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/explain-ml-models-shap-library-5ce375c85d7d?source=collection_archive---------4-----------------------#2021-02-17">https://medium.com/analytics-vidhya/explain-ml-models-shap-library-5ce375c85d7d?source=collection_archive---------4-----------------------#2021-02-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/def6f40ec0604671984144a52423d34b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hyebRtJ35t4V11KN7ws9cA.png"/></div></div></figure><p id="793f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">换句话说，SHAP(Shapley Additive Explanations)是一个用来理解<em class="jn">你的模型如何以某种方式</em>进行预测的工具。在<a class="ae jo" rel="noopener" href="/analytics-vidhya/explain-how-your-model-works-using-explainable-ai-c7cefc42fde"> <strong class="ir hi">我的上一篇博客</strong> </a>中，我试图解释解释我们模型的重要性。现在我们将在act上看到一个可解释的AI库，并一起在数据集上实现它。如果你对可解释人工智能一无所知，继续阅读我的<em class="jn">“解释你的模型如何使用可解释人工智能工作”。</em></p></div><div class="ab cl jp jq go jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="ha hb hc hd he"><p id="c856" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">作为数据科学家，我们应该能够“调试”我们的模型，使其可以理解。利益相关者和客户都会有问题，我们应该能够回答他们。在许多场景中，我们处理的模型具有相互冲突的目标，可解释性和准确性需要权衡。所以我们要用一个度量来比较这些模型，选择一个<strong class="ir hi">精确的</strong>和<strong class="ir hi">可解释的</strong>模型。</p><p id="6bc6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当我们试图解释我们的模型时，我们做了什么？我们将数据可视化，查看特征，并尝试了解哪些特征对模型很重要。<em class="jn">每个特征在某种程度上都有助于预测。</em>确定贡献有多种方法。我们将讨论劳埃德·沙普利提出的方案。他介绍了一种在游戏中公平分配玩家点数的方法。这个<em class="jn">“公平”</em>是根据一个数学公式确定的。这里我们就不为它的计算费心了。阅读克里斯托夫·莫尔纳尔的《可解释机器学习》一书中的这一章,了解更多细节。[1]</p><p id="4d5e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Shap库是按照上面解释的逻辑开发的工具。它对特征使用这种<em class="jn">公平信用分配方法</em>，并计算它们在最终预测中的份额。在它的帮助下，我们可以<em class="jn"/>“调试”我们的模型，观察它是如何借助Shapley值以某种方式预测一个观察值的。</p><p id="d63a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在最一般的形式中，<strong class="ir hi">Shapley值是一个特征值在所有可能的联合中的平均边际贡献</strong>。如果有N个要素，Shapley值将从N！不同的阶次组合，所以就产生了模型<em class="jn"> NP-hard </em>的问题。Shap库免除了我们所有的计算细节，并且非常快速地完成了计算。与其他方法相比，它既方便又可靠，因为数值是根据可靠的理论计算的。</p><blockquote class="jw jx jy"><p id="3241" class="ip iq jn ir b is it iu iv iw ix iy iz jz jb jc jd ka jf jg jh kb jj jk jl jm ha bi translated">将<strong class="ir hi">的预测解释为特征值玩的游戏</strong>是令人兴奋的。[1]</p></blockquote><p id="9aea" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了演示如何使用它，我们将通过<em class="jn">“机器学习训练营-高级课程”</em>使用由DPhi社区提供的心脏病预测数据集。挑战的链接是<a class="ae jo" href="https://dphi.tech/practice/challenge/51#problem" rel="noopener ugc nofollow" target="_blank">这里的</a>。</p><p id="dad9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">链接到代码:</strong></p><div class="kc kd ez fb ke kf"><a href="https://www.kaggle.com/semanurkps/heart-disease-prediction-xai-shap" rel="noopener  ugc nofollow" target="_blank"><div class="kg ab dw"><div class="kh ab ki cl cj kj"><h2 class="bd hi fi z dy kk ea eb kl ed ef hg bi translated">心脏病预测SHAP XAI</h2><div class="km l"><h3 class="bd b fi z dy kk ea eb kl ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自非数据源的数据</h3></div><div class="kn l"><p class="bd b fp z dy kk ea eb kl ed ef dx translated">www.kaggle.com</p></div></div><div class="ko l"><div class="kp l kq kr ks ko kt in kf"/></div></div></a></div><p id="86a0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们不会深入讨论EDA和模型构建的细节，您可以按照笔记本上的步骤进行操作。我们的重点将完全放在SHAP的模型解释上。</p><p id="9462" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们用我们的数据建立了一个逻辑回归模型，并获得了86%的准确率。现在我们将尝试理解我们的模型是如何形成其预测的。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">安装并导入库</figcaption></figure><p id="25b3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于逻辑回归属于“线性模型”范畴，我们将使用线性解释器。对于不同的模型类型，SHAP也有不同的解释:</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es le"><img src="../Images/19130146ac27bc29041105653feeafec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AUoQBnZpfP0VopgX_4I7PQ.jpeg"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated"><a class="ae jo" href="https://dphi.tech/lms/learn/machine-learning-bootcamp/825" rel="noopener ugc nofollow" target="_blank"> DPhi高级机器学习课程，第12天，第14张幻灯片</a></figcaption></figure><p id="7569" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们建立我们的解释器模型。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div></figure><p id="56ca" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上述矩阵包括我们的“SHAP”值。它们基本上是代表那些特征在确定该行中的患者是否患有心脏病时的<strong class="ir hi">重要性的系数。正值表示预测值为1，负值表示预测值为1。</strong></p><p id="b466" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Shap库为数据集中的每个观察值(行)计算一个<strong class="ir hi">“基值”</strong>。这个基值可以解释为线性回归模型中的β_ 0系数(截距)。如果我们不知道与该观察相关的任何特征，我们将得到这个值。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div></figure><p id="e83c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当我们试图<em class="jn">【调试】</em>一个模型时，有两种基本方法，局部和全局解释。</p><ul class=""><li id="dc98" class="lf lg hh ir b is it iw ix ja lh je li ji lj jm lk ll lm ln bi translated"><em class="jn">局部解释</em>:每一行都有它的系数，它们向我们展示了相关特征是如何对特定行的预测做出贡献的。</li><li id="aa6e" class="lf lg hh ir b is lo iw lp ja lq je lr ji ls jm lk ll lm ln bi translated">如果我们想看到<em class="jn">全局</em>(整体)特征重要性，我们可以对shapley值求和，并分别对所有列进行平均，而不是局部检查。</li></ul><p id="424b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">对于复杂模型</strong>更容易关注<strong class="ir hi">局部解释</strong>。您的模型输出的期望值是我们的参考值。对于特定的观察，我们将查看它是否超过或落后于这个基础值，然后尝试找出哪个特征驱动模型在那里进行预测。</p><p id="f021" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">对于观测值，每个要素的值对基值有正或负的贡献。当这些贡献对一个观测的所有特征进行求和时，我们可以看到我们离基准值有多远。shap库中的力图很好地将它可视化。现在，我们将检查3个不同的观察结果，特别是第一、第五和第六个。我们为什么选择他们？</p><blockquote class="jw jx jy"><p id="d189" class="ip iq jn ir b is it iu iv iw ix iy iz jz jb jc jd ka jf jg jh kb jj jk jl jm ha bi translated">第一个病人<strong class="ir hi">有心脏病</strong>模型<strong class="ir hi">预测正确</strong>。<br/>第五个病人<strong class="ir hi">没有心脏病</strong>模型<strong class="ir hi">预测正确。</strong> <br/>第六名患者<strong class="ir hi">患有心脏病</strong>但模型<strong class="ir hi">预测健康。</strong></p></blockquote><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">Shap使用javascript来形成其漂亮的可视化效果。有时它会导致错误，我们无法从colab或任何其他平台看到可视化效果。我建议您下载笔记本并在本地IDE中运行它们，以获得最佳效果。</figcaption></figure><p id="26db" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们仔细看看第一个病人，为什么这个人有心脏病？这是病人的数据。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">要了解特性代表什么，请查看<a class="ae jo" href="https://dphi.tech/practice/challenge/51#data" rel="noopener ugc nofollow" target="_blank">此链接中的元数据。</a></figcaption></figure><p id="e638" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">力图中的红色特征使我们的预测为1:病人有心脏病。<strong class="ir hi">箭头越大，该特征对预测的影响越大。</strong>最有贡献的特征如下:<em class="jn"> thal，cp，sex，exang，oldpeak，ca，slope。</em></p><p id="5371" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">蓝色特征表示降低患者心脏病存在概率的特征。该患者的<em class="jn"> Thalach </em>和<em class="jn"> restecg </em>。</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lt"><img src="../Images/a0be7c9173cd3093125d46a14faf9f7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U9M2rIhYys-xeK_RG7AKtg.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">患者的thal值为零，胸痛类型为2，性别为女性，运动诱发的心绞痛为0 (exang)，oldpeak为0。很明显，所有这些特征促使病人患心脏病。Thalach(达到的最大心率)和restecg(静息心电图结果)对其有所帮助，但它仍然远离正方向的基础值。所以病人有心脏病。</figcaption></figure><p id="f4ab" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">第五个病人没有心脏病，模型设法正确识别它。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">取消对这些行的注释，并在您的IDE中运行它。你会得到下面的力图。</figcaption></figure><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lu"><img src="../Images/01b397ee3aa28d37baedf249e9bb8907.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fenVPOhtWq9QnPHUba2fiQ.jpeg"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">可以看出，thalach、ca、cp、oldpeak特征将模型从基值向负方向驱动。它将患者归类为健康。</figcaption></figure><p id="07e7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">模型将第六个病人归类为健康的，而实际上病人患有心脏病。让我们试着找出原因。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">取消对这些行的注释，并在您的IDE中运行它。你会得到下面的力图。</figcaption></figure><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lv"><img src="../Images/701af0126aa1c6bc11171f2038d93b31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ka21SXq82Vk5LpqdN-rIqg.jpeg"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">我们可以看到，值向负方向走得很远。该模型的一个强有力的驱动因素似乎是负面的oldpeak、trestbps和thal。但患者有第三型胸痛。</figcaption></figure><p id="c84a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们来看看该患者的<strong class="ir hi">决策图</strong>。决策图有助于我们了解模型是如何完成决策的。它非常类似于力图，但更容易阅读。我们可以根据特性对模型的重要性对它们进行排序。我们甚至可以显示多个观察结果，并突出显示其中的特定观察结果(例如，错误的预测可以在所有观察结果中突出显示)。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">“logit”选项将值转化为概率。在这里，我们可以看到，当一个人患病时，为什么模型预测他是健康的。</figcaption></figure><p id="bc70" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">既然我们已经从局部的角度研究了这个模型，我们可以转向全局的解释。我们功能的重要性列举如下。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">功能按最重要到最不重要的顺序排列。</figcaption></figure><p id="600e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">显示要素重要性的另一种方法是使用不同样式的汇总图。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">这样，我们可以看到每个特征的边界。如果cp的shapley值是&lt;1 it drives model to predict healthy aand when it exceeds this value, it contributes to predict heart disease.</figcaption></figure><p id="b373" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">依赖图</strong>是从全局角度解释模型的另一种方式。可以同时对一个或多个要素进行绘图。它基本上是一个散点图的特点和他们的沙普利值为每一个观察。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">我们可以观察到chol(胆固醇)和它的shapley值(它对模型预测的贡献)之间存在线性关系。</figcaption></figure><p id="675d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">依赖图的属性如下:</p><ul class=""><li id="3c5e" class="lf lg hh ir b is it iw ix ja lh je li ji lj jm lk ll lm ln bi translated"><strong class="ir hi"> ind </strong>:想要的特性的索引，这里是chol</li><li id="70a8" class="lf lg hh ir b is lo iw lp ja lq je lr ji ls jm lk ll lm ln bi translated"><strong class="ir hi"> interaction_index </strong>:用于显式设置哪个特征用于着色。</li><li id="2c7e" class="lf lg hh ir b is lo iw lp ja lq je lr ji ls jm lk ll lm ln bi translated"><strong class="ir hi"> shap_values </strong>:我们之前生成的shap值矩阵</li><li id="608b" class="lf lg hh ir b is lo iw lp ja lq je lr ji ls jm lk ll lm ln bi translated"><strong class="ir hi">特性</strong>:用于生成依赖图(X_test)的数据。</li></ul><p id="9907" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">双向PDP </strong>(部分相关性图)显示了基于shapley值的两个特性之间的关系。</p><figure class="ku kv kw kx fd ii"><div class="bz dy l di"><div class="ky kz l"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">在这个图中我们可以看到胆固醇和年龄的关系。不出所料，存在线性关系。</figcaption></figure><p id="79ce" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们也可以在一个图表中反映所有观测值的力图。它产生了一个非常全面的图形，有下拉过滤器。这里您可以看到由于javascript错误导致的代码快照。</p><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lw"><img src="../Images/d59d783c4f6526e2f53580a86d2e2611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E0Rr4dz5F5N9EftTTXzHRA.png"/></div></div></figure><p id="9120" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">总而言之，shap是一个强大的库，可以帮助我们调试和解释模型的行为。随着模型变得越来越先进，解释它们的兴趣也增加了。这是数据科学爱好者可以添加到简历中的一项非常酷的杰出技能。在这篇文章中，我们分享了它的一些功能来帮助你开始使用它。请务必查看下面共享的资源，对它的其他功能做更多的研究，下载代码，并随心所欲地使用它们！</p><p id="69c8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">快乐学习！</p><p id="72ac" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">链接代码:</strong><a class="ae jo" href="https://www.kaggle.com/semanurkps/heart-disease-prediction-xai-shap" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/semanurkps/heart-disease-prediction-xai-shap</a></p><h1 id="513e" class="lx ly hh bd lz ma mb mc md me mf mg mh mi mj mk ml mm mn mo mp mq mr ms mt mu bi translated">参考</h1><p id="709f" class="pw-post-body-paragraph ip iq hh ir b is mv iu iv iw mw iy iz ja mx jc jd je my jg jh ji mz jk jl jm ha bi translated">[1] Christoph Molnar，可解释的机器学习——让黑盒模型变得可解释的指南，2019，<a class="ae jo" href="https://christophm.github.io/interpretable-ml-book/shapley.html#shapley" rel="noopener ugc nofollow" target="_blank">https://christophm . github . io/interpreable-ml-book/Shapley . html # Shapley</a></p><p id="3a6b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[2]dpi Tech，可讲解的AI课程，<a class="ae jo" href="https://dphi.tech/lms/learn/explainable-ai/563" rel="noopener ugc nofollow" target="_blank">https://dphi.tech/lms/learn/explainable-ai/563</a></p><p id="48a6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[3]斯科特·伦德伯格，微软研究院——用沙普利值解释机器学习，<a class="ae jo" href="https://youtu.be/ngOBhhINWb8" rel="noopener ugc nofollow" target="_blank">https://youtu.be/ngOBhhINWb8</a></p><p id="1308" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[4]<a class="ae jo" href="https://slundberg.github.io/shap/notebooks/plots/decision_plot.html" rel="noopener ugc nofollow" target="_blank">https://slund Berg . github . io/shap/notebooks/plots/decision _ plot . html</a></p><p id="d03f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">附加资源</strong></p><p id="5333" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[1]<a class="ae jo" href="https://dphi.tech/notebooks/816/gunnika/shap-implementation" rel="noopener ugc nofollow" target="_blank">https://dphi.tech/notebooks/816/gunnika/shap-implementation</a></p><p id="4c8a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[2]<a class="ae jo" href="https://pub.towardsai.net/explain-your-machine-learning-predictions-with-kernel-shap-kernel-explainer-fed56b9250b8" rel="noopener ugc nofollow" target="_blank">https://pub . toward sai . net/explain-your-machine-learning-predictions-with-kernel-shap-kernel-explainer-fed 56 b 9250 b 8</a></p><p id="e599" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae jo" href="https://dphi.tech/notebooks/816/gunnika/shap-implementation" rel="noopener ugc nofollow" target="_blank">https://dphi.tech/notebooks/816/gunnika/shap-implementation</a></p><p id="6238" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae jo" href="https://en.wikipedia.org/wiki/Shapley_value" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Shapley_value</a></p><figure class="ku kv kw kx fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es na"><img src="../Images/cb78156a3e4d00aa6db1d8060bb31150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zM7KnEz-DARP8GH3uNmf7Q.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated"><a class="ae jo" href="https://www.linkedin.com/in/semanurkapusizoglu/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a>——<a class="ae jo" href="https://github.com/semanurkps" rel="noopener ugc nofollow" target="_blank">GitHub</a></figcaption></figure></div></div>    
</body>
</html>