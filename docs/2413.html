<html>
<head>
<title>How to create a Recommendation System from scratch using Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用Keras从头开始创建推荐系统</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-create-a-recommendation-system-from-scratch-using-keras-f3647fc5c6f8?source=collection_archive---------10-----------------------#2021-04-22">https://medium.com/analytics-vidhya/how-to-create-a-recommendation-system-from-scratch-using-keras-f3647fc5c6f8?source=collection_archive---------10-----------------------#2021-04-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="8d72" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用IMDB数据集来训练电影推荐引擎</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/b2c42bf6e1589fe966ff52128abe81a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1352/0*BITUyojCfwjmqQk0"/></div></figure><p id="1a17" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作者安东尼奥·利斯</p><h1 id="9831" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">介绍</h1><p id="d4f3" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">大家好，我们继续我们关于如何在经典深度学习应用中从零开始训练算法的系列。</p><p id="f46d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我们将看到如何使用协同过滤算法从头开始创建和解释推荐引擎。</p><p id="2f1b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">推荐引擎是一种预测用户可能喜欢或不喜欢什么的工具。当你有大量的用户和产品，并且你想推荐哪些产品最有可能对哪些用户有用的时候，通常会用到它。</p><p id="cfab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有几个推荐系统的例子，比如网飞或者亚马逊的主页。</p><h1 id="5045" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">资料组</h1><p id="8e03" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">我们将用来测试我们模型的数据集是我们从<a class="ae kn" href="https://grouplens.org/datasets/movielens/" rel="noopener ugc nofollow" target="_blank">这里</a>下载的MovieLens 25M数据集。该数据集拥有2500万个评级和100万个标签应用，由162，000个用户应用于62，000部电影。</p><p id="4265" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过链接，我们总共下载了六个数据集。但是我们只对其中两个感兴趣:</p><ol class=""><li id="864b" class="ko kp hh ig b ih ii il im ip kq it kr ix ks jb kt ku kv kw bi translated">ratings.csv，包含用户对不同电影的评级</li><li id="4e91" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated">movies.csv映射每个电影的标题和类型</li></ol><p id="a63d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们来看看它们:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lc"><img src="../Images/38c7b30597ec743ecc9cedba6ebc6210.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/0*Sf3Ej-BH3nZ0UkI5"/></div></figure><p id="add2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先要做的是将两个数据集连接起来，使所有信息都包含在一个熊猫数据框架中:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="914e" class="li jl hh le b fi lj lk l ll lm">df = df.merge(df_movie, how="left", on="movieId")</span></pre><p id="ace7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中df是分级数据集，df_movie是电影数据集。所以我们得到了这样的结果:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/ddcc2fb554bc4a583303ce66ddde215c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*JaNkJqv6II3V0uLq"/></div></div></figure><p id="afe8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我们可以将此数据帧保存在拼花文件中，以便在接下来的笔记本中轻松加载:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="68fb" class="li jl hh le b fi lj lk l ll lm">df.to_parquet("../data/processed/df_rating_movie.parquet")</span></pre><h1 id="f381" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">数据探索</h1><p id="ba0b" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">让我们探索我们的数据。我们先来看看收视率较高的电影:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="bae2" class="li jl hh le b fi lj lk l ll lm">df.groupby(["movieId", "title", "genres"]).agg({"rating": "mean", "userId": "count"}).rename(columns={"userId": "n_reviews"}).sort_values("rating", ascending=False)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ls"><img src="../Images/e3580a380e01b6db1d3f496945b68153.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/0*DvmV7tjs68ZbXXj9"/></div></figure><p id="d7c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以看到，我们有很多电影只有一两个评论。为了有意义，我们需要筛选出一些评论:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="840c" class="li jl hh le b fi lj lk l ll lm">df_top_review = df.groupby(["movieId", "title", "genres"]).agg({"rating": "mean", "userId": "count"}).rename(columns={"userId": "n_reviews"}) </span><span id="5df8" class="li jl hh le b fi lt lk l ll lm">df_top_review = df_top_review[df_top_review.n_reviews &gt; 10] <br/>df_top_review.sort_values("rating", ascending=False)[:10]</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es lu"><img src="../Images/2db63758beb6488aad15b179ca7c1d26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*a3kX_-qls4Cz21h0"/></div></div></figure><p id="d6f6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在可以认出一些电影，但仍有一些电影像<a class="ae kn" href="https://www.imdb.com/title/tt0314519/" rel="noopener ugc nofollow" target="_blank">波利安娜</a>一样很少有评论。</p><p id="ca84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">来看看评论最多的电影:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="71bd" class="li jl hh le b fi lj lk l ll lm">df_top_review.sort_values("n_reviews", ascending=False)[:10]</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es lv"><img src="../Images/302492573722eb18d677f11c37ba23a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*B_L8o6A0pq6yfmZk"/></div></div></figure><p id="e3a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还可以看到评分最高的流派:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="319b" class="li jl hh le b fi lj lk l ll lm">df_top_genres = df.groupby(["genres"]).agg({"rating": "mean", "userId": "count"}).rename(columns={"userId": "n_reviews"}) </span><span id="c548" class="li jl hh le b fi lt lk l ll lm">df_top_genres = df_top_genres[df_top_genres.n_reviews &gt; 10] df_top_genres.sort_values("rating", ascending=False)[:10]</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lw"><img src="../Images/ad03f1bbc4771bfce039297d0466a80a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1036/0*6T741OGNbl96H3m5"/></div></figure><p id="8b4e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">和以前一样，我们可以看到评论最多的类型:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="18ed" class="li jl hh le b fi lj lk l ll lm">df_top_genres.sort_values("n_reviews", ascending=False)[:10]</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es lx"><img src="../Images/67727cdf28847a945b0bac1e62d9d4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/0*A3vbqdXa5t5bH1Ss"/></div></div></figure><p id="77b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">戏剧和喜剧，这里不奇怪，但是我们可以看到，喜剧的比率非常低。那是因为外面有很多平庸的喜剧。戏剧就不一样了。</p><p id="2449" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后将数据集分为训练集和验证集:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="0400" class="li jl hh le b fi lj lk l ll lm">df_train, df_val = train_test_split(df, random_state=42, test_size=0.2, stratify=df.rating)</span></pre><h1 id="a0f0" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">数据预处理</h1><p id="018c" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">在开始训练模型之前，我们需要实现一些基本的预处理步骤。我们首先对电影和用户Id进行编码，使它们从零开始，这样我们就可以轻松地使用Keras的嵌入层:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="33fe" class="li jl hh le b fi lj lk l ll lm">dict_movies = {} <br/>index = 0 <br/>for ids in sorted(movies_ids): <br/>    dict_movies[ids] = index <br/>    index += 1 </span><span id="77e4" class="li jl hh le b fi lt lk l ll lm">dict_users = {} <br/>index = 0 <br/>for ids in sorted(users_ids): <br/>    dict_users[ids] = index <br/>    index += 1 </span><span id="192e" class="li jl hh le b fi lt lk l ll lm">df_train["movieId"] = df_train["movieId"].map(dict_movies) df_val["movieId"] = df_val["movieId"].map(dict_movies) df_train["userId"] = df_train["userId"].map(dict_users) df_val["userId"] = df_val["userId"].map(dict_users)</span></pre><p id="c021" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们将评级和id转换为float32 NumPy向量:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="a77e" class="li jl hh le b fi lj lk l ll lm">for col in ["userId", "movieId", "rating"]: <br/>    df_train[col] = df_train[col].astype(np.float32) <br/>    df_val[col] = df_val[col].astype(np.float32)</span></pre><p id="564a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们定义了将在嵌入层中使用的唯一用户和电影的数量:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="5623" class="li jl hh le b fi lj lk l ll lm">num_unique_users=len(set(list(df_train.userId.unique()) + list(df_val.userId.unique()))) </span><span id="bf47" class="li jl hh le b fi lt lk l ll lm">num_unique_movies=len(set(list(df_train.movieId.unique()) + list(df_val.movieId.unique())))</span></pre><h1 id="7a83" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">协同过滤算法</h1><p id="aa50" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">协作过滤算法背后的基本概念是潜在因素可以通过用户的行为来捕获的思想。我们有用户和电影的潜在因素。相似的用户会有相似的电影口味，同时相似的电影也会被相同的用户喜欢。</p><p id="4fc4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们从实现协同过滤算法开始。我们将使用Keras Functional API来定义我们的模型:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="2455" class="li jl hh le b fi lj lk l ll lm">users_input = Input(shape=(1,), name="users_input") </span><span id="3d83" class="li jl hh le b fi lt lk l ll lm">users_embedding = Embedding(num_unique_users + 1, EMBEDDING_SIZE, name="users_embeddings")(users_input) </span><span id="3bb2" class="li jl hh le b fi lt lk l ll lm">users_bias = Embedding(num_unique_users + 1, 1, name="users_bias")(users_input) </span><span id="8158" class="li jl hh le b fi lt lk l ll lm">movies_input = Input(shape=(1,), name="movies_input") </span><span id="b25a" class="li jl hh le b fi lt lk l ll lm">movies_embedding = Embedding(num_unique_movies + 1, EMBEDDING_SIZE, name="movies_embedding")(movies_input) </span><span id="b637" class="li jl hh le b fi lt lk l ll lm">movies_bias = Embedding(num_unique_movies + 1, 1, name="movies_bias")(movies_input) </span><span id="732d" class="li jl hh le b fi lt lk l ll lm">dot_product_users_movies = multiply([users_embedding, movies_embedding]) </span><span id="05dd" class="li jl hh le b fi lt lk l ll lm">input_terms = dot_product_users_movies + users_bias + movies_bias input_terms = Flatten(name="fl_inputs")(input_terms) </span><span id="9463" class="li jl hh le b fi lt lk l ll lm">output = Dense(1, activation="relu", name="output")(input_terms) model = Model(inputs=[users_input, movies_input], outputs=output)</span></pre><p id="7f76" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看看模型总结:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ly"><img src="../Images/e34c0f848e80f99d52f0fb5c22558e26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1YnYvkCsOSxDfIuD"/></div></div></figure><p id="bf66" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以我们来解释一下。我们将有两个输入:</p><ul class=""><li id="f548" class="ko kp hh ig b ih ii il im ip kq it kr ix ks jb lz ku kv kw bi translated">代表进行审阅的用户的UserId</li><li id="0369" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb lz ku kv kw bi translated">代表所评论电影的MovieId</li></ul><p id="d50c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后我们有用户和电影的嵌入。基本上，我们正在创建一个长度为50的向量来表示单个用户和电影，以逼近我们想要逼近的潜在因素。</p><p id="c895" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们也在考虑另外两种嵌入，叫做用户和电影的偏见。就像在回归模型中一样，我们有一个偏差项，它为用户表示单个用户给出高评价的倾向。同时，一些电影是每个人都喜欢的，所以他们有一个基数高的评论，而不考虑正在做评论的特定用户。</p><p id="18e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们把用户和电影的潜在因素相乘，然后加上两个偏差。然后，我们使用密集层输出一个数字，这是我们的预测评级。</p><p id="4188" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在可以像往常一样定义优化器和损失函数:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="096f" class="li jl hh le b fi lj lk l ll lm">opt_adam = opt.Adam(lr = 0.005) </span><span id="5dc1" class="li jl hh le b fi lt lk l ll lm">model.compile(optimizer=opt_adam, loss= ['mse'], metrics=['mean_absolute_error'])</span></pre><p id="ed1e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用Adam优化器和均方误差作为损失函数。我们现在可以开始我们的培训了:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="56c2" class="li jl hh le b fi lj lk l ll lm">model.fit(x=[df_train.userId, df_train.movieId], y=df_train.rating, batch_size=512, epochs=3, verbose=1, validation_data=([df_val.userId, df_val.movieId], df_val.rating))</span></pre><p id="e316" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="ma">历元1/3<br/>39063/39063[= = = = = = = = = = = = = = = = = = = = = = = = = =]—2303s 59ms/step—损耗:0.9431 —均值_绝对_误差:0.7221—val _损耗:0.6360—val _均值_绝对_误差:0.6075 <br/>历元2/3<br/>39063/39063[= = = = = = = = = = = = = = = = = = = = =</em></p><p id="17e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们做得还不错，但我们可以做些改进。</p><h1 id="c8c1" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">限制输出范围</h1><p id="bb83" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">我们知道，我们的评级有一个可以在IMDB上给出的最小值和最大值。我们可以从数据中推断出来:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="f2a1" class="li jl hh le b fi lj lk l ll lm">min_rating=min(df_train.rating.min(), df_val.rating.min()) max_rating=max(df_train.rating.max(), df_val.rating.max())</span></pre><p id="7d6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的最低评分是0.5，最高评分是5。因此，我们现在可以限制我们的模型，使其只能预测该范围内的值。我们通过在最后一层使用一个sigmoid激活函数来达到这个目的。然后我们将这个数乘以最大值和最小值之差，再加上最小值:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="14b9" class="li jl hh le b fi lj lk l ll lm">output = Dense(1, activation="sigmoid", name="output")(input_terms) output = output * (max_rating - min_rating) + min_rating</span></pre><p id="c4d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以看到新模式的总结:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mb"><img src="../Images/4bd94bef7b253d156ae0c779658433b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*LCj8NVrAvfMJUerG"/></div></div></figure><p id="b2b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">和以前一样，我们使用Adam优化器和均方误差损失函数。所以我们编译并训练这个模型:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="fdf6" class="li jl hh le b fi lj lk l ll lm">opt_adam = opt.Adam(lr = 0.005) </span><span id="508c" class="li jl hh le b fi lt lk l ll lm">model.compile(optimizer=opt_adam, loss= ['mse'], metrics=['mean_absolute_error']) </span><span id="fb6d" class="li jl hh le b fi lt lk l ll lm">model.fit(x=[df_train.userId, df_train.movieId], y=df_train.rating, batch_size=2048, epochs=3, verbose=1, validation_data=([df_val.userId, df_val.movieId], df_val.rating))</span></pre><p id="f639" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="ma">纪元1/3<br/>9766/9766[= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =]—600s 61 ms/step—损耗:0.7700—mean _ absolute _ error:0.6722—val _ loss:0.6254—val _ mean _ absolute _ error:0.5998<br/>纪元2/3<br/>9766/9766[= = = = = = = = = = = = = = = = = = = = = =</em></p><p id="9198" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将验证损失从0.63提高到0.62，虽然提高不多，但这是一个非常简单的改进。</p><p id="6efe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以使用更“深入”的方法来改进模型。例如，在何等人的论文《神经协同过滤》中提出的方法..这是一种简单的方法。我们不是将潜在因素相乘并添加偏差，而是连接输入，并通过正则化在完全连接的层上添加。</p><p id="d07a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们不打算实现这一点，因为我发现分析我们创造的潜在因素和偏见更有趣。</p><h1 id="368a" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">探索电影的潜在因素和偏见</h1><p id="dc6f" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">首先，我们需要提取层的权重:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="060f" class="li jl hh le b fi lj lk l ll lm">dict_weights = {} </span><span id="ac52" class="li jl hh le b fi lt lk l ll lm">for layer in model.layers: <br/>    if layer.name in ["users_embeddings", "movies_embeddings", "users_bias", "movies_bias"]: <br/>        dict_weights[layer.name] = layer.weights</span></pre><p id="5572" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于用户匿名化，探索电影的潜在因素和偏见就更有意义了。我们从潜在因素开始。</p><p id="98c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将嵌入保存在pandas数据帧中，并像在原始数据集中一样定义关键MovieId:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="fc42" class="li jl hh le b fi lj lk l ll lm">df_movies_embeddings = pd.DataFrame(dict_weights["movies_embeddings"][0].numpy()) df_movies_embeddings.columns = ["emb_" + str(col) for col in df_movies_embeddings.columns] </span><span id="4be5" class="li jl hh le b fi lt lk l ll lm">df_movies_embeddings.reset_index(inplace=True) df_movies_embeddings.rename(columns={"index":"movieId"}, inplace=True)</span></pre><p id="afb7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在可以从电影的原始数据集类型和名称中恢复:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="0bcd" class="li jl hh le b fi lj lk l ll lm">df_movies_embeddings = df_movies_embeddings.merge(df_train[["movieId", "title", "genres"]].drop_duplicates(), how="left", on="movieId")</span></pre><p id="67f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了在二维散点图中观看电影，我们将使用统计方法<a class="ae kn" href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html" rel="noopener ugc nofollow" target="_blank"> t分布随机邻居嵌入(t-SNE) </a>来减少二维向量中的50长度嵌入:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="2357" class="li jl hh le b fi lj lk l ll lm">vec_tsne = TSNE(n_components=2).fit_transform(df_movies_embeddings[[col for col in df_movies_embeddings.columns if "emb" in col]]) </span><span id="081d" class="li jl hh le b fi lt lk l ll lm">df_movies_embeddings["tsne_0"] = vec_tsne[:, 0] df_movies_embeddings["tsne_1"] = vec_tsne[:, 1]</span></pre><p id="bb69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在可以看到前100部二维电影:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="2e08" class="li jl hh le b fi lj lk l ll lm">plt.figure(figsize=(12,12)) plt.scatter(df_movies_embeddings.tsne_0[:100], df_movies_embeddings.tsne_1[:100]) for i, x, y in zip(df_movies_embeddings.title[:100], df_movies_embeddings.tsne_0[:100], df_movies_embeddings.tsne_1[:100]): plt.text(x,y,i, color=np.random.rand(3)*0.7, fontsize=11)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mc"><img src="../Images/c09de21ba7f687c702c008f70a1bf061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*lIbV80vvYB_vhQm7"/></div></div></figure><p id="31be" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这样一来，我们就真的推断不出多少了。我们有太多的电影。但是我们可以对嵌入使用一些聚类方法。我们将使用具有100个集群的kmeans:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="dab1" class="li jl hh le b fi lj lk l ll lm">km = KMeans(100, random_state=101) <br/>km.fit(df_movies_embeddings[[col for col in df_movies_embeddings.columns if "emb" in col]]) </span><span id="b0fc" class="li jl hh le b fi lt lk l ll lm">clusters = km.predict(df_movies_embeddings[[col for col in df_movies_embeddings.columns if "emb" in col]]) </span><span id="b625" class="li jl hh le b fi lt lk l ll lm">df_movies_embeddings["cluster_n10"] = clusters</span></pre><p id="5982" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看一些集群:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es md"><img src="../Images/2948a7820e085b6bd451882873d27698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/0*bNmHSlwb9oBG2zfT"/></div></figure><p id="b5e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以集群56只是加勒比海盗系列。让我们探索其他集群:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es me"><img src="../Images/2830a3fc7f97ee8f90f229d3c884bd13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/0*4keJh-9lVE6_tbPD"/></div></figure><p id="2862" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">集群81是死亡系列的<a class="ae kn" href="https://www.wikiwand.com/en/Faces_of_Death" rel="noopener ugc nofollow" target="_blank">面孔。</a></p><p id="b9cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">集群84非常有趣:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mf"><img src="../Images/59d30d4574bffb39f7c5e8fa11946890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*E8_GJJ8l4d0YB0fX"/></div></div></figure><p id="f281" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它将《星际迷航》、《星球大战》、《哈利·波特》和《指环王》这几部传奇集放在了一起。所以这是一种幻想/科幻的混合。</p><p id="d047" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这非常有趣，可以作为一种新的方式，根据我们从评论中推断出的用户口味来定义流派。</p><p id="9006" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们可以看到电影的偏见:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="f01a" class="li jl hh le b fi lj lk l ll lm">df_movies_embeddings["bias"] = dict_weights["movies_bias"][0].numpy()</span></pre><p id="468b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">带着最大的偏见看电影:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mg"><img src="../Images/ddf1790d74d998fa4b73f109baf8eeae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*DxC5glmFRvyIU96p"/></div></div></figure><p id="cf69" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以我们可以看到《地球》是最有偏见的电影。意思是，即使你通常不喜欢某种类型的电影(例如纪录片)，你也可能喜欢《地球》。</p><h1 id="039f" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">结论</h1><p id="d6fd" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">所以在这篇文章中，我们展示了如何使用Keras从头开始编写推荐系统，并解释偏见和潜在因素。</p><p id="c0e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以在我的<a class="ae kn" href="https://github.com/antonai91/recommendation_system" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到所有代码。有任何问题，你可以通过<a class="ae kn" href="https://www.linkedin.com/in/lisiantonio/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>联系我。</p><p id="2e8b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你喜欢这篇文章，分享给你的朋友和同事吧！我会在下一篇文章中看到你。与此同时，保重，保持安全，记住<em class="ma">不要成为墙上的另一块砖。</em></p><p id="8c73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Anton.ai</p></div><div class="ab cl mh mi go mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ha hb hc hd he"><p id="bfab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="ma">原载于2021年4月22日</em><a class="ae kn" href="https://antonai.blog/how-to-create-a-recommendation-system-from-scratch-using-keras/" rel="noopener ugc nofollow" target="_blank"><em class="ma">https://antonai . blog</em></a><em class="ma">。</em></p></div></div>    
</body>
</html>