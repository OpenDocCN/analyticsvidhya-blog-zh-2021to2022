<html>
<head>
<title>LINEAR REGRESSION</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-b0d533614f5c?source=collection_archive---------7-----------------------#2021-03-11">https://medium.com/analytics-vidhya/linear-regression-b0d533614f5c?source=collection_archive---------7-----------------------#2021-03-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="a564" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在回归分析中，我们用一个预测模型来拟合我们的数据，并使用该模型从一个或多个自变量中预测因变量的值。</p><p id="cf20" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">简单回归寻求从单个预测变量预测结果变量，而多重回归寻求从几个预测变量预测结果。我们可以使用下面的通用等式来预测任何数据:</p><p id="2f5c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">(结果)i =(模型)i +(误差)I</p><p id="c8ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们这里适合的模型是线性模型。线性模型只是指基于直线的模型。你可以把它想象成试图用一条直线来概括一个数据集。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/fa88d2b839bff70a3757438f4e81f502.png" data-original-src="https://miro.medium.com/v2/resize:fit:1250/format:webp/0*7NGWYBeK4MqPGZbS.png"/></div></div></figure><p id="9819" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">直线的一些重要特征</p><p id="bf4e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">直线可以由两个东西来定义:</p><p id="fc88" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1)线(b1)的斜率或梯度</p><p id="b98f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2)直线与图形纵轴相交的点，也称为直线的截距(b0)。所以我们的一般方程变成:Yi = (b0 + b1Xi) + εi</p><p id="2764" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里易是我们要预测的结果，是预测变量的第I个分数。截距b0和斜率b1是模型中的参数，称为回归系数。有一个剩余项εi，它代表由直线预测的分数与因变量的第I个实际分数之间的差值。这个术语证明了这样一个事实，即我们的模型不会完全符合收集到的数据。通过回归，我们努力找到最能描述数据的直线。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jo"><img src="../Images/2c8dca5fcee746b981531e99cdf2ae54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1214/format:webp/0*zelRTu1nN_ehBOxw.png"/></div></figure><p id="c7eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相同的截距，但不同的斜率</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jp"><img src="../Images/8cc46508b3035686f1cec7f748954dc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/0*dkwsePTJmXpTxpO6.png"/></div></figure><p id="f40e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相同的斜率，但不同的截距</p><p id="022d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">相关和回归之间的差异</strong></p><p id="b36a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相关性分析关注的是了解变量之间是否存在关系以及这种关系有多强。回归分析关注的是找到一个表示变量之间关系的公式，以便从一个变量的值中找到另一个变量的近似值。</p><p id="c08d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">简单线性回归的假设</p><p id="bc16" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1.自变量和因变量之间的单线性可以用线性回归来表示。</p><p id="9b91" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.独立变量本质上必须是非随机的，即变量没有任何相关的分布。</p><p id="aae8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.模型的参数必须是线性的。</p><p id="e759" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.独立变量不应与误差项相关。</p><p id="8dac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.误差项必须相互独立，即一个误差项的出现不应影响其他误差项的出现。</p><p id="182c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">最小二乘法</strong></p><p id="6a39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最小二乘法是找到最符合数据的直线的一种方法。在所有可能画出的线中，最佳拟合的线是观察到的数据点和线之间差异最小的线。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jq"><img src="../Images/a5bb9cce61c56f629dcef535573cd150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/0*tx4T3l-eNlV4HPz4.png"/></div></figure><p id="459f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该图显示，当任何一条线与一组数据拟合时，该线与实际数据之间会有微小的差异。我们对直线和实际数据之间的垂直差异感兴趣，因为我们使用直线从x的值预测Y的值。这些差异中有些是正的(它们在线上，表明模型低估了它们的值)，有些是负的(它们在线下，表明模型高估了它们的值)。</p><p id="7343" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">了解拟合优度</strong></p><p id="6702" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">统计模型的拟合优度描述了它与一组观察值的拟合程度。拟合优度的测量值通常总结了观察值和模型预期值之间的差异。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jr"><img src="../Images/3eff149de3cec6f098249bb5aeb5a1c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/format:webp/0*fIJqKtkBVYJ5rOVJ.png"/></div></figure><p id="4bad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在线性回归中，拟合是通过R2表示的，除了R2，还有另一种拟合优度的衡量标准，称为调整后的R平方。简单地通过在模型中包括越来越多的预测值，可以使回归的R2值任意高。调整后的R2考虑了模型中独立变量的数量。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es js"><img src="../Images/737f59a813b5fb2cbea84027bb247924.png" data-original-src="https://miro.medium.com/v2/resize:fit:896/format:webp/0*nYE89OcfdEhqD-Wv.png"/></div></figure><p id="1a36" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">从样本到人群</strong></p><p id="7c15" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">像其他统计方法一样，使用回归，我们试图从样本中发现因变量和自变量之间的关系，并试图对总体进行推断。这就是线性回归中的显著性检验。</p><p id="f91c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">估计线的等式为:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jt"><img src="../Images/8dfe175e4270fb2643f3d0a1125b6b05.png" data-original-src="https://miro.medium.com/v2/resize:fit:398/format:webp/0*R0JT2LEHlFAdZyAX.png"/></div></figure><p id="8236" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里α和β分别是截距和斜率的估计值。显著性检验与这两个估计值相关。</p><p id="183b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">估计参数的显著性检验</strong></p><p id="c315" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">全局测试</strong></p><p id="0f96" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">H0: 所有参数同时等于零</p><p id="6b1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> H1: </strong>至少有一个非零值</p><p id="c46c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个测试是通过使用与我们在ANOVA中看到的相似的F统计来进行的。</p><p id="f53b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">本地测试</strong></p><p id="225a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于每个单独的参数，</p><p id="f3a9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> H0: </strong>参数值为零</p><p id="f77a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> H1: </strong>该值不为零</p><p id="4e27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该测试通过使用类似于单样本t检验的t统计来进行。</p><p id="8617" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于简单的线性回归，全局测试和局部测试没有区别，因为只有一个独立变量。</p><p id="b265" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">多元线性回归</strong></p><p id="71f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">多元线性回归(MLR)基本上是简单线性回归的扩展。一元线性回归只有一个解释变量，而多元回归考虑一个以上的自变量来解释因变量。所以从现实的角度来看，MLR比简单的线性回归更有吸引力。举个例子，</p><p id="aacf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">(工资)i = a + b1(学历)i + b2(经验)i + b3(生产力)i + b4(工作经验)i + (e)i</p><p id="984b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">假设</strong></p><p id="2019" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1.因变量和自变量之间的关系是线性的。散点图应作为回归分析中的探索步骤进行检查，以确定可能偏离线性的情况。</p><p id="cb8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.误差与独立变量无关。在残差分析中，用残差与单个预测值的散点图来检验这一假设。</p><p id="965d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.残差的期望值为零。这不是问题，因为估计回归方程的最小二乘法保证平均值为零。</p><p id="c86e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.残差的方差是常数。违反的一个例子是其分散(方差)随时间增加的残差模式。这种假设的另一个方面是，误差方差不应该随着预测值的大小而系统地变化。例如，预测值较大时的误差方差不应大于预测值较小时的误差方差。</p><p id="61ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.残差是随机的或在时间上不相关的。</p><p id="e07c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">6.误差项是正态分布的。要使回归方程的系数和其他统计数据的显著性的常规检验有效，必须满足这一假设。</p><p id="4f74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">多重共线性的概念</strong></p><p id="61f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">回归模型中的预测因子通常被称为“独立变量”,但这个术语并不意味着预测因子本身在统计上是相互独立的。事实上，对于自然系统来说，预测因子可能是高度相关的。――多重共线性是一个术语，用于描述预测变量间相关性较高的情况。已经注意到，估计的回归系数的方差取决于预测值的相互关系。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ju"><img src="../Images/713f2488f676211abc87f28fc6ff9d0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/0*QmwQsTKxJgsi8d1B.png"/></div></figure><p id="e782" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，多重共线性不会使回归模型无效，因为只要预测是基于用于校准方程的同一多元空间内的预测因子组合，方程的预测值可能仍然是好的。但是多重共线性也有一些负面影响。首先，回归系数的方差可能被夸大得太多，以至于单个系数在统计上不显著，即使总的回归方程很强，预测能力也很好。第二，系数的相对大小甚至符号都可能无法解释。第三，单个回归系数的值可能会随着方程中预测变量的删除或添加而彻底改变。事实上，系数的符号甚至可能改变。</p><p id="19e5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">多重共线性的迹象</strong></p><p id="61e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1.预测变量对之间的高度相关</p><p id="73b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.回归系数，其符号或数值没有很好的物理意义</p><p id="6546" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.重要预测因子的统计非显著回归系数</p><p id="1ac9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.回归系数的符号或大小对预测变量的插入或删除的极端敏感性</p><p id="d022" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">什么是VIF？</p><p id="147b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">方差膨胀因子(VIF)是一种统计数据，可用于识别预测变量矩阵中的多重共线性。――方差膨胀‖这里指的是上述多重共线性对估计回归系数方差的影响。多重共线性不仅取决于预测因子对之间的二元相关性，还取决于任何一个预测因子相对于其他预测因子的多元可预测性。因此，VIF基于所有其他预测因子的多元线性回归中每个预测因子的多重决定系数:</p><p id="a8eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">VIFi = 1/(1 — Ri2)</p><p id="ddb3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中Ri2是第I个预测因子对所有其他预测因子的回归中的多重决定系数，VIFi是与第I个预测因子相关的方差膨胀因子。请注意，如果第I个预测值独立于其他预测值，则方差膨胀因子为1，而如果第I个预测值可以从其他预测值中几乎完美地预测出来，则方差膨胀因子接近无穷大。在这种情况下，估计回归系数的方差是无界的。当一个或多个预测值的方差膨胀因子变大时，多重共线性被认为是一个问题。它看起来有多大是一个主观判断。一些研究者使用VIF 5，其他人使用VIF 10作为临界阈值。VIF与一个叫做公差的统计密切相关，公差是1/VIF。</p><p id="9f04" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">残差分析</strong></p><p id="0a57" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">残差分析包括检查回归残差的图表和统计数据，以检查模型假设是否得到满足。下面列出了一些常用的残差检验。所有这些都是为了检验误差项是否同分布。</p><ol class=""><li id="eb3a" class="jv jw hh ig b ih ii il im ip jx it jy ix jz jb ka kb kc kd bi translated"><strong class="ig hi"> 残差时间序列图:</strong>残差时间序列图可以表示残差的非常方差、残差的趋势或自相关等问题。</li><li id="6f27" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><strong class="ig hi">残差与预测值的散点图:</strong>假设残差与预测值不相关。散点图中一些明显的相关性模式表明了违规。</li><li id="c47f" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><strong class="ig hi">残差与单个预测值的散点图:</strong>残差被假定为与单个预测值不相关。散点图中的一些明显的相关性模式将表明这些假设的违反，并可能表明预测值的转换。</li><li id="8e7d" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><strong class="ig hi">残差直方图:</strong>残差假设为正态分布。因此，残差直方图应该类似于正态概率密度函数曲线。</li><li id="4092" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><strong class="ig hi">残差的滞后-1散点图:</strong>该图也涉及残差独立性的假设。时间t的残差应该独立于时间t-1的残差。因此，散点图应该类似于一个无形的点群。</li></ol><p id="e546" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">自相关的观念</strong></p><p id="d909" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自相关是给定时间序列与其自身在连续时间间隔内的滞后版本之间相似程度的数学表示。这与计算两个不同时间序列之间的相关性是一样的，只是同一时间序列会被使用两次，一次是以其原始形式，另一次是滞后一个或多个时间段。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kj"><img src="../Images/bbb8c7742efac6c3b67a0d3e16006260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/0*RNr7cp0Nz3veU1Xp.png"/></div></figure><p id="7c59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">计算自相关以检测数据中的模式。在图表中，第一个系列是随机的，而第二个系列显示了模式。</p><p id="7bc3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">德宾-沃森(D-W)统计</strong></p><p id="4ea3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Durbin-Watson (D-W)统计测试残差的自相关，特别是滞后1自相关。D-W统计根据正一阶自相关的替代假设检验无一阶自相关的零假设。替代假说也可能是负一阶自相关。假设残差遵循一阶自回归过程</p><p id="7910" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">et = pet-1+ nt</p><p id="82dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中nt是随机的，p是残差的一阶自相关系数。如果检验的是残差的正自相关，那么D-W检验的假设可以写成H0: p = 0对H1: p &gt; 0</p><p id="c5a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">D-W统计量由D =σ(ei—ei-1)2/σei2给出</p><p id="bcb5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可以看出，如果残差遵循一阶自回归过程，则d与一阶自相关系数p相关，因为d = 2 (1 — p)。</p><p id="eed9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上述等式意味着</p><p id="e8b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果没有自相关(p = 0 ), d = 2</p><p id="5b2b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果一阶自相关为1，d = 0</p><p id="10e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果一阶自相关为-1，d = 4</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h1 id="a4df" class="kr ks hh bd kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">参考</h1><h1 id="9e45" class="kr ks hh bd kt ku lp kw kx ky lq la lb lc lr le lf lg ls li lj lk lt lm ln lo bi translated">学术文献</h1><ul class=""><li id="5e54" class="jv jw hh ig b ih lu il lv ip lw it lx ix ly jb lz kb kc kd bi translated">[博什纳科夫，2011年] G .博什纳科夫。<a class="ae ma" href="http://www.maths.manchester.ac.uk/~goran/research-reports/psrr03-2009.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mb">关于随机系数模型的一阶和二阶平稳性</em> </a>。线性代数应用434，415–423。2011.</li><li id="0f16" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb lz kb kc kd bi translated">[Breitung，2002年]<a class="ae ma" href="https://pdfs.semanticscholar.org/e31b/c65824cc156d43d25b6ece0e9613b398233d.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mb">单位根与协整的非参数检验。</em> </a>《计量经济学杂志》，108卷2期，第343–363页。</li><li id="2fb0" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb lz kb kc kd bi translated">[达尔豪斯，2012年]达尔豪斯河(2012年)局部平稳过程。在<em class="mb">统计手册</em>(第30卷，第351-413页)中。爱思唯尔。</li><li id="e6fa" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb lz kb kc kd bi translated">【Nason，2006】<a class="ae ma" href="https://research-information.bristol.ac.uk/en/persons/guy-p-nason(c22adede-c5fc-4692-9b91-24afa15868b6).html" rel="noopener ugc nofollow" target="_blank">Nason，GP </a> 2006，<a class="ae ma" href="https://research-information.bristol.ac.uk/en/publications/stationary-and-nonstationary-time-series(c0005c54-b407-414e-944c-92fca5df2a2b).html" rel="noopener ugc nofollow" target="_blank">平稳与非平稳时间序列</a>。在H Mader &amp; SC Coles(编)<em class="mb">火山学中的统计学。</em>地质学会，第129–142页。</li><li id="6543" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb lz kb kc kd bi translated">[Vogt，2012年] Vogt，M. (2012年)。局部平稳时间序列的非参数回归。<em class="mb">统计年鉴</em>，<em class="mb"> 40 </em> (5)，2601–2633。</li><li id="67bb" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb lz kb kc kd bi translated">古吉拉特语，基本计量经济学，第5版，塔塔麦格劳-希尔</li><li id="03e1" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb lz kb kc kd bi translated">使用SPSS发现统计数据，第二版，Sage出版物</li><li id="72de" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb lz kb kc kd bi translated">Hair，j .，Anderson，r .，巴宾，b.《多元数据分析》,第7版，普伦蒂斯霍尔</li><li id="5b3b" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb lz kb kc kd bi translated">n . k . malhotra，Dash，s,《营销研究:应用导向》,第5版，培生教育</li><li id="f0b6" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb lz kb kc kd bi translated">Rud，O. P,《数据挖掘食谱:营销、风险和客户关系管理的建模数据》, John Wiley &amp; Sons，2000年</li></ul></div></div>    
</body>
</html>