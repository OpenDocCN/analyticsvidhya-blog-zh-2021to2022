<html>
<head>
<title>Akira’s Machine Learning news — #issue 29</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Akira的机器学习新闻—#第29期</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/akiras-machine-learning-news-issue-29-dab82a5b3cb7?source=collection_archive---------13-----------------------#2021-09-21">https://medium.com/analytics-vidhya/akiras-machine-learning-news-issue-29-dab82a5b3cb7?source=collection_archive---------13-----------------------#2021-09-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h2 id="aaa7" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">本周特稿/新闻。</h2><ul class=""><li id="93fb" class="jj jk hh jl b jm jn jo jp iw jq ja jr je js jt ju jv jw jx bi translated"><a class="ae jy" href="https://www.ravirajag.dev/blog/mlops-project-setup-part1" rel="noopener ugc nofollow" target="_blank">关于Pytorch Lightning的MLOps系列文章</a>现已发布。它涵盖了很多东西，从使用W &amp; B的模型到使用GitHub动作的CI/CD。</li><li id="8e01" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ju jv jw jx bi translated">Google Research在<a class="ae jy" href="https://arxiv.org/abs/2107.12283" rel="noopener ugc nofollow" target="_blank">发表了一篇论文</a>，描述了他们在非洲大陆的建筑分割任务的方法和细节。这是一个很好的实例，对工程有很大的帮助。</li></ul><p id="e799" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><p id="cb8c" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">在下面的章节中，我将介绍各种文章和论文，不仅仅是关于上述内容，还包括以下五个主题。</p><ol class=""><li id="e396" class="jj jk hh jl b jm kg jo kj iw kv ja kw je kx jt ky jv jw jx bi translated">本周特稿/新闻</li><li id="bd64" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">机器学习用例</li><li id="b9e6" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">报纸</li><li id="2318" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">机器学习技术相关文章</li><li id="36f1" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">其他主题</li></ol><p id="a17d" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="9870" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">1.本周特稿/新闻</h1><p id="3221" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://www.ravirajag.dev/blog/mlops-project-setup-part1?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">练习MLOps</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://www.ravirajag.dev/blog/mlops-project-setup-part1" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">www . ravi rajag . dev</strong></a></p><div class="lt lu ez fb lv lw"><a href="https://www.ravirajag.dev/blog/mlops-project-setup-part1?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">MLOps基础[第0周]:项目设置</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">本系列的目标是了解MLOps的基础知识(模型构建、监控、配置、测试……</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">www.ravirajag.dev</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk ml lw"/></div></div></a></div><p id="9313" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">本文涵盖了使用PyTorch lightning的MLOps、使用W&amp;B的可视化、使用Hydra的参数管理以及使用Github-Actions的CI/CD的实践。</p><p id="41c2" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2107.12283?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2107.12283" rel="noopener ugc nofollow" target="_blank">【arxiv.org】T21</a></p><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="ab fe cl mr"><img src="../Images/47ba8be16643b75e75d61d4ae2f52930.png" data-original-src="https://miro.medium.com/v2/0*eRnEcBuMVb3S-nF3"/></div></figure><p id="0b38" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2107.12283]通过高分辨率卫星图像进行大陆规模的建筑物检测<br/>本文描述了谷歌研究的非洲大陆建筑物检测分割任务的详细方法。此外，该论文描述了各种有价值的技术，例如使用骰子损失和混合、自学(嘈杂的学生)以使用未标记的数据，以及针对建筑物中容易出错的间隙调整损失权重。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="f99d" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="522d" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">2.机器学习用例</h1><p id="06a0" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://www.theregister.com/2021/09/13/ai_environmental_cost/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">对机器学习建模的影响</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://www.theregister.com/2021/09/13/ai_environmental_cost/" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">www.theregister.com</strong></a></p><div class="lt lu ez fb lv lw"><a href="https://www.theregister.com/2021/09/13/ai_environmental_cost/" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">AI caramba，那些神经网络是耗电的:计算人工…</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">下次你让Alexa关掉你卧室的灯或者让电脑写危险代码的时候，省下一点时间…</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">www.theregister.com</p></div></div><div class="mf l"><div class="mt l mh mi mj mf mk ml lw"/></div></div></a></div><p id="6f21" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">本文描述了对机器学习模型环境的影响。机器学习模型消耗大量的电力，今天的模型消耗更多的电力来使用许多参数和数据提高百分之几。作为对此的对策，它提到了边缘设备和模型简化。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="f4e1" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="4382" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">3.报纸</h1><p id="26be" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2106.14448?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">正规化的辍学网络结果向更近的</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2106.14448" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="mm mn mo mp fd mq er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es mu"><img src="../Images/752790d4dcadb96abde79e756198971d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6uIwK1wtquo7nImVTrqNPw.png"/></div></div></figure><p id="dc9c" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">【2106.14448】R-Drop:神经网络的正则化漏失<br/>作者提出了一种正则化R-Drop，该正则化R-Drop使漏失网络的两个前向传播的结果分布更加接近。它可以通过简单地增加两个输出之间的KL距离的损失来容易地实现，并且在NLP和CV中的所有18个任务中实现增加的精度，并且在几个任务中实现SotA性能。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="f7ab" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">【arxiv.org】<strong class="jl hi">减少训练数据</strong><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2107.07075" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a></p><figure class="mm mn mo mp fd mq er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es mz"><img src="../Images/e81deade3b5056efd5707cdda299dea6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Fx91lXD4FsHER4B9HzLyA.png"/></div></div></figure><p id="4cfe" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">【2107.07075】数据饮食上的深度学习:在训练早期发现重要的例子<br/>利用置信度和标签的差异(EL2N分数)进行数据约简的研究。根据训练开始时(几个历元)的EL2N分数，可以减少训练所需的数据。50%的缩减并没有降低准确率，并且有可能处理嘈杂的标签问题。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="9719" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2107.08430?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">最新版YOLO系列</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2107.08430" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="mm mn mo mp fd mq er es paragraph-image"><div class="ab fe cl mr"><img src="../Images/d45d01d518b4f35736a8417ff99b16c0.png" data-original-src="https://miro.medium.com/v2/0*Btc4whgcv9M4GDkH"/></div></figure><p id="7b99" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">【YOLOX:2021年超越YOLO系列】<br/>作者提出了YOLO的改良版YOLOX。它使用无锚点、解耦头、马赛克增强和一种新的标签分配策略。它比传统的目标检测模型更快更准确。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="cb84" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2006.07502?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">弥合弱监督和少镜头算法之间的鸿沟。</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2006.07502" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="mm mn mo mp fd mq er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es na"><img src="../Images/e077ac227da43b536de6ed79f3c39860.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lFQrcsUqLtDTop-7iqcBcw.png"/></div></div></figure><p id="5a00" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2006.07502] UniT:用于任意镜头对象检测和分割的统一知识转移<br/>在新类别具有大量图像数据但很少注释的设置中，作者提出了一种称为UniT的算法，该算法使用了少量镜头和弱监督学习。它通过从弱监督信号到具有现有类别的完全监督信号的学习来适应少数镜头。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="e91e" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2108.05895?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">结合变压器与MobileNet</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2108.05895" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="mm mn mo mp fd mq er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nb"><img src="../Images/f0e7f0b5036bb9fe2a270d9d38f16d71.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1zsJSEDLQpN9sN_f3jxB-Q.png"/></div></div></figure><p id="8aa1" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2108.05895]移动模型:桥接MobileNet和Transformer <br/>作者开发了一种轻量级网络移动模型，它通过双向耦合连接MobileNet和Transformer来处理本地和全局信息。这个结果比以前的研究更准确、更轻便。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="5594" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PointAugmenting_Cross-Modal_Augmentation_for_3D_Object_Detection_CVPR_2021_paper.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">一种利用图像和点云的三维物体检测方法</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PointAugmenting_Cross-Modal_Augmentation_for_3D_Object_Detection_CVPR_2021_paper.html" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">openaccess.thecvf.com</strong></a></p><figure class="mm mn mo mp fd mq er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nc"><img src="../Images/6abf4dbf0b383f5cd7cc35920fcb16be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MytmWz8qlDfCvdxnrkK_Iw.png"/></div></div></figure><p id="626d" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">【点增强:用于3D对象检测的跨模态增强】<br/>本文提出了点增强，一种使用图像和点云的3D对象检测方法。在处理两种数据的情况下，激光雷达数据和影像之间存在不匹配。为了解决这个问题，作者提出了一种新的数据增强方法来复制和粘贴激光雷达和图像，同时保持透视一致性。使用大型nuScenes和Waymo数据集，他们展示了除激光雷达外使用图像的有效性以及数据增强的有效性。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="facb" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://openaccess.thecvf.com/content/CVPR2021/html/Fang_LiDAR-Aug_A_General_Rendering-Based_Augmentation_Framework_for_3D_Object_Detection_CVPR_2021_paper.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">激光雷达点云数据的数据增强方法</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://openaccess.thecvf.com/content/CVPR2021/html/Fang_LiDAR-Aug_A_General_Rendering-Based_Augmentation_Framework_for_3D_Object_Detection_CVPR_2021_paper.html" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">openaccess.thecvf.com</strong></a></p><figure class="mm mn mo mp fd mq er es paragraph-image"><div role="button" tabindex="0" class="mv mw di mx bf my"><div class="er es nd"><img src="../Images/d7d784242cbf9e4cbcaa1a4d45061bb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MeEZwa_Z9_YwenWO7oDgVg.png"/></div></div></figure><p id="1e0f" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">【LiDAR-Aug:一个通用的基于渲染的三维物体检测增强框架】<br/>提出了一种激光雷达点云数据的数据增强方法。为了使数据与实际的激光雷达点云相同，他们通过随机放置对象来扩展点云数据，同时考虑到位置(ValidMAP)和激光的阻挡。KITTI数据集证实了这一效果。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="7ed3" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="0b6a" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">4.机器学习技术相关文章</h1><p id="e963" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://thegradient.pub/has-ai-found-a-new-foundation/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">庞大预学习模型的问题</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://thegradient.pub/has-ai-found-a-new-foundation/" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">the gradient . pub</strong></a></p><div class="lt lu ez fb lv lw"><a href="https://thegradient.pub/has-ai-found-a-new-foundation/" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">AI找到新的基础了吗？</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">8月，斯坦福大学的32名教师和117名研究科学家、博士后和学生</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">thegradient.pub</p></div></div><div class="mf l"><div class="ne l mh mi mj mf mk ml lw"/></div></div></a></div><p id="88df" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">一篇文章讨论了可用于一般目的的大量预训练模型(基础模型)的问题，如GPT-3。文章讨论了庞大的语言模型只会鹦鹉学舌，甚至不懂“不是”的意思。大多数商业模型不是基于大量的预训练模型。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h2 id="d067" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated"><a class="ae jy" href="https://physicsbaseddeeplearning.org/diffphys.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">用于物理模拟的深度学习</a></h2><p id="f0b8" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://physicsbaseddeeplearning.org/diffphys.html" rel="noopener ugc nofollow" target="_blank">physicsbaseddeeplearning.org</a></p><div class="lt lu ez fb lv lw"><a href="https://physicsbaseddeeplearning.org/diffphys.html" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">基于物理的深度学习</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">作为走向深度学习方法和物理模拟的更紧密和更通用的结合的下一步，我们将…</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">physicsbaseddeeplearning.org</p></div></div><div class="mf l"><div class="nf l mh mi mj mf mk ml lw"/></div></div></a></div><p id="66ed" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">这是一本利用深度学习进行物理模拟的书(免费查看)。它用代码解释。它涵盖了物理学x深度学习的最新主题，包括可微分流体模拟。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="2331" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="5c3f" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">5.其他主题</h1><p id="d72e" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://scikit-learn.org/dev/whats_new/v1.0.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">【scikit】学达1.0.0版本</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://scikit-learn.org/dev/whats_new/v1.0.html" rel="noopener ugc nofollow" target="_blank">【scikit-learn.org】</a></p><p id="747f" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://scikit-learn.org/dev/whats_new/v1.0.html" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/dev/whats_new/v1.0.html</a></p><p id="81eb" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="e171" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">🌟我每周发布时事通讯！请订阅！🌟</h1><div class="lt lu ez fb lv lw"><a href="https://www.getrevue.co/profile/akiratosei" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">阿基拉的机器学习新闻- Revue</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">由Akira的机器学习新闻-由Akihiro FUJII:制造工程师/机器学习工程师/硕士…</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">www.getrevue.co</p></div></div><div class="mf l"><div class="ng l mh mi mj mf mk ml lw"/></div></div></a></div><p id="8c32" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="f0e9" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">其他博客</h1><div class="lt lu ez fb lv lw"><a href="https://towardsdatascience.com/machine-learning-2020-summary-84-interesting-papers-articles-45bd45c0d35b" rel="noopener follow" target="_blank"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">机器学习2020摘要:84篇有趣的论文/文章</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">在这篇文章中，我总共展示了2020年发表的84篇我觉得特别有趣的论文和文章…</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">towardsdatascience.com</p></div></div><div class="mf l"><div class="nh l mh mi mj mf mk ml lw"/></div></div></a></div><div class="lt lu ez fb lv lw"><a href="https://towardsdatascience.com/recent-developments-and-views-on-computer-vision-x-transformer-ed32a2c72654" rel="noopener follow" target="_blank"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">计算机视觉x变形金刚的最新发展和看法</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">《变形金刚》和CNN的区别，为什么《变形金刚》很重要，它的弱点是什么。</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">towardsdatascience.com</p></div></div><div class="mf l"><div class="ni l mh mi mj mf mk ml lw"/></div></div></a></div><div class="lt lu ez fb lv lw"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/reach-and-limits-of-the-supermassive-model-gpt-3-5012a6ddff00"><div class="lx ab dw"><div class="ly ab lz cl cj ma"><h2 class="bd hi fi z dy mb ea eb mc ed ef hg bi translated">超大质量模型GPT-3的到达和极限</h2><div class="md l"><h3 class="bd b fi z dy mb ea eb mc ed ef dx translated">在这篇博文中，我将从技术上解释GPT 3号，GPT 3号取得了什么，GPT 3号没有取得什么…</h3></div><div class="me l"><p class="bd b fp z dy mb ea eb mc ed ef dx translated">medium.com</p></div></div><div class="mf l"><div class="nj l mh mi mj mf mk ml lw"/></div></div></a></div><p id="741e" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — —</p><h1 id="0615" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">关于我</h1><p id="aca8" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated">制造工程师/机器学习工程师/数据科学家/物理学硕士/<a class="ae jy" href="https://t.co/hjHHbG24Ph?amp=1" rel="noopener ugc nofollow" target="_blank">http://github.com/AkiraTOSEI/</a></p><p id="c51c" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">推特，我贴一句纸评论。</p></div></div>    
</body>
</html>