<html>
<head>
<title>Optimising Spark jobs with DataFrame Caching</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用数据帧缓存优化Spark作业</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/optimising-spark-jobs-with-dataframe-caching-be377b367fb8?source=collection_archive---------13-----------------------#2021-01-30">https://medium.com/analytics-vidhya/optimising-spark-jobs-with-dataframe-caching-be377b367fb8?source=collection_archive---------13-----------------------#2021-01-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/29c61b0f100920e48c40ecf7801062dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*flvc0p9LwpPO48_i.png"/></div></figure><p id="a2df" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">Apache Spark是一个广泛用于执行大数据分析和处理的框架。事实证明，它在吸收和处理大量数据方面非常有用。当处理如此庞大的数据集时，优化任务以确保效率是必不可少的。</p><p id="057a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这篇文章中，我将谈论我们如何优化我们在MiQ Digital的一项Spark工作。</p><p id="aef0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们考虑一个示例作业，它通过基于自定义逻辑对数据集的某些字段进行哈希运算来屏蔽这些字段。为了确保处理过的数据是有效的，需要对数据进行一些完整性检查:</p><ul class=""><li id="d0cc" class="jk jl hh in b io ip is it iw jm ja jn je jo ji jp jq jr js bi translated">原始数据和已处理数据的行数应该匹配</li><li id="bf49" class="jk jl hh in b io jt is ju iw jv ja jw je jx ji jp jq jr js bi translated">处理后，哈希字段的不同计数应该保持不变</li></ul><p id="561a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">考虑下面执行上述健全性检查的示例代码片段。</p><figure class="jy jz ka kb fd ii"><div class="bz dy l di"><div class="kc kd l"/></div></figure><p id="dc32" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">健全性测试是在2 TB的原始数据上执行的。下面给出了提交的每个作业所用的时间:</p><figure class="jy jz ka kb fd ii er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es ke"><img src="../Images/8a04cc9aace26bb19f21799d57d2e4b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*B_1o4hIgDtXTmh6u"/></div></div><figcaption class="kj kk et er es kl km bd b be z dx translated">不缓存花费的时间</figcaption></figure><p id="7272" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">作业Id 0和1指的是寻找整个数据帧的实际计数，而其余的对应于寻找不同字段的不同计数。<strong class="in hi"> <em class="kn">仅仅是健全性检查所花费的总时间就在24分钟左右！</em> </strong></p><p id="2185" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在上面的过程中，由于同一个数据帧被多次使用，Spark将为每个执行的计数操作重新计算数据帧。为了处理这样的场景，<strong class="in hi"> Spark提供了数据帧</strong>的<em class="kn">缓存</em>。</p><p id="96c5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">Spark提供了方法<em class="kn"> cache() </em>和<em class="kn"> persist() </em>来将您的数据持久化到不同的存储级别。</p><p id="2387" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">默认情况下，<em class="kn"> cache() </em>方法将在内存中缓存数据，但是使用<em class="kn"> persist() </em>可以指定想要缓存数据的存储级别。参考Spark提供的存储级别列表来缓存您的数据:<a class="ae jj" href="https://spark.apache.org/docs/2.4.3/rdd-programming-guide.html#which-storage-level-to-choose" rel="noopener ugc nofollow" target="_blank"> Spark存储级别</a>。</p><p id="f668" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们可以通过在执行计数检查之前缓存数据帧来优化我们的工作。我们可以通过以下方式将数据帧保存在<em class="kn">内存和磁盘</em>存储级别:</p><figure class="jy jz ka kb fd ii"><div class="bz dy l di"><div class="kc kd l"/></div></figure><p id="358d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">下面给出了保存数据帧后作业所用的时间。</p><figure class="jy jz ka kb fd ii er es paragraph-image"><div role="button" tabindex="0" class="kf kg di kh bf ki"><div class="er es ke"><img src="../Images/610257d5029afd28c5eac1afab1a404e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*chiU2oDw73DnKIMz"/></div></div><figcaption class="kj kk et er es kl km bd b be z dx translated">缓存后花费的时间</figcaption></figure><figure class="jy jz ka kb fd ii er es paragraph-image"><div class="er es ko"><img src="../Images/8e2943a66f227da1d464d74aec19ef21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*mLOgRex7WDgP0GQYN8WnGg.png"/></div><figcaption class="kj kk et er es kl km bd b be z dx translated">缓存前后作业所用时间的比较</figcaption></figure><p id="098d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">可以看到，作业0和1在缓存后花费的时间稍长，因为这是数据帧缓存的时间。然而，随后的操作在性能上有了相当大的提高，并且该作业需要大约13分钟才能完成，这大约是之前时间的一半！</p><h1 id="d8b4" class="kp kq hh bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">结论</h1><p id="ff65" class="pw-post-body-paragraph il im hh in b io ln iq ir is lo iu iv iw lp iy iz ja lq jc jd je lr jg jh ji ha bi translated">缓存重复使用且计算成本高昂的数据集可以显著提高作业的性能。根据数据集的大小、操作的复杂程度和可用内存，可以选择不同的存储级别来保存数据。</p></div></div>    
</body>
</html>