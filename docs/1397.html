<html>
<head>
<title>Targeted OCR on documents with OpenCV and PyTesseract</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用OpenCV和PyTesseract对文档进行目标OCR</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/targeted-ocr-on-documents-with-opencv-and-pytesseract-edc10b5ecb62?source=collection_archive---------1-----------------------#2021-02-28">https://medium.com/analytics-vidhya/targeted-ocr-on-documents-with-opencv-and-pytesseract-edc10b5ecb62?source=collection_archive---------1-----------------------#2021-02-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/a82704adf5d3e056ce7e9e8a0412d08c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HK2fvdGgqKCnpYqm"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">马库斯·温克勒在<a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="8caa" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">由于各地的组织都希望将他们的运营数字化，将物理文档转换为数字格式是一个常见的唾手可得的事情。这通常是通过光学字符识别(OCR)完成的，其中文本图像(扫描的物理文档)通过几种成熟的文本识别算法之一被转换成机器文本。在清晰的背景下处理打印文本时，文档OCR表现最佳，段落和字体大小一致。</p><p id="c532" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">实际上，这种情况远非常态。发票、表格甚至身份证件都有分散在整个文档空间的信息，这使得以数字方式提取相关数据的任务变得更加复杂。</p><p id="98b8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在本文中，我们将探索一种使用Python来定义文档图像中用于OCR的区域的简单方法。我们将使用一个信息分散在整个文档空间的文档示例—护照。下面的护照样本放在白色背景中，模拟护照复印件。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es js"><img src="../Images/f8687537755d0b458b46a18a74405c42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d877mZRbX__S33Ba7SbeeA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">公共领域的护照图片样本:<a class="ae it" href="https://commons.wikimedia.org/wiki/File:People%27s_Republic_of_China_Passport_(97-2_version_for_Single_Exit_and_Entry).png" rel="noopener ugc nofollow" target="_blank">维基媒体</a> &amp; <a class="ae it" href="https://www.nia.gov.cn/n741445/n741629/c763428/content.html" rel="noopener ugc nofollow" target="_blank">国家移民局</a></figcaption></figure><p id="020a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从这个passport映像中，我们希望获得以下字段:</p><ul class=""><li id="5236" class="jx jy hh iw b ix iy jb jc jf jz jj ka jn kb jr kc kd ke kf bi translated">名/名</li><li id="27e9" class="jx jy hh iw b ix kg jb kh jf ki jj kj jn kk jr kc kd ke kf bi translated">姓氏</li><li id="3bee" class="jx jy hh iw b ix kg jb kh jf ki jj kj jn kk jr kc kd ke kf bi translated">中文脚本中的名/名</li><li id="3957" class="jx jy hh iw b ix kg jb kh jf ki jj kj jn kk jr kc kd ke kf bi translated">中文书写的姓氏</li><li id="8311" class="jx jy hh iw b ix kg jb kh jf ki jj kj jn kk jr kc kd ke kf bi translated">护照号码</li></ul><p id="f5f7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，我们将导入所有必需的包。最重要的包是用于计算机视觉操作的<a class="ae it" href="https://docs.opencv.org/master/d6/d00/tutorial_py_root.html" rel="noopener ugc nofollow" target="_blank"> OpenCV </a>和用于强大的Tesseract OCR引擎的python包装器<a class="ae it" href="https://pypi.org/project/pytesseract/" rel="noopener ugc nofollow" target="_blank"> PyTesseract </a>。各个文档页面提供了安装和配置这些库的详细说明。</p><pre class="jt ju jv jw fd kl km kn ko aw kp bi"><span id="007a" class="kq kr hh km b fi ks kt l ku kv">from cv2 import cv2<br/>import pytesseract<br/>import pandas as pd<br/>import numpy as np<br/>import math<br/>from matplotlib import pyplot as plt</span></pre><p id="6716" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">接下来，我们将使用cv2.imread读取我们的护照图像。我们的第一个任务是从这个伪扫描页面中提取实际的护照文档区域。我们将通过检测护照的边缘并将其从图像中裁剪出来来实现这一点。</p><pre class="jt ju jv jw fd kl km kn ko aw kp bi"><span id="8236" class="kq kr hh km b fi ks kt l ku kv">img = cv2.imread('images\Passport.png',0)</span><span id="71b6" class="kq kr hh km b fi kw kt l ku kv">img_copy = img.copy()<br/>img_canny = cv2.Canny(img_copy, 50, 100, apertureSize = 3)</span></pre><p id="0b44" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">OpenCV库中包含的<a class="ae it" href="https://docs.opencv.org/master/da/d22/tutorial_py_canny.html" rel="noopener ugc nofollow" target="_blank"> Canny算法</a>使用多阶段过程来检测我们图像中的边缘。最后使用的三个参数是较低阈值和较高阈值(分别为minVal和maxVal)以及内核大小。</p><p id="983b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">运行Canny算法会产生以下输出。注意，由于选择了低阈值，保留了最小的边缘。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es kx"><img src="../Images/12b70bffeeb4f2ca9ec92e8c94b62533.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*fvvisTkLwcRs2MXmUokavA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">应用Canny算法操作后的图像</figcaption></figure><pre class="jt ju jv jw fd kl km kn ko aw kp bi"><span id="0ed7" class="kq kr hh km b fi ks kt l ku kv">img_hough = cv2.HoughLinesP(img_canny, 1, math.pi / 180, 100, minLineLength = 100, maxLineGap = 10)</span></pre><p id="658f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">接下来，我们在边缘检测图像上使用另一种叫做<a class="ae it" href="https://docs.opencv.org/3.4/d6/d10/tutorial_py_houghlines.html" rel="noopener ugc nofollow" target="_blank">霍夫变换</a>的算法，通过检测线绘制出护照区域的形状。minLineLength参数定义了一个形状必须包含多少像素才能被认为是一条“线”，maxLineGap参数表示被认为是同一形状的像素序列中的最大允许间隙。</p><pre class="jt ju jv jw fd kl km kn ko aw kp bi"><span id="9b4f" class="kq kr hh km b fi ks kt l ku kv">(x, y, w, h) = (np.amin(img_hough, axis = 0)[0,0], np.amin(img_hough, axis = 0)[0,1], np.amax(img_hough, axis = 0)[0,0] - np.amin(img_hough, axis = 0)[0,0], np.amax(img_hough, axis = 0)[0,1] - np.amin(img_hough, axis = 0)[0,1])</span><span id="009b" class="kq kr hh km b fi kw kt l ku kv">img_roi = img_copy[y:y+h,x:x+w]</span></pre><p id="e67b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们的护照在所有的边上都有直线——文件的边缘。因此，有了我们的线信息，我们可以选择通过检测到的线的外边缘来裁剪我们的护照区域:</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es ky"><img src="../Images/93ebf875afc3da9fdc1d1d4da41eb388.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*4yDv60X1G4Wkwbw5DbgckQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">使用检测到的线性边缘裁剪图像</figcaption></figure><p id="9157" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后，我们可以做一些好的ol' OCR！</p><p id="fd51" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">将护照垂直旋转后，我们开始在图像中选择想要捕捉数据的区域。几乎所有的国际护照都符合国际民航组织的标准，该标准概述了护照页面的设计和布局规范。这些规格之一是机器可读区(MRZ)，即你的护照文件底部有趣的两行。文件目视检查区(VIZ)中的大部分关键信息也包含在MRZ中，可由机器读取。在我们的练习中，这台机器是我们信赖的宇宙魔方引擎。</p><pre class="jt ju jv jw fd kl km kn ko aw kp bi"><span id="4841" class="kq kr hh km b fi ks kt l ku kv">img_roi = cv2.rotate(img_roi, cv2.ROTATE_90_COUNTERCLOCKWISE)</span><span id="9cc9" class="kq kr hh km b fi kw kt l ku kv">(height, width) = img_roi.shape<br/>img_roi_copy = img_roi.copy()</span><span id="5494" class="kq kr hh km b fi kw kt l ku kv">dim_mrz = (x, y, w, h) = (1, round(height*0.9), width-3, round(height-(height*0.9))-2)</span><span id="6204" class="kq kr hh km b fi kw kt l ku kv">img_roi_copy = cv2.rectangle(img_roi_copy, (x, y), (x + w ,y + h),(0,0,0),2)</span></pre><p id="1e12" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们使用四个维度来定义护照图像中的MRZ区域:水平偏移(从左侧)、垂直偏移(从顶部)、宽度和高度。对于MRZ，我们将假设它包含在我们护照底部的10%中。因此，使用OpenCV的矩形函数，我们可以在区域周围画一个方框来验证我们的维度选择。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es kz"><img src="../Images/020e615c244eaa52093bf18a493d2b61.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*sCoZs8S0sAhuoIy3F3ayFQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">选择区域周围有矩形框的图像</figcaption></figure><pre class="jt ju jv jw fd kl km kn ko aw kp bi"><span id="4c8f" class="kq kr hh km b fi ks kt l ku kv">img_mrz = img_roi[y:y+h, x:x+w]</span><span id="df1c" class="kq kr hh km b fi kw kt l ku kv">img_mrz =cv2.GaussianBlur(img_mrz, (3,3), 0)<br/>ret, img_mrz = cv2.threshold(img_mrz,127,255,cv2.THRESH_TOZERO)</span></pre><p id="aa3d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在新图像中裁剪出所选区域。我们将对裁剪后的图像执行一些基本的图像预处理，以便于更好地读出— <a class="ae it" href="https://docs.opencv.org/master/d4/d13/tutorial_py_filtering.html" rel="noopener ugc nofollow" target="_blank">高斯模糊</a>和<a class="ae it" href="https://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html" rel="noopener ugc nofollow" target="_blank">简单阈值处理</a>。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es la"><img src="../Images/1c4195877197d87e8ca29a2c62c80ee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wwa8pTtOnN4z4zeB8FfETg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">提取的MRZ区域</figcaption></figure><pre class="jt ju jv jw fd kl km kn ko aw kp bi"><span id="6384" class="kq kr hh km b fi ks kt l ku kv">mrz = pytesseract.image_to_string(img_mrz, config = '--psm 12')</span></pre><p id="a15b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们现在准备应用OCR处理。在我们的image_to_string属性中，我们配置了一个“带有方向和脚本检测(OSD)的稀疏文本”的页面分割方法。这旨在捕获图像中所有可用的文本。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es lb"><img src="../Images/e45c28b52f6ebcce4505b8cc1ac95165.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*lKs5WY9nrZJVhtXkCWsLqg.png"/></div></figure><p id="895f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">将Pytesseract输出与我们的原始passport图像进行比较，我们可以观察到在读取特殊字符时的一些错误。为了获得更准确的读数，可以使用Pytesseract的白名单配置进行优化；然而，就我们的目的而言，电流读数的精度已经足够。</p><pre class="jt ju jv jw fd kl km kn ko aw kp bi"><span id="e09b" class="kq kr hh km b fi ks kt l ku kv">mrz = [line for line in mrz.split('\n') if len(line)&gt;10]</span><span id="8025" class="kq kr hh km b fi kw kt l ku kv">if mrz[0][0:2] == 'P&lt;':<br/>  lastname = mrz[0].split('&lt;')[1][3:]<br/>else:<br/>  lastname = mrz[0].split('&lt;')[0][5:]</span><span id="2c4f" class="kq kr hh km b fi kw kt l ku kv">firstname = [i for i in mrz[0].split('&lt;') if (i).isspace() == 0 and len(i) &gt; 0][1]</span><span id="e189" class="kq kr hh km b fi kw kt l ku kv">pp_no = mrz[1][:9]</span></pre><p id="b95d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">根据ICAO关于MRZ代码结构的指南应用一些字符串操作，我们可以提取护照持有人的姓、名和护照号:</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es lc"><img src="../Images/3ae8fc4f8ff861b6816a8293c1abfd4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/1*vKGd4lY2E_BcGOGajYd1eA.png"/></div></figure><p id="c7bf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">非英语的文本怎么办？没问题Tesseract引擎已经为超过100种语言的<a class="ae it" href="https://github.com/tesseract-ocr/langdata" rel="noopener ugc nofollow" target="_blank">训练了模型</a>(尽管OCR性能的健壮性因每种支持的语言而异)。</p><pre class="jt ju jv jw fd kl km kn ko aw kp bi"><span id="6812" class="kq kr hh km b fi ks kt l ku kv">img_roi_copy = img_roi.copy()</span><span id="b0af" class="kq kr hh km b fi kw kt l ku kv">dim_lastname_chi = (x, y, w, h) = (455, 1210, 120, 70)<br/>img_lastname_chi = img_roi[y:y+h, x:x+w]<br/>img_lastname_chi = cv2.GaussianBlur(img_lastname_chi, (3,3), 0)<br/>ret, img_lastname_chi = cv2.threshold(img_lastname_chi,127,255,cv2.THRESH_TOZERO)</span><span id="7640" class="kq kr hh km b fi kw kt l ku kv">dim_firstname_chi = (x, y, w, h) = (455, 1300, 120, 70)<br/>img_firstname_chi = img_roi[y:y+h, x:x+w]<br/>img_firstname_chi = cv2.GaussianBlur(img_firstname_chi, (3,3), 0)<br/>ret, img_firstname_chi = cv2.threshold(img_firstname_chi,127,255,cv2.THRESH_TOZERO)</span></pre><p id="e1af" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用相同的区域选择方法，我们再次为我们的目标数据场定义维度(x，y，w，h ),并对裁剪的图像提取应用模糊和阈值处理。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es ld"><img src="../Images/0de8855a3ffbca83585010c8b81547c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:882/format:webp/1*TDTlNTAspXtkP5DwJTYW3g.png"/></div></figure><pre class="jt ju jv jw fd kl km kn ko aw kp bi"><span id="1432" class="kq kr hh km b fi ks kt l ku kv">lastname_chi = pytesseract.image_to_string(img_lastname_chi, lang = 'chi_sim', config = '--psm 7')</span><span id="4900" class="kq kr hh km b fi kw kt l ku kv">firstname_chi = pytesseract.image_to_string(img_firstname_chi, lang = 'chi_sim', config = '--psm 7')</span></pre><p id="2670" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，在我们的image_to_string参数中，我们将添加输入文本的语言脚本，简体中文。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es le"><img src="../Images/26027945c40e66211a94499f6b3a7586.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*dtG7JdwC3bBDHa5iC4DgYA.png"/></div></figure><p id="21cf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了完成练习，将所有收集到的字段传递给字典，并输出到表格中以供实际使用。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lf"><img src="../Images/0cf653294590379e31ddfeae697ceaf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1-nRs6EdOonaeiVhK2vjBQ.png"/></div></div></figure><p id="a8ab" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">OCR感兴趣区域的显式定义只是在OCR中获取所需数据的众多方法之一。根据您的使用情况，使用轮廓分析或对象检测等其他方法可能是最有效的。</p><p id="8f21" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如我们的护照练习所示，在应用OCR之前对图像进行适当的预处理是关键。当处理不同(有时有问题)图像质量的真实文档时，尝试不同的预处理技术以找到最适合您的文档类型的组合是值得的。玩得开心！</p><p id="7424" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="lg">这个用例可以在GitHub资源库</em> <a class="ae it" href="https://github.com/jasonlimcp/document_ocr" rel="noopener ugc nofollow" target="_blank"> <em class="lg">这里</em> </a> <em class="lg">找到。</em></p></div></div>    
</body>
</html>