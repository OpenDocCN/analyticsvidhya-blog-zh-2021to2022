<html>
<head>
<title>All you need to know about Naive Bayes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于朴素贝叶斯，你只需要知道</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/all-you-need-to-know-about-naive-bayes-1b1681bf6cc9?source=collection_archive---------7-----------------------#2021-01-22">https://medium.com/analytics-vidhya/all-you-need-to-know-about-naive-bayes-1b1681bf6cc9?source=collection_archive---------7-----------------------#2021-01-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="bf6c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇博客中，我将写一些简单、有效且常用的机器学习分类器，也就是朴素贝叶斯。</p><p id="091f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，我将解释什么是朴素贝叶斯，贝叶斯定理及其用途，朴素贝叶斯的数学工作，逐步实现，朴素贝叶斯的应用。此外，我会提供链接到我的jupter笔记本作为参考。</p><p id="bb67" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，没有任何进一步的到期让我们开始。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/2a3bb41d8ea2a54133b73bc9c13c805a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UWzlYUZwX7dyOlUb.jpg"/></div></div></figure><h1 id="7e06" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak">什么是朴素贝叶斯？</strong></h1><p id="2e55" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">它是一种基于贝叶斯定理的分类技术，假设预测因子之间是独立的。简而言之，朴素贝叶斯分类器假设一个类中特定特征的存在与任何其他特征的存在无关。</p><p id="5278" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，如果一个水果是红色的，圆形的，直径约为3英寸，它就可以被认为是苹果。即使这些特征相互依赖或依赖于其他特征的存在，所有这些特性都独立地有助于这个水果是苹果的概率，这就是为什么它被称为“幼稚”。</p><p id="572e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">朴素贝叶斯模型易于构建，对于非常大的数据集尤其有用。除了简单之外，朴素贝叶斯被认为比高度复杂的分类方法更好。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kr"><img src="../Images/4a5ebb849035e7fcc841a0efdf881994.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*lj51AwlQLDjk3rW-.png"/></div></figure><h1 id="5992" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">贝叶斯定理—</h1><p id="d314" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">在统计学和概率论中，贝叶斯定理(也称为贝叶斯规则)是一个数学公式，用于确定事件的条件概率。本质上，贝叶斯定理描述了基于可能与事件相关的条件的先验知识的事件概率。</p><h2 id="dace" class="ks jp hh bd jq kt ku kv ju kw kx ky jy ip kz la kc it lb lc kg ix ld le kk lf bi translated">贝叶斯定理的公式</h2><p id="c462" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">贝叶斯定理用下面的公式表示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lg"><img src="../Images/1d5f61eddcb15071c9ab845f3800770d.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*5gtfyxAQ32q36dEh.png"/></div></figure><p id="9f82" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中:</p><ul class=""><li id="60e2" class="lh li hh ig b ih ii il im ip lj it lk ix ll jb lm ln lo lp bi translated">P(A|B) —事件A发生的概率，假设事件B已经发生</li><li id="2100" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated">P(B|A) —事件B发生的概率，假设事件A已经发生</li><li id="3640" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated">P(A) —事件A的概率</li><li id="9d8f" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated">P(B) —事件B的概率</li></ul><h2 id="4f4f" class="ks jp hh bd jq kt ku kv ju kw kx ky jy ip kz la kc it lb lc kg ix ld le kk lf bi translated">贝叶斯定理的例子</h2><p id="1c8c" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">假设你是一家投资银行的财务分析师。根据你对<a class="ae lv" href="https://corporatefinanceinstitute.com/resources/knowledge/finance/private-vs-public-company/" rel="noopener ugc nofollow" target="_blank">上市公司</a>的研究，在过去三年中股价涨幅超过5%的公司中，有60%在此期间更换了他们的<a class="ae lv" href="https://corporatefinanceinstitute.com/resources/careers/jobs/what-is-a-ceo-chief-executive-officer/" rel="noopener ugc nofollow" target="_blank">首席执行官</a>。</p><p id="e86b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与此同时，同期股价涨幅不超过5%的公司中，只有35%更换了CEO。已知股票价格增长超过5%的概率是4%，求解雇首席执行官的公司股票增长超过5%的概率。</p><p id="e471" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在寻找概率之前，你必须首先定义概率的符号。</p><ul class=""><li id="8ba1" class="lh li hh ig b ih ii il im ip lj it lk ix ll jb lm ln lo lp bi translated">P(A) —股票价格上涨5%的概率</li><li id="439e" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated">P(B) —首席执行官被替换的概率</li><li id="5715" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated">P(A|B) —假设首席执行官已经更换，股票价格上涨5%的概率</li><li id="dd6f" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated">P(B|A) —给定股票价格，更换CEO的概率增加了5%。</li></ul><p id="33ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用贝叶斯定理，我们可以找到所需的概率:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lw"><img src="../Images/25f89628e3cb61944be5ea5a3f4cb938.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*s7Bo8xv-zICDquk7.png"/></div></div></figure><p id="8287" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，更换CEO的公司股票增长超过5%的概率为6.67%。</p><blockquote class="lx"><p id="878a" class="ly lz hh bd ma mb mc md me mf mg jb dx translated">现在我们知道了朴素贝叶斯算法背后的数学，让我们看看算法是如何工作的。</p></blockquote><h1 id="7438" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz mh kb kc kd mi kf kg kh mj kj kk kl bi translated">朴素贝叶斯算法是如何工作的？</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mk"><img src="../Images/69f5bd8a2d0a24a85f61643c957373cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/0*_X8sFNPGcbLhN_us.jpeg"/></div></figure><p id="4733" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们用一个例子来理解一下。下面我有一个天气的训练数据集和相应的目标变量“玩”(建议玩的可能性)。现在，我们需要根据天气情况对球员是否上场进行分类。让我们按照以下步骤来执行它。</p><p id="f541" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">步骤1:将数据集转换成频率表</p><p id="aee1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第二步:通过寻找概率来创建可能性表，比如阴概率= 0.29和玩的概率是0.64。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ml"><img src="../Images/265c0ce577ad58735cf6ba04a2f0547c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*K8_mgVx6Yini7S5Y.png"/></div></div></figure><p id="3cd1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第三步:现在，使用朴素贝叶斯方程计算每一类的后验概率。具有最高后验概率的类是预测的结果。</p><p id="0f6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">问题:</strong>如果天气晴朗，玩家会玩。这种说法正确吗？</p><p id="36e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以使用上面讨论的后验概率方法来解决它。</p><p id="00db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">P(是|晴)= P(晴|是)* P(是)/ P(晴)</p><p id="b510" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里我们有P (Sunny |Yes) = 3/9 = 0.33，P(Sunny) = 5/14 = 0.36，P( Yes)= 9/14 = 0.64</p><p id="8f89" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在P(是|晴)= 0.33 * 0.64 / 0.36 = 0.60，概率较大。</p><p id="9822" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">朴素贝叶斯使用类似的方法来预测基于各种属性的不同类别的概率。该算法主要用于文本分类和多类问题。</p><h1 id="f359" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">朴素贝叶斯的逐步实现</h1><p id="bbea" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">现在，让我们继续我们的朴素贝叶斯博客，并逐一了解所有步骤。我把整个过程分成了以下几个步骤:</p><ul class=""><li id="4622" class="lh li hh ig b ih ii il im ip lj it lk ix ll jb lm ln lo lp bi translated"><strong class="ig hi">处理数据</strong></li><li id="8ebe" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated"><strong class="ig hi">汇总数据</strong></li><li id="e3fa" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated"><strong class="ig hi">做出预测</strong></li><li id="7c08" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated"><strong class="ig hi">评估准确度</strong></li></ul><h2 id="97a1" class="ks jp hh bd jq kt ku kv ju kw kx ky jy ip kz la kc it lb lc kg ix ld le kk lf bi translated">步骤1:处理数据</h2><p id="e3d6" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">我们需要做的第一件事是加载我们的数据文件。数据是CSV格式，没有标题行或任何引号。我们可以使用open函数打开文件，并使用CSV模块中的reader函数读取数据行。</p><pre class="jd je jf jg fd mm mn mo mp aw mq bi"><span id="2094" class="ks jp hh mn b fi mr ms l mt mu">import csv<br/>import math<br/>import random</span><span id="8f54" class="ks jp hh mn b fi mv ms l mt mu">def loadCsv(filename):<br/>  lines = csv.reader(open(r'pima-indians-diabetes.data.csv'))<br/>  dataset = list(lines)<br/>  for i in range(len(dataset)):<br/>    dataset[i] = [float(x) for x in dataset[i]]<br/>  return dataset</span></pre><p id="8867" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们需要将数据分成训练和测试数据集。</p><pre class="jd je jf jg fd mm mn mo mp aw mq bi"><span id="871a" class="ks jp hh mn b fi mr ms l mt mu">def splitDataset(dataset, splitRatio):<br/>  trainSize = int(len(dataset) * splitRatio)<br/>  trainSet = []<br/>  copy = list(dataset)<br/>  while len(trainSet) &lt; trainSize:<br/>    index = random.randrange(len(copy))<br/>    trainSet.append(copy.pop(index))<br/>  return [trainSet, copy]</span></pre><h2 id="28f9" class="ks jp hh bd jq kt ku kv ju kw kx ky jy ip kz la kc it lb lc kg ix ld le kk lf bi translated">第二步:总结数据</h2><p id="03a9" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">收集的训练数据摘要包括每个属性的平均值和标准偏差(按类值)。在进行预测以计算属于每个类值的特定属性值的概率时，这些是必需的。</p><p id="40af" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以将汇总数据的准备工作分解为以下子任务:</p><pre class="jd je jf jg fd mm mn mo mp aw mq bi"><span id="55b7" class="ks jp hh mn b fi mr ms l mt mu"><strong class="mn hi"># Separate Data By Class</strong></span><span id="e993" class="ks jp hh mn b fi mv ms l mt mu">def separateByClass(dataset):<br/>  separated = {}<br/>  for i in range(len(dataset)):<br/>    vector = dataset[i]<br/>    if (vector[-1] not in separated):<br/>      separated[vector[-1]] = []<br/>      separated[vector[-1]].append(vector)</span><span id="019e" class="ks jp hh mn b fi mv ms l mt mu">  return separated</span><span id="218e" class="ks jp hh mn b fi mv ms l mt mu"><strong class="mn hi"># Calculate Mean</strong></span><span id="b767" class="ks jp hh mn b fi mv ms l mt mu">def mean(numbers):<br/>  return sum(numbers)/float(len(numbers))</span><span id="14b6" class="ks jp hh mn b fi mv ms l mt mu"><strong class="mn hi"># Calculate Standard Deviation</strong></span><span id="4961" class="ks jp hh mn b fi mv ms l mt mu">def stdev(numbers):<br/>  avg = mean(numbers)<br/>  variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)</span><span id="a55f" class="ks jp hh mn b fi mv ms l mt mu">  return math.sqrt(variance)</span><span id="1efa" class="ks jp hh mn b fi mv ms l mt mu"><strong class="mn hi"># Summarize Dataset</strong></span><span id="933e" class="ks jp hh mn b fi mv ms l mt mu">def summarize(dataset):<br/>  summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]<br/>  del summaries[-1]<br/>  return summaries</span><span id="fcfa" class="ks jp hh mn b fi mv ms l mt mu"><strong class="mn hi"># Summarize Attributes By Class</strong></span><span id="968f" class="ks jp hh mn b fi mv ms l mt mu">def summarizeByClass(dataset):<br/>  separated = separateByClass(dataset)<br/>  summaries = {} <br/>  for classValue, instances in separated.items():<br/>      summaries[classValue] = summarize(instances)</span><span id="c608" class="ks jp hh mn b fi mv ms l mt mu">  return summaries</span></pre><h2 id="8336" class="ks jp hh bd jq kt ku kv ju kw kx ky jy ip kz la kc it lb lc kg ix ld le kk lf bi translated">第三步:做预测</h2><p id="b2b7" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">我们现在准备使用从我们的训练数据准备的摘要来进行预测。进行预测包括计算给定数据实例属于每个类的概率，然后选择概率最大的类作为预测。我们需要执行以下任务:</p><pre class="jd je jf jg fd mm mn mo mp aw mq bi"><span id="e414" class="ks jp hh mn b fi mr ms l mt mu"><strong class="mn hi"># Calculate Gaussian Probability Density Function</strong></span><span id="fdc6" class="ks jp hh mn b fi mv ms l mt mu">def calculateProbability(x, mean, stdev):<br/>  exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))<br/>  return (1/(math.sqrt(2*math.pi)*stdev))*exponent</span><span id="1ec1" class="ks jp hh mn b fi mv ms l mt mu"><strong class="mn hi"># Calculate Class Probabilities</strong></span><span id="e5c0" class="ks jp hh mn b fi mv ms l mt mu">def calculateClassProbabilities(summaries, inputVector):<br/>  probabilities = {}<br/>  for classValue, classSummaries in summaries.items():<br/>     probabilities[classValue] = 1<br/>     for i in range(len(classSummaries)):<br/>         mean, stdev = classSummaries[i]<br/>         x = inputVector[i]<br/>         probabilities[classValue] *= calculateProbability(x, mean, stdev)<br/>     return probabilities</span><span id="9e46" class="ks jp hh mn b fi mv ms l mt mu"><strong class="mn hi"># Make a Prediction</strong></span><span id="8803" class="ks jp hh mn b fi mv ms l mt mu">def predict(summaries, inputVector): <br/>  probabilities = calculateClassProbabilities(summaries, inputVector) <br/>  bestLabel, bestProb = None, -1<br/>  for classValue, probability in probabilities.items():<br/>     if bestLabel is None or probability &gt; bestProb:<br/>        bestProb = probability<br/>        bestLabel = classValue<br/>  return bestLabel</span><span id="59dd" class="ks jp hh mn b fi mv ms l mt mu"><strong class="mn hi"># Make Predictions</strong></span><span id="3d8e" class="ks jp hh mn b fi mv ms l mt mu">def getPredictions(summaries, testSet):<br/>  predictions = []<br/>  for i in range(len(testSet)):<br/>     result = predict(summaries, testSet[i])<br/>     predictions.append(result)<br/>  return predictions</span><span id="6786" class="ks jp hh mn b fi mv ms l mt mu"><strong class="mn hi"># Get Accuracy</strong></span><span id="c2a6" class="ks jp hh mn b fi mv ms l mt mu">def getAccuracy(testSet, predictions):<br/>  correct = 0<br/>  for x in range(len(testSet)):<br/>     if testSet[x][-1] == predictions[x]:<br/>        correct += 1<br/>  return (correct/float(len(testSet)))*100.0</span></pre><p id="04de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们定义我们的主函数，在这里我们调用我们定义的所有这些方法，一个接一个地得到我们创建的模型的精度。</p><pre class="jd je jf jg fd mm mn mo mp aw mq bi"><span id="9587" class="ks jp hh mn b fi mr ms l mt mu">def main():<br/>  filename = 'pima-indians-diabetes.data.csv'<br/>  splitRatio = 0.67<br/>  dataset = loadCsv(filename) <br/>  trainingSet, testSet = splitDataset(dataset, splitRatio)<br/>  print('Split {0} rows into train = {1} and test = {2} rows'.format(len(dataset),len(trainingSet),len(testSet)))</span><span id="468b" class="ks jp hh mn b fi mv ms l mt mu">  #prepare model<br/>  summaries = summarizeByClass(trainingSet)</span><span id="091d" class="ks jp hh mn b fi mv ms l mt mu">  #test model<br/>  predictions = getPredictions(summaries, testSet)</span><span id="baa2" class="ks jp hh mn b fi mv ms l mt mu">  accuracy = getAccuracy(testSet, predictions)<br/>  print('Accuracy: {0}%'.format(accuracy))</span><span id="f26a" class="ks jp hh mn b fi mv ms l mt mu">main()</span></pre><p id="1f9c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">输出可能看起来像这样</strong></p><blockquote class="mw mx my"><p id="38e2" class="ie if mz ig b ih ii ij ik il im in io na iq ir is nb iu iv iw nc iy iz ja jb ha bi translated">将768行拆分成514行train = 514行，254行test = 254行，准确率:68.166727248241</p></blockquote><p id="45a0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出在68%左右，这在不使用scikit学习库的情况下是相当不错的</p><blockquote class="lx"><p id="1445" class="ly lz hh bd ma mb mc md me mf mg jb dx translated">这是我的Jupyter笔记本的链接，在那里我实现了相同的代码。你也可以参考一下。你也可以在同一个目录中找到数据集。</p></blockquote><div class="nd ne nf ng nh ni"><a href="https://github.com/Shag10/Machine-Learning/tree/master/Internity_Internship/Day-13" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab dw"><div class="nk ab nl cl cj nm"><h2 class="bd hi fi z dy nn ea eb no ed ef hg bi translated">shag 10/机器学习</h2><div class="np l"><h3 class="bd b fi z dy nn ea eb no ed ef dx translated">此时您不能执行该操作。您已使用另一个标签页或窗口登录。您已在另一个选项卡中注销，或者…</h3></div><div class="nq l"><p class="bd b fp z dy nn ea eb no ed ef dx translated">github.com</p></div></div><div class="nr l"><div class="ns l nt nu nv nr nw jm ni"/></div></div></a></div><h1 id="b231" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">朴素贝叶斯算法的应用</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kr"><img src="../Images/988f913305cac23a8fcadbbae06e2ad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*YISbvdLuBDbJ1ffI.jpg"/></div></figure><ul class=""><li id="f47b" class="lh li hh ig b ih ii il im ip lj it lk ix ll jb lm ln lo lp bi translated"><strong class="ig hi">实时预测:</strong>朴素贝叶斯是一个渴望学习的分类器，它肯定很快。因此，它可以用于实时预测。</li><li id="fb36" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated"><strong class="ig hi">多类预测:</strong>该算法也以多类预测特性而闻名。这里我们可以预测多类目标变量的概率。</li><li id="5c58" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated"><strong class="ig hi">文本分类/垃圾邮件过滤/情感分析:</strong>与其他算法相比，最常用于文本分类的朴素贝叶斯分类器(由于在多类问题中的更好结果和独立性规则)具有更高的成功率。因此，它被广泛用于垃圾邮件过滤(识别垃圾邮件)和情感分析(在社交媒体分析中，识别积极和消极的客户情感)</li><li id="a37c" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated"><strong class="ig hi">推荐系统:</strong>朴素贝叶斯分类器和<a class="ae lv" href="https://en.wikipedia.org/wiki/Collaborative_filtering" rel="noopener ugc nofollow" target="_blank">协同过滤</a>一起构建了一个推荐系统，该系统使用机器学习和数据挖掘技术来过滤看不见的信息，并预测用户是否喜欢给定的资源。</li></ul><h1 id="282c" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">朴素贝叶斯的利弊？</h1><p id="5396" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated"><strong class="ig hi"> <em class="mz">优点:</em> </strong></p><ul class=""><li id="1ccf" class="lh li hh ig b ih ii il im ip lj it lk ix ll jb lm ln lo lp bi translated">预测测试数据集的类别是容易和快速的。它在多类预测中也表现良好</li><li id="5747" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated">当独立性假设成立时，与其他模型(如逻辑回归)相比，朴素贝叶斯分类器的性能更好，并且需要的训练数据更少。</li><li id="d1e8" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated">与数字变量相比，它在分类输入变量情况下表现良好。对于数值变量，假设正态分布(钟形曲线，这是一个强假设)。</li></ul><p id="cf7e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="mz">缺点:</em> </strong></p><ul class=""><li id="91b2" class="lh li hh ig b ih ii il im ip lj it lk ix ll jb lm ln lo lp bi translated">如果分类变量具有在训练数据集中未观察到的类别(在测试数据集中)，则模型将分配0(零)概率，并且将无法进行预测。这就是通常所说的“零频率”。为了解决这个问题，我们可以使用平滑技术。最简单的平滑技术之一叫做拉普拉斯估计。</li><li id="6fd0" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated">另一方面，朴素贝叶斯也被认为是一个糟糕的估计量，所以predict _ probab的概率输出不要太认真。</li><li id="9e5f" class="lh li hh ig b ih lq il lr ip ls it lt ix lu jb lm ln lo lp bi translated">朴素贝叶斯的另一个限制是独立预测者的假设。在现实生活中，我们几乎不可能得到一组完全独立的预测值。</li></ul></div><div class="ab cl nx ny go nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ha hb hc hd he"><p id="7419" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">所以这都是从我这边来的，我试图提供关于朴素贝叶斯算法及其实现的所有重要信息。</strong> <strong class="ig hi">希望你能在这里找到有用的东西。谢谢你一直读到最后。</strong></p></div><div class="ab cl nx ny go nz" role="separator"><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc od"/><span class="oa bw bk ob oc"/></div><div class="ha hb hc hd he"><h1 id="799c" class="jo jp hh bd jq jr oe jt ju jv of jx jy jz og kb kc kd oh kf kg kh oi kj kk kl bi translated">参考文献—</h1><div class="oj ok ez fb ol ni"><a href="https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab dw"><div class="nk ab nl cl cj nm"><h2 class="bd hi fi z dy nn ea eb no ed ef hg bi translated">用Python和R语言学习朴素贝叶斯算法的6个简单步骤</h2><div class="np l"><h3 class="bd b fi z dy nn ea eb no ed ef dx translated">注意:本文最初发布于2015年9月13日，更新于2017年9月11日概述了解其中一个…</h3></div><div class="nq l"><p class="bd b fp z dy nn ea eb no ed ef dx translated">www.analyticsvidhya.com</p></div></div><div class="nr l"><div class="om l nt nu nv nr nw jm ni"/></div></div></a></div><div class="oj ok ez fb ol ni"><a href="https://corporatefinanceinstitute.com/resources/knowledge/other/bayes-theorem/" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab dw"><div class="nk ab nl cl cj nm"><h2 class="bd hi fi z dy nn ea eb no ed ef hg bi translated">贝叶斯定理-定义、公式和例子</h2><div class="np l"><h3 class="bd b fi z dy nn ea eb no ed ef dx translated">在统计和概率论中，贝叶斯定理(也称为贝叶斯规则)是一个数学公式，用于…</h3></div><div class="nq l"><p class="bd b fp z dy nn ea eb no ed ef dx translated">corporatefinanceinstitute.com</p></div></div><div class="nr l"><div class="on l nt nu nv nr nw jm ni"/></div></div></a></div><div class="oj ok ez fb ol ni"><a href="https://www.edureka.co/blog/naive-bayes-tutorial/" rel="noopener  ugc nofollow" target="_blank"><div class="nj ab dw"><div class="nk ab nl cl cj nm"><h2 class="bd hi fi z dy nn ea eb no ed ef hg bi translated">朴素贝叶斯教程| Python中的朴素贝叶斯分类器| Edureka</h2><div class="np l"><h3 class="bd b fi z dy nn ea eb no ed ef dx translated">在一个充满机器学习和人工智能的世界，围绕着我们周围的几乎一切…</h3></div><div class="nq l"><p class="bd b fp z dy nn ea eb no ed ef dx translated">www.edureka.co</p></div></div><div class="nr l"><div class="oo l nt nu nv nr nw jm ni"/></div></div></a></div></div></div>    
</body>
</html>