<html>
<head>
<title>Performing Sentiment Analysis on Yelp Restaurant Reviews</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对Yelp餐馆评论进行情感分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/performing-sentiment-analysis-on-yelp-restaurant-reviews-962334d6336d?source=collection_archive---------5-----------------------#2021-03-15">https://medium.com/analytics-vidhya/performing-sentiment-analysis-on-yelp-restaurant-reviews-962334d6336d?source=collection_archive---------5-----------------------#2021-03-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/befc957917e81c80f4dc640686188195.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DK0FP2xZU99QZpUzg_7OA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">拉斯维加斯的自助酒宴</figcaption></figure><p id="91d3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在这篇文章中，我们将使用Yelp数据集，其中包含拉斯维加斯自助餐的客户评论，我们将通过使用自然语言处理步骤来完成创建分类模型的整个过程。</p><p id="2f8e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们的目标是分析用户评论的情感，并创建一个分类模型来预测给定评论的情感值。我们将使用CSV格式的数据，可以从<a class="ae js" href="https://github.com/zeynep394/AIZA-NLP-Sentiment-Analysis/blob/main/restaurant.csv" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><p id="da02" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">目录:</strong></p><ol class=""><li id="fd8e" class="jt ju hi iw b ix iy jb jc jf jv jj jw jn jx jr jy jz ka kb bi translated">数据分析和可视化</li><li id="c42f" class="jt ju hi iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated">语言检测</li><li id="be89" class="jt ju hi iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated">删除字符</li><li id="4840" class="jt ju hi iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated">计算极性和主观性</li><li id="30a8" class="jt ju hi iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated">创建WordCloud</li><li id="625b" class="jt ju hi iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated">应用引理假设</li><li id="76fc" class="jt ju hi iw b ix kc jb kd jf ke jj kf jn kg jr jy jz ka kb bi translated">分类步骤</li></ol></div><div class="ab cl kh ki gp kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="hb hc hd he hf"><h1 id="6a96" class="ko kp hi bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">数据分析和可视化</h1><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lm"><img src="../Images/015c2fd65ab7c9b9f817a2dbe9004eb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E2CusOHWF1AprIJm04ZuUQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">导入“restaurant.csv”文件后的数据框</figcaption></figure><p id="754f" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">由于我们的目标是使用以前的客户评论和与它们相关的星级来找到给定文本的情感，很明显我们将只需要这个数据框架的两列；文本和星星栏。</p><p id="eb80" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了更好地理解文本和stars列之间的关系，首先我们检查stars列；它包含了多少唯一值？各星级分布如何？哪些评级被认为是正面情绪，哪些被认为是负面情绪？</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="47a3" class="lw kp hi ls b fi lx ly l lz ma">df.stars.unique()<br/>#How many unique star values are there</span><span id="30ca" class="lw kp hi ls b fi mb ly l lz ma">&gt;&gt;array([5, 4, 1, 3, 2], dtype=int64)</span><span id="4dc8" class="lw kp hi ls b fi mb ly l lz ma">df.stars.value_counts()<br/>#shows the distribution for each star value</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/22e7ad01aa8752aa88ff19c54c18262f.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*k6YxkXRXvCB827x_qIDoCg.png"/></div></figure><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="8eab" class="lw kp hi ls b fi lx ly l lz ma">#Let's see the distribution of each star rating as a pie chart<br/>#This way we can see that most of our data contains positive comments by costumers</span><span id="bf17" class="lw kp hi ls b fi mb ly l lz ma">plt.figure(figsize=(8,8))</span><span id="8605" class="lw kp hi ls b fi mb ly l lz ma">df[‘stars’].value_counts().plot.pie(autopct=’%1.1f%%’, startangle=60)</span><span id="53b0" class="lw kp hi ls b fi mb ly l lz ma">plt.title(‘Yıldızların Dağılım Grafiği’)</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div class="er es md"><img src="../Images/0d567b86c2fdfdab006228e82c5368f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*PlNfYwk14_w1XW2rsmUlaA.png"/></div></figure><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="d0ec" class="lw kp hi ls b fi lx ly l lz ma">x=df['stars'].value_counts()<br/>x=x.sort_index()</span><span id="5a88" class="lw kp hi ls b fi mb ly l lz ma">plt.figure(figsize=(10,6))<br/>ax= sns.barplot(x.index, x.values, alpha=0.8)<br/>plt.title("Star Rating Distribution")<br/>plt.ylabel('count')<br/>plt.xlabel('Star Ratings')</span><span id="9e45" class="lw kp hi ls b fi mb ly l lz ma">rects = ax.patches<br/>labels = x.values</span><span id="601c" class="lw kp hi ls b fi mb ly l lz ma">for rect, label in zip(rects, labels):<br/>    height = rect.get_height()<br/>    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')</span><span id="225a" class="lw kp hi ls b fi mb ly l lz ma">plt.show();</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es me"><img src="../Images/231ce61d97c0d1fdb9a6a9d406f62874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SDyDQ7_8FfLCXCTsjkM_lg.png"/></div></div></figure><p id="e3c7" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们使用了三种不同的方法来展示星级的分布。我们可以看到，从1到5有5个不同的评分值。</p><p id="08ab" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">因此，我们可以有把握地假设评分4和5代表积极情绪，而1和2代表消极情绪，这一分组将评分3留在后面，因此我们将它标记为中性情绪。</p><p id="db12" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了形成新决定的列，我们使用<code class="du mf mg mh ls b">loc</code>选择我们想要的组，并创建一个名为“情感”的列，然后我们分配情感分组值。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="bbeb" class="lw kp hi ls b fi lx ly l lz ma">df.loc[df['stars'] == 3, 'sentiment'] = 'neutral' <br/>df.loc[df['stars'] &lt; 3, 'sentiment'] = 'negative' <br/>df.loc[df['stars'] &gt; 3, 'sentiment'] = 'positive'</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div class="er es mi"><img src="../Images/44fe9c965a0dc9637d99abef64f59b1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*IT2tkcAnDSKeZnvYZGr01g.png"/></div></figure><h1 id="f693" class="ko kp hi bd kq kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk ll bi translated">语言检测</h1><p id="66bb" class="pw-post-body-paragraph iu iv hi iw b ix mo iz ja jb mp jd je jf mq jh ji jj mr jl jm jn ms jp jq jr hb bi translated">标注完情感类型，就到了语言检测的时候了。由于我们的数据来自全球数据集，一些用户评论不是英文的，在这一点上，我们可以用两种方式处理这个过程；一种是检测非英语语言并使用TextBlob翻译文本，另一种是简单地删除非英语语言。对于这个解决方案，我们将遵循第二个。</p><p id="11fa" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">就像我们上面所说的，我们只需要处理“星星”、“情感”和“文本”列，因此为了简化数据框，我们只选择这些列。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="c9a8" class="lw kp hi ls b fi lx ly l lz ma">new_df= df[['stars', 'sentiment','text']]</span></pre><p id="a58d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">有许多不同的库和方法来检测语言，如TextBlob、Polyglot、chardet和langid，但我们今天将使用langdetect，这是一个支持55种语言的python库。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="4de0" class="lw kp hi ls b fi lx ly l lz ma">$ pip install langdetect<br/>#install the library</span><span id="224b" class="lw kp hi ls b fi mb ly l lz ma">from langdetect import detect<br/>#import detect function from langdetect</span><span id="e849" class="lw kp hi ls b fi mb ly l lz ma">nonen=new_df[new_df['text'].apply(detect)!='en']<br/>#nonen is the dataframe of non-english user reviews</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/2a7b8b74dc1e0400e9a68103a2403911.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kFqCEEogIo2TyLNxfrlQ_w.png"/></div></div></figure><p id="7bae" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">选择所有英文文本，创建一个名为yelp的新数据框架。Yelp是我们从现在开始将要使用的数据框架。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="2e7a" class="lw kp hi ls b fi lx ly l lz ma">yelp=new_df[new_df['text'].apply(detect)=='en']<br/>#yelp is the data frame we will continue to work on.<br/>#yelp only contains English reviews</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div class="er es mu"><img src="../Images/944e1e5b49c29bde1e4552eca13b6027.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*rwyMP-N9C66phbjvJqQjUQ.png"/></div></figure><h1 id="769b" class="ko kp hi bd kq kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk ll bi translated">删除字符</h1><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="09c8" class="lw kp hi ls b fi lx ly l lz ma">yelp['text']=yelp['text'].str.lower()<br/>#change all strings to be lower</span><span id="002a" class="lw kp hi ls b fi mb ly l lz ma">yelp['text']=yelp['text'].str.replace('[^\w\s]','')<br/>#get rid of unwanted characters such as punctuation marks</span><span id="2cd6" class="lw kp hi ls b fi mb ly l lz ma">yelp['text']=yelp['text'].str.replace('\d+','') <br/>#removing numerals</span><span id="3085" class="lw kp hi ls b fi mb ly l lz ma">yelp['text']=yelp['text'].str.replace('\n',' ').str.replace('\r','')</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/50d962a2d4da75eb1d3ad4e44d329572.png" data-original-src="https://miro.medium.com/v2/resize:fit:1104/format:webp/1*YQ5uY8CmMHOGRyCyZouLTg.png"/></div></figure><h1 id="274b" class="ko kp hi bd kq kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk ll bi translated">计算极性和主观性</h1><p id="02d8" class="pw-post-body-paragraph iu iv hi iw b ix mo iz ja jb mp jd je jf mq jh ji jj mr jl jm jn ms jp jq jr hb bi translated">情感分析是确定给定文本的情感的过程，无论它是积极的还是消极的，或者是中性的。</p><p id="d770" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">TextBlob的<em class="mw">情感</em>功能通过返回两个属性<strong class="iw hj">极性</strong>和<strong class="iw hj">主观性</strong>来帮助我们理解文本的潜在情感。</p><p id="5804" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">Polarity返回一个在[-1，1]范围内的浮点值，其中1表示肯定的陈述，而-1表示否定的陈述。主观性也是一个在[0，1]范围内的浮点值。0表示个人观点，1表示事实信息。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="cbe7" class="lw kp hi ls b fi lx ly l lz ma">yelp['polarity'] = yelp['text'].apply(lambda x: TextBlob(x). sentiment)<br/>#applt textblob sentiment to yelp text column<br/>#and assign it to a new column named polarity</span><span id="b697" class="lw kp hi ls b fi mb ly l lz ma">sentiment_series = yelp['polarity'].tolist()<br/><br/>yelp[['polaarity','subjectivity']]=pd.DataFrame(sentiment_series,<br/>       index=yelp.index)<br/>       yelp.drop('polarity', inplace=True, axis=1)</span><span id="6e3e" class="lw kp hi ls b fi mb ly l lz ma">#split the list into two and create two new columns<br/>#assign the return values of sentiment function;<br/>#polarity and subjectivity to those columns</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mx"><img src="../Images/49db3e13783f02f9e5d8d8866495ec86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X30oIj2f3gd7z3BMTlooYg.png"/></div></div></figure><h1 id="3efa" class="ko kp hi bd kq kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk ll bi translated">创建单词云</h1><p id="d98b" class="pw-post-body-paragraph iu iv hi iw b ix mo iz ja jb mp jd je jf mq jh ji jj mr jl jm jn ms jp jq jr hb bi translated">Word cloud是用于基于文本的数据的可视化工具。它有助于确定文本数据中每个单词的频率或重要性。一个词云的基本逻辑是；特定单词在文本中出现得越多，它在单词云中出现得就越大、越粗。</p><p id="ed3e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">构建词云有三个步骤</p><ul class=""><li id="0403" class="jt ju hi iw b ix iy jb jc jf jv jj jw jn jx jr my jz ka kb bi translated">摘录评论</li><li id="4eac" class="jt ju hi iw b ix kc jb kd jf ke jj kf jn kg jr my jz ka kb bi translated">创建并生成单词云图像</li><li id="5a43" class="jt ju hi iw b ix kc jb kd jf ke jj kf jn kg jr my jz ka kb bi translated">使用matplotlib显示云</li></ul><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="106c" class="lw kp hi ls b fi lx ly l lz ma">from wordcloud import WordCloud</span><span id="de03" class="lw kp hi ls b fi mb ly l lz ma">wc = WordCloud( background_color="white", colormap="Dark2",<br/>               max_font_size=150, random_state=42)</span></pre><p id="f0eb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">单词云函数将字符串作为参数，因为我们希望找到正面和负面评论的单词云，所以我们通过star值选择文本值，并使用pandas的“join”方法将所有数据组合成一个字符串格式。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="b37f" class="lw kp hi ls b fi lx ly l lz ma">text_5_star=yelp[yelp['stars']&gt;3]<br/>text_5_star</span><span id="4caf" class="lw kp hi ls b fi mb ly l lz ma">text_5_star_review = " ".join(review for review in text_5_star.text)<br/>text_5_star_review</span><span id="d857" class="lw kp hi ls b fi mb ly l lz ma">text_1_star=yelp[yelp['stars']&lt;3]<br/>text_1_star</span><span id="1181" class="lw kp hi ls b fi mb ly l lz ma">text_1_star_review = " ".join(review for review in text_1_star.text)<br/>text_1_star_review</span></pre><p id="f258" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了给我们的单词云创建一个不同于默认单词云形状的形状，我们需要找到一个PNG文件作为蒙版。将我们的单词云遮罩成我们想要的形状后，下一步是使用<code class="du mf mg mh ls b">wc.generate()</code>生成它，然后我们可以使用matplotlib的<code class="du mf mg mh ls b">imshow()</code>函数将其可视化。</p><figure class="ln lo lp lq fd ij"><div class="bz dy l di"><div class="mz na l"/></div></figure><div class="ln lo lp lq fd ab cb"><figure class="nb ij nc nd ne nf ng paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/f7c6cf2782d5f227044bf6c6c4525178.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*rkfbb1A4Qi3aycFjgqBhug.png"/></div></figure><figure class="nb ij nc nd ne nf ng paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><img src="../Images/3aed755743269fa0abdfb469d92d3da0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*k9vKkzfmoSm9fQLy8gTTcw.png"/></div></figure></div><h1 id="64c9" class="ko kp hi bd kq kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk ll bi translated">应用引理假设</h1><p id="0821" class="pw-post-body-paragraph iu iv hi iw b ix mo iz ja jb mp jd je jf mq jh ji jj mr jl jm jn ms jp jq jr hb bi translated">词汇化基本上是一种将任何种类的单词转换成其基本词根模式的方法<em class="mw">。</em>由于语法原因，文档使用一个单词的不同形式，例如<em class="mw"> runs，running，</em>和<em class="mw"> ran </em>都是<em class="mw"> run这个单词的变体。</em></p><p id="03e4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">由于那些形式对我们的机器学习模型没有任何意义，所以我们的工作是告诉模型那些单词都是同一个词根的变体。这个过程被称为词汇化。</p><p id="fcf3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">在开始词汇化步骤之前，我们应该清除文本中不需要的字符，并应用标记化，这是一种将文本分成更小的称为标记的单元的方法。对文本数据进行标记后，我们将其存储在一个名为clean_text的列中，现在我们可以对该列中的每个单词应用词汇化。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="9b52" class="lw kp hi ls b fi lx ly l lz ma">yelp['text']=yelp['text'].str.replace('[^a-zA-Z]',' ')</span><span id="703b" class="lw kp hi ls b fi mb ly l lz ma">yelp['clean_text'] = yelp['text'].apply(lambda x: nltk.word_tokenize(x) ) </span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nh"><img src="../Images/3f2a4a4517ff7696b1e8db41b0384f86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XD8Emg6Emuvd7nY7eMQbAw.png"/></div></div></figure><p id="765c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">Python <code class="du mf mg mh ls b">nltk</code>是提供<strong class="iw hj"> WordNet词条解释器</strong>的包，它使用WordNet数据库来查找单词的词条。我们将导入这个包，并使用它的WordNetLemmatizer()方法对我们的文本进行lemmatize，并将其存储在名为stem_text的列中。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="9d0d" class="lw kp hi ls b fi lx ly l lz ma">import nltk<br/>from nltk.stem import WordNetLemmatizer<br/>lemmetizer_output= WordNetLemmatizer()<br/>  <br/>yelp['stem_text'] = yelp['clean_text'].apply(lambda x: [lemmetizer_output.lemmatize(j) for j in x if not j in set(STOP_WORDS)] )<br/>#applying lemmatization to each word of every column <br/>#by using pandas apply method<br/>#and checking for stop words at the same time</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ni"><img src="../Images/d405bac26ff317cb0f63c8d28f423c0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ChHXQwk0Nr3z-XYkx_46sw.png"/></div></div></figure><p id="0e60" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">完成词汇化后，我们使用pandas join()方法将文本从数组格式转换为文本格式，从而改变数据的格式。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="5ec0" class="lw kp hi ls b fi lx ly l lz ma">yelp['cleaned_text'] = yelp['stem_text'].apply(lambda x: ' '.join(x) ) </span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nj"><img src="../Images/36149668ad6f1ed6c002ef35e0922eb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PtqoHzdO-mFhO3S9z-UVEQ.png"/></div></div></figure><p id="e0a4" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在，我们的数据可以进行矢量化了。</p><h1 id="1f9f" class="ko kp hi bd kq kr mj kt ku kv mk kx ky kz ml lb lc ld mm lf lg lh mn lj lk ll bi translated">分类步骤</h1><p id="5c9d" class="pw-post-body-paragraph iu iv hi iw b ix mo iz ja jb mp jd je jf mq jh ji jj mr jl jm jn ms jp jq jr hb bi translated">很明显，计算机不能理解文本，至少我们不能理解文本，所以在你开始使用文本数据进行预测建模之前，文本数据需要特殊的准备。</p><p id="6ce0" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了使用这些我们花了很大力气清理的文本数据，我们必须找到一种让计算机理解的方法，这就是计数矢量化的用武之地；</p><p id="fcd2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">计数矢量化是一种使用one-hot-encoding将文本数据表示为数值的方法。输出向量的维数将等于我们的词汇表的大小。</p><p id="b5cf" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">为了更好地理解，让我们举个例子:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="cc3c" class="lw kp hi ls b fi lx ly l lz ma">x=yelp.cleaned_text #assign cleaned_text column to variable x <br/>y=yelp.sentiment #assign sentiment column to variable y</span><span id="e7b0" class="lw kp hi ls b fi mb ly l lz ma">x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3,random_state=42)</span><span id="608f" class="lw kp hi ls b fi mb ly l lz ma">#create train and test data</span></pre><p id="6b29" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">要创建计数矢量器，我们需要实例化一个。在制作矢量器时，我们可以设置一些特殊的参数(为了进一步的<a class="ae js" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="noopener ugc nofollow" target="_blank">阅读</a>)。但目前我们只会将<code class="du mf mg mh ls b">lowercase</code>设为true，将<code class="du mf mg mh ls b">stop_words</code>设为English</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="ef5a" class="lw kp hi ls b fi lx ly l lz ma">vect = CountVectorizer(lowercase=True, stop_words='english')<br/>x_train_dtm= vect.fit_transform(x_train) <br/># Call the <em class="mw">fit_transform()</em> function in order to learn a vocabulary from a document and transform it to a vector.<br/><br/><br/>print(x_train_dtm)</span><span id="ab91" class="lw kp hi ls b fi mb ly l lz ma">x_test_dtm=vect.transform(x_test)</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/64db79fbe8ae712d4d3ad1a0092a581e.png" data-original-src="https://miro.medium.com/v2/resize:fit:574/format:webp/1*aqB8Qm7Nwns6fv14a417qw.png"/></div></figure><p id="3f8d" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">现在让我们将矢量转换为数据框架，以便更好地理解它；</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="4453" class="lw kp hi ls b fi lx ly l lz ma">tf=pd.DataFrame(x_train_dtm.toarray(),columns=vect.get_feature_names())<br/>tf.head()</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nk"><img src="../Images/277c7c9c7cdf767a0e9fe2f2ba8565e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Yhb7A7QkvqkUfpLkze8DhQ.png"/></div></div></figure><p id="987e" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">既然我们已经了解了如何对文本数据进行矢量化，以及矢量化意味着什么，我们可以使用我们所了解的知识来训练分类算法，以对每个用户评论的情感进行分类。</p><figure class="ln lo lp lq fd ij"><div class="bz dy l di"><div class="mz na l"/></div></figure><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="3804" class="lw kp hi ls b fi lx ly l lz ma">vect = CountVectorizer(ngram_range=(1,2))<br/>tokenize_test(models,vect)<br/>#call the models function defined above to observe <br/>#accuracy scores of different classification algorithms</span></pre><figure class="ln lo lp lq fd ij er es paragraph-image"><div class="er es nl"><img src="../Images/b88cd9980977a9d375942b37ebf72094.png" data-original-src="https://miro.medium.com/v2/resize:fit:394/format:webp/1*SXfqbcyeOjLgHVPN_pFfZQ.png"/></div></figure><p id="ecfb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">感谢您的阅读！</p></div></div>    
</body>
</html>