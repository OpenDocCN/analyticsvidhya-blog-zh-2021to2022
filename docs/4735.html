<html>
<head>
<title>Know your Machine Learning Models Better With Model Interpretability</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过模型可解释性更好地了解您的机器学习模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/know-your-machine-learning-models-better-with-model-interpretability-2722390163b4?source=collection_archive---------2-----------------------#2022-01-25">https://medium.com/analytics-vidhya/know-your-machine-learning-models-better-with-model-interpretability-2722390163b4?source=collection_archive---------2-----------------------#2022-01-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/5dbbaa13b2f0e3e6fac98b6661c014d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/1*VoCfykNaez0QWynXaNYdaw.jpeg"/></div></div></figure><h1 id="695a" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">介绍</h1><p id="8002" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">机器学习已经成为许多数据驱动问题的解决方案。无论是识别银行系统中的欺诈交易、贷款预测、某种疾病的早期预测还是预测客户流失。</p><p id="db32" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">随着自动化取代了许多重复的过程，ML模型的使用提出了一系列的问题。</p><ol class=""><li id="c333" class="kq kr hh jp b jq kl ju km jy ks kc kt kg ku kk kv kw kx ky bi translated">我们如何仅仅通过查看RMSE、R平方得分、MAPE、准确度、AUC、精确度和召回率等指标来依赖特定模型的性能呢？？</li><li id="d4c8" class="kq kr hh jp b jq kz ju la jy lb kc lc kg ld kk kv kw kx ky bi translated">模型如何达到特定的决策或价值？</li><li id="d7a4" class="kq kr hh jp b jq kz ju la jy lb kc lc kg ld kk kv kw kx ky bi translated">什么特征促使模型做出特定的决策？</li></ol><p id="b380" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">本文通过解释<a class="ae le" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database" rel="noopener ugc nofollow" target="_blank">糖尿病预测</a>的用例来解释ML可解释性领域。在这篇文章结束时，你将理解为什么在训练后和推理过程中解释每一个ML模型是重要的。重点将更多地放在解释如何应用不同的模型解释方法上，而不是模型训练上。</p><h1 id="6dce" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">复杂性与可解释性</h1><p id="c8c7" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">为了更好地理解复杂性和可解释性之间的权衡，让我们首先理解训练ML模型的过程。</p><p id="9f23" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">每一个ML模型训练过程都包括以下内容-</p><ol class=""><li id="9c36" class="kq kr hh jp b jq kl ju km jy ks kc kt kg ku kk kv kw kx ky bi translated">求解方程</li><li id="df36" class="kq kr hh jp b jq kz ju la jy lb kc lc kg ld kk kv kw kx ky bi translated">损失函数</li><li id="19d7" class="kq kr hh jp b jq kz ju la jy lb kc lc kg ld kk kv kw kx ky bi translated">【计算机】优化程序</li><li id="b80b" class="kq kr hh jp b jq kz ju la jy lb kc lc kg ld kk kv kw kx ky bi translated">反向预测/权重更新</li></ol><p id="2307" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">为了获得更高的精度，我们经常尝试应用更复杂的方程(分量1)从训练数据中学习。这并不意味着我们不应该使用具有复杂数据的复杂模型。我们可以尝试不同的方法，如集成，甚至训练深度学习模型，以获得更好的评分模型。但是请记住，高度复杂的数据可能非常准确，但是不太容易解释。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lf"><img src="../Images/d96ddedf1e1057d2e264e9f966fe4ca8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QfqXw70r3qEmEqGyZc7-hg.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">不同ML模型的准确性和可解释性。来源:<a class="ae le" href="https://www.analyticsvidhya.com/blog/2019/08/decoding-black-box-step-by-step-guide-interpretable-machine-learning-models-python/" rel="noopener ugc nofollow" target="_blank"> A </a>维迪亚分析</figcaption></figure><p id="7bf1" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">参考上面提供的图表，我们可以看出，线性回归可能不如决策树准确，但其高度可解释性和深度神经网络可能高度准确，但可解释性较差。</p><p id="5821" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">但是，我们如何使用复杂的建模技术，并仍然能够解释这些模型？</p><p id="5453" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">这正是下一节要讨论的内容。</p><h1 id="4c43" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">用例—糖尿病预测</h1><p id="735a" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">本练习使用的数据集是<a class="ae le" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database" rel="noopener ugc nofollow" target="_blank">皮马印第安人糖尿病数据库</a>，其中包含糖尿病患者的重要信息。数据集有8个特征，数据集中的目标变量是以二进制格式标记的结果，0表示无糖尿病，1表示糖尿病。</p><p id="9f22" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">从探索性数据分析开始，接着是特征工程和用不同的集合模型进行实验。还采用了叠加等先进的建模方法，以增加演示模型的复杂性。</p><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="fb1e" class="lt iq hh lp b fi lu lv l lw lx">dia_df = pd.read_csv(‘/content/diabetes.csv’)</span><span id="2a78" class="lt iq hh lp b fi ly lv l lw lx">dia_df.head()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lz"><img src="../Images/ada381a2817e33159fe71c717ffbdb59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KYx2_0GZo-32AHDbuWO5Dw.png"/></div></div></figure><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="7fa2" class="lt iq hh lp b fi lu lv l lw lx">dia_df.info()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ma"><img src="../Images/ac0491a6c796d339866a92a57fd06777.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VWXEsJqyMd26PmDo4EYJUw.png"/></div></div></figure><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="f09d" class="lt iq hh lp b fi lu lv l lw lx">dia_df.isna().sum()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mb"><img src="../Images/f4cb55f62f97ca4be95bdc86cfee00d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*siiTJopssLN3WxydNPkJbA.png"/></div></figure><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="1f1b" class="lt iq hh lp b fi lu lv l lw lx">dia_df[‘Outcome’].value_counts(normalize=True)</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mc"><img src="../Images/3afd51f5846620d37508409204e4297c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*AwucJc6vrfwyI5i9Bx4cCA.png"/></div></figure><p id="7d7d" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">这表明目标变量是不平衡的。我们使用过采样来平衡数据。</p><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="1401" class="lt iq hh lp b fi lu lv l lw lx"># train test split</span><span id="1ac7" class="lt iq hh lp b fi ly lv l lw lx">X_train, X_test, y_train, y_test = train_test_split(dia_df.drop(‘Outcome’, axis=1), dia_df[‘Outcome’], test_size=0.3, random_state=1234)</span><span id="9dff" class="lt iq hh lp b fi ly lv l lw lx"># oversampling<br/>over_sampler = RandomOverSampler(random_state=1234)</span><span id="c7e2" class="lt iq hh lp b fi ly lv l lw lx">X_train, y_train = over_sampler.fit_resample(X_train, y_train)</span></pre><p id="b935" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">接下来，我们执行特征工程，如缩放数字特征。</p><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="7130" class="lt iq hh lp b fi lu lv l lw lx">scaler = MinMaxScaler()</span><span id="eff4" class="lt iq hh lp b fi ly lv l lw lx">X_train = scaler.fit_transform(X_train)</span><span id="4b61" class="lt iq hh lp b fi ly lv l lw lx">X_test = scaler.transform(X_test)</span></pre><p id="4ea9" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">一旦数据准备完成，我们就可以开始建模部分。让我们开始尝试不同的模型。</p><ol class=""><li id="9641" class="kq kr hh jp b jq kl ju km jy ks kc kt kg ku kk kv kw kx ky bi translated"><strong class="jp hi"><em class="md">K-最近邻</em> </strong></li></ol><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="10bb" class="lt iq hh lp b fi lu lv l lw lx">knn = KNeighborsClassifier()<br/>knn.fit(X_train, y_train)</span><span id="ff7c" class="lt iq hh lp b fi ly lv l lw lx">def show_metrics(y_true, y_pred):<br/>    print('Classification Report: \n')<br/>    print(classification_report(y_true, y_pred))<br/>    print('\nConfusion Matrix: \n')<br/>    print(confusion_matrix(y_true, y_pred))</span><span id="4dee" class="lt iq hh lp b fi ly lv l lw lx">y_pred_knn = knn.predict(X_test)</span><span id="798e" class="lt iq hh lp b fi ly lv l lw lx">show_metrics(y_test, y_pred_knn)</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es me"><img src="../Images/44958d398985adce1616b4bd612f6b8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HyNcILUAoGDKm9WZa3sTZw.png"/></div></div></figure><p id="22d7" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">2.<strong class="jp hi"> <em class="md">渐变助推模型</em> </strong></p><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="b92a" class="lt iq hh lp b fi lu lv l lw lx">gb_ensemble_model = GradientBoostingClassifier(n_estimators=500, learning_rate=0.001, max_depth=4, min_samples_split=4)</span><span id="eb54" class="lt iq hh lp b fi ly lv l lw lx">gb_ensemble_model.fit(X_train, y_train)</span><span id="77a3" class="lt iq hh lp b fi ly lv l lw lx">y_pred_gb = gb_ensemble_model.predict(X_test)</span><span id="bb72" class="lt iq hh lp b fi ly lv l lw lx">show_metrics(y_test, y_pred_gb)</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es me"><img src="../Images/108fd21b21f177f172ce13000a7d5b4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PzdNA_vSn4WvEclFmmiiIg.png"/></div></div></figure><p id="56e0" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">3.<strong class="jp hi"> <em class="md">堆叠集合模型</em> </strong></p><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="ee62" class="lt iq hh lp b fi lu lv l lw lx">clf1 = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.001, max_depth=4, min_samples_split=4)</span><span id="4419" class="lt iq hh lp b fi ly lv l lw lx">clf2 = KNeighborsClassifier(n_neighbors=20)</span><span id="b695" class="lt iq hh lp b fi ly lv l lw lx">meta_clf = LogisticRegression()</span><span id="d7d9" class="lt iq hh lp b fi ly lv l lw lx">stacked_ensemble = StackingClassifier([clf1, clf2], meta_classifier=meta_clf, use_probas=True)</span><span id="7bc7" class="lt iq hh lp b fi ly lv l lw lx">stacked_ensemble.fit(X_train, y_train)</span><span id="644f" class="lt iq hh lp b fi ly lv l lw lx">y_pred_se = stacked_ensemble.predict(X_test)</span><span id="4f12" class="lt iq hh lp b fi ly lv l lw lx">show_metrics(y_test, y_pred_se)</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es me"><img src="../Images/108fd21b21f177f172ce13000a7d5b4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PzdNA_vSn4WvEclFmmiiIg.png"/></div></div></figure><p id="1e26" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们尝试了不同的建模技术，从简单的KNN模型和越来越复杂的不同模型开始。让我们假设，堆叠集合模型给出了最好的预测结果，我们想用它来进行推断。在下一节中，我们将演示使用机器学习的可解释性来理解集合模型。</p><h1 id="1511" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">模型解释</h1><ol class=""><li id="52ca" class="kq kr hh jp b jq jr ju jv jy mf kc mg kg mh kk kv kw kx ky bi translated"><strong class="jp hi"> <em class="md">特征重要性图</em> </strong></li></ol><p id="f66d" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">如果您使用集合模型，Scikit-Learn在模型类中提供了一个变量，称为“feature_importances_”。一旦模型训练完成，我们就可以得到特征的重要性，并绘制一个图表，如下所示。</p><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="0670" class="lt iq hh lp b fi lu lv l lw lx">rf_model = RandomForestClassifier()<br/>rf_model.fit(X_train, y_train)</span><span id="94d5" class="lt iq hh lp b fi ly lv l lw lx">features = dia_df.drop('Outcome', axis=1).columns.tolist()</span><span id="38f7" class="lt iq hh lp b fi ly lv l lw lx">importances = rf_model.feature_importances_</span><span id="b2dc" class="lt iq hh lp b fi ly lv l lw lx">feature_imp_df = pd.DataFrame({'feature': features, 'importance': importances}).sort_values('importance', ascending=False)</span><span id="41b0" class="lt iq hh lp b fi ly lv l lw lx">plt.figure(figsize=(10,8))</span><span id="8b21" class="lt iq hh lp b fi ly lv l lw lx">plt.title('Random Forest Feature Importance')</span><span id="699b" class="lt iq hh lp b fi ly lv l lw lx">sns.barplot(y='feature', x='importance', data=feature_imp_df, color='skyblue')</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mi"><img src="../Images/41a831a68a8fa6b2b4e041cff58e977d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IiGREHdZTFaMHUgbSz0vow.png"/></div></div></figure><p id="e218" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">查看上面的图，我们可以对在决策中驱动模型的特征有一些基本的了解。我们可以根据我们的领域知识添加/删除一些功能，然后再看剧情。</p><p id="9be5" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">2.<strong class="jp hi"> <em class="md">决策树代理</em> </strong></p><p id="5043" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">模型解释的另一种方法是代理模型。当当前模型的决策复杂时，可以使用代理模型，我们使用我们的模型提供的结果来训练另一个高度可解释的模型。在这种情况下，我们选择决策树，因为通过绘制决策树更容易理解。需要注意的一点是，用于训练决策树的目标变量将是我们的堆叠集合模型的预测输出，而不是实际的目标。</p><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="0402" class="lt iq hh lp b fi lu lv l lw lx">dt_model = DecisionTreeClassifier()</span><span id="e763" class="lt iq hh lp b fi ly lv l lw lx"># stacked ensemble predictions<br/>y_pred_train_se = stacked_ensemble.predict(X_train)</span><span id="f0d0" class="lt iq hh lp b fi ly lv l lw lx"># training on predicted targets<br/>dt_model.fit(X_train, y_pred_train_se)</span><span id="e5ce" class="lt iq hh lp b fi ly lv l lw lx">fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (5,3), dpi=300)</span><span id="7c49" class="lt iq hh lp b fi ly lv l lw lx">out = plot_tree(dt_model, feature_names=features, class_names=['Not Diabetic', 'Diabetic'], max_depth=2, filled=True, fontsize=4)</span><span id="68ba" class="lt iq hh lp b fi ly lv l lw lx">for o in out:<br/>     arrow = o.arrow_patch<br/>     if arrow is not None:<br/>        arrow.set_edgecolor('black')<br/>        arrow.set_linewidth(0.2)</span><span id="9865" class="lt iq hh lp b fi ly lv l lw lx">plt.show()</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mj"><img src="../Images/ed593e7097ad87e06638b9ecf38e1f2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQP5M0V3Fx_d_cHCcmF4Qg.png"/></div></div></figure><p id="1508" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">3.<strong class="jp hi"> <em class="md">石灰交代者</em> </strong></p><p id="7359" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">LIME代表局部可解释的模型不可知解释。顾名思义，这种解释在给定一行数据作为模型输入的情况下输出一系列值。它有助于我们理解推动模型做出特定决策的特征。LIME是模型不可知的，这意味着它可以应用于任何可能的ML模型。</p><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="b6bf" class="lt iq hh lp b fi lu lv l lw lx">def predict_proba(data):<br/>    return np.array(list(zip(1-stacked_ensemble.predict(data),     stacked_ensemble.predict(data))))</span><span id="f0b1" class="lt iq hh lp b fi ly lv l lw lx">explainer = lime.lime_tabular.LimeTabularExplainer(X_train, mode='classification', training_labels=y_train.values, feature_names=features)</span><span id="f7b9" class="lt iq hh lp b fi ly lv l lw lx">def explain_instance(data):<br/>    exp = explainer.explain_instance(data, predict_proba,  num_features=len(features))<br/>    exp.show_in_notebook(show_table=True)</span><span id="85ac" class="lt iq hh lp b fi ly lv l lw lx">explain_instance(X_train[0])</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mk"><img src="../Images/9f647955dcef39b94b4452567b279ac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-7MMmMXLnU3cKBt1qsXPJg.png"/></div></div></figure><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="9503" class="lt iq hh lp b fi lu lv l lw lx">explain_instance(X_train[100])</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mk"><img src="../Images/c90c39ef55d20fbc77797d502a7bd079.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gpQDeWffI8hcNfyImSrrvg.png"/></div></div></figure><p id="95a0" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">4.<em class="md"> </em> <strong class="jp hi"> <em class="md"> SHAP交代</em> </strong></p><p id="6258" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">SHAP主张沙普利附加解释。基于每个特征的shapley值给出模型解释。它提供了局部和全局的解释。</p><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="fba4" class="lt iq hh lp b fi lu lv l lw lx">def local_explanation(data, i):<br/>    shap.initjs()<br/>    explainer = shap.TreeExplainer(gb_ensemble_model)<br/>    shap_values = explainer.shap_values(data)<br/>    return shap.force_plot(explainer.expected_value, shap_values[i], features=data[i], feature_names=features)</span><span id="4e7e" class="lt iq hh lp b fi ly lv l lw lx">local_explanation(X_train, 0)</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ml"><img src="../Images/1269c1400cbfbb675f709fe47779e3ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4SOvXMnpXpjYFrGbfyVwsw.png"/></div></div></figure><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="a0d2" class="lt iq hh lp b fi lu lv l lw lx">local_explanation(X_train, 100)</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ml"><img src="../Images/ea524b510e765bbb962a8602378ae5df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z-KU5FmDj3DOpP5PrSWmdw.png"/></div></div></figure><pre class="lg lh li lj fd lo lp lq lr aw ls bi"><span id="55fd" class="lt iq hh lp b fi lu lv l lw lx"># global explanation<br/>shap.initjs()<br/>explainer = shap.TreeExplainer(gb_ensemble_model)<br/>shap_values = explainer.shap_values(X_train)<br/>shap.summary_plot(shap_values, features=X_train, feature_names=features, plot_size=(12,8))</span></pre><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mm"><img src="../Images/345f44a4b05dc751fbd5681169e8f004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LyHPqcT2PSZui6BYmz511w.png"/></div></div></figure><h1 id="c1e9" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">结论</h1><p id="03af" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">本文向我们介绍了机器学习可解释性背后的基本思想，并解释了如何使用不同的方法来解释ML模型。</p><p id="47b3" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">如果你对深入研究模型解释感兴趣，我推荐你阅读这本电子书。</p><p id="1afa" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">本文中使用的代码可以通过这个<a class="ae le" href="https://gist.github.com/iamrajatroy/c91296e6f611bfb9d1cc66ea69be8358" rel="noopener ugc nofollow" target="_blank">链接</a>访问。</p></div></div>    
</body>
</html>