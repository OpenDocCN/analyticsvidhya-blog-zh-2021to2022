<html>
<head>
<title>✌️ Automation with Python.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python实现✌️自动化。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/%EF%B8%8F-do-some-automate-work-with-python-a4c5d50da79c?source=collection_archive---------9-----------------------#2021-06-26">https://medium.com/analytics-vidhya/%EF%B8%8F-do-some-automate-work-with-python-a4c5d50da79c?source=collection_archive---------9-----------------------#2021-06-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/6df1f5b77b20040a1a0d25be55c23fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_sydRtY-DM559T3L5cpyKg.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">来自unsplash</figcaption></figure><p id="93ff" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">用<a class="ae jr" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">美汤</a>和<a class="ae jr" href="https://pypi.org/project/requests/" rel="noopener ugc nofollow" target="_blank">请求</a>库从U <a class="ae jr" href="https://unsplash.com/wallpapers" rel="noopener ugc nofollow" target="_blank"> nspla </a> sh下载图片。</p><p id="6a96" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">首先我们需要安装请求库来获取内容表单<a class="ae jr" href="https://unsplash.com/wallpapers" rel="noopener ugc nofollow" target="_blank"><strong class="iv hi"><em class="js"/></strong></a></p><p id="0859" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在打开你的终端。</p><p id="d219" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">如果您的机器上安装了pip，那么您可以在终端上输入以下文本来安装请求库。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="48ed" class="kc kd hh jy b fi ke kf l kg kh"><strong class="jy hi"><em class="js"> </em></strong><em class="js">pip install requests</em></span></pre><p id="a9be" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">还有漂亮的汤4。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="541f" class="kc kd hh jy b fi ke kf l kg kh">pip install beautifulsoup4</span></pre><p id="13ae" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">你还需要html解析器。我们将使用“lxml”</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="d75d" class="kc kd hh jy b fi ke kf l kg kh">pip install lxml</span></pre><p id="dd90" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">如果你想创建一个虚拟环境，也可以通过pipenv或venv来实现。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="7d84" class="kc kd hh jy b fi ke kf l kg kh">//first make dir<br/>mkdir get_photos</span><span id="b7a8" class="kc kd hh jy b fi ki kf l kg kh">//change dir to get_photos<br/>cd get_photos</span><span id="ca10" class="kc kd hh jy b fi ki kf l kg kh">//now open your text editor and make file <br/>//photo_downloader.py</span><span id="e6af" class="kc kd hh jy b fi ki kf l kg kh">//if you have nvim then you can do <br/>nvim photo_downloader.py</span></pre><p id="0062" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在让我们编码。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="467c" class="kc kd hh jy b fi ke kf l kg kh">//first import <br/>import requests<br/>from bs4 import BeautifulSoup<br/>import lxml</span></pre><p id="7a4d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">请求库被导入，BeautifulSoup“类”是从bs4模块导入的。您可以通过以下方式在python shell中探索有关bs4的更多信息。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="f368" class="kc kd hh jy b fi ke kf l kg kh">//define function which take url(unsplash)<br/>def photo_downloader(url):<br/>    request = requests.get(url,allow_redirects=True)<br/>    data = BeautifulSoup(request.content,'lxml')<br/>    </span></pre><p id="b46e" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这里我们定义了一个photo_downloader函数，我们在这个函数中工作。</p><p id="bb38" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">首先用以url为参数的“requests.get”方法从网站获取内容。采用html和html解析器' BeautifulSoup类。</p><p id="d799" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">访问<a class="ae jr" href="https://unsplash.com/walpapers" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/wallpapers</a>并在您的浏览器中检查</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kj"><img src="../Images/f8bcf238a06875671775de91c08ffb0c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gHlpmgfIITMD9lr_DdalHg.png"/></div></div></figure><p id="a5f4" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在这里我们发现<figure>标签分隔了每张图片，现在我们将把每张<figure>标签看作</figure></figure></p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="7667" class="kc kd hh jy b fi ke kf l kg kh">    ...<br/>    all_images = data.find_all("figure",itemprop="image")<br/></span></pre><p id="6f2d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">data.find_all将搜索每一个<figure>图片，以区别于图片分隔符标签。</figure></p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="1bfa" class="kc kd hh jy b fi ke kf l kg kh">count = 0 //for change name of pictures<br/>for i in all_images:<br/>//find tag with photo downloadable href<br/>    url = i.find('a',rel="nofollow") <br/>    if url != None:<br/>        photo_url = url["href"]//take url to download<br/>        phto_bytes =requests.get(photo_url,allow_redirects=True)<br/>        with open(f'{count}wallpapers.jpg','wb') as photo:<br/>            photo.write(photo_bytes.content)<br/>            count +=1<br/>print("Done")</span><span id="6c47" class="kc kd hh jy b fi ki kf l kg kh"><br/>photo_downloader("https://unsplash.com/wallpapers")</span></pre><p id="8ef6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">all_images返回iterable对象，因此迭代all_images以获取每一张图像。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kk"><img src="../Images/89e0f60ee55859bd07a10a7a67915759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*edhjCRhKYdq0wJ2gb2d71A.png"/></div></div></figure><p id="795c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">标签<a>元素href具有可下载的图像url。我们可以像字典一样访问标签元素。现在我们有下载的url，请求它的内容是photo_bytes，它将返回状态代码。它的内容将被写入照片格式的文件，扩展名为*.jpg。在这里，您可以使用操作系统模块下载照片的其他文件夹</a></p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="374d" class="kc kd hh jy b fi ke kf l kg kh">             ...<br/>             os.chdir(os.getcwd())<br/>             ...</span></pre><p id="da10" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在用它的参数值调用函数</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="4ccd" class="kc kd hh jy b fi ke kf l kg kh">photo_downloader('https://unsplash.com/wallpapers')</span></pre><p id="be9b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">全部代码。</p><pre class="jt ju jv jw fd jx jy jz ka aw kb bi"><span id="8d60" class="kc kd hh jy b fi ke kf l kg kh">import requests<br/>from bs4 import BeautifulSoup<br/>import os<br/>import lxml</span><span id="c82e" class="kc kd hh jy b fi ki kf l kg kh">def photo_downloader(url):<br/>    request = requests.get(url,allow_redirects = True)<br/>    data = BeautifulSoup(request.text,'lxml')<br/>    all_image=data.find_all('figure',itemprop="image")<br/>    count =0<br/>    os.chdir('..\\pictures')<br/>    for i in all_image:<br/>        url=i.find('a',rel="nofollow")<br/>        if url != None:<br/>            i_url = url['href']<br/>            photo_bytes = requests.get(i_url,allow_redirects=True)<br/>            with open(f'{count}3d.jpg','wb') as photo:<br/>                photo.write(photo_bytes.content)<br/>                count +=1<br/><br/>    print("Done")<br/><br/><br/><br/>if __name__ == "__main__":<br/>    photo_downloader("<a class="ae jr" href="https://unsplash.com/s/photos/3d" rel="noopener ugc nofollow" target="_blank">https://unsplash.com/s/photos/3d</a>")</span></pre><p id="c6b5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这是为这个博客做的，试着自己试验一下，用一些其他的url实现它。✌️🗞️</p></div></div>    
</body>
</html>