<html>
<head>
<title>4 Performance improving techniques to make Spark Joins 10X faster</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">4项性能提升技术，使Spark Joins速度提高10倍</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/4-performance-improving-techniques-to-make-spark-joins-10x-faster-2ec8859138b4?source=collection_archive---------0-----------------------#2021-07-26">https://medium.com/analytics-vidhya/4-performance-improving-techniques-to-make-spark-joins-10x-faster-2ec8859138b4?source=collection_archive---------0-----------------------#2021-07-26</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a65a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Spark是一个针对大数据的闪电般快速的计算框架，支持跨机器集群的内存处理。在这篇博客中，我们将讨论spark中与JOIN操作相关的优化。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/9dddf8f2a51215088aeb8f83af2edb3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6l1I40K8YOzmd9sm6XHN7w.png"/></div></div></figure><p id="0304" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">连接两个数据集是一项繁重的操作，需要通过网络进行大量的数据移动(洗牌)，以确保具有匹配连接键的行在物理上位于同一位置(在同一节点上)。</p><p id="4295" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为spark中的数据集连接编写代码非常容易，但要使它具有高性能却很棘手，因为需要理解Spark中数据集是如何内部连接的。最近我研究了多个Spark join作业，并对它们进行了优化，使完成速度提高了10倍以上，现在我将分享我在优化Spark join方面的心得。我们首先理解join的内部结构来设置上下文。</p></div><div class="ab cl jq jr gp js" role="separator"><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv jw"/><span class="jt bw bk ju jv"/></div><div class="hb hc hd he hf"><h1 id="4809" class="jx jy hi bd jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku bi translated">流行的联接类型</h1><h2 id="a906" class="kv jy hi bd jz kw kx ky kd kz la lb kh iq lc ld kl iu le lf kp iy lg lh kt li bi translated">广播加入</h2><p id="9f5f" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">当连接中数据集的一端相当小时，这种类型的连接策略是合适的。(可以使用“火花”来配置阈值。sql。autoBroadcastJoinThreshold”，默认为10MB)。</p><p id="e8cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">考虑下面的例子，其中表A和小表B(小于10 MB)必须连接。在这种情况下，Spark驱动程序将表B广播给集群上存在表A的分区的所有节点。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lo"><img src="../Images/43ad8dda611f92025091bfec490e76b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LduMTI_GMdj4HoudMIGjww.png"/></div></div></figure><p id="aee5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，由于表B出现在我们拥有表A的数据的所有节点上，所以不再需要数据重排，表A的每个分区都可以与表B的所需条目相结合。</p><p id="bd6b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是最快的连接类型(因为较大的表不需要数据重排)，但有一个限制，即连接中的一个表必须很小。</p><h2 id="b602" class="kv jy hi bd jz kw kx ky kd kz la lb kh iq lc ld kl iu le lf kp iy lg lh kt li bi translated">排序合并联接</h2><p id="8968" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">这是标准连接类型，适用于连接两侧的数据集都是中型/大型的情况。</p><p id="7bd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种连接分三个阶段进行。</p><ol class=""><li id="5d9f" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated"><strong class="ih hj">混洗分区</strong>:该阶段输出的分区数默认值为200(可使用spark.sql.shuffle.partitions更改)。这一步的目标是以这样一种方式重组表A和表B的数据，即应该连接的行进入相同的分区标识符(要连接的数据行在物理上/在相同的节点上协同定位)。一行的分区标识符被确定为<strong class="ih hj"> <em class="ly">散列(连接键)% 200</em></strong>(spark . SQL . shuffle . partitions的值)。这是使用相同的散列函数对表A和B完成的。这会导致join列中具有相同值的所有行(在表A和表B中)在重新排列后被重新排列到同一节点(因为它们的哈希值是相同的)。这种类型的重新分区被称为<a class="ae jp" href="https://jaceklaskowski.gitbooks.io/mastering-spark-sql/content/spark-sql-HashPartitioning.html" rel="noopener ugc nofollow" target="_blank">哈希分区</a>。默认情况下，使用<em class="ly">计算散列值。java中的hashcode() </em>方法。</li><li id="700d" class="lp lq hi ih b ii lz im ma iq mb iu mc iy md jc lu lv lw lx bi translated"><strong class="ih hj">每个分区内的排序:</strong>这种排序也是基于连接键完成的。</li><li id="e328" class="lp lq hi ih b ii lz im ma iq mb iu mc iy md jc lu lv lw lx bi translated"><strong class="ih hj">连接排序后的分区</strong>:根据连接类型(INNER、LEFT等)，我们生成最终输出。这种方法类似于使用两个指针的“<a class="ae jp" href="https://www.baeldung.com/java-merge-sorted-arrays" rel="noopener ugc nofollow" target="_blank">合并两个排序数组</a>”的标准解决方案。</li></ol><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es me"><img src="../Images/5ae01bf90505b3288cdd26b5fd370294.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XGPU0-JOAo_1I3Jx_lZpgQ.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">排序合并联接</figcaption></figure><p id="96e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以使用spark UI中的SQL选项卡，找出作业中发生的连接类型。当连接两侧的数据集都很大时(或者选择了sortmerge连接)，大多数作业都会失败。我们将了解导致sortmerge join失败/缓慢的原因以及如何克服它。</p><h1 id="8694" class="jx jy hi bd jz ka mj kc kd ke mk kg kh ki ml kk kl km mm ko kp kq mn ks kt ku bi translated">最佳化</h1><p id="3fdc" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">当我们检查作业日志和失败时，会出现如下错误消息</p><pre class="je jf jg jh fd mo mp mq mr aw ms bi"><span id="8d9d" class="kv jy hi mp b fi mt mu l mv mw"><strong class="mp hj">ExecutorLostFailure</strong> (executor 235 exited unrelated to the running tasks) Reason: Container container_e327_1624530648585_229354_01_000378 on host:</span><span id="9830" class="kv jy hi mp b fi mx mu l mv mw"><strong class="mp hj">FetchFailed</strong>(BlockManagerId(76, prod-***-nm-0001, 7337, None), shuffleId=5, mapId=6477, reduceId=2,</span></pre><p id="348e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">错误信息并不意味着他们所说的，我们必须做多种优化来解决这个问题。以下是关键要点。</p><h2 id="a95b" class="kv jy hi bd jz kw kx ky kd kz la lb kh iq lc ld kl iu le lf kp iy lg lh kt li bi translated">数据偏斜度</h2><p id="4cb6" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">即使连接步骤的输入数据是统一分区的，在sortmerge连接中洗牌后产生的中间数据在新创建的分区中也可能不具有统一的数据大小。</p><p id="90a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果我们回忆一下上面的讨论，在sortmerge join的第一阶段，基于连接键对数据进行散列，并为其决定一个新的分区。如果我们在连接列中有一个非均匀分布的值，那么我们将在数据洗牌后产生一个倾斜的分区。</p><p id="2a51" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">示例:</p><p id="c06c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">假设我们必须将下表与基于searchSessionId列的任何其他表连接起来。(我们看到大部分数据都有空值，这意味着所有空的searchSessionId行将散列到相同的值，导致它们在洗牌步骤后都进入相同的分区)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es my"><img src="../Images/86a50490fffcffd8e07a3ec7b05bad75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AanTjz2gGpNDFruqzxMQqA.png"/></div></div></figure><p id="24e5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，我们会看到大多数任务完成得非常快，而一项任务需要很长时间才能完成。对于与另一个数据集连接的上述数据，下图显示了每个混洗分区的处理时间。我们看到大多数分区的处理速度非常快，单个分区花费了很长时间，这表明为连接而产生的混洗分区存在偏斜(由于连接键的值分布存在偏斜)。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mz"><img src="../Images/b2d74843edd55fd3ad82c948d57b5503.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GS1x8EWbsLNa95VDqOrjVA.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">数据偏斜导致连接缓慢</figcaption></figure><p id="a0af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通常，连接列中的不均匀分布会导致这种偏斜。(例如，值x在下面的第一个表中非常频繁，所有这些行在洗牌后都进入一个分区)。数据偏斜是连接失败/缓慢的最常见原因。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es na"><img src="../Images/1ef5621697da2e2b951ec2d70b1543cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0gwdqYu4JfpNAae5W2w2Hg.png"/></div></div></figure><p id="c3f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">处理数据偏斜度</strong></p><p id="686c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">a) <strong class="ih hj">将A和B的join</strong>替换为:<strong class="ih hj"><em class="ly">(</em></strong><em class="ly">)(A其中联接列为非空)join with(B))UNION with(A其中联接列为空</em> <strong class="ih hj"> <em class="ly"> ) </em> </strong>。这适用于除空值之外，联接列中的其他值均匀分布的情况。b)中讨论了一种更通用的方法。</p><p id="2e4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b) <strong class="ih hj">向连接列添加随机数:</strong>这里我们向连接键添加一些随机值，使其分布。</p><p id="33f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在表A中(有偏斜度):用一些字符连接，并在范围(1，3)中附加一些随机数。key -&gt; key+"_"+random(1，3)</p><p id="f523" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在表B中(具有均匀分布):将一行分解成三行，其中的连接键是x_1、x_2和x_3。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nb"><img src="../Images/b9289af60e68551bd7cc800c85167e80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1uTZSXncUZwba7vIhQqv6g.png"/></div></div></figure><p id="2a83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">发布此消息后，我们看到所有分区的大小都是一致的，因为现在新的连接列中没有偏斜，并且连接完成得更快。</p><p id="d8cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是帮助我们实现这一点的代码片段。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nc nd l"/></div></figure><h2 id="6ccf" class="kv jy hi bd jz kw kx ky kd kz la lb kh iq lc ld kl iu le lf kp iy lg lh kt li bi translated">保持输入数据精简</h2><p id="5fcb" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">如果联接变得太慢，请从数据中删除联接后不需要的列。将这些中间数据写到某个地方，并在join步骤中将其作为输入读取。这将减少数据洗牌过程中通过网络传输的数据量。</p><p id="f3c0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，过滤掉联接后可能不需要的任何行。</p><h2 id="f67e" class="kv jy hi bd jz kw kx ky kd kz la lb kh iq lc ld kl iu le lf kp iy lg lh kt li bi translated">将大连接拆分成多个较小的连接</h2><p id="3695" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">如果有办法在不影响功能的情况下将输入数据分割成较小的批，那么可以尝试以较小的批进行连接。在我们的例子中，我们连接了UUID场的两个数据集。两个数据集都有一个时间戳列。因此，我们没有连接全天数据，而是将一天分成多个时间段，只连接每个数据的相应时间段。我们有了这个想法，因为当我们连接全天数据时，需要2-3天才能完成，但对25%的数据进行采样，可以在1-2小时内完成连接，这表明较小的连接速度更快。</p><p id="5e2e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是将一个大连接分解成多个小连接(基于时间戳)的示例代码片段。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="nc nd l"/></div></figure><h2 id="3133" class="kv jy hi bd jz kw kx ky kd kz la lb kh iq lc ld kl iu le lf kp iy lg lh kt li bi translated">作业参数调整</h2><p id="b0e7" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">以下是我们可以增加的重要参数。(如果您有上述任何基本问题，这可能没有多大帮助)。</p><pre class="je jf jg jh fd mo mp mq mr aw ms bi"><span id="cd8a" class="kv jy hi mp b fi mt mu l mv mw">executor-memory, spark.executor.memoryOverhead, spark.sql.shuffle.partitions, executor-cores, num-executors</span></pre><h1 id="dd71" class="jx jy hi bd jz ka mj kc kd ke mk kg kh ki ml kk kl km mm ko kp kq mn ks kt ku bi translated"><strong class="ak">结论</strong></h1><p id="4bd3" class="pw-post-body-paragraph if ig hi ih b ii lj ik il im lk io ip iq ll is it iu lm iw ix iy ln ja jb jc hb bi translated">通过上述优化，我们能够将工作性能提高10倍以上。</p><p id="f48f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总结我们在博客中讨论的关键问题。</p><ol class=""><li id="6296" class="lp lq hi ih b ii ij im in iq lr iu ls iy lt jc lu lv lw lx bi translated">内部加入是如何发生的。广播联接与排序合并联接。</li><li id="42dc" class="lp lq hi ih b ii lz im ma iq mb iu mc iy md jc lu lv lw lx bi translated">为什么会发生数据偏斜(在输入数据中，而在输入数据分区中没有偏斜，但由于连接前的哈希分区而导致)</li><li id="c103" class="lp lq hi ih b ii lz im ma iq mb iu mc iy md jc lu lv lw lx bi translated">处理数据偏斜</li><li id="e8be" class="lp lq hi ih b ii lz im ma iq mb iu mc iy md jc lu lv lw lx bi translated">保持输入数据尽可能精简</li><li id="01fb" class="lp lq hi ih b ii lz im ma iq mb iu mc iy md jc lu lv lw lx bi translated">将大连接拆分成多个小连接</li><li id="106b" class="lp lq hi ih b ii lz im ma iq mb iu mc iy md jc lu lv lw lx bi translated">为join调整spark作业参数</li></ol><p id="a961" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据偏斜是连接失败/缓慢的主要原因。对于任何其他<a class="ae jp" href="https://learning.oreilly.com/library/view/apache-spark-quick/9781789349108/0ee1a5e2-09d0-49f0-99f5-9dee8336258d.xhtml" rel="noopener ugc nofollow" target="_blank">范围的转换</a>也是如此(如distinct()、reduceBykey()等)，类似的数据重排在开始时发生，将具有相同哈希值的键带到相同的分区。</p><p id="a999" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢阅读！欢迎任何意见或建议！</p><p id="a222" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">联系方式:<a class="ae jp" href="https://www.linkedin.com/in/suryakant-pandey/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>，<a class="ae jp" href="https://www.instagram.com/pd.skant/" rel="noopener ugc nofollow" target="_blank"> Instagram </a></p></div></div>    
</body>
</html>