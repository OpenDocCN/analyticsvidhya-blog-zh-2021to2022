<html>
<head>
<title>Word Count using MapReduce on Hadoop</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Hadoop上使用MapReduce进行字数统计</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/word-count-using-mapreduce-on-hadoop-6eaefe127502?source=collection_archive---------0-----------------------#2021-03-24">https://medium.com/analytics-vidhya/word-count-using-mapreduce-on-hadoop-6eaefe127502?source=collection_archive---------0-----------------------#2021-03-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="597e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您是否有大量的文本数据需要他们统计每个单词的出现次数？如果是的话，你已经有了Hadoop来处理你的“大数据”。</p><p id="e80a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们将尝试在Hadoop上运行MapReduce来解决字数问题。所以不再浪费时间，让我们开始吧。</p><p id="cb9f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">开始前我们需要关心的事情？</p><p id="564f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 1。Oracle VM VirtualBox: <br/> </strong>在本地安装Hadoop可能会很痛苦，而且大多数时候，如果不小心安装，很可能会出错。因此，我们将使用预先安装了Hadoop的Cloudera Quickstart虚拟机实例，然后<em class="jc">睡个安稳觉。</em></p><p id="d23b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你已经安装了VirtualBox，你就可以开始下一步了。如果没有，从这里的<a class="ae jd" href="https://www.virtualbox.org/wiki/Downloads" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">下载。</strong> </a></p><p id="b543" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">注意:</strong>最好安装VirtualBox 6 . 1 . 18版，以免出现任何问题。这个程序在这个版本上进行了测试，运行得非常完美。</p><p id="0ae1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。Cloudera Quickstart VM 5.4.2:<br/></strong>从<a class="ae jd" href="https://cutt.ly/UxYeKku" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">此</strong> </a>链接下载cloud era quick start VM 5 . 4 . 2。它是一个预装了Hadoop的虚拟机实例。</p><p id="715b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下载完成后，解压。zip文件，并将<strong class="ig hi">cloud era-quick start-VM-5 . 4 . 2–0-virtualbox . OVF</strong>文件作为“设备”导入VirtualBox。</p><p id="9975" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为此，请打开VirtualBox单击菜单栏上的文件，并选择导入设备选项。浏览至提取Cloudera Quickstart虚拟机的位置。</p><p id="de39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">根据您的需要配置设置，或者保持默认设置不变。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/d0a9e9df50ea0aa2445c2456e60abc46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2IYV3ZWLR-EkCnOlWeVhzw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">Oracle VM VirtualBox</figcaption></figure><p id="6205" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果一切都配置和设置成功，我们现在可以玩实际的游戏了。</p><p id="59e8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第一步:</strong>在VirtualBox上打开Cloudera Quickstart VM。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ju"><img src="../Images/52581230733687ada3a09472cb2a85ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8EVqKSFTi9PSjeezzVduqQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">Cloudera快速启动虚拟机</figcaption></figure><p id="c118" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">步骤2: </strong>在<strong class="ig hi"> /home/cloudera </strong>目录下创建一个. txt数据文件，该文件将作为输入传递给MapReduce程序。为简单起见，我们将其命名为<strong class="ig hi"> word_count_data.txt. </strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jv"><img src="../Images/4fff193df10d82389b3059701a48cb8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qeDfwkLbA5MuDowuRwJqjQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">文本数据文件</figcaption></figure><p id="98c5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Ritson是我的朋友。:)</p><p id="9204" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第三步:</strong>在<strong class="ig hi"> /home/cloudera </strong>目录下创建映射器和缩减器文件。</p><p id="6aaa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可以从下面的GitHub库中获得它们。<br/><strong class="ig hi"><br/></strong>a)<a class="ae jd" href="https://github.com/NSTiwari/Hadoop-MapReduce-Programs/blob/main/WordCount/mapper.py" rel="noopener ugc nofollow" target="_blank">mapper . py</a><br/>b)<a class="ae jd" href="https://github.com/NSTiwari/Hadoop-MapReduce-Programs/blob/main/WordCount/reducer.py" rel="noopener ugc nofollow" target="_blank">reducer . py</a></p><p id="5e7f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第四步:</strong>在Hadoop上运行之前，在本地测试MapReduce程序，检查一切是否正常。</p><p id="322b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Cloudera Quickstart VM实例上打开终端并运行以下命令:<br/><strong class="ig hi">cat word _ count _ data . txt | python mapper . py | sort-k 1，1 | python reducer.py </strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jw"><img src="../Images/6d6a9aa6a528f7bc217eb4193df65f00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_HO0ZlwBubsiaJ5VeFHFTQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">MapReduce的本地检查</figcaption></figure><p id="aac5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于上面的例子，获得的输出与预期的完全一样。<br/>如果你看到所有的单词都被正确地映射、排序并减少到各自的数量，那么你的程序就可以在Hadoop上测试了。</p><p id="ce94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第五步:</strong>配置Hadoop服务和设置。</p><p id="4f1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，在运行MapReduce程序进行字数统计之前，我们需要在Hadoop上配置某些设置。</p><p id="7015" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 5a:登录Cloudera Manager <br/> </strong>在Cloudera Quickstart VM上打开浏览器，并通过输入用户名和密码作为<em class="jc"> cloudera </em>的凭证打开<strong class="ig hi">quickstart.cloudera:7180/cmf/login.</strong>登录。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jx"><img src="../Images/657a1997c7dcc01a2eea7b2f75ec9c26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qRCnuwqulFnutzBc-3xfeA.png"/></div></div></figure><p id="81ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">注意:</strong>如果您在登录<strong class="ig hi">quickstart.cloudera:7180/cmf/login</strong>时看到错误<em class="jc">“无法连接”</em>，请尝试重启CDH服务。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/913590a92e36723fa9a03be1e8c29a04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q1mehLZwDqcfAL9yVhofUg.png"/></div></div></figure><p id="b468" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过键入以下命令重新启动CDH服务:<br/><strong class="ig hi">sudo/home/cloud era/cloud era-manager-express-force</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jy"><img src="../Images/44d4607b9d1cb92b3c675edc4d99b646.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gsrznl18RunJI6PB7YyBXg.png"/></div></div></figure><p id="7300" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 5b:开始HDFS和纱线服务。<br/> </strong>点击下拉箭头，选择<em class="jc">开始</em>选项，用于HDFS和纱线服务。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jz"><img src="../Images/bfcee7b50ac2c8a0a136e70c05527020.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fdhq2aBhGmsSU_xgnwz02g.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">开始HDFS和纱线服务</figcaption></figure><p id="e5b1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果两者都有，您将看到以下内容；HDFS和纱线服务成功启动。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ka"><img src="../Images/acc4a17325a1de640f68b5fcf5398bf8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ryx9k6mEDmK4Aeb3cuOpSg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">HDFS服务成功启动</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kb"><img src="../Images/21cc14288040fef7d0775d6dde33fcc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UiSe7F-21QNzsh1d6VcA_g.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">纱线服务成功启动</figcaption></figure><p id="90e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第六步:在HDFS上创建一个目录</p><p id="404e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们在HDFS上创建一个名为<strong class="ig hi"> word_count_map_reduce </strong>的目录，我们的输入数据及其结果输出将存储在这里。</p><p id="182b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用下面的命令。<br/><strong class="ig hi">sudo-u HDFS Hadoop fs-mkdir/word _ count _ map _ reduce</strong></p><p id="4ecb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">注意:</strong>如果目录已经存在，则使用以下命令创建一个新目录或删除现有目录。</p><p id="c6c9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">导出HADOOP _ USER _ NAME = HDFS<br/>HDFS DFS-rmr/word _ count _ map _ reduce</strong></p><p id="e79b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用以下命令列出HDFS目录项。<br/> <strong class="ig hi"> hdfs dfs -ls / </strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es jw"><img src="../Images/8120e3f2b62b9fc528493975522e189a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bCPuECmXaUclkf6UaoKO0g.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">删除/创建HDFS上的目录</figcaption></figure><p id="9293" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">步骤7: </strong>将输入的数据文件复制到HDFS上。</p><p id="ada8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用以下命令将word_count_data.txt文件复制到HDFS上的<strong class="ig hi"> word_count_map_reduce </strong>目录。</p><p id="227a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">sudo-u HDFS Hadoop fs-put/home/cloud era/word _ count _ data . txt/word _ count _ map _ reduce</strong></p><p id="0828" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">检查文件是否成功复制到所需位置。<br/><strong class="ig hi">HDFS DFS-ls/word _ count _ map _ reduce</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/21432785a71ccfa64a5b5d9f61b0d1fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E4zT2ZZCKDkDKLPZbSMUiQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">HDFS上的输入文件复制成功</figcaption></figure><p id="b480" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第八步:</strong>下载hadoop-streaming JAR 2.7.3。</p><p id="0ec3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在虚拟机上打开浏览器，进入<a class="ae jd" href="https://jar-download.com/artifacts/org.apache.hadoop/hadoopstreaming/2.7.3/source-code" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">这个</strong> </a> <strong class="ig hi"> </strong>链接，下载hadoop-streaming JAR 2.7.3文件。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/7e352ff103eaf413975f296a2860aa37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uoZ5AU2cBsWgvhKTXQ3ohg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">下载Hadoop-流JAR 2.7.3</figcaption></figure><p id="a0c9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">文件下载完成后，将其解压到<strong class="ig hi"> /home/cloudera </strong>目录下。仔细检查JAR文件是否解压成功，是否存在于<br/> <strong class="ig hi"> /home/cloudera </strong>目录中。</p><p id="c8d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> ls </strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/32fbff15f768090e343e0f6445fe2abb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NRGXB5iQb921DLHXdTcwDA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">hadoop-streaming-2.7.3.jar下载成功</figcaption></figure><p id="48e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第9步:</strong>在Hadoop上配置运行MapReduce的权限。</p><p id="cd8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们几乎已经准备好在Hadoop上运行MapReduce作业，但在此之前，我们需要授予在Hadoop上读取、写入和执行Mapper和Reducer程序的权限。</p><p id="6a74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还需要为默认用户(cloudera)提供在HDFS内部编写输出文件的权限。</p><p id="2875" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为此，请运行以下命令:</p><p id="4cb9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">chmod 777 mapper . py reducer . py<br/>sudo-u HDFS Hadoop fs-chown cloud era/word _ count _ map _ reduce</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/b7d6f6664390812058324d49898f6334.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m9ppYlaZQ5Ghw4pgL3vArA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">授予在HDFS上读取、写入和执行文件的权限</figcaption></figure><p id="288c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">第十步:</strong>在Hadoop上运行MapReduce。</p><p id="f857" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们正处于这个项目的最后一步。使用以下命令在Hadoop上运行MapReduce作业。</p><p id="3629" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">Hadoop jar/home/cloud era/Hadoop-streaming-2 . 7 . 3 . jar \<br/>&gt;-input/word _ count _ map _ reduce/word _ count _ data . txt \<br/>&gt;-output/word _ count _ map _ reduce/output \<br/>&gt;-mapper/home/cloud era/mapper . py \<br/>&gt;-reducer/home/cloud era/reducer . py</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kc"><img src="../Images/04bee69e5beb80fcf07cd3a2b0952ad1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UdDcMWHlUcwA4XtOc9REQg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">为MapReduce执行Hadoop流</figcaption></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kd"><img src="../Images/867f1d9c403696224cae711493493e44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cduKIKvyWh4otHlK4xAeJQ.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">MapReduce作业已执行</figcaption></figure><p id="6a58" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果您在终端上看到如上两幅图所示的输出，那么MapReduce作业执行成功。</p><p id="15a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">步骤11: </strong>读取MapReduce输出。</p><p id="9a64" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，最后运行下面的命令来读取MapReduce的输出，以计算您创建的输入数据文件的字数。</p><p id="9a56" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">HDFS DFS-cat/word _ count _ map _ reduce/output/part-00000</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ke"><img src="../Images/c2e4a8975473192dc1ac0fe5d7312d30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uzpi-PKcQgQwkVUuoj6UFg.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">Hadoop上的MapReduce输出</figcaption></figure><p id="d04e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">恭喜您，Hadoop上MapReduce的输出完全符合预期。输入数据文件中的所有单词已经被映射、排序并减少到它们各自的计数。</p><p id="9db2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想在这方面谈得更多，请随时通过LinkedIn与我联系。到那时，再见。</p></div></div>    
</body>
</html>