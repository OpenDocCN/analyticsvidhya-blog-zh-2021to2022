<html>
<head>
<title>Everything You Need to Know About Linear Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">关于线性回归你需要知道的一切</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/everything-you-need-to-know-about-linear-regression-750a69a0ea50?source=collection_archive---------3-----------------------#2021-01-08">https://medium.com/analytics-vidhya/everything-you-need-to-know-about-linear-regression-750a69a0ea50?source=collection_archive---------3-----------------------#2021-01-08</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="b912" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">线性回归</em> </strong> <em class="jd">是现实生活中机器学习问题中使用最广泛的人工智能算法之一——这要归功于它的简单性、可解释性和速度！在接下来的几分钟里，我们将了解这个算法背后的工作原理！</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/afc62ebc6dcd53b774f490a83b5cab76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MkEov3K6UUjhuwOd.jpeg"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">来源:谷歌图片</figcaption></figure><h1 id="54d3" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">什么是线性回归？</h1><p id="cea9" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">线性回归</em> </strong>试图通过将<strong class="ih hj">线性</strong>方程拟合到观察到的数据来模拟两个变量之间的关系。一个变量被认为是<em class="jd">解释变量</em>或<em class="jd">自变量</em>，另一个被认为是<em class="jd">因变量—来源:</em><a class="ae kx" href="http://www.stat.yale.edu/Courses/1997-98/101/linreg.htm#:~:text=Linear%20regression%20attempts%20to%20model,to%20be%20a%20dependent%20variable." rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="jd">Yale.edu</em></strong></a></p><h1 id="de91" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">线性回归的应用和方法</h1><h2 id="77e2" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">商业应用</h2><p id="2f79" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">线性回归用于各种商业预测问题:</em> </strong></p><ol class=""><li id="f7a4" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated"><em class="jd">股票预测</em></li><li id="30d6" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><em class="jd">预测未来价格/成本</em></li><li id="0aab" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><em class="jd">预测未来收入</em></li><li id="ea7c" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><em class="jd">新产品性能对比</em></li></ol><h2 id="0bac" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">线性回归的好处</h2><ol class=""><li id="d7bf" class="lm ln hi ih b ii ks im kt iq ma iu mb iy mc jc lr ls lt lu bi translated"><em class="jd">缓解</em></li><li id="4bc0" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><em class="jd">可解释性</em></li><li id="a1b1" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><em class="jd">可扩展性</em></li><li id="225d" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><em class="jd">在线设置部署良好</em></li></ol><h2 id="0d81" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">线性回归的机器学习方法</h2><ol class=""><li id="29f9" class="lm ln hi ih b ii ks im kt iq ma iu mb iy mc jc lr ls lt lu bi translated"><em class="jd">简单和多元线性回归</em></li><li id="c651" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><em class="jd">多项式回归</em></li><li id="450a" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><em class="jd">岭回归和套索回归(线性回归的升级)</em></li><li id="4f44" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><em class="jd">决策树回归</em></li><li id="6d24" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><em class="jd">支持向量回归</em></li></ol><h2 id="f329" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">通俗地说就是线性回归</h2><blockquote class="md me mf"><p id="f56a" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">你可以把线性回归看作是问题<strong class="ih hj">“我如何用X来预测Y？”</strong>，其中X是你有的一些信息，Y是你想知道的一些信息。</p></blockquote><p id="b6a7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">我们来看下面这个经典的例子——</em></strong><a class="ae kx" href="https://www.keboola.com/blog/linear-regression-machine-learning" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj"><em class="jd">来源</em> </strong> </a></p><p id="b690" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可能想卖掉你的房子，并且你有关于那栋房子的<em class="jd">卧室数量</em> <strong class="ih hj"> <em class="jd"> (X) </em> </strong>的信息，在这里，关键是找到房子的<em class="jd">价格</em><strong class="ih hj"><em class="jd">【Y】</em></strong>。</p><blockquote class="md me mf"><p id="f733" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">线性回归创建了一个方程，其中输入给定的数字(X ),输出想要找出的目标变量(Y)。</p></blockquote><p id="f2df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，我们将使用包含房屋购买历史记录的数据集，其形式为<strong class="ih hj"> <em class="jd">(“卧室数量”、“售价”)</em> </strong>:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mj"><img src="../Images/bf091a0cda07250c9d4dc890d11bbbd0.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*qPG52Y4tneQaF-F_11zuRQ.png"/></div></figure><blockquote class="md me mf"><p id="899f" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">现在让我们将相同的数据可视化</p></blockquote><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mk"><img src="../Images/ce0eb0317bdf32c9e86ab417430cb434.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mrMgUFWlX-YsgBrM.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated"><strong class="bd jw">X轴<strong class="bd jw">上的卧室数量</strong>X轴</strong>和Y轴<strong class="bd jw">上的<strong class="bd jw">售价</strong></strong></figcaption></figure><blockquote class="md me mf"><p id="d695" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">看散点图，似乎有一个趋势:一个房子的卧室越多，它的售价越高(老实说，这并不奇怪)。</p></blockquote><p id="742d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，假设我们训练了一个线性回归模型来得到一个如下形式的方程:</p><p id="4f01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">售价= 77143 *(卧室数量)—74286</em></p><blockquote class="md me mf"><p id="3832" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">这个等式起到了预测的作用。如果你输入卧室的数量，你会得到房子出售价格的预测值。</p></blockquote><p id="cf06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于上面的具体例子:</p><p id="e79c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">你的售价= 77143 *两间卧室——74286 = 8万</em></p><p id="3505" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">换句话说，你可以以大约8万美元的价格卖掉你的两居室。但是线性回归不仅仅如此。我们也可以把它形象化，看看不同卧室数量的房子的价格是多少</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ml"><img src="../Images/73392d39c5f9f01983708d8e59e65999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NuDkPJUZLDpIjfoF.png"/></div></div></figure><blockquote class="md me mf"><p id="bbec" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">这是因为线性回归试图找到一条<strong class="ih hj">最符合数据</strong>的直线。线性回归不仅限于房地产问题:它还可以应用于各种业务用例。</p></blockquote><h1 id="088f" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">数学解释</h1><h2 id="d670" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">简单线性回归</h2><p id="d415" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">线性回归是如此有用和成熟的算法，它既是一个统计模型，也是一个机器学习模型。在这里，我们将主要关注机器学习方面，但我们也将绘制一些与统计学类似的东西，以便描绘一幅完整的画面。</p><p id="79bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦定型，该模型就采取这种类型的线性回归方程的形式:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mm"><img src="../Images/f7319a362a9bc272f6ec0131ade4320c.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/0*NuhB9DklbPcAM8R0.png"/></div></figure><p id="037f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">等式中的术语— </em> </strong></p><ul class=""><li id="27ef" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc mn ls lt lu bi translated"><strong class="ih hj"> <em class="jd"> y </em> </strong>是输出变量。在机器学习中又称为<em class="jd">目标变量</em>，或者在统计建模中称为<em class="jd">因变量</em>。它代表了我们试图预测的连续值。</li><li id="a8a8" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc mn ls lt lu bi translated"><strong class="ih hj"> <em class="jd"> x </em> </strong>是输入变量。在机器学习中，x被称为<em class="jd">特征</em>，而在统计学中，它被称为<em class="jd">自变量</em>。它代表了在任何给定时间给我们的信息。</li><li id="2a09" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc mn ls lt lu bi translated"><strong class="ih hj"> <em class="jd"> w0 </em> </strong>是<em class="jd">偏置项</em>或y轴截距。</li><li id="0d91" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc mn ls lt lu bi translated"><strong class="ih hj"> <em class="jd"> w1 </em> </strong>是<em class="jd">回归系数</em>或比例因子。在经典统计学中，它相当于线性回归模型拟合后产生的最佳拟合直线上的斜率。</li><li id="fb9c" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc mn ls lt lu bi translated"><strong class="ih hj"> <em class="jd"> wi </em> </strong>统称为<em class="jd">砝码</em>。</li></ul><blockquote class="md me mf"><p id="830b" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">回归分析(建模)的目标是找到方程中未知参数的值；也就是说，为了找到权重w0和w1的值</p></blockquote><h2 id="e2f4" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">多元线性回归</h2><p id="9447" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">简单和多重线性回归都假设输入变量和输出目标变量之间存在线性关系。</p><p id="cb78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">主要的区别是它们作为输入的独立变量的数量。简单线性回归只取单个特征，多元线性回归取多个x值。对于具有n个输入变量的模型，上述公式可以改写为:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mo"><img src="../Images/71428f56010fab084ed609ceda637b18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CgRlGzMd9aBSsaLr.png"/></div></div></figure><blockquote class="md me mf"><p id="6acb" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">其中xi <em class="hi"> </em>是第I个特征，具有自己的wi权重。</p></blockquote><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mp"><img src="../Images/ba4433f5172716634044db28210c2873.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9j_cDqBP3lHrtBwz.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">图片来源:Keboola</figcaption></figure><blockquote class="md me mf"><p id="55ca" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">简单线性回归模型可以用图形表示为数据点之间的最佳拟合线，而多元线性回归模型可以表示为<strong class="ih hj">平面(二维)</strong>或<strong class="ih hj">超平面(高维)。</strong></p></blockquote><p id="8359" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管存在差异，简单回归模型和多元回归模型都是线性模型——它们采用线性方程的形式。这就是所谓的线性假设。</p><blockquote class="md me mf"><p id="abf4" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">很简单，这意味着我们假设独立变量和独立特征之间的关系类型是线性的。</p></blockquote><h1 id="0386" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">训练LR模型</h1><p id="0a6a" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">我们用一种叫做<strong class="ih hj"> <em class="jd">普通最小二乘法</em></strong>—<strong class="ih hj"><em class="jd">OLS</em></strong>(或者就是最小二乘法)的方法来训练线性回归算法。训练的目标是找到线性方程<strong class="ih hj"> <em class="jd"> y = wo + w1x中的权重wi。</em> </strong></p><ol class=""><li id="191d" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated">随机权重初始化。实际中，w0和w1在开始时是未知的。该过程的目标是为这些模型参数找到合适的值。为了开始这个过程，我们随机设置权重值，或者初始化为0。</li></ol><blockquote class="md me mf"><p id="8f00" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">还有其他数学上的正当性如<strong class="ih hj"> Xavier初始化</strong>等。</p></blockquote><p id="e790" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.将初始化的权重输入到线性方程中，并为每个观测点生成预测。</p><p id="342c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.计算<strong class="ih hj"><em class="jd"/></strong><em class="jd">(RSS)。残差，或误差项</em>，是每个<strong class="ih hj"><em class="jd"/></strong>和<strong class="ih hj"> <em class="jd">预测输出</em> </strong>之间的差值。</p><blockquote class="md me mf"><p id="3a1e" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">它们是对我们的回归函数预测输出与真实值相比有多好的逐点估计。我们通过计算每个观测值的<em class="hi">实际值——预测值</em>来获得残差。</p></blockquote><p id="6a09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们<strong class="ih hj"> <em class="jd">对每个观察点的残差</em> </strong> <em class="jd">求平方，并对残差求和以达到我们的RSS。</em></p><p id="0160" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里的基础是，较低的RSS  意味着我们的<strong class="ih hj"> <em class="jd">最佳拟合线</em> </strong>更接近每个数据点，反之亦然。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es mq"><img src="../Images/7e39e51abbea362c8a2589befd8e319f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/format:webp/0*YlKbA3VwEfKzbQOk.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">实际值(蓝点)越接近回归线(红线)越好。</figcaption></figure><p id="4e30" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.最小化RSS的模型参数选择。机器学习方法通过定义<em class="jd">成本函数</em>和<em class="jd">经由<strong class="ih hj"> <em class="jd">梯度下降最小化</em>来寻找线性模型的最佳参数。</strong></em> </p><blockquote class="md me mf"><p id="3927" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">通过这样做，我们获得了权重的最佳可能值。</p></blockquote><h2 id="3d2e" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">价值函数</h2><p id="6dc6" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在线性回归的情况下，成本函数与误差的残差和相同。该算法解决了最小化问题，并使用<strong class="ih hj"> <em class="jd">梯度下降来实现。</em> </strong></p><h2 id="9458" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">梯度下降</h2><p id="d399" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">梯度下降是一种根据每个数据点的损失函数改变权重的方法。我们计算每个输入输出数据点的误差平方和。我们对<em class="jd">权重</em>和<em class="jd">偏差</em>取<em class="jd">偏导数</em>，得到每一点的成本函数的<em class="jd">斜率。</em></p><blockquote class="md me mf"><p id="96d0" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">基于斜率，梯度下降更新该组权重和偏差的值，并在新值上重复训练循环(向期望的目标靠近一步)。</p></blockquote><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mr"><img src="../Images/69fd942bc4a3b520e6618131034fc726.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*QFw7axayhPWBkVO1.jpeg"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">图片来源:Morioh——渐变下降图解</figcaption></figure><p id="1ad1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">重复该迭代方法，直到达到最小误差，并且梯度下降不能进一步最小化成本函数，它取决于各种超参数，其中一个关键参数是<strong class="ih hj"> <em class="jd">学习速率</em> </strong>。</p><blockquote class="md me mf"><p id="3c19" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated"><strong class="ih hj">学习率</strong>是指每次迭代时参数变化的程度。如果学习率太高，模型无法收敛，并从好的成本优化跳到坏的成本优化。如果学习率太低，模型将需要太长时间才能收敛到最小误差。</p></blockquote><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ms"><img src="../Images/01a3861fca3ff9ac86628305ba6ee88c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*OnrnDOEgcKHBglTu.png"/></div><figcaption class="jq jr et er es js jt bd b be z dx translated">图片来源:ka ggle——学习率图解</figcaption></figure><h1 id="46bc" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">评估我们的模型</h1><p id="940d" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">我们如何评价我们模型的准确性？</em>T45】</strong></p><blockquote class="md me mf"><p id="3fe4" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">首先，您需要确保在训练数据集上训练模型，并在测试集上构建评估指标，以避免过度拟合。之后，您可以检查几个评估指标来确定您的模型执行得有多好。</p></blockquote><p id="7046" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">评价拟合优度有多种度量:</em> </strong></p><p id="defd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">均方误差</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mt"><img src="../Images/d5dfb81738bf64073d712ae0a6b8d8b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*01xotnBFfdXsN43PixOvTw.png"/></div></figure><p id="af02" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">MSE的计算方法是RSS除以数据点的总数，即给定数据集中的观察值或样本的总数。MSE告诉我们每个数据点的平均RSS是多少。</p><p id="d292" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">均方根误差(RMSE) </strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mu"><img src="../Images/c53da8b668cb11b76b9af94a98203f6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/0*_bIUCmwyUEq68vEB.png"/></div></figure><p id="e5ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">RMSE采用MSE值，并对其应用平方根。RMSE可以直接用来解释我们的预测模型产生的“平均误差”。</p><p id="db79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> R2或R平方或R2分数</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es mv"><img src="../Images/ef8cfd0a4ba80806bc9ea628715ebc9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*hSeq0IodE7N2hi4tEX_zng.png"/></div></figure><p id="7846" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">r平方是对线性函数所占因变量方差的度量。</p><blockquote class="md me mf"><p id="98db" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">一旦我们训练和评估了我们的模型，我们就改进它以做出更准确的预测。</p></blockquote><h1 id="7039" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">改进我们的模型</h1><p id="0273" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated"><em class="jd">有多种方法可以改善你的线性回归模型。</em></p><h2 id="5cb8" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">数据预处理</h2><p id="801d" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">正确地<strong class="ih hj"> <em class="jd">清理您的数据</em> </strong>会对您的建模产生最大的改进。</p><p id="05c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">确保:</em></p><ol class=""><li id="6f87" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated"><strong class="ih hj"> <em class="jd">清除异常值:</em> </strong>异常值在定量反应y倾斜线的斜率不成比例。移除它们以获得更合适的线条。</li><li id="5646" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><strong class="ih hj"> <em class="jd">移除多重共线性:</em> </strong>为所有要素创建一个<em class="jd">相关矩阵</em>，以检查哪些要素对具有高相关性。删除这些功能，只保留一个。</li><li id="679f" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><strong class="ih hj"> <em class="jd">断言正态分布:</em> </strong>模型假设自变量遵循一个<strong class="ih hj"> <em class="jd">高斯分布</em> </strong>。如果变量不是正态分布的，则使用对数变换对其进行变换。</li><li id="5c2e" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><strong class="ih hj"> <em class="jd">断言线性假设:</em> </strong>如果你的自变量与你的预测变量没有线性关系，对数变换它们，将多项式关系重塑为线性。</li></ol><blockquote class="md me mf"><p id="56ce" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">欲了解更多关于<strong class="ih hj">概率分布</strong>的信息，请参考—<a class="ae kx" rel="noopener" href="/datadriveninvestor/mathematics-for-machine-learning-part-5-8df72392ec10">https://medium . com/datadriveninvestor/mathematics-for-machine-learning-part-5-8df 72392 ec10</a></p></blockquote><h2 id="790d" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">特征缩放</h2><p id="080c" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">特征可以有不同的数量级。随着梯度下降，不同比例的要素转换较慢(或根本不转换)。</p><p id="665d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae kx" href="https://www.kdnuggets.com/2020/04/data-transformation-standardization-normalization.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> <em class="jd">将</em> </strong> </a>你的特征正常化、标准化，以加快和改善模型训练。</p><h2 id="c648" class="ky jv hi bd jw kz la lb ka lc ld le ke iq lf lg ki iu lh li km iy lj lk kq ll bi translated">正规化</h2><p id="1159" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">正则化<em class="jd">(通常不用于简单回归)</em>可以认为是一种<strong class="ih hj"> <em class="jd">特征选择方法。</em> </strong></p><blockquote class="md me mf"><p id="2a16" class="if ig jd ih b ii ij ik il im in io ip mg ir is it mh iv iw ix mi iz ja jb jc hb bi translated">由此对拟合优度贡献较低的特征被移除和/或减弱其效果，而重要的特征被强调。</p></blockquote><p id="c5f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在线性回归设置中，有两种常用的正则化技术:</p><ol class=""><li id="9117" class="lm ln hi ih b ii ij im in iq lo iu lp iy lq jc lr ls lt lu bi translated"><a class="ae kx" href="https://www.geeksforgeeks.org/lasso-vs-ridge-vs-elastic-net-ml/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> <em class="jd">【套索】L1回归</em></strong></a>-使用惩罚项来移除对整体模型性能影响不大的预测变量</li><li id="1352" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><a class="ae kx" href="https://www.geeksforgeeks.org/lasso-vs-ridge-vs-elastic-net-ml/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> <em class="jd">岭L2回归</em></strong></a><strong class="ih hj"><em class="jd"/></strong>-使用惩罚项降低预测变量的影响(但不移除特征)</li></ol><h1 id="d313" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">初学者的挑战</h1><ol class=""><li id="3e45" class="lm ln hi ih b ii ks im kt iq ma iu mb iy mc jc lr ls lt lu bi translated"><a class="ae kx" href="https://www.kaggle.com/rsadiq/salary" rel="noopener ugc nofollow" target="_blank"> <em class="jd">根据多年工作经验预测薪资</em> </a></li><li id="2624" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><a class="ae kx" href="https://www.kaggle.com/poojarangi/annual-food-imports-to-us" rel="noopener ugc nofollow" target="_blank"> <em class="jd">根据历史数据建立美国食品进口的经济预测</em> </a></li><li id="d7d5" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><a class="ae kx" href="https://www.kaggle.com/ashydv/advertising-dataset" rel="noopener ugc nofollow" target="_blank"> <em class="jd">比较不同的广告渠道如何影响总销售额</em> </a></li><li id="b65b" class="lm ln hi ih b ii lv im lw iq lx iu ly iy lz jc lr ls lt lu bi translated"><a class="ae kx" href="https://www.kaggle.com/umairnsr87/predict-the-number-of-upvotes-a-post-will-get" rel="noopener ugc nofollow" target="_blank"> <em class="jd">预测一个社交媒体帖子将获得的支持票数</em> </a></li></ol><h1 id="db4e" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">其他资源和参考</h1><div class="mx my ez fb mz na"><a href="https://elleknowsmachines.com/linear-regression/" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">线性回归:初学者的机器学习算法</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">线性回归是最简单的机器学习算法，非常适合初学者。在…</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">elleknowsmachines.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no jo na"/></div></div></a></div><div class="mx my ez fb mz na"><a href="https://machinelearningmastery.com/linear-regression-for-machine-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">机器学习的线性回归-机器学习掌握</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">线性回归也许是统计学和机器中最著名和最容易理解的算法之一</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">machinelearningmastery.com</p></div></div><div class="nj l"><div class="np l nl nm nn nj no jo na"/></div></div></a></div><div class="mx my ez fb mz na"><a href="https://www.keboola.com/blog/linear-regression-machine-learning" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">机器学习线性回归终极指南</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">线性回归和逻辑回归是在现实生活中使用最广泛的机器学习算法之一</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">www.keboola.com</p></div></div><div class="nj l"><div class="nq l nl nm nn nj no jo na"/></div></div></a></div><p id="663d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">对于线性回归:从零开始实现，请查看我的GitHub库— </em> </strong></p><div class="mx my ez fb mz na"><a href="https://github.com/tanvipenumudy/Winter-Internship-Internity/blob/main/Day%207%20-%20Linear%20Regression/Linear%20Regression.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">tanvipenumudy/Winter-实习-实习</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">存储库跟踪每天分配的工作-tanvipenumudy/Winter-实习-实习</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">github.com</p></div></div><div class="nj l"><div class="nr l nl nm nn nj no jo na"/></div></div></a></div><p id="f036" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">(<strong class="ih hj"> <em class="jd">使用的数据集</em></strong>—<a class="ae kx" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data" rel="noopener ugc nofollow" target="_blank"><em class="jd">https://www . ka ggle . com/c/house-prices-advanced-regression-techniques/data</em></a>)</p><p id="10d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="jd">分拆文章— </em> </strong></p><div class="mx my ez fb mz na"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/house-price-prediction-using-linear-regression-from-scratch-b2b48fd73689"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hj fi z dy nf ea eb ng ed ef hh bi translated">从零开始用线性回归预测房价</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">今天，让我们从零开始，尝试用线性回归算法解决经典的房价预测问题。</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">medium.com</p></div></div><div class="nj l"><div class="ns l nl nm nn nj no jo na"/></div></div></a></div></div></div>    
</body>
</html>