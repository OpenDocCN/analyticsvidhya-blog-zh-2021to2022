<html>
<head>
<title>Brief View Of Google’s Trax Library</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google的Trax库简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/brief-view-of-googles-trax-library-b78eae008cb6?source=collection_archive---------4-----------------------#2021-08-23">https://medium.com/analytics-vidhya/brief-view-of-googles-trax-library-b78eae008cb6?source=collection_archive---------4-----------------------#2021-08-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="7b62" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">什么是Trax？</h1><p id="c6cd" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">Trax-一个端到端的库，提供简单易懂的代码。Trax中的代码通常具有更简单的结构，这与TensorFlow和Pytorch等其他库的大代码相反。在<a class="ae ka" href="https://research.google.com/teams/brain/" rel="noopener ugc nofollow" target="_blank">谷歌大脑团队</a>积极使用和维护。</p><p id="4c75" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">它最初是许多库的派生版本，但主要是遵循TensorFlow风格。</p><h2 id="0eb2" class="kg if hh bd ig kh ki kj ik kk kl km io jn kn ko is jr kp kq iw jv kr ks ja kt bi translated">安装::-</h2><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/3df07f2d08c7b8df23ddda419926cced.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*K9EqtH3vS3rrgBb2"/></div></div></figure><h1 id="47ca" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">图:安装Trax</h1><p id="ff11" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">上面可以看到，使用它类似于TensorFlow和Numpy。</p><p id="a903" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">在Tensorflow中，我们定义“将Tensorflow作为Tf导入”,在本库中，我们的做法与“导入Trax”相同。</p><p id="06b5" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">它包括了NLP任务的一些基本模型(例如:LSTM，ResNET，Transformer)。用于各种领域，如研究图书馆，用于不断开发新模型，并在包括Tensorflow数据集的数据集上测试它们。T2T也称为张量-2-张量数据集。</p><p id="5116" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">此库—用于基于Python的笔记本来处理自定义模型，以及基于Shell的命令，用于在预训练的模型上训练模型。</p><h1 id="45fb" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">Trax是如何工作的？</h1><p id="e61a" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">源自TensorFlow，使用Numpy等核心Python库。它有一些包介绍了在Trax中编码的更有效的方法。</p><ol class=""><li id="519c" class="lg lh hh je b jf kb jj kc jn li jr lj jv lk jz ll lm ln lo bi translated"><strong class="je hi"> Trax和Fastmath </strong></li></ol><p id="5120" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">它的模型基于一种叫做Tensors的阵列结构，通常使用“Numpy”操作。数组”库函数。结合使用该库和Numpy库，通过使用GPU和TPU来加速它们，提高了计算速度。这使得在张量上自动计算梯度的需要成为可能，这也被预先打包到“Trax”中。Fastmath”包感谢它的后端——<a class="ae ka" href="https://github.com/google/jax" rel="noopener ugc nofollow" target="_blank">JAX</a>和<a class="ae ka" href="https://tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow Numpy </a>。</p><p id="9c9c" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">下面是Fastmath和Trax Numpy的基本代码。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lp"><img src="../Images/3df4fa83e7308be0a9bcc9c0701a97c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*u-AGJTXCzaRDxsdd"/></div></div></figure><h2 id="182a" class="kg if hh bd ig kh ki kj ik kk kl km io jn kn ko is jr kp kq iw jv kr ks ja kt bi translated">图:它工作了(<a class="ae ka" href="https://github.com/google/trax" rel="noopener ugc nofollow" target="_blank">Https://Github.Com/Google/Trax</a>)</h2><ol class=""><li id="d404" class="lg lh hh je b jf jg jj jk jn lq jr lr jv ls jz ll lm ln lo bi translated"><strong class="je hi">图层</strong></li></ol><p id="2c44" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">层是这个库的必要组成部分，其中的一层能够计算具有零个或多个输入或零个或多个输出的函数。输入和输出是作为JAX和Numpy.Array工作的张量。可以使用没有任何权重或子层的Trax层，而无需初始化该层。</p><p id="2949" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">这些层还被定义为对象，这使它们变得简单——“_ _ call _ _”方法，这使我们能够直接在输入数据上使用。</p><p id="82c2" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">下面的代码—来自它的文档。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lt"><img src="../Images/91e1c638d41a9c60adfda8bf809108c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*331wXsh3nONBDaBr"/></div></div></figure><p id="8cd5" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">这些层与Tensorflow或Pytorch等其他框架中的层相同，但与其他层不同的是这些层被编码成的行数。</p><p id="3674" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">我们现在将直接切入其层的实现。在Tensorflow中，模型是使用“顺序”定义的，在这里，它是使用“串行”完成的。“串行”是一个组合器，它根据每一层的输入/输出来组合子层。它使用层的堆叠，这使得将输入传递到每一层变得容易。</p><p id="d042" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">举例:</strong></p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lu"><img src="../Images/d4360aef8b62a634d10ee12648dc5291.png" data-original-src="https://miro.medium.com/v2/resize:fit:586/0*_tF9UmTFklFyowzx"/></div></figure><p id="9567" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">它看起来就像一个“张量流”。顺序”模型，但它的内部结构各层，这使它运行速度很快。</p><p id="6726" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">它还允许您定义自己的层和子层。</p><p id="f4d6" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">下面是Trax模型在实际图层中的样子:</strong></p><p id="3b88" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">下面是我的一个课程笔记本中的代码块，在那里我了解到了Trax。</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lv"><img src="../Images/b027cf918ebe19ca014869e747d3e44c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*pqWS9j3ZAEzH5VC-"/></div></div></figure><h1 id="9879" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">结论:-</h1><p id="f5f5" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">由于它仍在开发中，我很幸运地在一个在线课程中获得了使用这个库的实践经验。我可以说，这使得NLP任务变得更加容易，而不是实现深度学习和像RNNs这样的神经网络。</p><p id="c0f5" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated"><strong class="je hi">参考文献:- </strong></p><ol class=""><li id="aae7" class="lg lh hh je b jf kb jj kc jn li jr lj jv lk jz ll lm ln lo bi translated">这个链接是关于“Trax是如何产生的”</li></ol><p id="a89d" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">h<a class="ae ka" href="https://coursera.org/share/1bdab833b3fbbee79133006f2cab236f" rel="noopener ugc nofollow" target="_blank">ttps://coursera . org/share/1 bdab 833 B3 FB bee 79133006 F2 cab 236 f</a></p><ol class=""><li id="fa3f" class="lg lh hh je b jf kb jj kc jn li jr lj jv lk jz ll lm ln lo bi translated">该链接详细遵循Trax文档。</li></ol><p id="3cb9" class="pw-post-body-paragraph jc jd hh je b jf kb jh ji jj kc jl jm jn kd jp jq jr ke jt ju jv kf jx jy jz ha bi translated">h<a class="ae ka" href="https://trax-ml.readthedocs.io/en/latest/notebooks/trax_intro.html" rel="noopener ugc nofollow" target="_blank">ttps://trax-ml . readthedocs . io/en/latest/notebooks/trax _ intro . html</a></p></div></div>    
</body>
</html>