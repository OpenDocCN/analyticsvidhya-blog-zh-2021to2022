<html>
<head>
<title>Building ML models to classify Traffic Signs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">建立ML模型对交通标志进行分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-ml-models-to-classify-traffic-signs-37534e1c53e5?source=collection_archive---------6-----------------------#2021-05-08">https://medium.com/analytics-vidhya/building-ml-models-to-classify-traffic-signs-37534e1c53e5?source=collection_archive---------6-----------------------#2021-05-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="9e50" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">概述</strong></h1><blockquote class="jc jd je"><p id="36d6" class="jf jg jh ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">我的项目旨在建立一个高精度的ML模型，根据某些输入变量来检测交通标志的类型。</p><p id="09d1" class="jf jg jh ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">对于自动化和自动驾驶汽车的未来来说，这是一个至关重要的项目。为了确保道路上行人和乘客的最高安全水平，自动驾驶汽车需要能够预测交通标志的最先进技术。</p><p id="474b" class="jf jg jh ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">因此，我的交通标志检测项目可以让自动驾驶汽车准确预测交通标志，让我们离更安全的道路和高速公路更近一步。</p></blockquote></div><div class="ab cl ke kf go kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="ha hb hc hd he"><h1 id="3dad" class="ie if hh bd ig ih kl ij ik il km in io ip kn ir is it ko iv iw ix kp iz ja jb bi translated">探索性数据分析</h1><p id="2d84" class="pw-post-body-paragraph jf jg hh ji b jj kq jl jm jn kr jp jq ks kt jt ju ku kv jx jy kw kx kb kc kd ha bi translated"><strong class="ji hi">检查缺失值</strong></p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ky"><img src="../Images/15d68572995c5d5acc173d2cc188975a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aPRmNbJeY6Q64ZXb7J99Fw.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图1:检查缺失值的热图</figcaption></figure><p id="6b29" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">我从检查数据集的形状和结构开始。然后，继续检查我的数据集中是否有任何丢失的值。</p><p id="3e12" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">由于左侧的热图颜色一致，我们知道数据集中没有缺失值。</p><p id="741c" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">如图2所示，有四个显示感兴趣区域的<strong class="ji hi">输入变量</strong>，这有助于我们对代表交通标志类型的离散输出变量——classID——进行分类:</p><ul class=""><li id="40c8" class="lo lp hh ji b jj jk jn jo ks lq ku lr kw ls kd lt lu lv lw bi translated">顶行(顶行)</li><li id="04d8" class="lo lp hh ji b jj lx jn ly ks lz ku ma kw mb kd lt lu lv lw bi translated">底部行(底部行)</li><li id="0598" class="lo lp hh ji b jj lx jn ly ks lz ku ma kw mb kd lt lu lv lw bi translated">左栏(左栏)</li><li id="6b64" class="lo lp hh ji b jj lx jn ly ks lz ku ma kw mb kd lt lu lv lw bi translated">右栏(右栏)</li></ul><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mc"><img src="../Images/72c41c827d2fb387bc7b4e0c16b3bad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JUF_-hbEEHCN8gJE-S0_OQ.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图2:交通标志数据框</figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es md"><img src="../Images/5050d7b842b64976f6cb26243e4b4772.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dTSh0g1F2UqzE-T81Aga_Q.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图ClassID的因子图</figcaption></figure><p id="f89d" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">左侧的因子图显示了代表不同交通标志的每个classID的数量。</p><p id="e207" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">显然，这是一个多类分类问题，因为输出变量可以是从0到42的任何离散数字。因此，我不能使用回归，因为我不想根据某些独立变量和控制变量来预测连续的产量。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es me"><img src="../Images/51f3a5f801b29b498728ed1cfef23e6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AGn8hENq4KtNS7gYnxIssQ.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图4:显示对应于交通标志类型的ClassID的类的键</figcaption></figure><p id="13fc" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">我既不能使用逻辑回归，也不能使用任何其他二元分类器，因为这属于多类分类的范畴。</p><p id="8d7e" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">因此，我使用分类预测模型来逼近从4个输入变量到离散输出变量classID的映射函数(fx)。这个输出变量也称为标签或类别。</p><p id="6ca0" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">在下面的散点图中，彩色图例显示了classID，气泡的大小根据左列(leftCol)值而变化。最小的黄色气泡中似乎有某种模式，这些气泡集中在最高水平的顶行和底行。除此之外，在classIDs中看不到多少簇，我可以根据这些簇来对它们进行分类。这可以通过减少输出变量/标签的数量来简化模型。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mf"><img src="../Images/fbfa875f87119db17c8f267de01d777d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sQmt0ATWYFDtGJbHXvjfsQ.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图5:散点图</figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mg"><img src="../Images/11720b97f3efb7690ee7b003861e85fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DFUCY5vc_RMR-ecABi2OSw.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图6:相关矩阵</figcaption></figure><p id="fc8d" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">然而，由于没有明显的模式将单个的ClassIDs分类以减少类的数量，所以我在我的模型中使用了所有43个独立的类。</p><p id="0af3" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">似乎顶行和底行也具有正的强线性关系(如在相关矩阵中所重申的)，这可以通过假设检验来进一步探索，并且可能与交通标志的检测相关。</p><p id="44d7" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">在我的分析中，我使用了3个模型:</p><ul class=""><li id="2376" class="lo lp hh ji b jj jk jn jo ks lq ku lr kw ls kd lt lu lv lw bi translated">决策树分类</li><li id="b656" class="lo lp hh ji b jj lx jn ly ks lz ku ma kw mb kd lt lu lv lw bi translated">随机森林分类</li><li id="a1db" class="lo lp hh ji b jj lx jn ly ks lz ku ma kw mb kd lt lu lv lw bi translated">Ada增强分类</li></ul></div><div class="ab cl ke kf go kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="ha hb hc hd he"><h1 id="a70e" class="ie if hh bd ig ih kl ij ik il km in io ip kn ir is it ko iv iw ix kp iz ja jb bi translated">决策树模型</h1><p id="186d" class="pw-post-body-paragraph jf jg hh ji b jj kq jl jm jn kr jp jq ks kt jt ju ku kv jx jy kw kx kb kc kd ha bi translated">在决策树建模中，数据基于某些条件被连续分割，帮助我们对观察结果进行分类。在下图中，标准为“gini”，最大深度为2，拆分器为“最佳”。图表中显示的“基尼”分数是计算节点纯度的一种方法。叶节点涂上粉红色，节点涂上白色。粉红色叶子的“基尼”值为0.0，意味着在该叶子中只存在一类样本，而“基尼”值大于0.0意味着该叶子/节点包含不同类的样本。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es mh"><img src="../Images/db47ff63cb8834de14965f6050357746.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*H2WlKKHu_ynnY-VMHW8qBQ.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图7:可视化分类树(叶子涂上粉红色，节点涂上白色)</figcaption></figure><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mi"><img src="../Images/a0937a40d999d9c187641760f3e53ae0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G3dLiwDp5TO73jv7ojmBPw.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图8:带有类名的分类树</figcaption></figure><p id="1b11" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">。如左图所示，粉色树叶的class = y[36]，表示classID=13。图4中的钥匙告诉我们，班级编号13代表“让路”标志。因此，根据分类树图，我们知道所有bottomRow &gt; 604.5的观测值都是classID = 13或“让路”交通标志的样本。</p><p id="d9a5" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">为了提高模型的准确性，我使用不同的参数值(如标准和最大深度)运行了各种决策树分类模型。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mj"><img src="../Images/09288598944df183d6eab7325817a0a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4OU1atrUNU4hiGvtjE2UQg.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图9:决策树分类的最大深度与准确度</figcaption></figure><p id="3efe" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">正如我们在图9中看到的，使用“基尼”作为标准比使用“熵”给出了更好的准确度分数。此外，似乎在修剪树到最大深度= 4或最大深度= 6(大约)时，精确度最高。此图中显示的最佳准确度得分为0.16015625。</p></div><div class="ab cl ke kf go kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="ha hb hc hd he"><h1 id="30d0" class="ie if hh bd ig ih kl ij ik il km in io ip kn ir is it ko iv iw ix kp iz ja jb bi translated">随机森林模型</h1><p id="7eb3" class="pw-post-body-paragraph jf jg hh ji b jj kq jl jm jn kr jp jq ks kt jt ju ku kv jx jy kw kx kb kc kd ha bi translated">随机森林是一种分类的集成学习方法，由过多的个体决策树组成。</p><p id="8335" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">为了提高模型的准确性，我使用不同的参数值运行了各种随机森林分类模型，例如criterion、n_estimators和max depth。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mk"><img src="../Images/d2c9e4ca1d758e855faa6e080759f85e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6_YGCf92VWoaozn5cib_AA.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图10:显示不同n估计量的准确度分数的输出</figcaption></figure><p id="68d0" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">从上面的图10中，我们可以看到n_estimator: 60和n_estimator: 90给出了最高的精度分数。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ml"><img src="../Images/558aeb7decba860ff81efa7854944dce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D4Fl-XD1y2Q-Fn_CtKijgw.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图11:随机森林分类的最大深度与精确度</figcaption></figure><p id="4ff4" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">正如我们在图11中看到的，使用“熵”作为标准比使用n_estimators = 90的“熵”给出了更好的准确度分数。此外，似乎在最大深度= 5(大约)时，精确度最高。此图中显示的最佳准确度得分为0.1640625。</p></div><div class="ab cl ke kf go kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="ha hb hc hd he"><h1 id="c931" class="ie if hh bd ig ih kl ij ik il km in io ip kn ir is it ko iv iw ix kp iz ja jb bi translated">自适应增强(AdaBoost)模型</h1><p id="9900" class="pw-post-body-paragraph jf jg hh ji b jj kq jl jm jn kr jp jq ks kt jt ju ku kv jx jy kw kx kb kc kd ha bi translated">Adaboost试图通过将各种弱分类器组合成一个来建立强预测模型。增强用于最小化模型中的偏差误差，这些偏差误差不能识别基于观察的有意义的模式。</p><p id="e385" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">为了提高模型的准确性，我使用不同的参数值运行了各种Adaboost分类模型:n估计量和学习率。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mm"><img src="../Images/fbe55cb8d67eb050dc818bb27c00e486.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9U-LuVUke6G6rJr3Mz7z0g.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图12:显示AdaBoost的不同n估计量的准确度分数的输出</figcaption></figure><p id="c96e" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">从上面的图11中，我们可以看到n_estimator: 60和n_estimator: 85给出了最高的相同精度分数，所以我在我的模型中使用了60到85之间的n_estimator。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mn"><img src="../Images/5eb0ebc551914c6b135a00afa4c435ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h4rvwTe5L_Bm0SzsC8_RwA.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图13:循环寻找最佳学习率</figcaption></figure><p id="618b" class="pw-post-body-paragraph jf jg hh ji b jj jk jl jm jn jo jp jq ks js jt ju ku jw jx jy kw ka kb kc kd ha bi translated">学习率是在每次提升迭代中给予每个分类器的权重。学习率越高，每个分类器的贡献越大。<strong class="ji hi">根据图13，我们可以看到，在n_estimators = 75的情况下，AdaBoost模型获得最高精度的学习率为0.08。</strong>然而，即使以最佳学习率获得的0.15625的准确度分数低于随机森林和决策树的准确度分数。</p></div><div class="ab cl ke kf go kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="ha hb hc hd he"><h1 id="81c2" class="ie if hh bd ig ih kl ij ik il km in io ip kn ir is it ko iv iw ix kp iz ja jb bi translated">最佳模特</h1><p id="2373" class="pw-post-body-paragraph jf jg hh ji b jj kq jl jm jn kr jp jq ks kt jt ju ku kv jx jy kw kx kb kc kd ha bi translated">如图12所示，随机森林分类是最好的模型，精度得分为0.164。该模型击败了Ada Boost和决策树分类模型，因为它具有最高的准确性得分。准确度分数是评估ML模型的关键指标，因为它告诉我们测试数据集中所有正确预测的输出变量的度量。</p><figure class="kz la lb lc fd ld er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es mo"><img src="../Images/7246cf02f141d40301aab3946111ca3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RQyVREMogZ7_jj-ZwTjJ-w.png"/></div></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图12:比较不同分类模型的准确度分数的线图</figcaption></figure></div><div class="ab cl ke kf go kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="ha hb hc hd he"><h1 id="1714" class="ie if hh bd ig ih kl ij ik il km in io ip kn ir is it ko iv iw ix kp iz ja jb bi translated">限制</h1><ul class=""><li id="c8d6" class="lo lp hh ji b jj kq jn kr ks mp ku mq kw mr kd lt lu lv lw bi translated">需要更多的观察来提高准确性，因为这是一个43类(多类)分类问题。</li><li id="d9f4" class="lo lp hh ji b jj lx jn ly ks lz ku ma kw mb kd lt lu lv lw bi translated">交叉验证来微调模型的超参数(如lasso中的alpha)不是很有用，因为这是一个只有四个输入要素的分类问题。尽管如此，它仍能给我们一些关于特性重要性的相关信息，如图13所示，rightCol似乎是最不重要的。学习率为0.0001(最佳alpha)的lasso模型的系数为:</li></ul><figure class="kz la lb lc fd ld er es paragraph-image"><div class="er es ms"><img src="../Images/24e9195d5534350bc109cbf08dae0ff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*RSJT2f8CXIPOt3yhZVQC7g.png"/></div><figcaption class="lk ll et er es lm ln bd b be z dx translated">图13:套索模型系数</figcaption></figure></div><div class="ab cl ke kf go kg" role="separator"><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj kk"/><span class="kh bw bk ki kj"/></div><div class="ha hb hc hd he"><h1 id="1a31" class="ie if hh bd ig ih kl ij ik il km in io ip kn ir is it ko iv iw ix kp iz ja jb bi translated">参考</h1><ol class=""><li id="3ebe" class="lo lp hh ji b jj kq jn kr ks mp ku mq kw mr kd mt lu lv lw bi translated">Hideo，G. (2020)。<em class="jh">决策树:使用Python </em>构建、修剪并可视化决策树。【在线】中等。可从以下网址获得:<a class="ae mu" href="https://towardsdatascience.com/decision-tree-build-prune-and-visualize-it-using-python-12ceee9af752" rel="noopener" target="_blank">https://towards data science . com/decision-tree-build-prune-and-visualize-it-using-python-12 CEE 9 af 752</a></li><li id="3c75" class="lo lp hh ji b jj lx jn ly ks lz ku ma kw mb kd mt lu lv lw bi translated">托尼，你好。(2019).<em class="jh">了解随机森林</em>。【在线】中等。可从以下网址获得:<a class="ae mu" href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2" rel="noopener" target="_blank">https://towards data science . com/understanding-random-forest-58381 e 0602d 2</a></li><li id="7cda" class="lo lp hh ji b jj lx jn ly ks lz ku ma kw mb kd mt lu lv lw bi translated"><a class="ae mu" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . adaboostclassifier . html</a></li></ol></div></div>    
</body>
</html>