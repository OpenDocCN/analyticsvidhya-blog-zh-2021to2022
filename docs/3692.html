<html>
<head>
<title>Object Detection State of the Art-YOLO-V3</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">目标探测技术现状-YOLO-V3</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/object-detection-state-of-the-art-yolo-v3-79ad2937832?source=collection_archive---------8-----------------------#2021-07-18">https://medium.com/analytics-vidhya/object-detection-state-of-the-art-yolo-v3-79ad2937832?source=collection_archive---------8-----------------------#2021-07-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="b884" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">问题表述:</h1><p id="a572" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">有时，我们希望找出图像中的内容，以便我们可以出于各种原因使用这些信息，例如:如果我们知道图像中的对象是什么，它的范围是什么，以及它的准确位置，我们可以使用它来完成多项任务，例如对单个图像中不同类型的对象进行分类，这在设计自动驾驶汽车时非常方便。近年来，我们通过使用深度学习模型，在这种复杂的任务中取得了更好的准确性。在这篇博客中，我们将会看到一个叫做YOLO的模型(你只能看一次)和它的第三个版本。</p><p id="3c38" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">对象检测试图解决的任务是检测单个图像中的多个对象，并通过在这些对象上绘制一个称为边界框的矩形来定位这些对象。一个图像可以有多个对象，它们也有多个边界框。请看一下图像，以便更好地理解。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kf"><img src="../Images/b95423fe17c7d4e85acc5927bf2c5e05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yKlWDBQT7e5OkOsWTOHvNg.jpeg"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">物体检测。来源-谷歌图片搜索。</figcaption></figure><p id="0a6a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">因此，我们的模型解决的任务是给定一个输入图像，它应该返回我们每个对象的边界框，即目标和定位，第二个任务是分类，它告诉它相应的类别标签，类别标签将因问题而异。</p><h1 id="fb6c" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">YOLO-V3车型详情:</h1><p id="5482" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">现在让我们来看看yolov3模型的内部。该模型由许多部分组成，但首先，让我们谈谈所使用的主干网络，也称为特征提取器，它用于提取目标定位及其分类的重要特征。这是一个完全连接的卷积网络(FCN)，这意味着它没有密集层或最大池层。在这个模型的早期版本中，他们使用了VGG和ResNet作为主干，但是在Yolo V3中，他们使用了一个名为DarkNet-53的FCN。这是一个53层的完全卷积网络，如下图所示。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es kv"><img src="../Images/f84f36717884a816276ad18c352c252c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1064/format:webp/1*ISLwwI8mCRT5jDvwUhRqrw.jpeg"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">Yolo建筑</figcaption></figure><p id="957d" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">模型中图像的典型输入大小是(416x416x3)，它被输入到模型中。</p><h2 id="05c8" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated">卷积模块:</h2><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lk"><img src="../Images/8e7a6a1695e5ca8af87d7ca845b9d46e.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/format:webp/1*7uk2hd0mkF2FLoIj8NmENw.jpeg"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">卷积块</figcaption></figure><p id="4051" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">这里的卷积块意味着它具有在每个块旁边提到的滤波器大小的卷积运算，并且每个内核的大小也被定义，如果在内核大小中您看到“3 x 3 / 2 ”,这意味着步距等于2，因为我们在这里不使用最大池运算，我们必须使用步距运算来减小图像大小。您还会注意到输出列中的大小图像的大小也减小了2倍</p><p id="79af" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">卷积操作后，它被传递到BatchNormalisation层，随后是LeakyRelu激活。</p><h2 id="1d48" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated">剩余块:</h2><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ll"><img src="../Images/6f2c1f1d4727bc1d8cd40350aa920d48.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*YfHrr0txuVRIICaLkKrO7g.jpeg"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">街区</figcaption></figure><p id="cbfc" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">残差块的想法源自ResNet，其中他们使用残差层，如果它们不提供太多信息，则允许梯度跳过卷积操作。通过这样做，梯度的流动变得平滑，并且所有不重要的信息被网络忽略。</p><p id="b6c4" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在暗网中，残差块的工作方式如下，如您所见，在一个较大的块中有多个块，我们将其命名为巨型块，因此在这个巨型块中有2个不同核大小(1，3)的卷积块，滤波器的数量分别为(32，64)，在此之后是一个残差块。</p><p id="2af1" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">因此，从上图来看，进入我们的巨型块的输入是128*128*64的形状，并且在图像大小变为128*128*64之后，它被传递到2个卷积块，因此残差块所做的只是将接收到我们的巨型块(128*128*64)中的输入与第二卷积块的输出连接起来，第二卷积块将输出与接收到的(128*128*64)相同形状的张量。所以它增加了一个快捷连接。</p><p id="a8d2" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">你可能已经注意到在我们的巨型块外面标有“1x，2x，4x，8x”。这意味着整个巨型块会重复该次数。因为输入张量和输出张量的形状是相同的，所以我们可以重复运算而没有任何误差。</p><p id="929e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">因此，一旦图像被传递到模型中，图像大小就会缩小32倍，因为正如您看到的，在每个块之后，我们都会应用一个步长为2的卷积块，这是5倍，因此我们得到了2⁵=32.如果传递的图像形状是416*416*3，则提取的特征形状将是13*13*1024 (1024是最后一个大块内的过滤器数量)。</p><p id="6f65" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">现在我们已经成功地从主干网络中提取了特征，让我们继续前进。</p><h2 id="7c86" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated">3级输出:</h2><p id="11da" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">它通过自上而下的路径和横向连接将低分辨率、语义强的特征与高分辨率、语义弱的特征结合起来。</p><p id="f1da" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">正如您在架构中看到的，三个输出来自3个不同的巨型块，称为scale1，其张量形状为(52*52*256)，scale2，其形状为(26*26*512)，scale3，其形状为(13*13*1024)。这个想法来自特征金字塔网络(FPN ),这是另一种对象检测模型。</p><h1 id="bf88" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">模型输出公式:</h1><p id="f0eb" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">到目前为止，我们已经了解了图像是如何通过网络传递的，现在让我们看看模型的输出应该是什么。</p><p id="abde" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">直到我们将shape (416*416)的图像下采样为52*52、26*26、13*13。但是为了理解，让我们只考虑13*13*1024输出的输出特征块。我们来看看下图。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lm"><img src="../Images/98a24191dd8bd5156f450864f0513ca6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*db-ryP-IycCChdiCZzrb_Q.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">Yolo输出</figcaption></figure><p id="7443" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">首先为了预测的目的，我们将把我们的图像分成13×13个块。在我们的例子中，如果输入图像是形状的，那么总的块将是(416/13)*(416/13)=32*32，所以网格的每个块(用红色标记)将具有13的形状，并且将有32*32个这样的块。</p><p id="191a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">因此，根据论文，每个区块的每个网格单元将包含3个锚定框，每个单元将有85个值。让我来解释一下。</p><p id="b25d" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">假设你在MS-COCO数据集上训练物体检测，我们知道它有80组类。所以这个数字85将分成4个边界框偏移量+1个抽象度分数+ 80个类别概率=85。</p><h2 id="2c7e" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated">锚箱:</h2><p id="6929" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><em class="ln">锚框</em>是一组预定义的具有一定高度和宽度的边界框。这个想法来自YOLO-V2。他们在MS-COCO数据集上对边界框的维度进行k-means聚类，以获得模型的良好先验。下图显示了我们通过选择不同的k值得到的平均IOU值。他们发现k = 5给出了一个很好的召回值与模型复杂度的比值。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lo"><img src="../Images/74221ee27e4dff958d20cdd2674d0bea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*lYS3X83Qq_weYyFUQq-uWg.jpeg"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">锚箱。</figcaption></figure><h2 id="2b3a" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated">边界框偏移量:</h2><p id="19cd" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated"><strong class="je hi"> tx和ty: </strong>该单元格边框的<strong class="je hi">偏移量</strong>的x和y坐标。</p><p id="112a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi"> tw和th: </strong>该单元格边框的高度和宽度。</p><p id="a2b8" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">这些是对每个单元格的预测。请记住，这些不是实际的边界框坐标，它们只是偏移量、宽度和高度，我们将使用这些坐标来计算实际的边界框。</p><h2 id="b3fe" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated">客观性分数:</h2><p id="1678" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">不可能每个13*13锚定框内部都有一个对象，所以为了捕捉这个信息，我们有一个二进制标签，如果对象出现在网格单元中，这个标签就是1，否则就是0。</p><h2 id="5c7d" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated">类别概率:</h2><p id="008c" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">现在我们已经检测到了这个物体，我们还想知道这个物体的类型是什么:猫，狗，鸟，等等。因此，如果我们的数据集中有80个不同的类别，那么每个类别将有80个类别概率值。</p><p id="7cf4" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">边界框表示:</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lp"><img src="../Images/de7d26e23d6c403c37b82c1fe258a919.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*KjrFjAO0RfvUuyA_p3Th5g.jpeg"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">包围盒表示。</figcaption></figure><ul class=""><li id="db46" class="lq lr hh je b jf ka jj kb jn ls jr lt jv lu jz lv lw lx ly bi translated">这里<strong class="je hi"> bx，by </strong>是x，y中心坐标。我们在sigmoid函数中传递我们的<strong class="je hi"> tx，ty </strong>值，将它们缩小到0-1之间，然后加上<strong class="je hi"> cx，cy </strong>，它们是单元格网格的左上角坐标。我们使用sigmoid是因为如果预测超过1，那么边界框的中心可能会移动到另一个单元网格中，这打破了YOLO背后的理论，因为如果我们假设红框负责预测对象，则对象的中心一定位于当前的单元网格中，而不是其他地方。所以我们用一个sigmoid来保持网格本身的中心。</li><li id="5d9d" class="lq lr hh je b jf lz jj ma jn mb jr mc jv md jz lv lw lx ly bi translated"><strong class="je hi"> bw，bh </strong>是我们包围盒的宽度和高度，如果对包含物体的盒子的预测bx和by是(0.3，0.8)，那么13×13特征图上的实际宽度和高度是(13∫0.3，13∫0.8)。</li><li id="498a" class="lq lr hh je b jf lz jj ma jn mb jr mc jv md jz lv lw lx ly bi translated"><strong class="je hi"> tx，ty，tw，th </strong>是我们在预测中得到的。</li><li id="b21c" class="lq lr hh je b jf lz jj ma jn mb jr mc jv md jz lv lw lx ly bi translated"><strong class="je hi"> cx </strong>和<strong class="je hi"> cy </strong>是网格的左上角坐标。</li><li id="f1de" class="lq lr hh je b jf lz jj ma jn mb jr mc jv md jz lv lw lx ly bi translated"><strong class="je hi"> pw </strong>和<strong class="je hi"> ph </strong>为母扣的锚尺寸。这些预定义的锚是通过在数据集上运行K-means聚类获得的。</li></ul><p id="1728" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi">多尺度输出:</strong></p><p id="b942" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在上面的解释中，我们只看到了对13*13特征图的预测。相同的概念将适用于26*26和52*52特征输出。通过在不同的网格维度中应用变换，我们检测不同大小的对象。在13*13网格中，我们可以检测非常小的对象，而在26*26网格中，我们可以检测中等大小的对象，对于52*52网格，我们可以检测较大的对象，通过连接输出，我们可以在单个图像上得到所有三个结果的组合。</p><p id="179c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在每个比例下，每个网格单元使用3个预定义的锚点预测3个边界框，使得使用的锚点总数为9。(不同尺度的主播不一样)。</p><h2 id="aa72" class="kw if hh bd ig kx ky kz ik la lb lc io jn ld le is jr lf lg iw jv lh li ja lj bi translated"><strong class="ak">非最大抑制</strong></h2><p id="bd43" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">所以对于一个输入图像，模型预测(52*52 +26*26 +13*13)*3 =10647个盒子，这已经很多了。为了解决这个问题，我们局部地丢弃分类概率小于0.5的框，并且我们使用“<strong class="je hi">非最大抑制”</strong>技术来处理围绕同一对象的多个边界框。为了过滤掉它，我们使用IOU(交集/并集)分数，该分数计算实际和预测的边界框之间有多少重叠，并通过比较该特定对象的实际边界框和所有预测的边界框，使用它来过滤不需要的边界框。</p><p id="657a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">因此，我们需要的输出形状是13*13*425(5*(80+4+1))，其中5是锚盒的数量，但是我们有13*13*1024的特征图。因此，要将特征转换为我们想要的输出，我们只需使用1 x 1卷积层进行转换。</p><p id="537e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">13*13*1024(特征图)→(1 * 1 * 425 conv)→13 * 13 * 425(输出)</p><p id="6d0b" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">现在我们的模型完成了。现在我们可以训练它了。</p><h1 id="8561" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">谢谢你</h1></div></div>    
</body>
</html>