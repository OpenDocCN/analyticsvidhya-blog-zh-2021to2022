<html>
<head>
<title>Face Mask Detection using Faster RCNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于快速RCNN的人脸面具检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/face-mask-detection-using-faster-rcnn-2df35f53cce8?source=collection_archive---------20-----------------------#2021-01-04">https://medium.com/analytics-vidhya/face-mask-detection-using-faster-rcnn-2df35f53cce8?source=collection_archive---------20-----------------------#2021-01-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="f5ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">快速RCNN是检测2D彩色图像中目标的有效工具。该模型在<a class="ae jc" href="http://papers.neurips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf" rel="noopener ugc nofollow" target="_blank"> TPAMI 2016 </a>中首次提出，是对之前<a class="ae jc" href="https://openaccess.thecvf.com/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html" rel="noopener ugc nofollow" target="_blank"> RCNN </a>和<a class="ae jc" href="https://openaccess.thecvf.com/content_iccv_2015/html/Girshick_Fast_R-CNN_ICCV_2015_paper.html" rel="noopener ugc nofollow" target="_blank"> Fast RCNN </a>工作的改进，通过引入深度区域提议网络。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/122fceef3c7e4c7b39afa238ec29b8be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f6927KNdgYzxFcwuEwnmPg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来自原始RCNN工作的检测模型。</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jt"><img src="../Images/f6e7412c4faf2a3704972b7fe4e4ba8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*tROeCWUCVQIU76SJSiyJDQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">深层区域建议网络(RPN)从原来更快的RCNN工作。</figcaption></figure></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="6426" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们讨论了如何使用更快的RCNN网络来解决使用<a class="ae jc" href="https://www.kaggle.com/andrewmvd/face-mask-detection" rel="noopener ugc nofollow" target="_blank"> Kaggle数据集的二进制人脸面具检测问题。</a>在这个GitHub <a class="ae jc" href="https://github.com/adoskk/KaggleFaceMaskDetection" rel="noopener ugc nofollow" target="_blank">资源库</a>上可以找到PyTorch的完整实现和预训练模型。</p><p id="9bf0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Kaggle数据集包含853张带有相应xml注释的图像。每个注释包含边界框坐标信息，以及不同的遮罩类型。数据集中有三种不同的掩码类型:a)带掩码；b)不带面罩；c)面罩佩戴不正确。我们简单地使用a)和b)作为原型。</p><p id="14c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在培训之前，让我们浏览一下数据集，看看班级分布。我们从两个角度来考察:a)从对象层次的类分布；b)图像层面的类别分布。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kb"><img src="../Images/d58b6e7a2abab38be823109c07263c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:846/format:webp/1*LxPZzd_nggVJ0Y5LielA5w.png"/></div></figure><p id="47dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的结果显示数据集是高度不平衡的，如果在对象级别和图像级别上都有“带遮罩”组,“不带遮罩”组几乎是1/4。一个简单的解决方案是在训练数据中将“无掩码”组过采样4，同时保持测试数据不变。为了简单起见，我们以3:1的比例分割训练和测试数据。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kc"><img src="../Images/6a721fce909011bfdc780478836e82b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1392/format:webp/1*d_Ra-HX3GzGZrnyKFE34kg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">split_dataset.py中包含分割数据集和过采样的代码</figcaption></figure></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="324c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型设置遵循PyTorch官方网站上的教程:<a class="ae jc" href="https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html" rel="noopener ugc nofollow" target="_blank">https://py torch . org/tutorials/intermediate/torch vision _ tutorial . html</a></p><p id="8550" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们快速讨论一下这个模型是如何工作的。</p><p id="1c67" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，主干模型是在<a class="ae jc" href="https://cocodataset.org/" rel="noopener ugc nofollow" target="_blank"> COCO数据集</a>上预先训练的resnet50网络。一旦训练完毕，resnet50网络层将被冻结，不会进一步训练。</p><p id="fca1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如前所示，对于每个像素，给出了n个不同的锚定框。我们设置k=5，比例为32、24、24、16、8，纵横比不同。默认的特征映射包含256个通道，我们在<a class="ae jc" href="https://github.com/pytorch/vision/blob/master/torchvision/models/detection/rpn.py" rel="noopener ugc nofollow" target="_blank"> RPNHead类</a>中设置输入通道数= 256。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jt"><img src="../Images/f6e7412c4faf2a3704972b7fe4e4ba8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/1*tROeCWUCVQIU76SJSiyJDQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">在我们的例子中k=5。由于输入特征映射包含256个通道，我们设置RPNHead输入通道= 256。</figcaption></figure><p id="d6fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于特征生成层是固定的，唯一需要改变的是cls和reg层，这就是为什么这里引入了一个新的<a class="ae jc" href="https://github.com/pytorch/vision/blob/master/torchvision/models/detection/faster_rcnn.py" rel="noopener ugc nofollow" target="_blank"> FastRCNNPredictor类</a>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kd"><img src="../Images/450e5350806b6bbdbe5255e87e2fe227.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*FXDuj0Ex980R772RvDSMYA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">主模型的快照。</figcaption></figure></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="12ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">评估和结果。</p><p id="c5b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们遵循教程并使用COCO评估指标，这里是训练20个时期后的测试结果。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ke"><img src="../Images/ae3e5b4d68c460a175fd98657200f314.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*dIuFo9HOl77mx3eUoyOqMQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">最高的AP和AR几乎达到80%。</figcaption></figure><p id="9b83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是测试结果的快照。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kf"><img src="../Images/5d1ea37717b7b645e48c2017058ba793.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*004GJbQMmGxWskUf4CbMHQ.png"/></div></figure></div></div>    
</body>
</html>