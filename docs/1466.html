<html>
<head>
<title>Driver’s License Data extraction using CNN (yolov5). Part-1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用CNN (yolov5)提取驾照数据。第一部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/drivers-license-data-extraction-using-cnn-yolov5-14585709f4d8?source=collection_archive---------3-----------------------#2021-03-03">https://medium.com/analytics-vidhya/drivers-license-data-extraction-using-cnn-yolov5-14585709f4d8?source=collection_archive---------3-----------------------#2021-03-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/34e3f09cd50e8b68c66d44c67ae7cc67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*EH8R1I63EUw6zTLMKzYq0Q.jpeg"/></div></figure><h1 id="3205" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">CNN是什么？</h1><blockquote class="jk jl jm"><p id="00cd" class="jn jo jp jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在<!-- -->深度学习中，卷积神经网络(CNN，或ConvNet)是一类深度神经网络，最常用于分析视觉图像。它们也称为移位不变或空间不变人工神经网络(SIANN)，基于扫描隐藏层和平移不变特性的卷积核的共享权重架构。它们应用于图像和视频识别、推荐系统、图像分类、图像分割、医学图像分析、自然语言处理、脑机接口和金融时间序列。</p></blockquote><p id="517f" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi kp translated"><span class="l kq kr ks bm kt ku kv kw kx di">在</span>这个教程中，我将使用YOLOv5架构来浏览一个完整的CNN例子。YOLOv5由<a class="ae ky" href="https://www.linkedin.com/in/glenn-jocher" rel="noopener ugc nofollow" target="_blank">的格伦·乔彻</a>(Utralytics的创始人&amp; CEO)发布。在Github <a class="ae ky" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank">这里</a>公开发布。Glenn介绍了基于YOLOv5 Pytorch的方法，是的！YOLOv5是用<a class="ae ky" href="https://github.com/pytorch/pytorch" rel="noopener ugc nofollow" target="_blank"> Pytorch </a>框架写的。</p></div><div class="ab cl kz la gp lb" role="separator"><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le lf"/><span class="lc bw bk ld le"/></div><div class="hb hc hd he hf"><h2 id="630b" class="lg in hi bd io lh li lj is lk ll lm iw km ln lo ja kn lp lq je ko lr ls ji lt bi translated"><strong class="ak">按照以下步骤获取驾照重要信息。</strong></h2><h1 id="5230" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">准备好数据:</h1><p id="f2d8" class="pw-post-body-paragraph jn jo hi jq b jr lu jt ju jv lv jx jy km lw kb kc kn lx kf kg ko ly kj kk kl hb bi translated">我已经从网上公开的<a class="ae ky" href="https://www.insider.com/what-drivers-license-looks-like-in-every-state" rel="noopener ugc nofollow" target="_blank">来源</a>收集了数据，这是我们申请美国驾照的案例。我已经将所有的图片编辑到一个文件夹中，并为数据预处理部分做好了准备。</p><p id="67e0" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">收集的数据必须用我们希望从驾驶执照中检测的所有区域的边界框进行注释/标记，例如<em class="jp">姓名、地址、DL编号、性别和出生日期</em>。因此，我们用感兴趣的检测对所有图像进行标记。每个图像的标签数量构成总类别，在这种情况下是<code class="du lz ma mb mc b">'5'</code>。</p><h1 id="314e" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">数据预处理:</h1><p id="4533" class="pw-post-body-paragraph jn jo hi jq b jr lu jt ju jv lv jx jy km lw kb kc kn lx kf kg ko ly kj kk kl hb bi translated">我已经使用<a class="ae ky" href="https://roboflow.com" rel="noopener ugc nofollow" target="_blank"> Roboflow </a>进行标记，我们也可以使用<a class="ae ky" href="https://github.com/tzutalin/labelImg" rel="noopener ugc nofollow" target="_blank"> LabelImg </a>进行同样的操作。</p><figure class="me mf mg mh fd ij er es paragraph-image"><div class="er es md"><img src="../Images/4722cdd2c0376d955432fd30e12df08c.png" data-original-src="https://miro.medium.com/v2/resize:fit:930/format:webp/1*mc3cRKlYsmMSuZBXumO96g.png"/></div><figcaption class="mi mj et er es mk ml bd b be z dx translated">许可证的标签</figcaption></figure><p id="cdad" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">我的数据集很小，包括所有50个州的驾照。数据集很小，因为获得真正的许可证是不可行的。</p><h1 id="82dc" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">选择CNN进行迁移学习:😵</h1><p id="3cf8" class="pw-post-body-paragraph jn jo hi jq b jr lu jt ju jv lv jx jy km lw kb kc kn lx kf kg ko ly kj kk kl hb bi translated">我们可以使用最先进的模型来完成各种深度学习任务，只是受限于个人偏好和用例。你可以在这里查看PyTorch提供的车型:【https://pytorch.org/vision/0.8/models.html T4】</p><p id="984a" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">物体检测问题我个人喜欢<code class="du lz ma mb mc b">YOLO</code>。随着<a class="ae ky" href="https://github.com/ultralytics/yolov5" rel="noopener ugc nofollow" target="_blank"> YOLO </a>架构的发展，可能性是无限的。</p><blockquote class="jk jl jm"><p id="3356" class="jn jo jp jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">预训练的检查点用于训练自定义数据集的架构。这叫做<strong class="jq hj">迁移学习</strong>。迁移学习是机器学习中的一个研究问题，它专注于存储在解决一个问题时获得的知识，并将其应用于不同但相关的问题。例如，在学习识别汽车时获得的知识可以应用于识别卡车。</p></blockquote><p id="bc7c" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">选择一个预训练模型/重量开始训练。这里我们选择<a class="ae ky" href="https://github.com/ultralytics/yolov5/blob/master/models/yolov5l.yaml" rel="noopener ugc nofollow" target="_blank"> YOLOv5l </a>。我们选择了一个更大的模型来获得更好的精度分数。</p><figure class="me mf mg mh fd ij er es paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="er es mm"><img src="../Images/00c657f9e873d253c8546c053ac78531.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Xxlc3LQYReSDq4kH.png"/></div></div></figure><h1 id="e77c" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">设置环境:</h1><p id="ff05" class="pw-post-body-paragraph jn jo hi jq b jr lu jt ju jv lv jx jy km lw kb kc kn lx kf kg ko ly kj kk kl hb bi translated">您可以简单地克隆yolov5项目:</p><pre class="me mf mg mh fd mr mc ms mt aw mu bi"><span id="9b13" class="lg in hi mc b fi mv mw l mx my">$ git clone https://github.com/ultralytics/yolov5  # clone repo</span><span id="fca0" class="lg in hi mc b fi mz mw l mx my">$ cd yolov5</span><span id="84ea" class="lg in hi mc b fi mz mw l mx my">$ pip install -r requirements.txt  # install dependencies</span></pre><blockquote class="jk jl jm"><p id="2f62" class="jn jo jp jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">注意:如果你有一个GPU，你可以按照<a class="ae ky" href="https://pytorch.org/get-started/locally/" rel="noopener ugc nofollow" target="_blank">这些</a>步骤来设置pytorch CUDA启用，然后，按照上述步骤。</p></blockquote><p id="fec2" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">下载任何权重后，我们都要在神经网络<code class="du lz ma mb mc b">.YAML</code> <a class="ae ky" href="https://github.com/ultralytics/yolov5/blob/master/models/yolov5l.yaml" rel="noopener ugc nofollow" target="_blank">文件</a>中编辑多个相同权重的类。例如，我们已经下载了yolov5l weights，所以我们必须将类的数量从默认的(80)编辑到我们的用例(5)中，即<em class="jp">姓名、地址、DL编号、性别和出生日期。</em></p><figure class="me mf mg mh fd ij er es paragraph-image"><div class="er es na"><img src="../Images/c37709cee44fc5404e889cee457af578.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*l6yMGq5NUssDagDd7bRNmg.png"/></div><figcaption class="mi mj et er es mk ml bd b be z dx translated">按需上课。</figcaption></figure><p id="9710" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">当我们从Roboflow下载数据集并将其提取到yolov5文件夹中时，我们得到了另一个<code class="du lz ma mb mc b">.YAML</code>文件，该文件包含train + test数据的位置，并带有我们给它的类名。</p><figure class="me mf mg mh fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/edee8e38e293a96b0676fd12bf96446c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*WIALwowkVwrrw9TCjYdGbQ.png"/></div><figcaption class="mi mj et er es mk ml bd b be z dx translated">数据集。yolov5格式的yaml文件</figcaption></figure><p id="9b4e" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated"><strong class="jq hj">文件夹结构</strong>应该是这样的:</p><figure class="me mf mg mh fd ij er es paragraph-image"><div class="er es nc"><img src="../Images/b8ac2a8ea8c3c274ad9b6ad1fd63d965.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*ZakYpDSmb0vQoZDD3pg_VA.png"/></div></figure><blockquote class="jk jl jm"><p id="679d" class="jn jo jp jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">注意:不要忘记从Roboflow webapp中提取yolo格式的数据集。</p></blockquote><h1 id="54e6" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">训练数据💜</h1><p id="4f51" class="pw-post-body-paragraph jn jo hi jq b jr lu jt ju jv lv jx jy km lw kb kc kn lx kf kg ko ly kj kk kl hb bi translated">在<strong class="jq hj">我们的数据集</strong>、批量大小、图像大小以及任一预训练<code class="du lz ma mb mc b">--weights yolov5l.pt</code>上训练一个YOLOv5l模型(推荐)。预训练重量从<a class="ae ky" href="https://github.com/ultralytics/yolov5/releases" rel="noopener ugc nofollow" target="_blank">最新的YOLOv5版本</a>中自动下载。</p><p id="aed1" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">我们必须编写以下带有指定参数的命令来开始训练过程。为了更好地理解所有的参数或者添加新的参数，你必须参考根目录中的<code class="du lz ma mb mc b">train.py</code>文件。</p><pre class="me mf mg mh fd mr mc ms mt aw mu bi"><span id="d8a7" class="lg in hi mc b fi mv mw l mx my"># Train YOLOv5l on DL for 300 epochs</span><span id="8824" class="lg in hi mc b fi mz mw l mx my">$ python train.py --img 640 --batch 4 --epochs 300 --data US_DL.yaml --cfg yolov5l.yaml --weights yolov5l.pt</span></pre><p id="9242" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">为了在网络上获得更好的洞察力和训练的实时反馈，你可以使用这个命令<code class="du lz ma mb mc b">$ pip install wandb</code>安装weights &amp; bias(<a class="ae ky" href="https://wandb.ai/" rel="noopener ugc nofollow" target="_blank">wandb . ai</a></p><figure class="me mf mg mh fd ij er es paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="er es nd"><img src="../Images/156c29809c6690669e74d64396edd51e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O9iip2sMXpEJoGiWzGm8RQ.png"/></div></div><figcaption class="mi mj et er es mk ml bd b be z dx translated">训练从300个纪元开始</figcaption></figure><p id="d134" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">完整的wandbai日志可以在这里找到:<a class="ae ky" href="https://wandb.ai/thinkersloop/YOLOv5/runs/2ahw81wk/overview?workspace=user-thinkersloop" rel="noopener ugc nofollow" target="_blank"><em class="jp">https://wandb . ai/thinkers loop/yolov 5/runs/2 ahw 81wk/overview？workspace = user-thinkers loop</em></a></p><h2 id="927d" class="lg in hi bd io lh li lj is lk ll lm iw km ln lo ja kn lp lq je ko lr ls ji lt bi translated">结果:</h2><figure class="me mf mg mh fd ij er es paragraph-image"><div role="button" tabindex="0" class="mn mo di mp bf mq"><div class="er es ne"><img src="../Images/7b9c52e576e0981eef4bc7c4e8e037e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*krB7J3RpkyIwxQnM75nG3A.png"/></div></div><figcaption class="mi mj et er es mk ml bd b be z dx translated">结果经过300个时代的训练。</figcaption></figure><h1 id="645a" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">随机数据测试:</h1><p id="64de" class="pw-post-body-paragraph jn jo hi jq b jr lu jt ju jv lv jx jy km lw kb kc kn lx kf kg ko ly kj kk kl hb bi translated">训练最好的模型可以在<strong class="jq hj"> runs\train\exp </strong>文件夹中找到。</p><p id="6bc3" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">现在，让我们来测试一下。<code class="du lz ma mb mc b">detect.py</code>根据各种来源进行推理。</p><pre class="me mf mg mh fd mr mc ms mt aw mu bi"><span id="f87f" class="lg in hi mc b fi mv mw l mx my">$ python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.5 --source test/images</span></pre><p id="beaa" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">生成的图像存储在<strong class="jq hj"> runs\detect\exp </strong>文件夹。</p><pre class="me mf mg mh fd mr mc ms mt aw mu bi"><span id="c9e9" class="lg in hi mc b fi mv mw l mx my">(YOLO-v5) C:\Users\luckie\Projects\Dream\DL data extract\YOLO-v5\yolov5&gt;python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.5 --source test/images<br/>Namespace(agnostic_nms=False, augment=False, classes=None, conf_thres=0.5, device='', exist_ok=False, img_size=640, iou_thres=0.45, name='exp', project='runs/detect', save_conf=False, save_txt=False, source='test/images', update=False, view_img=False, weights=['runs/t<br/>rain/exp/weights/best.pt'])<br/>YOLOv5  torch 1.7.1+cu101 CUDA:0 (GeForce RTX 2070 SUPER, 8192.0MB)</span><span id="e2e5" class="lg in hi mc b fi mz mw l mx my">Fusing layers...<br/>Model Summary: 392 layers, 46622106 parameters, 0 gradients, 114.2 GFLOPS</span><span id="360c" class="lg in hi mc b fi mz mw l mx my">image 1/2 C:\Users\luckie\Projects\Dream\DL data extract\YOLO-v5\yolov5\test\images\test1.jpg: 416x640 1 addresss, 1 date_of_births, 1 license_numbers, 1 names, 1 sexs, Done. (0.050s)</span><span id="458d" class="lg in hi mc b fi mz mw l mx my">image 2/2 C:\Users\luckie\Projects\Dream\DL data extract\YOLO-v5\yolov5\test\images\Alabama-s_jpg.rf.fa47b8af18b6c8263fa5f4c9b7ae760f.jpg: 448x640 1 addresss, 1 date_of_births, 1 license_numbers, 1 names, 1 sexs, Done. (0.048s)</span><span id="b0d2" class="lg in hi mc b fi mz mw l mx my">Results saved to runs\detect\exp<br/>Done. (0.136s)</span></pre><figure class="me mf mg mh fd ij er es paragraph-image"><div class="er es nf"><img src="../Images/b065d7ff97bd9483aeb235003bd923cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1360/format:webp/1*IM7Ns1tGooQJe8jo1qYcZg.jpeg"/></div></figure><p id="2bf1" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi kp translated"><span class="l kq kr ks bm kt ku kv kw kx di"> C </span>祝贺您成功完成上述步骤。干杯！</p><figure class="me mf mg mh fd ij er es paragraph-image"><div class="er es ng"><img src="../Images/bc97adcade95c9dde136aaf99cdef0bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/0*Gh72tMicraybHoOT.gif"/></div></figure><p id="7499" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated"><strong class="jq hj">我的代码的完整版本可以在这里找到:</strong></p><div class="nh ni ez fb nj nk"><a href="https://github.com/lucky-verma/US-Driver-License-data-extraction/tree/master/YOLO-v5" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab dw"><div class="nm ab nn cl cj no"><h2 class="bd hj fi z dy np ea eb nq ed ef hh bi translated">美国驾驶执照数据提取/YOLO V5在master lucky-Verma/美国驾驶执照数据提取</h2><div class="nr l"><h3 class="bd b fi z dy np ea eb nq ed ef dx translated">这个Pytorch实现了从驾驶执照中提取数据，提取所有的分类细节。…</h3></div><div class="ns l"><p class="bd b fp z dy np ea eb nq ed ef dx translated">github.com</p></div></div><div class="nt l"><div class="nu l nv nw nx nt ny ik nk"/></div></div></a></div><p id="e9cd" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">您可以通过LinkedIn联系我:</p><div class="nh ni ez fb nj nk"><a href="https://www.linkedin.com/in/lucky-verma/" rel="noopener  ugc nofollow" target="_blank"><div class="nl ab dw"><div class="nm ab nn cl cj no"><h2 class="bd hj fi z dy np ea eb nq ed ef hh bi translated">幸运的维尔马-研究生研究助理-马里兰大学巴尔的摩县| LinkedIn</h2><div class="nr l"><h3 class="bd b fi z dy np ea eb nq ed ef dx translated">熟练的Python开发人员，具有在信息技术和研究行业工作的经验…</h3></div><div class="ns l"><p class="bd b fp z dy np ea eb nq ed ef dx translated">www.linkedin.com</p></div></div><div class="nt l"><div class="nz l nv nw nx nt ny ik nk"/></div></div></a></div><p id="a15a" class="pw-post-body-paragraph jn jo hi jq b jr js jt ju jv jw jx jy km ka kb kc kn ke kf kg ko ki kj kk kl hb bi translated">谢谢大家！😀</p><figure class="me mf mg mh fd ij er es paragraph-image"><a href="https://www.buymeacoffee.com/luckyverma"><div class="er es oa"><img src="../Images/1140eecacfba5c282bdf17fb7431cdde.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*CdxEUMh0_7AGku4eWnhlog.png"/></div></a></figure></div></div>    
</body>
</html>