<html>
<head>
<title>What is the most important stuff in Vision Transformer?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">视觉变形金刚里最重要的东西是什么？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/what-is-the-most-important-stuff-in-vision-transformer-7635d02f0baf?source=collection_archive---------2-----------------------#2021-11-01">https://medium.com/analytics-vidhya/what-is-the-most-important-stuff-in-vision-transformer-7635d02f0baf?source=collection_archive---------2-----------------------#2021-11-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="0f90" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇博客文章描述了论文“补丁是你所需要的吗？”(<a class="ae jc" href="https://openreview.net/forum?id=TVHS5Y4dNvM" rel="noopener ugc nofollow" target="_blank">在审，2021 </a>)，已提交ICLR2022(截至10月底在审)。本文提出的ConvMixer由CNN+BN组成，与之前的Vision Transformer系列不同，它甚至可以在CIFAR等小数据集上实现结果。然后，我们将从模型包含全局信息和局部信息处理机制的角度讨论补丁是否真的是唯一重要的东西。在这篇文章中，我将根据以下几项进行解释。</p><ol class=""><li id="6ddf" class="jd je hh ig b ih ii il im ip jf it jg ix jh jb ji jj jk jl bi translated">摘要</li><li id="4752" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">视觉变压器</li><li id="1931" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">拟议模型的结构</li><li id="bb3d" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">结果</li><li id="9521" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">你真的只需要补丁吗？</li><li id="a07b" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">结论</li></ol><h1 id="de7a" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">1.摘要</h1><p id="15ea" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">本文摘要如下。</p><p id="f3ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在PyTorch中，ConvMixer可以用大约6行代码实现。该模型比ViT和MLP混合器更有效，即使在CIFAR这样的小数据集上也能达到96%的准确率。作者认为，根据这一结果，修补图像可能比变压器本身更重要。</p><p id="d18c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文提出的Conv混频器采用CNN和批处理范数的结构。近年来，基于变压器的模型已被用于计算机视觉(CV)任务，如图像识别，但在本文中，变压器没有被使用。然而，本文没有使用变压器。然而，它的特点是比以前基于变压器的模型更精确。</p><p id="6410" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于这一结果，作者认为最近基于变压器的模型的突破可能不是由于变压器本身，而是由于在那里发生的“图像修补过程”。</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="ac5e" class="jr js hh bd jt ju lb jw jx jy lc ka kb kc ld ke kf kg le ki kj kk lf km kn ko bi translated">2.什么是视觉变形金刚？</h1><p id="6f7d" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">首先，我要解释一下本文比较的对象ViT(视觉变压器)，以及它所基于的变压器。那么让我们从变压器开始。</p><h2 id="c995" class="lg js hh bd jt lh li lj jx lk ll lm kb ip ln lo kf it lp lq kj ix lr ls kn lt bi translated">变压器</h2><p id="d9ce" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">该变压器是在论文“注意力是你所需要的一切”(<a class="ae jc" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank"> Vaswani et al .，2017 </a>)中提出的模型。它是一个使用称为自我关注的机制的模型，这种机制既不是CNN，也不是LSTM，并建立了Transformer模型，以显著优于现有的方法。结果比现有的方法好得多。</p><p id="8026" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意下图中标有多头注意的部分是Transformer的核心部分，但它也像ResNet一样使用了skip-joining。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div class="er es lu"><img src="../Images/818ae178d8a2043160e092595994f411.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/0*2nHsR7Hbu58vb59x.png"/></div><figcaption class="mc md et er es me mf bd b be z dx translated">变压器架构。来自<a class="ae jc" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">瓦斯瓦尼等人，2017 </a></figcaption></figure><p id="a989" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">变压器中使用的注意机制使用了三个变量:<strong class="ig hi"> <em class="mg"> Q </em> </strong>(查询)、<strong class="ig hi"> <em class="mg"> K </em> </strong>(键)、和<strong class="ig hi"> <em class="mg"> V </em> </strong>(值)。简单地说，它计算一个查询标记(标记:类似于一个单词)和一个键标记的注意力权重，并乘以与每个键相关联的值。简而言之，它计算查询令牌和密钥令牌之间的关联(注意力权重),并乘以与每个密钥相关联的值。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mh"><img src="../Images/427ab8b271427eba1d7e0e33e55f52ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CG3luu-tjlwQ2y3e.png"/></div></div></figure><p id="f202" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将<strong class="ig hi"> Q，K，V </strong>计算定义为单头，多头注意机制定义如下。上图中的(单头)注意机制原样使用了<strong class="ig hi"> <em class="mg"> Q </em> </strong>和<strong class="ig hi"> <em class="mg"> K </em> </strong>。尽管如此，在多头注意力机制中，每个头都有其投影矩阵<strong class="ig hi"><em class="mg"/></strong><strong class="ig hi"><em class="mg"/></strong><strong class="ig hi"><em class="mg">【w_i^v</em></strong>，并且它们使用使用这些矩阵投影的特征值来计算注意力权重。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mh"><img src="../Images/8e76d686ff7276b3604d5dea516eb506.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SK6_x7IZxbHEZC0A.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">多头注意力</figcaption></figure><p id="58df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果这种注意机制中使用的<strong class="ig hi"> <em class="mg"> Q，K，V </em> </strong>都是从同一个输入计算出来的，则专门称为自我注意。另一方面，Transformer解码器的上部不是一个“自我”注意力机制，因为它使用来自编码器的<strong class="ig hi"> <em class="mg"> Q </em> </strong>和来自解码器的<strong class="ig hi"> <em class="mg"> K </em> </strong>和<strong class="ig hi"> <em class="mg"> V </em> </strong>来计算注意力。</p><p id="8ef7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">实际应用的图像如下图所示。该图示出了使用单词“making”作为查询为每个关键令牌计算的注意力权重的可视化。转换器使用多头自关注机制传播到后面的层，每个头学习不同的依赖关系。下图中的关键词是彩色的，代表每个头部的注意力权重。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mm"><img src="../Images/dfb5395f4b822ff37ae5266126004586.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4v08PviLhsAXBi5L.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">注意力权重可视化。图片引自<a class="ae jc" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">瓦斯瓦尼等人，2017 </a>我已经注释过了。</figcaption></figure><p id="8cd7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意力权重可视化。图片引自<a class="ae jc" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">瓦斯瓦尼等人，2017 </a>我已经注释过了。</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h2 id="404d" class="lg js hh bd jt lh li lj jx lk ll lm kb ip ln lo kf it lp lq kj ix lr ls kn lt bi translated">视觉转换器(ViT)</h2><p id="0ec5" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">视觉变压器(ViT)是一种将变压器应用于图像分类任务的模型，于2020年10月提出(<a class="ae jc" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"> Dosovitskiy等人2020 </a>)。模型架构与原始的Transformer几乎相同，但有一点不同，它允许将图像作为输入处理，就像自然语言处理一样。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mn"><img src="../Images/d1161a83433ba4e5fd8e6c5bfa0bc48e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dorEbbhQMsZAg2Xv.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">视觉转换器架构。图片引自<a class="ae jc" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"> Dosovitskiy等人2020 </a>，我已经给它做了注释。</figcaption></figure><p id="2848" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">视觉转换器架构。图片引自<a class="ae jc" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"> Dosovitskiy et al. 2020 </a>，我已经做了注释。</p><p id="ae3b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，ViT将图像分成N个“小块”,例如16x16。由于面片本身是3D数据(高x宽x通道数)，它们不能由处理语言(2D)的转换器直接处理，因此它将它们展平并进行线性投影，以将其转换为2D数据。因此，每个补丁都可以被视为一个令牌，可以输入到转换器中。</p><p id="b63f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，ViT采用先预训练后微调的策略。ViT使用包含3亿张图像的数据集JFT-300M进行预训练，然后在ImageNet等下游任务上进行微调。ViT是第一个在ImageNet上实现SotA性能的纯变形金刚模型，这导致了对变形金刚应用于计算机视觉任务的研究大幅增加。</p><p id="19db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是，训练ViT需要大量的数据。变压器在数据较少的情况下不太准确，但在数据较多的情况下变得更加准确，并且在JFT-300M上进行预训练时表现优于CNN。更多详情请参考原论文。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div class="er es mo"><img src="../Images/5da709e2f81ef6097b9b771ea9091316.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/0*HlIeTgx0GOitOZhk.png"/></div><figcaption class="mc md et er es me mf bd b be z dx translated">视觉转换结果。(<a class="ae jc" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"> Dosovitskiy等人2020 </a></figcaption></figure></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="567c" class="jr js hh bd jt ju lb jw jx jy lc ka kb kc ld ke kf kg le ki kj kk lf km kn ko bi translated">3.拟议模型的结构</h1><p id="5762" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">现在，让我们进入本文提出的Conv混频器的结构。首先，模型的架构如下面的图2所示。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mp"><img src="../Images/640173c3d50abc7f5aa9d058d7abbcac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qPwvSTorY--QiXwZ4g6cgw.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">ConvMixer架构(来自<a class="ae jc" href="https://openreview.net/forum?id=TVHS5Y4dNvM" rel="noopener ugc nofollow" target="_blank">https://openreview.net/forum?id=TVHS5Y4dNvM</a>)</figcaption></figure><p id="9270" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该模型的总体架构与ViT相同:补丁嵌入、多次通过ConvMixer层块、使用全局平均池和全连接层进行分类。在结构上，不需要像ViT中那样添加位置嵌入向量，块本身也相对简单。ConvMixer模型(不是ConvMixer层，而是整个模型)可以在Pytorch中实现，只有六行代码，如下图3所示。尽管这个实现有点特殊，但您可以看到它是一个结构相对简单的模型。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mq"><img src="../Images/da2c9ffef2176a789ff2409ea1a9ebfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jImqBNr3RS376HOsm1qWqw.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">ConvMixer代码(来自<a class="ae jc" href="https://openreview.net/forum?id=TVHS5Y4dNvM" rel="noopener ugc nofollow" target="_blank">https://openreview.net/forum?id=TVHS5Y4dNvM</a></figcaption></figure><p id="0ed8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们更仔细地看看模型的结构，它可以被分解成以下步骤，我们将更详细地了解每一个步骤。</p><p id="2867" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 1。打补丁</strong></p><p id="a4ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。ConvMixer层xN </strong></p><p id="84eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> — 2.1深度方向Conv </strong></p><p id="c72a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> — 2.2点Conv </strong></p><p id="5887" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。使用衬垫层分类</strong></p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h2 id="ad55" class="lg js hh bd jt lh li lj jx lk ll lm kb ip ln lo kf it lp lq kj ix lr ls kn lt bi translated">1.修补</h2><p id="d195" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">在ViT中，修补是通过将图像分成固定大小的块、展平它们，然后线性投影它们以将它们转换成2D数据来实现的。ConvMixer不需要将图像(HxWxC)投影到2D数据，因为它使用CNN。ConvMixer做同样的事情，将图像分成小块，但在将图像分成小块后，它应用卷积为每个小块创建特征。如果你把它看成是[CNN -&gt; BN]代替ViT的[Flatten -&gt; Linnear]过程就很好理解了。公式如下。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mr"><img src="../Images/63ca48396d52667f87be158623def2fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2koUNdkxuB1GnxKNeHv0fg.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">修补</figcaption></figure><p id="b8fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">顺带一提，这里用到的激活函数σ叫做GELU(高斯误差线性单位，<a class="ae jc" href="https://arxiv.org/abs/1606.08415v4" rel="noopener ugc nofollow" target="_blank"> Dan et al .，2016 </a>)。该激活函数使用高斯分布φ的累积函数，并且如下面的等式所示。它在无穷远处渐近于RELU，但在零附近表现出平滑的行为。</p><p id="3bce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"><em class="mg">【GELU(x)= x *φ(x)</em></strong></p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es ms"><img src="../Images/68b53252967d6aad9dbfbe8ce0c2ec11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f0DInHkTwusdk7znRQaLPQ.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">GELU激活函数(<a class="ae jc" href="https://arxiv.org/abs/1606.08415v4" rel="noopener ugc nofollow" target="_blank">丹等，2016 </a>)</figcaption></figure></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h2 id="317e" class="lg js hh bd jt lh li lj jx lk ll lm kb ip ln lo kf it lp lq kj ix lr ls kn lt bi translated">2 ConvMixer层xN</h2><p id="5330" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">接下来，我们将看看ConvMixer层，这是本文的核心技术。图层的结构是深度方向conv和点方向conv的组合，如下所示。让我们详细看一下每一个。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mt"><img src="../Images/e555130c591ec25c5e1ceeb29e427b0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CM3ZEl11ulGjxB6GQVQ5PA.png"/></div></div></figure><h2 id="89b3" class="lg js hh bd jt lh li lj jx lk ll lm kb ip ln lo kf it lp lq kj ix lr ls kn lt bi translated">2–1.深度方向卷积</h2><p id="6f3a" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">首先，让我们看看深度方向的Conv，它位于ConvMixer层的前半部分。顾名思义，它对每个深度或每个通道执行单独的卷积。图表如下。(图摘自<a class="ae jc" href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728" rel="noopener" target="_blank">这篇博文</a>。)</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div class="er es mu"><img src="../Images/656a2bd017bb5f89f2bdabc0aac6f5bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NkiNfJHW2Ab2j_G0iFbGtg.png"/></div><figcaption class="mc md et er es me mf bd b be z dx translated">正常卷积(图摘自<a class="ae jc" href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728" rel="noopener" target="_blank">这篇博文</a>)</figcaption></figure><figure class="lv lw lx ly fd lz er es paragraph-image"><div class="er es mu"><img src="../Images/d93c951dfb8f848848c8a472d129e924.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*83v-FgBo3WZOwa5_Hbn8_A.png"/></div><figcaption class="mc md et er es me mf bd b be z dx translated">深度conv(图摘自<a class="ae jc" href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728" rel="noopener" target="_blank">这篇博文</a>)</figcaption></figure><p id="4ffe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上图显示了正常的CNN，下图显示了12x12x3(HWC)图像上的深度卷积。对于普通的CNN，卷积核的维数是[核大小，核大小，通道]。每个内核的输出图被聚集成单个特征图(一个通道)。通过对输出声道的数量(在这种情况下为256)使用该滤波器，输出具有输出声道数量的深度的特征图。</p><p id="5aba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一方面，在深度conv中，每个内核是[内核大小，内核大小，1](*多个通道可以被视为一组，但为了简单起见，我使用1)。与跨越所有输入通道的普通卷积不同，卷积是针对每个输入通道进行的。换句话说，全局处理是基于每个特征图中的信息完成的。</p><h2 id="0535" class="lg js hh bd jt lh li lj jx lk ll lm kb ip ln lo kf it lp lq kj ix lr ls kn lt bi translated">2–2.逐点Conv</h2><p id="556a" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">接下来，我们来看看逐点卷积，它是在ConvMixer层的后半部分执行的(下图摘自这篇博文)。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div class="er es mu"><img src="../Images/d9099f1a16ab29144e69fa95dbd56ff9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*soVGlLsptHEm8bnps0unww.png"/></div><figcaption class="mc md et er es me mf bd b be z dx translated">逐点conv(图摘自<a class="ae jc" href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728" rel="noopener" target="_blank">这篇博文</a>)</figcaption></figure><p id="cc9e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这与前面描述的深度方向的Conv相反，其中每个位置都在整个深度上进行处理。换句话说，在考虑完整特征图中的信息的同时进行局部处理。</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h2 id="b8fd" class="lg js hh bd jt lh li lj jx lk ll lm kb ip ln lo kf it lp lq kj ix lr ls kn lt bi translated">3.分类使用<strong class="ak">衬垫层</strong></h2><p id="3d4e" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">这与常规ResNet和EfficientNet中完成的过程相同。通过取平均值(全局平均池)，将每个要素地图中的信息转换为单个值。然后通过加权这些值来执行分类(密集层)。</p><p id="f76d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在基于变换器的方法中，输出向量是二维的，因此它可以传播到所有便利层，而不需要这个平均过程。</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="3438" class="jr js hh bd jt ju lb jw jx jy lc ka kb kc ld ke kf kg le ki kj kk lf km kn ko bi translated">4.结果</h1><p id="4a9d" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">首先，我们来看看ImageNet训练的结果(见下图)。这是在没有预训练的情况下训练ImageNet的结果，我们可以看到对于相同数量的参数，ConvMixer具有更高的精度。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mv"><img src="../Images/d3d9523a7188cc76f3f4d30ded1e0732.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LDW_AJxig8O88OzaAjZKtw.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">ImageNet结果(来自<a class="ae jc" href="https://openreview.net/forum?id=TVHS5Y4dNvM" rel="noopener ugc nofollow" target="_blank">https://openreview.net/forum?id=TVHS5Y4dNvM</a></figcaption></figure><p id="c6f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ConvMixer的另一个特性是它在大型数据集(如ImageNet)和小型数据集(如CIFAR)上的准确性。在很多提出ViT、MLP混频器等ViT系列的论文中，都包含了CIFAR10经过微调后的训练结果，但全刮训练的精度却没有。我觉得这是因为ViT系列的模型需要大量的数据，精度不是很好。本文给出了CIFAR的全划痕训练结果，并声称ConvMixer是数据高效的，准确率约为96%(表3)。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mw"><img src="../Images/aafac0610a6617e3a185f1a6c4906497.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AOkAtoBDMEH2_FOhEvCFcg.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">CIFAR10结果(来自https://openreview.net/forum?id=TVHS5Y4dNvM<a class="ae jc" href="https://openreview.net/forum?id=TVHS5Y4dNvM" rel="noopener ugc nofollow" target="_blank"/>)</figcaption></figure><h1 id="211c" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">5.你真的只需要补丁吗？</h1><p id="ce33" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated"><strong class="ig hi"> <em class="mg">注！这部分包含了很多个人观点。</em> </strong></p><p id="3676" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自2020年底推出ViT以来，提出了各种改进方法。有些改进使用了变压器，有些结构不依赖变压器，比如本文和MLP混频器(<a class="ae jc" href="https://arxiv.org/abs/2105.01601" rel="noopener ugc nofollow" target="_blank"> Ilya et al，2021 </a>)。那么，像这篇论文声称的那样“打补丁”重要吗？在这一节中，让我们从不同的角度来观察这个架构。</p><p id="8c5a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，让我们比较三种架构:ViT、MLP混频器和ConvMixer。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mn"><img src="../Images/d1161a83433ba4e5fd8e6c5bfa0bc48e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dorEbbhQMsZAg2Xv.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">视觉转换器架构。图片引自<a class="ae jc" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"> Dosovitskiy et al. 2020 </a>，我已经做了注释。</figcaption></figure><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mx"><img src="../Images/266fa788e7fa661d697a30ba6cca4ad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zEMf7Dxdp2ZBdp_fN0elIg.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">MLP混合器(<a class="ae jc" href="https://arxiv.org/abs/2105.01601" rel="noopener ugc nofollow" target="_blank">伊利亚等人，2021 </a></figcaption></figure><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es mp"><img src="../Images/640173c3d50abc7f5aa9d058d7abbcac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qPwvSTorY--QiXwZ4g6cgw.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">ConvMixer(来自<a class="ae jc" href="https://openreview.net/forum?id=TVHS5Y4dNvM" rel="noopener ugc nofollow" target="_blank">https://openreview.net/forum?id=TVHS5Y4dNvM</a></figcaption></figure><p id="0914" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ViT的Transformer编码器模块、MIP-Mixer的MLP1和ConvMixer的ConvMixer层都包含将局部信息处理(补丁内的信息传播)和全局信息处理(补丁间的信息传播)结合在一起的处理。</p><p id="5f9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于全局信息处理，ViT使用自我注意，MLP混合器使用MLP1，而ConvMixer使用深度conv来处理全局信息。像ResNet和EfficientNet这样的传统CNN模型滑动一个固定大小的内核(主要使用三个)，因此它们的层处理和传播的范围很窄。</p><p id="6f67" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ConvMixer中使用的深度conv对于全局信息处理来说似乎较弱。尽管如此，ConvMixer将CNN的内核大小设置为7或9(通常经常使用3)，并且它被认为是为处理全局信息而设计的。事实上，随着内核大小的减小，精确度也会降低。至于本地信息处理，ViT使用(位置式)FFN，MLP混频器使用MLP2，而ConvMixer使用点式conv来处理本地信息。</p><p id="3ef3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这样，ViT系列的网络遵循变压器模块的结构，其中使用全局信息处理和局部信息处理。我相信这种处理全球信息的机制不同于传统的CNN模式。</p><p id="d95c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">除了《变形金刚》、《MLP》和CNN之外，全球处理还有哪些选择？不是简历论文，而是测试这一点的论文是“FNet:将令牌与傅立叶变换混合”(J <a class="ae jc" href="https://arxiv.org/abs/2105.03824" rel="noopener ugc nofollow" target="_blank"> ames et al .，2021 </a>)。</p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="mi mj di mk bf ml"><div class="er es my"><img src="../Images/670c205840673e36f5d7ed14627b9c85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ma5yYlkFJg26za8bjQ6gQ.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">FNet (J <a class="ae jc" href="https://arxiv.org/abs/2105.03824" rel="noopener ugc nofollow" target="_blank">艾姆斯等人，2021 </a>)。</figcaption></figure><p id="0cef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">FNet采用傅立叶变换作为全局过程。由于它是在不同的基础上求和，因此从物理上进行解释具有挑战性，但它已经取得了一些良好的结果。如题，本文重点讨论混合令牌。除了傅立叶变换，作者还尝试了将符号(如单词)与随机矩阵和线性变换混合的模型，以解释全局信息。</p><p id="c37e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然打补丁可能也有帮助，但从这篇FNet论文来看，除了本地信息之外，考虑全局信息似乎也有一些效果</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><h1 id="b7e7" class="jr js hh bd jt ju lb jw jx jy lc ka kb kc ld ke kf kg le ki kj kk lf km kn ko bi translated">6.结论</h1><p id="567f" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">在这篇文章中，我解释了ConvMixer，它可以通过使用CNN的简单模型超越ViT。在标题中，作者声称打补丁很重要。但是，也许做传统CNN无法考虑的全局处理也很重要。</p></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><p id="b52f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="d986" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">🌟我每周发布时事通讯！请订阅！🌟</h1><div class="mz na ez fb nb nc"><a href="https://www.getrevue.co/profile/akiratosei" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hi fi z dy nh ea eb ni ed ef hg bi translated">阿基拉的机器学习新闻- Revue</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">由Akira的机器学习新闻-由Akihiro FUJII:制造工程师/机器学习工程师/硕士…</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">www.getrevue.co</p></div></div><div class="nl l"><div class="nm l nn no np nl nq ma nc"/></div></div></a></div><p id="8e8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="e39c" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">其他博客</h1><div class="mz na ez fb nb nc"><a href="https://towardsdatascience.com/machine-learning-2020-summary-84-interesting-papers-articles-45bd45c0d35b" rel="noopener follow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hi fi z dy nh ea eb ni ed ef hg bi translated">机器学习2020摘要:84篇有趣的论文/文章</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">在这篇文章中，我总共展示了2020年发表的84篇我觉得特别有趣的论文和文章…</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="nr l nn no np nl nq ma nc"/></div></div></a></div><div class="mz na ez fb nb nc"><a href="https://towardsdatascience.com/recent-developments-and-views-on-computer-vision-x-transformer-ed32a2c72654" rel="noopener follow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hi fi z dy nh ea eb ni ed ef hg bi translated">计算机视觉x变形金刚的最新发展和看法</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">《变形金刚》和CNN的区别，为什么《变形金刚》很重要，它的弱点是什么。</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="ns l nn no np nl nq ma nc"/></div></div></a></div><div class="mz na ez fb nb nc"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/reach-and-limits-of-the-supermassive-model-gpt-3-5012a6ddff00"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hi fi z dy nh ea eb ni ed ef hg bi translated">超大质量模型GPT-3的到达和极限</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">在这篇博文中，我将从技术上解释GPT 3号，GPT 3号取得了什么，GPT 3号没有取得什么…</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">medium.com</p></div></div><div class="nl l"><div class="nt l nn no np nl nq ma nc"/></div></div></a></div><div class="mz na ez fb nb nc"><a href="https://towardsdatascience.com/do-vision-transformers-see-like-convolutional-neural-networks-paper-explained-91b4bd5185c8" rel="noopener follow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hi fi z dy nh ea eb ni ed ef hg bi translated">视觉变形器看起来像卷积神经网络吗？(论文解释)</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">我将仔细研究CNN和变形金刚之间的差异</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">towardsdatascience.com</p></div></div><div class="nl l"><div class="nu l nn no np nl nq ma nc"/></div></div></a></div><p id="6e7e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="a8a2" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">关于我</h1><p id="82bb" class="pw-post-body-paragraph ie if hh ig b ih kp ij ik il kq in io ip kr ir is it ks iv iw ix kt iz ja jb ha bi translated">制造工程师/机器学习工程师/数据科学家/物理学硕士/<a class="ae jc" href="https://t.co/hjHHbG24Ph?amp=1&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">http://github.com/AkiraTOSEI/</a></p><p id="ac29" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">推特:【https://twitter.com/AkiraTOSEI T2】</p><div class="mz na ez fb nb nc"><a href="https://www.linkedin.com/in/%E4%BA%AE%E5%AE%8F-%E8%97%A4%E4%BA%95-999868122/" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hi fi z dy nh ea eb ni ed ef hg bi">Akihiro FUJII - Engineering Manager - 株式会社エクサウィザーズ/ExaWizards Inc. | LinkedIn</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">Twitter(我对最新的论文有一个简单的解释) :机器上的https://twitter.com/AkiraTOSEI-周报…</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">www.linkedin.com</p></div></div><div class="nl l"><div class="nv l nn no np nl nq ma nc"/></div></div></a></div></div></div>    
</body>
</html>