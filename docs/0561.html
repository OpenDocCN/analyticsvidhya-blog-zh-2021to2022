<html>
<head>
<title>Realtime Face Emotion Recognition using transfer learning in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow中基于迁移学习的实时人脸情感识别</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/realtime-face-emotion-recognition-using-transfer-learning-in-tensorflow-3add4f4f3ff3?source=collection_archive---------0-----------------------#2021-01-22">https://medium.com/analytics-vidhya/realtime-face-emotion-recognition-using-transfer-learning-in-tensorflow-3add4f4f3ff3?source=collection_archive---------0-----------------------#2021-01-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="16c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让项目开始吧！！</p><h1 id="49d2" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">数据集:</h1><p id="d43c" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">我们将使用的数据集是2013年在国际机器学习会议上发表的fer2013。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/a733d39f6535db442ac60076f6c14e93.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UxtJKEoM02tXBICTYyOB7g.jpeg"/></div></div></figure><p id="6435" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您可以通过以下链接下载该数据集:</p><div class="ks kt ez fb ku kv"><a href="https://www.kaggle.com/msambare/fer2013" rel="noopener  ugc nofollow" target="_blank"><div class="kw ab dw"><div class="kx ab ky cl cj kz"><h2 class="bd hj fi z dy la ea eb lb ed ef hh bi translated">FER-2013年</h2><div class="lc l"><h3 class="bd b fi z dy la ea eb lb ed ef dx translated">从图像中学习面部表情</h3></div><div class="ld l"><p class="bd b fp z dy la ea eb lb ed ef dx translated">www.kaggle.com</p></div></div><div class="le l"><div class="lf l lg lh li le lj kq kv"/></div></div></a></div></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><p id="0537" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们深入到项目中，首先使用Jupyter Notebook或任何其他您喜欢的环境打开一个新项目。首先也是最重要的，导入库</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="b020" class="lw je hi ls b fi lx ly l lz ma">import tensorflow as tf <br/>import cv2 <br/>import os<br/>import matplotlib.pyplot as plt <br/>import pandas as pd<br/>import numpy as np</span></pre><p id="835b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">OpenCV-Python是一个Python绑定库，旨在解决计算机视觉问题。方法从指定的文件中加载一幅图像。如果图像无法读取(由于缺少文件、不正确的权限、不支持或无效的格式)，则此方法返回一个空矩阵。我们可以通过下面一行代码来读取图像:</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="5835" class="lw je hi ls b fi lx ly l lz ma">img_array = cv2.imread(‘train/0/Training_3908.jpg’)</span></pre><p id="d419" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了检查图像的大小，我们使用:</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="fa12" class="lw je hi ls b fi lx ly l lz ma">img_array.shape</span></pre><p id="8d43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">matplotlib 函数<strong class="ih hj"> imshow </strong>()从一个二维numpy数组中创建一个图像。对于数组中的每个元素，该图像都有一个正方形。每个方块的颜色由相应数组元素的值和<strong class="ih hj"> imshow </strong>()使用的颜色图决定。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="134e" class="lw je hi ls b fi lx ly l lz ma">plt.imshow(img_array)</span></pre><p id="ea35" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将创建一个包含目录名的变量和一个包含该目录下文件夹名的列表。在我的例子中，我已经根据情感标签重命名了文件夹。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="e595" class="lw je hi ls b fi lx ly l lz ma">Datadirectory = "Training/"<br/>Classes = ["0","1","2","3","4","5","6"]</span></pre><p id="9019" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> ImageNet </strong>数据集包含固定<strong class="ih hj">大小</strong>的图像<strong class="ih hj"> 224 </strong> * <strong class="ih hj"> 224 </strong>和<strong class="ih hj">具有</strong> RGB通道，但由于<strong class="ih hj"> fer2013 </strong>具有大小<strong class="ih hj"> 48*48 </strong>的图像，因此我们必须调整图像的大小。为了调整图像的大小，OpenCV提供了cv2.resize()函数。<strong class="ih hj"> cv2.cvtColor() </strong>方法用于将图像从一个颜色空间转换到另一个颜色空间。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="ccb3" class="lw je hi ls b fi lx ly l lz ma">img_size = 224 <br/>new_array = cv2.resize(img_array, (img_size, img_size))<br/>plt.imshow(cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB))<br/>plt.show()</span></pre><p id="04ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">执行上述代码的原因是我们正在使用迁移学习，因此对于迁移学习，如果我们想要使用任何深度学习分类器，那么这些维度必须相同。现在，我们将读取所有的图像，并将它们转换为数组。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="7896" class="lw je hi ls b fi lx ly l lz ma">training_Data = []<br/>def create_training_Data():<br/>  for category in Classes:<br/>    path = os.path.join(Datadirectory, category)<br/>    class_num = Classes.index(category)<br/>    for img in os.listdir(path):<br/>      try:<br/>        img_array = cv2.imread(os.path.join(path, img))<br/>        new_array = cv2.resize(img_array, (img_size, img_size))<br/>        training_Data.append([new_array, class_num])<br/>      except Exception as e:<br/>        pass</span></pre><p id="070f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们调用这个函数:</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="1424" class="lw je hi ls b fi lx ly l lz ma">create_training_Data()</span></pre><p id="7444" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了让我们的深度学习架构变得动态和健壮，让我们打乱顺序:</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="c276" class="lw je hi ls b fi lx ly l lz ma">import random<br/>random.shuffle(training_Data)</span></pre><p id="2fa1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们把特性和标签分开。我们将使用深度学习架构MobileNet，它需要4个维度，因此我们将重塑功能列表。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="e311" class="lw je hi ls b fi lx ly l lz ma">X = []<br/>y = []<br/>for features, label in training_Data:<br/>  X.append(features)<br/>  y.append(label)<br/>X = np.array(X).reshape(-1, img_size, img_size, 3) <br/># 3 is the channel for RGB</span></pre><p id="d702" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练神经网络的最佳实践之一是将你的数据标准化以获得一个接近于0的平均值。数据通常会加速学习并导致更快的收敛。让我们在训练前将数据标准化</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="671f" class="lw je hi ls b fi lx ly l lz ma">X =X/255.0</span></pre><p id="dcee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将使用迁移学习来训练我们的深度学习模型</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="5656" class="lw je hi ls b fi lx ly l lz ma">from tensorflow import keras<br/>from tensorflow.keras import layers</span></pre><p id="62ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Keras应用程序是深度学习模型，可与预训练的权重一起使用。这些模型可用于预测、特征提取和微调。这是一些可用模型的图表。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es me"><img src="../Images/28677addb56811601388333ec1d1d7e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8DFTKud8fXayYzGN5g90fA.png"/></div></div></figure><p id="df0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将使用MobileNetV2</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="7226" class="lw je hi ls b fi lx ly l lz ma">model = tf.keras.applications.MobileNetV2()</span></pre><p id="3384" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们改变基本输入</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="ccad" class="lw je hi ls b fi lx ly l lz ma">base_input = model.layers[0].input</span></pre><p id="0667" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因为我们想要七个班级，所以让我们削减产量</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="297f" class="lw je hi ls b fi lx ly l lz ma">base_output = model.layers[-2].output</span></pre><p id="db55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">密集层</strong>是深度连接的神经网络<strong class="ih hj">层</strong>，这意味着<strong class="ih hj">密集层</strong>中的每个神经元接收来自其前一<strong class="ih hj">层</strong>的所有神经元的输入。<strong class="ih hj">激活</strong>功能是一个数学“门”，位于馈入当前神经元的输入和去往下一个<strong class="ih hj">层</strong>的输出之间。它可以像阶跃函数一样简单，根据规则或阈值打开或关闭神经元输出。这里我们使用relu作为激活函数。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="5a47" class="lw je hi ls b fi lx ly l lz ma">final_output = layers.Dense(128)(base_output) <br/>final_output = layers.Activation(‘relu’)(final_output) <br/>final_output = layers.Dense(64)(final_output)<br/>final_output = layers.Activation(‘relu’)(final_output)<br/>final_output = layers.Dense(7, activation=’softmax’)(final_output) </span></pre><p id="791c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们创建我们的新模型。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="3a34" class="lw je hi ls b fi lx ly l lz ma">new_model = keras.Model(inputs = base_input, outputs = final_output)</span></pre><p id="af01" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">编译</strong>定义损失函数、优化器和指标。仅此而已。这与重量无关，您可以<strong class="ih hj">编译</strong>一个<strong class="ih hj">模型</strong>任意多次，而不会对预训练的重量造成任何问题。你需要一个<strong class="ih hj">编译的模型</strong>来训练(因为训练使用了损失函数和优化器)。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="f0a8" class="lw je hi ls b fi lx ly l lz ma">new_model.compile(loss=”sparse_categorical_crossentropy”, optimizer = “adam”, metrics = [“accuracy”])</span></pre><p id="252d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练<strong class="ih hj">型号</strong>25个时代。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="26dd" class="lw je hi ls b fi lx ly l lz ma">new_model.fit(X, Y, epochs = 25)</span></pre><p id="c948" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是保存模型的代码。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="7fc7" class="lw je hi ls b fi lx ly l lz ma">new_model.save(‘Final_model_95p07.h5’)</span></pre><p id="8783" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面的代码是测试它使用一个现场摄像头。</p><pre class="kh ki kj kk fd lr ls lt lu aw lv bi"><span id="3389" class="lw je hi ls b fi lx ly l lz ma">import cv2 # pip install opencv-python<br/>#pip install opencv-contrib-python full package<br/>#from deepface import DeepFace #pip install deepface<br/>path = "haarcascade_frontalface_default.xml"<br/>font_scale = 1.5<br/>font = cv2.FONT_HERSHEY_PLAIN</span><span id="bc18" class="lw je hi ls b fi mf ly l lz ma">#set the rectangle background to white<br/>rectangle_bgr = (255, 255, 255)<br/>#make a black image<br/>img = np.zeros((500, 500))<br/>#set some text<br/>text = "Some text in a box!"<br/># get the width and height of the text box<br/>(text_width, text_height) = cv2.getTextSize(text, font, fontScale=font_scale, thickness=1)[0]<br/># set the text start position<br/>text_offset_x = 10<br/>text_offset_y = img.shape[0] - 25<br/>#make the coords of the box with a small padding of two pixels<br/>box_coords = ((text_offset_x, text_offset_y), (text_offset_x + text_width + 2, text_offset_y - text_height - 2))<br/>cv2.rectangle(img, box_coords[0], box_coords[1], rectangle_bgr, cv2.FILLED)<br/>cv2.putText(img, text, (text_offset_x, text_offset_y), font, fontScale=font_scale, color=(0, 0, 0), thickness=1)</span><span id="5741" class="lw je hi ls b fi mf ly l lz ma">cap = cv2.VideoCapture(1)<br/># Check if the webcam is opened correctly<br/>if not cap.isOpened():<br/>  cap = cv2.VideoCapture(0)<br/>if not cap.isOpened():<br/>  raise IOError("Cannot open webcam")</span><span id="18e2" class="lw je hi ls b fi mf ly l lz ma">while True:<br/>  ret, frame = cap.read()<br/>  #eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')<br/>  faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')<br/>  gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)<br/>  #print(faceCascade.empty())<br/>  faces = faceCascade.detectMultiScale(gray,1.1,4)<br/>  for x,y,w,h in faces:<br/>    roi_gray = gray[y:y+h, x:x+w]<br/>    roi_color = frame[y:y+h, x:x+w]<br/>    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)<br/>    facess = faceCascade.detectMultiScale(roi_gray)<br/>    if len(facess) == 0:<br/>      print("Face not detected")<br/>    else:<br/>      for (ex,ey,ew,eh) in facess:<br/>        face_roi = roi_color[ey: ey+eh, ex:ex + ew] ## cropping the face<br/>    <br/>    final_image = cv2.resize(face_roi, (224,224))<br/>    final_image = np.expand_dims(final_image,axis=0) ## need fourth dimension<br/>    final_image = final_image/255.0</span><span id="5948" class="lw je hi ls b fi mf ly l lz ma">font = cv2.FONT_HERSHEY_SIMPLEX</span><span id="e260" class="lw je hi ls b fi mf ly l lz ma">Predictions = new_model.predict(final_image)</span><span id="0828" class="lw je hi ls b fi mf ly l lz ma">font_scale = 1.5<br/>    font = cv2.FONT_HERSHEY_PLAIN</span><span id="0a08" class="lw je hi ls b fi mf ly l lz ma">if(np.argmax(Predictions)==0):<br/>      status = "Angry"</span><span id="2c32" class="lw je hi ls b fi mf ly l lz ma">x1,y1,w1,h1 = 0,0,175,75<br/>      #Draw black background rectangle<br/>      cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0,0,0), -1)<br/>      #Addd text<br/>      cv2.putText(frame, status, (x1 + int(w1/10), y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)</span><span id="e36d" class="lw je hi ls b fi mf ly l lz ma">cv2.putText(frame, status,(100,150),font, 3,(0, 0, 255),2,cv2.LINE_4)</span><span id="9233" class="lw je hi ls b fi mf ly l lz ma">cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 255))</span><span id="83cd" class="lw je hi ls b fi mf ly l lz ma">elif (np.argmax(Predictions)==1):<br/>      status = "Disgust"</span><span id="367e" class="lw je hi ls b fi mf ly l lz ma">x1,y1,w1,h1 = 0,0,175,75<br/>      #Draw black background rectangle<br/>      cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0,0,0), -1)<br/>      #Addd text<br/>      cv2.putText(frame, status, (x1 + int(w1/10), y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)</span><span id="47c4" class="lw je hi ls b fi mf ly l lz ma">cv2.putText(frame, status,(100,150),font, 3,(0, 0, 255),2,cv2.LINE_4)</span><span id="f7cc" class="lw je hi ls b fi mf ly l lz ma">cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 255))</span><span id="c130" class="lw je hi ls b fi mf ly l lz ma">elif (np.argmax(Predictions)==2):<br/>      status = "Fear"</span><span id="be80" class="lw je hi ls b fi mf ly l lz ma">x1,y1,w1,h1 = 0,0,175,75<br/>      #Draw black background rectangle<br/>      cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0,0,0), -1)<br/>      #Addd text<br/>      cv2.putText(frame, status, (x1 + int(w1/10), y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)</span><span id="d738" class="lw je hi ls b fi mf ly l lz ma">cv2.putText(frame, status,(100,150),font, 3,(0, 0, 255),2,cv2.LINE_4)</span><span id="64d1" class="lw je hi ls b fi mf ly l lz ma">cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 255))<br/>    <br/>    elif (np.argmax(Predictions)==3):<br/>      status = "Happy"</span><span id="ac02" class="lw je hi ls b fi mf ly l lz ma">x1,y1,w1,h1 = 0,0,175,75<br/>      #Draw black background rectangle<br/>      cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0,0,0), -1)<br/>      #Addd text<br/>      cv2.putText(frame, status, (x1 + int(w1/10), y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)</span><span id="8b6e" class="lw je hi ls b fi mf ly l lz ma">cv2.putText(frame, status,(100,150),font, 3,(0, 0, 255),2,cv2.LINE_4)</span><span id="4d8e" class="lw je hi ls b fi mf ly l lz ma">cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 255))</span><span id="34d2" class="lw je hi ls b fi mf ly l lz ma">elif (np.argmax(Predictions)==4):<br/>      status = "Sad"</span><span id="3692" class="lw je hi ls b fi mf ly l lz ma">x1,y1,w1,h1 = 0,0,175,75<br/>      #Draw black background rectangle<br/>      cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0,0,0), -1)<br/>      #Addd text<br/>      cv2.putText(frame, status, (x1 + int(w1/10), y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)</span><span id="c5f8" class="lw je hi ls b fi mf ly l lz ma">cv2.putText(frame, status,(100,150),font, 3,(0, 0, 255),2,cv2.LINE_4)</span><span id="ac38" class="lw je hi ls b fi mf ly l lz ma">cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 255))</span><span id="223e" class="lw je hi ls b fi mf ly l lz ma">elif (np.argmax(Predictions)==5):<br/>      status = "Surprise"</span><span id="d817" class="lw je hi ls b fi mf ly l lz ma">x1,y1,w1,h1 = 0,0,175,75<br/>      #Draw black background rectangle<br/>      cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0,0,0), -1)<br/>      #Addd text<br/>      cv2.putText(frame, status, (x1 + int(w1/10), y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)</span><span id="323f" class="lw je hi ls b fi mf ly l lz ma">cv2.putText(frame, status,(100,150),font, 3,(0, 0, 255),2,cv2.LINE_4)</span><span id="382f" class="lw je hi ls b fi mf ly l lz ma">cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 255))</span><span id="165e" class="lw je hi ls b fi mf ly l lz ma">else:<br/>      status = "Neutral"</span><span id="28a7" class="lw je hi ls b fi mf ly l lz ma">x1,y1,w1,h1 = 0,0,175,75<br/>      #Draw black background rectangle<br/>      cv2.rectangle(frame, (x1, x1), (x1 + w1, y1 + h1), (0,0,0), -1)<br/>      #Addd text<br/>      cv2.putText(frame, status, (x1 + int(w1/10), y1 + int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)</span><span id="690c" class="lw je hi ls b fi mf ly l lz ma">cv2.putText(frame, status,(100,150),font, 3,(0, 0, 255),2,cv2.LINE_4)</span><span id="6a71" class="lw je hi ls b fi mf ly l lz ma">cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 0, 255))</span><span id="6afc" class="lw je hi ls b fi mf ly l lz ma">cv2.imshow('Face Emotion Recognition', frame)</span><span id="a1cd" class="lw je hi ls b fi mf ly l lz ma">if cv2.waitKey(2) &amp; 0xFF == ord('q'):<br/>    break</span><span id="a331" class="lw je hi ls b fi mf ly l lz ma">cap.release()<br/>cv2.destroyAllWindows()</span></pre></div></div>    
</body>
</html>