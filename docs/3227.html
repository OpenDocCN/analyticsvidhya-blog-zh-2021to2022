<html>
<head>
<title>Table Extraction using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的表格提取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/table-extraction-using-deep-learning-3c91790aa200?source=collection_archive---------0-----------------------#2021-06-20">https://medium.com/analytics-vidhya/table-extraction-using-deep-learning-3c91790aa200?source=collection_archive---------0-----------------------#2021-06-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="658a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用TensorFlow构建深度学习模型，从图像中提取表格数据。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/e37f30d730064dce5e57577a957ed412.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oMQun4oLQWF6w-6XH617tw.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://unsplash.com/photos/oyXis2kALVg" rel="noopener ugc nofollow" target="_blank">法比奥在Unsplash上拍摄的照片</a></figcaption></figure><p id="22c6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">表是一种有用的结构表示，它将数据组织成行和列，旨在捕捉数据中不同元素和属性之间的关系。</p><p id="ee8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">表格已经成为我们日常生活的一部分:从基本的交易到复杂的分析结果，它们已经成为每一份文件和文档的一部分，甚至是以简洁的方式反映信息的最小需求。</p><p id="6888" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">互联网时代的技术进步和将文档保存为硬拷贝的不便使得文档、事件、交易或任何真实世界的记录(包括图像和其他多媒体信息)的数字化成为必要。因此，非结构化数据大量涌入，在这个庞大的非结构化数据池中，跟踪具有结构化语义的表格信息在人力资源方面变得更加昂贵和耗时；处理这个问题的唯一方法是借助计算机来解决。</p><p id="5810" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但是使用电脑有一个很大的缺点。主要问题是，当今世界有大量数字化的非结构化数据，在这个非结构化领域中，这些表没有其最初的本质来捕捉关系；他们只能在视觉上表现出来。就人类的理解而言，这些表的视觉表示和结构表示之间的差异可以忽略不计。另一方面，非结构化形式的表格对于计算机来说只不过是图像的一部分。</p><p id="796c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了解决这个问题，我们的主要目标是通过将表格从非结构化格式中分离出来并使用计算机视觉恢复其原始形式来理解表格。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="baf4" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">(尤指为开车者设计的) 公路交通图</h1><p id="f64f" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">这一部分概述了博客的结构，并提供了本博客将涵盖的主要阶段的高层次视图。</p><ul class=""><li id="5b4c" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj">先决条件</strong></li><li id="ba34" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj">问题理解</strong></li><li id="8651" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj">数据采集</strong></li><li id="2e67" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj">分析和预处理</strong></li><li id="a83a" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj">相关作品</strong></li><li id="52a7" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj">发展</strong></li><li id="da9c" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj">结论</strong></li><li id="c330" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj">讨论和未来工作</strong></li></ul><p id="ca4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，让我们开始吧…</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="9d01" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">1.先决条件</h1><p id="64af" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">这里列出了构建类似的基于深度学习的项目所需的先决条件(或者说是有帮助的)。</p><ul class=""><li id="d6d4" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj">虚拟环境，python，pip，机器学习和深度学习概念。</strong></li><li id="a1dc" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><strong class="ih hj"> TensorFlow </strong> —访问<a class="ae jt" href="https://www.tensorflow.org/tutorials" rel="noopener ugc nofollow" target="_blank">官方文档</a>开始使用。</li><li id="6423" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">从Youtube上JCharis的这个<strong class="ih hj"> </strong> <a class="ae jt" href="https://youtu.be/_9WiB2PDO7k" rel="noopener ugc nofollow" target="_blank">视频教程</a>中可以了解到Streamlit</li></ul><p id="d4c4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果您的工具箱中没有先决条件，请不要担心，请浏览博客。一个人可以随时回来学习需要什么！</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="3b1d" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">2.问题理解</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ls"><img src="../Images/4db6523254c61b8b1c61c37204d6af0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KhD2HAgLs_3rLrF3jRmiPA.png"/></div></div></figure><p id="ad62" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.1。概述</strong></p><p id="b5fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">研究的目标是开发一个系统，该系统将图像作为输入，并使用计算机视觉从输入图像(如果有)中的表格中提取信息。该任务可以被认为具有四个主要步骤:I)检测图像中表格的存在，ii)定位图像中的表格，iii)解码表格单元之间的结构关系，以及iv)理解每个单元内的文本。</p><p id="61a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个任务对于一个五岁的孩子来说可能是天真的，但是如果我们在我们的思想深渊中进行更深一步的跳跃，我们会意识到检测一张桌子，在一张纸上定位它并不遵循任何硬性的规则。它作为我们认知的一部分，由视觉皮层(从我们的意识理解中抽象出来)自动完成。</p><p id="e93f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.2。深度学习的使用</strong></p><p id="7176" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">十多年来，计算机视觉已经认识到深度学习的潜力。与以前的技术相比，深度学习已经在需要一定认知量并且无法使用基于规则的方法解决的问题中展示了有希望的结果。</p><p id="e366" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这项研究中，我们将利用<a class="ae jt" href="https://ml4a.github.io/ml4a/convnets/" rel="noopener ugc nofollow" target="_blank">卷积神经网络</a>(一种基于参数共享的深度学习模型)来解决在给定图像中检测和定位表格的问题，并使用预定义的<a class="ae jt" href="https://nanonets.com/blog/ocr-with-tesseract/" rel="noopener ugc nofollow" target="_blank"> OCR </a>算法从检测到的表格中提取文本。</p><p id="cb7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">桌子检测和定位可以被框定为一个<a class="ae jt" href="https://ai.stanford.edu/~syyeung/cvweb/tutorial3.html" rel="noopener ugc nofollow" target="_blank">图像分割</a>问题，其中系统必须通过预测桌子的屏蔽图像来将桌子区域与图片的其余部分分开。</p><p id="cbb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 2.3。问题约束</strong></p><p id="6d0d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这个问题，必须管理的一些主要约束:</p><p id="9fa3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> i)低</strong> <strong class="ih hj">等待时间— </strong>由于该解决方案旨在应用于大块文档图像，因此提取模型应该不会花费很长时间。</p><p id="8ffc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> ii) </strong> <strong class="ih hj">数据变异— </strong>它是这个领域的关键约束之一。在这个互联网和物联网时代，模型应该接受来自各种来源的流数据，并应该处理各种类型的转换图像(剪切、旋转、噪声等。).</p><p id="210d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> iii)适中的空间需求— </strong>设计的模型应该具有较低的内存需求。对于访问模型的设备来说，应该直接通过应用程序(低内存约束)或通过API(允许我们在一定程度上不受内存约束)来访问模型。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="369b" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">3.数据收集</h1><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lt"><img src="../Images/fcebf345a448231d442bfdd92c6782db.png" data-original-src="https://miro.medium.com/v2/resize:fit:576/format:webp/1*Auzg6M3ijQpt2EPX9cj9Dg.png"/></div></figure><p id="ad23" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">深度学习是一种数据驱动的人工神经网络技术，需要大量高质量的训练数据才能有效。Table Bank、ICDAR和Marmot是三个重要的研究成果，它们收集数据来研究和解释图片、pdf和其他可移植格式的表格，并通过开源其数据集来加速表格理解方面的研究。</p><p id="4da6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这项研究中，我们将使用Marmot数据集来开发我们的模型。数据集包含xml格式的数据集的给定图像中的表的边界框的注释。</p><blockquote class="lu lv lw"><p id="e884" class="if ig lx ih b ii ij ik il im in io ip ly ir is it lz iv iw ix ma iz ja jb jc hb bi translated">点击<a class="ae jt" href="https://www.icst.pku.edu.cn/cpdp/docs/20190424190300041510.zip" rel="noopener ugc nofollow" target="_blank">此处</a>下载数据集。</p><p id="dce8" class="if ig lx ih b ii ij ik il im in io ip ly ir is it lz iv iw ix ma iz ja jb jc hb bi translated">注意，我们将使用由TableNet团队<em class="hi">注释的同一数据集的另一个版本。</em>这个<a class="ae jt" href="https://drive.google.com/drive/folders/1QZiv5RKe3xlOBdTzuTVuYRxixemVIODp" rel="noopener ugc nofollow" target="_blank">数据集</a>由原始Marmot数据的列级边界框注释组成。为了方便起见，在整个博客中，我们将原始数据集称为<strong class="ih hj"> <em class="hi"> marmot_v1 </em> </strong>，而将后者称为<strong class="ih hj"><em class="hi">marmot _ extended</em></strong><em class="hi"/>。</p></blockquote></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="0434" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">4.分析和预处理</h1><p id="7f1a" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">从给定的<a class="ae jt" href="https://www.icst.pku.edu.cn/cpdp/docs/20190424190300041510.zip" rel="noopener ugc nofollow" target="_blank"> URL </a>下载数据集后，我们提取了数据集(<strong class="ih hj"> marmot_v1 </strong>)。现在我们来看看提取的目录，看看数据集是如何组织的。</p><p id="0964" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 4.1。实验观察</strong></p><ul class=""><li id="de4d" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">主文件夹包含一个文件夹数据，它实际上保存了数据以及一些描述数据集的文件。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mb"><img src="../Images/a79e4c116b5069392e2a875ffce5cb78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*DYi1P9t6ebfbBliHI-URVw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">解压缩的zip文件组织</figcaption></figure><ul class=""><li id="e3b2" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">Marmot数据集由中文和英文页面组成，分别保存在不同的文件夹中。</li><li id="3310" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">这两个文件夹(中文和英文)有相同的目录结构，都包括文件夹命名为积极和消极。</li><li id="0ece" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">为了简单起见，我们将只考虑英文文件夹。有两个文件夹，即标签和原始，在积极和消极的目录。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/68052d315b4b01c3148ee2c599366f90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*Oy3ugfvyyIKyJf3WqwbuFg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">正/原始目录中的文件数量及其部分内容</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/818e253af65251477fee076022415448.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*oufw-gwxnOtemmHeXIbQvw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图像数据点的数量和xml注释的数量</figcaption></figure><ul class=""><li id="0469" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">现在，让我们来看看数据集中的一个样本数据点</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es me"><img src="../Images/e7c6e98548984f409580dc41c9936180.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*HJFBfcek6SUo9ZFAjMdsWw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">数据集的样本图像</figcaption></figure><ul class=""><li id="8169" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">下面给出了相应的注释文件</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mf"><img src="../Images/c0a66dd6ef63db67bcc01da372512444.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5A-6T72pOPRJv9lLnuijug.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">相应的xml注释</figcaption></figure><ul class=""><li id="9040" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">表格的边界框和表格本身由(突出显示的)<strong class="ih hj">复合</strong>标签定义。但是需要注意的一点是，<strong class="ih hj"> BBox </strong>属性被赋予了一个很长的十六进制序列，所以我们必须以某种方式将这个序列转换成有意义的符号。我们将在本节的下一部分(4.2)处理这个问题。</li></ul><p id="54f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们来看看<strong class="ih hj">土拨鼠_扩展的</strong>数据集</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mg"><img src="../Images/817996245631996a65852153f885194b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*71Ytn39YLrivqbFfFdBLaQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">marmot扩展目录的内容</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mh"><img src="../Images/c672ab8d5082602ffdc4417ab64cb413.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*swoIalPwIdCe5gsqIG_S8A.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">数据点和注释的数量</figcaption></figure><ul class=""><li id="b496" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">这些注释包含图像中表格每一列的边界框</li><li id="01cd" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">该数据集仅包含原始数据集的English/Positive子文件夹中的图像。</li><li id="16a0" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">注释文件的数量是495，而位图图像有509个。因此，相应图像的14个xml文件不存在。</li></ul><p id="f51a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们之前已经看到了数据集(<strong class="ih hj"> marmot_v1 </strong>)中的典型图像数据，让我们只检查来自<strong class="ih hj"> marmot_extended </strong>的注释文件的布局</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mi"><img src="../Images/3ff147db185075b27181e47710d95f38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vn-NOG5DliGzBG7bJ_LnaQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">TableNet团队注释的marmot_extended的XML注释</figcaption></figure><ul class=""><li id="4eec" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">这些新注释只包含图像中每一列的边界框。xml文件中的每个<strong class="ih hj">对象</strong>标签表示一列，每个对象下的<strong class="ih hj"> bndbox </strong>标签保存该特定列的边界框的直角坐标</li><li id="2d7e" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">我们已经看到<strong class="ih hj"> marmot_v1 </strong>中的注释只包含表格注释</li><li id="4c69" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">我们将使用这两种类型的注释(table from <strong class="ih hj"> marmot_v1 </strong>和column from<strong class="ih hj">marmot _ extended</strong>)并根据这些注释为数据集中出现的每个图像创建蒙版图像。</li><li id="9ac3" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">由于缺少14个数据点的列级注释，我们也将忽略14个表级注释。</li></ul><p id="7d14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在进入预处理阶段之前，我们将检查数据集中每个图像的宽度和高度分布。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mj"><img src="../Images/bf1ff0197588c591af04d04bb62dfc60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YoaKFH13nL17LOFuEC1J3g.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图像宽度和高度的分布</figcaption></figure><ul class=""><li id="2e8d" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">从上面的图中我们可以看到，数据集中所有图像的宽度和高度都是(816，1056)</li></ul><h2 id="ab6a" class="mk kc hi bd kd ml mm mn kh mo mp mq kl iq mr ms kp iu mt mu kt iy mv mw kx mx bi translated">4.2.预处理</h2><p id="edb3" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">对于这个阶段，我们必须分析所提供的注释，并从中生成掩码图像(对于表和列)。下面简要列出了完成任务所遵循的预处理操作:</p><ul class=""><li id="2251" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">转换十六进制记数法并返回<strong class="ih hj"> marmot_v1 </strong>对应的浮点值。为此，我们定义了一个可以在移动中读取注释时调用的函数</li><li id="811d" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">从<strong class="ih hj"> marmot_v1 </strong>中读取表格的边界框数据。这是通过解析每个带注释的xml文件并定位所有的<em class="lx">复合</em>标签来完成的，其中<em class="lx">标签</em>属性被设置为‘Table’下面提供了为执行此任务而定义的python函数:</li></ul><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="my mz l"/></div></figure><ul class=""><li id="07da" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">我们对<strong class="ih hj"> marmot_extended </strong>注释做了同样的事情来获得列级注释。</li><li id="bbc3" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">将上述两个任务结合起来，为所有图像获得表格和列级注释(使用下面给出的函数)。</li></ul><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="my mz l"/></div></figure><p id="b72e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们想象一个这样的图像及其表和列掩码。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es na"><img src="../Images/2ab9be07ef9c67f17b9085514a0cc030.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gb293B07MicbSV3au6bJmA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">数据集及其处理过的掩膜的示例图像</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="8e11" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">5.相关作品</h1><p id="b23e" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">现在让我们快速看一下这个问题的各种解决方案。这一部分不是开发过程的一部分，但是它通过探索在这个方向上采取的思想的类似实现提供了一个更广阔的视角；下面简要介绍其中一些:</p><p id="f5ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 5.1。文档图像中表格检测的近域微调优势</strong></p><p id="90ae" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[ <a class="ae jt" href="https://arxiv.org/abs/1912.05846" rel="noopener ugc nofollow" target="_blank">安吉拉·卡萨多-加西亚等人2019 </a></p><p id="357a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们的研究主要集中在计算机视觉模型中迁移学习的性能如何提高，如果学习的参数在更多的相似任务中共享，而不是不相似的任务。研究中执行的任务分为两个阶段:</p><p id="f93d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">I)使用诸如yolo、mask-rnn、retina-net的SOTA对象检测模型进行实验，以在Pascal POV数据集(自然图像数据集)上学习对象检测，然后使用ICDAR、Marmot数据(桌子检测和识别数据)微调训练参数。</p><p id="4395" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ii)使用相同的对象检测模型进行另一组实验，但是这次它们首先使用TableNet数据集(表检测和识别数据集)进行训练，然后在ICDAR和Marmot数据集的帮助下进行参数的微调。</p><p id="ea69" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于两组实验，应用了迁移学习，首先从远处的域(自然图像)开始，然后从近处的域(桌子检测)开始。他们的实验结果表明，当将闭域迁移学习应用于文档图像中的表格检测时，有相当大的改进。</p><p id="a878" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5 <strong class="ih hj"> .2。GFTE:基于图形的财务表格提取</strong></p><p id="37ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae jt" href="https://arxiv.org/abs/2003.07560" rel="noopener ugc nofollow" target="_blank">李艺仁等人2020 </a></p><p id="dcb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该小组所做工作的主要贡献可以简要概括为:</p><p id="5dac" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">I)从几种类型的融资文件中汇编中国金融数据集FinTab。该数据集由1600多张不同类型的表格图像及其结构注释组成。</p><p id="aa52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ii)引入基于图的卷积神经网络模型，命名为GFTE。下面讨论该模型的工作原理。</p><p id="9e8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这种方法中的表被表示为一个图，其中每个单元被视为一个节点。这些节点通过关系相互连接:垂直的、水平的或不相关的。因此，他们的问题可以解释为:给定一组节点及其特征，预测一对节点之间的关系。</p><p id="fc9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们使用三种类型的信息以及每个节点作为输入:I)文本内容ii)绝对位置和iii)表的图像。这些绝对位置特征被转换为相对位置特征，文本特征被嵌入并通过LSTM层发送以获得语义信息，然后这些获得的特征被组合并馈送到两层图形卷积网络。之后使用相对位置特征和GCN的输出，计算节点特征。同时，对图像进行预处理，利用三层细胞神经网络提取特征。这些节点特征和图像特征然后被馈送到MLP，以模拟细胞之间的垂直和水平关系。</p><p id="ad5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.3。TableNet:深度学习模型，用于从扫描的文档图像中进行端到端的表格检测和表格数据提取</p><p id="f125" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[ <a class="ae jt" href="https://arxiv.org/abs/2001.01469" rel="noopener ugc nofollow" target="_blank">帕利瓦尔等人2020年</a></p><p id="f4f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这项工作中，他们提出了一个端到端的深度学习模型，用于表格识别的TableNet，并为旱獭数据提供了额外的注释。该方法结合了迁移学习，因为预训练的具有ImageNet权重的VGG-19被用作所提出的模型的编码器。VGG-19网络末端的全连接层被具有ReLU激活和丢弃的1x1卷积层所取代。编码器之后是两个不同的卷积解码器分支，因为模型需要同时检测表和识别其结构语义。在这些解码器分支中使用了附加层来过滤有用的特征，然后对这些特征图中的每一个进行上采样以产生图像。单个输入图像分别为表和列生成两个不同的带标签的输出图像。一旦获得语义标记的图像，OCR算法被应用于单词位置，并且使用基于规则的行提取技术将行提取为单词的集合。</p></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="a48a" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">6.发展</h1><p id="9589" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我们现在正在使用我们在早期阶段收集和处理的数据来创建和训练深度学习模型。让我们开始我们的第一次切割策略。</p><p id="decb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 6.1。在TensorFlow中实现TableNet</strong></p><p id="6216" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了解决这个问题，我们将使用迁移学习和设计架构，其灵感来自TableNet团队的<a class="ae jt" href="https://arxiv.org/abs/2001.01469" rel="noopener ugc nofollow" target="_blank">工作</a>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nb"><img src="../Images/7d73d8dcf6f7986c8dda31f1b42a40c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3K1GM6S77St2wyi8TnDuRQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Paliwal等人在2020年提出的TableNet架构。来自VGG19编码器的block_3、block_4和block_5池层的特征映射用于解码阶段的上下文聚合。</figcaption></figure><p id="5529" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">型号规格</strong></p><ul class=""><li id="74dd" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">与使用预训练VGG19作为基本编码器的原始TableNet架构(如上图所示)不同，我们的模型可以与各种类型的预训练视觉模型(如VGG、雷斯网、DenseNet、EfficientNet、Xception)一起工作，作为基本编码器。</li><li id="4c63" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">该模型采用允许编码器权重在整个训练中保持恒定的选项。换句话说，该选项可用于允许或限制模型的微调。</li><li id="c9fa" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">该模型还具有正则化参数，该参数将对编码器网络末端的卷积层和列解码器的卷积层采用<em class="lx">TF . keras . regulators</em></li><li id="038b" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">因为上述预训练模型的架构彼此不同。对于解码期间的上下文聚合，从其绘制特征映射的层因基本编码器而异</li><li id="8a60" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">表和列解码器的架构保持不变。</li></ul><blockquote class="lu lv lw"><p id="3e9e" class="if ig lx ih b ii ij ik il im in io ip ly ir is it lz iv iw ix ma iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong>要检查哪些层用于上下文聚合(来自其他编码器架构)，请参考下面给出的代码。</p></blockquote><p id="69b4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">模型定义</strong></p><p id="ceef" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面提供了定义模型所需的TensorFlow python代码。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="my mz l"/></div></figure><p id="eee9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 6.2。尝试各种编码器和设置</strong></p><p id="daad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上一节中，我们说明了我们的模型与许多类型的预训练编码器兼容，并且包含可以在训练期间强制正则化和微调的参数。在这一部分中，我们将使用编码器和设置的各种组合进行实验，记录训练和测试损失，以评估每个模型的性能。</p><p id="6947" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">概要:</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="my mz l"/></div></figure><p id="f6f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">讨论:</strong></p><ul class=""><li id="aa73" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">我们对TableNet架构进行了实验，调整了各种参数，如预训练编码器、辍学率和最终层的正则化。</li><li id="d58b" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">在我们的一个测试中，我们还试图冻结DenseNet最初几个块的层，但这并没有帮助我们避免过度拟合。</li><li id="155e" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">如上表所示，TableNet model dense net encoder(dropout为0.6，没有正则化，没有层冻结)在验证集上具有最佳性能，并且该模型比其他模型显示出更少的过度拟合迹象。</li></ul><p id="5a06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 6.3。使用TensorFlow Lite压缩获得的模型</strong></p><p id="9e1b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将导入最佳模型，并尝试使用一种称为训练后量化的技术来最小化空间需求。在这种方法中，通过优化模型权重的数据类型表示来压缩模型。这意味着通过保留尽可能多的信息，权重的数据类型从其原始数据类型更改为较低精度的表示形式(例如，从浮点32更改为浮点16)。</p><p id="2689" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，我们不需要为此创建算法；TensorFlow Lite将代表我们轻松处理所有复杂问题。只需按照下面的说明使用TF Lite执行量化。</p><ul class=""><li id="00b4" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">加载模型</li></ul><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="my mz l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nc"><img src="../Images/491259d65edd6749a355bfb6b4ebc622.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*j2taU2WPI0OkgqkK6v0Gdw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">量化前的模型大小</figcaption></figure><ul class=""><li id="51df" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">定义TF Lite转换器对象</li><li id="a15f" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">设置所需的优化类型</li><li id="e1ce" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">转换模型</li></ul><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="my mz l"/></div></figure><ul class=""><li id="5cea" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">保存TF Lite模型</li></ul><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="my mz l"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mh"><img src="../Images/7081f60c14787745548a7eee88f1c72a.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*R3BdbQk8sHW7yc-gG3exPg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">量化后的模型大小</figcaption></figure><p id="7bbc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">太好了！与. h5版本相比，该模型现在大约压缩了75%。它是完整的，并准备好用于获得分段掩模。我们现在可以通过使用OCR技术提取所需的文本信息，比如对分段的表区域进行镶嵌。在下一部分，我们将看看整个过程，并定义最终的管道。</p><p id="1160" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">6.4。定义最终管道</p><p id="f09d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们将利用在上一部分中获得的压缩TF Lite模型来构建我们的最终管道，即从接受一个图像(作为磁盘上的一个文件存在)获得一个包含提取的表格数据的csv(也将作为一个文件保存在磁盘上)。下面提供了最终管道的算法和python实现。</p><ul class=""><li id="6205" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj">最终流水线的算法</strong></li></ul><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="my mz l"/></div></figure><ul class=""><li id="89ff" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj">最终流水线的python代码</strong></li></ul><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="my mz l"/></div></figure><ul class=""><li id="3956" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated"><strong class="ih hj">使用最终函数进行推理</strong></li></ul><p id="ab12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">I)让我们尝试使用下面的图像作为输入</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nd"><img src="../Images/7ba26d179565570f10bd9d44b7afff8f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kDIZSYHjArWCnECzscK2Fw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">包含表格的文档的示例图像</figcaption></figure><p id="741f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ii)模型预测的分段表如下所示</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ne"><img src="../Images/baf194e5e96c74c68165295c69756dde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p6MGPl9SXeOivh5dRVWwuw.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">分段表格图像</figcaption></figure><p id="83fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">iii)作为文本提取的表格</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nf"><img src="../Images/6fe42d4a5efe1fa575dc9149fc5d5f30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ESnjxrkMbjuS7f-pQoyKkQ.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">从OCR模块获取文本</figcaption></figure><p id="28b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> 6.5。使用Streamlit的基于网络的用户界面</strong></p><p id="70eb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这一部分中，我们将使用python的streamlit包创建一个包装器，以便可以方便地测试模型。</p><blockquote class="lu lv lw"><p id="7aef" class="if ig lx ih b ii ij ik il im in io ip ly ir is it lz iv iw ix ma iz ja jb jc hb bi translated"><strong class="ih hj">注意:</strong>本节未显示streamlit应用程序部署的python代码；然而，如果你需要它，你可以检查我的知识库。访问我的博客<a class="ae jt" rel="noopener" href="/analytics-vidhya/predicting-volcanic-eruptions-from-seismic-behavior-3b8e6bbd7ffc">根据地震行为预测火山爆发</a>了解更多关于如何利用Streamlit创建web应用的信息。</p></blockquote><p id="db3a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所开发的系统包含一些将在下一节讨论的限制，由于这些限制，模型不能被部署(被其他用户使用)。因此，以下视频提供了streamlit web-app(本地部署)的工作演示:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ng mz l"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">流媒体网络应用演示</figcaption></figure></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="3d43" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">7.结论</h1><p id="095a" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">因此，作为总结，让我们回顾一下本研究中到目前为止发生的事情，并探索系统可能遇到的一些现实问题(如果部署的话)。</p><ul class=""><li id="f25d" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">首先，我们获得了marmot data提供的图像，并将两种类型的注释(<strong class="ih hj"> marmot_v1 </strong>用于表格，而<strong class="ih hj"> marmot_extended </strong>用于列)转换为实际的掩码图像，这些图像可以用作监督学习的标签。</li><li id="e3a1" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">然后，我们使用python的TensorFlow框架实现了TableNet架构。</li><li id="f748" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">我们修改了原始设计，使其能够与各种预训练的视觉模型一起运行，并提供了启用/禁用微调和正则化的选项。</li><li id="201c" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">之后，我们从实验中挑选出最佳模型，并使用TF Lite转换器对其进行压缩。</li><li id="bb04" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">最后，我们利用streamlit将我们的模型封装在一个可以交互使用的UI中。</li></ul><p id="a297" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">局限性:</strong></p><p id="b095" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然该模型能够很好地提取表格数据，但我们的实现面临一些严重的限制/挑战。</p><ul class=""><li id="ca18" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">当图像有多个表格时，提取质量会降低，因为它试图只分割一个包含所有表格的矩形区域。</li><li id="024d" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">对分段的表格区域使用OCR时，文本检测较弱。如果它能够学习细胞级分割并将OCR应用于每个细胞，这将是有利的。</li><li id="662f" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">它无法区分包含行/列标题的单元格和包含实际数据的单元格。</li></ul></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="62a3" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">8.未来的工作</h1><p id="28f7" class="pw-post-body-paragraph if ig hi ih b ii kz ik il im la io ip iq lb is it iu lc iw ix iy ld ja jb jc hb bi translated">我们已经到了博客的末尾，这一部分的目的是为未来的改进提供一个方向。最初，我们可以尝试排除上一节中讨论的限制，因为:</p><ul class=""><li id="a905" class="le lf hi ih b ii ij im in iq lg iu lh iy li jc lj lk ll lm bi translated">收集和管理带有单元级注释的大型数据集可能会有所帮助。</li><li id="ae95" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">然后，我们可以训练我们的模型来学习和预测细胞水平的分割，给定一个图像，其中有一个表格。</li><li id="aa5e" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated">开发的模型一次只接受一个图像，我们可以开发一个实际的应用程序，并将其部署在web上，该应用程序将获取一组图像(比如，一个包含多个页面的PDF文件)，并给出这组图像中的所有表格(PDF)。</li></ul></div><div class="ab cl ju jv gp jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="hb hc hd he hf"><h1 id="199f" class="kb kc hi bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">9.参考</h1><ul class=""><li id="c272" class="le lf hi ih b ii kz im la iq nh iu ni iy nj jc lj lk ll lm bi translated"><a class="ae jt" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">申请课程</a></li><li id="1902" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><a class="ae jt" href="https://arxiv.org/abs/1912.05846" rel="noopener ugc nofollow" target="_blank">文档图像中表格检测的近域微调优势</a></li><li id="b89c" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><a class="ae jt" href="https://arxiv.org/abs/2003.07560" rel="noopener ugc nofollow" target="_blank"> GFTE:基于图形的财务表格提取</a></li><li id="cdd7" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><a class="ae jt" href="https://arxiv.org/abs/2001.01469" rel="noopener ugc nofollow" target="_blank"> TableNet:深度学习模型，用于从扫描的文档图像中进行端到端的表格检测和表格数据提取</a></li><li id="6fbb" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><a class="ae jt" href="https://arxiv.org/abs/2004.14356" rel="noopener ugc nofollow" target="_blank"> AxCell:从机器学习论文中自动提取结果</a></li><li id="1854" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><a class="ae jt" href="https://www.tensorflow.org/tutorials" rel="noopener ugc nofollow" target="_blank"> TensorFlow教程</a></li><li id="cbf3" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><a class="ae jt" href="https://product.hubspot.com/blog/git-and-github-tutorial-for-beginners" rel="noopener ugc nofollow" target="_blank"> Git和GitHub博客</a></li></ul><h1 id="da64" class="kb kc hi bd kd ke nk kg kh ki nl kk kl km nm ko kp kq nn ks kt ku no kw kx ky bi translated">外部链接</h1><ul class=""><li id="7650" class="le lf hi ih b ii kz im la iq nh iu ni iy nj jc lj lk ll lm bi translated"><a class="ae jt" href="https://github.com/cssoumyade/Table-Extraction" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> GitHub库</strong> </a></li><li id="0a7c" class="le lf hi ih b ii ln im lo iq lp iu lq iy lr jc lj lk ll lm bi translated"><a class="ae jt" href="https://www.linkedin.com/in/cssoumyade/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">在LinkedIn上联系我</strong> </a></li></ul></div></div>    
</body>
</html>