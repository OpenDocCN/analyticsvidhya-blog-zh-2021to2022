<html>
<head>
<title>Deep Learning, the summarized way Part-1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习，总结的方法第一部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-learning-the-summarized-way-part-1-23e2eee01ddd?source=collection_archive---------16-----------------------#2021-05-12">https://medium.com/analytics-vidhya/deep-learning-the-summarized-way-part-1-23e2eee01ddd?source=collection_archive---------16-----------------------#2021-05-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="49ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">网上和书本上有很多关于深度学习的资源。但是很难找到一个统一的版本，所以我决定想出一些文章，以概括的方式呈现主题。</p><p id="d55f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">这篇文章是给谁看的？</strong>这篇文章将真正帮助那些已经学习了深度学习的<strong class="ig hi"/><strong class="ig hi"/>基础知识的人，并希望<em class="jc">刷新他们的记忆</em>。我会尽我所能使它对新来者友好，但我不会涉及太多的细节。</p><p id="4d2d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">外面有如此多的资源。为什么会这样？如前所述，很难找到统一的资源。相信我，我不会用太多的理论来膨胀文章，<em class="jc">只有必要的信息</em>刷新你的记忆。</p><p id="14bd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">简短声明:</strong>为了提高对特定主题的理解，我可能会使用一些外行的类比，这些类比在该主题的真实理论中并不适用，但肯定会帮助您更好地理解该主题。此外，我的大部分DL知识都是受<a class="ae jd" href="https://www.pyimagesearch.com/" rel="noopener ugc nofollow" target="_blank"> Pyimagesearch </a>和<a class="ae jd" href="https://machinelearningmastery.com/" rel="noopener ugc nofollow" target="_blank"> MLMastery </a>的启发，所以你可能会注意到他们文章中的一些参考。</p></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="0576" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">什么是Keras，Tensorflow，OpenCV？</h1><p id="e1a9" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">Tensorflow和Theano是用于通用数学计算的库。虽然你可能主要在深度学习领域听说过它们，但它们也用于许多其他应用。</p><p id="54bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Keras是一个深度学习框架，位于Tensorflow或Theano之上，通过提供如此多的实用函数和API，帮助您轻松抽象地进行深度学习。实际的深度学习工作发生在后端系统(Tensorflow或Theano)中，Keras通过对所有样板代码负责，使您的生活更加轻松。</p><p id="626e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">OpenCV与深度学习世界完全无关，通常用于计算机视觉和基本的图像操作(读取/显示/操作图像)。</p></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="6714" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">什么是深度学习？</h1><p id="ca03" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">深度学习(DL)是机器学习的一个子领域，而机器学习又是人工智能(AI)的一个子领域。</p><p id="2ac2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">监督ML </strong>:算法在一个既有输入又有输出(标签)的数据集上训练。该算法旨在为所提供的看不见的数据找到输出标签。示例:逻辑回归、支持向量机(SVM)、人工神经网络(ANN)。深度学习使用ANN作为其核心，有时这两者可以互换使用。</p><p id="65c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">无监督ML: </strong>该算法在有一些输入但没有输入标签的数据集上进行训练。该算法旨在将相似类型的输入分组到一个聚类中。这方面的例子有k均值聚类和PCA(主成分分析)。</p></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="123b" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">流行的数据集和架构</h1><p id="05b1" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated"><strong class="ig hi">热门数据集:</strong> MNIST(手写数字灰度图像)、CIFAR-10(飞机、鸟、猫、卡车等十类……)、ImageNet(拥有22000类的数据集)。</p><p id="73ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">流行架构:</strong> AlexNet，VGGNet，ResNet，MobileNet，GoogLeNet。</p><p id="e41e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">名字末尾的‘Net’字真的让我搞不清楚是数据集还是架构。例如，ImageNet是一个数据集，而ResNet是一个体系结构。</p></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="6c85" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">DL网络成分</h1><ol class=""><li id="062c" class="ko kp hh ig b ih kj il kk ip kq it kr ix ks jb kt ku kv kw bi translated"><strong class="ig hi"> <em class="jc">数据集:</em> </strong>由于深度学习是一种监督学习，所以你的数据应该既有输入也有输出标签。</li><li id="2a52" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated"><strong class="ig hi"> <em class="jc">一个模型/架构:</em> </strong> <em class="jc"> </em>层数，每层神经元数。</li><li id="8304" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated"><strong class="ig hi"> <em class="jc">损失函数:</em> </strong>量化模型在训练数据集上学习时表现的“好”或“差”。如果类别是&gt; 2，我们使用<em class="jc">分类交叉熵</em>。对于2类，我们使用<em class="jc">二进制交叉熵</em>。</li><li id="340e" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated"><strong class="ig hi"> <em class="jc">优化方法</em> </strong>:根据我们从上一步得到的值(模型好坏)，应该用什么方法来调整模型参数。一些技术是随机梯度下降(SGD)、RMSProp、Adagrad、Adadelta、Adam。</li></ol></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="1f36" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">模型参数与超参数</h1><p id="a545" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">模型参数是一个变量，其值“<em class="jc">模型可以在训练期间自己学习</em>。DL网络中的模型参数通常被分配一些初始值(<em class="jc">库自行处理，不需要您做任何事</em>)，并且模型在训练期间学习这些参数的最佳值。这类参数的最好例子是神经网络中神经元/节点的<em class="jc">权重</em>。</p><p id="3730" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">超参数是一个变量，其值为您期望的值<em class="jc"/>，并且该参数的值<em class="jc">从未由基于数据集的模型</em>估计或学习。肯定有一个选项可以在训练时更新该值(使用像decay这样的概念)，但这需要由您来完成，而模型不会这样做。一些例子是<em class="jc">学习率</em>，时期数。这些是在反复试验中起作用的参数，你必须不断地调整它们来改进你的模型，但是随着你获得经验，你会变得善于定义它们。</p><blockquote class="lc ld le"><p id="3ff6" class="ie if jc ig b ih ii ij ik il im in io lf iq ir is lg iu iv iw lh iy iz ja jb ha bi translated">模型权重是模型参数，而学习速率、批量大小和时期数是超参数。</p></blockquote></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="301b" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">资料组</h1><p id="aa36" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated"><strong class="ig hi">训练数据集:</strong>模型用来拟合其模型参数的数据。此数据集参与模型定型。</p><p id="e6fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">验证数据集:</strong>模型使用的<em class="jc">数据，用于报告训练时每个历元后的准确度或损失。该数据集也参与模型训练。</em></p><blockquote class="lc ld le"><p id="ec26" class="ie if jc ig b ih ii ij ik il im in io lf iq ir is lg iu iv iw lh iy iz ja jb ha bi translated">如果您看到下面的示例输出，模型使用训练数据集进行一个时期的训练，然后使用验证数据集检查它在当前时期的表现，并基于它调整其模型参数。</p></blockquote><figure class="lj lk ll lm fd ln er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es li"><img src="../Images/725395420f359c4982d5f4a6e4b75b0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pf7tPdEMNlSFCZp7k4yMig.png"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">模型训练的示例输出</figcaption></figure><p id="107c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">测试数据集:</strong>您<em class="jc">使用的数据</em>用于评估模型在训练后的表现。该数据集仅用于测试，模型在训练期间不会使用它。</p><blockquote class="lc ld le"><p id="e811" class="ie if jc ig b ih ii ij ik il im in io lf iq ir is lg iu iv iw lh iy iz ja jb ha bi translated">因此，验证数据集由模型用于评估目的，而测试数据集由您用于评估目的。</p><p id="aa78" class="ie if jc ig b ih ii ij ik il im in io lf iq ir is lg iu iv iw lh iy iz ja jb ha bi translated">通常，验证数据集可以从训练数据集(训练数据集的20%)中导出，但是如果训练数据集非常小，则可以使用测试数据集作为验证数据集。</p></blockquote></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="78bf" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">纪元与批处理</h1><p id="8efc" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">在训练时，模型从训练数据集中选取一个样本，尝试使用其当前模型参数预测输出，并根据该预测的好坏，尝试调整其模型参数。</p><p id="ca19" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">批量大小</strong>表示模型在调整模型参数之前处理的样本数量。它可以在每1个样本(批大小=1)后调整它，或者可能在整个数据集(批大小=数据集的长度)后调整它。</p><p id="13b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">历元数</strong>是训练数据集中的完整遍数/回合数。假设您有5个纪元。因此，如果模型已经到达数据集的末尾，它将跳回数据集的第一个样本，再次遍历并处理整个数据集，直到结束，这个循环将重复5次。</p><p id="7a33" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果您在下面看到训练过程的样本输出，您会注意到我们有20个时期，每个时期有18000步。每个历元的步数通常使用length _ of _ your _ datset//BATCH _ SIZE计算，您仍然可以选择提供自定义值，但我建议使用此公式。</p><figure class="lj lk ll lm fd ln er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ly"><img src="../Images/366f16b82b149188d71e50cc98f757f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mmep9bY0fe48dt7DrtNeEQ.png"/></div></div><figcaption class="lu lv et er es lw lx bd b be z dx translated">培训过程的输出示例</figcaption></figure><p id="3c83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意，批量大小不同于每个时期的步数。每个时期的步骤实际上是根据批量大小计算的，但是参数的调整是根据批量大小的值而不是每个时期的步骤的值进行的。</p></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="1b9b" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">一些常用术语</h1><ol class=""><li id="0cfa" class="ko kp hh ig b ih kj il kk ip kq it kr ix ks jb kt ku kv kw bi translated"><strong class="ig hi">反向传播:</strong>任何深度学习模型的工作原理主要涉及两个过程:<br/>模型从输入数据集中挑选一批图像，并尝试使用其当前模型参数来预测每幅图像的输出。这是正向传播。<br/>根据预测的好坏，模型计算梯度(误差),并使用该梯度更新所有模型参数。这被称为反向传播。</li><li id="ab03" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated"><strong class="ig hi">一个热门编码:</strong>假设你有一个数据集，其中的输出标签是一些常量值，例如，“猫”或“狗”或“0”“1”。深度学习模型不能对这些类型的标签起作用，相反，它希望它们是某种向量。一种热编码将这些标签转换成某种向量。例如，“猫”将被转换为[0，0，1]，“狗”将被转换为[0，1，0]。</li><li id="1782" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated"><strong class="ig hi">将模型架构作为图像查看:</strong>Keras的<em class="jc"> plot_model() </em>函数帮助您绘制和可视化您的模型。它给出了关于层、输入和输出的所有细节。</li><li id="edb3" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated"><strong class="ig hi">将模型保存到磁盘:</strong><em class="jc">model . save()</em>允许您以HDF5格式将模型序列化到磁盘。</li></ol></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="94a1" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">解释优化方法</h1><p id="175e" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">正向传递完成后，模型需要更新其参数。模型在这次更新中使用的策略是由我们在定义模型架构时使用的优化算法决定的。以下是一些常用的优化算法:</p><ol class=""><li id="27d8" class="ko kp hh ig b ih ii il im ip lz it ma ix mb jb kt ku kv kw bi translated"><strong class="ig hi">普通梯度下降(VGD): </strong>这里的普通只是表示这是传统的梯度下降算法，其中模型在遍历整个数据集之后更新其参数(具体是权重)<strong class="ig hi"> </strong>。</li><li id="e741" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated"><strong class="ig hi">随机梯度下降(SGD): </strong>这里模型在处理小批量训练数据后更新其参数。</li></ol><blockquote class="lc ld le"><p id="62f0" class="ie if jc ig b ih ii ij ik il im in io lf iq ir is lg iu iv iw lh iy iz ja jb ha bi translated"><strong class="ig hi">VGD:</strong>batch _ size =数据集长度；<strong class="ig hi">SGD:</strong>1&lt;batch _ size&lt;=小于数据集长度的某个随机数。</p></blockquote><p id="5b63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.<strong class="ig hi"> Adagrad: </strong>对不经常改变的参数进行较大的更新，而对经常改变的参数进行较小的更新。主要优点是我们不必手动调整学习率，算法的自适应特性有助于自动调整。缺点是有些缓存问题后来用<strong class="ig hi"> Adadelta </strong>解决了。</p><p id="87d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.<strong class="ig hi"> RMSProp </strong></p><p id="d52b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.<strong class="ig hi">亚当</strong></p><p id="07f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用哪一个？</p><blockquote class="lc ld le"><p id="5828" class="ie if jc ig b ih ii ij ik il im in io lf iq ir is lg iu iv iw lh iy iz ja jb ha bi translated">除了SGD和Adam，我几乎没见过有人用别的优化方法。PyImagesearch的Adrian Rosebrock博士个人建议从SGD开始，然后是Adam，最后是RMSProp，因为Adam在大多数情况下往往会优于RMSProp。</p></blockquote></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="8e0e" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">数据扩充</h1><p id="4b3a" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">您的模型与它所处理的数据集一样好。因此，您的数据集应该涵盖模型在现实世界中可能看到的所有可能场景。数据增强从数据集中选取一幅图像，并对该图像应用各种变换(如旋转、缩放、剪切)，然后将该图像馈送到深度学习模型。唯一的目的是用各种数据的可能性来训练我们的模型。</p><p id="fb43" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用<em class="jc"> ImageDataGenerator </em>为我们处理数据扩充。代码看起来是这样的</p><pre class="lj lk ll lm fd mc md me mf aw mg bi"><span id="857b" class="mh jm hh md b fi mi mj l mk ml">traindatagen = ImageDataGenerator(zoom_range=0.15, fill_mode="nearest", rescale=1. / 255, width_shift_range=0.1,<br/>                                  height_shift_range=0.1)<br/><br/>train_generator = traindatagen.flow_from_directory(directory="./train_custom", target_size=(128, 128),<br/>                                                   batch_size=BATCH_SIZE, class_mode="categorical")</span></pre><p id="ee1d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc"> flow_from_directory() </em>方法对于加载数据集非常方便。唯一的先决条件是，它希望数据保存在分层的文件夹结构中(如果还没有，我通常使用定制的python脚本来准备这种文件夹结构)。备选选项是<em class="jc"> flow() </em>，它不期望这个文件夹结构。</p><figure class="lj lk ll lm fd ln er es paragraph-image"><div class="er es mm"><img src="../Images/588f11728982f454e832c1c3c7dde97f.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*ePtWUibTQv1FlNaqyaHuxg.png"/></div><figcaption class="lu lv et er es lw lx bd b be z dx translated"><em class="mn"> flow_from_directory()需要这种类型的</em>层次文件夹结构。Folder1、Folder2代表每个类</figcaption></figure><blockquote class="lc ld le"><p id="7265" class="ie if jc ig b ih ii ij ik il im in io lf iq ir is lg iu iv iw lh iy iz ja jb ha bi translated">数据扩充仅应用于训练和验证数据集，而不会应用于测试数据集。</p></blockquote></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="d113" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">方便的回调(培训监控和模型检查点)</h1><p id="aa47" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated"><strong class="ig hi">训练监控:</strong>如前所述，模型超参数是您在查看当前模型性能时必须调整的参数。你不能只是预测模型超参数，并期望它们在第一次就起作用。但是如果你的模型需要23个小时来完成训练呢？你会等23个小时，然后做出调整的决定吗？你不能只是坐着等待训练完成，然后检查训练的表现。相反，模型性能监控应该与训练并行进行。这就是训练监视器派上用场的地方。</p><blockquote class="lc ld le"><p id="7ca9" class="ie if jc ig b ih ii ij ik il im in io lf iq ir is lg iu iv iw lh iy iz ja jb ha bi translated">Keras允许您定义自定义回调函数，并将它们传递给模型。每当模型被训练时，这些函数将被Keras调用。您还可以选择指定Keras在模型训练期间何时(纪元完成后、训练开始前或训练完成后)调用您的函数。Keras还传递函数请求的模型参数，如当前训练精度、验证损失等。您甚至可以提供多个回调函数，它们将由Keras按顺序调用。</p></blockquote><p id="6aeb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于您的回调函数在模型训练期间从Keras接收到的参数，您可以做出决策，如绘制一个图表以确定准确性或损失，并将它们保存到磁盘。这有助于您在模型接受训练时，并行地可视化和评估您的模型训练。</p><p id="29c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我不会讨论如何创建这种类型的训练监视器，但是你可以在这里检查一个示例(不是我的代码)<a class="ae jd" href="https://github.com/agoila/lisa-faster-R-CNN/blob/master/pyimagesearch/callbacks/trainingmonitor.py" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="34cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">模型检查点:</strong>如果您的培训过程即将完成，但您的系统不知何故关闭了或者云会话消失了，会发生什么？当您的模型满足某个条件时(比如每10秒或当模型性能提高时)，应该有一些自动的方法在磁盘上存储/检查您的模型。一旦你在你的磁盘上有了模型，你就可以从它弯曲的同一点继续训练。这里也使用了相同的回调原则，您可以指定检查点应该何时发生。Keras会在训练期间调用你的检查点函数。下面是我如何定义检查点回调的一个小例子:</p><pre class="lj lk ll lm fd mc md me mf aw mg bi"><span id="b287" class="mh jm hh md b fi mi mj l mk ml">filepath = "./checkpoints/model-checkpoint-{epoch:02d}-{val_accuracy:.2f}.hdf5"<br/>modelCheckPoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')</span></pre><p id="a9d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我希望Keras在每次我的模型的验证准确性增加时检查我的模型。一旦您定义了所有的回调函数，这就是您将这些回调传递给模型的方式:</p><pre class="lj lk ll lm fd mc md me mf aw mg bi"><span id="cf29" class="mh jm hh md b fi mi mj l mk ml">H = model.fit(train_generator, steps_per_epoch=len(train_generator) // BATCH_SIZE,<br/>              validation_data=test_generator, validation_steps=len(test_generator) // BATCH_SIZE, epochs=EPOCHS,<br/>              <strong class="md hi">callbacks=[TrainingMonitor("./perEpochGraph.png"), modelCheckpoint]</strong>)</span></pre></div><div class="ab cl je jf go jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="ha hb hc hd he"><h1 id="ab7c" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">最后的话</h1><p id="9f65" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">我希望你喜欢这篇文章，它确实刷新了你的深度学习知识。编译这样的东西真的需要很大的努力，所以请在你的网络上分享这篇文章，不要忘记查看下一部分 的<a class="ae jd" href="https://dhruv-pandey93.medium.com/deep-learning-the-summarized-way-part-2-35d88351a18a" rel="noopener">，它涵盖了更多的概念。再次非常感谢来自</a><a class="ae jd" href="https://www.pyimagesearch.com/" rel="noopener ugc nofollow" target="_blank"> PyImagesearch </a>的Adrian Rosebrock博士和来自<a class="ae jd" href="https://machinelearningmastery.com/" rel="noopener ugc nofollow" target="_blank"> MLMastery </a>的Jason Brownlee，他们不仅帮助我理解了DL基础知识，还为我走向实用的DL技术铺平了道路。</p></div></div>    
</body>
</html>