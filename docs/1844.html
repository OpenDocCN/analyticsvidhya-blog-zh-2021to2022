<html>
<head>
<title>Advanced operation in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量流中的高级运算</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/advanced-operation-in-tensorflow-9b7d3157b08?source=collection_archive---------25-----------------------#2021-03-21">https://medium.com/analytics-vidhya/advanced-operation-in-tensorflow-9b7d3157b08?source=collection_archive---------25-----------------------#2021-03-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="d315" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">什么是渐变和重塑？</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/f891b105278e77f9ba361ac3fe9d4ee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M_VB7Or0Ru8zJr3ZQuh6Rw.png"/></div></div></figure><p id="2544" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">之前我们已经介绍了TensorFlow中的基本操作，如乘法、matmul和reduce sum。在这篇文章中，我将谈论像整形，渐变和随机高级操作。</p><div class="ke kf ez fb kg kh"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/basic-operations-of-tensorflow-e6311e2eb8a0"><div class="ki ab dw"><div class="kj ab kk cl cj kl"><h2 class="bd hi fi z dy km ea eb kn ed ef hg bi translated">张量流的基本运算</h2><div class="ko l"><h3 class="bd b fi z dy km ea eb kn ed ef dx translated">张量流简介第2部分</h3></div><div class="kp l"><p class="bd b fp z dy km ea eb kn ed ef dx translated">medium.com</p></div></div><div class="kq l"><div class="kr l ks kt ku kq kv jg kh"/></div></div></a></div></div><div class="ab cl kw kx go ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ha hb hc hd he"><h1 id="c90e" class="ld le hh bd lf lg lh li lj lk ll lm ln in lo io lp iq lq ir lr it ls iu lt lu bi translated">梯度操作</h1><p id="db93" class="pw-post-body-paragraph ji jj hh jk b jl lv ii jn jo lw il jq jr lx jt ju jv ly jx jy jz lz kb kc kd ha bi translated">我们将结合梯度带使用梯度函数，计算函数在某一点的斜率。</p><h1 id="47e9" class="ld le hh bd lf lg ma li lj lk mb lm ln in mc io lp iq md ir lr it me iu lt lu bi translated">寻找最佳方案</h1><p id="b139" class="pw-post-body-paragraph ji jj hh jk b jl lv ii jn jo lw il jq jr lx jt ju jv ly jx jy jz lz kb kc kd ha bi translated">在许多机器学习问题中，你需要找到一个最优值，即最小值或最大值。例如，您可能希望最小化损失函数或最大化目标函数。</p><p id="a38b" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">最小值:</strong>坡度变化&gt; 0</p><p id="0603" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated"><strong class="jk hi">最大:</strong>坡度变化&lt; 0</p></div><div class="ab cl kw kx go ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ha hb hc hd he"><h1 id="52b9" class="ld le hh bd lf lg lh li lj lk ll lm ln in lo io lp iq lq ir lr it ls iu lt lu bi translated">计算梯度</h1><p id="a78f" class="pw-post-body-paragraph ji jj hh jk b jl lv ii jn jo lw il jq jr lx jt ju jv ly jx jy jz lz kb kc kd ha bi translated">首先我们定义一个变量x</p><pre class="ix iy iz ja fd mf mg mh mi aw mj bi"><span id="100a" class="mk le hh mg b fi ml mm l mn mo">#define x<br/>x = tf.Variable(-1.0 )</span><span id="4372" class="mk le hh mg b fi mp mm l mn mo">#define y within instance of GradientTape</span><span id="c0a0" class="mk le hh mg b fi mp mm l mn mo">with tf.GradientTape() as tape :<br/>      tape.watch(x)<br/>      y = tf.multiply(x,x) </span><span id="91e5" class="mk le hh mg b fi mp mm l mn mo">#next we compute the gradient</span><span id="ec37" class="mk le hh mg b fi mp mm l mn mo">g = tape.gradient(y,x)<br/>print(g.numpy())</span></pre><ul class=""><li id="87d0" class="mq mr hh jk b jl jm jo jp jr ms jv mt jz mu kd mv mw mx my bi translated">请注意，我们将watch方法应用于渐变磁带的一个实例，然后传递变量x。这将允许我们计算y到x *的变化率</li></ul><p id="9d0b" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">输出为-2.0，这意味着在x等于-1时斜率为-2，这意味着y开始下降。</p></div><div class="ab cl kw kx go ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ha hb hc hd he"><h1 id="a406" class="ld le hh bd lf lg lh li lj lk ll lm ln in lo io lp iq lq ir lr it ls iu lt lu bi translated">重塑</h1><p id="fe94" class="pw-post-body-paragraph ji jj hh jk b jl lv ii jn jo lw il jq jr lx jt ju jv ly jx jy jz lz kb kc kd ha bi translated">整形被认为是对图像分类问题特别有用的操作。通过整形，你可以很容易地将矩阵整形为向量。</p><p id="7d61" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">我会给你看一个重塑的例子。</p><pre class="ix iy iz ja fd mf mg mh mi aw mj bi"><span id="dc4d" class="mk le hh mg b fi ml mm l mn mo">#example we generate grayscale image </span><span id="dfa3" class="mk le hh mg b fi mp mm l mn mo">gray = tf.random.uniform([2,2],maxval = 255 , dtype='int32' )</span><span id="76c6" class="mk le hh mg b fi mp mm l mn mo">#reshape grayscale image <br/>gray = tf.reshape(gray , [2*2 , 1] )</span></pre><p id="d827" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">这就是TensorFlow中使用的所有高级操作。</p></div><div class="ab cl kw kx go ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="ha hb hc hd he"><p id="7915" class="pw-post-body-paragraph ji jj hh jk b jl jm ii jn jo jp il jq jr js jt ju jv jw jx jy jz ka kb kc kd ha bi translated">这就是张量流中的损失函数。你可以关注我的媒体或者在我的Linkedin中与我联系，以保持对媒体的关注。</p><div class="ke kf ez fb kg kh"><a href="https://www.linkedin.com/in/sweeliang/" rel="noopener  ugc nofollow" target="_blank"><div class="ki ab dw"><div class="kj ab kk cl cj kl"><h2 class="bd hi fi z dy km ea eb kn ed ef hg bi translated">Swee Liang Chua — NYP信息技术学院(SIT) —新加坡，新加坡| LinkedIn</h2><div class="ko l"><h3 class="bd b fi z dy km ea eb kn ed ef dx translated">查看Swee Liang Chua在全球最大的职业社区LinkedIn上的个人资料。瑞良的教育是…</h3></div><div class="kp l"><p class="bd b fp z dy km ea eb kn ed ef dx translated">www.linkedin.com</p></div></div></div></a></div><h1 id="e28c" class="ld le hh bd lf lg ma li lj lk mb lm ln in mc io lp iq md ir lr it me iu lt lu bi translated">另请参见:</h1><div class="ke kf ez fb kg kh"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/introduction-to-tensorflow-8f2dbaba8844"><div class="ki ab dw"><div class="kj ab kk cl cj kl"><h2 class="bd hi fi z dy km ea eb kn ed ef hg bi translated">张量流简介</h2><div class="ko l"><h3 class="bd b fi z dy km ea eb kn ed ef dx translated">在这篇文章中，我将介绍张量流的基础知识，在深入研究之前，你需要了解这些知识…</h3></div><div class="kp l"><p class="bd b fp z dy km ea eb kn ed ef dx translated">medium.com</p></div></div><div class="kq l"><div class="mz l ks kt ku kq kv jg kh"/></div></div></a></div><div class="ke kf ez fb kg kh"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/basic-operations-of-tensorflow-e6311e2eb8a0"><div class="ki ab dw"><div class="kj ab kk cl cj kl"><h2 class="bd hi fi z dy km ea eb kn ed ef hg bi translated">张量流的基本运算</h2><div class="ko l"><h3 class="bd b fi z dy km ea eb kn ed ef dx translated">张量流简介第2部分</h3></div><div class="kp l"><p class="bd b fp z dy km ea eb kn ed ef dx translated">medium.com</p></div></div><div class="kq l"><div class="kr l ks kt ku kq kv jg kh"/></div></div></a></div></div></div>    
</body>
</html>