<html>
<head>
<title>Akira’s Machine Learning news — #Week 12, 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Akira的机器学习新闻—2021年第12周</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/akiras-machine-learning-news-week-12-2021-c7072495c544?source=collection_archive---------21-----------------------#2021-03-28">https://medium.com/analytics-vidhya/akiras-machine-learning-news-week-12-2021-c7072495c544?source=collection_archive---------21-----------------------#2021-03-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="126b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2021年第12周</p><p id="a361" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">论文或文章的发表日期不一定是同一周※</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="098d" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated">本周特稿/新闻。</h2><ul class=""><li id="ddd3" class="ke kf hh ig b ih kg il kh ip ki it kj ix kk jb kl km kn ko bi translated">有一项研究表明，将CNN整合到基于变压器的模型中可以提高精确度。这可能是研究趋势的转折点，因为迄今为止的主流是通过将自我关注(Transformer的核心技术之一)纳入基于CNN的模型来提高准确性。另外，Vision Transformer只是把图像分成小块放入模型，但我认为这里使用的方法，即在放入Transformer之前使用CNN获取更多本地化信息，可以通用于Vision &amp;语言。</li><li id="846a" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb kl km kn ko bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.11886" rel="noopener ugc nofollow" target="_blank">有一项研究表明，深化变压器模型不会提高准确性，因为注意力图都是相似的</a>。这很好的解决了《视觉变压器》中稍微描述的“只靠自我关注，感应偏差小，所以用ImageNet的数据量无法达到精度”的问题。供您参考，CNN(ResNet)报道了一个类似的<a class="ae kp" href="https://arxiv.org/abs/2010.15327" rel="noopener ugc nofollow" target="_blank">现象，在那里共同的表征被学习到多个层次</a>。</li><li id="8a24" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb kl km kn ko bi translated"><a class="ae kp" href="https://pytorch.org/blog/introducing-pytorch-profiler-the-new-and-improved-performance-tool/" rel="noopener ugc nofollow" target="_blank">在Pytorch 1.8.1中，实现了一个可视化显示计算状态的工具</a>，它可以在Tensorboard中可视化，并允许您检查网络每层的计算时间和内存使用情况。它非常有用。</li></ul><h2 id="b63b" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated">现实世界中的机器学习</h2><ul class=""><li id="c932" class="ke kf hh ig b ih kg il kh ip ki it kj ix kk jb kl km kn ko bi translated"><a class="ae kp" href="https://www.cnbc.com/2021/02/03/amazon-using-ai-equipped-cameras-in-delivery-vans.html" rel="noopener ugc nofollow" target="_blank">亚马逊正在使用一种工具来监控送货司机的危险迹象。虽然这有助于防止事故和提高安全性，但它也带来了隐私问题(例如，当打私人电话时，它可以被关闭)。如</a><a class="ae kp" href="https://aiindex.stanford.edu/report/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%28ja%29&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">斯坦福大学报告</a>所示，自动监控系统越来越便宜，所以我觉得“隐私与实用性”的问题需要进一步讨论，包括法律的制定。</li><li id="dba6" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb kl km kn ko bi translated">脸书似乎正在开发一项服务，它可以生成并读出一份绘制照片的文档，以便视障人士可以欣赏照片。自从CLIP和<a class="ae kp" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank"> DALL E </a>问世以来，Vision &amp;语言系统的发展已经令人瞩目，因此它很可能是一项高质量的服务。此外，自从Vision Tranformer问世以来，文本和图像都可以由Transformer处理，这可能有助于该领域的发展。</li></ul><h2 id="a569" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated">报纸</h2><ul class=""><li id="1f03" class="ke kf hh ig b ih kg il kh ip ki it kj ix kk jb kl km kn ko bi translated"><a class="ae kp" href="https://openreview.net/forum?id=d-XzF81Wg1" rel="noopener ugc nofollow" target="_blank">已经发表了一篇论文，研究为什么批处理规范化是有效的</a>。这方面的研究已经有好几个了，但是本文提出了一个简单的假设“因为它抑制了最后一层的输出所以是好的”，并且得到了实验验证。另据了解，当加入Dropout时，批量归一化的网络的精度会下降，其原因(很可能)被广泛认为是“Dropout对通过批量归一化计算的方差和均值的计算产生不利影响”。但是，此处提出的假设是，由于剔除和批量正规化之间的相似性，在已经具有这种效果的批量正规化模型中包含剔除不会提高准确性。</li><li id="0a7b" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb kl km kn ko bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.06255" rel="noopener ugc nofollow" target="_blank">这项研究表明，当使用为每个像素分配不同值并跨通道共享值的层时，准确性更好，这与卷积不同，卷积将固定值过滤器应用于每个通道的每个像素</a>，因为它就像自我关注的简化版本，作者说，“我们可以凭经验确认自我关注是视觉最近发展的重要驱动力。</li></ul><p id="8056" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><p id="7a96" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在下面的章节中，我将介绍各种文章和论文，不仅仅是关于上述内容，还包括以下五个主题。</p><ol class=""><li id="7bd4" class="ke kf hh ig b ih ii il im ip kv it kw ix kx jb ky km kn ko bi translated">本周特稿/新闻</li><li id="580d" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb ky km kn ko bi translated">机器学习用例</li><li id="d8c4" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb ky km kn ko bi translated">报纸</li><li id="e93a" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb ky km kn ko bi translated">机器学习技术相关文章</li><li id="5995" class="ke kf hh ig b ih kq il kr ip ks it kt ix ku jb ky km kn ko bi translated">其他主题</li></ol><p id="694b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="ae05" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">1.本周特稿/新闻</h1><h2 id="a6b9" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.11816?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">将CNN导入变压器</strong> </a></h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es lq"><img src="../Images/24f5a0d8192eb592784b51f6d76cca36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jfOqmnkEYgI3tvFIN-kxcw.png"/></div></div></figure><p id="257c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mc">【2103.11816】将卷积设计纳入视觉变形器</em> <br/>一项将CNN纳入ViT的研究，旨在通过显式纳入来捕获局部成分。提出了将CNN抽象应用到图像修补的图像到令牌，将CNN结合到FFN的LeFF模块，等等。超出EfficientNet-B4和DeiT的结果。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="c62f" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.11886?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">解决深化变形金刚</strong> </a>时产生类似注意力地图的问题</h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es md"><img src="../Images/bdb72571597838a0e3faa2cd8cc4e33a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UX574I__VO56HRONbUeChQ.png"/></div></div></figure><p id="7f4e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mc">【2103.11886】deep ViT:走向更深层次的视觉转换者</em> <br/>用ImageNet训练的vit不会从深化中受益，因为生成了类似的注意力地图。从头部注意力高度多样性的角度来看，他们能够通过引入一个可学习的参数来混合头部注意力以提高注意力的多样性，从而通过加深来提高准确性。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="43f3" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://pytorch.org/blog/introducing-pytorch-profiler-the-new-and-improved-performance-tool/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak"> Pytorch可以让你直观的检查计算量。</strong>T13】</a></h2><div class="me mf ez fb mg mh"><a href="https://pytorch.org/blog/introducing-pytorch-profiler-the-new-and-improved-performance-tool/" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">PyTorch</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">微软首席项目经理华微软首席工程经理吉塔</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">pytorch.org</p></div></div><div class="mq l"><div class="mr l ms mt mu mq mv ma mh"/></div></div></a></div><p id="ca99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">官方博客介绍torch.profiler，在Pytrorch 1.8.1中改进。通过此次更新，您可以通过Tensorboard直观地测量数据加载时间等。还可以可视化网络每一层的计算时间，并查看瓶颈层在哪里。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="951b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="cd5d" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">2.机器学习用例</h1><h2 id="43e5" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://www.cnbc.com/2021/02/03/amazon-using-ai-equipped-cameras-in-delivery-vans.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">亚马逊使用系统监控送货司机的冒险行为</strong> </a></h2><div class="me mf ez fb mg mh"><a href="https://www.cnbc.com/2021/02/03/amazon-using-ai-equipped-cameras-in-delivery-vans.html" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">亚马逊正在送货车上使用配备人工智能的摄像头，一些司机担心隐私</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">一些美国工厂的亚马逊司机很快就会有一双额外的眼睛看着他们上路…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">www.cnbc.com</p></div></div></div></a></div><p id="f003" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">亚马逊正在使用一个系统来监控送货司机的危险行为，如斜眼、打哈欠和使用安全带。虽然该系统可以监控危险行为并提高安全性，但它也存在一些问题，如隐私问题和向送货司机发送你不信任他们的信息。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="2a51" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://tech.fb.com/how-facebook-is-using-ai-to-improve-photo-descriptions-for-people-who-are-blind-or-visually-impaired/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">为视障人士提供准确的替代文字</strong> </a></h2><div class="me mf ez fb mg mh"><a href="https://tech.fb.com/how-facebook-is-using-ai-to-improve-photo-descriptions-for-people-who-are-blind-or-visually-impaired/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">脸书如何使用人工智能来改善盲人或视觉障碍者的照片描述…</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">2016年，我们推出了自动替代文本，这是一种计算机视觉技术，通过描述照片让脸书变得更容易访问…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">tech.fb.com</p></div></div><div class="mq l"><div class="mw l ms mt mu mq mv ma mh"/></div></div></a></div><p id="ce7f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果照片有描述其外观的替代文本，您可以不用看照片就能阅读照片中的内容，但大多数照片没有该替代文本。脸书自动生成高度准确的替代文本，并使用文本到语音来解释文本，以便视障人士可以享受脸书饲料。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="472b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="66b6" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">3.报纸</h1><p id="c652" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip mx ir is it my iv iw ix mz iz ja jb ha bi translated">【arxiv.org】<strong class="ig hi">通过反转卷积过程提高精度</strong><strong class="ig hi">——</strong><a class="ae kp" href="https://arxiv.org/abs/2103.06255" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi"/></a></p><figure class="lr ls lt lu fd lv er es paragraph-image"><div class="ab fe cl na"><img src="../Images/a8771fd826b2cdb428b68722e1b75b2c.png" data-original-src="https://miro.medium.com/v2/0*nCb1ETQ7vHbXNWbS"/></div></figure><p id="2c77" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mc">【2103.06255】对合:反转卷积的固有特性用于视觉识别</em> <br/>与卷积不同，卷积将固定值的滤波器应用于每个通道中的每个像素，他们提出了对合，为每个像素分配不同的值，并在通道之间共享该值。它被认为是一种自我关注，是卷积的相反运算，而且不像卷积，从一开始就有很宽的视野。他们证实了图像分类、对象检测和分割的性能改进。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="0fd4" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://openreview.net/forum?id=d-XzF81Wg1&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">批量正规化为什么有效？</strong> </a></h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es nb"><img src="../Images/509d29cfd61bc56b124263619c231bb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TUSVcPGrnIHZicHJAU7r0A.png"/></div></div></figure><p id="4d8f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mc">解构BatchNorm的正则化| OpenReview </em> <br/>一项旨在检验批处理正则化为何有效的研究。他们通过实验证实，批量归一化通过抑制最终图层(就在分类图层之前)的输出来提高精度，并通过添加具有类似效果的正则化来提高概化性能。他们还指出，作为一个正则化术语，Dropout与batch正则化具有相同的效果。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="88d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae kp" href="https://arxiv.org/abs/2102.06183?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">几帧足以代表一部电影。</strong>T3】</a></p><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es nc"><img src="../Images/725f06bf62e9719488e84498f154eeeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C2sQPSh3n5YwJCwan4ea2A.png"/></div></div></figure><p id="f04d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mc">【2102.06183】少即是多:通过稀疏采样进行视频和语言学习的ClipBERT</em><br/>基于少量帧足以表示视频的思想，我们通过在Conv2D系统中仅处理少量帧来研究视频和文本的预训练。通过E2E训练，结果超过了现有的研究。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="190d" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://arxiv.org/abs/2103.10957?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">无监督分割信息对比学习</strong> </a></h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es nd"><img src="../Images/b879c244c684ebc5c6cc5cc3954894f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BxzAW5D_SF7otmGeMquPaw.png"/></div></div></figure><p id="1d6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mc">【2103.10957】采用对比检测的高效视觉预处理</em> <br/>他们提出了一种无监督的对比学习DetCon，根据无监督分割生成的掩模，将相同掩模类别的特征聚集在一起。在保持对比学习的计算成本为1/5的同时，他们在预训练中获得了超过传统方法和监督表示的对象检测的有用表示。</p><h2 id="812f" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kp" href="https://arxiv.org/abs/2004.01888?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">一种跟踪方法，不仅关注对象检测，还关注Re-id </strong> </a></h2><figure class="lr ls lt lu fd lv er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es ne"><img src="../Images/1b149ccbf79cbf1c71d66fc70bcc1408.png" data-original-src="https://miro.medium.com/v2/resize:fit:1194/format:webp/1*UZVhJdxlIELFgLBftVhgHw.png"/></div></div></figure><p id="e13c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">FairMOT:关于多目标跟踪中检测和再识别的公平性这是一项不仅关注目标检测而且关注再识别的跟踪研究。在跟踪中，当使用基于锚点的对象检测时，多个锚点被分配给一个对象，这导致与附近的对象混淆，但是它们可以使用CenterNet来避免这个问题，CenterNet是没有锚点的对象检测方法。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="496e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="5acb" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">4.机器学习技术相关文章</h1><p id="ee75" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip mx ir is it my iv iw ix mz iz ja jb ha bi translated"><a class="ae kp" href="https://ruder.io/recent-advances-lm-fine-tuning/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">语言模式的微调</strong> </a></p><div class="me mf ez fb mg mh"><a href="https://ruder.io/recent-advances-lm-fine-tuning/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">语言模型微调的最新进展</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">微调预先训练的语言模型(LM)已经成为在自然语言环境中进行迁移学习的事实标准</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">ruder.io</p></div></div><div class="mq l"><div class="nf l ms mt mu mq mv ma mh"/></div></div></a></div><p id="650c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一篇详述语言模型微调的文章。文章引用了几篇论文，介绍了自适应微调、行为微调和以低学习率和大量时期进行稳定微调的训练。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="a332" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae kp" href="https://towardsdatascience.com/a-machine-learning-engineers-tutorial-to-transfer-learning-for-multi-class-image-segmentation-b34818caec6b?gi=70d64eee7d82&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener" target="_blank"> <strong class="ig hi">用Unet进行多类分割</strong> </a></p><div class="me mf ez fb mg mh"><a href="https://towardsdatascience.com/a-machine-learning-engineers-tutorial-to-transfer-learning-for-multi-class-image-segmentation-b34818caec6b" rel="noopener follow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">一个机器学习工程师的教程，以转移学习的多类图像分割…</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">分割模型最佳参数化的调试指南</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">towardsdatascience.com</p></div></div><div class="mq l"><div class="ng l ms mt mu mq mv ma mh"/></div></div></a></div><p id="f5c6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一篇带有代码的文章，解释了一个使用Unet的例子，Unet常用于语义分割，用于分割医学图像中的异常区域。解释详细，通俗易懂。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="eb70" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="8e6b" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">5.其他主题</h1><p id="bfb8" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip mx ir is it my iv iw ix mz iz ja jb ha bi translated"><a class="ae kp" href="https://heartbeat.fritz.ai/full-body-deepfakes-3d-human-filters-and-more-new-enhanced-ar-features-round-the-corner-for-7154e51814be?gi=221b55f4b60b&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> Snapchat用收购来提振AR？</strong> </a></p><div class="me mf ez fb mg mh"><a href="https://heartbeat.fritz.ai/full-body-deepfakes-3d-human-filters-and-more-new-enhanced-ar-features-round-the-corner-for-7154e51814be" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">全身Deepfakes、3D人体滤镜等等:增强的AR新功能即将推出…</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">在Snap收购初创公司Ariel AI之后，让我们来看看Snapchat的AR产品会有什么</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">heartbeat.fritz.ai</p></div></div><div class="mq l"><div class="nh l ms mt mu mq mv ma mh"/></div></div></a></div><p id="2c72" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章预测了最近收购Snap Inc .将如何增强Snap chat的AR功能。文章介绍了被收购公司拥有的一些技术，如智能手机上的实时人体合成、语音交互等。它还提到了一种可以从单幅RGB图像中重建人体3D模型的技术。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><p id="0ad9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="9b5d" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">你可以得到每周的时事通讯。请订阅！</h1><p id="a1bc" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip mx ir is it my iv iw ix mz iz ja jb ha bi translated">过去的时事通讯</p><div class="me mf ez fb mg mh"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-machine-learning-news-week-11-2021-474227" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">Akira的机器学习新闻-# 2021年第11周</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">Akira的机器学习新闻-2021年第11周。(论文或文章的发表日期不一定是…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">www.getrevue.co</p></div></div><div class="mq l"><div class="ni l ms mt mu mq mv ma mh"/></div></div></a></div><div class="me mf ez fb mg mh"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-machine-learning-news-week-10-2021-453505" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">Akira的机器学习新闻-# 2021年第10周</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">Akira的机器学习新闻-2021年第10周</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">www.getrevue.co</p></div></div><div class="mq l"><div class="nj l ms mt mu mq mv ma mh"/></div></div></a></div><div class="me mf ez fb mg mh"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-machine-learning-news-february-2021-419853" rel="noopener  ugc nofollow" target="_blank"><div class="mi ab dw"><div class="mj ab mk cl cj ml"><h2 class="bd hi fi z dy mm ea eb mn ed ef hg bi translated">Akira的机器学习新闻-2021年2月</h2><div class="mo l"><h3 class="bd b fi z dy mm ea eb mn ed ef dx translated">2020年2月特稿/新闻。机器学习用例物联网和人工智能可以结合起来自动化很多事情…</h3></div><div class="mp l"><p class="bd b fp z dy mm ea eb mn ed ef dx translated">www.getrevue.co</p></div></div><div class="mq l"><div class="nk l ms mt mu mq mv ma mh"/></div></div></a></div><p id="1a60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="671d" class="kz jk hh bd jl la lb lc jp ld le lf jt lg lh li jw lj lk ll jz lm ln lo kc lp bi translated">关于我</h1><p id="aa0c" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip mx ir is it my iv iw ix mz iz ja jb ha bi translated">制造工程师/机器学习工程师/数据科学家/物理学硕士/<a class="ae kp" href="https://t.co/hjHHbG24Ph?amp=1&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">http://github.com/AkiraTOSEI/</a></p><p id="4c56" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">推特，我贴一句纸评论。</p><figure class="lr ls lt lu fd lv"><div class="bz dy l di"><div class="nl nm l"/></div></figure></div></div>    
</body>
</html>