<html>
<head>
<title>Automatic image annotation using Active learning of weather conditions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用天气条件的主动学习的自动图像注释</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/automatic-image-annotation-using-active-learning-of-weather-conditions-928b01bd8a0f?source=collection_archive---------24-----------------------#2021-03-23">https://medium.com/analytics-vidhya/automatic-image-annotation-using-active-learning-of-weather-conditions-928b01bd8a0f?source=collection_archive---------24-----------------------#2021-03-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><blockquote class="ie if ig"><p id="122c" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">实施多标签天气分类模型:白天、夜晚或黄昏用于视觉条件，晴朗、下雨或下雪用于天气条件。</p><p id="caf3" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">实施“损失预测模块”,用于选择要注释和训练的数据。</p><p id="1aa2" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">数据集的大部分可以被自动注释。</p></blockquote></div><div class="ab cl jg jh go ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="ha hb hc hd he"><h1 id="8357" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">概述:</h1><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es kl"><img src="../Images/ac7c81439ac6dbe64a95867cc3851bef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Bu72hSo0sPPE9vYDlCfb6A.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">天气分类模型和自动标注标准概述。</figcaption></figure></div><div class="ab cl jg jh go ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="ha hb hc hd he"><h1 id="5ae2" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">数据不平衡</h1><p id="66fe" class="pw-post-body-paragraph ih ii hh ik b il lb in io ip lc ir is ld le iv iw lf lg iz ja lh li jd je jf ha bi translated">所有实时数据都包含不平衡数据。该模型应该在所有标签上表现良好。以下是所用数据集的示例。</p><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es lj"><img src="../Images/758018783554cfe3f18d196f7e74e424.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pdYk4jN1HzITY59YAc9sMw.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">班级的分布显示出数据的不平衡。为每个类别选择可训练数据是很重要的。</figcaption></figure><p id="d434" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is ld iu iv iw lf iy iz ja lh jc jd je jf ha bi translated">解决方案:</p><ol class=""><li id="e79b" class="lk ll hh ik b il im ip iq ld lm lf ln lh lo jf lp lq lr ls bi translated">数据的欠采样:不平衡的类分布将有一个或多个样本很少的类(少数类)和一个或多个样本很多的类(多数类)。它包括通过消除属于多数类的样本来减少数据，目的是均衡每类样本的数量。这将不对称从1:100降低到1:10或1:2的类别分布。</li><li id="bbca" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf lp lq lr ls bi translated">类别权重:解决数据不平衡的方法之一是为每个标签提供权重，这为少数标签提供了更多的重要性，从而最终结果是所有标签的平衡。使用中值频率平衡的类权重计算如下:w_class = median_freq / freq_class</li><li id="72cf" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf lp lq lr ls bi translated">数据扩充:数据扩充是一种无需收集更多真实数据就能增加数据集多样性的技术。它防止模型过度拟合。</li></ol></div><div class="ab cl jg jh go ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="ha hb hc hd he"><h1 id="3b05" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">迁移学习</h1><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es ly"><img src="../Images/71ceb8af6aea359364b9011ff5a2fb80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v-cG2o76Xx7i9sx8QPHpxg.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">从其他类似数据集中初始化权重。</figcaption></figure></div><div class="ab cl jg jh go ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="ha hb hc hd he"><h1 id="fc61" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">损失预测模块</strong></h1><figure class="km kn ko kp fd kq er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es lz"><img src="../Images/5709b0f7cd2313efcc5c343dbb4d2d78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pa93AYyX66WhdD3b07KFSA.jpeg"/></div></div><figcaption class="kx ky et er es kz la bd b be z dx translated">损失预测模块的体系结构。这个模块连接到目标模型的几个中间层。中间特征被映射到标量值作为损失预测。计算损失的图解。给定输入，目标模型输出目标预测，并且损失预测模块输出预测的损失。</figcaption></figure><ol class=""><li id="2424" class="lk ll hh ik b il im ip iq ld lm lf ln lh lo jf lp lq lr ls bi translated">附加到目标模型的损失预测模块根据没有标签的输入预测损失值。</li><li id="d20b" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf lp lq lr ls bi translated">丢失预测模块评估未标记池中的所有数据点。具有前K个预测损失的数据点被注释并添加到训练数据集中。</li></ol></div><div class="ab cl jg jh go ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="ha hb hc hd he"><h1 id="9c53" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">主动学习</h1><p id="6a44" class="pw-post-body-paragraph ih ii hh ik b il lb in io ip lc ir is ld le iv iw lf lg iz ja lh li jd je jf ha bi translated">问题:</p><ul class=""><li id="77f1" class="lk ll hh ik b il im ip iq ld lm lf ln lh lo jf ma lq lr ls bi translated">应该对哪些数据进行标记和训练？</li><li id="ae99" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">估算模型的性能？</li></ul><p id="ea73" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is ld iu iv iw lf iy iz ja lh jc jd je jf ha bi translated">解决方案:</p><ul class=""><li id="d285" class="lk ll hh ik b il im ip iq ld lm lf ln lh lo jf ma lq lr ls bi translated">网络识别难以预测的图像</li><li id="333a" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">从整个数据库中扫描独特的图像</li><li id="2bd3" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">确定最佳情况和最差情况下的性能</li><li id="401e" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">没有基础事实的近似误差估计</li></ul><figure class="km kn ko kp fd kq er es paragraph-image"><div class="er es mb"><img src="../Images/c3a5f39d68a34347c9ce2370b68155f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*yB2Q3Jn3-eL1LImf_0RVsg.jpeg"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">loos预测输出</figcaption></figure><ul class=""><li id="a9c2" class="lk ll hh ik b il im ip iq ld lm lf ln lh lo jf ma lq lr ls bi translated">高损失=高误差=预测出错的高可能性</li><li id="6c81" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">低损失=低误差=预测正确的可能性高</li><li id="4035" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">最高的k精度总是具有最低的精度(最坏的情况)</li><li id="9ec5" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">最低的k精度总是最高的精度(最好的情况)</li><li id="26e4" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">选择前k个图像进行手动标记和重新训练</li></ul><h1 id="cb4b" class="jn jo hh bd jp jq mc js jt ju md jw jx jy me ka kb kc mf ke kf kg mg ki kj kk bi translated">自动注释</h1><ul class=""><li id="71e9" class="lk ll hh ik b il lb ip lc ld mh lf mi lh mj jf ma lq lr ls bi translated">标记的和未标记的数据可以通过阈值损失本身来决定</li><li id="f696" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">非常少量的非常高的误差数据被手动标记用于再训练。</li><li id="fc93" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">大多数低误差数据可以自动标记为高精度。</li><li id="fe67" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">Rest是未标记的，并且期望在使用非常少的新样本的主动学习的进一步循环中被标记。</li></ul></div><div class="ab cl jg jh go ji" role="separator"><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl jm"/><span class="jj bw bk jk jl"/></div><div class="ha hb hc hd he"><h1 id="873c" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">详细流程</h1><ol class=""><li id="4afb" class="lk ll hh ik b il lb ip lc ld mh lf mi lh mj jf lp lq lr ls bi translated">数据分析:</li></ol><ul class=""><li id="68b6" class="lk ll hh ik b il im ip iq ld lm lf ln lh lo jf ma lq lr ls bi translated">了解数据集中的分布和模式。</li><li id="318b" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">查找损坏的图像/标签。</li><li id="6891" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">寻找数据不平衡和偏差。</li><li id="fac7" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">将异常值和边界条件可视化。</li></ul><p id="e36b" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is ld iu iv iw lf iy iz ja lh jc jd je jf ha bi translated">2.建立端到端的培训/评估框架</p><ul class=""><li id="597d" class="lk ll hh ik b il im ip iq ld lm lf ln lh lo jf ma lq lr ls bi translated">人类基线</li><li id="5f5f" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">用固定参数获取模型的基线。</li><li id="5052" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">过度拟合模型以检查容量。</li><li id="64b8" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">调整超参数</li></ul><p id="76ea" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is ld iu iv iw lf iy iz ja lh jc jd je jf ha bi translated">在未标记数据集上使用主动学习的步骤:</p><ul class=""><li id="6a6c" class="lk ll hh ik b il im ip iq ld lm lf ln lh lo jf ma lq lr ls bi translated">第一步是手动标记数据的一个非常小的子样本。它提供了标签之间的本质区别。</li><li id="70e4" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">一旦有了少量的标注数据，就需要对模型进行训练。该模型不会很好，但将有助于该模型了解参数空间的哪些区域需要进一步标记。</li><li id="c836" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">使用迁移学习:据观察，在训练的早期阶段，由于数据量明显较少，要训练的层数应该很少，并且用预训练的权重冻结其他层。训练层的层数随着可训练数据的增加而增加。</li><li id="42cc" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">在模型被训练之后，该模型被用于在剩余的未标记数据点上预测类别。基于模型的预测，在每个未标记的数据点上选择分数。在我们的例子中，使用了损失预测模块。</li><li id="93a9" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">具有高预测损失的数据点被手动标记并用于再训练。</li><li id="0143" class="lk ll hh ik b il lt ip lu ld lv lf lw lh lx jf ma lq lr ls bi translated">这个过程可以重复:可以在新的标记数据集上训练新的模型，该数据集已经基于优先级分数进行了标记。一旦在数据子集上训练了新的模型，未标记的数据点可以在模型中运行，以更新优先化分数，从而继续标记。这样，随着模型变得越来越好，人们可以不断优化标记策略。</li></ul><p id="215f" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is ld iu iv iw lf iy iz ja lh jc jd je jf ha bi translated">退房:<a class="ae mk" href="http://karpathy.github.io/2019/04/25/recipe/" rel="noopener ugc nofollow" target="_blank">http://karpathy.github.io/2019/04/25/recipe/</a></p></div></div>    
</body>
</html>