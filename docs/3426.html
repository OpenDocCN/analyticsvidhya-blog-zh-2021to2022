<html>
<head>
<title>How To Show Your Minority Class Much-Needed TLC</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何展示你的少数民族阶级急需的TLC</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-show-your-minority-class-much-needed-tlc-44f8670268f6?source=collection_archive---------14-----------------------#2021-06-30">https://medium.com/analytics-vidhya/how-to-show-your-minority-class-much-needed-tlc-44f8670268f6?source=collection_archive---------14-----------------------#2021-06-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="c280" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">关于类不平衡的综合实践教程，并附有Python代码示例</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/3d6118f354d06d8634f6be96c2481aa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QoePl4GxqsfKvFKIrssszQ.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">照片由<a class="ae jm" href="https://unsplash.com/@ivanana?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">伊万娜拉</a>在<a class="ae jm" href="https://unsplash.com/s/photos/care?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="9d43" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在纽约市和美国，最糟糕的情况已经过去的后电晕时代，我们应该首先花些时间给自己一些早该有的TLC，但是一旦该说的都说了，该做的都做了，让我们谈谈如何在你的下一个分类项目中给你的少数民族班级一些适当的TLC。</p><p id="34f5" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在我Flatiron项目后半段的大部分时间里，我感兴趣的每一个话题都毫无例外地以失衡告终。第三阶段，我想从事一个尽可能远离我专业领域的课题，即金融。我偶然发现了一个Kaggle数据集，用于开发一个分类模型来预测信用卡持有人是否会拖欠即将到来的付款。所有金融术语都有一个学习曲线，但我不知道这将是我通过几个不平衡数据集的旅程的开始，即第4阶段的仇恨推文和顶石的黑色素瘤图像。</p><p id="e208" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在这篇博客中，我将深入探讨如何使用台湾信用卡数据集来处理你下一个机器学习项目中的类别不平衡问题。关于Kaggle数据集的完整代码，请参考下面列出的Jupyter笔记本:</p><div class="kj kk ez fb kl km"><a href="https://github.com/datascisteven/Medium-Blogs/blob/main/Class_Imbalance.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hi fi z dy kr ea eb ks ed ef hg bi translated">datassisteven/Medium-博客</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">我的中型博客的代码库。通过在…上创建一个帐户，为datassisteven/Medium-Blogs的发展做出贡献</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">github.com</p></div></div><div class="kv l"><div class="kw l kx ky kz kv la jg km"/></div></div></a></div><p id="a133" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为了运行本报告中提供的代码，您需要安装<code class="du lb lc ld le b">imbalanced-learn</code>包，这需要以下依赖项:</p><ul class=""><li id="1a57" class="lf lg hh jp b jq jr jt ju jw lh ka li ke lj ki lk ll lm ln bi translated">python (&gt;=3.6)</li><li id="0ae6" class="lf lg hh jp b jq lo jt lp jw lq ka lr ke ls ki lk ll lm ln bi translated">numpy (&gt;=1.13.3)</li><li id="4330" class="lf lg hh jp b jq lo jt lp jw lq ka lr ke ls ki lk ll lm ln bi translated">scipy (&gt;=0.19.1)</li><li id="c177" class="lf lg hh jp b jq lo jt lp jw lq ka lr ke ls ki lk ll lm ln bi translated">scikit-learn (&gt;=0.23)</li></ul><p id="bf1c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">安装完依赖项后，使用以下终端命令之一安装<code class="du lb lc ld le b">imbalanced-learn</code>包:</p><ul class=""><li id="cc8e" class="lf lg hh jp b jq jr jt ju jw lh ka li ke lj ki lk ll lm ln bi translated"><code class="du lb lc ld le b">pip install -U imbalanced-learn</code></li><li id="8350" class="lf lg hh jp b jq lo jt lp jw lq ka lr ke ls ki lk ll lm ln bi translated"><code class="du lb lc ld le b">conda install -c conda-forge imbalanced-learn</code></li></ul><p id="ecc0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">前一个命令可以用于任何Python安装，而后一个命令用于conda环境中的安装。</p><h1 id="dc16" class="lt lu hh bd lv lw lx ly lz ma mb mc md in me io mf iq mg ir mh it mi iu mj mk bi translated">什么是不平衡数据集？</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="ab fe cl ml"><img src="../Images/65c4cac6a1eeb7d2fe933430be3f97bb.png" data-original-src="https://miro.medium.com/v2/format:webp/1*h_KspF6X8DkGen7G_UQ8Qg.jpeg"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">照片由<a class="ae jm" href="https://unsplash.com/@designschnecke?utmsource=unsplash&amp;utmmedium=referral&amp;utmcontent=creditCopyText" rel="noopener ugc nofollow" target="_blank"> <em class="mm">芭芭拉·霍恩</em> </a> <em class="mm">在</em>的Unsplash上拍摄</figcaption></figure><p id="5af6" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果不同分类类别的比例不相等，则认为数据集不平衡。期望真实数据完全平衡甚至有些平衡是不现实的。作为数据科学家，我们经常会面对一个数据集，这个数据集是通过我们自己的努力填充的，或者是由一个类(多数类)的许多实例组成的，但我们感兴趣的实例却很少，即少数类。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="ab fe cl ml"><img src="../Images/9b716207ae45c8f91cc3bb324262f1c4.png" data-original-src="https://miro.medium.com/v2/format:webp/1*_w_7MvNsJcAdKOC-Clj6nQ.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">目标变量“默认”分布的条形图</figcaption></figure><p id="4029" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">对于信用卡默认数据集，这是用于说明目标变量分布的可视化，它表明该客户群中有22.1%属于少数族裔。根据谷歌的机器学习课程，具有20%-40%少数民族类别的数据集被认为是轻度不平衡的，1%-20%是中度不平衡的，任何低于1%的都是极度不平衡的。</p><h2 id="08c1" class="mn lu hh bd lv mo mp mq lz mr ms mt md jw mu mv mf ka mw mx mh ke my mz mj na bi translated">显示不平衡分布的代码</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nb nc l"/></div></figure><p id="35a4" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">要运行该代码，您需要导入数据集并执行80/20的训练验证分割。在训练模型之前，我选择不做任何预处理或特征工程。</p><h1 id="583f" class="lt lu hh bd lv lw lx ly lz ma mb mc md in me io mf iq mg ir mh it mi iu mj mk bi translated">为什么我们需要从解决不平衡开始？</h1><p id="9471" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated">不平衡数据集对数据科学家提出了挑战，因为大多数机器学习算法都期望平衡的类分布，并在这样的分布下最佳地执行。如果一个阶层的代表性过高，模型就会偏向多数阶层，将少数阶层视为数据中的噪音。我们作为标准承担者所依赖的指标，如准确性，变得毫无意义。</p><p id="511f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我们想象一个场景，其中我们有一个10，000个客户的数据集，其中有9，500个非违约者和500个违约者，我们将9250个正确地识别为非违约者(真阴性)，25个正确地识别为违约者(真阳性)，475个错误地识别为非违约者(假阴性)，250个错误地识别为违约者(假阳性)。我们可能会倾向于满足于我们的模型达到92.75%的准确率，但仔细观察，尽管准确率如此之高，我们的模型只能识别500个少数案例中的25个。如果我们仅仅依赖准确性作为我们的绩效指标，我们会被误导，认为我们的模型能够正确预测违约者。如果我们试图识别癌症检测呈阳性的患者，我们会意识到无法识别少数群体(即癌症检测呈阳性的患者)的潜在负面影响。</p><h1 id="4647" class="lt lu hh bd lv lw lx ly lz ma mb mc md in me io mf iq mg ir mh it mi iu mj mk bi translated">处理阶级不平衡的工具有哪些？</h1><ol class=""><li id="2043" class="lf lg hh jp b jq nd jt ne jw ni ka nj ke nk ki nl ll lm ln bi translated">对训练样本进行不同的加权</li><li id="4931" class="lf lg hh jp b jq lo jt lp jw lq ka lr ke ls ki nl ll lm ln bi translated">为更多少数类实例合并附加数据集</li><li id="2dd7" class="lf lg hh jp b jq lo jt lp jw lq ka lr ke ls ki nl ll lm ln bi translated">对训练数据集进行重采样</li></ol><p id="5e6a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在这篇博客中，我将只关注重采样方法。诚然，Flatiron的doxology使我偏向于项目的选项2和3，但时间不允许我为项目合并另一个数据集。</p><h1 id="552b" class="lt lu hh bd lv lw lx ly lz ma mb mc md in me io mf iq mg ir mh it mi iu mj mk bi translated">绩效指标审查</h1><p id="c9f9" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated">我们之前看到了准确性如何提供模型性能的误导性指示，因此我们必须在训练过程中寻找一些其他指标来评估具有不平衡数据集的模型。让我们来看看我在评估模型时使用的指标:</p><h2 id="2239" class="mn lu hh bd lv mo mp mq lz mr ms mt md jw mu mv mf ka mw mx mh ke my mz mj na bi translated">精确度和召回率</h2><p id="f132" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated">如果我们看一下精度公式(TP / TP + FP)和召回公式(TP / TP + FN ),我们会注意到这两个指标明显忽略了真正的否定。Precision告诉我们，在所有我们预测为阳性的阳性结果(即TP和FP)中，我们正确预测并真正为阳性的百分比是多少。相反，回忆(或TPR)告诉我们，在所有阳性实例(即TP和FN)中，我们预测有多少是阳性的。</p><p id="fe37" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果我们更仔细地观察这两个公式，一个最小化假阳性的模型会有更高的精确度，一个最小化假阴性的模型会有更高的召回率。随着FP的接近零，精度变得越来越接近简化为分数TP/TP，换句话说，接近1。类似地，当FN接近0时，回忆接近1。</p><p id="b2cf" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">从上面的场景中，让我们回忆一下TP的数量是25，FP的数量是250，FN的数量是475，这给了我们9%的精确度和5%的召回率，这对于识别违约者来说不是一个好兆头。这强调了衡量标准而不是准确性的重要性。</p><h2 id="2c0d" class="mn lu hh bd lv mo mp mq lz mr ms mt md jw mu mv mf ka mw mx mh ke my mz mj na bi translated">F1分数</h2><p id="d22e" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated">这是召回率和精确度的调和平均值，所以它同时考虑了假阳性和假阴性。由于我们希望最小化FP和FN，最大化F1分数将是选择最佳模型的有用指标。就像偏差和差异一样，回忆和精确也有类似的相互作用，提高一个是以牺牲另一个为代价的。</p><h2 id="c119" class="mn lu hh bd lv mo mp mq lz mr ms mt md jw mu mv mf ka mw mx mh ke my mz mj na bi translated">ROC曲线和ROC-AUC评分</h2><p id="94e1" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated">这是最常用于比较不平衡数据集的不同模型的指标，而不是准确性。它在x轴上绘制FPR，在y轴上绘制TPR。TPR(或回忆)不在正面类中，我们正确预测了多少，而FPR不在负面类(FP和TN)中，我们错误预测了多少。因此，这里我们有一个情况，我们想要最大化一个和最小化另一个，即最大化TPR和最小化FPR。</p><p id="bb65" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">值得注意的是，ROC-AUC分数为0.5的基线模型表明该分类器没有任何辨别能力，这对应于度量图中从左下到右上的对角线。这可能是两种情况之一，要么是模型预测每个数据点的随机类，要么是常数类。也就是说，例如，在右上角，当TPR和FPR都等于1时，阳性类的每个成员都被正确分类，而阴性类的每个成员都被错误分类。</p><p id="ab25" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">直到最近，我还没有太多考虑ROC-AUC分数为0意味着什么，但这意味着所有积极的类实例都被预测为消极的，所有消极的都被预测为积极的。当AUC在0.5和1之间时，我们的模型能够检测到比FN和FP更多的TP和TN，因此能够更好地区分阳性和阴性类别。</p><h2 id="6871" class="mn lu hh bd lv mo mp mq lz mr ms mt md jw mu mv mf ka mw mx mh ke my mz mj na bi translated">PR曲线和PR-AUC评分</h2><p id="a0df" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated">PR曲线在x轴上绘制回忆，在y轴上绘制精度。基线取决于数据集的分布。对于完美分布的数据集，基线为50%。随机估计值的PR-AUC分数等于数据集中阳性实例的百分比。对于具有10%阳性实例的数据集，基线PR-AUC得分为0.10，因此高于基线的数字将构成得分的改善。对于我们目前的数据集，基线PR-AUC评分约为0.22。</p><p id="3317" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">虽然我在项目期间使用PR-AUC作为衡量标准，但从那时起，我的理解是，它在高度不平衡的数据集或比较具有类似极端不平衡的模型时更有用。</p><h2 id="bbea" class="mn lu hh bd lv mo mp mq lz mr ms mt md jw mu mv mf ka mw mx mh ke my mz mj na bi translated">评估模型性能的代码</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nb nc l"/></div></figure><h1 id="399a" class="lt lu hh bd lv lw lx ly lz ma mb mc md in me io mf iq mg ir mh it mi iu mj mk bi translated">重采样方法概述</h1><p id="b6ad" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated">为了对训练数据集进行重采样，模块<code class="du lb lc ld le b">imbalanced-learn</code>为手头的任务提供了四种不同类别的方法或技术:</p><ol class=""><li id="ab8b" class="lf lg hh jp b jq jr jt ju jw lh ka li ke lj ki nl ll lm ln bi translated">欠采样方法</li><li id="6d63" class="lf lg hh jp b jq lo jt lp jw lq ka lr ke ls ki nl ll lm ln bi translated">过采样方法</li><li id="578a" class="lf lg hh jp b jq lo jt lp jw lq ka lr ke ls ki nl ll lm ln bi translated">组合方法</li><li id="ca07" class="lf lg hh jp b jq lo jt lp jw lq ka lr ke ls ki nl ll lm ln bi translated">集成方法</li></ol><p id="e0cc" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这里有一个不同类别的快速回顾，因为全面的讨论本身就是一篇博文。欠采样包括从多数类中移除实例，过采样包括添加少数类的实例，组合方法对两个类进行重采样，目的都是为了创建两个类的更均匀分布。我认为我们在Flatiron时已经意识到过采样比欠采样更好用，因为我们可能会因为欠采样而丢失重要信息。然而，前者有其自身的缺陷，包括复制无信息实例的可能性。</p><p id="5e6b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">欠采样方法分为两类:固定欠采样和清洁欠采样。固定欠采样方法是指在数据集达到平衡之前移除少数实例的方法，而清理方法是基于某种标准或算法来清理要素空间。在我们实施的方法中，单侧选择、编辑过的最近邻和Tomek链接将被视为清理方法，而如果您在重采样后查看多数类和少数类的分布，则接近失误将被视为固定的。</p><p id="2977" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">过采样方法包括复制少数实例的技术，如随机过采样，或基于某些算法生成合成实例的技术，如SMOTE。通过对少数类进行过采样，我们的模型了解了少数类的具体情况，但它无法很好地进行概括。为了抵消这种过度拟合的趋势，SMOTE沿着特征空间中连接两个相邻少数实例的线段随机生成新的样本。最终，它已经成为产生SMOTE变体整个家族的过采样的首选方法之一。</p><p id="f621" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">说到这里，组合方法将两个世界的优点结合在一起，试图解决SMOTE的缺点，包括它通过盲目选择最近邻居而产生额外噪声和重叠类的趋势。ENN和托梅克链接各自在SMOTE过程之后实现，作为减轻一些缺点的过滤手段。</p><p id="95fb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">最后，集成方法分为两大类:boosting和bagging。提升包括按顺序或系列训练分类器，所有训练样本的权重相等，并且在每次迭代后，模型误分类的样本的权重增加。Bagging或bootstrap聚合涉及在原始数据集的子集上拟合基本分类器，然后通过平均或投票来聚合预测。</p><h2 id="0a7c" class="mn lu hh bd lv mo mp mq lz mr ms mt md jw mu mv mf ka mw mx mh ke my mz mj na bi translated">模型训练代码</h2><p id="5829" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated">我们希望使用下面的参数<code class="du lb lc ld le b">strategy=most_frequent</code>运行一个分类器<code class="du lb lc ld le b">DummyClassifier()</code>来确定我们的基线分数。这意味着什么呢？分类器预测训练集中最频繁的标签，即预测每个实例的0或多数类。在这种情况下，我们的精确度是多少？我们将得到一个等于多数类的比例或78.12%的准确度。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nb nc l"/></div></figure><p id="9e42" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">至于PR-AUC得分，它将等于少数民族类的比例(21.88%)，对于ROC-AUC，它应等于0.5，这对应于没有我们之前建立的辨别能力。</p><p id="8738" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">下面是运行SMOTE的过采样方法的代码，但是我们将实例化一个不同的重采样方法，但是运行插入新方法的<code class="du lb lc ld le b">run_resampling</code>函数。这可以应用于所有欠采样、过采样和组合重采样方法。</p><p id="e649" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">提醒一下，我们在数据集上执行了80/20分割，从目标(<code class="du lb lc ld le b">y</code>)变量中分割特征(<code class="du lb lc ld le b">X</code>)变量，在训练(<code class="du lb lc ld le b">X_train</code>)集上运行<code class="du lb lc ld le b">fit_transform</code>，在测试集(<code class="du lb lc ld le b">X_valid</code>)上只运行<code class="du lb lc ld le b">transform</code>。对训练数据运行几个模型，并且在重采样之前确定最佳模型。因为我们在进程中间跳转，这就是我们如何到达代码中的<code class="du lb lc ld le b">GradientBoostingClassifier()</code>。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="nb nc l"/></div></figure><p id="46ac" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们用<code class="du lb lc ld le b">StandardScaler()</code>对数据集进行了规范化，但是作为提醒，我们希望在训练集上运行<code class="du lb lc ld le b">.fit()</code>和<code class="du lb lc ld le b">.transform()</code>，但是在测试或验证集上只运行<code class="du lb lc ld le b">.transform()</code>。这就是上面函数中的<code class="du lb lc ld le b">X_train_norm</code>和<code class="du lb lc ld le b">X_valid_norm</code>。</p><h2 id="d5e9" class="mn lu hh bd lv mo mp mq lz mr ms mt md jw mu mv mf ka mw mx mh ke my mz mj na bi translated">关于原始项目的最终想法</h2><p id="4ca9" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated">最初，我不太愿意总结我的第三阶段项目的结果，因为我预计重新采样会在指标方面产生一些实质性的变化。它们都不能产生比基本分类器更高的准确度，但是Tomek链接和单边选择是最接近的。SMOTE以准确性为代价产生了更高的F1分数，而Tomek Links具有类似的准确性，F1分数略有提高。我无法提高PR-AUC或ROC-AUC评分，它们基本上始终保持不变。</p><p id="f990" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">最终，在我的项目中，通过微调超参数，我能够提高我的准确性和ROC-AUC分数。</p><p id="0eef" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这是我最初项目的数据框架:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="ab fe cl ml"><img src="../Images/f318572912b4d1b6f6823891967a7845.png" data-original-src="https://miro.medium.com/v2/format:webp/1*8O7O2IR91n_d01mj_p1_nw.png"/></div></figure><p id="a1a1" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">回想起来，基线准确率为78%，我仍然认为还有潜在的改进空间。我可以容忍ROC-AUC或F1评分增加的准确性下降。</p><p id="6311" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在不平衡数据集的大计划中，我认为这个数据集只是轻度不平衡，因此重采样方法可能不那么有效，甚至可能对它们有害。在回顾一些Kaggle repos时，似乎我在提高准确性和ROC-AUC分数方面的努力并非没有先例。然而，这值得进一步研究，因为Alam等人使用K-Means SMOTE过采样的GBDT模型产生了89%的准确性，而Islam等人使用他们的<em class="nm">机器学习方法</em>产生了95%的准确性。</p><p id="8402" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">博客的代码是我的原始项目的简化版本，位于以下位置:</p><div class="kj kk ez fb kl km"><a href="https://github.com/datascisteven/Taiwan-CC-Default-Prediction" rel="noopener  ugc nofollow" target="_blank"><div class="kn ab dw"><div class="ko ab kp cl cj kq"><h2 class="bd hi fi z dy kr ea eb ks ed ef hg bi translated">datassisteven/Taiwan-CC-Default-Prediction</h2><div class="kt l"><h3 class="bd b fi z dy kr ea eb ks ed ef dx translated">项目作者:Steven Yan项目顾问:李芳芳、约书亚茨马诺夫斯基一家总部位于美国的信用卡发行商</h3></div><div class="ku l"><p class="bd b fp z dy kr ea eb ks ed ef dx translated">github.com</p></div></div><div class="kv l"><div class="nn l kx ky kz kv la jg km"/></div></div></a></div><h2 id="da9d" class="mn lu hh bd lv mo mp mq lz mr ms mt md jw mu mv mf ka mw mx mh ke my mz mj na bi translated">资源:</h2><p id="309e" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated"><strong class="jp hi">谷歌的机器学习速成班:</strong>https://developers.google.com/machine-learning/crash-course T2</p><p id="4351" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">不平衡学习用户指南:<a class="ae jm" href="https://imbalanced-learn.org/stable/user_guide.html" rel="noopener ugc nofollow" target="_blank">https://imbalanced-learn.org/stable/user_guide.html</a></p><p id="5aef" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">娜塔莉·霍克汉姆:不平衡数据集的机器学习:</strong><a class="ae jm" href="https://www.youtube.com/watch?v=X9MZtvvQDR4" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=X9MZtvvQDR4</a></p><h2 id="a827" class="mn lu hh bd lv mo mp mq lz mr ms mt md jw mu mv mf ka mw mx mh ke my mz mj na bi translated">参考资料:</h2><p id="4d93" class="pw-post-body-paragraph jn jo hh jp b jq nd ii js jt ne il jv jw nf jy jz ka ng kc kd ke nh kg kh ki ha bi translated">Alam，T.M .，Shaukat，k .，Hameed，I .，Luo，s .，Sarwar，M.U .，Shabbir，s .，Li，j .，&amp; Khushi，M. (2020)。不平衡数据集中信用卡违约预测的研究。<em class="nm"> IEEE访问，8 </em>，201173–201198。<a class="ae jm" href="https://doi.org/10.1109/ACCESS.2020.3033784" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1109/ACCESS.2020.3033784</a></p><p id="934c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">马，于(2020)。信用卡账单违约概率的预测。<em class="nm">商业与管理开放期刊，08 </em>，231–244。<a class="ae jm" href="https://doi.org/10.4236/ojbm.2020.81014" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.4236/ojbm.2020.81014</a></p><p id="c5fe" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">新泽西州激流市、佐治亚州维萨尼市和东巴格里市(2020年)。PSD2可解释的人工智能信用评分模型。<em class="nm"> ArXiv，abs/2011.10367 </em>。<a class="ae jm" href="https://arxiv.org/pdf/2011.10367.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2011.10367.pdf</a></p><p id="ed28" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">lematre，g .，Nogueira，f .，和Aridas，C.K. (2017年)。不平衡学习:一个Python工具箱来解决机器学习中不平衡数据集的诅咒。<em class="nm"> ArXiv，abs/1609.06570 </em>。<a class="ae jm" href="http://jmlr.org/papers/v18/16-365.html" rel="noopener ugc nofollow" target="_blank">https://jmlr.org/papers/v18/16-365.html</a></p><p id="8682" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">Galar，m .，Fernández，a .，Tartas，e .，Bustince，h .，和Herrera，F. (2012年)。类不平衡问题的集成综述:基于Bagging、Boosting和Hybrid的方法。IEEE系统、人和控制论汇刊，C部分(应用和评论)，42 ，463–484。<a class="ae jm" href="https://doi.org/10.1109/TSMCC.2011.2161285" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1109/TSMCC.2011.2161285</a></p><p id="858e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">加西亚，v .，桑切斯，j .，和莫琳达，R.A. (2010年)。探索类不平衡问题重采样策略的性能。国际能源机构/AIE。<a class="ae jm" href="https://doi.org/10.1007/978-3-642-13022-9_54" rel="noopener ugc nofollow" target="_blank">https://doi.org/10.1007/978-3-642-13022-9<em class="nm">54</em>T37】</a></p><p id="76be" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">伊斯拉姆，埃伯勒，w .，&amp;加福尔，S. (2018)。结合机器学习和启发式方法的信用违约挖掘。<em class="nm"> ArXiv，abs/1807.01176 </em>。https://arxiv.org/pdf/1807.01176.pdf<a class="ae jm" href="https://arxiv.org/pdf/1807.01176.pdf" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>