<html>
<head>
<title>Akira’s ML news — #Week 8, 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Akira的ML新闻—2021年第8周</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/akiras-ml-news-week-8-2021-a59ee101cef7?source=collection_archive---------12-----------------------#2021-02-19">https://medium.com/analytics-vidhya/akiras-ml-news-week-8-2021-a59ee101cef7?source=collection_archive---------12-----------------------#2021-02-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="dc06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是我在2021年第8周(2月14日~)读到的一些我觉得特别有意思的论文和文章。我已经尽量介绍最近的了，但是论文提交的日期可能和星期不一样。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="a6a9" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated">主题</h2><ol class=""><li id="eeb4" class="ke kf hh ig b ih kg il kh ip ki it kj ix kk jb kl km kn ko bi translated">机器学习论文</li><li id="91ab" class="ke kf hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">技术文章</li><li id="8874" class="ke kf hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">机器学习用例的例子</li><li id="ac6d" class="ke kf hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">其他主题</li></ol><h2 id="958b" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated">—每周编辑精选</h2><ul class=""><li id="30f1" class="ke kf hh ig b ih kg il kh ip ki it kj ix kk jb ku km kn ko bi translated"><a class="ae kv" href="https://arxiv.org/abs/2101.11986?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">具有改进的图像标记化的ViT模型</a></li><li id="e59f" class="ke kf hh ig b ih kp il kq ip kr it ks ix kt jb ku km kn ko bi translated"><a class="ae kv" href="https://arxiv.org/abs/2102.05095?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">运行中的变压器识别任务</a></li><li id="172f" class="ke kf hh ig b ih kp il kq ip kr it ks ix kt jb ku km kn ko bi translated"><a class="ae kv" href="https://arxiv.org/abs/2102.06171?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">在没有批量标准化的情况下表现优于EfficientNet的网络</a></li></ul><h1 id="132c" class="kw jk hh bd jl kx ky kz jp la lb lc jt ld le lf jw lg lh li jz lj lk ll kc lm bi translated">1.机器学习论文</h1><h2 id="2175" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://arxiv.org/abs/2101.09978?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> GANs生成GUI </a></h2><figure class="ln lo lp lq fd lr er es paragraph-image"><div class="ab fe cl ls"><img src="../Images/37eadb5ff09f32ea52e1c37be78890ac.png" data-original-src="https://miro.medium.com/v2/0*KaqkO0e1XlyPpVUQ"/></div></figure><p id="4ca6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lv">【2101.09978】GUIGAN:学习使用生成式对抗网络生成GUI设计</em> <br/>一种生成智能手机应用程序GUI的GAN，使用顺序生成每个元素(如按钮)的策略，使用SeqGAN而不是直接生成每个像素。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="8413" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://arxiv.org/abs/2010.04456?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">用机器学习扩充模拟结果</a></h2><figure class="ln lo lp lq fd lr er es paragraph-image"><div class="ab fe cl ls"><img src="../Images/5b7a266f4649b8d7d2846cb3074d95ca.png" data-original-src="https://miro.medium.com/v2/0*a_iZ_uTXV2WIrZRw"/></div></figure><p id="90c6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lv">【2010.04456】用深度网络增强物理模型，用于复杂动力学预测<br/> </em>他们提出了APHYNITY(增强不完整的物理模型，用于识别和预测复杂动力学)，它使用ML的力量来补充基于物理的模拟，这种模拟往往过于简化现象，无法很好地预测它们。通过将ML和物理模型结合起来，他们可以成功地预测单一模型无法近似的东西。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="7371" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://arxiv.org/abs/2102.06171?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">性能优于EfficientNet但没有批量标准化的网络</a></h2><figure class="ln lo lp lq fd lr er es paragraph-image"><div class="ab fe cl ls"><img src="../Images/924a518e440857ac521ab9f5276356e5.png" data-original-src="https://miro.medium.com/v2/0*miLJP82lkV68cakQ"/></div></figure><p id="02f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lv">【2102.06171】无需归一化的高性能大规模图像识别<br/> </em>他们提出了无需批量归一化就能优于EfficientNet的NFNets。虽然采用了一种机制，像以前的工作一样通过批量归一化来模拟网络的缩放(<a class="ae kv" href="https://arxiv.org/abs/2101.08692" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2101.08692</a>)，但他们使用自适应梯度裁剪(AGC)来根据权重的大小自适应地限制梯度大小。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="58a9" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://arxiv.org/abs/2102.05095?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">运行中的变压器识别任务</a></h2><figure class="ln lo lp lq fd lr er es paragraph-image"><div class="ab fe cl ls"><img src="../Images/5b39f72eaeab640ccedefad3acb64f92.png" data-original-src="https://miro.medium.com/v2/0*VMH3Vx7y-KsdKBd8"/></div></figure><p id="2e29" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lv">【2102.06171】无需归一化的高性能大规模图像识别</em> <br/>他们提出了仅使用变压器的TimeSformer，并在动作识别任务中超越了基于CNN的模型。它计算时间方向上的注意力，然后像在ViT中一样在修补每一帧后计算空间方向上的注意力。它在Kinetics-400，600上实现了Sota性能，在Something-Something-V2上也实现了高精度。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="12c7" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://arxiv.org/abs/2102.06108?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">利用小波提高分辨率的生成模型</a></h2><figure class="ln lo lp lq fd lr er es paragraph-image"><div class="ab fe cl ls"><img src="../Images/914c427f55442d9e6758ec3f84129aca.png" data-original-src="https://miro.medium.com/v2/0*1xSKmwJVnfXG0mo_"/></div></figure><p id="42f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lv">【2102.06108】SWAGAN:一种基于风格的小波驱动生成模型<br/> </em>在StyleGAN中，这项研究通过渐进增长小波而不是RGB图像生成高分辨率图像，并且可以达到与基于RGB方法相同的质量，而计算资源仅为基于RGB方法的1/4。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="938e" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://arxiv.org/abs/2101.11986?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">具有改进的图像标记化的ViT模型</a></h2><figure class="ln lo lp lq fd lr er es paragraph-image"><div class="ab fe cl ls"><img src="../Images/90c780daa53cf0644a2eaec084cd9541.png" data-original-src="https://miro.medium.com/v2/0*ASOaHLpFd8selBk6"/></div></figure><p id="8b85" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lv">【2101.11986】Tokens-to-Token ViT:在ImageNet上从零开始训练视觉变形器<br/> </em> ViT是第一个精度超过当时最高性能CNN模型的纯变形器模型，当数据集为中等规模或模型规模较小时，其性能比等效CNN模型差。他们认为这是因为图像标记化过于简单，因此他们提出了一个T2T模块，允许通过混合周围的标记进行复制和重新标记化。结果超过了具有相同参数数量的ResNet的结果。此外，他们通过应用ghost net(<a class="ae kv" href="https://arxiv.org/abs/1911.11907')" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1911.11907')</a>中使用的压缩方法成功压缩了模型。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="fd84" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated">检测艺术品中的人物。</h2><figure class="ln lo lp lq fd lr er es paragraph-image"><div class="ab fe cl ls"><img src="../Images/16fa19c73a9c86b1cb6a21fbaa3ccc8a.png" data-original-src="https://miro.medium.com/v2/0*uA0HbalBOyEa3GQh"/></div></figure><p id="fe61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lv">【2102.06529】仅使用风格转换来改进艺术图像中的对象检测<br/> </em>这是一项通过使用修改后的COCO女士(即风格转换为艺术风格)进行微调来检测艺术作品中的人物的研究。原则上，它可以用于非人类的检测，并且它可以用于收集描绘某个对象的艺术品。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="d21b" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://arxiv.org/abs/2102.03141?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">从多幅图像中创建动画</a></h2><figure class="ln lo lp lq fd lr er es paragraph-image"><div class="ab fe cl ls"><img src="../Images/1f207d4fc20156e213043dc3b7e3a825.png" data-original-src="https://miro.medium.com/v2/0*y1w306a38B2q2YTL"/></div></figure><p id="52b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lv">【2102.03141】Character gan:少镜头关键点角色动画和寄托<br/> </em>这是一个从几个图像创建动画的研究。通过将图像的每个部分分成三层，他们可以生成不会混淆前景和背景的图像，同时通过预测遮罩，他们可以让模型学会保持各个部分之间的联系。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h1 id="e765" class="kw jk hh bd jl kx lw kz jp la lx lc jt ld ly lf jw lg lz li jz lj ma ll kc lm bi translated">2.技术文章</h1><h2 id="8ac6" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://blog.tensorflow.org/2021/01/custom-object-detection-in-browser.html?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">使用Tensorflow.js运行对象检测模型</strong> </a></h2><div class="mb mc ez fb md me"><a href="https://blog.tensorflow.org/2021/01/custom-object-detection-in-browser.html" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">使用TensorFlow.js在浏览器中进行自定义对象检测</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">获取和处理数据如前所述，该模型将使用袋鼠数据集进行训练…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">blog.tensorflow.org</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms lt me"/></div></div></a></div><p id="b7f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文解释了如何使用tensorflow.js训练对象检测模型，该模型允许您创建在浏览器中运行的模型，以及如何使用它通过网络摄像头执行实时检测。详细解释了该过程的每个步骤。</p><h2 id="d94d" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://distill.pub/2020/circuits/frequency-edges/?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">检测高低频的神经元</strong> </a></h2><div class="mb mc ez fb md me"><a href="https://distill.pub/2020/circuits/frequency-edges/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">高低频检测器</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">一个对从高到低空间频率的定向转换做出反应的早期视觉神经元家族。一些…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">蒸馏. pub</p></div></div><div class="mn l"><div class="mt l mp mq mr mn ms lt me"/></div></div></a></div><p id="e30e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一篇关于DNN神经元检测到的模式的讨论文章。用于图像识别的DNN模型不仅具有用于识别简单图案(例如简单曲线、直线和颜色)的机制，还具有用于识别组合了高和低频率的图案的组。文章认为它们是用来识别物体边界的。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="b183" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://distill.pub/2020/grand-tour/?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">可视化一个量词</strong> </a></h2><div class="mb mc ez fb md me"><a href="https://distill.pub/2020/grand-tour/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">可视化神经网络与大旅游</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">“大旅行”是一种经典的高维点云可视化技术，它可以投射出一个高维的…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">蒸馏. pub</p></div></div><div class="mn l"><div class="mu l mp mq mr mn ms lt me"/></div></div></a></div><p id="fc1d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章使用了一种叫做GroundTour的方法，直观地展示了在一个简单的卷积网络的训练过程中，属于每个标签的数据是如何分类的。有趣的是，每个标签的学习时间是不同的，并且对立样本在中间层形成独立于正常数据的聚类。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h1 id="5fc6" class="kw jk hh bd jl kx lw kz jp la lx lc jt ld ly lf jw lg lz li jz lj ma ll kc lm bi translated">3.机器学习用例</h1><h2 id="5fd7" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" href="https://electrek.co/2021/01/29/wind-farm-eagle-deaths-cut-by-82-percent-ai-optical-technology/?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">风力发电机自动减速防止鸟撞</strong> </a></h2><div class="mb mc ez fb md me"><a href="https://electrek.co/2021/01/29/wind-farm-eagle-deaths-cut-by-82-percent-ai-optical-technology/" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">这种人工智能光学技术将风力涡轮机鹰的死亡率降低了82% - Electrek</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">IdentiFlight的智能摄像机可以发现老鹰等猛禽，然后停止风力涡轮机以保护鸟类…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">electrek.co</p></div></div><div class="mn l"><div class="mv l mp mq mr mn ms lt me"/></div></div></a></div><p id="b117" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">风力发电设施会导致野生鸟类与它们相撞，导致死亡。为了防止这种情况，已经安装了一个系统，该系统使用机器学习来识别15公里范围内的飞行物体，从而确定是否减慢风力涡轮机的旋转。这让我们在保护野生动物的同时，最大限度地减少发电的减法。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h2 id="1913" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" rel="noopener" href="/criteo-engineering/top-applications-of-graph-neural-networks-2021-c06ec82bfc18?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter"> <strong class="ak"> GNN应用举例</strong> </a></h2><div class="mb mc ez fb md me"><a rel="noopener follow" target="_blank" href="/criteo-engineering/top-applications-of-graph-neural-networks-2021-c06ec82bfc18"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">图形神经网络的主要应用2021</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">gnn在学术界取得了长足的进步。但是我们在工业上有很好的应用吗？</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">medium.com</p></div></div><div class="mn l"><div class="mw l mp mq mr mn ms lt me"/></div></div></a></div><p id="00ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文介绍了图形神经网络的一些现实应用，包括阿里巴巴用于推荐，谷歌用于硬件优化和药物发现。</p><h1 id="9aab" class="kw jk hh bd jl kx ky kz jp la lb lc jt ld le lf jw lg lh li jz lj lk ll kc lm bi translated">4.其他主题</h1><h2 id="0947" class="jj jk hh bd jl jm jn jo jp jq jr js jt ip ju jv jw it jx jy jz ix ka kb kc kd bi translated"><a class="ae kv" rel="noopener" href="/pytorch/introducing-lightning-flash-the-fastest-way-to-get-started-with-deep-learning-202f196b3b98?utm_campaign=Akira%27s%20ML%20news&amp;utm_medium=email&amp;utm_source=Revue%20newsletter"> <strong class="ak">闪电来自Pytorch闪电</strong> </a></h2><div class="mb mc ez fb md me"><a rel="noopener follow" target="_blank" href="/pytorch/introducing-lightning-flash-the-fastest-way-to-get-started-with-deep-learning-202f196b3b98"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">闪电简介—从深度学习基线到研究瞬间完成</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">Flash是一个任务集合，用于快速原型制作、基线和微调，以实现快速和可扩展的DL，构建于…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">medium.com</p></div></div><div class="mn l"><div class="mx l mp mq mr mn ms lt me"/></div></div></a></div><p id="00d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Pytorch闪电放出了闪电闪，比Pyroch闪电还要简单。它可以在几行代码中使用训练好的模型执行文本分类、表格数据分类和图像表示向量获取。</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h1 id="b315" class="kw jk hh bd jl kx lw kz jp la lx lc jt ld ly lf jw lg lz li jz lj ma ll kc lm bi translated">关于机器学习的每周时事通讯</h1><div class="mb mc ez fb md me"><a href="https://www.getrevue.co/profile/akiratosei" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">阿基拉的ML新闻杂志</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">关于我:制造工程师/机器学习工程师/物理学硕士/ ExaWizards Inc. _ _ _ _ _…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">www.getrevue.co</p></div></div><div class="mn l"><div class="my l mp mq mr mn ms lt me"/></div></div></a></div></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><h1 id="864c" class="kw jk hh bd jl kx lw kz jp la lx lc jt ld ly lf jw lg lz li jz lj ma ll kc lm bi translated">过去的时事通讯</h1><div class="mb mc ez fb md me"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-ml-news-week-7-2021-372359" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">Akira的ML新闻-# 2021年第7周</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">以下是我在2021年第7周(2月7日~)读到的一些我觉得特别有趣的论文和文章…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">www.getrevue.co</p></div></div><div class="mn l"><div class="mz l mp mq mr mn ms lt me"/></div></div></a></div><div class="mb mc ez fb md me"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-ml-news-week-6-2021-345481" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">Akira的ML新闻-# 2021年第6周</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">以下是我在2021年第6周(1月31日~)读到的一些我觉得特别有趣的论文和文章…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">www.getrevue.co</p></div></div><div class="mn l"><div class="na l mp mq mr mn ms lt me"/></div></div></a></div><div class="mb mc ez fb md me"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/akiras-ml-news-january-2021-34a7249c6bb9"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">Akira的ML新闻# 2021年1月</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">以下是我在2021年1月读到的一些我觉得特别有趣的论文和文章。</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">medium.com</p></div></div><div class="mn l"><div class="nb l mp mq mr mn ms lt me"/></div></div></a></div><div class="mb mc ez fb md me"><a href="https://towardsdatascience.com/machine-learning-2020-summary-84-interesting-papers-articles-45bd45c0d35b" rel="noopener follow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">机器学习2020摘要:84篇有趣的论文/文章</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">在这篇文章中，我总共展示了2020年发表的84篇我觉得特别有趣的论文和文章…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">towardsdatascience.com</p></div></div><div class="mn l"><div class="nc l mp mq mr mn ms lt me"/></div></div></a></div><h1 id="f579" class="kw jk hh bd jl kx ky kz jp la lb lc jt ld le lf jw lg lh li jz lj lk ll kc lm bi translated">关于我</h1><p id="94ca" class="pw-post-body-paragraph ie if hh ig b ih kg ij ik il kh in io ip nd ir is it ne iv iw ix nf iz ja jb ha bi translated">制造工程师/机器学习工程师/数据科学家/物理学硕士/<a class="ae kv" href="https://t.co/hjHHbG24Ph?amp=1" rel="noopener ugc nofollow" target="_blank">http://github.com/AkiraTOSEI/</a></p><p id="d572" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">推特，我贴一句纸评论。</p><figure class="ln lo lp lq fd lr"><div class="bz dy l di"><div class="ng nh l"/></div></figure></div></div>    
</body>
</html>