<html>
<head>
<title>Let's Talk about Random Forests!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">再说随机森林！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/lets-talk-about-random-forests-524ae1138d8b?source=collection_archive---------14-----------------------#2021-04-19">https://medium.com/analytics-vidhya/lets-talk-about-random-forests-524ae1138d8b?source=collection_archive---------14-----------------------#2021-04-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/8c41184b6875847233e46a7dee2c0e0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-yJz1Y3ZsIBb0Js1rzBVSA.jpeg"/></div></div></figure><p id="f1e7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在我之前的文章中，我们讨论了<a class="ae jn" rel="noopener" href="/analytics-vidhya/decision-tree-101-e94a5d131fa0">决策树</a>算法。尽管决策树是一个非常酷的直观算法，但它也带来了过度拟合的诅咒。在本文中，我们将基于决策树的思想，学习在机器学习领域广泛使用的随机森林算法。</p><p id="d222" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">随机森林算法</strong></p><ul class=""><li id="b520" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">根据维基百科</li></ul><blockquote class="jx jy jz"><p id="950b" class="ip iq ka ir b is it iu iv iw ix iy iz kb jb jc jd kc jf jg jh kd jj jk jl jm ha bi translated"><strong class="ir hi">随机森林</strong>或<strong class="ir hi">随机决策森林</strong>是一种用于分类、回归和其他任务的集成学习方法，它通过在训练时构建大量<strong class="ir hi">决策</strong>树并输出作为类(分类)或单个树的均值/平均预测(回归)的模式的类来操作</p></blockquote><h1 id="1e4d" class="ke kf hh bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">步伐</h1><ol class=""><li id="55c4" class="jo jp hh ir b is lc iw ld ja le je lf ji lg jm lh ju jv jw bi translated">在这种情况下，我们获取训练数据，然后从中创建引导数据集。看看下面的图片，更好地了解它。</li></ol><figure class="lj lk ll lm fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es li"><img src="../Images/8e917cb7fae164ceb5aedd497089f8b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bMQmaPCqY4OaLx3F2wuQww.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">拔靴带</figcaption></figure><ul class=""><li id="3c94" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">所以我们所做的是，我们获取完整的数据集，然后将数据集分成多个部分。请记住，这些示例可以在不同的引导示例中重复。</li><li id="d8dd" class="jo jp hh ir b is lr iw ls ja lt je lu ji lv jm jt ju jv jw bi translated">然后，我们获取这些自举样本，并使用它们来制作多个决策树。所创建的决策树将具有不同的行为，因为它们是使用不同的样本创建的。</li><li id="1897" class="jo jp hh ir b is lr iw ls ja lt je lu ji lv jm jt ju jv jw bi translated">我们通过创建多个决策树获得的多样性使其比单个决策树更有效。</li></ul><p id="0b97" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">我们现在如何使用它们？</strong></p><ul class=""><li id="bf83" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">现在我们已经创建了决策树，我们如何评估它或使用它来进行预测。</li><li id="2db9" class="jo jp hh ir b is lr iw ls ja lt je lu ji lv jm jt ju jv jw bi translated">为了评估，我们执行以下技巧。定型集中的大部分数据都没有进入引导数据集。它被称为'<strong class="ir hi">出袋数据集</strong>，我们可以用它来评估随机森林。</li><li id="be8a" class="jo jp hh ir b is lr iw ls ja lt je lu ji lv jm jt ju jv jw bi translated">我们举一个例子，然后把它传递给不同的决策树。如果是回归任务，我们取输出的平均值。在分类任务的情况下，我们给出的输出是由大多数树预测的输出。</li><li id="f1b9" class="jo jp hh ir b is lr iw ls ja lt je lu ji lv jm jt ju jv jw bi translated">被错误分类的袋外样本比例为“<strong class="ir hi">袋外误差”。</strong></li></ul><p id="fc17" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">装袋技术</strong></p><ul class=""><li id="ea50" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">装袋是random forest正在使用的一种技术。</li><li id="0c5d" class="jo jp hh ir b is lr iw ls ja lt je lu ji lv jm jt ju jv jw bi translated">装袋可以总结为引导，然后是聚集步骤。</li><li id="8dfa" class="jo jp hh ir b is lr iw ls ja lt je lu ji lv jm jt ju jv jw bi translated">在随机森林中，我们应用这种打包技术，首先引导数据集创建多个决策树，然后聚合它们的结果以给出最终输出。</li></ul><p id="0531" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">随机森林的优点</strong></p><ul class=""><li id="26d0" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">随机森林对于离群值是健壮的，因为它们通过多个树输出的聚合得到平均。</li><li id="197f" class="jo jp hh ir b is lr iw ls ja lt je lu ji lv jm jt ju jv jw bi translated">它非常适合非线性数据。</li><li id="01d3" class="jo jp hh ir b is lr iw ls ja lt je lu ji lv jm jt ju jv jw bi translated">过度拟合的风险很低，因为结果是基于多个决策树的输出来计算的。</li></ul><p id="7866" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">希望这篇文章能让你更好地理解随机森林是如何工作的。</p><p id="3498" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在那之前，祝你学习愉快！！！</p></div></div>    
</body>
</html>