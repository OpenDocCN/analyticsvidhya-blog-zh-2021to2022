<html>
<head>
<title>Web Scraping Best Children’s Hospitals for Cancer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">癌症最佳儿童医院</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-best-childrens-hospitals-for-cancer-5574db6d4090?source=collection_archive---------13-----------------------#2021-02-25">https://medium.com/analytics-vidhya/web-scraping-best-childrens-hospitals-for-cancer-5574db6d4090?source=collection_archive---------13-----------------------#2021-02-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="e6fd" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">Python vs鼠标</h2></div><p id="0c5a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当所需的结构不容易下载时，Web抓取是从在线来源获得结构化数据集的好方法。我试过几个Python包，最喜欢的是<a class="ae js" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="noopener ugc nofollow" target="_blank">美汤</a>。我将用这篇文章来记录我是如何利用它来刮美国新闻网站的一角的，这是各种排名(学校，医院等)的来源。).我的目标数据集是儿科肿瘤医院的详细排名，这里列出了<a class="ae js" href="https://health.usnews.com/best-hospitals/pediatric-rankings/cancer" rel="noopener ugc nofollow" target="_blank"/>。我将在代码中布置构建模块，到最后，我将整个脚本以及抓取的数据集放在电子表格中。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es jt"><img src="../Images/44e700ce16655b9a72368cd0670a3864.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*r47gIbt-nc3VcbZE."/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">照片由<a class="ae js" href="https://unsplash.com/@pankajpatel?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Pankaj Pate </a> l在<a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplas </a> h上拍摄</figcaption></figure><h1 id="4a00" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated"><strong class="ak">为什么要刮网</strong></h1><p id="1507" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">我的一个医生朋友，住在另一个国家，最近询问了美国的儿童医院。不久前，我偶然发现了美国大学排名新闻，当然，这也是我搜索它时谷歌建议的第一件事。</p><p id="eb64" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我本可以花几分钟打一份Excel电子表格并分享它。但是，当我浏览网站时，我意识到《美国新闻》不仅提供了基于专业评分、专家意见和患者数量三项指标的综合排名(T10)，还提供了不同类别的详细评分(或分组(T16)，以排名第一的费城儿童医院(T12)为例，它构成了总分)。</p><p id="29d3" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我意识到这将增加我点击每个排名医院的链接、在屏幕间切换、打字和反复检查的时间。这也是一个很好的机会来解决一些网络抓取代码，而不是手工完成。所以我们开始吧。</p><h1 id="d054" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated"><strong class="ak">刮排名和总分</strong></h1><p id="6137" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">通常，抓取一个相当简单的网站的工作流程包括:</p><ol class=""><li id="d0d7" class="lg lh hh iy b iz ja jc jd jf li jj lj jn lk jr ll lm ln lo bi translated">启动BeautifulSoup对象</li><li id="87c1" class="lg lh hh iy b iz lp jc lq jf lr jj ls jn lt jr ll lm ln lo bi translated">找到嵌入数据的标签</li><li id="31c8" class="lg lh hh iy b iz lp jc lq jf lr jj ls jn lt jr ll lm ln lo bi translated">如有必要，使用正则表达式或一些字符串操作来提取数据</li><li id="a157" class="lg lh hh iy b iz lp jc lq jf lr jj ls jn lt jr ll lm ln lo bi translated">将数据放入熊猫数据帧作为输出</li></ol><p id="a03f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">要做2，我们需要先考察网页的源代码。我是这样做的</p><ol class=""><li id="0061" class="lg lh hh iy b iz ja jc jd jf li jj lj jn lk jr ll lm ln lo bi translated">在谷歌浏览器中打开网页</li><li id="65f0" class="lg lh hh iy b iz lp jc lq jf lr jj ls jn lt jr ll lm ln lo bi translated">右键单击任何空白区域，然后单击“查看页面源代码”</li></ol><p id="9924" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于<a class="ae js" href="https://health.usnews.com/best-hospitals/pediatric-rankings/cancer" rel="noopener ugc nofollow" target="_blank">综合排名</a>页面，这将我们带到一个充满html代码的页面(在您的浏览器中，url应该是view-source:<a class="ae js" href="https://health.usnews.com/best-hospitals/pediatric-rankings/cancer" rel="noopener ugc nofollow" target="_blank">https://health . us news . com/best-hospitals/pediatric-rankings/cancer)</a>。但是我们可以通过搜索排名最靠前的医院:费城儿童医院来快速定位这些数据。而且，数据似乎是放在银盘上，在网页的最后一个<code class="du lu lv lw lx b">script</code>标签中，作为<code class="du lu lv lw lx b">window</code>变量的值提供给我们的。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es ly"><img src="../Images/56fed6ecde6f70f2f6b9f06dd91ee626.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z5yOW5_raB7mJVV-n8RYwA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">包含数据的<script>标签&lt;/root&gt;</script></figcaption></figure><p id="70aa" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在Python中，让我们首先设置导入:</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="b0af" class="md kk hh lx b fi me mf l mg mh">from bs4 import BeautifulSoup<br/>import requests</span><span id="ad8c" class="md kk hh lx b fi mi mf l mg mh">import json<br/>import pandas as pd</span><span id="c052" class="md kk hh lx b fi mi mf l mg mh">import pprint</span></pre><p id="1728" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">然后几行字引发了<code class="du lu lv lw lx b">soup</code>对象</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="7eb2" class="md kk hh lx b fi me mf l mg mh">url = '<a class="ae js" href="https://health.usnews.com/best-hospitals/pediatric-rankings/cancer'" rel="noopener ugc nofollow" target="_blank">https://health.usnews.com/best-hospitals/pediatric-rankings/cancer'</a><br/>prefix = '<a class="ae js" href="https://health.usnews.com/'" rel="noopener ugc nofollow" target="_blank">https://health.usnews.com/'</a><br/>user_agent = {'User-agent' : 'Mozilla/5.0'}</span><span id="1672" class="md kk hh lx b fi mi mf l mg mh">page = requests.get(url, headers=user_agent)<br/>soup = BeautifulSoup(page.text, 'lxml')</span></pre><p id="8626" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">接下来，我们将定位<code class="du lu lv lw lx b">script</code>标签，提取其文本，并使用<code class="du lu lv lw lx b">json</code>的<code class="du lu lv lw lx b">loads</code>将文本读入字典。从那里我们可以很容易地读取数据的结构，我们在这里称之为<code class="du lu lv lw lx b">matches</code>。</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="e5e7" class="md kk hh lx b fi me mf l mg mh">script_tags = [d for ld in soup.find_all('script')]<br/>script_text = script_tags[-1].text<br/>script_data = json.loads(script_text.split("window['__PAGE_CONTEXT_QUERY_STATE__'] = ")[1].rstrip().rstrip(';\n'))</span><span id="246c" class="md kk hh lx b fi mi mf l mg mh">matches = script_data.get('src/containers/pages/health/hospitals/search/index.js').get('data').get('matches')</span></pre><p id="4ccf" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><code class="du lu lv lw lx b">matches</code>是10个字典的列表，其中每个字典包含一家医院的数据(如下所示)。我们将提取<code class="du lu lv lw lx b">name</code>、<code class="du lu lv lw lx b">ranking</code>和<code class="du lu lv lw lx b">scores</code>，并将它们存储在一个数据帧中。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mj"><img src="../Images/30030f860b4236848b5922e27b38c684.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KZJBdUhBrhR5T37yyxlmMA.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">匹配列表的一个元素，其中医院的各种数据点被组织在一个字典中</figcaption></figure><p id="9a40" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将通过编写一个函数来实现</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="0f76" class="md kk hh lx b fi me mf l mg mh">def extract_overall_scores(match):<br/>    name = match.get('name')<br/>    rank = int(match.get('ranking').get('rank'))<br/>    score_specialty = convert_score(match.get('scores')[0].get('score'))<br/>    score_expert = convert_score(match.get('scores')[1].get('score'))<br/>    score_volume = convert_score(match.get('scores')[2].get('score'))<br/>    cols = ['Rank', 'Hospital', 'Specialty Score', 'Expert Opinion', 'Volume Score']<br/>    data = [rank, name, score_specialty, score_expert, score_volume]<br/>    return pd.DataFrame(columns=cols, data=[data])</span></pre><p id="f30d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里，我们使用另一个函数<code class="du lu lv lw lx b">convert_score</code>将string转换成期望的类型，整数、浮点或布尔。我们看到《美国新闻》使用百分比格式(如99%)和分子/分母(如14/15)来计算分数，因此我们逐个编写代码来进行适当的计算。</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="a20a" class="md kk hh lx b fi me mf l mg mh">def convert_score(s):<br/>    if s is None:<br/>        return None<br/>    if type(s) is bool:<br/>        return s<br/>    elif s.endswith('%'):<br/>        return float(s.rstrip('%')) / 100<br/>    elif '/' in s:<br/>        return float(s.split('/')[0]) / float(s.split('/')[1])<br/>    else:<br/>        return float(s)</span></pre><p id="69ad" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">到目前为止，我们可以简单地执行以下操作来获得排名前10的医院的总体得分。</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="38d1" class="md kk hh lx b fi me mf l mg mh">df_score = pd.concat([extract_overall_scores(i) for i in matches]).reset_index(drop=True)</span></pre><h1 id="af21" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated"><strong class="ak">刮取详细记分卡</strong></h1><p id="6fe4" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">我们现在继续刮详细的记分卡。对于每个医院，可以通过列表<code class="du lu lv lw lx b">matches</code>中每个元素的<code class="du lu lv lw lx b">full_score_url</code>中的url找到完整的记分卡。这导致了一个专门针对一家医院的网页，其中的类别，如“结果和经验”和“专业认可”，以及子类别，如“结果和经验”下的“在整个医院预防感染的能力”，不仅有“优秀”和“高于平均水平”等分数，还有数字分数。对于想详细研究和比较这些医院的人来说，这可能会很有趣。</p><p id="8a35" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们只需要将我们之前定义的<code class="du lu lv lw lx b">prefix</code>和这个<code class="du lu lv lw lx b">full_score_url</code>字符串连接起来，就可以得到完整的URL。</p><figure class="ju jv jw jx fd jy er es paragraph-image"><div role="button" tabindex="0" class="jz ka di kb bf kc"><div class="er es mk"><img src="../Images/8aedf1f8215549302e7d7e1b014e533a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dvr8Wq9clraASIni5JXiCw.png"/></div></div><figcaption class="kf kg et er es kh ki bd b be z dx translated">在匹配列表的一个元素中，我们找到了full_scorecard_url</figcaption></figure><p id="bd0d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们再次在其中一个完整的页面上“检查页面源”,发现数据同样以字典的形式放在最后一个<code class="du lu lv lw lx b">script</code>标签中。通过仔细搜索我们想要的数据，我们发现它被深深地埋藏在一串字典中:<code class="du lu lv lw lx b">data</code>-&gt;-<code class="du lu lv lw lx b">context</code>-&gt;-<code class="du lu lv lw lx b">hospital</code>-&gt;-<code class="du lu lv lw lx b">scorecard</code>-&gt;-<code class="du lu lv lw lx b">measure_groups</code>。为了提取数据，我们需要遍历一系列列表，其中每个元素都是一个字典，包含实际的分数。我们编写了一个函数来一步一步地做这件事。为了能够与总分数据帧合并，我们还提取了医院的<code class="du lu lv lw lx b">name</code>,作为合并的关键。</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="26b9" class="md kk hh lx b fi me mf l mg mh">def extract_full_scores(match):<br/>    full_scorecard = match.get('full_scorecard_url')<br/>    page_scorecard = requests.get(prefix+full_scorecard, headers=user_agent)<br/>    soup_scorecard = BeautifulSoup(page_scorecard.text, 'lxml')<br/>    <br/>    script_tags = [d for d in soup_scorecard.find_all('script')]<br/>    script_text = script_tags[-1].text<br/>    script_data = json.loads(script_text.split("window['__PAGE_CONTEXT_QUERY_STATE__'] = ")[1].rstrip().rstrip(';\n'))<br/>    script_data = script_data.get('src/containers/pages/health/hospitals/profile/scorecard/index.js').get('data').get('context')<br/>    name = script_data.get('hospital').get('name')<br/>    script_data1 = script_data.get('hospital').get('scorecard')['measure_groups']<br/>    <br/>    cols = ['Hospital'] + [measure.get('title') for measures in script_data1 for measure in measures.get('measures')]<br/>    data = [name] + [convert_score(measure.get('score').get('value')) for measures in script_data1 for measure in measures.get('measures')]<br/>    return pd.DataFrame(columns=cols, data=[data])</span></pre><h1 id="0348" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">把它放在一起</h1><p id="1c89" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">到目前为止，我们已经构建了提取总体分数和详细分数的部分代码。使用下面的代码行，我们将能够抓取这些分数，并将它们放入一个数据帧中</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="3e33" class="md kk hh lx b fi me mf l mg mh">df_score = pd.concat([extract_overall_scores(i) for i in matches]) \<br/>    .merge(pd.concat([extract_full_scores(i) for i in matches]), on='Hospital') \<br/>    .reset_index(drop=True)</span></pre><h1 id="a626" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">超越前10名</h1><p id="880c" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">如果你回到最初的排名<a class="ae js" href="https://health.usnews.com/best-hospitals/pediatric-rankings/cancer" rel="noopener ugc nofollow" target="_blank">页面</a>，排名中会出现更多的医院，并且只有当你滚动到页面底部时，它们才会出现在网页上。到目前为止，这段代码只找到了前10位。我们要怎么做才能得到剩下的？</p><p id="b7b8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">结果是，您可以通过在url的末尾添加一个参数来访问第二组(第11-20)医院，就像，而不是使用下面的和滚动，</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="dd5d" class="md kk hh lx b fi me mf l mg mh"><a class="ae js" href="https://health.usnews.com/best-hospitals/pediatric-rankings/cancer" rel="noopener ugc nofollow" target="_blank">https://health.usnews.com/best-hospitals/pediatric-rankings/cancer</a></span></pre><p id="7ced" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用以下命令直接访问:</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="fa08" class="md kk hh lx b fi me mf l mg mh"><a class="ae js" href="https://health.usnews.com/best-hospitals/pediatric-rankings/cancer" rel="noopener ugc nofollow" target="_blank">https://health.usnews.com/best-hospitals/pediatric-rankings/cancer</a>?page=2</span></pre><p id="9f9a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">同样的，你用<code class="du lu lv lw lx b">page=3</code>、<code class="du lu lv lw lx b">page=4</code>等等来访问后面/更低的排名。在Python中，除了我们之前使用的参数之外，我们需要做的是给<code class="du lu lv lw lx b">requests.get()</code>的<code class="du lu lv lw lx b">params</code>参数输入一个字典。在上面第二个10家医院的URL示例中，我们将执行以下操作，其余的提取代码保持不变。</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="135b" class="md kk hh lx b fi me mf l mg mh">page = requests.get(url, headers=user_agent, params={'page': 2})</span></pre><p id="d4b3" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，我们可以编写一个函数来指向任何一个<code class="du lu lv lw lx b">page</code>，并将所有的分数收集到一个数据帧中。</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="eca5" class="md kk hh lx b fi me mf l mg mh">def extract_page_data(page):<br/>    page = requests.get(url, headers=user_agent, params={'page': page})<br/>    soup = BeautifulSoup(page.text, 'lxml')<br/>    <br/>    script_tags = [d for d in soup.find_all('script')]<br/>    script_text = script_tags[-1].text<br/>    script_data = json.loads(script_text.split("window['__PAGE_CONTEXT_QUERY_STATE__'] = ")[1].rstrip().rstrip(';\n'))<br/>    <br/>    matches = script_data.get('src/containers/pages/health/hospitals/search/index.js').get('data').get('matches')<br/>    df_score = pd.concat([extract_overall_scores(i) for i in matches]) \<br/>        .merge(pd.concat([extract_full_scores(i) for i in matches]), on='Hospital') \<br/>        .reset_index(drop=True)</span><span id="4745" class="md kk hh lx b fi mi mf l mg mh">return df_score</span></pre><p id="dd12" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">假设我们对排名前50的医院感兴趣。我们可以执行以下操作来获取所有这些数据。</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="4cf3" class="md kk hh lx b fi me mf l mg mh">df_score_all = pd.concat([extract_page_data(page) for page in range(1, 6)]).reset_index(drop=True)</span></pre><h1 id="efc0" class="kj kk hh bd kl km kn ko kp kq kr ks kt in ku io kv iq kw ir kx it ky iu kz la bi translated">数据集</h1><p id="9b5d" class="pw-post-body-paragraph iw ix hh iy b iz lb ii jb jc lc il je jf ld jh ji jj le jl jm jn lf jp jq jr ha bi translated">现在，我们已经构建了代码片段，我们可以将它们放在一起，收集排名前50位的医院的数据，如下所示。</p><pre class="ju jv jw jx fd lz lx ma mb aw mc bi"><span id="6341" class="md kk hh lx b fi me mf l mg mh">#%% Imports<br/>from bs4 import BeautifulSoup<br/>import requests<br/>import json<br/>import pandas as pd</span><span id="2cf5" class="md kk hh lx b fi mi mf l mg mh">#%% Define parameters and extract "matches"</span><span id="4557" class="md kk hh lx b fi mi mf l mg mh">url = '<a class="ae js" href="https://health.usnews.com/best-hospitals/pediatric-rankings/cancer'" rel="noopener ugc nofollow" target="_blank">https://health.usnews.com/best-hospitals/pediatric-rankings/cancer'</a><br/>prefix = '<a class="ae js" href="https://health.usnews.com/'" rel="noopener ugc nofollow" target="_blank">https://health.usnews.com/'</a><br/>user_agent = {'User-agent' : 'Mozilla/5.0'}</span><span id="a68a" class="md kk hh lx b fi mi mf l mg mh">#%% Definition to convert string to score<br/>def convert_score(s):<br/>    if s is None:<br/>        return None<br/>    if type(s) is bool:<br/>        return s<br/>    elif s.endswith('%'):<br/>        return float(s.rstrip('%')) / 100<br/>    elif '/' in s:<br/>        return float(s.split('/')[0]) / float(s.split('/')[1])<br/>    else:<br/>        return float(s)</span><span id="9046" class="md kk hh lx b fi mi mf l mg mh">#%% Definition to extract overall scores<br/>def extract_overall_scores(match):<br/>    name = match.get('name')<br/>    rank = int(match.get('ranking').get('rank'))<br/>    score_specialty = convert_score(match.get('scores')[0].get('score'))<br/>    score_expert = convert_score(match.get('scores')[1].get('score'))<br/>    score_volume = convert_score(match.get('scores')[2].get('score'))<br/>    cols = ['Rank', 'Hospital', 'Specialty Score', 'Expert Opinion', 'Volume Score']<br/>    data = [rank, name, score_specialty, score_expert, score_volume]<br/>    return pd.DataFrame(columns=cols, data=[data])</span><span id="0dbc" class="md kk hh lx b fi mi mf l mg mh">#%% Definition to extract full data<br/>def extract_full_scores(match):<br/>    full_scorecard = match.get('full_scorecard_url')<br/>    page_scorecard = requests.get(prefix+full_scorecard, headers=user_agent)<br/>    soup_scorecard = BeautifulSoup(page_scorecard.text, 'lxml')<br/>    <br/>    script_tags = [d for d in soup_scorecard.find_all('script')]<br/>    script_text = script_tags[-1].text<br/>    script_data = json.loads(script_text.split("window['__PAGE_CONTEXT_QUERY_STATE__'] = ")[1].rstrip().rstrip(';\n'))<br/>    script_data = script_data.get('src/containers/pages/health/hospitals/profile/scorecard/index.js').get('data').get('context')<br/>    name = script_data.get('hospital').get('name')<br/>    script_data1 = script_data.get('hospital').get('scorecard')['measure_groups']<br/>    <br/>    cols = ['Hospital'] + [measure.get('title') for measures in script_data1 for measure in measures.get('measures')]<br/>    data = [name] + [convert_score(measure.get('score').get('value')) for measures in script_data1 for measure in measures.get('measures')]<br/>    return pd.DataFrame(columns=cols, data=[data])</span><span id="6f20" class="md kk hh lx b fi mi mf l mg mh">#%% Definition to extract overall and full scores<br/>def extract_page_data(page):<br/>    page = requests.get(url, headers=user_agent, params={'page': page})<br/>    soup = BeautifulSoup(page.text, 'lxml')<br/>    <br/>    script_tags = [d for d in soup.find_all('script')]<br/>    script_text = script_tags[-1].text<br/>    script_data = json.loads(script_text.split("window['__PAGE_CONTEXT_QUERY_STATE__'] = ")[1].rstrip().rstrip(';\n'))<br/>    <br/>    matches = script_data.get('src/containers/pages/health/hospitals/search/index.js').get('data').get('matches')<br/>    df_score = pd.concat([extract_overall_scores(i) for i in matches]) \<br/>        .merge(pd.concat([extract_full_scores(i) for i in matches]), on='Hospital') \<br/>        .reset_index(drop=True)</span><span id="6124" class="md kk hh lx b fi mi mf l mg mh">return df_score</span><span id="db36" class="md kk hh lx b fi mi mf l mg mh">#%% Extract top 50 hospitals<br/>df_score_all = pd.concat([extract_page_data(page) for page in range(1, 6)]).reset_index(drop=True)</span><span id="9f2b" class="md kk hh lx b fi mi mf l mg mh">#%% Export to a CSV<br/>df_score_all.to_csv('pediatric_cancer_2021.csv', index=False)</span></pre><p id="3186" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后，如果你有兴趣，数据集可以在这里下载<a class="ae js" href="https://drive.google.com/file/d/1tkIcMs1bJLvp9F2Es4h-FMKLp22txcjD/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">。你可以随意摆弄这些数据。</a></p></div></div>    
</body>
</html>