<html>
<head>
<title>Akira’s Machine Learning news — #Week 10, 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Akira的机器学习新闻—2021年第10周</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/akiras-machine-learning-news-week-10-2021-68fb77aab933?source=collection_archive---------14-----------------------#2021-03-16">https://medium.com/analytics-vidhya/akiras-machine-learning-news-week-10-2021-68fb77aab933?source=collection_archive---------14-----------------------#2021-03-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h2 id="8a92" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">本周特稿/新闻。</h2><ul class=""><li id="209c" class="jj jk hh jl b jm jn jo jp iw jq ja jr je js jt ju jv jw jx bi translated"><a class="ae jy" href="https://arxiv.org/abs/2103.01913" rel="noopener ugc nofollow" target="_blank">看起来一个基于维基百科的多语言和图像数据集</a>要发布了。自Vision Transformer推出以来，视觉领域&amp;语言的研究一直在不断发展，如此庞大的数据集的发布可能会进一步加快研发的步伐。</li><li id="b1ca" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ju jv jw jx bi translated"><a class="ae jy" href="https://arxiv.org/abs/2103.01988" rel="noopener ugc nofollow" target="_blank"> <em class="ke">从Instagram上收集的十亿级无标签数据集上的自我监督学习研究出现了</em> </a>。由此产生的表示采集网络已被证实在ImageNet中是有用的。个人认为Instagram偏向于风景、人物、动物等。，但我很好奇这些对于不同领域的效果如何，比如工业数据。</li><li id="5885" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ju jv jw jx bi translated">Pytorch 现在提供了支持GPU和自动微分的快速傅立叶变换，<a class="ae jy" rel="noopener" href="/pytorch/pytorch-lightning-v1-2-0-43a032ade82b"> Pytroch Lightning还能够利用量化、修剪和深度速度</a>，因此Pytorch部队可能会继续大步前进。</li></ul><h2 id="d4c8" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">机器学习用例</h2><ul class=""><li id="b164" class="jj jk hh jl b jm jn jo jp iw jq ja jr je js jt ju jv jw jx bi translated"><a class="ae jy" href="https://www.nytimes.com/2021/02/11/style/disabled-fashion-facebook-discrimination.html" rel="noopener ugc nofollow" target="_blank">脸书误判不当广告的故事</a>显示了机器学习完全自动化的危险。现阶段的机器学习模型还不具备人类的认知能力，所以我认为它们在一段时间内需要适当的人类支持。</li><li id="e7a8" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ju jv jw jx bi translated"><a class="ae jy" href="https://techhq.com/2021/02/ai-and-iot-5-use-cases-where-its-gathering-pace/" rel="noopener ugc nofollow" target="_blank">物联网和AI可以结合起来，让很多事情自动化</a>。随着机器学习的快速发展和5G的广泛使用，我们可能会来到一个结合物联网和人工智能的全自动化和优化系统将成为常态的社会。</li><li id="0576" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ju jv jw jx bi translated">我觉得自动驾驶系统对攻击的<a class="ae jy" href="https://venturebeat.com/2021/02/22/eu-report-warns-that-ai-makes-autonomous-vehicles-highly-vulnerable-to-attack/" rel="noopener ugc nofollow" target="_blank">脆弱性</a>是一个主要问题。就汽车而言，被攻击与人的死亡直接相关，因此在自动驾驶变得普遍之前，对策将是必要的。</li></ul><h2 id="635d" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">报纸</h2><ul class=""><li id="e4d4" class="jj jk hh jl b jm jn jo jp iw jq ja jr je js jt ju jv jw jx bi translated">本周我们有一些关于变压器的论文。首先有一个<a class="ae jy" href="https://arxiv.org/abs/2103.03206" rel="noopener ugc nofollow" target="_blank">研究一个可以处理高维数据的Transformer模型用于多模态数据</a>。transformer模型很容易将不同类型的数据关联起来，因此可以用于多模态数据。如果能处理高维数据就更有用了。此外，在《变形金刚》中，人们倾向于关注自我注意机制，但有<a class="ae jy" href="https://arxiv.org/abs/2103.03404" rel="noopener ugc nofollow" target="_blank">研究显示，跳过结和MLPs扮演着重要角色</a>。许多应用实例的出现可能会推动变压器的理论分析。</li><li id="a348" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ju jv jw jx bi translated">有两篇关于提高GAN效率的论文:<a class="ae jy" href="https://arxiv.org/abs/2103.00397" rel="noopener ugc nofollow" target="_blank">一篇关于使用瘦身后的GAN用少量数据生成高质量数据</a>，另一篇关于通过同时更新生成器和鉴别器来提高学习速度。gan需要大量的数据，并且网络往往很大，因此研究如何提高现实世界应用的效率是非常受欢迎的。</li></ul><p id="b0dc" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi">— — — — — — — — — — — — — — — — — — –</p><p id="4c78" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated">在下面的章节中，我将介绍各种文章和论文，不仅仅是关于上述内容，还包括以下五个主题。</p><ol class=""><li id="d975" class="jj jk hh jl b jm kh jo kk iw kw ja kx je ky jt kz jv jw jx bi translated">本周特稿/新闻</li><li id="a423" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt kz jv jw jx bi translated">机器学习用例</li><li id="8c45" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt kz jv jw jx bi translated">报纸</li><li id="38f6" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt kz jv jw jx bi translated">机器学习技术相关文章</li><li id="4294" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt kz jv jw jx bi translated">其他主题</li></ol><p id="999b" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="e4e3" class="la im hh bd in lb lc ld ir le lf lg iv lh li lj iz lk ll lm jd ln lo lp jh lq bi translated">1.本周特稿/新闻</h1><p id="a4ef" class="pw-post-body-paragraph kf kg hh jl b jm jn ki kj jo jp kl km iw lr ko kp ja ls kr ks je lt ku kv jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2103.01913?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">多语种的大型数据集和图像</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2103.01913" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es lu"><img src="../Images/95165d362f8a9f68a07c069338f01ef2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wMDR5-V9W469ccxwi4rinw.png"/></div></div></figure><p id="789a" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【2103.01913】WIT:基于维基百科的多模态多语言机器学习图像文本数据集</em> <br/>提出了基于维基百科的多语种和图像数据集WIT。它是目前最大的多模态数据集，包含108种语言的总共3760万个实体和1150万个图像。该数据集将于3月20日发布。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="1cf5" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2103.01988?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">用从互联网上收集的十亿张图片进行自我监督学习。</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2103.01988" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es mg"><img src="../Images/35c65284600576a30818c994cb731c6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jokFOtx74jR2pHemPX6dUg.png"/></div></div></figure><p id="82d6" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【2103.01988】野外视觉特征的自我监督预训练</em> <br/>他们提出了SEER，一种对从互联网上收集的十亿级数据进行自我监督表示学习的方法。结果优于现有的方法，表明即使使用真实数据，表征学习也是有效的。他们将SwAV用于自我监督方法，将RegNet用于网络。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="56ae" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><a class="ae jy" href="https://pytorch.org/blog/the-torch.fft-module-accelerated-fast-fourier-transforms-with-autograd-in-pyTorch/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">快速傅立叶变换现已在Pytorch v1.8中可用</strong> </a></p><div class="mh mi ez fb mj mk"><a href="https://pytorch.org/blog/the-torch.fft-module-accelerated-fast-fourier-transforms-with-autograd-in-pyTorch/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">PyTorch</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">快速傅立叶变换(FFT)计算离散傅立叶变换…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">pytorch.org</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my me mk"/></div></div></a></div><p id="3d5b" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【原标题:The torch.fft模块:PyTorch | PyTorch中带亲笔签名的加速快速傅立叶变换】</em> <br/> Pytorch v1.8增加了对快速傅立叶变换的支持。它支持GPU和自动微分。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="40b5" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="cb3b" class="la im hh bd in lb lc ld ir le lf lg iv lh li lj iz lk ll lm jd ln lo lp jh lq bi translated">2.机器学习用例</h1><p id="4c5f" class="pw-post-body-paragraph kf kg hh jl b jm jn ki kj jo jp kl km iw lr ko kp ja ls kr ks je lt ku kv jt ha bi translated"><a class="ae jy" href="https://wayve.ai/blog/driving-intelligence-with-end-to-end-deep-learning/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">具备端到端学习的自动驾驶</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://wayve.ai/blog/driving-intelligence-with-end-to-end-deep-learning/" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">way ve . ai</strong></a></p><div class="mh mi ez fb mj mk"><a href="https://wayve.ai/blog/driving-intelligence-with-end-to-end-deep-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">我们驾驶智能的新兴行为与端到端深度学习| Wayve</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">这段视频显示了我们在伦敦国王十字车站总部附近的一个十字路口完成了一次无保护的右转。这个…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">wayve.ai</p></div></div><div class="mt l"><div class="mz l mv mw mx mt my me mk"/></div></div></a></div><p id="dd23" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【原标题:我们的驾驶智能与端到端深度学习的新兴行为| Wayve】</em><br/>Wayve正在使用端到端学习进行自动驾驶。这种方法的优点包括降低学习成本和保持中间输出的丰富高维特征的能力，并且它使用端到端的强化学习和模仿学习来学习从摄像机、位置信息和汽车的状态来操作汽车。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="abcc" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><a class="ae jy" href="https://www.forbes.com/sites/robtoews/2021/02/28/a-wave-of-billion-dollar-computer-vision-startups-is-coming/?sh=69bbffe13f4c&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">基于计算机视觉技术的创业公司</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://www.forbes.com/sites/robtoews/2021/02/28/a-wave-of-billion-dollar-computer-vision-startups-is-coming/?sh=69bbffe13f4c" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">www.forbes.com</strong></a></p><div class="mh mi ez fb mj mk"><a href="https://www.forbes.com/sites/robtoews/2021/02/28/a-wave-of-billion-dollar-computer-vision-startups-is-coming" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">一波十亿美元的计算机视觉初创公司正在到来</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">计算机视觉是现代人工智能中技术最成熟的领域。这就要翻译了…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">www.forbes.com</p></div></div><div class="mt l"><div class="na l mv mw mx mt my me mk"/></div></div></a></div><p id="4926" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【原标题:一波十亿美元计算机视觉创业公司来了】</em> <br/>本文介绍一家专注于计算机视觉技术机器学习方法的创业公司。例如，它介绍了使用无人机自动施用有机肥、农业中的疾病检测、零售业中的无收银员购物以及保险业中的自动损害评估。</p><p id="e848" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><a class="ae jy" href="https://aws.amazon.com/lookout-for-vision/?nc1=h_ls&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">亚马逊推出制造业异常检测服务</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://aws.amazon.com/lookout-for-vision/?nc1=h_ls" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">aws.amazon.com</strong></a></p><div class="mh mi ez fb mj mk"><a href="https://aws.amazon.com/lookout-for-vision/?nc1=h_ls&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">亚马逊视觉了望台</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">使用计算机视觉检测产品缺陷以实现质量检测自动化亚马逊视觉了望台是一台机器…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">aws.amazon.com</p></div></div><div class="mt l"><div class="nb l mv mw mx mt my me mk"/></div></div></a></div><p id="e7a3" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【原标题:亚马逊瞭望视觉】</em> <br/>亚马逊在AWS上为制造业推出了一项服务，可以从大约30张图像中进行学习，并检测产品中的凹痕和裂缝等缺陷。这项服务有一个按小时收费的收费结构。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="b160" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="7c31" class="la im hh bd in lb lc ld ir le lf lg iv lh li lj iz lk ll lm jd ln lo lp jh lq bi translated">3.报纸</h1><p id="5344" class="pw-post-body-paragraph kf kg hh jl b jm jn ki kj jo jp kl km iw lr ko kp ja ls kr ks je lt ku kv jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2103.00430v2?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">甘那更新G/D同时进行</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2103.00430v2" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a></p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es nc"><img src="../Images/d5d52e6ec8c32b66c80c773808617f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W2-PQ0nFz9YPwf1uFUmk-w.png"/></div></div></figure><p id="9915" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【2103.00430 v2】一阶段训练生成对抗网络</em> <br/> GANs通常是一边固定一边单独更新D/G，但是他们提出了一种不固定一边一次更新D/G的方法。所提出的方法可以应用于许多现有的GANs，并且可以将学习过程加速1.5倍，而不损害准确性。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="9568" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2103.03230?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">可以处理音频、视频、点云的变形金刚模型，可以处理超过10万个特征的高维输入</strong> </a></p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es nd"><img src="../Images/f3a5ccee2778410de3f40d893dab5122.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CjWBqX8JcF0fbNRSBSGGEQ.png"/></div></div></figure><p id="1dba" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【2103.03230】Barlow Twins:通过冗余减少的自我监督学习</em> <br/>在基于图像的自我监督表示学习中使用相关矩阵的研究。为了消除表示中的冗余，训练网络，使得从具有不同数据扩充的两幅图像获得的特征的相关矩阵成为同一性。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="8f7c" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2103.03404?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">跳过连接和MLP在变压器中起很大作用</strong> </a></p><figure class="lv lw lx ly fd lz er es paragraph-image"><div class="ab fe cl ne"><img src="../Images/3674e7506adb29f98ad16e41364823c7.png" data-original-src="https://miro.medium.com/v2/0*0SWNMavNtgDnXom8"/></div></figure><p id="27a1" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated">注意力并不是你所需要的全部:纯粹的注意力随着深度成倍地下降。他们从理论和实验上表明，当自我注意机制不伴随跳跃连接或MLPs时，它更有可能收敛到秩1矩阵，并且它们在变压器的学习中起着重要作用。虽然论文的标题很有煽动性，“注意力不是你需要的全部”，但这并不意味着他们在否认变形金刚的有效性。相反，这项研究的动机始于这样一个问题，“它为什么有效？</p><p id="3441" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2103.00397?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">用变细的GAN和少量数据生成高质量图像</strong> </a></p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es nf"><img src="../Images/b4dd734d14fda0a50af79aa242eec05f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B7yzo6ExWjCCw7CsEl8HsA.png"/></div></div></figure><p id="8dc3" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【2103.00397】超数据高效的GAN训练:先抽一张彩票，再对其进行强硬训练</em> <br/>利用GAN生成高质量小数据量图像的研究。他们使用基于彩票假设的瘦网络和强大的数据增强，如GANs的对抗性学习。采用彩票假设的精简网络往往在数据较少的情况下表现更好，仅用CIFAR10的10%就实现了FID 14.38。据diff aug(<a class="ae jy" href="https://arxiv.org/abs/2006.10738" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2006.10738</a>)报道，精简后的网络往往表现更好，这可能是因为当模型很大但数据很少时，有过度拟合的趋势。</p><p id="4297" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2103.03230?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2103.03230" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es ng"><img src="../Images/75ab5dcddb34f7bbd83c357aed9dcc53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cJpLUSGm7tWBUgYoKAC9mg.png"/></div></div></figure><p id="96e8" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【2103.03230】Barlow Twins:通过冗余减少的自我监督学习</em> <br/>在基于图像的自我监督表示学习中使用相关矩阵的研究。为了消除表示中的冗余，训练网络，使得从具有不同数据扩充的两幅图像获得的特征的相关矩阵成为同一性。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="3b5d" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2101.05022?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">将单个标签转换为带有位置信息的多个标签</strong> </a></p><figure class="lv lw lx ly fd lz er es paragraph-image"><div role="button" tabindex="0" class="ma mb di mc bf md"><div class="er es nh"><img src="../Images/12ae50f97553605d03b532a1129f5069.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zd-hMkZQgJXn6PGVinCkhw.png"/></div></div></figure><p id="df7b" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【2101.05022】重新标记ImageNet:从单标签到多标签，从全局标签到本地化标签</em> <br/>他们提出了重新标记，一种将单标签转换为位置信息多标签的策略。通过将最终的FC层应用于在不同数据集上训练的强大分类器的预间隙Conv层中的每个像素，单个标签被转换为多个位置信息标签。他们证实了它在图像识别和物体检测方面的有效性。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="47d6" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="3985" class="la im hh bd in lb lc ld ir le lf lg iv lh li lj iz lk ll lm jd ln lo lp jh lq bi translated">4.机器学习技术相关文章</h1><p id="cb40" class="pw-post-body-paragraph kf kg hh jl b jm jn ki kj jo jp kl km iw lr ko kp ja ls kr ks je lt ku kv jt ha bi translated"><a class="ae jy" href="https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa?gi=aeefd3d2cf4f&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener" target="_blank"> <strong class="jl hi">机器学习中使用的距离度量的概述、使用示例和缺点</strong> </a></p><div class="mh mi ez fb mj mk"><a href="https://towardsdatascience.com/9-distance-measures-in-data-science-918109d069fa" rel="noopener follow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">数据科学中的9种距离度量</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">常见距离测量的优点和缺陷</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">towardsdatascience.com</p></div></div><div class="mt l"><div class="ni l mv mw mx mt my me mk"/></div></div></a></div><p id="d35a" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【原标题:数据科学中的9种距离度量|走向数据科学】</em> <br/>一篇解释机器学习中使用的距离度量的文章。很好理解，有图有解释。不仅如此，还提到了它们在什么样的场合下使用，使用这些距离会产生什么问题。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="d020" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><a class="ae jy" href="https://huggingface.co/blog/simple-considerations?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">使用深度学习做机器学习项目时要检查的事情</strong> </a></p><div class="mh mi ez fb mj mk"><a href="https://huggingface.co/blog/simple-considerations" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">简单的人构建奇特的神经网络的简单考虑</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">随着机器学习不断渗透到行业的方方面面，神经网络也从未如此炒作过。对于…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">huggingface.co</p></div></div><div class="mt l"><div class="nj l mv mw mx mt my me mk"/></div></div></a></div><p id="8c44" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated">【<em class="ke">原标题:🚧简单的人建立花哨的神经网络的简单考虑] </em> <br/>这篇文章描述了当使用深度学习模型做机器学习项目时，你应该首先做什么。它谈到仔细查看数据，从简单的模型开始而不是构建复杂的模型，并通过使用小模型来检查错误。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="1d55" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="ae86" class="la im hh bd in lb lc ld ir le lf lg iv lh li lj iz lk ll lm jd ln lo lp jh lq bi translated">5.其他主题</h1><p id="5f9d" class="pw-post-body-paragraph kf kg hh jl b jm jn ki kj jo jp kl km iw lr ko kp ja ls kr ks je lt ku kv jt ha bi translated"><a class="ae jy" rel="noopener" href="/pytorch/pytorch-lightning-v1-2-0-43a032ade82b?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter"> <strong class="jl hi"> Pytorch Lightning v1.2发布</strong> </a></p><div class="mh mi ez fb mj mk"><a rel="noopener follow" target="_blank" href="/pytorch/pytorch-lightning-v1-2-0-43a032ade82b"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">PyTorch Lightning V1.2.0-深度速度，修剪，量化，SWA</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">包括与DeepSpeed、PyTorch profiler、修剪、量化、SWA、PyTorch Geometric等的新集成。</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">medium.com</p></div></div><div class="mt l"><div class="nk l mv mw mx mt my me mk"/></div></div></a></div><p id="cb78" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated"><em class="ke">【原标题:py torch Lightning v 1 . 2 . 0-deep speed、剪枝、量化、SWA】</em><br/>py torch Lightning v 1.2已经发布。它支持量化、修剪和使用DeepSpeed库来加速学习。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="e280" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="552b" class="la im hh bd in lb lc ld ir le lf lg iv lh li lj iz lk ll lm jd ln lo lp jh lq bi translated">过去的时事通讯</h1><div class="mh mi ez fb mj mk"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-machine-learning-news-week-9-2021-437385" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">Akira的机器学习新闻-# 2021年第9周</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">本周特稿/新闻。研究表明，变压器的改进方法是可行的</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">www.getrevue.co</p></div></div><div class="mt l"><div class="nl l mv mw mx mt my me mk"/></div></div></a></div><div class="mh mi ez fb mj mk"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-machine-learning-news-february-2021-419853" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">Akira的机器学习新闻-2021年2月</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">2020年2月特稿/新闻。机器学习用例物联网和人工智能可以结合起来自动化很多事情…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">www.getrevue.co</p></div></div><div class="mt l"><div class="nm l mv mw mx mt my me mk"/></div></div></a></div><div class="mh mi ez fb mj mk"><a href="https://towardsdatascience.com/machine-learning-2020-summary-84-interesting-papers-articles-45bd45c0d35b" rel="noopener follow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hi fi z dy mp ea eb mq ed ef hg bi translated">机器学习2020摘要:84篇有趣的论文/文章</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">在这篇文章中，我总共展示了2020年发表的84篇我觉得特别有趣的论文和文章…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">towardsdatascience.com</p></div></div><div class="mt l"><div class="nn l mv mw mx mt my me mk"/></div></div></a></div><h1 id="0bca" class="la im hh bd in lb lc ld ir le lf lg iv lh li lj iz lk ll lm jd ln lo lp jh lq bi translated">关于我</h1><p id="4b60" class="pw-post-body-paragraph kf kg hh jl b jm jn ki kj jo jp kl km iw lr ko kp ja ls kr ks je lt ku kv jt ha bi translated">制造工程师/机器学习工程师/数据科学家/物理学硕士/exa wizards/<a class="ae jy" href="https://t.co/hjHHbG24Ph?amp=1" rel="noopener ugc nofollow" target="_blank">http://github.com/AkiraTOSEI/</a></p><p id="102b" class="pw-post-body-paragraph kf kg hh jl b jm kh ki kj jo kk kl km iw kn ko kp ja kq kr ks je kt ku kv jt ha bi translated">推特，我贴一句纸评论。</p></div></div>    
</body>
</html>