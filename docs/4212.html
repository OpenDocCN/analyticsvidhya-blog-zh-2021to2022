<html>
<head>
<title>LIME : The zest of Explainable AI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">石灰:可解释人工智能的热情</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/lime-the-zest-of-explainable-ai-19ccb70b2488?source=collection_archive---------10-----------------------#2021-09-08">https://medium.com/analytics-vidhya/lime-the-zest-of-explainable-ai-19ccb70b2488?source=collection_archive---------10-----------------------#2021-09-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="a187" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">嗨，读者们，</p><p id="de24" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">《神探夏洛克·福尔摩斯》中臭名昭著的反派角色莫里亚蒂有许多邪恶的阴谋。但是我们抽烟斗，戴猎鹿帽，超级侦探(是的，我是康伯巴奇的粉丝！)夏洛克·福尔摩斯能够看穿犯罪策划者的谎言，并确定这种疯狂行为的因果关系。</p><p id="24e8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果要我做比较，莫里亚蒂将是人工智能模型，而夏洛克将是试图找出模型行为中“为什么”的莱姆。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/ad5bd597eff1621fac79cf841a56a1da.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*YSgM8eubSG9ZEuFThBYyng.jpeg"/></div></figure><h1 id="31b7" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">问题的案例文件</h1><p id="aff7" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">神经网络和机器学习算法通常是黑盒。术语“黑盒”是指使用未知的内部机制获得已知输出的过程。通常情况下，我们不知道决策是如何或为什么做出的，我们只知道结果。这么多未知，怎么能相信一个模型呢？</p><p id="0377" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如只有钻石才能切割钻石一样，在经历了多次失败之后，这个数学之谜被交给了我们自己的数学侦探supreme。</p><h1 id="25de" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">莱姆:我们侦探的性格素描</h1><p id="effc" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">LIME代表本地可解释的模型竞争解释。这是可解释人工智能(XAI)概念的琼浆玉液。当从自下而上的方法阅读时，这个缩写词是非常自明的。</p><p id="700a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">模型竞争</strong>意味着某些东西绕过了模型的建筑构成。术语<strong class="ig hi">可解释的</strong>意味着石灰将产生易于人类理解的结果。<strong class="ig hi"> Local </strong>补充道，该模型将通过近似的本地解释来解释。这是通过改变特征来修改单个数据点，然后测量这种改变带来的影响来实现的。</p><p id="bdfe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">局部解释可以是诸如决策树、线性回归或任何其他的模型，其在局部模型的小扰动(诸如添加噪声、删除单词、像素化图像的一部分的变化)之后被训练，然后测量这种变化的影响。</p><h1 id="a247" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">滚动摄像机动作:将石灰应用于股票情绪数据</h1><p id="dce3" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">股票情绪的数据集可以从这个<a class="ae kn" href="https://www.kaggle.com/yash612/stockmarket-sentiment-dataset" rel="noopener ugc nofollow" target="_blank">链接</a>下载。数据集包含字符串格式的情感，以及与之相关联的情感(1表示积极，-1表示消极)。</p><p id="3b9f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据集的快照:</p><ul class=""><li id="bfd6" class="ko kp hh ig b ih ii il im ip kq it kr ix ks jb kt ku kv kw bi translated">正面情绪(1):“用户:AAP电影。FEA/GEED指标的回报率为55%,全年仅交易15笔。厉害了。”</li><li id="e22a" class="ko kp hh ig b ih kx il ky ip kz it la ix lb jb kt ku kv kw bi translated">负面情绪(-1):“AAP——用户如果是这样，那么当前的下降趋势将被打破。否则，这只是中期下跌趋势中的一次短期修正。”</li></ul><h2 id="1b23" class="lc jl hh bd jm ld le lf jq lg lh li ju ip lj lk jy it ll lm kc ix ln lo kg lp bi translated">步骤1:导入库</h2><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lq lr l"/></div></figure><h2 id="2d7e" class="lc jl hh bd jm ld le lf jq lg lh li ju ip lj lk jy it ll lm kc ix ln lo kg lp bi translated">第二步:预处理</h2><p id="8cca" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">在这一步中，我们将导入数据集，然后将其分成训练和测试数据帧，之后我们将使用tf-idf对它们进行矢量化。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lq lr l"/></div></figure><p id="6e27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Tf-idf返回大小为(字数*输入句子数)的向量。</p><p id="85eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，每个输入都是一个大小向量(数据集中的字数*1)。由于存在多个要素，因此分析这些要素中的哪一个对输出的贡献最大非常重要。让我们使用这些特性构建一个简单的分类器——逻辑回归分类器。</p><h2 id="a972" class="lc jl hh bd jm ld le lf jq lg lh li ju ip lj lk jy it ll lm kc ix ln lo kg lp bi translated">步骤3:构建模型</h2><p id="2549" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">我们使用tf-idf向量作为模型的输入特征。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lq lr l"/></div></figure><p id="1b68" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该模型的f1分数为:</p><pre class="jd je jf jg fd ls lt lu lv aw lw bi"><span id="f7fb" class="lc jl hh lt b fi lx ly l lz ma">0.8517110266159695</span></pre><h2 id="c2db" class="lc jl hh bd jm ld le lf jq lg lh li ju ip lj lk jy it ll lm kc ix ln lo kg lp bi translated">第四步:添加石灰</h2><p id="75ae" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">现在我们加入石灰来理解模型。我们将使用LimeTextExplainer为可解释性生成局部预测。该函数将需要解释的问题、从黑盒模型(逻辑回归)生成的问题的预测标签以及用于解释的特征数量作为输入参数。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lq lr l"/></div></figure><p id="12b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该代码会产生以下结果</p><pre class="jd je jf jg fd ls lt lu lv aw lw bi"><span id="bf60" class="lc jl hh lt b fi lx ly l lz ma">Text: <br/>Check out list of top performers since AAP peak, from user - Dogs like FS DE? +80% in NFX? Please.  <br/>Probability (Positve) = 0.7287929697067268<br/>Probability (Negative) = 0.2712070302932732<br/>True Class is: negative</span></pre><p id="ec5a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果可以用不同类型的可视化显示出来。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lq lr l"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mb"><img src="../Images/667e6c9c1fd1b80cf2dff4c667c4cb98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YYV8cGS_SsVfqCr1-oi6pA.png"/></div></div></figure><p id="9705" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该图像显示了主要特征对积极和消极结果的贡献。因此，特征“AAP”量化积极的结果，而像“FS”这样的特征量化消极的结果。</p><h1 id="edcf" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">摘要</h1><p id="7e4c" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">这篇文章的主旨是石灰可以用来解释任何使用局部近似的模型。可解释的部分是要更加注意，这是人的组成部分。通过改变数据点测试多个案例，然后得出结论。</p><p id="8f19" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，这句话非常适合这种情况:</p><blockquote class="mg mh mi"><p id="28ab" class="ie if mj ig b ih ii ij ik il im in io mk iq ir is ml iu iv iw mm iy iz ja jb ha bi translated">乱不是坑，乱是梯。</p></blockquote><p id="f133" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">编码快乐！！！</p></div></div>    
</body>
</html>