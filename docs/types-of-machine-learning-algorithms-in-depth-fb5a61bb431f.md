# 机器学习算法的类型(ELI5)

> 原文：<https://medium.com/analytics-vidhya/types-of-machine-learning-algorithms-in-depth-fb5a61bb431f?source=collection_archive---------14----------------------->

在我之前的文章中，我已经解释了人工智能是如何在后台工作的。所以在开始之前请核实一下。

*注意:这不是一本关于算法的学术教科书/数学解释。这是为那些想了解这个*的人准备的

> **类型:**

1.  监督学习
2.  无监督学习
3.  强化学习

> **监督学习:**

顾名思义，监督学习涉及在监督人在场的情况下学习的机器学习算法。

这类似于师生场景。有一位老师指导学生从书本和其他材料中学习。然后对学生进行测试，如果正确，学生通过。否则，老师会调教学生，让学生从他或她过去犯的错误中学习。以完全相同的方式，你让机器通过使用算法来学习，并给出必要的反馈和微调，以获得更大的准确性。

**例子**

假设你有一个侄女，刚满 2 岁，正在学说话。你想教她什么是狗和猫。那你是做什么的？你要么给她看狗和猫的视频，要么带一只狗和一只猫在现实生活中给她看，这样她就能明白它们有什么不同。

现在你告诉她一些事情，让她明白这两种动物之间的不同。

*   狗和猫都有四条腿和一条尾巴。
*   狗有大小不同的种类。另一方面，猫总是很小。
*   狗的嘴巴长，而猫的嘴巴小。
*   狗叫，猫喵。
*   不同的狗有不同的耳朵，而猫有几乎相同的耳朵。

现在你带你的侄女回家，给她看不同的狗和猫的照片。如果她能够区分狗和猫，你就成功地教会了她。

这里发生了什么？你在那里引导她达到区分狗和猫的目标。你教会了她猫和狗的所有区别。然后你测试她是否能够学习。如果她能学会，她就把狗叫成狗，把猫叫成猫。如果没有，你教她更多，并且能够教她。你充当了监督者，你的侄女充当了必须学习的算法。你甚至知道什么是狗，什么是猫。确保她学的是正确的东西。这就是监督学习遵循的原则。

作为一名数据科学家，从技术角度来说，你给了人工智能一组特殊的数据，其中包含关于猫和狗的特征。你还可以给出关于它是猫还是狗的答案，并要求机器通过应用特定的监督学习算法来学习它。机器学习，你检查机器是否能够通过给出不包含答案的数据来正确预测。听起来很简单，对吗？…

它包括各种算法，如线性回归、逻辑回归、支持向量机等

> **无监督学习:**

你的侄女长大了，今天是她 6 岁生日，她邀请了她的朋友来参加生日聚会。所以为了让这个活动更特别，她计划给她的朋友一个小盒子，里面装着一块不同类型的巧克力。所以你给她买了一大盒巧克力，里面有各种不同的巧克力。普通的，牛奶巧克力，坚果巧克力，黑巧克力等等。

所以，作为一个 6 岁的孩子，还没有完全理解不同类型的巧克力，我可以说她的大脑仍然能够区分不同类型的巧克力。最终，她将能够仅仅通过看一眼就认出一块巧克力，并且能够很容易地说出它是什么牌子，里面是否有坚果或焦糖。然后，她可以很容易地将它们分类，给她的朋友一个所有类型的组合。

在无监督学习中，输出将不会是诸如辨别它是一只猫还是一只狗之类的东西。这里更多的是通过寻找更多的模式来对数据或类别进行分组。无监督学习的目标是发现数据点之间的相似性和差异性。

现在，如果你看到了我们到目前为止所看到的两种类型之间的区别，被监管的总是有一个监管人/老师在开始时教某人，而这里不是这样。没有主管你也能得到数据。所以在这里你不会给机器关于巧克力的信息或答案。它只是学会自己对它们进行分类。

它包括各种算法，如聚类、KNN 和 Apriori 算法。

> **强化学习:**

假设你某天早上醒来，你在一个完全陌生的世界，在那里你不懂规则。你环顾四周，然后迈出一步，什么也没发生。你不知道这样做是否有帮助。然后你环顾四周，再走一步。还是什么都没发生。在这种环境下，你怎么能指望学会如何做人呢？

但是你又向前迈了一步，跳起来从树上摘了一个果子吃了。好吃！看到你刚刚看到的，并采取特定的行动，你得到了这个奖励。所以你把这种情况/行为与积极的价值观联系起来。所以，如果你再次遇到这种情况，你要学会再次做同样的动作。太好了。

然而，你在之前采取的*步骤让你进入了导致奖励的情况，所以这也值得一些赞扬。没那么多，但还是很多。你在之前的情况下采取的措施，也值得一点赞扬，同样，不太值得。*

惩罚也是如此，比如撞墙，流鼻血。你采取的直接导致惩罚的行动应该被认为是非常消极的。你在那之前采取的步骤也应该被劝阻很多，但不要太多。

因此，实际上，当你在特定的情况下采取随机的行动，而没有立即被告知是好是坏时，当最终给予惩罚或奖励时，你可以追溯性地将反馈应用到特定情况下采取的行动的记忆链中。

例如，如果你玩游戏 GTA，我们可以看到除了我们之外的许多人不受干扰地在环境中移动，驾驶汽车等。他们实际上并没有被编程，而是强化学习代理，他们已经掌握了如何通过一个特定的环境

渐渐地，你知道某些行为是更可取的，即使它们不会直接带来回报。当你学下棋时，也发生了同样的事情。开始时，你做了一个随机的移动，根据移动后发生的事情，你知道这是一个好的还是一个坏的移动。最终，先前棋步的记忆堆栈和反馈帮助你做出更好的决定。

同样的，如果你在玩了数千场比赛和数百万步棋后，在某个时候使用一台人工智能(机器),它将有能力击败世界冠军。

它包括各种算法，如马尔可夫决策过程、Q 学习等。

这些是不同类型的机器学习算法的细节。在下一篇文章中，我将采用上述任何一种算法，并进一步详细解释。如果你喜欢这篇文章，请随时关注我。