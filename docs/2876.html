<html>
<head>
<title>UNET Implementation in PyTorch — Idiot Developer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch中的UNET实现——白痴开发者</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/unet-implementation-in-pytorch-idiot-developer-da40d955f201?source=collection_archive---------1-----------------------#2021-05-22">https://medium.com/analytics-vidhya/unet-implementation-in-pytorch-idiot-developer-da40d955f201?source=collection_archive---------1-----------------------#2021-05-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f66c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本教程重点介绍PyTorch框架中名为<strong class="ih hj"> UNET </strong>的图像分割架构的实现。这是一个简单的编码器-解码器架构，由Olaf Ronneberger等人于2015年在德国弗莱堡大学开发，用于生物医学图像分割。</p><blockquote class="jd je jf"><p id="8297" class="if ig jg ih b ii ij ik il im in io ip jh ir is it ji iv iw ix jj iz ja jb jc hb bi translated"><strong class="ih hj">获取代码</strong>:<a class="ae jk" href="https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture/blob/main/PyTorch/unet.py" rel="noopener ugc nofollow" target="_blank">https://github . com/nikhilroxtomar/Semantic-Segmentation-Architecture/blob/main/py torch/unet . py</a></p></blockquote><figure class="jl jm jn jo fd jp"><div class="bz dy l di"><div class="jq jr l"/></div></figure><h1 id="d8a6" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">什么是图像分割？</h1><p id="bb1a" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">一幅图像由多个物体组成，比如人、汽车、动物或任何其他物体。为了对图像进行分类，我们使用图像分类，其中任务是预测输入图像的标签或类别。现在想象一下，我们需要找到对象的确切位置，即哪个像素属于哪个对象。在这种情况下，我们需要像素级分类，也就是说，我们需要分割图像。</p><p id="8cd7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，图像分割是网络将图像作为输入并输出逐像素掩码的过程。这有助于在像素级别更好地理解图像中的场景。图像分割广泛应用于医学成像、自主车辆、卫星成像等等。</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="9fa3" class="js jt hi bd ju jv lc jx jy jz ld kb kc kd le kf kg kh lf kj kk kl lg kn ko kp bi translated">UNET —网络架构</h1><p id="41b1" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">UNET是一种U形编码器-解码器网络架构，它由四个编码器模块和四个解码器模块组成，通过一个桥连接。编码器网络(收缩路径)将空间维度减半，并将每个编码器块的滤波器(特征通道)数量加倍。同样，解码器网络使空间维度加倍，特征通道的数量减半。</p><figure class="jl jm jn jo fd jp er es paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="er es lh"><img src="../Images/1fd00c6760631addffc2a2b42a952cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*abDsxLhaamho0Naq.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated">摘自原始论文的UNET架构框图。</figcaption></figure><p id="b531" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">阅读更多:<a class="ae jk" href="https://idiotdeveloper.com/what-is-unet/" rel="noopener ugc nofollow" target="_blank">什么是UNET？</a></p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="01f3" class="js jt hi bd ju jv lc jx jy jz ld kb kc kd le kf kg kh lf kj kk kl lg kn ko kp bi translated">进口火炬</h1><pre class="jl jm jn jo fd ls lt lu lv aw lw bi"><span id="202f" class="lx jt hi lt b fi ly lz l ma mb">import torch import <br/>torch.nn as nn</span></pre><h1 id="86d8" class="js jt hi bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">卷积块</h1><p id="214f" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">整个UNET架构使用两个3×3卷积层，每个卷积层后面都有一个ReLU激活。</p><p id="a70b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里我们创建一个简单的类，名为<em class="jg">conv _布洛克</em>。</p><pre class="jl jm jn jo fd ls lt lu lv aw lw bi"><span id="0d16" class="lx jt hi lt b fi ly lz l ma mb">class conv_block(nn.Module):<br/>    def __init__(self, in_c, out_c):<br/>        super().__init__()<br/>        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)<br/>        self.bn1 = nn.BatchNorm2d(out_c)</span><span id="25a6" class="lx jt hi lt b fi mc lz l ma mb">         self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)<br/>        self.bn2 = nn.BatchNorm2d(out_c)</span><span id="0784" class="lx jt hi lt b fi mc lz l ma mb">         self.relu = nn.ReLU()</span><span id="a46e" class="lx jt hi lt b fi mc lz l ma mb">     def forward(self, inputs):<br/>        x = self.conv1(inputs)<br/>        x = self.bn1(x)<br/>        x = self.relu(x)</span><span id="cdbf" class="lx jt hi lt b fi mc lz l ma mb">        x = self.conv2(x)<br/>        x = self.bn2(x)<br/>        x = self.relu(x)<br/>         return x</span></pre><p id="2b1d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">原始UNET在卷积层和ReLU之间不使用批规格化。在这里，我们在它们之间插入批处理规范化。它有助于网络减少内部协方差漂移，使网络在训练时更加稳定。</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="42cf" class="js jt hi bd ju jv lc jx jy jz ld kb kc kd le kf kg kh lf kj kk kl lg kn ko kp bi translated">编码器模块</h1><p id="eef8" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">从最初的论文</p><blockquote class="md"><p id="b83d" class="me mf hi bd mg mh mi mj mk ml mm jc dx translated"><em class="mn">收缩路径遵循卷积网络的典型架构。它由两个3×3卷积(无填充卷积)的重复应用组成，每个卷积后跟一个整流线性单元(ReLU)和一个2×2最大合并操作，跨距为2，用于下采样。在每个下采样步骤，我们将特征通道的数量增加一倍。</em></p></blockquote><pre class="mo mp mq mr ms ls lt lu lv aw lw bi"><span id="d80e" class="lx jt hi lt b fi ly lz l ma mb">class encoder_block(nn.Module):<br/>    def __init__(self, in_c, out_c):<br/>        super().__init__()<br/>        self.conv = conv_block(in_c, out_c)<br/>        self.pool = nn.MaxPool2d((2, 2))</span><span id="f4de" class="lx jt hi lt b fi mc lz l ma mb">     def forward(self, inputs):<br/>        x = self.conv(inputs)<br/>        p = self.pool(x)<br/>        return x, p</span></pre><p id="a2c2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在<em class="jg"> encoder_block </em>中，我们使用了填充来确保输出特征图的形状(高度和宽度)与输入特征图保持一致。</p><p id="a7af" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jg">编码器_模块</em>由一个<em class="jg">conv _模块</em>和一个2×2最大池组成。每经过一个区块，过滤器的数量增加一倍，高度和宽度减少一半。</p><p id="e6c8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">编码器块返回两个输出:</p><ul class=""><li id="0376" class="mt mu hi ih b ii ij im in iq mv iu mw iy mx jc my mz na nb bi translated">x:它是<em class="jg">conv _块</em>的输出，并作为汇集层的输入和解码器块的跳过连接特征映射。</li><li id="bbef" class="mt mu hi ih b ii nc im nd iq ne iu nf iy ng jc my mz na nb bi translated">p:它是池层的输出。</li></ul></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="8e1d" class="js jt hi bd ju jv lc jx jy jz ld kb kc kd le kf kg kh lf kj kk kl lg kn ko kp bi translated">解码器块</h1><p id="8e60" class="pw-post-body-paragraph if ig hi ih b ii kq ik il im kr io ip iq ks is it iu kt iw ix iy ku ja jb jc hb bi translated">从最初的论文</p><blockquote class="md"><p id="5719" class="me mf hi bd mg mh mi mj mk ml mm jc dx translated"><em class="mn">扩展路径中的每一步都包括特征图的上采样，随后是将特征通道数量减半的2×2卷积(“上卷积”)，与收缩路径中相应裁剪的特征图的连接，以及两个3×3卷积，每个卷积之后是ReLU </em></p></blockquote><p id="8a29" class="pw-post-body-paragraph if ig hi ih b ii nh ik il im ni io ip iq nj is it iu nk iw ix iy nl ja jb jc hb bi translated">在上面的行中，上卷积被称为转置卷积。</p><pre class="jl jm jn jo fd ls lt lu lv aw lw bi"><span id="d757" class="lx jt hi lt b fi ly lz l ma mb">class decoder_block(nn.Module):<br/>    def __init__(self, in_c, out_c):<br/>        super().__init__()<br/>        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)<br/>        self.conv = conv_block(out_c+out_c, out_c)</span><span id="189b" class="lx jt hi lt b fi mc lz l ma mb">     def forward(self, inputs, skip):<br/>        x = self.up(inputs)<br/>        x = torch.cat([x, skip], axis=1)<br/>        x = self.conv(x)<br/>        return x</span></pre></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="172d" class="js jt hi bd ju jv lc jx jy jz ld kb kc kd le kf kg kh lf kj kk kl lg kn ko kp bi translated">UNET建筑</h1><pre class="jl jm jn jo fd ls lt lu lv aw lw bi"><span id="e1b7" class="lx jt hi lt b fi ly lz l ma mb">class build_unet(nn.Module):<br/>    def __init__(self):<br/>        super().__init__()<br/>         """ Encoder """<br/>        self.e1 = encoder_block(3, 64)<br/>        self.e2 = encoder_block(64, 128)<br/>        self.e3 = encoder_block(128, 256)<br/>        self.e4 = encoder_block(256, 512)</span><span id="eff6" class="lx jt hi lt b fi mc lz l ma mb">         """ Bottleneck """<br/>        self.b = conv_block(512, 1024)</span><span id="c0e1" class="lx jt hi lt b fi mc lz l ma mb">         """ Decoder """<br/>        self.d1 = decoder_block(1024, 512)<br/>        self.d2 = decoder_block(512, 256)<br/>        self.d3 = decoder_block(256, 128)<br/>        self.d4 = decoder_block(128, 64)</span><span id="c7bb" class="lx jt hi lt b fi mc lz l ma mb">         """ Classifier """<br/>        self.outputs = nn.Conv2d(64, 1, kernel_size=1, padding=0)</span><span id="c749" class="lx jt hi lt b fi mc lz l ma mb">     def forward(self, inputs):<br/>        """ Encoder """<br/>        s1, p1 = self.e1(inputs)<br/>        s2, p2 = self.e2(p1)<br/>        s3, p3 = self.e3(p2)<br/>        s4, p4 = self.e4(p3)</span><span id="7fcd" class="lx jt hi lt b fi mc lz l ma mb">         """ Bottleneck """<br/>        b = self.b(p4)</span><span id="10b6" class="lx jt hi lt b fi mc lz l ma mb">         """ Decoder """<br/>        d1 = self.d1(b, s4)<br/>        d2 = self.d2(d1, s3)<br/>        d3 = self.d3(d2, s2)<br/>        d4 = self.d4(d3, s1)</span><span id="c9c0" class="lx jt hi lt b fi mc lz l ma mb">         """ Classifier """<br/>        outputs = self.outputs(d4)</span><span id="2554" class="lx jt hi lt b fi mc lz l ma mb">        return outputs</span></pre><p id="2fb3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的代码完全实现了PyTorch框架中的UNET架构。</p></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><h1 id="6017" class="js jt hi bd ju jv lc jx jy jz ld kb kc kd le kf kg kh lf kj kk kl lg kn ko kp bi translated">阅读更多</h1><ol class=""><li id="8c43" class="mt mu hi ih b ii kq im kr iq nm iu nn iy no jc np mz na nb bi translated"><a class="ae jk" href="https://arxiv.org/pdf/1505.04597.pdf" rel="noopener ugc nofollow" target="_blank"> U-Net:用于生物医学图像分割的卷积网络</a></li><li id="0485" class="mt mu hi ih b ii nc im nd iq ne iu nf iy ng jc np mz na nb bi translated"><a class="ae jk" href="https://amaarora.github.io/2020/09/13/unet.html" rel="noopener ugc nofollow" target="_blank"> U-Net:用60行代码实现py torch</a></li></ol></div><div class="ab cl kv kw gp kx" role="separator"><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la lb"/><span class="ky bw bk kz la"/></div><div class="hb hc hd he hf"><p id="4a4f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jg">原载于2021年5月22日https://idiotdeveloper.com</em><a class="ae jk" href="https://idiotdeveloper.com/unet-implementation-in-pytorch/" rel="noopener ugc nofollow" target="_blank"><em class="jg"/></a><em class="jg">。</em></p></div></div>    
</body>
</html>