<html>
<head>
<title>⚕️ Breast Cancer Wisconsin [Diagnostic] - EDA 📊📈</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">⚕️乳腺癌威斯康星州[诊断] - EDA📊📈</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/breast-cancer-diagnostic-dataset-eda-fa0de80f15bd?source=collection_archive---------3-----------------------#2021-02-14">https://medium.com/analytics-vidhya/breast-cancer-diagnostic-dataset-eda-fa0de80f15bd?source=collection_archive---------3-----------------------#2021-02-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="9a59" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">乳腺癌威斯康星州(诊断)数据集-探索性数据分析</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/b8ae93db736acac96eeaff48bfe2e577.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pxFCmhRFTighUn88baLcSA.png"/></div></div></figure><div class="jo jp ez fb jq jr"><a href="https://www.kaggle.com/shubamsumbria/breast-cancer-prediction" rel="noopener  ugc nofollow" target="_blank"><div class="js ab dw"><div class="jt ab ju cl cj jv"><h2 class="bd hi fi z dy jw ea eb jx ed ef hg bi translated">乳腺癌预测</h2><div class="jy l"><h3 class="bd b fi z dy jw ea eb jx ed ef dx translated">这是威斯康星清洁乳腺癌(诊断)数据集</h3></div><div class="jz l"><p class="bd b fp z dy jw ea eb jx ed ef dx translated">www.kaggle.com</p></div></div><div class="ka l"><div class="kb l kc kd ke ka kf jm jr"/></div></div></a></div><blockquote class="kg kh ki"><p id="79cf" class="kj kk kl km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ha bi translated"><strong class="km hi">数据集信息:</strong></p><p id="e162" class="kj kk kl km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ha bi translated">从乳腺肿块的细针抽吸(FNA)的数字化图像中计算特征。它们描述了细胞核的特征。</p><p id="7e10" class="kj kk kl km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ha bi translated">使用多面方法树(MSM-T)获得上述分离平面[K. P. Bennett，“通过线性规划构建决策树”《第四届中西部人工智能和认知科学学会论文集》，第97–101页，1992年]，一种使用线性规划构建决策树的分类方法。在1-4个特征和1-3个分离平面的空间中使用穷举搜索选择相关特征。</p><p id="526b" class="kj kk kl km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ha bi translated">用于获得3维空间中的分离平面的实际线性程序描述于:[K. P. Bennett和O. L. Mangasarian:“两个线性不可分集合的鲁棒线性编程判别”，Optimization Methods and Software 1，1992，23–34]。</p><p id="420a" class="kj kk kl km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ha bi translated"><strong class="km hi">引自</strong> Dua，d .和Graff，C. (2019)。UCI机器学习资源库【http://archive.ics.uci.edu/ml<a class="ae li" href="http://archive.ics.uci.edu/ml%5D" rel="noopener ugc nofollow" target="_blank">】</a>。加州欧文:加州大学信息与计算机科学学院。</p></blockquote><p id="1328" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi">导入必要的库</strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="dca5" class="lr if hh ln b fi ls lt l lu lv">import pandas as pd<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span></pre><p id="0f1e" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi">将数据集加载到Pandas数据框中</strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="86a5" class="lr if hh ln b fi ls lt l lu lv">df = pd.read_csv("../input/breast-cancer-prediction/data.csv")<br/>df.head()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/05b0ea0b79aa0b1df521fdb115ed0c07.png" data-original-src="https://miro.medium.com/v2/format:webp/1*CEkt_I76tw1AaMzS27uqzQ.png"/></div></figure><h2 id="831e" class="lr if hh bd ig lx ly lz ik ma mb mc io lj md me is lk mf mg iw ll mh mi ja mj bi translated">属性信息:</h2><ol class=""><li id="08e6" class="mk ml hh km b kn mm kr mn lj mo lk mp ll mq lh mr ms mt mu bi translated"><em class="kl">身份证号</em></li><li id="61d1" class="mk ml hh km b kn mv kr mw lj mx lk my ll mz lh mr ms mt mu bi translated"><em class="kl">诊断(M =恶性，B =良性)</em></li></ol><p id="47be" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl">为每个细胞核(3–32)计算十个实值特征:</em></p><p id="7ccc" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl"> a)半径(从中心到周边各点的平均距离)</em></p><p id="953b" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl"> b)纹理(灰度值的标准偏差)</em></p><p id="0c39" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl"> c)周长</em></p><p id="525b" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl"> d)面积</em></p><p id="93e8" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl"> e)平滑度(半径长度的局部变化)</em></p><p id="d8fd" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl"> f)密实度(周长/面积— 1.0) </em></p><p id="4b97" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl"> g)凹度(轮廓凹入部分的严重程度)</em></p><p id="326c" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl"> h)凹点(轮廓的凹部数量)</em></p><p id="bae3" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl"> i)对称性</em></p><p id="9f27" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl"> j)分形维数(“海岸线近似值”-1)</em></p><ul class=""><li id="9637" class="mk ml hh km b kn ko kr ks lj na lk nb ll nc lh nd ms mt mu bi translated">我已经在Kaggle上上传了干净且随时可用的乳腺癌诊断数据集(链接在开头)。我从原始数据集中删除了不需要的列(id号和未命名的32)。重新映射诊断列的值(M: 1和B: 0)。</li></ul><p id="7267" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi">检查空值和缺失值</strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="a30e" class="lr if hh ln b fi ls lt l lu lv">print("\nNull Values:\n", df.isnull().sum())<br/>print("\nMissing Values:\n", df.isna().sum())</span><span id="23b0" class="lr if hh ln b fi ne lt l lu lv">Null Values:<br/> diagnosis                  0<br/>radius_mean                0<br/>texture_mean               0<br/>perimeter_mean             0<br/>area_mean                  0<br/>smoothness_mean            0<br/>compactness_mean           0<br/>concavity_mean             0<br/>concave points_mean        0<br/>symmetry_mean              0<br/>fractal_dimension_mean     0<br/>radius_se                  0<br/>texture_se                 0<br/>perimeter_se               0<br/>area_se                    0<br/>smoothness_se              0<br/>compactness_se             0<br/>concavity_se               0<br/>concave points_se          0<br/>symmetry_se                0<br/>fractal_dimension_se       0<br/>radius_worst               0<br/>texture_worst              0<br/>perimeter_worst            0<br/>area_worst                 0<br/>smoothness_worst           0<br/>compactness_worst          0<br/>concavity_worst            0<br/>concave points_worst       0<br/>symmetry_worst             0<br/>fractal_dimension_worst    0<br/>dtype: int64<br/><br/>Missing Values:<br/> diagnosis                  0<br/>radius_mean                0<br/>texture_mean               0<br/>perimeter_mean             0<br/>area_mean                  0<br/>smoothness_mean            0<br/>compactness_mean           0<br/>concavity_mean             0<br/>concave points_mean        0<br/>symmetry_mean              0<br/>fractal_dimension_mean     0<br/>radius_se                  0<br/>texture_se                 0<br/>perimeter_se               0<br/>area_se                    0<br/>smoothness_se              0<br/>compactness_se             0<br/>concavity_se               0<br/>concave points_se          0<br/>symmetry_se                0<br/>fractal_dimension_se       0<br/>radius_worst               0<br/>texture_worst              0<br/>perimeter_worst            0<br/>area_worst                 0<br/>smoothness_worst           0<br/>compactness_worst          0<br/>concavity_worst            0<br/>concave points_worst       0<br/>symmetry_worst             0<br/>fractal_dimension_worst    0<br/>dtype: int64</span></pre><p id="8d96" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi">数据集信息</strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="5ac2" class="lr if hh ln b fi ls lt l lu lv">df.info()<br/>&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 569 entries, 0 to 568<br/>Data columns (total 31 columns):<br/> #   Column                   Non-Null Count  Dtype  <br/>---  ------                   --------------  -----  <br/> 0   diagnosis                569 non-null    int64  <br/> 1   radius_mean              569 non-null    float64<br/> 2   texture_mean             569 non-null    float64<br/> 3   perimeter_mean           569 non-null    float64<br/> 4   area_mean                569 non-null    float64<br/> 5   smoothness_mean          569 non-null    float64<br/> 6   compactness_mean         569 non-null    float64<br/> 7   concavity_mean           569 non-null    float64<br/> 8   concave points_mean      569 non-null    float64<br/> 9   symmetry_mean            569 non-null    float64<br/> 10  fractal_dimension_mean   569 non-null    float64<br/> 11  radius_se                569 non-null    float64<br/> 12  texture_se               569 non-null    float64<br/> 13  perimeter_se             569 non-null    float64<br/> 14  area_se                  569 non-null    float64<br/> 15  smoothness_se            569 non-null    float64<br/> 16  compactness_se           569 non-null    float64<br/> 17  concavity_se             569 non-null    float64<br/> 18  concave points_se        569 non-null    float64<br/> 19  symmetry_se              569 non-null    float64<br/> 20  fractal_dimension_se     569 non-null    float64<br/> 21  radius_worst             569 non-null    float64<br/> 22  texture_worst            569 non-null    float64<br/> 23  perimeter_worst          569 non-null    float64<br/> 24  area_worst               569 non-null    float64<br/> 25  smoothness_worst         569 non-null    float64<br/> 26  compactness_worst        569 non-null    float64<br/> 27  concavity_worst          569 non-null    float64<br/> 28  concave points_worst     569 non-null    float64<br/> 29  symmetry_worst           569 non-null    float64<br/> 30  fractal_dimension_worst  569 non-null    float64<br/>dtypes: float64(30), int64(1)<br/>memory usage: 137.9 KB</span></pre><ul class=""><li id="4204" class="mk ml hh km b kn ko kr ks lj na lk nb ll nc lh nd ms mt mu bi translated">在检查了空值计数、缺失值计数和信息等各个方面之后。这个数据集是完美的，因为没有Nul和缺失值。</li></ul><p id="c6fe" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi">数据的统计描述</strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="358b" class="lr if hh ln b fi ls lt l lu lv">df.describe()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/c5ad25676a34e2a70d12b76c64cf05b5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*zpqS09TTjA-1F3MAs6nyJg.png"/></div></figure><p id="5861" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi">提取平均值、平方误差和最差特征</strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="3134" class="lr if hh ln b fi ls lt l lu lv">df_mean = df[df.columns[:11]]<br/>df_se = df.drop(df.columns[1:11], axis=1)<br/>df_se = df_se.drop(df_se.columns[11:], axis=1)<br/>df_worst = df.drop(df.columns[1:21], axis=1)</span></pre><h2 id="f192" class="lr if hh bd ig lx ly lz ik ma mb mc io lj md me is lk mf mg iw ll mh mi ja mj bi translated"><strong class="ak">基于诊断的计数:</strong></h2><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="84ca" class="lr if hh ln b fi ls lt l lu lv">df.diagnosis.value_counts() \<br/>    .plot(kind="bar", width=0.1, color=["lightgreen", "cornflowerblue"], legend=1, figsize=(8, 5))<br/>plt.xlabel("(0 = Benign) (1 = Malignant)", fontsize=12)<br/>plt.ylabel("Count", fontsize=12)<br/>plt.xticks(fontsize=12);<br/>plt.yticks(fontsize=12)<br/>plt.legend(["Benign"], fontsize=12)<br/>plt.show()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/6f6040397aa24099c16cca61020fbc1e.png" data-original-src="https://miro.medium.com/v2/format:webp/1*bhJz3dG8_Ss-LkoUMf633Q.png"/></div></figure><p id="7907" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">观察:</em> </strong> <em class="kl">我们有357个恶性病例和212个良性病例，所以我们的数据集是</em>不平衡的，我们可以使用各种重采样算法，如欠采样、过采样、SMOTE等。<em class="kl">使用“足够”的正确算法。</em></p><h2 id="9342" class="lr if hh bd ig lx ly lz ik ma mb mc io lj md me is lk mf mg iw ll mh mi ja mj bi translated"><strong class="ak"> <em class="nf">与诊断的相关性:</em> </strong></h2><p id="a965" class="pw-post-body-paragraph kj kk hh km b kn mm kp kq kr mn kt ku lj ng kx ky lk nh lb lc ll ni lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">均值特征与诊断的相关性:</em> </strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="f1f8" class="lr if hh ln b fi ls lt l lu lv">plt.figure(figsize=(20, 8))<br/>df_mean.drop('diagnosis', axis=1).corrwith(df_mean.diagnosis).plot(kind='bar', grid=True, title="Correlation of Mean Features with Diagnosis", color="cornflowerblue");</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/7c4d4ca48ad61a94155b566365e5c436.png" data-original-src="https://miro.medium.com/v2/format:webp/1*CWfOwk2kr9V4dlUtKrQrag.png"/></div></figure><p id="1b99" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">观察:</em> </strong></p><ul class=""><li id="62a7" class="mk ml hh km b kn ko kr ks lj na lk nb ll nc lh nd ms mt mu bi translated"><em class="kl">分形_维数_均值与目标变量最小相关。</em></li><li id="5157" class="mk ml hh km b kn mv kr mw lj mx lk my ll mz lh nd ms mt mu bi translated"><em class="kl">所有其他均值特征与目标变量有显著相关性。</em></li></ul><p id="af01" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">平方误差特征与诊断的相关性:</em> </strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="44a7" class="lr if hh ln b fi ls lt l lu lv">plt.figure(figsize=(20, 8))<br/>df_se.drop('diagnosis', axis=1).corrwith(df_se.diagnosis).plot(kind='bar', grid=True, title="Correlation of Squared Error Features with Diagnosis", color="cornflowerblue");</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/1bc1f63b28d23cad90ccd3549ba59f3c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*wxoyz_z5leVP2qJRZltIrw.png"/></div></figure><p id="6cf3" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">观察:</em> </strong></p><ul class=""><li id="2427" class="mk ml hh km b kn ko kr ks lj na lk nb ll nc lh nd ms mt mu bi translated"><em class="kl">纹理_se、平滑度_se、对称性_se和分形_维数_se与目标变量的相关性最小。</em></li><li id="7e71" class="mk ml hh km b kn mv kr mw lj mx lk my ll mz lh nd ms mt mu bi translated"><em class="kl">所有其他平方误差特征与目标变量具有显著相关性。</em></li></ul><p id="23c6" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">最差特征与诊断的相关性:</em> </strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="28b0" class="lr if hh ln b fi ls lt l lu lv">plt.figure(figsize=(20, 8))<br/>df_worst.drop('diagnosis', axis=1).corrwith(df_worst.diagnosis).plot(kind='bar', grid=True, title="Correlation of Worst Error Features with Diagnosis", color="cornflowerblue");</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/5005da1f633cccbf2f521cd1bbdea148.png" data-original-src="https://miro.medium.com/v2/format:webp/1*KRoas7hhG4iiQcEZgyx41A.png"/></div></figure><p id="e7f8" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">观察:</em> </strong></p><ul class=""><li id="b6df" class="mk ml hh km b kn ko kr ks lj na lk nb ll nc lh nd ms mt mu bi translated"><em class="kl">所有最坏的特征都与目标变量有显著的相关性。</em></li></ul><p id="72b1" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">提取均值、平方误差和最差特征列</em> </strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="d32a" class="lr if hh ln b fi ls lt l lu lv">df_mean_cols = list(df.columns[1:11])<br/>df_se_cols = list(df.columns[11:21])<br/>df_worst_cols = list(df.columns[21:])</span></pre><p id="3dc0" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">根据诊断一分为二</em> </strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="2477" class="lr if hh ln b fi ls lt l lu lv">dfM = df[df['diagnosis'] == 1]<br/>dfB = df[df['diagnosis'] == 0]</span></pre><h2 id="a4ae" class="lr if hh bd ig lx ly lz ik ma mb mc io lj md me is lk mf mg iw ll mh mi ja mj bi translated">基于核和诊断的分布:</h2><p id="24f8" class="pw-post-body-paragraph kj kk hh km b kn mm kp kq kr mn kt ku lj ng kx ky lk nh lb lc ll ni lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">表示特征vs诊断:</em> </strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="b7fa" class="lr if hh ln b fi ls lt l lu lv">plt.rcParams.update({'font.size': 8})<br/>fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 10))<br/>axes = axes.ravel()<br/>for idx, ax in enumerate(axes):<br/>    ax.figure<br/>    binwidth = (max(df[df_mean_cols[idx]]) - min(df[df_mean_cols[idx]])) / 50<br/>    ax.hist([dfM[df_mean_cols[idx]], dfB[df_mean_cols[idx]]],<br/>            bins=np.arange(min(df[df_mean_cols[idx]]), max(df[df_mean_cols[idx]]) + binwidth, binwidth), alpha=0.5,<br/>            stacked=True, label=['M', 'B'], color=['b', 'g'])<br/>    ax.legend(loc='upper right')<br/>    ax.set_title(df_mean_cols[idx])<br/>plt.tight_layout()<br/>plt.show()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/14145c97ca4df04970e4bdfcb1ce0876.png" data-original-src="https://miro.medium.com/v2/format:webp/1*6lR8R9KotiCzGW5_qCSuwg.png"/></div></figure><p id="41dd" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">平方误差特征vs诊断:</em> </strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="2520" class="lr if hh ln b fi ls lt l lu lv">plt.rcParams.update({'font.size': 8})<br/>fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 10))<br/>axes = axes.ravel()<br/>for idx, ax in enumerate(axes):<br/>    ax.figure<br/>    binwidth = (max(df[df_se_cols[idx]]) - min(df[df_se_cols[idx]])) / 50<br/>    ax.hist([dfM[df_se_cols[idx]], dfB[df_se_cols[idx]]],<br/>            bins=np.arange(min(df[df_se_cols[idx]]), max(df[df_se_cols[idx]]) + binwidth, binwidth), alpha=0.5,<br/>            stacked=True, label=['M', 'B'], color=['b', 'g'])<br/>    ax.legend(loc='upper right')<br/>    ax.set_title(df_se_cols[idx])<br/>plt.tight_layout()<br/>plt.show()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/3db2d82f0e625e84b645434b81b1d09c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*Id_U4cAnNuxYZXSWheTpBA.png"/></div></figure><p id="6e51" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">最差特征vs诊断:</em> </strong></p><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="a246" class="lr if hh ln b fi ls lt l lu lv">plt.rcParams.update({'font.size': 8})<br/>fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 10))<br/>axes = axes.ravel()<br/>for idx, ax in enumerate(axes):<br/>    ax.figure<br/>    binwidth = (max(df[df_worst_cols[idx]]) - min(df[df_worst_cols[idx]])) / 50<br/>    ax.hist([dfM[df_worst_cols[idx]], dfB[df_worst_cols[idx]]],<br/>            bins=np.arange(min(df[df_worst_cols[idx]]), max(df[df_worst_cols[idx]]) + binwidth, binwidth), alpha=0.5,<br/>            stacked=True, label=['M', 'B'], color=['b', 'g'])<br/>    ax.legend(loc='upper right')<br/>    ax.set_title(df_worst_cols[idx])<br/>plt.tight_layout()<br/>plt.show()</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/4a70ab690409cbde18cb61ffa1b4417c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*YFqTNEvhUx1q4GIiEdYdyQ.png"/></div></figure><h2 id="0ed3" class="lr if hh bd ig lx ly lz ik ma mb mc io lj md me is lk mf mg iw ll mh mi ja mj bi translated"><strong class="ak">检查不同特征之间的多重共线性:</strong></h2><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="dac6" class="lr if hh ln b fi ls lt l lu lv">def pairplot(dfx):<br/>    import seaborn as sns<br/>    name = str([x for x in globals() if globals()[x] is dfx][0])<br/>    if name == 'df_mean':<br/>        x = "Mean"<br/>    elif name == 'df_se':<br/>        x = "Squared Error"<br/>    elif name == 'df_worst':<br/>        x = "Worst"<br/>    sns.pairplot(data=dfx, hue='diagnosis', palette='crest', corner=True).fig.suptitle('Pairplot for {} Featrues'.format(x), fontsize = 20)</span><span id="59c6" class="lr if hh ln b fi ne lt l lu lv">pairplot(df_mean)</span></pre><p id="e8ae" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">表示特性:</em> </strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/ccf5802885e363180b4bc9b46bf28d69.png" data-original-src="https://miro.medium.com/v2/format:webp/1*cCIhafFgO7tSl9DFdQFUYw.png"/></div></figure><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="bd89" class="lr if hh ln b fi ls lt l lu lv">pairplot(df_se)</span></pre><p id="214f" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">平方误差特性:</em> </strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/67296bdc04919eff0848d3e822f301aa.png" data-original-src="https://miro.medium.com/v2/format:webp/1*AmROsfqGcoBOuAv1QmfGSg.png"/></div></figure><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="9dc8" class="lr if hh ln b fi ls lt l lu lv">pairplot(df_worst)</span></pre><p id="bdbf" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">最差特性:</em> </strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/c3c6f23207d53158f294a7a844aa06a9.png" data-original-src="https://miro.medium.com/v2/format:webp/1*JwlGRxV4jXejsEvTHAQL0g.png"/></div></figure><p id="fd1a" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">观察值:</em> </strong>半径、周长和面积属性之间几乎完美的线性模式暗示着这些变量之间存在多重共线性。另一组可能暗示多重共线性的变量是凹度、凹点和密实度。</p><h2 id="5561" class="lr if hh bd ig lx ly lz ik ma mb mc io lj md me is lk mf mg iw ll mh mi ja mj bi translated"><strong class="ak">细胞核特征间关联热图:</strong></h2><pre class="jd je jf jg fd lm ln lo lp aw lq bi"><span id="9767" class="lr if hh ln b fi ls lt l lu lv">corr_matrix = df.corr()  # Correlation Matrix<br/><br/># Mask for Heatmap<br/>mask = np.zeros_like(corr_matrix, dtype=np.bool)<br/>mask[np.triu_indices_from(corr_matrix)] = True<br/><br/># Correlation Matrix Heatmap including all features<br/>fig, ax = plt.subplots(figsize=(22, 10))<br/>ax = sns.heatmap(corr_matrix, mask=mask, annot=True, linewidths=0.5, fmt=".2f", cmap="YlGn");<br/>bottom, top = ax.get_ylim()<br/>ax.set_ylim(bottom + 0.5, top - 0.5);<br/>ax.set_title("Correlation Matrix Heatmap including all features");</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="ab fe cl lw"><img src="../Images/fcb171a8f9d0905b5f14759fc42454d0.png" data-original-src="https://miro.medium.com/v2/format:webp/1*QJMkoViOa9J08Oku3-FIeA.png"/></div></figure><p id="e0b0" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">观察值:</em> </strong> <em class="kl"> </em>我们可以验证一些变量之间的多重共线性。这是因为这三列基本上包含相同的信息，即观察值(单元)的物理大小。因此，当我们进一步分析时，我们应该只选择这三列中的一列。</p><blockquote class="kg kh ki"><p id="fc3f" class="kj kk kl km b kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh ha bi translated"><strong class="km hi">多重共线性问题</strong> <a class="ae li" href="https://www.analyticsvidhya.com/blog/2020/03/what-is-multicollinearity/#article-data:~:text=next.-,The%20Problem%20with%20having%20Multicollinearity,Multicollinearity%20may%20not%20affect%20the%20accuracy%20of%20the%20model%20as%20much.%20But%20we%20might%20lose%20reliability%20in%20determining%20the%20effects%20of%20individual%20features%20in%20your%20model%20%E2%80%93%20and%20that%20can%20be%20a%20problem%20when%20it%20comes%20to%20interpretability." rel="noopener ugc nofollow" target="_blank">(参考分析Vidhya) </a></p></blockquote><h2 id="035d" class="lr if hh bd ig lx ly lz ik ma mb mc io lj md me is lk mf mg iw ll mh mi ja mj bi translated">使用该数据集时要记住的事项:</h2><ul class=""><li id="1654" class="mk ml hh km b kn mm kr mn lj mo lk mp ll mq lh nd ms mt mu bi translated">稍微不平衡的数据集(<em class="kl"> 357个恶性病例和212个良性病例</em>)。我们必须选择适当的重采样算法来进行平衡。</li><li id="fc4b" class="mk ml hh km b kn mv kr mw lj mx lk my ll mz lh nd ms mt mu bi translated">某些要素之间的多重共线性。</li><li id="d094" class="mk ml hh km b kn mv kr mw lj mx lk my ll mz lh nd ms mt mu bi translated">由于三列基本上包含相同的信息，即单元的物理大小，我们必须选择适当的特征选择方法来消除不必要的特征。</li></ul><p id="195a" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><em class="kl">目前正在进行</em> <strong class="km hi">乳腺癌预测的不同机器学习分类算法对比分析</strong> <em class="kl">。查看</em>我的<a class="ae li" href="https://github.com/shubamsumbria66" rel="noopener ugc nofollow" target="_blank"> GitHub </a>档案了解更多详情。</p><p id="f54d" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated">如果你觉得这个故事信息丰富，请留下评论。✨</p><p id="4ce8" class="pw-post-body-paragraph kj kk hh km b kn ko kp kq kr ks kt ku lj kw kx ky lk la lb lc ll le lf lg lh ha bi translated"><strong class="km hi"> <em class="kl">感谢阅读！</em> </strong> <em class="kl"> </em>🤗</p></div></div>    
</body>
</html>