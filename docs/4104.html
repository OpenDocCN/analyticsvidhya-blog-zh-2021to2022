<html>
<head>
<title>Music Classification Using Deep Learning | Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的音乐分类| Python</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/music-classification-using-deep-learning-python-b22614adb7a2?source=collection_archive---------2-----------------------#2021-08-27">https://medium.com/analytics-vidhya/music-classification-using-deep-learning-python-b22614adb7a2?source=collection_archive---------2-----------------------#2021-08-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/5e31f7cbf26b24b8aeb1bbe6a2a64c03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N_ZjrILo09Jet5wNn-6FGw.png"/></div></div></figure><p id="ad28" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">深度神经网络已被用于各种分类任务，帮助人类做出重要决定或自己做出这些决定。</p><p id="8102" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">不同音乐流派之间的区别是我们可以应用深度学习的一个任务。我决定开始这个深度学习项目，学习音频分类和处理。</p><p id="8b28" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我在这里与你分享我的发现。</p><p id="0d23" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">本文将包含以下小节:</p><ul class=""><li id="47dc" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated"><strong class="ir hi">探索GTZAN数据集。</strong></li><li id="cc4e" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated"><strong class="ir hi">加载和扩充数据。</strong></li><li id="3e46" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated"><strong class="ir hi">建造我们的模型</strong></li><li id="0f7e" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">结果和结论。</li></ul></div><div class="ab cl kb kc go kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="ha hb hc hd he"><p id="fd3e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们开始吧。</p><h2 id="ba77" class="ki kj hh bd kk kl km kn ko kp kq kr ks ja kt ku kv je kw kx ky ji kz la lb lc bi translated">GTZAN数据集</h2><p id="4b57" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji lh jk jl jm ha bi translated">GTZAN数据集是一组<strong class="ir hi"> 1000个不同的音频文件，即10种不同类别的</strong>音乐；</p><ul class=""><li id="04c5" class="jn jo hh ir b is it iw ix ja jp je jq ji jr jm js jt ju jv bi translated">布鲁斯音乐</li><li id="bb79" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">经典的</li><li id="1c1e" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">国家</li><li id="8f5f" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">迪斯科舞厅</li><li id="9f54" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">嘻哈</li><li id="86a5" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">爵士乐</li><li id="901a" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">金属</li><li id="9cc0" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">流行音乐</li><li id="7604" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">瑞格舞</li><li id="6fde" class="jn jo hh ir b is jw iw jx ja jy je jz ji ka jm js jt ju jv bi translated">岩石</li></ul><p id="22a7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它由每节课100个文件组成，每个音频片段长30秒。</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es li"><img src="../Images/c917b8316a85a9fdf419da659f36bdad.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*YzElCr-GqAh0XXFC_ADwkw.png"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">数据集的目录结构</figcaption></figure><p id="b018" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">正如上面的快照所示，我们这里有4种不同类型的数据。</p><p id="0253" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">'<strong class="ir hi">流派_原创'</strong>文件夹由1000个原创音频文件组成，这些文件根据其流派(标签)被分隔到不同的文件夹中。</p><p id="0328" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">'<strong class="ir hi"> images_original' </strong>文件夹由这些音频文件的Mel光谱图的图像组成。</p><p id="e991" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">“<strong class="ir hi"> features_30_sec.csv </strong>”和“<strong class="ir hi"> features_3_sec.csv </strong>”各包含从音频文件中提取的不同特征，如不同<em class="lr"> melspec </em>分量的平均值和标准偏差以及<em class="lr">滚降频率。</em></p><p id="1fc0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们绘制一个音频文件；</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/8e40e27f3db8f9f795944a21a2da63bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*RX9VUf_RBeEK1T6Ml3TKCA.png"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">绘制的音频样本</figcaption></figure><p id="c9d6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们看看<em class="lr"> images_original </em>文件夹包含了什么。我们将绘制其中一幅图像。</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es lt"><img src="../Images/6700e4ca8110ed0b4daa9d534b25dd48.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*SglznS2RGbyyp6P0jCz6fQ.png"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">一个爵士音乐文件的Mel谱图</figcaption></figure><p id="cb02" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上图显示了使用Mel谱图的音频文件的图示。</p></div><div class="ab cl kb kc go kd" role="separator"><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg kh"/><span class="ke bw bk kf kg"/></div><div class="ha hb hc hd he"><h2 id="5d6c" class="ki kj hh bd kk kl km kn ko kp kq kr ks ja kt ku kv je kw kx ky ji kz la lb lc bi translated">加载数据</h2><p id="6682" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji lh jk jl jm ha bi translated">即使我们有可用的光谱图，我仍然会应用增强并自己提取特征。</p><p id="ef90" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">增强参数以及模型架构改编自<em class="lr"> Marcharla Vaibhavi和P. Radha Krishna </em>在“<a class="ae lu" href="https://www.researchgate.net/profile/Pisipati-Radha-Krishna/publication/353244342_Music_Genre_Classification_using_Neural_Networks_with_Data_Augmentation_A_Make_in_India_Creation/links/60ef05789541032c6d3e78ff/Music-Genre-Classification-using-Neural-Networks-with-Data-Augmentation-A-Make-in-India-Creation.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi"> <em class="lr">使用带有数据增强的神经网络进行音乐流派分类</em> </strong> </a>”中的工作</p><p id="320e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们首先导入所需的库。</p><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="48ed" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> audiomentations </strong>库是一个易于使用的工具，允许我们以各种方式增加音频文件。</p><p id="f379" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们创建函数来扩充我们的数据。</p><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="95bb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="lr"> add_noise </em>和<em class="lr"> pitch_shift </em>实例现在可以用来扩充任何音频文件。</p><p id="dbf5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们需要为训练和测试准备数据。</p><p id="7743" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">它将按以下顺序完成:加载音频文件→分成测试和训练元素→扩充训练数据→从测试和训练集中提取特征→对标签进行编码。</p><p id="0463" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">相当长的旅程！</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lx"><img src="../Images/4167c802f9ab3ff735ba1f138bfc4fb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jV90QWKWVa_fAcJQQNHmrg.jpeg"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">照片由<a class="ae lu" href="https://unsplash.com/@spencerimbrockphoto?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">斯潘塞·因布罗克</a>在<a class="ae lu" href="https://unsplash.com/s/photos/music?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="351f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们从加载一个文件开始，检查如何提取它的mel-spectrogram。</p><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="8fb6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在这里，我们已经将声谱图应用到先前加载的同一个文件中。</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es ly"><img src="../Images/b3e2ad8c013d2d2401fdb17ddc64fdbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1292/format:webp/1*oIiv6v1PtSIqAcIyxB3cvQ.png"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">梅尔光谱图</figcaption></figure><p id="4b67" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们编写一个例程，加载所有的音频文件及其标签。</p><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">加载完整的音频数据</figcaption></figure><p id="ff89" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">数组X和Y现在包含了我们的音频数据和它们对应的标签。</p><p id="b2ca" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">X的形状:(999，617400) </strong></p><p id="7353" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">Y的形状:(999，10) </strong></p><p id="9e16" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，我们将这些数据分成测试集和训练集，并扩充训练集。</p><pre class="lj lk ll lm fd lz ma mb mc aw md bi"><span id="434e" class="ki kj hh ma b fi me mf l mg mh">from sklearn.model_selection import train_test_split<br/></span><span id="955a" class="ki kj hh ma b fi mi mf l mg mh">#split the data using the SkLearn library</span><span id="d5e6" class="ki kj hh ma b fi mi mf l mg mh">audio_train, audio_test, y_train, y_test = train_test_split(\<br/>     X, Y, test_size=0.20, random_state=6)</span></pre><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div></figure><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">来自训练数据增强和特征提取</figcaption></figure><p id="c10e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">！！上面的代码可能需要几分钟才能完成，因为它要处理700个文件！！</strong></p><p id="0cc7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们有以下变量:</p><p id="2e89" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">x _ train→Mel-spectrogram形式的所有训练数据。(形状= 2397，128，1206)</p><p id="e338" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">y _ train→训练数据的标签</p><p id="e474" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是我们还需要从测试数据中提取mel-spec特征。</p><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">从测试数据中提取特征</figcaption></figure><p id="d990" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请注意，这次我们没有增加数据，因为测试数据应该保持原始状态，以便进行最佳评估。</p><pre class="lj lk ll lm fd lz ma mb mc aw md bi"><span id="c246" class="ki kj hh ma b fi me mf l mg mh">#converting the test and train data to numpy array<br/>X_train = np.stack(X_train)<br/>X_test = np.stack(X_test)</span></pre><p id="a2a8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">还有最后一步。我们的标签仍然是文本形式。我们需要对这些数字进行编码。好在什么都有图书馆:d。</p><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="aecc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在只剩下最后一件事了。Keras conv2d层要求我们为数据增加一个额外的维度。相当简单的整形过程。</p><pre class="lj lk ll lm fd lz ma mb mc aw md bi"><span id="b163" class="ki kj hh ma b fi me mf l mg mh">X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)<br/>X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)</span></pre><h2 id="129e" class="ki kj hh bd kk kl km kn ko kp kq kr ks ja kt ku kv je kw kx ky ji kz la lb lc bi translated">构建模型</h2><p id="8144" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji lh jk jl jm ha bi translated">现在我们的数据已经准备好了，我们可以继续构建和编译模型了。我们将使用Tensorflow的Keras API来构建模型。</p><p id="393f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如前所述，模型架构取自一篇研究论文，文章末尾添加了一个链接。</p><figure class="lj lk ll lm fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/45ab757b1ccb0142e8330ec69c9cf862.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VD6Zob_zgSg6DRZb2rInlg.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">模型架构</figcaption></figure><p id="0619" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们编码这个。</p><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div></figure><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es mj"><img src="../Images/f99d3f4db6848800fe9eb78866341ffc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*h7RVvv_1JEl2d0eTec6WnA.png"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">模型摘要</figcaption></figure><p id="f340" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们只需要训练它。</p><p id="7d3a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">训练一个2D CNN模型需要很长时间，我在一个笔记本上做了我的处理。在开始培训之前，请确保您已经设置了GPU环境。</p><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div></figure><p id="2acf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后，让我们画出精度图。</p><figure class="lj lk ll lm fd ii"><div class="bz dy l di"><div class="lv lw l"/></div></figure><h2 id="b610" class="ki kj hh bd kk kl km kn ko kp kq kr ks ja kt ku kv je kw kx ky ji kz la lb lc bi translated">结果和结论</h2><figure class="lj lk ll lm fd ii er es paragraph-image"><div class="er es mk"><img src="../Images/306485c96d00a31586162bc32370875f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*NPTIMKPAm0K6vuLSMKBlKg.png"/></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">训练和验证准确性</figcaption></figure><p id="fb53" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们当前模型的最高精度为<strong class="ir hi"> 52.5 %。这证明了音乐分类是一项艰巨的任务。即使有这样一个复杂的模型和扩充的数据，我们也只能勉强跨过50 %的门槛。</strong></p><p id="b983" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">实现的论文实际上提到了六种不同的增强技术。我们只使用了2个，也许使用更多的这些可以改善结果。你可以自由地进行实验。</p><h2 id="969c" class="ki kj hh bd kk kl km kn ko kp kq kr ks ja kt ku kv je kw kx ky ji kz la lb lc bi translated">最后的想法</h2><p id="ce93" class="pw-post-body-paragraph ip iq hh ir b is ld iu iv iw le iy iz ja lf jc jd je lg jg jh ji lh jk jl jm ha bi translated">这种型号有很多种可能性可以试用。其中之一是从CNN模型转移到RCNN。其他技术可以尝试提取Mel谱图之外的特征。</p><p id="d62c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你发现任何这样的新技术，请在评论中提及它们。</p><p id="333e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">论文参考:<em class="lr"> </em> <a class="ae lu" href="https://www.researchgate.net/profile/Pisipati-Radha-Krishna/publication/353244342_Music_Genre_Classification_using_Neural_Networks_with_Data_Augmentation_A_Make_in_India_Creation/links/60ef05789541032c6d3e78ff/Music-Genre-Classification-using-Neural-Networks-with-Data-Augmentation-A-Make-in-India-Creation.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="lr">奎师那，Macharla Vaibhavi P. Radha。"使用数据增强的神经网络进行音乐流派分类."(2021).</em>T19】</a></p></div></div>    
</body>
</html>