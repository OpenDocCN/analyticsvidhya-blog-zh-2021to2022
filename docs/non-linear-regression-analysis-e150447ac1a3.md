# éçº¿æ€§å›å½’åˆ†æ

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/non-linear-regression-analysis-e150447ac1a3?source=collection_archive---------0----------------------->

![](img/c5eb8de6fd47ba8e58632679c47b5d49.png)

å›¾ç‰‡æ¥æº:ä½œè€…

# ä»‹ç»

å¦‚æœæ•°æ®æ˜¾ç¤ºæ›²çº¿è¶‹åŠ¿ï¼Œé‚£ä¹ˆ**çº¿æ€§å›å½’**ä¸**éçº¿æ€§å›å½’**ç›¸æ¯”ä¸ä¼šäº§ç”Ÿéå¸¸å‡†ç¡®çš„ç»“æœï¼Œå› ä¸ºé¡¾åæ€ä¹‰ï¼Œ**çº¿æ€§å›å½’**å‡å®š**æ•°æ®**æ˜¯**çº¿æ€§çš„**ã€‚è®©æˆ‘ä»¬å­¦ä¹ ä¸€ä¸‹**éçº¿æ€§å›å½’**å¹¶åœ¨ **python** ä¸­åº”ç”¨ä¸€ä¸ªä¾‹å­ã€‚åœ¨è¿™æœ¬ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†ä¸€ä¸ª**éçº¿æ€§æ¨¡å‹**æ‹Ÿåˆåˆ°ä¸ 1960 å¹´è‡³ 2014 å¹´ä¸­å›½ GDP ç›¸å¯¹åº”çš„**æ•°æ®ç‚¹**ã€‚

# å¯¼å…¥æ‰€éœ€çš„åº“

```
# Basic Data Science libraries**import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline****sns.set()**
```

> è™½ç„¶çº¿æ€§å›å½’å¾ˆå¥½åœ°è§£å†³äº†è®¸å¤šé—®é¢˜ï¼Œä½†å®ƒä¸èƒ½ç”¨äºæ‰€æœ‰æ•°æ®é›†ã€‚é¦–å…ˆå›å¿†ä¸€ä¸‹**çº¿æ€§å›å½’**å¦‚ä½•å¯¹æ•°æ®é›†å»ºæ¨¡ã€‚å®ƒæ¨¡æ‹Ÿäº†ä¸€ä¸ª**å› å˜é‡**å˜é‡ ***y*** å’Œä¸€ä¸ª**è‡ªå˜é‡**å˜é‡ ***x*** ä¹‹é—´çš„**çº¿æ€§å…³ç³»ã€‚å®ƒæœ‰ä¸€ä¸ªç®€å•çš„ 1 æ¬¡æ–¹ç¨‹ï¼Œä¾‹å¦‚ **y = 2ğ‘¥ + 3** ã€‚**

```
**x = np.arange(-5.0, 5.0, 0.1)** #You can adjust the slope and intercept to verify the changes in the graph.
**y = 2*(x) + 3
y_noise = 2 * np.random.normal(size=x.size)
ydata = y + y_noise
plt.figure(figsize=(8,6))
plt.plot(x, ydata,  'bo')
plt.plot(x,y, 'r') 
plt.ylabel('Dependent Variable')
plt.xlabel('Indepdendent Variable')
plt.show()**
```

![](img/2f1ab5e1d15c5c4edb8a40463a23e68f.png)

**éçº¿æ€§å›å½’**æ˜¯**ç‹¬ç«‹**å˜é‡ **ğ‘¥** å’Œ**å› å˜é‡**ğ‘¦ä¹‹é—´çš„å…³ç³»ï¼Œè¿™å¯¼è‡´äº†**éçº¿æ€§å‡½æ•°æ¨¡å‹åŒ–**æ•°æ®ã€‚æœ¬è´¨ä¸Šä»»ä½•ä¸æ˜¯**çº¿æ€§**çš„å…³ç³»éƒ½å¯ä»¥ç§°ä¸º**éçº¿æ€§**ï¼Œé€šå¸¸ç”¨ **ğ‘˜** åº¦çš„**å¤šé¡¹å¼**è¡¨ç¤º(æœ€å¤§åŠŸç‡ **ğ‘¥** )ã€‚

> **ğ‘¦ =ğ‘x +ğ‘ğ‘¥ +ğ‘ğ‘¥+ğ‘‘**

**éçº¿æ€§**å‡½æ•°å¯ä»¥æœ‰ç±»ä¼¼äº**æŒ‡æ•°**ã€**å¯¹æ•°**ã€**åˆ†æ•°**ç­‰å…ƒç´ ã€‚ä¾‹å¦‚:

> **ğ‘¦=log(ğ‘¥)**

ç”šè‡³æ›´å¤æ‚ï¼Œä¾‹å¦‚:

> **ğ‘¦=log(ğ‘ğ‘¥ +ğ‘ğ‘¥ +ğ‘ğ‘¥+ğ‘‘)**

è®©æˆ‘ä»¬æ¥çœ‹çœ‹ä¸€ä¸ª**ä¸‰æ¬¡**å‡½æ•°çš„å›¾å½¢ã€‚

```
**x = np.arange(-5.0, 5.0, 0.1)** #You can adjust the slope and intercept to verify the changes in the graph
**y = 1*(x**3) + 1*(x**2) + 1*x + 3
y_noise = 20 * np.random.normal(size=x.size)
ydata = y + y_noise
plt.plot(x, ydata,  'bo')
plt.plot(x,y, 'r') 
plt.ylabel('Dependent Variable')
plt.xlabel('Indepdendent Variable')
plt.show()**
```

![](img/382709007a069205442060882abf4715.png)

> å¯ä»¥çœ‹åˆ°ï¼Œè¿™ä¸ªå‡½æ•°æœ‰ ***ğ‘¥*** å’Œ ***ğ‘¥*** ä½œä¸º**ç‹¬ç«‹**å˜é‡ã€‚æ­¤å¤–ï¼Œè¯¥å‡½æ•°çš„å›¾å½¢ä¸æ˜¯åœ¨ **2D** å¹³é¢ä¸Šçš„ç›´çº¿ã€‚æ‰€ä»¥è¿™æ˜¯ä¸€ä¸ª**éçº¿æ€§å‡½æ•°**ã€‚

# éçº¿æ€§å›å½’ç¤ºä¾‹

ä¸¾ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬å°†å°è¯•ç”¨ä¸€ä¸ªéçº¿æ€§æ¨¡å‹æ¥æ‹Ÿåˆ 1960 å¹´è‡³ 2014 å¹´ä¸­å›½ GDP çš„æ•°æ®ç‚¹ã€‚æˆ‘ä»¬ä¸‹è½½äº†ä¸€ä¸ªæœ‰ä¸¤åˆ—çš„æ•°æ®é›†ï¼Œç¬¬ä¸€åˆ—æ˜¯ 1960 å¹´åˆ° 2014 å¹´ä¹‹é—´çš„ä¸€å¹´ï¼Œç¬¬äºŒåˆ—æ˜¯ä¸­å›½åœ¨é‚£ä¸€å¹´ä»¥ç¾å…ƒè®¡ç®—çš„ç›¸åº”å¹´åº¦å›½å†…ç”Ÿäº§æ€»å€¼ã€‚

```
**import numpy as np
import pandas as pd**#downloading dataset
**!wget -nv -O china_gdp.csv** [**https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/china_gdp.csv**](https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/china_gdp.csv) **df = pd.read_csv("china_gdp.csv")
df.head(10)**
```

![](img/483c25057b75923abb35dbd5eb085632.png)

# ç»˜åˆ¶æ•°æ®é›†

è¿™æ˜¯æ•°æ®ç‚¹çš„æ ·å­ã€‚å®ƒçœ‹èµ·æ¥æœ‰ç‚¹åƒé€»è¾‘å‡½æ•°æˆ–æŒ‡æ•°å‡½æ•°ã€‚å¼€å§‹æ—¶å¢é•¿ç¼“æ…¢ï¼Œä» 2005 å¹´å¼€å§‹ï¼Œå¢é•¿éå¸¸æ˜¾è‘—ã€‚æœ€åï¼Œå®ƒåœ¨ 2010 å¹´ä»£ç•¥æœ‰å‡é€Ÿã€‚

```
**plt.figure(figsize=(8,5))
x_data, y_data = (df["Year"].values, df["Value"].values)
plt.plot(x_data, y_data, 'ro')
plt.ylabel('GDP')
plt.xlabel('Year')
plt.show()**
```

![](img/758978f2f728061ffc1af8ff6a00fa9e.png)

# é€‰æ‹©æ¨¡å‹

> ä»å¯¹è¯¥å›¾çš„åˆæ­¥è§‚å¯Ÿï¼Œæˆ‘ä»¬ç¡®å®šé€»è¾‘å‡½æ•°å¯ä»¥æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è¿‘ä¼¼ï¼Œå› ä¸ºå®ƒå…·æœ‰ä»ç¼“æ…¢å¢é•¿å¼€å§‹ï¼Œåœ¨ä¸­é—´å¢é•¿ï¼Œç„¶ååœ¨æœ€åå†æ¬¡ä¸‹é™çš„ç‰¹æ€§ï¼›å¦‚ä¸‹å›¾æ‰€ç¤º:

```
**X = np.arange(-5.0, 5.0, 0.1)
Y = 1.0 / (1.0 + np.exp(-X))****plt.plot(X,Y) 
plt.ylabel('Dependent Variable')
plt.xlabel('Indepdendent Variable')
plt.show()**
```

![](img/6c52dba65e9f3cadaa70556bff50248e.png)![](img/d50802e5e07178a29f60f8f50f26ff49.png)

# æ„å»ºæ¨¡å‹

ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ„å»ºæˆ‘ä»¬çš„å›å½’æ¨¡å‹å¹¶åˆå§‹åŒ–å®ƒçš„å‚æ•°ã€‚

```
**def sigmoid(x, Beta_1, Beta_2):
     y = 1 / (1 + np.exp(-Beta_1*(x-Beta_2)))
     return y****beta_1 = 0.10
beta_2 = 1990.0**#logistic function
**Y_pred = sigmoid(x_data, beta_1 , beta_2)****#plot initial prediction against datapoints
plt.plot(x_data, Y_pred*15000000000000.)
plt.plot(x_data, y_data, 'ro'**
```

![](img/c7f46e6a57fbd8240750fc0b2a1a67d8.png)

æˆ‘ä»¬åœ¨è¿™é‡Œçš„ä»»åŠ¡æ˜¯ä¸ºæˆ‘ä»¬çš„**æ¨¡å‹**æ‰¾åˆ°**æœ€ä½³å‚æ•°**ã€‚è®©æˆ‘ä»¬å…ˆæŠŠ**æ­£å¸¸åŒ–**æˆ‘ä»¬çš„***x*** å’Œ ***y*** :

## æˆ‘ä»¬å¦‚ä½•ä¸ºæ‹Ÿåˆçº¿æ‰¾åˆ°æœ€ä½³å‚æ•°ï¼Ÿ

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ **curve_fit** ï¼Œå®ƒä½¿ç”¨éçº¿æ€§æœ€å°äºŒä¹˜æ³•æ¥æ‹Ÿåˆæˆ‘ä»¬çš„ **sigmoid å‡½æ•°**åˆ°æ•°æ®ã€‚ä½¿ **sigmoid(xdataï¼Œ*popt)** - **ydata** çš„æ®‹å·®å¹³æ–¹å’Œæœ€å°çš„å‚æ•°çš„æœ€ä½³å€¼ã€‚popt æ˜¯æˆ‘ä»¬ä¼˜åŒ–çš„å‚æ•°ã€‚

```
# Lets normalize our data
**xdata =x_data/max(x_data)
ydata =y_data/max(y_data)****from scipy.optimize import curve_fit
popt, pcov = curve_fit(sigmoid, xdata, ydata)**# Now we plot our resulting regression model.
**x = np.linspace(1960, 2015, 55)
x = x/max(x)
plt.figure(figsize=(8,5))
y = sigmoid(x, *popt)
plt.plot(xdata, ydata, 'ro', label='data')
plt.plot(x,y, linewidth=3.0, label='fit')
plt.legend(loc='best')
plt.ylabel('GDP')
plt.xlabel('Year')
plt.show()**
```

![](img/5586c01a20bb92357010c2e78feb0a59.png)

# **æˆ‘ä»¬æ¨¡å‹çš„è®¡ç®—ç²¾åº¦ï¼Ÿ**

```
# split data into train/test
**msk = np.random.rand(len(df)) < 0.8
train_x = xdata[msk]
test_x = xdata[~msk]
train_y = ydata[msk]
test_y = ydata[~msk]**# build the model using train set
**popt, pcov = curve_fit(sigmoid, train_x, train_y)**# predict using test set
**y_hat = sigmoid(test_x, *popt)**# evaluation
**print("Mean absolute error: %.2f" % np.mean(np.absolute(y_hat - test_y)))
print("Residual sum of squares (MSE): %.2f" % np.mean((y_hat - test_y) ** 2))
from sklearn.metrics import r2_score
print("R2-score: %.2f" % r2_score(y_hat , test_y)**
```

> **å¹³å‡ç»å¯¹è¯¯å·®:0.05
> æ®‹å·®å¹³æ–¹å’Œ(MSE): 0.00
> R2 è¯„åˆ†:0.95**

# æ„Ÿè°¢é˜…è¯»

æ›´å¤šæ­¤ç±»å†…å®¹[ç‚¹å‡»æ­¤å¤„](/@kalamanoj989)å¹¶å…³æ³¨æˆ‘ã€‚