<html>
<head>
<title>Overfitting vs. Data Leakage in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的过拟合与数据泄漏</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/overfitting-vs-data-leakage-in-machine-learning-ec59baa603e1?source=collection_archive---------2-----------------------#2021-03-19">https://medium.com/analytics-vidhya/overfitting-vs-data-leakage-in-machine-learning-ec59baa603e1?source=collection_archive---------2-----------------------#2021-03-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/c33533cbbb01e80d409f341bf4d3d4cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X6PLA8BfLPvbD2OtmFerJg.jpeg"/></div></div></figure><p id="e773" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">构建机器学习(ML)模型并不总是直截了当的，工作流可以被封装成几个清晰的步骤，包括数据收集和准备、模型训练和评估以及模型部署。然而，为了将我们的ML模型部署到生产中，实现高精度并不是我们应该依赖的测量模型性能的唯一正确的方法。过于乐观的准确性结果可能表明有猫腻。但是我们如何知道背后的问题呢？嗯，大多数ML从业者应该熟悉过度拟合，这是我们可能遇到的一个问题，或者可能是数据泄漏。</p><p id="f1e0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">更进一步的问题是在ML中这两个术语之间是否有区别？我记得有一次我遇到了数据泄露问题，我的一个同事让我只说“过拟合”而不是“数据泄露”，因为简单地说数据泄露就是过拟合。这就是我写这篇文章的原因。但是首先，为了正确地解决这个问题，让我们回忆一下过度拟合的定义。</p><h1 id="8321" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">什么是过度拟合？</h1><figure class="km kn ko kp fd ii er es paragraph-image"><div class="er es kl"><img src="../Images/a349e0c5ed53073bd8cd6b1d26a3c5bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*woAsnd94ExVcatrKsfybow.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">过度拟合时训练和验证/测试精度之间的差异[2]</figcaption></figure><p id="108c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了评估特定ML模型的性能，我们总是将数据分成两组，包括训练和测试子集。该算法在训练数据集上进行训练，并在测试数据集上进行评估/测试，然后应用(部署到生产中)对新的(看不见的)数据点进行预测。当模型在训练数据上表现太好，但在新数据点上表现不佳时，就会发生过度拟合，而目标是最大化它在看不见的数据点上的准确性(我们不只是希望它从数据中学习)。这意味着该模型不能推广到看不见的数据(即，经过训练的模型不能适应新数据)。</p><h1 id="3b47" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">什么是数据泄露？</h1></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><blockquote class="lb"><p id="3fc9" class="lc ld hh bd le lf lg lh li lj lk jm dx translated"><em class="ll">“当你用来训练一个机器学习算法的数据恰好拥有你试图预测的信息时”。</em></p><p id="2b7e" class="lc ld hh bd le lf lg lh li lj lk jm dx translated"><em class="ll">——</em>丹尼尔·d·古铁雷斯</p></blockquote></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><p id="6f1d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">数据泄漏被认为是机器学习[1]中的“十大错误之一”，当训练数据集中的一个数据点的信息泄漏/引入时，就会发生这种情况，该数据点在训练阶段是不可获得的(即，测试数据集意外包含在训练数据集中)。</p><h1 id="319f" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">过度拟合与数据泄漏</h1><p id="a883" class="pw-post-body-paragraph ip iq hh ir b is lm iu iv iw ln iy iz ja lo jc jd je lp jg jh ji lq jk jl jm ha bi translated">经过上述定义后，区别是否清晰？如果没有，我们在这里对比一下。</p><p id="7df8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当数据泄漏发生时，可能会导致过度拟合(过于乐观的训练精度)，但该模型在测试数据上也表现得太好。正如我们提到的，数据点从测试集泄露到训练集，这意味着模型将预测它学习/看到的东西(但我们认为它是看不见的数据点)，而过度拟合可能导致预测模型的泛化性能较差。</p><h1 id="4095" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">为什么了解ML中过度拟合和数据泄漏的区别很重要？</h1></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><blockquote class="lb"><p id="20c1" class="lc ld hh bd le lf lg lh li lj lk jm dx translated">“所有的生活都是解决问题”。— <em class="ll">卡尔·波普尔</em></p></blockquote></div><div class="ab cl ku kv go kw" role="separator"><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz la"/><span class="kx bw bk ky kz"/></div><div class="ha hb hc hd he"><p id="41a1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你在考试，理解问题有多重要？嗯，我确实相信正确理解问题是正确答案的50%。在解决任何领域的问题时，这种想法都是相似的，重要的是确定和识别问题/原因，以便选择和正确实施解决方案。了解过度拟合和数据泄漏之间的区别可以节省时间和资源，并有助于更快地做出决策。</p><h1 id="a696" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">关于过度拟合的进一步阅读</h1><ol class=""><li id="7104" class="lr ls hh ir b is lm iw ln ja lt je lu ji lv jm lw lx ly lz bi translated"><a class="ae ma" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">过拟合</a></li><li id="cc76" class="lr ls hh ir b is mb iw mc ja md je me ji mf jm lw lx ly lz bi translated">Vezhnevets，亚历山大，和奥尔加巴里诺瓦。"通过去除混淆样本来避免过度拟合."<em class="mg">欧洲机器学习会议</em>。施普林格，柏林，海德堡，2007。</li><li id="2afe" class="lr ls hh ir b is mb iw mc ja md je me ji mf jm lw lx ly lz bi translated"><em class="mg">提示7:最小化过度拟合</em>。d .奇克科(2017年12月)。<a class="ae ma" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5721660" rel="noopener ugc nofollow" target="_blank">“计算生物学中机器学习的十个快速技巧”</a></li></ol><h1 id="5f8f" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">关于数据泄漏的进一步阅读</h1><ol class=""><li id="65e7" class="lr ls hh ir b is lm iw ln ja lt je lu ji lv jm lw lx ly lz bi translated"><a class="ae ma" href="https://machinelearningmastery.com/data-preparation-without-data-leakage/" rel="noopener ugc nofollow" target="_blank">数据准备时如何避免数据泄露</a></li><li id="565c" class="lr ls hh ir b is mb iw mc ja md je me ji mf jm lw lx ly lz bi translated">瑞安马克。<em class="mg">结构化数据深度学习</em>。曼宁出版公司，2020。</li><li id="2e90" class="lr ls hh ir b is mb iw mc ja md je me ji mf jm lw lx ly lz bi translated">丹尼尔·古铁雷斯..机器学习和数据科学:统计学习方法介绍，美国，工艺出版社，2015年。</li></ol><h1 id="a50e" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="773a" class="pw-post-body-paragraph ip iq hh ir b is lm iu iv iw ln iy iz ja lo jc jd je lp jg jh ji lq jk jl jm ha bi translated">过度拟合和数据泄漏都是机器学习中严重而重要的问题，因为它们都呈现误导性的结果，因为如果它们被部署在现实世界中，它们可能具有戏剧性的影响。</p><p id="d927" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">你对数据泄露或这篇文章有什么问题吗？请在评论中提出你的问题，我会尽力回答。</p><h1 id="2390" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">参考</h1><p id="18e4" class="pw-post-body-paragraph ip iq hh ir b is lm iu iv iw ln iy iz ja lo jc jd je lp jg jh ji lq jk jl jm ha bi translated">[1]尼斯贝特、罗伯特、约翰·埃尔德和加里·迈纳。<a class="ae ma" href="https://books.google.ca/books?hl=en&amp;lr=&amp;id=U5np34a5fmQC&amp;oi=fnd&amp;pg=PP1&amp;dq=Nisbet,+R.,+Elder,+J.+and+Miner,+G.+2009.+Handbook+of+Statistical+Analysis+and+Data+Mining+Applications.+Academic+Press.&amp;ots=Ss_-ERBhGK&amp;sig=f60wYYOuBekf9JRKzA21BwBJAA8&amp;redir_esc=y#v=onepage&amp;q=Nisbet%2C%20R.%2C%20Elder%2C%20J.%20and%20Miner%2C%20G.%202009.%20Handbook%20of%20Statistical%20Analysis%20and%20Data%20Mining%20Applications.%20Academic%20Press.&amp;f=false" rel="noopener ugc nofollow" target="_blank"> <em class="mg">统计分析与数据挖掘应用手册</em> </a>。学术出版社，2009年。</p><p id="2dbb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[2] <a class="ae ma" href="https://aigeekprogrammer.com/convnets-and-overfitting/" rel="noopener ugc nofollow" target="_blank">卷积神经网络3:卷积神经网络和过拟合</a></p></div></div>    
</body>
</html>