<html>
<head>
<title>UP-DETR: Unsupervised Pre-training for Object Detection with Transformers (A Review)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">UP-DETR:用变形金刚进行目标检测的无监督预训练(综述)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/up-detr-unsupervised-pre-training-for-object-detection-with-transformers-a-review-c4b996e12a9c?source=collection_archive---------3-----------------------#2021-09-23">https://medium.com/analytics-vidhya/up-detr-unsupervised-pre-training-for-object-detection-with-transformers-a-review-c4b996e12a9c?source=collection_archive---------3-----------------------#2021-09-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="029a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">无人监管的预训练，拯救世界！</p></div><div class="ab cl jc jd go je" role="separator"><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh ji"/><span class="jf bw bk jg jh"/></div><div class="ha hb hc hd he"><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es jj"><img src="../Images/462b760dba024d09d206019eabd3b148.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vmkYxdm504B8h_MwZWuKQQ.jpeg"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated"><a class="ae jz" href="https://towardsdatascience.com/explained-deep-learning-in-tensorflow-chapter-0-acae8112a98" rel="noopener" target="_blank">来源</a></figcaption></figure><p id="b294" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">来自SCTU<em class="ka">和中国腾讯微信人工智能</em>的研究人员提出了<a class="ae jz" href="https://arxiv.org/abs/2011.09094" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> UP-DETR </strong> </a>，这是一种用于物体检测的无监督学习方法，将在本文中进行探索。它是由<em class="ka">脸书艾提出的<a class="ae jz" href="https://arxiv.org/abs/2005.12872" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi"/></a>物体检测方法的一个进步。</em></p><p id="7add" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">受自然语言处理中预训练变形金刚</strong>的巨大成功的启发，UP-DETR的作者提出了一个名为随机查询补丁检测的托词任务来无监督地预训练DETR (UP-DETR)用于对象检测。</p><blockquote class="kb kc kd"><p id="5973" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated">在深入研究UP-DETR的内部工作原理之前，理解变形金刚在深度学习中的作用以及为什么计算机视觉任务需要它们是很重要的。</p></blockquote><h1 id="b2c2" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak"> 1。你需要的只是关注</strong></h1><p id="deac" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">2017年，Vaswani等人(<em class="ka">来自谷歌</em>)提出了一种网络架构，<a class="ae jz" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">变压器</strong> </a>，完全基于注意力机制，完全免除了递归和卷积。该模型在机器翻译任务中表现出色，同时还确保了促进更快训练的并行化能力。</p><p id="c392" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于捕获长期相关性，在序列到序列任务中，如NLP递归神经网络工作良好，但由于顺序计算，它们很慢，并且容易遭受消失/爆炸梯度问题。</p><blockquote class="lk"><p id="783f" class="ll lm hh bd ln lo lp lq lr ls lt jb dx translated">即使变形金刚不使用任何循环单元，它们实际上是如何捕捉长期依赖模式的，你可能想知道！在1.2中回答..3…</p><p id="06d7" class="ll lm hh bd ln lo lp lq lr ls lt jb dx translated">“注意”机制。</p></blockquote><figure class="lv lw lx ly lz jo er es paragraph-image"><div class="er es lu"><img src="../Images/47171209ed15eb0b810a5d0226780eb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*6nbWN5an1woAy6L4O7QRFA.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">来源:<a class="ae jz" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><p id="aa8f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi ma translated">不能告诉你把注意力机制当作一个黑匣子来深入理解变压器的工作，我强烈推荐你阅读<strong class="ig hi"> Jay Alammar </strong> <a class="ae jz" href="http://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">文章</strong> </a>(用直观教具很好地解释)</p><p id="e602" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">了解<strong class="ig hi">查询(Q)、键(K)和值(V) </strong>向量的作用是很重要的。</p><p id="86d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">要进一步了解《注意力是你所需要的全部》一文，请观看视频。</p><figure class="jk jl jm jn fd jo"><div class="bz dy l di"><div class="mb mc l"/></div></figure><h1 id="a2dc" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">2.为什么视觉任务需要变形金刚？</h1><p id="517f" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">与RNNs相比，转换器允许对输入序列元素之间的长相关性进行建模，并支持序列的<strong class="ig hi">并行处理</strong>。变形金刚的<strong class="ig hi">简单的设计</strong>允许它们使用类似的处理模块处理多种模态(例如，图像、视频、文本和语音),并展示了<strong class="ig hi">对超大容量网络和海量数据集的卓越可扩展性</strong>。这些优势已经在涉及变压器网络的各种视觉任务上取得了令人兴奋的进展。— <a class="ae jz" href="https://arxiv.org/abs/2101.01169" rel="noopener ugc nofollow" target="_blank">链接</a></p><h1 id="732c" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak"> 3。DETR(简单回顾)</strong></h1><p id="368e" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">2020年提出的方法使用变换器编码器-解码器架构将对象检测作为集合预测问题来处理。它利用全局损失，通过二分匹配强制进行唯一的预测-给定固定的一小组学习对象查询，DETR推理关于对象和全局图像上下文的关系，以直接并行输出最终的预测集。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es md"><img src="../Images/ea94de216130250c5a5f9ae7cefcb5bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*ViuDWBoyn0JwsyqMnTlp6w.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated"><a class="ae jz" href="https://arxiv.org/pdf/2005.12872.pdf" rel="noopener ugc nofollow" target="_blank">图二:DETR </a></figcaption></figure><p id="d06e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">DETR是一种监督学习方法，它给出n组预测作为输出。这里<a class="ae jz" href="https://www.geeksforgeeks.org/maximum-bipartite-matching/" rel="noopener ugc nofollow" target="_blank">二分匹配</a>损失在确保单个对象不会在单个图像输入中被多次检测到方面起着关键作用。</p><blockquote class="kb kc kd"><p id="d791" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="hh">值得注意的是，该损失函数考虑了边界框的分类损失和回归损失。</em> </strong></p><p id="7827" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated">1.假设给定的输入图像具有<strong class="ig hi"> 2 </strong>标记的地面实况对象。2.假设DETR的总预测数(N)为<strong class="ig hi"> 4 </strong></p><p id="9598" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated">这个<strong class="ig hi">损失函数</strong>将试图鼓励模型进行预测，使得它给出两个具有它们的类和边界框的预测以及两个没有类的预测。否则会受到惩罚。</p></blockquote><h1 id="1470" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">4.无监督预训练</h1><p id="bba1" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">由于目标函数的局部最优和复杂模型的过拟合倾向，深度前馈神经网络训练可能是困难的。无监督预训练是从使用无监督标准(如深度信任网络或深度自动编码器)训练的神经网络开始辨别神经网络的过程。这种方法有时有助于优化。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es me"><img src="../Images/2231365df1a554073c8611bc5d7a6ad3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*eAMu7htA8flTLclMeN1kkA.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">来源:<a class="ae jz" href="https://iq.opengenus.org/applications-of-autoencoders/" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><p id="1efa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个想法简单明了。我们不是随机初始化权重，而是针对某项任务对它们进行预训练(通常是自动编码器中的特征重构)，然后固定权重。然后，我们针对下游任务对其进行微调(<strong class="ig hi">从特征空间中更有利的区域开始，以便模型比随机初始化其权重时学习得更快</strong></p><h1 id="1d77" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">4.上DETR</h1><blockquote class="lk"><p id="e3da" class="ll lm hh bd ln lo lp lq lr ls lt jb dx translated">主图开始…</p></blockquote><p id="e56e" class="pw-post-body-paragraph ie if hh ig b ih mf ij ik il mg in io ip mh ir is it mi iv iw ix mj iz ja jb ha bi translated">UPDETR方法，从给定的图像中随机裁剪面片，然后将它们作为查询提供给解码器。该模型被预先训练以从原始图像中检测这些查询补丁。预处理中的两个关键问题如下。</p><ol class=""><li id="b555" class="mk ml hh ig b ih ii il im ip mm it mn ix mo jb mp mq mr ms bi translated">多任务学习。</li><li id="49af" class="mk ml hh ig b ih mt il mu ip mv it mw ix mx jb mp mq mr ms bi translated">多查询本地化。</li></ol><p id="e5fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">UP-DETR认为，尽管DETR在目标检测任务上表现良好，但它在训练和优化方面存在障碍，这需要大规模的训练数据和相对较长的训练时间表。</p><p id="7ffe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可以从下图中推断出，UP-DETR需要更少的时间来收敛，并且从长远来看表现良好，很明显，DETR在PASCAL VOC [ <a class="ae jz" href="https://cv.gluon.ai/build/examples_datasets/pascal_voc.html#:~:text=Pascal%20VOC%20is%20a%20collection,and%202007%20test%20for%20validation.&amp;text=The%20total%20time%20to%20prepare,Internet%20speed%20and%20disk%20performance." rel="noopener ugc nofollow" target="_blank"> link </a>中表现不佳，其训练数据和实例相对少于COCO [ <a class="ae jz" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> link </a></p><p id="41d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这表明在训练数据不足的情况下，变压器的预训练是必不可少的</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es my"><img src="../Images/86e504e0130e324a08cb211bc807fcbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CQE1vAG1BqEAxAA-kdghlA.png"/></div></div></figure><blockquote class="kb kc kd"><p id="30c7" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated">多任务学习</p></blockquote><p id="4008" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">简单地说，目标分类和定位的结合称为目标检测。</p><p id="df17" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了防止查询补丁检测破坏分类特征，引入了保持变压器特征区分的<strong class="ig hi"> <em class="ka">冻结预训练骨干</em> </strong>和<strong class="ig hi"> <em class="ka">补丁特征重构</em> </strong>。</p><p id="c18f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，消融研究表明<strong class="ig hi">冻结CNN主干</strong>在预训练阶段对特征辨别起着重要作用。</p><blockquote class="kb kc kd"><p id="c68d" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated">多查询本地化</p></blockquote><p id="629c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不同的对象查询集中于不同的位置区域和盒子大小。提出了一个简单的单查询预训练，并扩展到多查询版本，以证明这一性质。</p><p id="2d77" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">引入对象查询混洗和注意屏蔽来解决多查询补丁中查询补丁和对象查询之间的分配问题。</p><h1 id="dce1" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak">两阶段攻击！</strong></h1><p id="f698" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">以无人监管的方式对变压器进行预处理。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es mz"><img src="../Images/e553037be5902225ee420d2707a8ab76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*73_1R2PPH0bKxPvSnoc6fw.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated"><a class="ae jz" href="https://www.enjoyalgorithms.com/blogs/supervised-unsupervised-and-semisupervised-learning" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="a199" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">UP-DETR在没有任何标签的<strong class="ig hi"> ImageNet </strong>训练集上进行了预训练。CNN骨干网(ResNet-50)是用SwAV预先训练的</p><p id="0f39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> II) </strong> <strong class="ig hi">微调</strong></p><p id="b497" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该模型通过预训练上行DETR参数进行初始化，并利用标记数据针对VOC和COCO上的所有参数(包括CNN)进行微调。</p><p id="b939" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如前所述，这个阶段从一个有利的特征空间开始，因此它表现良好，收敛良好。</p><p id="78b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该模型用150/300个时期的短/长时间表进行微调，学习率分别在100/200个时期乘以0.1。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es na"><img src="../Images/07bcc7d3dccbe3cdfd565c6759fb5e87.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/1*iDYuAOgV1LIMLweOPFmHCQ.gif"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated"><a class="ae jz" href="https://g-stat.com/optimization-gradients-overview/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="fa01" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">架构细节</h1><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es nb"><img src="../Images/0d7c42b5ca1383afcdf222b570f2704b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/format:webp/1*Sd1bJlK8WJ9cBFP3eVcvBg.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">来源:<a class="ae jz" href="https://arxiv.org/pdf/2011.09094.pdf" rel="noopener ugc nofollow" target="_blank">链接</a></figcaption></figure><p id="c8db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如您所见，输入图像首先通过CNN主干网，以提取特征映射(f ),该映射被添加到位置编码中，并被送入多个transformer编码器层。编码器的输出馈入解码器。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es nc"><img src="../Images/6fd310d18813e87fb2ce4ca31ab14c2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:174/format:webp/1*1A5lZW0S9Kat_koeFguPdQ.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">c =通道；h =高度；w =宽度</figcaption></figure><p id="2fba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">来自相同输入图像的随机裁剪的查询补丁被馈送到具有GAP(全局平均池)的CNN主干中，使得它给出补丁特征(p ),该特征然后与相同维度的对象查询相加，以馈送到解码器中。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es nd"><img src="../Images/cb1f3e15e9011d8aae88288eef01d893.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*61ac02s8mQL1HUzey9hrIQ.png"/></div></div><figcaption class="jv jw et er es jx jy bd b be z dx translated"><a class="ae jz" href="https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="daae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有N个对象查询。当模型被训练时，这些是可学习的。</p><blockquote class="kb kc kd"><p id="2a69" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated">"对象查询的作用就像是一群人<strong class="ig hi"/>"</p><p id="09a6" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated">这些家伙将负责询问某个位置和盒子大小[这反过来将有助于模型]根据它给出预测。</p></blockquote><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es ne"><img src="../Images/7428b448a8502b02f139c8a7656970e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/1*4sPcIQnrrKU-TLgO72Unsg.gif"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated">😆对象查询-动物园动物园</figcaption></figure><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es nf"><img src="../Images/bde2a6414d209f69dce13595f7d60793.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*M2i574F_qX2jDef95h3tBw.png"/></div><figcaption class="jv jw et er es jx jy bd b be z dx translated"><a class="ae jz" href="https://arxiv.org/pdf/2005.12872v3.pdf" rel="noopener ugc nofollow" target="_blank">摘自DETR论文</a></figcaption></figure><p id="eb43" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">损失函数</strong></p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es ng"><img src="../Images/f02dbcbf7339dd437628d9c0dc7cbaab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*tC0PkF2bXDMbi-j5Nx4h7w.png"/></div></figure><blockquote class="kb kc kd"><p id="6aec" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated">对于训练前阶段的损失计算；预测结果由三个要素组成。</p><p id="27e5" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated"><strong class="ig hi">cˇI</strong>= =&gt;对每个对象查询的<strong class="ig hi">匹配或不匹配</strong>的二元分类</p><p id="b472" class="ie if ka ig b ih ii ij ik il im in io ke iq ir is kf iu iv iw kg iy iz ja jb ha bi translated"><strong class="ig hi">b\i</strong>= =&gt;定义框中心坐标的向量<strong class="ig hi"> {x，y，w，h }</strong><br/><br/><strong class="ig hi">p\i</strong>= =&gt;ResNet-50主干的C = 2048的重构特征</p></blockquote><p id="d07c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">L rec 分量是本文提出的重建损失，用于在无监督预训练期间平衡分类和定位。保持特征区分的L2归一化面片特征之间的均方误差。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es nh"><img src="../Images/87f63b21d7460bbda423d26496a9566d.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*4BGJ33D2tE3l1td2Kz43gA.png"/></div></figure><p id="2025" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于多查询补丁，</p><p id="4054" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们有<strong class="ig hi">“M”</strong>个查询片和<strong class="ig hi">“N”</strong>个对象查询，那么我们将N个对象查询分成M个组，其中每个查询片被分配给N/M个对象查询。</p><p id="4ece" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作者假设了更好的泛化的两个要求<br/> <strong class="ig hi"> i)查询补丁的独立性(注意力屏蔽)ii)对象查询的多样性(对象查询混洗)</strong></p><p id="d299" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了满足查询补丁的独立性，我们利用注意屏蔽矩阵来控制不同对象查询之间的交互。</p><p id="212c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了模拟对象查询之间的隐式组分配，我们在预训练期间随机打乱所有对象查询嵌入的排列。10%的查询补丁在预训练期间被屏蔽为零，类似于退出。在他们的进一步研究中，“对象查询混洗是没有帮助的”</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es ni"><img src="../Images/0ce58d7784e3e622324aec27243b5494.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*IvPOI1thmOJz9WJNJx0Tdw.png"/></div></figure><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es nj"><img src="../Images/d34f8885360e1f5de0f897fbe7ed7190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*pjYQTtYZpmo-lrQz6cHFVA.png"/></div></figure><p id="23f5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">结果表明，即使有足够的训练数据(即COCO上的18K图像),预训练变压器仍然是不可或缺的</strong></p><p id="1d06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">UP-DETR的结果被进一步扩展用于单镜头检测和全景分割，并且它似乎也在这些任务中全面地执行。</p><p id="44c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下曲线和结果总结了无监督方法的重要性。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es nk"><img src="../Images/afcc265608c05c3cbdd507e55079846a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*smdteLX1bKTEbZL0n84KMw.png"/></div></div></figure><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es nl"><img src="../Images/909eb77ab7ac730f4e7c70a9ca320791.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*B-Y7F14I5zsrMcAbRm4-BA.png"/></div></figure><p id="9e2f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过无监督的预训练，UP-DETR在对象检测、单镜头检测和全景分割方面明显优于DETR。</p><h1 id="c565" class="kh ki hh bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">参考</h1><ol class=""><li id="8a56" class="mk ml hh ig b ih lf il lg ip nm it nn ix no jb mp mq mr ms bi translated"><a class="ae jz" href="https://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank">图解变压器——杰伊·阿拉玛</a></li><li id="b75d" class="mk ml hh ig b ih mt il mu ip mv it mw ix mx jb mp mq mr ms bi translated"><a class="ae jz" href="https://arxiv.org/abs/2005.12872" rel="noopener ugc nofollow" target="_blank">使用变压器的端到端物体检测</a></li><li id="7948" class="mk ml hh ig b ih mt il mu ip mv it mw ix mx jb mp mq mr ms bi translated"><a class="ae jz" href="https://arxiv.org/abs/2011.09094" rel="noopener ugc nofollow" target="_blank">上DETR:用变形金刚进行物体检测的无监督预训练</a></li><li id="49b2" class="mk ml hh ig b ih mt il mu ip mv it mw ix mx jb mp mq mr ms bi translated"><a class="ae jz" href="https://www.geeksforgeeks.org/maximum-bipartite-matching/" rel="noopener ugc nofollow" target="_blank">最大二部匹配— Geeksforgeeks </a></li></ol><blockquote class="lk"><p id="1c02" class="ll lm hh bd ln lo np nq nr ns nt jb dx translated">下次见！</p></blockquote><blockquote class="kb kc kd"><p id="89bc" class="ie if ka ig b ih mf ij ik il mg in io ke mh ir is kf mi iv iw kg mj iz ja jb ha bi translated"><strong class="ig hi">在LinkedIn上联系我<br/></strong>linkedin.com/in/praveenkumar-rajendran/</p></blockquote></div></div>    
</body>
</html>