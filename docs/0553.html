<html>
<head>
<title>Risk Prediction for Type II Diabetes (Random Forest Model in Python)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">II型糖尿病的风险预测(Python中的随机森林模型)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/risk-prediction-models-for-type-ii-diabetes-random-forest-model-in-python-a512b13da26c?source=collection_archive---------6-----------------------#2021-01-21">https://medium.com/analytics-vidhya/risk-prediction-models-for-type-ii-diabetes-random-forest-model-in-python-a512b13da26c?source=collection_archive---------6-----------------------#2021-01-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="fb16" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jc translated">在萨福克大学的商业分析硕士课程中，我们有一门Python入门课，这是数据分析的一个组成部分。我们已经讨论了Python开发环境、语法和基础。然后，用熊猫文库进行探索性数据分析和假设检验。在所有的基础知识之后，我们深入到主要的统计概念和模型，如线性回归、训练-测试分割、偏差-方差权衡、K-最近邻(KNN)和分类。然后，我们学习了逻辑回归、决策树，最后我们学习了数据API和时间序列介绍。我们的核心书籍是由Andreas C. Müller &amp; Sarah Guido所著的<a class="ae jl" href="https://www.amazon.com/Introduction-Machine-Learning-Python-Scientists/dp/1449369413" rel="noopener ugc nofollow" target="_blank">《Python机器学习导论》。</a></p><p id="cff3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章将描述我在本课程结束时完成的最终项目。该项目基于两项研究<a class="ae jl" href="https://www.cdc.gov/pcd/issues/2019/pdf/19_0109.pdf" rel="noopener ugc nofollow" target="_blank">“使用机器学习技术为二型糖尿病构建风险预测模型”，作者分别是谢Z、尼古拉耶娃O、罗J、李D. </a>和<a class="ae jl" href="https://bmcmedicine.biomedcentral.com/track/pdf/10.1186/1741-7015-9-103" rel="noopener ugc nofollow" target="_blank">“为二型糖尿病开发风险预测模型:方法和报告的系统回顾”由柯林斯GS，马利特S，奥马尔O，余LM。</a></p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jm"><img src="../Images/d5223720859ba8f1614e2cbdbdca0f16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RZDNuaMALLVpf8ztXSsc3Q.jpeg"/></div></div></figure><p id="f8e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">用于分析的数据来自<a class="ae jl" href="https://www.cdc.gov/brfss/index.html" rel="noopener ugc nofollow" target="_blank">行为风险因素监测系统(BRFSS) </a>，该系统收集美国居民健康相关的电话调查数据。由于BRFSS调查数据文件的格式不同于csv格式，我使用了github上的Winston Larson的作品，他在github上做了大量的BRFSS数据提取和清理工作。</p><p id="009c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2014年的原始数据有279个变量和464，644条记录。基于上面提到的同行评议文章，我选择了26个主要的个人和一般健康相关特征，如一般健康、身体质量指数、年龄、睡眠时间等。目标变量表示对“您是否被告知患有糖尿病？”的回答为<em class="jy">是</em>或<em class="jy">否</em>的二元分类问题。源代码可以在<a class="ae jl" href="https://github.com/asoloveva/Random_Forest_Modeling_BFRSS_Data_Type2_Diabetes/blob/master/Random%20Forest(CDC%20Project).ipynb" rel="noopener ugc nofollow" target="_blank">链接</a>中查看。</p><h1 id="f4b0" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">清洁</h1><p id="e06e" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">第一步，我们排除30岁以下可能患有1型糖尿病的人，怀孕的人和患有前期糖尿病的人，这些人不是我们的主要关注点。下一步，我们永久删除NA值，剩下143，383个观察值供我们分析，我们运行<em class="jy">描述</em>函数，在<em class="jy"> </em> NA值删除<em class="jy">后，检查数据<em class="jy"> </em>的汇总统计。</em>此外，我们为每个变量构建了一个直方图，以验证它们是否正态分布。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="61c4" class="lh ka hh ld b fi li lj l lk ll"><em class="jy"># Dropping permanently NA values and run summary statistics</em><br/>df.dropna(inplace=<strong class="ld hi">True</strong>)<br/>df.describe()<br/>df.hist(figsize=(20,20))</span></pre><p id="212c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是检查我们的数据是否平衡，当我们的目标变量在一个类别中的相对频率比另一个类别中的相对频率低时，这是推荐的(对于我们的主要问题“您是否被告知患有糖尿病？”)</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="56f5" class="lh ka hh ld b fi li lj l lk ll"># Is our data balanced? It is!<br/>df.diabete3.value_counts(normalize=<strong class="ld hi">True</strong>)</span></pre><p id="a45e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">来自Pandas库的上述<em class="jy"> value_counts </em>函数产生包含唯一值计数的比率。在我们的例子中，它给出了以下比率:0.83人回答<em class="jy">否</em>，0.16人回答<em class="jy">是</em>。最好有一个10%左右的平衡比例，或者使用基于Daniel T.Larose的书<em class="jy">“发现数据中的知识-数据挖掘简介”</em>的重采样技术</p><p id="96d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们验证了我们的数据是平衡的，有16%的比例后，我们将我们的特征(个人和健康信息)分配给X，将我们的目标变量(是或否答案)分配给y。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="e164" class="lh ka hh ld b fi li lj l lk ll">feature_cols =['genhlth','age','bmi_class','checkup1','income2','race','mscode','flushot6','employ1','sex','marital','education','sleptim1','cvdcrhd4','hlthcvr1','menthlth','chckidny','useequip','exercise','addepev2','renthom1','exerany2','blind','decide','hlthpln1','smoker']<br/><br/>X = df[feature_cols]<br/>y = df.diabete3</span></pre><h1 id="baef" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">创建训练和测试数据</h1><p id="b152" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">下一步是将数据分成两个数据集，即训练数据集和测试数据集。对于这些数据，我使用70/30的方法，留下30%的数据用于测试。Sikit-learn库有一个函数<em class="jy"> train_test_split </em>，该函数<em class="jy"> </em>随机拆分训练集和测试集上的数据。随机状态参数设置为50，用于控制估计器的随机性。(简单地说，每次运行模型时，我们都会得到相同的随机精确分割，并且每次运行都不会不同)。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="de5a" class="lh ka hh ld b fi li lj l lk ll">X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 50, test_size=0.3)</span></pre><h1 id="da79" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">决策树模型</h1><p id="cac7" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">首先创建一个简单的决策树模型，以便在最后将其与随机森林模型进行比较。Sikit-learn库有一个<em class="jy">决策树分类器</em>函数，用于创建一个决策树分类器，然后拟合训练数据。用来衡量分割质量的默认标准是“基尼系数”。树的最大深度是默认的None(这肯定不是最好的方法；然而，它不会干扰项目的目标)。该功能的其余参数可在<a class="ae jl" href="https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html" rel="noopener ugc nofollow" target="_blank">文档</a>中找到。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="f922" class="lh ka hh ld b fi li lj l lk ll"><em class="jy"># Make a decision tree and train</em><br/>tree = DecisionTreeClassifier(random_state=50)</span><span id="4611" class="lh ka hh ld b fi lm lj l lk ll"><em class="jy"># Train tree</em><br/>tree.fit(X_train, y_train)</span></pre><p id="7c7e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们使用拟合的模型，通过Sikit-learn库中的<em class="jy">预测</em>函数进行预测。该函数获取拟合数据并预测新数据的标签。另一个函数，<em class="jy"> predict_proba，</em>为每个类找到一个概率。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="4f91" class="lh ka hh ld b fi li lj l lk ll"><em class="jy"># Using fitted model and Make predictions</em><br/>X_train_tree_predictions = tree.predict(X_train)<br/>X_train_tree_probs = tree.predict_proba(X_train)[:, 1]</span><span id="4898" class="lh ka hh ld b fi lm lj l lk ll">tree_predictions = tree.predict(X_test)<br/>tree_probs = tree.predict_proba(X_test)[:, 1]</span></pre><p id="5d06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是用<em class="jy"> roc_auc_score </em>函数根据我们的预测得分计算受试者工作特征曲线下的面积(ROC AUC)。它显示了我们的分类模型在所有分类阈值的性能。在我们的例子中，ROC AUC是0.59。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="56b5" class="lh ka hh ld b fi li lj l lk ll"><em class="jy"># Calculate ROC AUC</em><br/>roc_value = roc_auc_score(y_test, tree_probs)</span></pre><p id="a269" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们需要检查哪些特征在预测糖尿病中是最重要的。特征重要性函数确定最重要的特征是一般健康、收入、睡眠时间和年龄。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="9cdb" class="lh ka hh ld b fi li lj l lk ll">feature_tree = pd.DataFrame({'Feature': feature_cols,<br/>                   'Importance': tree.feature_importances_}).\<br/>                    sort_values('Importance', ascending = <strong class="ld hi">False</strong>)</span></pre><p id="6f9c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后一步是进行样本检验，如交叉验证(CV ),以确定我们模型的最终估计。对于该步骤，我们使用<em class="jy"> cross_val_score </em>函数，并将k-folds设置为10，并计算这些交叉验证分数平均值。在我们的例子中，分数是0.76，准确率为76%。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="67c4" class="lh ka hh ld b fi li lj l lk ll">scores = cross_val_score(tree, X, y, cv=10, scoring= 'accuracy')<br/>np.mean(scores)</span></pre><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es ln"><img src="../Images/497f5189d09b0d2a160b43872318b5e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CTPbXDKCUWCwmioXYdACKw.png"/></div></div><figcaption class="lo lp et er es lq lr bd b be z dx translated"><em class="ls">决策树可视化</em></figcaption></figure><h1 id="2be3" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">随机森林模型</h1><p id="fecc" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">随机森林建模过程包括与决策树模型构建过程相似的所有步骤。随机森林是产生具有所有这些树的平均预测的类的树的集合。在我们的例子中，我们构建了100棵树，我们没有指定树的最大深度。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="9e67" class="lh ka hh ld b fi li lj l lk ll"><em class="jy"># Create the model with 100 trees</em><br/>model = RandomForestClassifier(n_estimators=100, max_features='sqrt', oob_score=<strong class="ld hi">True</strong>, random_state=50, n_jobs=-1, verbose = 1)<br/><br/><em class="jy">#Fit the Model on Training data</em><br/>model.fit(X_train, y_train)</span></pre><p id="3c00" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们使用我们的拟合模型进行预测，并找到每一类的概率，就像我们之前对决策树模型所做的那样。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="a6e8" class="lh ka hh ld b fi li lj l lk ll"><em class="jy">#Using fitted model, make predictions</em><br/>X_train_rf_predictions = model.predict(X_train)<br/>X_train_rf_probs = model.predict_proba(X_train)[:, 1]<br/><br/>rf_predictions = model.predict(X_test)<br/>rf_probs = model.predict_proba(X_test)[:, 1]</span></pre><p id="b6bd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是使用<em class="jy"> roc_auc_score </em>函数根据我们的预测得分计算ROC AUC。在这个模型中，ROC AUC是0.78，比我们在决策树模型中得到的要高。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="a405" class="lh ka hh ld b fi li lj l lk ll"><em class="jy"># Calculate ROC AUC</em><br/>roc_value = roc_auc_score(y_test, rf_probs)</span></pre><p id="6765" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们需要检查哪些特征在预测糖尿病中是最重要的。特征重要性函数确定最重要的特征是收入、睡眠时间、年龄和总体健康状况。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="84b4" class="lh ka hh ld b fi li lj l lk ll"><em class="jy"># Compute feature importances</em><br/>feature_model = pd.DataFrame({'Feature': feature_cols,<br/>                   'importance': model.feature_importances_}).\<br/>                    sort_values('importance', ascending = <strong class="ld hi">False</strong>)</span></pre><p id="c16c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后一步是运行交叉验证(CV ),以确定我们模型的最终估计。在随机森林模型中，准确率为0.84，比简单决策树模型高8%。</p><pre class="jn jo jp jq fd lc ld le lf aw lg bi"><span id="6020" class="lh ka hh ld b fi li lj l lk ll">scores = cross_val_score(model, X, y, cv=10, scoring= 'accuracy')<br/>np.mean(scores)</span></pre><p id="8601" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">谢谢你和我一起阅读或完成这个项目！我真的很感谢你在评论中的反馈或使用的其他模型的例子。欢迎任何问题和批评！</p><h1 id="eac2" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">参考</h1><p id="585a" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">[1]谢Z，尼古拉耶娃O，罗J，李d .利用机器学习技术为建立风险预测模型.Prev慢性Dis 201916:190109.http://dx.doi.org/10.5888/pcd16.190109external图标。</p><p id="0a73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[2]柯林斯GS，马利特S，奥马尔O，余LM。为二型糖尿病开发风险预测模型:方法和报告的系统回顾。BMC Med 20119(1):103.<a class="ae jl" href="https://bmcmedicine.biomedcentral.com/articles/10.1186/1741-7015-9-103" rel="noopener ugc nofollow" target="_blank">https://BMC medicine . biomed central . com/articles/10.1186/1741-7015-9-103</a></p><p id="a7c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[3] Larson W .利用疾病预防控制中心的数据对健康和行为的见解。【https://github.com/winstonlarson/brfss T2】号</p><p id="697e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[4]纳尔逊j .决策树。摘自《统计学习导论》第八章。【http://faculty.marshall.usc.edu/gareth-james/ T4】</p></div></div>    
</body>
</html>