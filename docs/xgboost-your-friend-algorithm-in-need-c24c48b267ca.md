# XGBoost:你需要的朋友算法

> 原文：<https://medium.com/analytics-vidhya/xgboost-your-friend-algorithm-in-need-c24c48b267ca?source=collection_archive---------14----------------------->

XGBoost 是梯度推进决策树的高速高性能实现。这是陈天齐创建的梯度推进机器的实现，现在得到了其他开发者的大量支持。它是分布式机器学习社区(DMLC)开发的更大工具集的一部分，该社区还负责有影响力的 mxnet 深度学习库。

XGBoost 是一个软件库，您可以下载并安装到您的设备上，并从一系列不同的界面使用。XGBoost 特别支持以下主要接口:

*   命令行界面(CLI)
*   C++
*   计算机编程语言
*   稀有
*   朱莉娅
*   Java 语言(一种计算机语言，尤用于创建网站)
*   斯卡拉
*   Hadoop

# 特征

该库中几乎没有多余的东西，因为它是基于计算速度和模型效率的激光。但是，它包含了一系列高级功能。

该模型的实现集成了 scikit-learn 和 R 实现的特性，以及正则化等新特性。梯度提升有三种不同的方式:

*   学习率用于梯度推进算法，也称为梯度推进机。
*   利用随机梯度增强，在行、列和每个分割级别进行子采样。
*   正则化梯度增强(RGB)同时使用 L1 和 L2 正则化。

该库提供了一个可用于多种计算环境的框架，包括但不限于:

*   在训练过程中，使用所有 CPU 内核并行构建树。
*   使用机器集群，分布式计算可以用来训练非常大的模型。
*   对于不适合内存的非常大的数据集，使用核外计算。
*   数据结构和算法被缓存以充分利用可用的硬件。

该算法的实现旨在最大限度地利用计算时间和内存资源。为了训练模型，设计目标之一是充分利用可用资源。以下是算法实现的一些主要特征:

*   通过自动处理缺失数据值实现稀疏感知。
*   块结构促进了树构造的并行化。
*   继续训练，以便使用新数据改进已拟合的模型。

# 为什么要用 XGBoost？

## 执行速度

总的来说，XGBoost 很快。与其他梯度增强实现相比，这一个非常快。

**模型性能**

在分类和回归预测建模问题上，XGBoost 主导了结构化或表格化数据集。

梯度推进决策树算法由 XGBoost 库实现。

梯度推进、多重加法回归树、随机梯度推进和梯度推进机器都是用于定义该算法的概念。

Boosting 是一种集成技术，涉及将新模型应用于现有模型以纠正错误。模型是按照逻辑顺序添加的，直到不再需要修改为止。例如，AdaBoost 算法对难以预测的数据点进行加权。

梯度增强是一种涉及创建新模型的技术，这些新模型估计先前模型的残差或误差，然后将这些残差或误差组合起来以做出最终预测。梯度推进得名于这样一个事实，即它使用梯度下降算法来最小化损失，同时引入新的模型。

使用这种技术可以解决回归和分类预测建模问题。