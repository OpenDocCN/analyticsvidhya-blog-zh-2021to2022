<html>
<head>
<title>Responsible AI toolkit for pytorch models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">pytorch模型的负责任的人工智能工具包</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/responsible-ai-toolkit-for-pytorch-models-c1b827c6cfed?source=collection_archive---------5-----------------------#2021-10-25">https://medium.com/analytics-vidhya/responsible-ai-toolkit-for-pytorch-models-c1b827c6cfed?source=collection_archive---------5-----------------------#2021-10-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="a0b7" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">使用pytorch的数据工程和建模</h1><h1 id="f4f3" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">数据工程过程</h1><p id="6d40" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">注意:这只是一个样本演示数据(根本不是真实的)。这里的目的是展示示例代码和逻辑</p><h1 id="1641" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">密码</h1><ul class=""><li id="cb94" class="ka kb hh je b jf jg jj jk jn kc jr kd jv ke jz kf kg kh ki bi translated">为表格数据集编写pytorch代码</li><li id="ed00" class="ka kb hh je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki bi translated">导入库</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="79a4" class="kx if hh kt b fi ky kz l la lb">import torch<br/>from torch.utils.data import Dataset<br/>from torchvision import datasets<br/>from torchvision.transforms import ToTensor<br/>import matplotlib.pyplot as plt</span><span id="7034" class="kx if hh kt b fi lc kz l la lb">import os<br/>import torch<br/>from torch import nn<br/>from torch.utils.data import DataLoader<br/>from torchvision import datasets, transforms</span><span id="df7a" class="kx if hh kt b fi lc kz l la lb">print(torch.__version__)</span><span id="85fd" class="kx if hh kt b fi lc kz l la lb">import pandas as pd<br/>import seaborn as sn</span><span id="43b2" class="kx if hh kt b fi lc kz l la lb">pd.set_option('display.max_columns', None)<br/>pd.set_option('display.max_rows', None)</span><span id="6eb8" class="kx if hh kt b fi lc kz l la lb">df = pd.read_csv('Sample_IssueDataset.csv')</span><span id="a3f3" class="kx if hh kt b fi lc kz l la lb">df.head()</span><span id="5918" class="kx if hh kt b fi lc kz l la lb">df1 = pd.get_dummies(df)</span><span id="e9de" class="kx if hh kt b fi lc kz l la lb">df1.head()</span><span id="2c43" class="kx if hh kt b fi lc kz l la lb">y = df1.iloc[:,1]<br/>X = df1.iloc[:,:18]</span><span id="4d69" class="kx if hh kt b fi lc kz l la lb">X = X.drop(columns=['EmployeeLeft'])</span><span id="012e" class="kx if hh kt b fi lc kz l la lb">from sklearn.model_selection import train_test_split</span><span id="dc5e" class="kx if hh kt b fi lc kz l la lb">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)</span><span id="b500" class="kx if hh kt b fi lc kz l la lb">X_train_torch = torch.tensor(X_train.values)<br/>X_test_torch = torch.tensor(X_test.values)<br/>y_train_torch = torch.tensor(y_train.values)<br/>y_test_torch = torch.tensor(y_test.values)</span><span id="a59a" class="kx if hh kt b fi lc kz l la lb">device = 'cuda' if torch.cuda.is_available() else 'cpu'<br/>print('Using {} device'.format(device))</span><span id="3b20" class="kx if hh kt b fi lc kz l la lb">class NeuralNetwork(nn.Module):<br/>    def __init__(self):<br/>        super(NeuralNetwork, self).__init__()<br/>        self.flatten = nn.Flatten()<br/>        self.linear_relu_stack = nn.Sequential(<br/>            nn.Linear(9380*17, 10),<br/>            nn.ReLU(),<br/>            #nn.Linear(9380*17, 10),<br/>            #nn.ReLU(),<br/>            nn.Linear(9380*17, 10),<br/>        )</span><span id="5636" class="kx if hh kt b fi lc kz l la lb">    def forward(self, x):<br/>        x = self.flatten(x)<br/>        logits = self.linear_relu_stack(x)<br/>        return logits</span><span id="638a" class="kx if hh kt b fi lc kz l la lb">model = NeuralNetwork().to(device)<br/>print(model)</span><span id="0325" class="kx if hh kt b fi lc kz l la lb">print("Model structure: ", model, "\n\n")</span><span id="3581" class="kx if hh kt b fi lc kz l la lb">for name, param in model.named_parameters():<br/>    print(f"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \n")</span><span id="a67d" class="kx if hh kt b fi lc kz l la lb">import torch<br/> <br/>train_features = torch.tensor(X_train.to_numpy())<br/>train_labels = torch.tensor(y_train.to_numpy())<br/> <br/>validation_features = torch.tensor(X_test.to_numpy())<br/>validation_labels = torch.tensor(y_test.to_numpy())</span><span id="4d23" class="kx if hh kt b fi lc kz l la lb">n_features = X_train.shape[1]<br/># 31<br/>model = torch.nn.Sequential(torch.nn.Linear(n_features, 18),<br/>                            torch.nn.ReLU(),<br/>                            torch.nn.Linear(18, 1),<br/>                            torch.nn.Sigmoid())</span><span id="25ce" class="kx if hh kt b fi lc kz l la lb">criterion = torch.nn.BCELoss()<br/> <br/>optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.001)</span><span id="59ae" class="kx if hh kt b fi lc kz l la lb">X_train_torch.shape<br/>y_train_torch.shape</span><span id="25d1" class="kx if hh kt b fi lc kz l la lb">n_batches = 2<br/>train_features_batched = train_features.reshape(n_batches,<br/>                                               int(train_features.shape[0]/n_batches),<br/>                                               train_features.shape[1])<br/>train_labels_batched = train_labels.reshape(n_batches,<br/>                                            int(train_labels.shape[0]/n_batches))</span><span id="8564" class="kx if hh kt b fi lc kz l la lb">n_epochs = 100<br/>loss_list = []<br/>validate_loss_list = []<br/> <br/>for epoch in range(n_epochs):<br/>    for batch_idx in range(n_batches):<br/>        optimizer.zero_grad()<br/>         <br/>        outputs = model(train_features_batched[batch_idx].float())<br/>         <br/>     <br/>        loss = criterion(outputs.flatten().float(),<br/>                         train_labels_batched[batch_idx].float())<br/>     <br/>         <br/>        loss.backward()<br/>         <br/>        optimizer.step()<br/>         <br/>    outputs = model(train_features.float())<br/>     <br/>    validation_outputs = model(validation_features.float())<br/>     <br/>         <br/>    loss = criterion(outputs.flatten().float(),<br/>                     train_labels.float())<br/>     <br/>    validate_loss = criterion(validation_outputs.flatten().float(),<br/>                              validation_labels.float())<br/>     <br/>    loss_list.append(loss.item())<br/>     <br/>    validate_loss_list.append(validate_loss)<br/> <br/>print('Finished Training')<br/> <br/>import matplotlib.pyplot as plt<br/>plt.plot(loss_list, linewidth=3)<br/>plt.plot(validate_loss_list, linewidth=3)<br/>plt.legend(("Training Loss", "Validation Loss"))<br/>plt.xlabel("Epoch")<br/>plt.ylabel("BCE Loss")</span><span id="4103" class="kx if hh kt b fi lc kz l la lb">y_pred = model(validation_features[1].flatten().float())<br/>print(y_pred)</span><span id="05dd" class="kx if hh kt b fi lc kz l la lb">import matplotlib.pyplot as plt<br/>import numpy as np</span><span id="bcb6" class="kx if hh kt b fi lc kz l la lb">type(validation_features.flatten().float())</span><span id="d4b3" class="kx if hh kt b fi lc kz l la lb">model.eval()</span><span id="3484" class="kx if hh kt b fi lc kz l la lb">y_pred = model(validation_features[0].flatten().float())</span><span id="30fc" class="kx if hh kt b fi lc kz l la lb">len(y_pred)</span><span id="a5a8" class="kx if hh kt b fi lc kz l la lb">len(validation_features[0].flatten().float())</span><span id="9ff7" class="kx if hh kt b fi lc kz l la lb">model.train()<br/>epochs = 5<br/>errors = []<br/>for epoch in range(epochs):<br/>    optimizer.zero_grad()<br/>    # Forward pass<br/>    y_pred = model(train_features.float())<br/>    # Compute Loss<br/>    loss = criterion(y_pred.squeeze(), train_labels.float())<br/>    errors.append(loss.item())<br/>    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))<br/>    # Backward pass<br/>    loss.backward()<br/>    optimizer.step()</span><span id="26d1" class="kx if hh kt b fi lc kz l la lb">model.train()<br/>epochs = 500<br/>errors = []<br/>for epoch in range(epochs):<br/>    optimizer.zero_grad()<br/>    # Forward pass<br/>    y_pred = model(validation_features.float())<br/>    # Compute Loss<br/>    loss = criterion(y_pred.squeeze(), validation_labels.float())<br/>    errors.append(loss.item())<br/>    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))<br/>    # Backward pass<br/>    loss.backward()<br/>    optimizer.step()</span><span id="f090" class="kx if hh kt b fi lc kz l la lb">import matplotlib.pyplot as plt<br/>import numpy as np<br/>def plotcharts(errors):<br/>    errors = np.array(errors)<br/>    plt.figure(figsize=(12, 5))<br/>    graf02 = plt.subplot(1, 2, 1) # nrows, ncols, index<br/>    graf02.set_title('Errors')<br/>    plt.plot(errors, '-')<br/>    plt.xlabel('Epochs')<br/>    graf03 = plt.subplot(1, 2, 2)<br/>    graf03.set_title('Tests')<br/>    a = plt.plot(train_labels.numpy(), 'yo', label='Real')<br/>    plt.setp(a, markersize=10)<br/>    a = plt.plot(y_pred.detach().numpy(), 'b+', label='Predicted')<br/>    plt.setp(a, markersize=10)<br/>    plt.legend(loc=7)<br/>    plt.show()<br/>plotcharts(errors)</span><span id="0e7d" class="kx if hh kt b fi lc kz l la lb">model.eval()<br/>y_pred = model(validation_features.float())<br/>after_train = criterion(y_pred.squeeze(), validation_labels.float())<br/>print('Test loss after Training' , after_train.item())</span><span id="3940" class="kx if hh kt b fi lc kz l la lb">import matplotlib.pyplot as plt<br/>import numpy as np<br/>def plotcharts(errors):<br/>    errors = np.array(errors)<br/>    plt.figure(figsize=(12, 5))<br/>    graf02 = plt.subplot(1, 2, 1) # nrows, ncols, index<br/>    graf02.set_title('Errors')<br/>    plt.plot(errors, '-')<br/>    plt.xlabel('Epochs')<br/>    graf03 = plt.subplot(1, 2, 2)<br/>    graf03.set_title('Tests')<br/>    a = plt.plot(train_labels.numpy(), 'yo', label='Real')<br/>    plt.setp(a, markersize=10)<br/>    a = plt.plot(y_pred.detach().numpy(), 'b+', label='Predicted')<br/>    plt.setp(a, markersize=10)<br/>    plt.legend(loc=7)<br/>    plt.show()<br/>plotcharts(errors)</span><span id="52ce" class="kx if hh kt b fi lc kz l la lb">probs = torch.sigmoid(y_pred)<br/>print(probs)</span></pre><ul class=""><li id="02a9" class="ka kb hh je b jf ld jj le jn lf jr lg jv lh jz kf kg kh ki bi translated">现在RAI tooklit实现了</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="0c5f" class="kx if hh kt b fi ky kz l la lb">class WrappedPytorchModel(object):<br/>    """A class for wrapping a PyTorch model in the scikit-learn specification."""</span><span id="395b" class="kx if hh kt b fi lc kz l la lb">    def __init__(self, model):<br/>        """Initialize the PytorchModelWrapper with the model and evaluation function."""<br/>        self._model = model<br/>        # Set eval automatically for user for batchnorm and dropout layers<br/>        self._model.eval()</span><span id="1707" class="kx if hh kt b fi lc kz l la lb">    def predict(self, dataset):<br/>        """Predict the output using the wrapped PyTorch model.<br/>        :param dataset: The dataset to predict on.<br/>        :type dataset: interpret_community.dataset.dataset_wrapper.DatasetWrapper<br/>        """<br/>        # Convert the data to pytorch Variable<br/>        if isinstance(dataset, pd.DataFrame):<br/>            dataset = dataset.values<br/>        wrapped_dataset = torch.Tensor(dataset)<br/>        with torch.no_grad():<br/>            result = self._model(wrapped_dataset).numpy()<br/>        # Reshape to 2D if output is 1D and input has one row<br/>        if len(dataset.shape) == 1:<br/>            result = result.reshape(1, -1)<br/>        return result</span><span id="b729" class="kx if hh kt b fi lc kz l la lb">    def predict_classes(self, dataset):<br/>        """Predict the class using the wrapped PyTorch model.<br/>        :param dataset: The dataset to predict on.<br/>        :type dataset: interpret_community.dataset.dataset_wrapper.DatasetWrapper<br/>        """<br/>        # Convert the data to pytorch Variable<br/>        if isinstance(dataset, pd.DataFrame):<br/>            dataset = dataset.values<br/>        wrapped_dataset = torch.Tensor(dataset)<br/>        with torch.no_grad():<br/>            result = torch.max(self._model(wrapped_dataset), 1)[0].numpy()<br/>        # Reshape to 2D if output is 1D and input has one row<br/>        if len(dataset.shape) == 1:<br/>            result = result.reshape(1, -1)<br/>        return result</span><span id="337b" class="kx if hh kt b fi lc kz l la lb">    def predict_proba(self, dataset):<br/>        """Predict the output probability using the wrapped PyTorch model.<br/>        :param dataset: The dataset to predict_proba on.<br/>        :type dataset: interpret_community.dataset.dataset_wrapper.DatasetWrapper<br/>        """<br/>        return self.predict(dataset)</span><span id="4e34" class="kx if hh kt b fi lc kz l la lb">class WrappedClassificationModel(object):<br/>    """A class for wrapping a classification model."""</span><span id="8e76" class="kx if hh kt b fi lc kz l la lb">    def __init__(self, model, eval_function):<br/>        """Initialize the WrappedClassificationModel with the model and evaluation function."""<br/>        self._eval_function = eval_function<br/>        self._model = model<br/></span><span id="1798" class="kx if hh kt b fi lc kz l la lb">    <br/>    def predict(self, dataset):<br/>        probabilities = self._model.predict_classes(dataset).flatten()<br/>        return [1 if proba &gt; 0.5 else 0 for proba in probabilities]<br/>#        return self._model.predict_classes(dataset).flatten()</span><span id="49e1" class="kx if hh kt b fi lc kz l la lb">    def predict_proba(self, dataset):<br/>        """Predict the output probability using the wrapped model.<br/>        :param dataset: The dataset to predict_proba on.<br/>        :type dataset: interpret_community.dataset.dataset_wrapper.DatasetWrapper<br/>        """<br/>        proba_preds = self._eval_function(dataset)<br/>        if isinstance(proba_preds, pd.DataFrame):<br/>            proba_preds = proba_preds.values</span><span id="664f" class="kx if hh kt b fi lc kz l la lb">        return proba_preds</span><span id="c382" class="kx if hh kt b fi lc kz l la lb">from interpret_community.common.model_wrapper import _eval_model<br/>from interpret_community.common.model_wrapper import wrap_model<br/>from interpret_community.dataset.dataset_wrapper import DatasetWrapper<br/>eval_function, eval_ml_domain = _eval_model(WrappedPytorchModel(model), DatasetWrapper(validation_features.float()), "classification")</span><span id="59b5" class="kx if hh kt b fi lc kz l la lb">newmodel = WrappedClassificationModel(WrappedPytorchModel(model), eval_function)</span></pre><ul class=""><li id="cbcf" class="ka kb hh je b jf ld jj le jn lf jr lg jv lh jz kf kg kh ki bi translated">预言；预测；预告</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="0d8e" class="kx if hh kt b fi ky kz l la lb">newmodel.predict(validation_features.float())<br/>y_pred = newmodel.predict(validation_features.float())</span></pre><ul class=""><li id="0722" class="ka kb hh je b jf ld jj le jn lf jr lg jv lh jz kf kg kh ki bi translated">预测概率</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="abca" class="kx if hh kt b fi ky kz l la lb">newmodel.predict_proba(validation_features.float())</span></pre><ul class=""><li id="c7ab" class="ka kb hh je b jf ld jj le jn lf jr lg jv lh jz kf kg kh ki bi translated">测试类</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="bec4" class="kx if hh kt b fi ky kz l la lb">WrappedPytorchModel(model).predict_classes(validation_features.float()).flatten()</span></pre><ul class=""><li id="d18b" class="ka kb hh je b jf ld jj le jn lf jr lg jv lh jz kf kg kh ki bi translated">禁用骰子日志</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="33e4" class="kx if hh kt b fi ky kz l la lb">import logging<br/>logging.basicConfig()<br/>logging.getLogger().setLevel(logging.WARN)</span></pre><ul class=""><li id="d4c4" class="ka kb hh je b jf ld jj le jn lf jr lg jv lh jz kf kg kh ki bi translated">解释器配置和运行</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="f6d7" class="kx if hh kt b fi ky kz l la lb">from interpret.ext.blackbox import KernelExplainer</span><span id="0c9b" class="kx if hh kt b fi lc kz l la lb">explainer = KernelExplainer(newmodel, np.array(validation_features.float()))</span><span id="d438" class="kx if hh kt b fi lc kz l la lb">global_explanation = explainer.explain_global(np.array(validation_features.float()))</span></pre><figure class="ko kp kq kr fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es li"><img src="../Images/74adc87abfb3952999c9b1f8c826a865.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*f4uHYQs7-VNwWmyl.jpg"/></div></div></figure><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="3137" class="kx if hh kt b fi ky kz l la lb"># Sorted SHAP values<br/>print('ranked global importance values: {}'.format(global_explanation.get_ranked_global_values()))<br/># Corresponding feature names<br/>print('ranked global importance names: {}'.format(global_explanation.get_ranked_global_names()))<br/># Feature ranks (based on original order of features)<br/>print('global importance rank: {}'.format(global_explanation.global_importance_rank))</span><span id="e85d" class="kx if hh kt b fi lc kz l la lb"># Note: Do not run this cell if using PFIExplainer, it does not support per class explanations<br/># Per class feature names<br/>print('ranked per class feature names: {}'.format(global_explanation.get_ranked_per_class_names()))<br/># Per class feature importance values<br/>print('ranked per class feature values: {}'.format(global_explanation.get_ranked_per_class_values()))</span><span id="6ff1" class="kx if hh kt b fi lc kz l la lb"># Print out a dictionary that holds the sorted feature importance names and values<br/>print('global importance rank: {}'.format(global_explanation.get_feature_importance_dict()))</span></pre><ul class=""><li id="8b38" class="ka kb hh je b jf ld jj le jn lf jr lg jv lh jz kf kg kh ki bi translated">解释仪表板</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="546a" class="kx if hh kt b fi ky kz l la lb">ExplanationDashboard(global_explanation, newmodel, dataset=np.array(validation_features.float()), true_y=np.array(validation_labels.float()))</span></pre><figure class="ko kp kq kr fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lq"><img src="../Images/ea6c231c05505292d7ba5a8cf9cb34e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wX635F7zEn2o3X4e.jpg"/></div></div></figure><ul class=""><li id="ac67" class="ka kb hh je b jf ld jj le jn lf jr lg jv lh jz kf kg kh ki bi translated">面粉分析</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="64b5" class="kx if hh kt b fi ky kz l la lb">A_test = X_test["Survey, Relative, Peer's Average Review of Employee"]</span><span id="4075" class="kx if hh kt b fi lc kz l la lb">from raiwidgets import FairnessDashboard</span><span id="f469" class="kx if hh kt b fi lc kz l la lb"># A_test contains your sensitive features (e.g., age, binary gender)<br/># y_true contains ground truth labels<br/># y_pred contains prediction labels</span><span id="6f66" class="kx if hh kt b fi lc kz l la lb">FairnessDashboard(sensitive_features=A_test,<br/>                  y_true=np.array(validation_labels.float()).tolist(),<br/>                  y_pred=y_pred)</span></pre><figure class="ko kp kq kr fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lr"><img src="../Images/14c3e85834cb4c1c8036cee1ecc01cc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Bt9AbC4OHWrYk9Bi.jpg"/></div></div></figure><figure class="ko kp kq kr fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es ls"><img src="../Images/44d15ba4bf336608013ca44f2f948262.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JiJk8pBbTjoskDfZ.jpg"/></div></div></figure><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="97d1" class="kx if hh kt b fi ky kz l la lb">features = ['Activity on Company Forums', 'Hired through SMTP','National Origin (code)', 'Negative Review in Past 5 Years', 'Survey, Relative, Attitude toward Peers', "Survey, Relative, Peer's Average Attitude toward Environment","Survey, Relative, Peer's Average Attitude toward Resources", "Survey, Relative, Peer's Average Attitude toward WorkType", "Survey, Relative, Peer's Average Attitude toward Workload", "Survey, Relative, Peer's Average Review of Employee", "University_Americanos College", 'University_Kyrgyz National University', 'University_Rice University', 'University_Smolensk Humanitarian University', 'University_Universitas Negeri Jakarta', 'University_Universitas Pasundan', 'University_University of Commerce Luigi Bocconi']</span></pre><ul class=""><li id="8ccd" class="ka kb hh je b jf ld jj le jn lf jr lg jv lh jz kf kg kh ki bi translated">误差分析</li></ul><pre class="ko kp kq kr fd ks kt ku kv aw kw bi"><span id="47a7" class="kx if hh kt b fi ky kz l la lb">from raiwidgets import ErrorAnalysisDashboard</span><span id="5f97" class="kx if hh kt b fi lc kz l la lb">ErrorAnalysisDashboard(global_explanation, newmodel, dataset=np.array(validation_features.float()), true_y=np.array(validation_labels.float()), features=features)</span></pre><figure class="ko kp kq kr fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lt"><img src="../Images/a96ce580cd061aaf9c36b0af9ebdd07a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*0U613LyD5xqb74tL.jpg"/></div></div></figure><ul class=""><li id="f334" class="ka kb hh je b jf ld jj le jn lf jr lg jv lh jz kf kg kh ki bi translated">完成的</li></ul><p id="a65e" class="pw-post-body-paragraph jc jd hh je b jf ld jh ji jj le jl jm jn lu jp jq jr lv jt ju jv lw jx jy jz ha bi translated"><em class="lx">最初发表于</em><a class="ae ly" href="https://github.com/balakreshnan/EDSPBootCamp/blob/main/pytorchrai.md" rel="noopener ugc nofollow" target="_blank"><em class="lx">【https://github.com】</em></a><em class="lx">。</em></p></div></div>    
</body>
</html>