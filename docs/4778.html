<html>
<head>
<title>Recent Advances in Self-Supervised and Unsupervised Representation Learning (2019~2022).</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">自我监督和无监督表征学习的最新进展(2019~2022)。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/recent-advances-in-self-supervised-and-unsupervised-representation-learning-2019-2022-1553a45cf8fd?source=collection_archive---------0-----------------------#2022-02-11">https://medium.com/analytics-vidhya/recent-advances-in-self-supervised-and-unsupervised-representation-learning-2019-2022-1553a45cf8fd?source=collection_archive---------0-----------------------#2022-02-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="a343" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我上一次关于半监督学习的工作碰巧引起了很多人的兴趣。所以，我决定对表征学习做一个类似的总结。我个人热爱这个领域，对2022年寄予厚望。在这篇文章中，我试图总结最近出版的许多重要作品。我可能已经错过了一些，但我仍然试图作出一个很好的介绍文章，这个领域的ML。希望节省某人消化信息的时间。</p><h1 id="f3bb" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">对比学习</h1><p id="0005" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">由<a class="ae kf" href="http://yann.lecun.com/exdb/publis/pdf/chopra-05.pdf" rel="noopener ugc nofollow" target="_blank"> Sumit Chopra等人</a>提出。2005年。</p><p id="c8a6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对比学习是从被组织成相似/不相似对的数据中学习相似/不相似表示的框架。这种损失也称为InfoNCE，通常表示为:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/4b807e971110ebbb17fae437a2939415.png" data-original-src="https://miro.medium.com/v2/resize:fit:1046/format:webp/1*7hj4De-x7CaA_8aBDBgkkg.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">摘自<a class="ae kf" href="https://arxiv.org/pdf/2003.04297.pdf" rel="noopener ugc nofollow" target="_blank"> MoCo </a></figcaption></figure><p id="99cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中q是查询样本的表示，而k+和k-分别是正和负关键样本的表示。通常，q和k样本是同一图像的增强对。最后，使用温度超参数τ来调节灵敏度。这个框架是许多作品的核心思想。</p><h1 id="af00" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">视觉表征对比学习的简单框架</h1><p id="1d1a" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">也称为SimCLR，由<a class="ae kf" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank">陈婷等人</a>提出。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ks"><img src="../Images/59a3e381a97f3101e0c9babe542300c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/1*O-ui13fi2HIHd0ArYDv-Kg.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank"> SimCLR </a></figcaption></figure><p id="0cbd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最初，我们增加一个小批量以获得阳性配对。然后，相同的编码器f和投影头g (MLP)被应用于扩充的样本。最后，我们应用上面定义的对比损失来最大化一致性，最小化同一样本图像的增强对之间的距离。因此，重要的是要注意，批量越大，我们的对比学习框架的负面样本就越多。这带来了计算的复杂性。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kt"><img src="../Images/01a77130dcf545ab64854fddd8e33d47.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/1*pqlSvUnrTVV1eVpYPU6e_A.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2002.05709.pdf" rel="noopener ugc nofollow" target="_blank"> SimCLR </a></figcaption></figure><h1 id="c0be" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">借口不变表征的自我监督学习</h1><p id="d4b5" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">PIRL提议由<a class="ae kf" href="https://arxiv.org/pdf/1912.01991.pdf" rel="noopener ugc nofollow" target="_blank">伊山·米斯拉等人</a>提出。在上面的SimCLR图中，您可能已经注意到了这个方法。因此，我觉得有必要简单介绍一下，因为它与该领域的最新进展密切相关。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ku"><img src="../Images/8a59459b265bebf41d9257ca1b216fb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*gjfUWEy8Ce1bg5EeEIvfPg.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/1912.01991.pdf" rel="noopener ugc nofollow" target="_blank"> PIRL </a></figcaption></figure><p id="48e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上图显示了PIRL框架的概况。I_t是原始样本图像I的增强视图，而θ表示主编码器(ResNet)的权重，f和g是两个独立的投影头(全连接层)。正如我们所看到的，我们需要获得9个变换/增强的图像补片并连接它们的表示。因此，投影头g采用比来自顶部分支的嵌入大9倍的级联嵌入。在我们应用投影头之后，我们应用如下的对比学习:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kv"><img src="../Images/d947b96b7876eac219981bdfd0373ff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*qmStT7RVQV_rp32AGnuZwg.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/1912.01991.pdf" rel="noopener ugc nofollow" target="_blank"> PIRL </a></figcaption></figure><p id="a936" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中m_I是由存储体m存储的原始图像(未扩充)的特征向量。因此，我们试图最大化特征向量m_I和来自两个分支的相应投影之间的一致性。注意，负样本是从存储体中随机采样的。</p><h1 id="3dc7" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">无监督视觉表征学习的动量对比</h1><p id="7976" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">明凯何等人提出了一种无监督的表示学习方法，称为<a class="ae kf" href="https://arxiv.org/pdf/1911.05722.pdf" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es kw"><img src="../Images/0e934ee176453f7d16830f107c7f2fa5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qVI9p_4l0gQ4Jo23hztaBg.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/1911.05722.pdf" rel="noopener ugc nofollow" target="_blank"> MoCo </a></figcaption></figure><p id="991e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如上图所示，作者放弃了在整个训练过程中存储特征表示的记忆库，因为它在训练中带来了内存开销。取而代之的是，他们引入了一个动量编码器，这个编码器可以根据主编码器的移动平均值进行更新。此外，他们建议字典作为一个队列结构(先进先出)，它也存储特征表示。它比记忆库小得多，因为作者认为没有必要存储过去某个时期获得的特征向量。如图所示，对比损失是通过最小化来自两个网络的图像的扩充对的表示的距离和最大化从字典中随机采样的表示的距离来实现的。有趣的是，有许多工作表明，由记忆库完成的表征平均与编码器平均(动量编码器)非常相似。然而，动量编码器显著降低了存储成本。</p><p id="bb47" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面附上伪代码:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lb"><img src="../Images/2c817528b35ee9f4f9489889c11d57c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*RB6FtWZpusjBsXrOiB_KNw.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/1911.05722.pdf" rel="noopener ugc nofollow" target="_blank"> MoCo </a></figcaption></figure><h1 id="fcf1" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">MoCo v2和MoCo v3</h1><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lc"><img src="../Images/19ad16464e0a71b2f7bce70eb99af74d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/1*izA4gvHxuO8sUPoCUIAw0g.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2003.04297.pdf" rel="noopener ugc nofollow" target="_blank"> MoCo v2 </a></figcaption></figure><p id="6496" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">MoCo v2对原始框架做了一些修改。我想根据上图总结如下:</p><ol class=""><li id="15cc" class="ld le hh ig b ih ii il im ip lf it lg ix lh jb li lj lk ll bi translated">附加MLP头作为最终模块(添加到两个编码器)。下面附上的原始代码快照总结了这个MLP头。我们看到，我们简单地用一对全连接层替换最后一个全连接层，在它们之间有ReLU激活(隐藏层2048-d，带有ReLU)。</li></ol><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es lm"><img src="../Images/4199a8255d51105ff6c64a1d55759522.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2uoGOCwzqZNElKVqFpmL7g.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://github.com/facebookresearch/moco" rel="noopener ugc nofollow" target="_blank">原始代码</a></figcaption></figure><p id="d4a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.作者通过包括模糊增强来包括更强的增强。</p><p id="5720" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.作者包括一个余弦学习率调度程序。</p><h1 id="3f98" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">激发你自己的潜能——自我监督学习的新方法</h1><p id="1652" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">BYOL由J <a class="ae kf" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank"> ean-Bastien Grill等人</a>提出。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ln"><img src="../Images/eee3fd10e4c9ccc83c9eab8fcec1fe1e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*c7n5-NsMIDHtuJtMdPrX3w.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank"> BYOL </a></figcaption></figure><p id="ed71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我希望到现在为止，你已经熟悉了“表现”和“投射”这样的术语。如果不是，请花时间去了解其中的区别:d。</p><p id="b863" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">BYOL的主要贡献是，作者放弃了MoCo和PIRL分别使用的字典或内存缓冲区。相反，他们引入了另一个<strong class="ig hi">预测头</strong> (MLP类似于投影头)。因此，从上图中我们可以注意到，预测头获取在线编码器(主编码器)的投影，并尝试预测来自动量编码器的投影。预测头非常重要，因为它有助于避免折叠(当所有表示都相同时)。</p><blockquote class="lo lp lq"><p id="2144" class="ie if lr ig b ih ii ij ik il im in io ls iq ir is lt iu iv iw lu iy iz ja jb ha bi translated">注意，这个预测器只应用于在线分支，使得在线管道和目标管道之间的架构不对称。</p></blockquote><p id="8e3b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我认为这是一种正规化。此外，作者完全放弃使用负样本，并提出损失如下:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lv"><img src="../Images/052ddbe23968918f527c4300b6e72289.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*r8C2Dc6zcIbfi4Z8SpLk5g.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank"> BYOL </a></figcaption></figure><p id="eb9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中所有的特征向量都是l2归一化的。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lw"><img src="../Images/24fbb7521c6961eb454d412a4ff21ca5.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*g5zzA8PVgAjNRdOMnd1Hhg.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2006.07733.pdf" rel="noopener ugc nofollow" target="_blank"> BYOL </a></figcaption></figure><p id="a413" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">尽管框架不同寻常，但BYOL的表现优于所有之前的同行。</p><h2 id="862a" class="lx jd hh bd je ly lz ma ji mb mc md jm ip me mf jq it mg mh ju ix mi mj jy mk bi translated">MoCo v3</h2><p id="ec8d" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">现在回到MoCo家族(译注:</p><p id="5d94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它是为自监督ResNet和ViT开发的，去年由何等人提出</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ml"><img src="../Images/9b61f374a0324098406de40f04d9abe4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*Aw97Mmu2HChw2syp4QIgbw.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2104.02057.pdf" rel="noopener ugc nofollow" target="_blank"> MoCo v3 </a></figcaption></figure><p id="1ddd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我想把这些贡献总结如下:</p><ol class=""><li id="67f7" class="ld le hh ig b ih ii il im ip lf it lg ix lh jb li lj lk ll bi translated">作者放弃字典，使用预测头作为BYOL。</li></ol><blockquote class="lo lp lq"><p id="4bbb" class="ie if lr ig b ih ii ij ik il im in io ls iq ir is lt iu iv iw lu iy iz ja jb ha bi translated">在MoCo v3中，两个MLP中的所有层都具有BN。BYOL/SwAV的MLP头有不同的BN设计。</p></blockquote><ol class=""><li id="9f66" class="ld le hh ig b ih ii il im ip lf it lg ix lh jb li lj lk ll bi translated">对比损失还在游戏里。作者发现大批量(4096)足以获得优异的性能。</li></ol><p id="98f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.主干可以用VisionTransformer (ViT)代替。事实上，整个工作是为了融入ViTs lol。</p><p id="859a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">更多详情请参考<a class="ae kf" href="https://arxiv.org/pdf/2104.02057.pdf" rel="noopener ugc nofollow" target="_blank">原文</a>。</p><h1 id="68d3" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">探索简单的连体表示学习</h1><p id="05f1" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">SimSiam是由何等人于2020年提出的。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mm"><img src="../Images/0effd3e232607c42df6cc53f35473db1.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*rBqHPrHMT_1ZhDtQZn8k4Q.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2011.10566.pdf" rel="noopener ugc nofollow" target="_blank">暹罗</a></figcaption></figure><p id="43a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这项工作中，作者表明可能没有必要使用动量编码器作为教师模型。事实上，一个简单而古老的连体框架可以取得很大的效果。然而，在上图中，我们可以看到有一个<strong class="ig hi">预测器</strong>头，它试图预测同一图像的增强样本的输出表示。此外，作者指出停车梯度操作在避免坍塌中起着至关重要的作用。乍一看，这个框架与SimCLR非常相似。但是，您应该记得，SimCLR依赖于阴性样本，它不执行梯度停止。因此，SimCLR还需要更大的批量，这带来了额外的计算成本。下面提供了伪代码:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mn"><img src="../Images/91294a01d1b65cc06ee6f5026d49e65d.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*QEclhWZ6I4Us9N-WNMs58A.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2011.10566.pdf" rel="noopener ugc nofollow" target="_blank">辛暹</a></figcaption></figure><p id="99bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我简单总结一下，以防你不熟悉PyTorch框架。</p><ol class=""><li id="8705" class="ld le hh ig b ih ii il im ip lf it lg ix lh jb li lj lk ll bi translated">你放大一幅图像以获得一对放大的样本。</li><li id="943f" class="ld le hh ig b ih mo il mp ip mq it mr ix ms jb li lj lk ll bi translated">我们使用网络f_theta获得我们的投影。</li><li id="a189" class="ld le hh ig b ih mo il mp ip mq it mr ix ms jb li lj lk ll bi translated">我们使用<strong class="ig hi">预测器</strong>头(MLP)来计算预测嵌入。注意，对于增强图像的每个投影，我们试图预测该对本身的投影。</li><li id="d777" class="ld le hh ig b ih mo il mp ip mq it mr ix ms jb li lj lk ll bi translated">计算负余弦相似性损失。注意，停止毕业。在目标投影(z)上执行。</li></ol><p id="8a54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作者还指出，如果我们放弃我们的预测器(即预测器h是单位矩阵)，该框架就会失败。此外，预测器的学习率不需要在整个训练过程中衰减。事实上，如果预测器的lr保持不变，SimSiam甚至可以获得更好的结果。</p><blockquote class="lo lp lq"><p id="426b" class="ie if lr ig b ih ii ij ik il im in io ls iq ir is lt iu iv iw lu iy iz ja jb ha bi translated">一种可能的解释是h应该适应最新的表示，因此在表示被充分训练之前，没有必要强迫它收敛(通过减少lr)。在我们的模型的许多变体中，我们已经观察到具有常数lr的h提供了稍好的结果。</p></blockquote><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mt"><img src="../Images/5b295464dd90fff5248d08ef02daf4ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i01tZT0s0C6CVC2nPuKI7A.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2011.10566.pdf" rel="noopener ugc nofollow" target="_blank">辛暹</a></figcaption></figure><p id="5bf9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以观察到，像SimSiam这样简单的框架可以实现与当前SOTA方法相当的结果。这绝对是一个有趣的作品，我希望这个想法在未来会得到更深入的研究。</p><h1 id="e5ac" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">奖金(:</h1><h1 id="d626" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">逃离你的老师:用一种新颖的自我监督的方法理解BYOL</h1><p id="1db9" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">RAFT是由<a class="ae kf" href="https://arxiv.org/pdf/2011.10944.pdf" rel="noopener ugc nofollow" target="_blank">海州石等人</a>在2020年提出的。</p><p id="bf5b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">实际上，我认为作者们正在研究和改进这项工作。但是，我觉得很有趣，想和大家分享一下。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mu"><img src="../Images/56951ff6438f0174e6d49e02e50c4383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1162/format:webp/1*9I5rwxwJLPI-USRt2l5-yw.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2011.10944.pdf" rel="noopener ugc nofollow" target="_blank">木筏</a></figcaption></figure><p id="bf1b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作者对试图匹配动量编码器的想法提出了质疑。因此，他们提出了一种不同的方法，其中在线编码器试图最大化其表示和平均教师(MT)的表示之间的距离。同时，它还试图最小化同一图像的增强样本的表示之间的距离。RAFT以一种与BYOL完全相反的方式整合了MT，它通过鼓励在线与过去不同(势头更新)来明确防止崩溃。而且，他们证明BYOL实际上是一种特殊形式的木筏(更多细节请参考原始论文)。上图非常清楚地显示了BYOL框架和RAFT框架之间的区别。总的来说，我们也已经注意到了我们现在非常熟悉的<strong class="ig hi">预测器</strong>。(:</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es mv"><img src="../Images/0018ec1db3213b79a5db8f5eb3716c23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*294h3dS_SPXd0pPNFJ2OOQ.png"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2011.10944.pdf" rel="noopener ugc nofollow" target="_blank">筏</a></figcaption></figure><p id="3174" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面提供了RAFT的算法。我总结如下:</p><ol class=""><li id="6f93" class="ld le hh ig b ih ii il im ip lf it lg ix lh jb li lj lk ll bi translated">获得同一图像的增强对。</li><li id="d568" class="ld le hh ig b ih mo il mp ip mq it mr ix ms jb li lj lk ll bi translated">计算两个扩充样本的<strong class="ig hi">预测</strong>嵌入。</li><li id="8eec" class="ld le hh ig b ih mo il mp ip mq it mr ix ms jb li lj lk ll bi translated">计算相同样本的MT投影嵌入。</li><li id="7ed3" class="ld le hh ig b ih mo il mp ip mq it mr ix ms jb li lj lk ll bi translated"><strong class="ig hi">对齐损失</strong>是在两个<strong class="ig hi">预测</strong>嵌入之间计算的，它鼓励一对尽可能接近。这只是l2归一化嵌入的MSE损失。</li><li id="76d7" class="ld le hh ig b ih mo il mp ip mq it mr ix ms jb li lj lk ll bi translated"><strong class="ig hi">负的跨模型损失</strong>促使预测嵌入(来自在线编码器)与MT的投影嵌入不同。</li></ol><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="er es mw"><img src="../Images/1f4dea855a0fcb33baa336f25aa9f800.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yK10IPyuRHVJ3vWPRrV5Vg.png"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated"><a class="ae kf" href="https://arxiv.org/pdf/2011.10944.pdf" rel="noopener ugc nofollow" target="_blank">木筏</a></figcaption></figure><p id="3684" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作者还指出，<strong class="ig hi">预测器</strong>在其他作品中起到了至关重要的作用，有助于避免表示崩溃。他们认为这是BYOL尽管有着不同寻常的学习策略却没有失败的主要原因。此外，他们认为RIFT框架鼓励在线编码器不断改进其历史(MT ),因此我们不需要期待完全的融合。总体而言，MT是一种正则化子，作者认为RAFT比BYOL更有利。</p><h1 id="33e7" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">然后</h1><div class="mx my ez fb mz na"><a href="https://chingisoinar.medium.com/self-supervised-learning-representation-learning-via-invariant-causal-mechanisms-42ca16f45902" rel="noopener follow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hi fi z dy nf ea eb ng ed ef hg bi translated">自我监督学习:通过不变因果机制的表征学习</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">你好，我最近不太活跃，但我有一些空闲时间来提供这篇文章。我发现了更多有趣的作品…</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">chingisoinar.medium.com</p></div></div><div class="nj l"><div class="nk l nl nm nn nj no km na"/></div></div></a></div><div class="mx my ez fb mz na"><a href="https://chingisoinar.medium.com/self-supervised-learning-what-should-not-be-contrastive-in-contrastive-learning-937814576cef" rel="noopener follow" target="_blank"><div class="nb ab dw"><div class="nc ab nd cl cj ne"><h2 class="bd hi fi z dy nf ea eb ng ed ef hg bi translated">自我监督学习:对比学习中什么不应该是对比</h2><div class="nh l"><h3 class="bd b fi z dy nf ea eb ng ed ef dx translated">如果你研究对比学习，你会发现这项工作是非常有见地的。不像以前的作品在…</h3></div><div class="ni l"><p class="bd b fp z dy nf ea eb ng ed ef dx translated">chingisoinar.medium.com</p></div></div><div class="nj l"><div class="np l nl nm nn nj no km na"/></div></div></a></div><h1 id="3fbf" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">一些遗言</h1><p id="407b" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">我试图涵盖最近出版的所有重要作品。然而，我可能已经错过了一些。如果我错过了这方面的有趣作品，请告诉我。总的来说，我可能错过了本文中一些有趣的技术细节；然而，我的目标是尽快向你介绍这个领域。如果您对其中任何一部作品感兴趣，请慢慢阅读原文，了解更多更好的细节(:感谢您花时间阅读我的文章。我希望通过节省一些消化信息的时间来减轻某人的生活。</p><h2 id="fc56" class="lx jd hh bd je ly lz ma ji mb mc md jm ip me mf jq it mg mh ju ix mi mj jy mk bi translated">我的看法</h2><p id="2960" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">正如我们可能注意到的那样，脸书研究小组在这一领域一直做着令人惊叹的工作。此外，我们可以注意到这一领域的一些趋势，因为最近的工作大多使用动量编码器。此外，我们还注意到，最近的工作不依赖于负面样本。我只想分享这些发现。</p></div></div>    
</body>
</html>