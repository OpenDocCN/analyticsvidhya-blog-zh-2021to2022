<html>
<head>
<title>Bag of Tricks for Image Classification with Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络用于图像分类的技巧包</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/bag-of-tricks-for-image-classification-with-convolutional-neural-networks-99f00a9b9565?source=collection_archive---------9-----------------------#2021-03-23">https://medium.com/analytics-vidhya/bag-of-tricks-for-image-classification-with-convolutional-neural-networks-99f00a9b9565?source=collection_archive---------9-----------------------#2021-03-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1899" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">原文:<a class="ae jd" href="https://arxiv.org/abs/1812.01187" rel="noopener ugc nofollow" target="_blank">用卷积神经网络进行图像分类的锦囊妙计</a></p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="92e3" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">概述</h1><p id="30e0" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">我们将总结上述论文提出的技术。本文提出了各种“技巧”来轻松地提高CNN图像分类的性能。本文讨论了对现代硬件训练有用的技巧，回顾了改进剩余模型结构的想法，以及训练程序的变化。</p><p id="da8f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每种方法都与基线ResNet50模型进行了经验比较，所提出的方法最终在ImageNet上将准确率从75.3%提高到79.29%。本文还展示了所提出的技巧在应用于迁移学习时的优越性。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es ko"><img src="../Images/84027d5b6f0e5521a509238d64ad6c31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ac3IXMXAYmpum_W9"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图片由乔丹·怀特在<a class="ae jd" href="https://unsplash.com/photos/AjT_T5J8aH0" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="2962" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">本文提出的“锦囊妙计”由以下技术组成。</p><h1 id="af07" class="jl jm hi bd jn jo le jq jr js lf ju jv jw lg jy jz ka lh kc kd ke li kg kh ki bi translated">基线模型</h1><p id="7b9d" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">本文首先提出了一个基线模型，该模型使用了以下步骤的数据扩充管道。</p><ol class=""><li id="c21b" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated">随机采样图像并将其解码为[0，255]中的32位浮点原始像素值。</li><li id="4c67" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">随机裁剪一个矩形区域，其纵横比以[3/4，4/3]随机采样，面积以[8%，100%]随机采样，然后将裁剪区域调整为224 x 224的正方形图像。</li><li id="487f" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">以0.5的概率水平翻转。</li><li id="6535" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">使用从[0.6，1.4]中统一提取的系数缩放色调、饱和度和亮度。</li><li id="a552" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">用从正态分布N (0，0.1)采样的系数添加PCA噪声。</li><li id="e466" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">通过分别减去123.68、116.779、103.939并除以58.393、57.12、57.375来归一化RGB通道。</li><li id="8439" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">在验证过程中，我们将每个图像的短边调整为256像素，同时保持其纵横比。接下来，我们在中心裁剪出224乘224的区域，并像训练一样标准化RGB通道。</li></ol><p id="5ed4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">权重通过从[a，a]中得出的Xavier算法进行初始化，其中a = sqrt(6/(din + dout))。其中din和dout为输入和输出通道尺寸。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lx"><img src="../Images/2803c03d7800227a20053ab50941bad1.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*uyueAUpWV58Y7aiOBcUDfg.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">基线模型的结果</figcaption></figure><p id="a793" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">经过训练的基线模型的结果略低于原始论文的结果，主要是由于不同的训练程序。</p><h1 id="84d1" class="jl jm hi bd jn jo le jq jr js lf ju jv jw lg jy jz ka lh kc kd ke li kg kh ki bi translated">增加批量</h1><p id="0fa9" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">用增加的批量大小进行训练有助于收敛，并且它降低了整体计算速度，但是由于每个时期较少的训练迭代，可能减慢训练过程。此外，经验结果表明，较大批量的训练将导致验证准确性下降。尽管如此，我们仍然可以使用多篇论文提出的技术，从更大的批量中获益，同时避免潜在的问题。</p><ul class=""><li id="3ad7" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc ly lp lq lr bi translated"><strong class="ih hj"> <em class="lz">线性缩放学习率:</em> </strong>与增加的批量成比例地线性增加学习率，会平衡因批量较大而造成的训练迭代中的损失。例如，如果我们使用2倍的批量大小，我们也将学习速率提高2倍。</li><li id="57aa" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc ly lp lq lr bi translated"><strong class="ih hj"> <em class="lz">学习率热身</em> </strong> <em class="lz"> : </em>我们在开始时使用一个小的学习率，然后在训练过程稳定时切换回初始学习率。这是因为，在训练初期，所有参数都离最终解很远。</li><li id="eb04" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc ly lp lq lr bi translated"><strong class="ih hj">BN的零γ:</strong>当γ和β是分别初始化为1和0的可学习参数时，批规范化执行γxˇ+β的计算。我们对所有BN层初始化γ = 0，并在训练的初始阶段假装层数较少。</li><li id="bd06" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc ly lp lq lr bi translated"><strong class="ih hj"> <em class="lz">无偏差衰减:</em> </strong>权重衰减用于防止过拟合，但在避免过拟合方面，偏差不必衰减。因此，我们仅对卷积和全连接层中的权重应用权重衰减。</li><li id="edd7" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc ly lp lq lr bi translated"><strong class="ih hj"> <em class="lz">低精度训练:</em> </strong>常用的32位浮点表示对于现代硬件来说效率不高。根据该论文，Nvidia V100 GPU在FP32中提供14 TFLOPS，但在FP16中超过100 TFLOPS。</li></ul><div class="kp kq kr ks fd ab cb"><figure class="ma kt mb mc md me mf paragraph-image"><img src="../Images/bba606e2dd15fef0d02c47df716d1035.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/1*acahQhz4zPtMSA_-m-ApBg.png"/></figure><figure class="ma kt mg mc md me mf paragraph-image"><img src="../Images/b816a01b472c4b9998f8f4105f4e7af9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*AmUdCLJwlzzP13ve4I2HCQ.png"/></figure></div><p id="db0f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">左侧的图表描述了每种技术分别应用于ResNet50模型时的验证准确性。下一个图表比较了在多个模型架构上应用所提出的方法的性能优势。</p><h1 id="4d42" class="jl jm hi bd jn jo le jq jr js lf ju jv jw lg jy jz ka lh kc kd ke li kg kh ki bi translated"><strong class="ak">模型架构调整(ResNet50) </strong></h1><p id="aefb" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">正如论文中所述:“模型调整是对网络架构的微小调整，例如改变特定卷积层的步幅。这种调整通常几乎不会改变计算复杂性，但可能会对模型精度产生不可忽略的影响。”模型架构中简单的概念变化显示了性能的惊人提高。</p><div class="kp kq kr ks fd ab cb"><figure class="ma kt mh mc md me mf paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/3fdac533d2b6a15d529e0c65e83aa755.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/1*H6nVJqAIflJTo4VnAEg7oQ.png"/></div></figure><figure class="ma kt mi mc md me mf paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/fc557df94f1c40960a73ddea46bb6488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*n4nqqfrTiYa9o9QuLQIz_w.png"/></div></figure></div><p id="e164" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上图描述了最初的ResNet50模型架构和应用于该模型的三个调整，并显示了性能的提高。每个调整都可以解释如下</p><ul class=""><li id="5638" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc ly lp lq lr bi translated">ResNet-B:修改ResNet的下采样块，以在第二层应用步长卷积，因为原始模型通过第一个1x1卷积层丢失了3/4的图像。</li><li id="7553" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc ly lp lq lr bi translated">ResNet-C:通过替换7x7卷积来修改输入级。7 × 7卷积比3 × 3卷积贵5.4倍。因此，用三个3 × 3卷积替换输入干中的7 × 7卷积将提高性能，同时保持原始模型的复杂性。</li><li id="2d9e" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc ly lp lq lr bi translated">ResNet-D:修改下采样块的第二条路径。我们注意到，下采样块的第二路径中的1 × 1卷积也忽略了3/4的输入特征图，并且用平均池来代替步进卷积。</li></ul><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es mj"><img src="../Images/c807b5c47851a58d95ebfdea472ba2c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1080/format:webp/1*nyyM1QRM1BkPM-5RUS2GcQ.png"/></div></figure><p id="e190" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在各种实现和论文中提出了ResNet-B，C，并且在本文中提出了ResNet-D的修改。每种方法都优于上面的一种方法，通过这三种方法，观察到总精度提高了1%。</p><h1 id="c334" class="jl jm hi bd jn jo le jq jr js lf ju jv jw lg jy jz ka lh kc kd ke li kg kh ki bi translated">训练改进</h1><p id="27c4" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">先前的方法改进了正向传播阶段的训练。本节中的方法将着重于改进培训过程。</p><p id="8927" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">余弦学习率衰减</strong></p><p id="15b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以用各种方式来衰减学习速率，例如步长衰减，其中权重不连续减少，或者指数衰减，其中在时段n的学习速率是k的指数，常数(例如lr=0.94^n).本文展示了余弦学习率衰减的有效性，其中学习率由下面的三角公式计算。T是总迭代次数，η是初始学习率。学习率按余弦函数衰减，精度在训练过程中逐渐增加。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es mk"><img src="../Images/f306a6d9993055e24691923ffea625fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*NpUOQJMCBzbUaN6o3x_fYQ.png"/></div></figure><div class="kp kq kr ks fd ab cb"><figure class="ma kt ml mc md me mf paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/a2b63ef25f0d65e9edc3e400a96de398.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*_cu7OlovVK4uySIymfEhmA.png"/></div></figure><figure class="ma kt mm mc md me mf paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><img src="../Images/8ea7ab6be6bd7683db4d8c5f1aa7a9e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*ahht3y5HVJHPjmzmO7vmnw.png"/></div></figure></div><p id="274d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">标签平滑</strong></p><p id="c7d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">标签平滑“平滑”答案标签，并指导模型预测平滑的标签，而不是像0，1这样的极值。确切的公式描述如下。例如，如果ε=0.1，则对于真实类，模型必须预测(1-ε)=0.9，当有K=10个类时，模型必须预测ε/(K-1)=0.0111。标注平滑通过防止输出分数过于明显，具有防止过度拟合的效果。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es mn"><img src="../Images/f2c7871266c60d5e6916476f639861ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*lEsVPDydSJSEcVtCZrACbA.png"/></div></figure><p id="c679" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">知识蒸馏</strong></p><p id="1478" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">知识升华使用预先训练的教师模型来指导模型。除了常规的交叉熵损失<em class="lz"> l </em> (p，softmax(z))，我们添加第二项来惩罚教师模型和学习者模型的softmax输出之间的差异。T是一个超参数，T = 20用于本文的训练。</p><p id="a743" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管如此，我也不明白这个模型如何从这项技术中获益。在这篇文章中没有更多关于这种技术的解释。根据<a class="ae jd" href="https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764" rel="noopener" target="_blank">这一点，</a>“较小的网络然后被训练来学习较大网络的确切行为，方法是尝试在每个级别复制其输出(而不仅仅是最终损失)”知识提取用于将较大模型的特征转移到较小的模型，以获得更快的推理速度和移动能力。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mo"><img src="../Images/c036b296a2f79f7bd890d8a522f76d0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1312/format:webp/1*BpaLgjYsTdoCYeLwCmilJA.png"/></div></div></figure><p id="9610" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">混搭训练</strong></p><p id="e028" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Mixup是另一种数据扩充方法，它通过混合图片和类标签来工作。下图描述了这种方法。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es mp"><img src="../Images/8086925bdb9f232b567dd8ade05e42ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:648/format:webp/1*7MblAezJzZFI2092vrzd0w.png"/></div></figure><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mq"><img src="../Images/a57870dbe7f3933cf46f6484f06ec8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*JwmZYnfhjdtf8mbF.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图片来自<a class="ae jd" rel="noopener" href="/swlh/paper-mixup-beyond-empirical-risk-minimization-image-classification-6ee40a45ad17">本博客</a>作者<a class="ae jd" href="https://sh-tsang.medium.com/?source=post_page-----6ee40a45ad17--------------------------------" rel="noopener">曾锡浩</a></figcaption></figure><h1 id="3e22" class="jl jm hi bd jn jo le jq jr js lf ju jv jw lg jy jz ka lh kc kd ke li kg kh ki bi translated"><strong class="ak">实验结果</strong></h1><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="er es mr"><img src="../Images/d1017833c24fdc6fb6f20c4058c46803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_V6cdsuvUYt7i3dKcElr1Q.png"/></div></div></figure><p id="3c45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上图显示了每种方法的性能改进。“有效”模型表示由前面讨论的技巧和模型调整组成的模型。对于ResNet50模型，我们实现了大约2%的性能提升。知识提炼未能提高InceptionV3和MobileNet模型的性能。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ms"><img src="../Images/c343b9eb5bba159f26ab1a08bee89f12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1282/format:webp/1*8vNH7S_X77xMtQn-OyHIwA.png"/></div><figcaption class="la lb et er es lc ld bd b be z dx translated">麻省理工学院Places 365数据集验证集/测试集上的迁移学习结果</figcaption></figure><div class="kp kq kr ks fd ab cb"><figure class="ma kt mt mc md me mf paragraph-image"><img src="../Images/cb68519c7579d7576a785613bc43a11c.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*DkWv5G9W0DXiOirKT6mg8A.png"/></figure><figure class="ma kt mu mc md me mf paragraph-image"><img src="../Images/3f50b8157f723435458bb697f000703a.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*jxpIZirn1sel68bA4Qy_5Q.png"/><figcaption class="la lb et er es lc ld bd b be z dx mv di mw mx translated">左:在Pascal VOC(对象检测)上的更快RCNN性能，右:在ADE20K(语义分割)上的FCN性能</figcaption></figure></div><p id="e924" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上图描述了对象检测和语义分割等其他任务的技术性能提升。它还在麻省理工学院places 365数据集上显示了更好的迁移学习性能。尽管性能有所提高，但这可能是一个明显的结果。</p><h1 id="fc85" class="jl jm hi bd jn jo le jq jr js lf ju jv jw lg jy jz ka lh kc kd ke li kg kh ki bi translated">我的看法</h1><p id="ecb3" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">本文回顾了通过简单的技巧显著提高CNN性能的“锦囊妙计”。我觉得专注于深度学习的最基本基础对于提高性能至关重要。有些论文采用非常复杂的方法只是为了提高1~2%的精度，但是通过本文中的方法以及其他技巧，我相信这些技巧可以对实际应用产生非常大的影响。</p></div></div>    
</body>
</html>