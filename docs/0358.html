<html>
<head>
<title>Web Scraping using BeautifulSoup in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python中的BeautifulSoup进行网页抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-using-beautifulsoup-in-python-b444add3496d?source=collection_archive---------15-----------------------#2021-01-13">https://medium.com/analytics-vidhya/web-scraping-using-beautifulsoup-in-python-b444add3496d?source=collection_archive---------15-----------------------#2021-01-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7be0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">考虑一个场景，您必须从网站上收集关于表单或一些文档的数据，以便使用机器学习进行分析或导出一些统计数据。在这种情况下，您可以使用python库BeautifulSoup从网页中抓取数据。以下是下载EDGAR数据集的步骤，该数据集包含美国证券交易委员会的备案信息，公众可通过互联网免费获取。在这里，你必须找到刮掉所有的数据，从公司档案页，并保存它，为进一步的处理。数据以不同的文件格式呈现，如gif、jpg、txt、HTML。我们还需要将它转换成一种常见的形式，以便进一步处理。</p><p id="0fc7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第一步:<strong class="ig hi"> : </strong>使用urllib库中的urlopen和BeautifulSoup打开网站，提取网页上的数据，这些数据是从按钮中提取的点击<strong class="ig hi">图1.1 </strong>中给出的documents按钮，并追加到一个包含所有ahref链接的数组link_list[]中。在<strong class="ig hi">中，图1.2 </strong>是给它的代码。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/b58a2103c5dc00bf8a90f0b3b1a0cc39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1290/format:webp/1*vN20Chih_frliGbRKrCRNA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">图1.1</strong><a class="ae jp" href="https://www.sec.gov/cgi-bin/browse-edgar?CIK=1067491&amp;owner=exclude" rel="noopener ugc nofollow" target="_blank"><strong class="bd jo">https://www.sec.gov/cgi-bin/browse-edgar?CIK=1067491&amp;所有者=排除</strong></a><strong class="bd jo">【1】</strong></figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jq"><img src="../Images/f21a2bc4481cf9a6bde385511edf2591.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*kYn3PcGn295RW7OKxDF6Jg.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">图1.2从网页</strong>中的按钮提取数据ahref链接的代码</figcaption></figure><p id="8892" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第二步:<strong class="ig hi"> : </strong>在<strong class="ig hi">图2.1 </strong>列名文档中包含所有不同文件类型URL的网页出现。在<strong class="ig hi">图2.2 </strong>中，遍历数组link_list[]中的每个URL，打开每个URL找到所有行，从包含不同文件的行中获取ahref链接，并将其附加到数组data_list[]中。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jq"><img src="../Images/a5ed97b466d3bf2307b705c34d3efc2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*ZQBosVvVFIuqdlqc6pb94Q.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">图2.1 https://www . sec . gov/Archives/Edgar/data/1000106749120000084/0001067491-20-000084-index . htm[2]。</strong></figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jq"><img src="../Images/d4390048d1099e06a2dc904b27e19526.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*lwjkDXIzTUWqiSyUJ6aSkA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">图2.2为每个文档提取链接的代码</strong></figcaption></figure><p id="8c47" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">步骤3:在<strong class="ig hi">图3.1 </strong>中，每个文件扩展名类型被分离到不同的数组中，以便进一步处理。以便只有有用的文件类型才能用于进一步的分析。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="jr js di jt bf ju"><div class="er es jq"><img src="../Images/73adf85431285801c29d262346b7758d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*EJY8SSKg9YG5EsWNajGAaA.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">图3.1分隔不同文件扩展名链接的代码</strong></figcaption></figure><p id="1638" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第四步:在<strong class="ig hi">图4.1 </strong>中，它在包含所有。htm文件URL，它使用urllib库中的urlopen打开每个URL，并使用BeautifulSoup提取文本，剥离所有不需要的html标签，并将其写回到txt文件中，并将文件保存在目录中。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jv"><img src="../Images/b03df65832c3d45b30df6d4268c17fcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*P06YfahJsHEVJidK0zNDgw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><strong class="bd jo">图4.1转换代码。htm链接到txt文件</strong></figcaption></figure><p id="527e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">参考</p><p id="c489" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1)<a class="ae jp" href="https://www.sec.gov/cgi-bin/browse-edgar?CIK=1067491&amp;owner=exclude" rel="noopener ugc nofollow" target="_blank">https://www.sec.gov/cgi-bin/browse-edgar?CIK=1067491&amp;所有者=排除</a></p><p id="d4bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2)https://www . sec . gov/Archives/Edgar/data/106749120000084/0001067491-20-000084-index . htm</p></div></div>    
</body>
</html>