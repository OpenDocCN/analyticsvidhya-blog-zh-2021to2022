<html>
<head>
<title>ML23: Handling Missing Values</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML23:处理缺失值</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ml23-1b08fb0dd4b0?source=collection_archive---------16-----------------------#2021-03-14">https://medium.com/analytics-vidhya/ml23-1b08fb0dd4b0?source=collection_archive---------16-----------------------#2021-03-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="6547" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">除了输入平均值、中间值或众数之外的方法</h2></div><p id="b135" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">处理缺失值的常见方法包括丢弃和输入均值、中值或众数。还有类似<strong class="iy hi"> <em class="js">随机森林</em> </strong> &amp; <strong class="iy hi"> <em class="js">贝叶斯岭</em> </strong>的高级方法。那么，如何确保处理缺失值的最佳实践避免欠拟合&amp;过拟合？</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><blockquote class="ka kb kc"><p id="0db9" class="iw ix js iy b iz ja ii jb jc jd il je kd jg jh ji ke jk jl jm kf jo jp jq jr ha bi translated"><strong class="iy hi"> <em class="hh">大纲</em></strong><em class="hh"><br/>(1)</em><a class="ae kg" href="#7d5d" rel="noopener ugc nofollow"><em class="hh">前提条件</em></a><em class="hh"><br/>(2)</em><a class="ae kg" href="#fcb1" rel="noopener ugc nofollow"><em class="hh">两种缺失值</em></a><em class="hh"><br/>(3)</em><a class="ae kg" href="#afa2" rel="noopener ugc nofollow"><em class="hh">缺失值的处理方法</em></a><em class="hh"><br/>(4)</em><a class="ae kg" href="#dd0f" rel="noopener ugc nofollow"><em class="hh">插补在实践中</em></a></p></blockquote></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="7d5d" class="kh ki hh bd kj kk kl km kn ko kp kq kr in ks io kt iq ku ir kv it kw iu kx ky bi translated">(1)先决条件</h1><h2 id="0901" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated">1-1术语[1][2]</h2><p id="4386" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated"><strong class="iy hi"> 1。NA </strong> =一个缺失值。代表<em class="js">不可用</em>或<em class="js">不适用</em>。</p><blockquote class="ka kb kc"><p id="b174" class="iw ix js iy b iz ja ii jb jc jd il je kd jg jh ji ke jk jl jm kf jo jp jq jr ha bi translated">熊猫对象中缺失数据的表示方式有些不完美，但对很多用户来说是有用的。对于数字数据，pandas使用浮点值<strong class="iy hi"> NaN </strong>(不是数字)来表示缺失的数据。我们称之为易于检测的标记值:</p><p id="f016" class="iw ix js iy b iz ja ii jb jc jd il je kd jg jh ji ke jk jl jm kf jo jp jq jr ha bi translated">在pandas中，我们采用了R编程语言中使用的一种约定，即<strong class="iy hi">将丢失的数据称为NA </strong>，表示<strong class="iy hi">不可用</strong>。在统计应用程序中，NA数据可能是不存在的数据，也可能是存在但未被观察到的数据(例如，通过数据收集问题)。清理数据进行分析时，对缺失数据本身进行分析<strong class="iy hi">通常很重要</strong>以识别数据收集问题或由缺失数据导致的数据中的潜在偏差。[1]</p></blockquote><p id="280b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">2.<strong class="iy hi">特征</strong> = ML-specific term，统计学和经济学中又称为预测因子、自变量、解释变量、回归变量、外生或输入。<br/> 3。<strong class="iy hi">目标</strong> = ML专用术语，在统计学和经济学中也称为响应、因变量、回归变量、内生变量或输出变量。<br/> 4。<strong class="iy hi">数据点</strong> = ML专用术语，统计学上也叫观察或案例。数据点是数据帧中的一行。<br/> 5。<strong class="iy hi">数据集/数据帧</strong> =许多数据点组成一个数据集/数据帧。</p><h2 id="b24d" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated">1–2数据类型[3]</h2><p id="775a" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">一般来说，我们将数据分为两类:</p><p id="7c15" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[i] <strong class="iy hi">数值数据</strong>:连续&amp;离散<br/>【ii】<strong class="iy hi">分类数据</strong>:顺序&amp;名义</p><p id="bfc4" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">此外，我们可以将数据分类为:</p><p id="e064" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[i] <strong class="iy hi">数值数据</strong>:比率水平&amp;区间水平<br/>【ii】<strong class="iy hi">分类数据</strong>:序数水平&amp;名义水平</p><p id="99f1" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">然后，让我们探究这四个级别的数据:</p><ol class=""><li id="05f1" class="ls lt hh iy b iz ja jc jd jf lu jj lv jn lw jr lx ly lz ma bi translated"><strong class="iy hi">比率级</strong>:可以分类、排序，也可以加减乘除。<em class="js">如收入。</em></li><li id="4a27" class="ls lt hh iy b iz mb jc mc jf md jj me jn mf jr lx ly lz ma bi translated"><strong class="iy hi">区间层次</strong>:可以分类、排序以及加减。<strong class="iy hi"><em class="js"/></strong>不能乘除。<em class="js">如摄氏温度。这种类型的数据很少，只有摄氏度，华氏度，很少有李克特量表。</em></li><li id="74c1" class="ls lt hh iy b iz mb jc mc jf md jj me jn mf jr lx ly lz ma bi translated"><strong class="iy hi">序数级</strong>:可以分类，排序。<strong class="iy hi"> <em class="js">不会</em> </strong> <em class="js"> </em>加减乘除。<em class="js">如，一个调查的问题有5个选项，分别为1~5分。</em></li><li id="d5bb" class="ls lt hh iy b iz mb jc mc jf md jj me jn mf jr lx ly lz ma bi translated"><strong class="iy hi">标称等级</strong>:只能分类。<em class="js">例如，汽车的颜色。</em></li></ol><h1 id="fcb1" class="kh ki hh bd kj kk mg km kn ko mh kq kr in mi io kt iq mj ir kv it mk iu kx ky bi translated">(2)两种缺失值[4][5]</h1><p id="b518" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">实际上有三种:完全随机缺失(MCAR)、随机缺失(MAR)和非随机缺失(MNAR) [4][5]。但为了简单起见，我们重点介绍其中的两种:<strong class="iy hi"> <em class="js">随机缺失</em> </strong> &amp; <strong class="iy hi"> <em class="js">系统缺失</em> </strong>，即<strong class="iy hi"><em class="js">MCAR</em></strong><strong class="iy hi"><em class="js">MNAR</em></strong>分别。</p><p id="39aa" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">问题来了:如何识别NAs是MCAR还是MNAR？Zumel和Mount (2014)[5]指出:</p><blockquote class="ml"><p id="60d3" class="mm mn hh bd mo mp mq mr ms mt mu jr dx translated">“如果您不知道缺失值是随机的还是系统的，我们建议假设差异是系统的，而不是尝试根据错误的传感器假设将值输入变量。”</p></blockquote><p id="cae8" class="pw-post-body-paragraph iw ix hh iy b iz mv ii jb jc mw il je jf mx jh ji jj my jl jm jn mz jp jq jr ha bi translated">简而言之，不失一般性，我们应该假设NAs是MNAR。基于这个建议，我们现在深入研究数字数据和分类数据。</p><p id="f93b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">{A} <strong class="iy hi">分类数据</strong>:假设NAs是MNAR，我们可以简单的将所有NAs归为一个特殊的类别。</p><p id="686f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">{B} <strong class="iy hi">数字数据</strong>:假设NAs是MNAR，那么我们的选择就很少了，这些方法会大大减少数字数据包含的信息，例如，将数字数据转换为类别数据，然后执行上面的过程。因此，在实际操作中，我们<strong class="iy hi"> <em class="js">往往假设数值型数据中的NAs在某种程度上是随机缺失的，并将其作为MCAR </em> </strong>，然后我们可以用<em class="js">均值</em>、<em class="js">中位数</em>、<em class="js">众数</em>或其他ML方法如<em class="js">贝叶斯岭</em> &amp; <em class="js">随机森林</em>来估算NAs。</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="afa2" class="kh ki hh bd kj kk kl km kn ko kp kq kr in ks io kt iq ku ir kv it kw iu kx ky bi translated">(3)缺失值的处理方法</h1><p id="7a54" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">让我们看一下缺失值插补方法。请记住，大多数方法<em class="js">都假设NAs在某种程度上是随机缺失的</em>，并且可以被视为MCAR。</p><h2 id="b1d7" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated">1.丢弃NAs</h2><p id="136d" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">这是最简单和最直观的方法，删除所有包含NA的数据点(所有行)。然而，这是一种毁灭性的方式，因为它削减了数据集的信息，并在数据集中产生偏见。</p><h2 id="93ff" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated">2.均值/中值/众数插补</h2><p id="a223" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">与丢弃包含任何NA的所有数据点相比，这种方法更好。一些缺点是减少方差，扭曲分布和减少观察到的关系。</p><p id="00fa" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[A] <strong class="iy hi">数字数据</strong>:平均值/中位数插补。</p><p id="41d4" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[B] <strong class="iy hi">分类数据</strong>:模式插补。</p><h2 id="a957" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated">3.热卡插补</h2><p id="bd60" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">很像kNN [6]。平均优于均值/中值/众数插补。</p><h2 id="8fed" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated">4.回归插补</h2><p id="b190" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated"><strong class="iy hi">优点</strong>:比均值/中值/众数插补更精确。</p><p id="5b60" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">缺点:低估方差，强化现有关系，减少一般化，变量必须有相关性才能产生有效值，估算值可能超出合理范围。</p><h2 id="5f44" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated">5.多重插补</h2><blockquote class="ka kb kc"><p id="b20b" class="iw ix js iy b iz ja ii jb jc jd il je kd jg jh ji ke jk jl jm kf jo jp jq jr ha bi translated"><strong class="iy hi">多重插补</strong>是解决缺失数据问题的一种通用方法，可用于几个常用的统计软件包。它旨在通过创建几个不同的貌似合理的<strong class="iy hi">估算</strong>数据集并适当组合从每个数据集获得的结果，来考虑缺失数据的不确定性。[7]</p></blockquote><h2 id="88da" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated">6.ML算法插补</h2><p id="fc91" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">kNN，决策树，随机森林，BayesianRidge等等。</p><h2 id="3bfe" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated">7.其他估算方法</h2><p id="7399" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated"><strong class="iy hi">7–1创建“NAs”类别</strong></p><p id="a9a6" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如前所述，如果我们确定NAs是MNAR，我们可以按如下方式处理分类数据和数值数据的NAs:</p><p id="028a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">{A} <strong class="iy hi">分类数据</strong>:假设NAs是MNAR，我们可以简单地将所有NAs归为一个特殊的类别。</p><p id="33d7" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">{B} <strong class="iy hi">数字数据</strong>:假设NAs是MNAR，那么我们的选择就很少，这些方法会极大地减少数字数据包含的信息，例如，将数字数据转换为类别数据并执行上述过程。因此，在实践中，我们<strong class="iy hi"> <em class="js">往往假设数值型数据中的NAs在某种程度上是随机缺失的，并将其作为MCAR </em> </strong>，然后我们可以用<em class="js">均值</em>、<em class="js">中位数</em>、<em class="js">众数</em>或其他ML方法如<em class="js">贝叶斯岭</em> &amp; <em class="js">随机森林</em>来估算NAs。</p><p id="8e26" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">7–2将NAs转换成某个数字</strong></p><p id="5a76" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是针对数字数据的。如果你能够发现某种洞察力，例如，那些特征“收入”缺失的人大多是家庭主妇和学生，那么我们可以合理地将这些NAs转换为“0”。进一步，我们可以创建一个新的特征“income_NA”(称为屏蔽变量)，将那些“income”缺失的归类为“1”，其余的归类为“0”。</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="dd0f" class="kh ki hh bd kj kk kl km kn ko kp kq kr in ks io kt iq ku ir kv it kw iu kx ky bi translated">(4)实践中的归责</h1><p id="dfe7" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">接下来，我们现在从不同的来源进一步了解实际中缺失值的插补方法。</p><h2 id="a603" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated"><strong class="ak">4–1删除NAs &amp;均值/中值/众数插补</strong></h2><p id="55e9" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">虽然处理缺失值是数据预处理中的一个重要步骤，但许多流行的Python &amp; R书籍，如McKinney (2018)、VanderPlas (2017)、Wickham和Grolemund (2016)以及James G .等人(2013) [1][8][9][10]仅讨论了丢弃NAs、均值/中值/众数插补和插值插补，而没有提及其他方法。</p><h2 id="60bd" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated"><strong class="ak">4–2 kNN</strong></h2><figure class="nb nc nd ne fd nf er es paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="er es na"><img src="../Images/f81ce8686b258c3187d811dcde57c17c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1Zxy3GihI4MmBptC.gif"/></div></div><figcaption class="nm nn et er es no np bd b be z dx translated">图kNN的决策边界[11]</figcaption></figure><blockquote class="ka kb kc"><p id="edc7" class="iw ix js iy b iz ja ii jb jc jd il je kd jg jh ji ke jk jl jm kf jo jp jq jr ha bi translated">…我们可以使用机器学习来预测缺失数据的值。为此，我们将具有缺失值的特征视为<strong class="iy hi">目标向量</strong>，并使用剩余的特征子集来预测缺失值。虽然我们可以使用各种各样的机器学习算法来估算值，但最受欢迎的选择是KNN 。[12]</p></blockquote><p id="962a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Albon(2018) [12]指出，kNN是缺失值插补的流行选择。然而，就我而言，kNN是一种懒惰的学习方法，耗时，只适合小规模数据集。此外，我不认为kNN会优于RF，RF更有效，工作方式相似，平均而言，参考以下两幅图中描述的kNN、SVM(线性)、SVM (RBF)、决策树、随机森林、AdaBoost的决策边界。</p><div class="nb nc nd ne fd ab cb"><figure class="nq nf nr ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><img src="../Images/9d3f96613de81480efafe6477716dd64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*KC1ZrJKcAHg7ORZLAUweAQ.png"/></div></figure><figure class="nq nf nw ns nt nu nv paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><img src="../Images/aed0a9b476fd27cd766942914f5f9a90.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*Eog_qujdzIDnQVRXllAkvQ.png"/></div><figcaption class="nm nn et er es no np bd b be z dx nx di ny nz translated">图2 &amp; 3:不同模型的决策界限[13]</figcaption></figure></div><h2 id="c07f" class="kz ki hh bd kj la lb lc kn ld le lf kr jf lg lh kt jj li lj kv jn lk ll kx lm bi translated">4–3毫升插补方法</h2><p id="88d4" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">sk learn . impute . iterative imputr的文档介绍了一种测试，用于测量著名的“加州住房”数据集上各种插补方法的均方误差[14]。以下排名展示了意想不到的发现:</p><p id="98ed" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">BayesianRidge ≈树外回归因子&gt;决策树回归因子&gt;近邻回归因子≈平均值≈中值</p><figure class="nb nc nd ne fd nf er es paragraph-image"><div role="button" tabindex="0" class="ng nh di ni bf nj"><div class="er es oa"><img src="../Images/c44148b5e2afbf9566bbb0c898c97219.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*EI7XGE_VZ3uMYnKH.png"/></div></div><figcaption class="nm nn et er es no np bd b be z dx translated">图4:插补方法的比较[14]</figcaption></figure><ol class=""><li id="253c" class="ls lt hh iy b iz ja jc jd jf lu jj lv jn lw jr lx ly lz ma bi translated"><strong class="iy hi"> BayesianRidge </strong>:根据文档，这可以视为贝叶斯多重插补+正则项(lasso &amp; ridge)。</li><li id="22b6" class="ls lt hh iy b iz mb jc mc jf md jj me jn mf jr lx ly lz ma bi translated"><strong class="iy hi">extractreesregressor</strong>:类似于r中的<em class="js"> missForest( ) </em>，另外<em class="js"> missForest( ) </em>接近使用<em class="js"> rf </em>的<em class="js">mice()</em>；然而，<em class="js"> missForest( ) </em>的文档指出“它可以并行运行以节省计算时间。”因此，<em class="js"> missForest( ) </em>可以看作是使用<em class="js"> rf </em>的<em class="js"> mice( ) </em>的高效版本。</li><li id="486f" class="ls lt hh iy b iz mb jc mc jf md jj me jn mf jr lx ly lz ma bi translated">决策树回归器:决策树。</li><li id="03e9" class="ls lt hh iy b iz mb jc mc jf md jj me jn mf jr lx ly lz ma bi translated"><strong class="iy hi">KNeighborsRegressor</strong>:kNN。</li></ol></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="7d25" class="kh ki hh bd kj kk kl km kn ko kp kq kr in ks io kt iq ku ir kv it kw iu kx ky bi translated">(5)结论</h1><p id="5d57" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">在Python中，<strong class="iy hi"><em class="js">Bayesian ridge</em></strong>&amp;<strong class="iy hi"><em class="js">extractreesregressor</em>of<em class="js"/></strong><em class="js">sk learn . impute . iterative import</em>可能是输入缺失值的最佳选择。在R中，<strong class="iy hi"> <em class="js"> missForest( ) </em> </strong>包<strong class="iy hi"><em class="js">miss forest</em></strong>&amp;包<strong class="iy hi"><em class="js">mouse或者VIM </em> </strong>中的贝叶斯相关方法都是必须尝试的方法。</p></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="3484" class="kh ki hh bd kj kk kl km kn ko kp kq kr in ks io kt iq ku ir kv it kw iu kx ky bi translated">(6)参考文献</h1><p id="85ec" class="pw-post-body-paragraph iw ix hh iy b iz ln ii jb jc lo il je jf lp jh ji jj lq jl jm jn lr jp jq jr ha bi translated">[1]麦金尼，W. (2018)。<em class="js">用于数据分析的Python:与Pandas、NumPy、IPython的数据角力</em>。加利福尼亚州:奥赖利媒体。</p><p id="ef5e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[2]程，T. C .(身份不明)。NCCU统计系研究生水平课程<em class="js">应用回归分析</em>讲义。</p><p id="1053" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[3]奥兹德米尔，s .，&amp;苏萨拉，D. (2018)。<em class="js">特色工程变得简单</em>。英国伯明翰:Packt。</p><p id="1958" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[4]阿尔邦，C. (2018)。<em class="js">使用Python的机器学习食谱:从预处理到深度学习的实用解决方案</em>。加利福尼亚州:奥赖利媒体。</p><p id="51cc" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[5]新泽西州祖梅尔和新泽西州芒特(2014年)。<em class="js">实用数据科学带R </em>。纽约州谢尔特岛:曼宁。</p><p id="4398" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[6] Kowarik，a .，&amp; Templ，M. (2016年)。<em class="js">用R包VIM进行插补</em>。统计软件杂志，74卷7期。从https://bit.ly/3cqv7Qy<a class="ae kg" href="https://bit.ly/3cqv7Qy" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="7488" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[7] Sterne，J.A.C .，R . White I . R .等人(2009年)。<em class="js">流行病学和临床研究中缺失数据的多重插补:潜力和陷阱</em>。从https://bit.ly/30EFmv6<a class="ae kg" href="https://bit.ly/30EFmv6" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="1e9d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[8]范德普拉斯，J. (2017年)。<em class="js"> Python数据科学手册:处理数据的基本工具</em>。加利福尼亚州:奥赖利媒体。</p><p id="678c" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[9]韦克汉和格罗勒蒙德(2016年)。<em class="js"> R为数据科学</em>。加利福尼亚州:奥赖利媒体。</p><p id="4b8b" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[10]詹姆斯等人(2013年)。统计学习介绍:在R中的应用。纽约州纽约市:斯普林格。</p><p id="f948" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[11]亚马逊(2018)。<em class="js">亚马逊SageMaker支持kNN分类和回归</em>。从https://amzn.to/2Oy6nhp<a class="ae kg" href="https://amzn.to/2Oy6nhp" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="b621" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[12]与[4]相同</p><p id="3907" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[13]托马斯，M. (2016年)。比较分类器。从https://bit.ly/2OPx5lw<a class="ae kg" href="https://bit.ly/2OPx5lw" rel="noopener ugc nofollow" target="_blank">取回</a></p><p id="19fe" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[14]scikit-learn.org(身份不明)。用迭代输入器的变量输入缺失值。从https://bit.ly/3qLx4fu<a class="ae kg" href="https://bit.ly/3qLx4fu" rel="noopener ugc nofollow" target="_blank">取回</a></p></div></div>    
</body>
</html>