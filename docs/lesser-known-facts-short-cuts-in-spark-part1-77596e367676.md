# é²œä¸ºäººçŸ¥çš„äº‹å®/ç«èŠ±çš„æ·å¾„(ç¬¬ä¸€éƒ¨åˆ†)

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/lesser-known-facts-short-cuts-in-spark-part1-77596e367676?source=collection_archive---------0----------------------->

![](img/e25f73d32b4ce87257089e9d35e7b598.png)

é©¬å…‹Â·å¼—è±å½»Â·å¸ƒæœ—åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šçš„ç…§ç‰‡

ä½œä¸ºä¸€åæ•°æ®å·¥ç¨‹å¸ˆï¼Œæˆ‘ä»¬æ¯å¤©éƒ½é¢ä¸´æŒ‘æˆ˜ï¼Œéœ€è¦è§£å†³ä¸€äº›ä¸å¸¸è§çš„æ¡ˆä¾‹ã€‚

æˆ‘ä»¬ä¸èƒ½æŠŠåŒæ ·çš„æ€ç»´è¿‡ç¨‹åº”ç”¨åˆ°æ‰€æœ‰çš„åœ°æ–¹ã€‚æˆ‘ä»¬éœ€è¦è€ƒè™‘éœ€è¦ä»˜å‡ºçš„åŠªåŠ›ä»¥åŠå¦‚ä½•å‡å°‘æ—¶é—´ã€‚

ä½†ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä»¬åº”è¯¥åœ¨ä¸‹ç»“è®ºä¹‹å‰äº†è§£å†…éƒ¨æƒ…å†µã€‚

åœ¨è¿™ç¯‡åšå®¢ä¸­ï¼Œæˆ‘å°†è®¨è®º Spark ä¸­çš„ä¸€äº›æŠ€å·§å’Œçªé—¨ä»¥åŠä¸€äº›é²œä¸ºäººçŸ¥çš„äº‹å®ï¼Œè¿™äº›å¯¹æˆ‘ä»¬å¤§å¤šæ•°æ•°æ®å·¥ç¨‹å¸ˆæ¥è¯´éƒ½å¾ˆæœ‰ç”¨ã€‚

# 1.count()æ€»æ˜¯è§¦å‘å¯¹æ¯ä¸€è¡Œçš„æ±‚å€¼ï¼Ÿ

æˆ‘ä»¬çŸ¥é“ã€‚ç¼“å­˜æˆ–æŒä¹…åŒ–æ˜¯ä¸€ç§è½¬æ¢ã€‚é™¤éæˆ‘ä»¬å¯¹ç¼“å­˜çš„æ•°æ®å¸§è°ƒç”¨ä»»ä½•æ“ä½œï¼Œå¦åˆ™å®ƒä¸ä¼šè¢«å…·ä½“åŒ–ã€‚

æˆ‘è·‘äº†åˆæ€ä¹ˆæ ·ã€‚æŒ‡æœ›æ•°æ®å¸§ï¼Ÿå®ƒåº”è¯¥ç¼“å­˜/ç‰©åŒ–æ•°æ®ï¼Œå¯¹å—ï¼Ÿ

ä¸å°½ç„¶ï¼Œä¸ rdd ç›¸æ¯”ï¼Œæ•°æ®å¸§å’Œæ•°æ®é›†ä¸Šçš„è®¡æ•°æ˜¯ä¸åŒçš„ã€‚

åœ¨ RDDï¼Œæˆ‘ä»¬æ²¡æœ‰ rdd ä¸Šçš„ catalyst optimiserï¼Œå› æ­¤å®ƒå°†å§‹ç»ˆè¯„ä¼°ä¸€åˆ‡ã€‚

ä½†æ˜¯å¦ä¸€æ–¹é¢ï¼Œé€šè¿‡ä½¿ç”¨ catalystï¼ŒDataFrame/Dataset å˜å¾—æ›´åŠ æ™ºèƒ½ï¼Œå®ƒå˜æˆäº† SQL ä¸­çš„â€œselect count(*) from â€¦â€çš„ç­‰ä»·ç‰©ï¼Œè¿™å¯ä»¥åœ¨ä¸æ‰«ææŸäº›æ•°æ®æ ¼å¼çš„æ•°æ®çš„æƒ…å†µä¸‹å®Œæˆ(ä¾‹å¦‚ï¼ŒParquet)ã€‚

ä½†æ˜¯è¯·æ³¨æ„ï¼Œå¦ä¸€æ–¹é¢ï¼Œç¼“å­˜æ•°æ®å¸§/æ•°æ®é›†ç¡®å®éœ€è¦ç¼“å­˜æ‰€æœ‰å†…å®¹ã€‚

éœ€è¦äº†è§£æ›´å¤šï¼Ÿ

[https://databricks . com/blog/2017/02/16/processing-ä¸‡äº¿è¡Œæ¯ç§’-å•æœº-can-nested-loop-joins-fast . html](https://databricks.com/blog/2017/02/16/processing-trillion-rows-per-second-single-machine-can-nested-loop-joins-fast.html)

# 2.åœ¨æ•°æ®æ¡†ä¸­æŸ¥æ‰¾ç©ºåˆ—çš„å¿«æ·æ–¹å¼ï¼Ÿ

åœ¨åŒ…å« 100 åˆ—çš„æ•°æ®å¸§çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éœ€è¦è·å¾—æ¯ä¸€åˆ—ä¸­çš„ç©ºè®°å½•çš„è®¡æ•°ï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨ã€‚å¯¹æ¯ä¸€åˆ—ä½¿ç”¨ç©ºå‡½æ•°ï¼Œæˆ–è€…åªä½¿ç”¨ä¸€ä¸ªç®€å•çš„å‘½ä»¤ï¼Œå¦‚:

**df . select(df . columns . map(c =>sum(col(c). is null . cast(" int "))ã€‚åˆ«å(c)): _*)ã€‚show()**

![](img/dc15b41cfa5e05b3277aa310b70f571c.png)

# 3.ä»€ä¹ˆæ˜¯ metastore è¶…æ—¶ï¼Ÿæˆ‘ä¸ºä»€ä¹ˆè¦åœ¨ä¹ï¼Ÿ

***æ— æ³•è·å–åˆ° jdbc çš„è¿æ¥:MySQL://<>/central _ metastoreï¼Ÿuse SSL = true&requires sl = falseã€‚ä¼‘çœ  7000 æ¯«ç§’ã€‚å‰©ä½™å°è¯•æ¬¡æ•°:2 æ¬¡***

ä¸¾ä¸€ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬ä½¿ç”¨ spark å°†æ•°æ®è¾“å…¥ ADLSGen2/S3ï¼Œä½¿ç”¨ API æˆ– HTTPS è°ƒç”¨ï¼Œä¾‹å¦‚ä½¿ç”¨ sprimgml åº“è°ƒç”¨ SFDCã€‚

[https://github.com/springml/spark-salesforce](https://github.com/springml/spark-salesforce)

Springml spark-salesforce åº“å°†å¸®åŠ©æ‚¨è¿æ¥åˆ° SFDC å¹¶è·å–æ•°æ®ã€‚

è¿™ä½¿å¾— HTTPS æ°‘è°ƒä¸åŒäºå…¶ä»– JDBC æ°‘è°ƒã€‚

ååé‡æ ¹æ®æˆ‘ä»¬åœ¨æ¯ä¸ª https è°ƒç”¨ä¸­å°è¯•è®¿é—®çš„åˆ—æ•°è€Œå˜åŒ–ã€‚

å½“æˆ‘ä»¬è¯•å›¾è®¿é—®ä¸€ä¸ªæ‹¥æœ‰æ•°ç™¾ä¸‡æ¡è®°å½•çš„å·¨å¤§å¯¹è±¡æ—¶ï¼ŒSpark å°†èŠ±è´¹å¤§é‡æ—¶é—´æŸ¥è¯¢ SFDCã€‚

å½“ spark å®Œæˆ GET è¯·æ±‚æ—¶ï¼Œhive metastores è¶…æ—¶ã€‚

æ— æ³•è·å–åˆ° jdbc çš„è¿æ¥:mysql:// <> /central_metastoreï¼ŸuseSSL=true&requireSSL=falseã€‚ä¼‘çœ  7000 æ¯«ç§’ã€‚å‰©ä½™å°è¯•æ¬¡æ•°:2

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éœ€è¦è°ƒæ•´ä»¥ä¸‹å‚æ•°ã€‚

```
**spark.hadoop.hive.server2.session.check.interval(default 60000ms)****spark.hadoop.hive.server2.idle.operation.timeout(default 7200000ms)****spark.hadoop.hive.server2.idle.session.timeout(default 900000ms)*****spark.hadoop.hive.server2.idle.operation.interval***
```

ä¼šè¯/æ“ä½œè¶…æ—¶çš„æ£€æŸ¥é—´éš”ï¼Œä»¥æ¯«ç§’ä¸ºå•ä½ï¼Œå¯é€šè¿‡è®¾ç½®ä¸ºé›¶æˆ–è´Ÿå€¼æ¥ç¦ç”¨ã€‚
ä¾‹å¦‚ï¼Œå€¼â€œ60000â€è¡¨ç¤º 1 åˆ†é’Ÿï¼Œè¡¨ç¤ºæ¯ 1 åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ä¼šè¯ã€‚

**T4 b . spark . Hadoop . hive . server 2 . idle . operation . time out**

åœ¨è¿™æ®µæ—¶é—´å†…æœªè¢«è®¿é—®æ—¶ï¼Œæ“ä½œå°†è¢«å…³é—­ï¼Œå•ä½ä¸ºæ¯«ç§’ã€‚é€šè¿‡è®¾ç½®ä¸ºé›¶æ¥ç¦ç”¨ã€‚

å¯¹äºæ­£å€¼ï¼Œä»…æ£€æŸ¥ç»ˆç«¯çŠ¶æ€ä¸‹çš„æ“ä½œ(å·²å®Œæˆã€å·²å–æ¶ˆã€å·²å…³é—­ã€å‡ºé”™)ã€‚å¯¹äºè´Ÿå€¼ï¼Œæ£€æŸ¥æ‰€æœ‰æ“ä½œï¼Œè€Œä¸ç®¡çŠ¶æ€å¦‚ä½•ã€‚
ä¾‹å¦‚ï¼Œå€¼â€œ7200000msâ€è¡¨ç¤ºå¦‚æœæŸ¥è¯¢/æ“ä½œä»åœ¨è¿è¡Œï¼Œå°†åœ¨ 2 å°æ—¶åè¶…æ—¶ã€‚

***c . spark . Hadoop . hive . server 2 . idle . session . time out***

å¦‚æœä¼šè¯åœ¨ç»™å®šçš„æŒç»­æ—¶é—´(æ¯«ç§’)å†…æœªè¢«è®¿é—®ï¼Œä¼šè¯å°†è¢«å…³é—­ã€‚

æˆ‘ä»¬å¯ä»¥ç¦ç”¨è®¾ç½®ä¸ºé›¶æˆ–è´Ÿå€¼ã€‚
å€¼â€œ900000â€è¡¨ç¤ºä¼šè¯å°†åœ¨ 15 åˆ†é’Ÿä¸æ´»åŠ¨åè¶…æ—¶ã€‚

# **4ã€‚æˆ‘è¯¥ç”¨ä»€ä¹ˆï¼ŒSavemodeã€‚è¦†ç›–è¿˜æ˜¯æ¨¡å¼(â€œè¦†ç›–â€)ï¼Ÿï¼Ÿ**

å½“æˆ‘ä»¬åœ¨ SparkSQL ä¸Šå·¥ä½œæ—¶ï¼Œä¸€äº›å¼€å‘äººå‘˜ä½¿ç”¨â€œoverwriteâ€æ¨¡å¼ï¼Œä¸€äº›ä½¿ç”¨â€œSavemode.overwriteâ€æ¨¡å¼ã€‚

ä¸¤è€…æœ‰åŒºåˆ«å—ï¼Ÿ

ä¸ï¼Œâ€œè¦†ç›–â€æ˜¯ Savemode.overwrite çš„ç®€å†™å‘½ä»¤

çœ‹çœ‹ä¸‹é¢çš„æºä»£ç ã€‚

```
**/**
 * Specifies the behavior when data or table already exists. Options include:
 * â€” `overwrite`: overwrite the existing data.
 * â€” `append`: append the data.
 * â€” `ignore`: ignore the operation (i.e. no-op).
 * â€” `error` or `errorifexists`: default option, throw an exception at runtime.
 *
 * @since 1.4.0
 */****def mode(saveMode: String): DataFrameWriter[T] = {
 this.*mode* = saveMode.toLowerCase(Locale.*ROOT*) match {
 case â€œoverwriteâ€ => SaveMode.*Overwrite* case â€œappendâ€ => SaveMode.*Append* case â€œignoreâ€ => SaveMode.*Ignore* case â€œerrorâ€ | â€œerrorifexistsâ€ | â€œdefaultâ€ => SaveMode.*ErrorIfExists* case _ => throw new IllegalArgumentException(sâ€Unknown save mode: $saveMode. â€ +
 â€œAccepted save modes are â€˜overwriteâ€™, â€˜appendâ€™, â€˜ignoreâ€™, â€˜errorâ€™, â€˜errorifexistsâ€™.â€)
 }
 this
}**
```

# 5.ç«èŠ±ä¸åŒ VS ä¸¢å¼ƒé‡å¤

distinct å’Œ DropDuplicates ä¹‹é—´çš„ä¸»è¦åŒºåˆ«ä»…åœ¨äºåˆ—çš„å­é›†ã€‚

åœ¨ Distinct å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬éœ€è¦åœ¨è°ƒç”¨å‡½æ•°ä¹‹å‰ä¼ é€’ select å­å¥ä¸­çš„åˆ—ã€‚

å…¶ä¸­ï¼Œ`dropDuplicates(colNames)`å°†åœ¨åˆ é™¤ç»™å®šåˆ—çš„é‡å¤é¡¹åè¿”å›æ•°æ®å¸§ä¸­çš„æ‰€æœ‰åˆ—ã€‚

ä» [javadoc](https://spark.apache.org/docs/1.5.1/api/java/org/apache/spark/sql/DataFrame.html#dropDuplicates()) æ¥çœ‹ï¼Œdistinc()å’Œ dropDuplicates()æ²¡æœ‰åŒºåˆ«ã€‚

```
**dropDuplicates****public DataFrame dropDuplicates()****Returns a new DataFrame that contains only the unique rows from this DataFrame. This is an alias for distinct.**
```

dropDuplicates()æ˜¯åœ¨ 1.4 ä¸­ä½œä¸º distinct()çš„æ›¿ä»£è€Œå¼•å…¥çš„ï¼Œå› ä¸ºæ‚¨å¯ä»¥ä½¿ç”¨å®ƒçš„é‡è½½æ–¹æ³•æ¥è·å¾—åŸºäºåˆ—å­é›†çš„å”¯ä¸€è¡Œã€‚

æœªå®Œå¾…ç»­..

ç¬¬ 2 éƒ¨åˆ†å·²ç»åœ¨è¿™é‡Œå‘è¡¨äº†ã€‚

[](https://link.medium.com/lExxlOuM9hb) [## é²œä¸ºäººçŸ¥çš„äº‹å®/ç«èŠ±çš„æ·å¾„(ç¬¬äºŒéƒ¨åˆ†)

### è¿™æ˜¯é²œä¸ºäººçŸ¥çš„äº‹å®/ç«èŠ±æ·å¾„çš„ç¬¬äºŒéƒ¨åˆ†ï¼Œæˆ‘å°†åœ¨è¿™é‡Œè°ˆè®ºä¸€äº›æœªçŸ¥çš„å’Œâ€¦

link.medium.com](https://link.medium.com/lExxlOuM9hb) ![](img/0564afa916f47d189c7aef68aa837e17.png)

ä½ å¯ä»¥åœ¨è¯„è®ºä¸­å‘è¡¨ä½ çš„åé¦ˆã€‚

é˜¿å‰ç‰¹Â·åº“ç›å°”Â·è°¢è’‚

å¤§æ•°æ®å·¥ç¨‹å¸ˆâ€”çƒ­çˆ±å¤§æ•°æ®ã€åˆ†æã€äº‘å’ŒåŸºç¡€è®¾æ–½ã€‚

[è®¢é˜…](https://ajithshetty28.medium.com/subscribe) âœ‰ï¸ || [æ›´å¤šåšå®¢](https://ajithshetty28.medium.com/)ğŸ“|| [é“¾æ¥äº](https://www.linkedin.com/in/ajshetty28)ğŸ“Š|| [ä¸ªäººèµ„æ–™é¡µé¢](https://ajithshetty.github.io/)ğŸ“š|| [Git å›è´­](https://github.com/ajithshetty/)ğŸ‘“

**è®¢é˜…æˆ‘çš„:** [**æ¯å‘¨ç®€è®¯åˆšå¥½å¤Ÿæ•°æ®**](https://justenoughdata.substack.com/)