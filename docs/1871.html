<html>
<head>
<title>Parse Confluent Kafka messages without Avro schema registry</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不使用Avro模式注册表解析融合Kafka消息</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/parse-confluent-kafka-messages-without-avro-schema-registry-b1b24013af7a?source=collection_archive---------10-----------------------#2021-03-23">https://medium.com/analytics-vidhya/parse-confluent-kafka-messages-without-avro-schema-registry-b1b24013af7a?source=collection_archive---------10-----------------------#2021-03-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/3670d9f6207cc324225730b94a5b9a99.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/0*iqza3grlPh_kjqlt"/></div></figure><h1 id="bbd6" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">解析二进制序列化程序</h1><h1 id="a04f" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">用例</h1><ul class=""><li id="94b4" class="jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">融合的卡夫卡信息被推送到事件中心</li><li id="e727" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">使用镜像制作工具移动消息</li><li id="021b" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">合流使用的二进制Avro格式进行序列化</li><li id="adf4" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">模式注册id也内置在消息有效负载中</li></ul><h1 id="a15f" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">要求</h1><ul class=""><li id="9120" class="jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">Azure帐户</li><li id="8661" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">创建事件中心命名空间标准版</li><li id="fef3" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">创建一个活动中心</li><li id="7f3c" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">在源Kafka中安装镜像制作工具2</li><li id="5f10" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">从事件中心获取SAS密钥</li><li id="0c3c" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">配置镜像生成器，使用SAS密钥向事件中心发送消息</li><li id="00b0" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">选择要发送的主题</li><li id="fa1f" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">在事件中心中，每个主题将创建一个与Kafka相同主题名称的事件中心</li><li id="22a8" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">创建Azure数据块</li><li id="c892" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">使用运行时7.6创建集群</li><li id="2860" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">创建pyspark笔记本</li></ul><h1 id="3898" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">代码部分</h1><ul class=""><li id="613d" class="jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb bi translated">使用Azure数据块</li><li id="a4a7" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">使用python spark解析代码</li><li id="ebfe" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">装载进口货物</li><li id="361c" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">创建一个函数来分隔融合位，如模式id和值</li><li id="23aa" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">前4个字节作为模式id。</li><li id="7230" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">移除这6个字节会使处理变得更容易，因为剩余的都是Avro</li><li id="d6a5" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">1个字节是汇合的幻字节</li><li id="6c2b" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">2–5个字节是模式id值</li></ul><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="b3ad" class="kq in hi km b fi kr ks l kt ku">%python<br/>from pyspark.sql.types import StringType<br/>from pyspark.sql.functions import udf<br/>import pyspark.sql.functions as fn<br/><br/>binary_to_string = fn.udf(lambda x: str(int.from_bytes(x, byteorder='big')), StringType())</span><span id="3475" class="kq in hi km b fi kv ks l kt ku">%python<br/><br/>df1 = spark.read.format("avro").option("mode", "PERMISSIVE").option("header", "true").load("dbfs:/FileStore/shared_uploads/xxxx@xxxxx.com/part_00000_ae91d923_dcca_4690_xxxx_xxxxxxxxxx_c000.avro")</span><span id="5999" class="kq in hi km b fi kv ks l kt ku">%python<br/><br/>display(df1)</span></pre><ul class=""><li id="8052" class="jk jl hi jm b jn kw jp kx jr ky jt kz jv la jx jy jz ka kb bi translated">拆分子字符串</li><li id="a6e1" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">拉模式ID</li></ul><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="42e3" class="kq in hi km b fi kr ks l kt ku">%python<br/>df2 = df1 \<br/>  .withColumn('fixedValue', fn.expr("substring(value, 6, length(value)-5)")) \<br/>  .withColumn('valueSchemaId', binary_to_string(fn.expr("substring(value, 2, 4)")))</span></pre><ul class=""><li id="8a2c" class="jk jl hi jm b jn kw jp kx jr ky jt kz jv la jx jy jz ka kb bi translated">现在加载Avro模式文件</li><li id="71b8" class="jk jl hi jm b jn kc jp kd jr ke jt kf jv kg jx jy jz ka kb bi translated">从融合Kafka注册表导出模式信息</li></ul><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="7dfa" class="kq in hi km b fi kr ks l kt ku">%python<br/>from pyspark.sql.avro.functions import from_avro, to_avro<br/><br/>jsonFormatSchema = open("/dbfs/FileStore/shared_uploads/xxxx@xxxxxxx.com/avro_####_schemaname.avsc", "r").read()</span><span id="4e43" class="kq in hi km b fi kv ks l kt ku">%python<br/>import pyspark.sql.avro.functions<br/>from pyspark.sql.avro.functions import from_avro, to_avro<br/><br/># display(df2.select(from_avro('fixedValue, schema.toString()) as 'record))<br/>output = df2\<br/>  .select(from_avro("fixedValue", jsonFormatSchema).alias("record")</span><span id="c9c0" class="kq in hi km b fi kv ks l kt ku">%python<br/>display(output.select("record"))</span><span id="b554" class="kq in hi km b fi kv ks l kt ku">%python<br/>df3 = output.select("record.*")<br/>display(output.select("record.*"))</span><span id="7f56" class="kq in hi km b fi kv ks l kt ku">%python<br/>output.select("record.*").count()</span></pre></div><div class="ab cl lb lc gp ld" role="separator"><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg lh"/><span class="le bw bk lf lg"/></div><div class="hb hc hd he hf"><p id="a897" class="pw-post-body-paragraph li lj hi jm b jn kw lk ll jp kx lm ln jr lo lp lq jt lr ls lt jv lu lv lw jx hb bi translated"><em class="lx">最初发表于</em><a class="ae ly" href="https://github.com/balakreshnan/Accenture/blob/master/Ingestion/confluentkafka.md" rel="noopener ugc nofollow" target="_blank"><em class="lx">【https://github.com】</em></a><em class="lx">。</em></p></div></div>    
</body>
</html>