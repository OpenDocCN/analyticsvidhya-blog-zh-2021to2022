<html>
<head>
<title>Custom OCR with Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带有机器学习的自定义OCR</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ocr-with-machine-learning-55c7d082fe78?source=collection_archive---------7-----------------------#2021-02-11">https://medium.com/analytics-vidhya/ocr-with-machine-learning-55c7d082fe78?source=collection_archive---------7-----------------------#2021-02-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ea7f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不是每个AI问题都需要深度学习。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/3488a8781860279927103ebbb139560b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LjgDi4m2NqZzyQt_LKerFA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">作者图片</figcaption></figure><p id="9e61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在撰写本文时，关于使用机器学习的自定义光学字符识别的帖子数量非常少。你可能会看到的常见方法利用了深度学习或<a class="ae js" href="https://github.com/tesseract-ocr/tesseract" rel="noopener ugc nofollow" target="_blank">宇宙魔方</a>库。在这篇文章中，我将解释如何使用机器学习来训练你自己的光学字符识别器。我们要研究的方法不需要太多的数据，但是执行起来非常好。我用这个为尼日利亚车牌制作了一个原型ALPR。所以让我们开始吧。</p><p id="c357" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，你要知道OCR，就像你的<em class="jt">猫vs狗</em>教程一样，只是图像分类。是啊！一种多类图像分类。然而，在这种情况下，你的文件夹不会被标记为<strong class="ig hi">猫和狗</strong>，而是<strong class="ig hi"> A-Z </strong>和<strong class="ig hi">0–9</strong>。</p><p id="5f7d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">！！！</strong>注意有时<strong class="ig hi">零‘0’</strong>可能看起来像<strong class="ig hi">字母‘O’，</strong>根据你的字体类型选择一个或两个<strong class="ig hi">。</strong></p><p id="6673" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此外，我们不会使用Keras、Tensorflow或任何深度学习库。相反，我们将使用一种我们都知道并且喜爱的流行的机器学习分类算法，<em class="jt">逻辑回归</em>。</p><h1 id="030e" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">概述</h1><p id="c4e1" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">1.收集和清理数据集</p><p id="9b38" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.基于梯度方向直方图的特征提取</p><p id="b390" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.培训和测试</p><h1 id="5249" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak">收集和清理数据</strong></h1><p id="4244" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">像所有机器学习问题一样，我需要数据。数据是驱动<em class="jt">人工智能</em>的引擎。正如我前面提到的，这是用于车牌识别程序。所以，我在镇上到处走，给汽车拍照和录像。对于视频，我写了一个简单的程序来每秒保存2帧。最后，我有了相当多的车牌，然而，我没有使用所有的照片，因为这是一个原型，但结果令人印象深刻。由于大多数车牌都是歪斜的，所以还有很多工作要做。我必须对所有的图像进行透视校正。</p><p id="7f54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样，利用我的图像处理技能，我用OpenCV编写了另一个python脚本来帮助我在选择了车牌的四个角之后校正透视。此后，我对图像进行了阈值处理，得到了提取并保存的字母轮廓。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kx"><img src="../Images/cb8af5180e575f913f556c908aa8ea30.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/1*X20XcEv03d8TnBAO2NBmJw.gif"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">透视变换—作者的图像</figcaption></figure><p id="a7fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">仍然在清理中，我有大约1037张不同字母A-Z，0-9的图片，这些图片又要被分类到它们各自的文件夹中。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ky"><img src="../Images/e8502cd8cb2abe1fb1eebaf195ce1990.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*RdjR8YEHCCcJccIe1oK0sg.gif"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">要排序的字符-按作者排序的图像</figcaption></figure><p id="707a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">拖放当然不是一个选项，所以再次，python来拯救！！。编写了另一个脚本，但是这一次，程序一个接一个地显示字符，并且当在键盘上按下相应的字符时，它保存到适当的文件夹中。因此，如果显示字母<strong class="ig hi">‘A’</strong>的图像，并且在键盘上按下<strong class="ig hi">‘A’</strong>，它会将其保存到文件夹<strong class="ig hi">‘A’</strong>。最后，我还必须做视觉确认，并消除任何错误。最后，清洗和分类完成了！</p><h1 id="a6a5" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak">使用梯度方向直方图(HOG)的特征提取</strong></h1><p id="5531" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">现在，我的数据已经被清理了，至少60%的工作已经完成。我开始从我的图像中提取特征。</p><p id="e698" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">给大家介绍一下，<strong class="ig hi">方向渐变直方图(HOG) </strong>。HOG从2004年就有了，现在还在用。如果你是那些跳过图像处理的基础，跳入深度学习的人之一，你可能不知道我在说什么。然而，只需知道它类似于发生在卷积神经网络中的特征提取，因此<a class="ae js" href="https://learnopencv.com/histogram-of-oriented-gradients/" rel="noopener ugc nofollow" target="_blank">参见此处</a>了解更多细节。</p><p id="dc41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们通过使用下面的代码来看看一只猪是什么样子的。</p><pre class="jd je jf jg fd kz la lb lc aw ld bi"><span id="728b" class="le jv hh la b fi lf lg l lh li">import cv2<br/>from skimage.feature import hog</span><span id="521e" class="le jv hh la b fi lj lg l lh li">im_test =  cv2.imread('ocr_data/train/A/roi107644.jpg',0)<br/>_,hog_img= hog(im_test,orientations=9,pixels_per_cell=(8,8), cells_per_block=(1, 1),visualize=<strong class="la hi">True</strong>)<br/>plt.imshow(hog_img,cmap='gray')</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lk"><img src="../Images/1d1cb91e73dc31ecc57b1e82c0e68d33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eLsMb2kpG0Ennpxq1zh2Ow.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">字母A的方向梯度直方图(HOG)——作者图片</figcaption></figure><p id="65cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是，我把它当成了一维数组。数组的长度通常由提取HOG的参数集决定。在这个例子中，我的是1052列。</p><h1 id="2cc0" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">使用逻辑回归和测试进行培训</h1><p id="7b75" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">从这里，我读入每幅图像，执行特征提取，然后将提取的特征及其相应的标签存储在一个列表中，稍后再将其转换为数据帧。</p><pre class="jd je jf jg fd kz la lb lc aw ld bi"><span id="f793" class="le jv hh la b fi lf lg l lh li">features = []<br/>labels = []<br/><strong class="la hi">for</strong> i,j <strong class="la hi">in</strong> enumerate(zip(pathimg,labels_list)):<br/>  imgs,label = j<br/>  <strong class="la hi">for</strong> img <strong class="la hi">in</strong> imgs:<br/>      img = cv2.imread(train_dir+label+'/'+img)<br/>      img_res=cv2.resize(img,(64,128),interpolation=cv2.INTER_AREA)<br/>      img_gray= cv2.cvtColor(img_res,cv2.COLOR_BGR2GRAY)<br/>      hog_img= hog(img_gray,orientations=9,pixels_per_cell=(8,8), cells_per_block=(1, 1))<br/>      features.append(hog_img)<br/>      labels.append(label)</span><span id="804c" class="le jv hh la b fi lj lg l lh li">df = pd.DataFrame(np.array(features))<br/>df['target'] = labels<br/>df</span></pre><p id="28b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后我检查数据是否平衡，通过使用</p><pre class="jd je jf jg fd kz la lb lc aw ld bi"><span id="f4c4" class="le jv hh la b fi lf lg l lh li">sns.countplot(x='target', data=df)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ll"><img src="../Images/e048ffc944181462a62e2d8648492de4.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*uqoR4xaIzErEWnXCPX-yVA.png"/></div></figure><p id="64fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">哎呀，数据非常不平衡。然后我们把它分成训练集和测试集，然后使用imblearn I通过过采样来平衡数据。</p><h1 id="684a" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated"><strong class="ak">培训</strong></h1><p id="84d4" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">在这里，我使用逻辑回归来构建我的分类器。</p><pre class="jd je jf jg fd kz la lb lc aw ld bi"><span id="5a37" class="le jv hh la b fi lf lg l lh li">x = np.array(df.iloc[:,:-1])<br/>y = np.array(df['target'])</span><span id="02cc" class="le jv hh la b fi lj lg l lh li">from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import train_test_split<br/>x_train, x_test, y_train, y_test = train_test_split(x, y,<br/>                                                    test_size=0.20,<br/>                                                    random_state=42)</span><span id="187e" class="le jv hh la b fi lj lg l lh li">from imblearn.over_sampling import SMOTE<br/>sm = SMOTE(random_state=0)<br/>sm_x,sm_y=sm.fit_sample(x_train, y_train)</span><span id="8969" class="le jv hh la b fi lj lg l lh li">bal_df = pd.DataFrame(sm_x)<br/>bal_df['target']=pd.DataFrame(sm_y)<br/>sns.countplot(x='target', data=bal_df)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ll"><img src="../Images/94beeb0486246b5e7cbb97d4ddbf8e86.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*2rKYdqOpfcBvba0K4pN4sg.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">平衡数据—按作者分类的图像</figcaption></figure><pre class="jd je jf jg fd kz la lb lc aw ld bi"><span id="a9fc" class="le jv hh la b fi lf lg l lh li">lreg = LogisticRegression()<br/>clf=lreg.fit(sm_x, sm_y)<br/>y_pred = clf.predict(x_test)<br/>print('Accuracy <strong class="la hi">{:.2f}</strong>'.format(clf.score(x_test, y_test)))<br/><br/><strong class="la hi">from</strong> <strong class="la hi">sklearn.metrics</strong> <strong class="la hi">import</strong> classification_report<br/>print(classification_report(y_test, y_pred))</span></pre><p id="8ab9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是培训的结果。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lm"><img src="../Images/b22c5312f9d339ec9e24619534f6f003.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/format:webp/1*lxBalxWB0tSFiGAAaKKBfg.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">ocr分类报告-按作者分类的图像</figcaption></figure><h1 id="d580" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">测试</h1><p id="e007" class="pw-post-body-paragraph ie if hh ig b ih ks ij ik il kt in io ip ku ir is it kv iv iw ix kw iz ja jb ha bi translated">最后，让我们使用我们的模型。</p><p id="aa21" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们加载我们的分类器并读入我们的图像。</p><pre class="jd je jf jg fd kz la lb lc aw ld bi"><span id="9a8c" class="le jv hh la b fi lf lg l lh li"># Load the classifier<br/>clf = joblib.load("ocr_data/models/hog_lreg_model_3.pkl")</span><span id="e283" class="le jv hh la b fi lj lg l lh li"># Read the input image<br/>im = cv2.imread("ocr_data/licenseplates/licplate4.jpg")</span></pre><p id="76ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们将图像转换为灰度，这样我们就可以对其进行阈值处理，找到轮廓，然后从左到右对其进行排序。您可以查找python的“排序”内置函数。</p><pre class="jd je jf jg fd kz la lb lc aw ld bi"><span id="1914" class="le jv hh la b fi lf lg l lh li"># Convert to grayscale<br/>im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)<br/><br/># Threshold the image in order to find contours<br/>ret, im_th = cv2.threshold(im_gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)</span><span id="ce18" class="le jv hh la b fi lj lg l lh li"># Find contours in the image<br/>ctrs,hier = cv2.findContours(im_th, cv2.RETR_TREE,<br/>                                 cv2.CHAIN_APPROX_SIMPLE)<br/>bboxes=[cv2.boundingRect(c) for c in ctrs]<br/>sorted_bboxes = sorted(bboxes,key=lambda b:b[0])</span></pre><p id="78f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们使用指定的最大宽度和高度遍历排序后的边界框，裁剪字符，调整大小，提取HOG特征，将它们传递给分类器以获得预测，然后将结果存储在一个列表中。</p><pre class="jd je jf jg fd kz la lb lc aw ld bi"><span id="2823" class="le jv hh la b fi lf lg l lh li">plate_char=[]<br/>for num,i_bboxes in enumerate(sorted_bboxes):<br/>    [x,y,w,h]=i_bboxes<br/>    if h&gt;100 and w &lt; 100:<br/>    # Make the rectangular region around the digit<br/>        cv2.rectangle(im,(x,y),(x+w,y+h),(0,255,0),1)<br/>        roi=im_gray[y:y+h,x:x+w]<br/>        # Resize the image<br/>        roi = cv2.resize(roi, (64, 128), interpolation=cv2.INTER_AREA)<br/>        # Calculate the HOG features<br/>        # use the same parameters used for training<br/>        roi_hog_fd = hog(roi, orientations=9, pixels_per_cell=(8, 8),<br/>                         cells_per_block=(1, 1))<br/>        cpred = clf.predict(np.array([roi_hog_fd]))<br/>        <br/>        cv2.putText(im, str((cpred[0])), (x,y+h),cv2.FONT_HERSHEY_SIMPLEX,<br/>                    2, (0, 200, 250), 3)<br/>        plate_char.append(str(cpred[0]))</span><span id="ed62" class="le jv hh la b fi lj lg l lh li">print(''.join(plate_char))</span><span id="03a1" class="le jv hh la b fi lj lg l lh li">cv2.imshow('result',im)</span></pre><p id="ca06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就是这样！</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ln"><img src="../Images/71b90704c2c1bca44e754cfa49fa84f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*T_5f2ovkD825Ek141hW4Kg.jpeg"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">作者使用训练过的模型图像在车牌上执行ocr</figcaption></figure><p id="7346" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">笔记本的链接可以在<a class="ae js" href="https://github.com/jideilori/ocr-ml" rel="noopener ugc nofollow" target="_blank">这里</a>找到</p></div></div>    
</body>
</html>