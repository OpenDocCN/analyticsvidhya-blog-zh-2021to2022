<html>
<head>
<title>Logistic Regression Understanding and Implementation From Scratch (Part 2)| Python | Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始理解和实现逻辑回归(第2部分)| Python |机器学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/logistic-regression-understanding-and-implementation-from-scratch-part-2-python-machine-4fe70100bc90?source=collection_archive---------2-----------------------#2021-06-16">https://medium.com/analytics-vidhya/logistic-regression-understanding-and-implementation-from-scratch-part-2-python-machine-4fe70100bc90?source=collection_archive---------2-----------------------#2021-06-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/e3f4daffcc0cd113c2757e3c5be1df09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ES05amEOBioOFAxIy9YLLg.png"/></div></div></figure><ul class=""><li id="bfba" class="ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg bi translated">这是一个由两部分组成的系列。  <a class="ae ji" href="https://writersbyte.com/programming/logistic-regression-understanding-and-implementation-from-scratch-part-1-python-machine-learning/" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi"> <em class="jh">第一部分</em> </strong> </a> <strong class="ir hi"> <em class="jh">将是所有关于逻辑回归算法的理论理解。第2部分(这一部分)将涵盖编码部分，我们将在这里用PYTHON* </em> </strong>实现逻辑回归</li></ul><p id="bab2" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">如果你对逻辑回归算法 的<strong class="ir hi"> <em class="jh">理论工作感到困惑，你可以在这里阅读第一部分<a class="ae ji" href="https://writersbyte.com/programming/logistic-regression-understanding-and-implementation-from-scratch-part-1-python-machine-learning/" rel="noopener ugc nofollow" target="_blank">。</a></em></strong></p><p id="924b" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">本教程中使用的全部代码可以在这里找到。</p><p id="2d5b" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">因为我们有密切相关的逻辑回归和线性回归，我建议你也阅读一下线性回归，以便更好地理解这些算法。你可以在这里阅读<a class="ae ji" href="https://writersbyte.com/datascience/implementing-multi-variable-linear-regression-algorithm-in-python/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="8dc8" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">因为我们已经在第1部分中介绍了这个理论，这里我们将直接进入代码。</p><div class="jy jz ez fb ka kb"><a href="https://writersbyte.com/windows/chocolatey-package-manager-a-sweet-way-to-install-software-on-windows/" rel="noopener  ugc nofollow" target="_blank"><div class="kc ab dw"><div class="kd ab ke cl cj kf"><h2 class="bd hi fi z dy kg ea eb kh ed ef hg bi translated">Chocolatey软件包管理器:在Windows上安装软件的好方法</h2><div class="ki l"><h3 class="bd b fi z dy kg ea eb kh ed ef dx translated">自从Windows问世以来，在Windows上安装软件的传统方式是打开浏览器，搜索…</h3></div><div class="kj l"><p class="bd b fp z dy kg ea eb kh ed ef dx translated">writersbyte.com</p></div></div><div class="kk l"><div class="kl l km kn ko kk kp in kb"/></div></div></a></div><h1 id="f437" class="kq kr hh bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">Python实现。</h1><p id="e95b" class="pw-post-body-paragraph jj jk hh ir b is lo jl jm iu lp jn jo iw lq jq jr iy lr jt ju ja ls jw jx jc ha bi translated">我们将从导入所有重要的库开始。我们不会使用来自任何库的逻辑回归，因为那将违背本文的目的。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="89f9" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">让我们首先探索一下我们将使用的数据集。</p><p id="d901" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">由于我们使用逻辑回归预测离散类，我们将使用心血管疾病可能性的数据集。数据集是开源的，可以在这里找到<a class="ae ji" href="https://www.kaggle.com/nareshbhat/health-care-data-set-on-heart-attack-possibility" rel="noopener ugc nofollow" target="_blank"/>。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="lx ly l"/></div></figure><figure class="lt lu lv lw fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/4754a3c7791e96110528c0bbc05732f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*F_ei5UpOGDXqlrEOfbdAsw.png"/></div><figcaption class="ma mb et er es mc md bd b be z dx translated">我们的输入功能概述| heart.csv</figcaption></figure><p id="9b31" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">从上面的概述中，我们看到我们共有12个输入特征存储在变量<strong class="ir hi"> sample_x. </strong>中</p><p id="edf3" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">我们的输出是一系列的1和0，其中1表示支持心血管疾病的可能性，0表示拒绝。</p><p id="23f4" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">我们总共有大约300个样本。我们分离出前250个样本作为训练数据，剩下的50个将用于测试。</p><h1 id="f8d2" class="kq kr hh bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">算法</h1><ol class=""><li id="8c5a" class="ip iq hh ir b is lo iu lp iw me iy mf ja mg jc mh je jf jg bi translated">使用随机初始化的权重计算输出。</li><li id="3746" class="ip iq hh ir b is mi iu mj iw mk iy ml ja mm jc mh je jf jg bi translated">计算原始产量和预测产量之间的损失。</li><li id="1cd9" class="ip iq hh ir b is mi iu mj iw mk iy ml ja mm jc mh je jf jg bi translated">使用梯度下降更新权重。</li><li id="2e92" class="ip iq hh ir b is mi iu mj iw mk iy ml ja mm jc mh je jf jg bi translated">重复，直到达到最大迭代次数或损失显著减少。</li></ol><p id="3b5d" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">从上面的步骤中，我们可以分离出我们需要的函数。让我们开始编码吧。</p><ul class=""><li id="54cb" class="ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg bi translated"><strong class="ir hi">乙状结肠</strong>:</li></ul><pre class="lt lu lv lw fd mn mo mp mq aw mr bi"><span id="51ac" class="ms kr hh mo b fi mt mu l mv mw"><strong class="mo hi">def</strong> get_sigmoid(inp):<br/>    <br/>    <em class="jh">#simply returning sigmoid our values</em><br/>    <strong class="mo hi">return</strong> (1/(1+np.exp(-inp))) - 0.00000001</span></pre><ul class=""><li id="fb87" class="ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg bi translated"><strong class="ir hi">损失:</strong></li></ul><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="lx ly l"/></div></figure><ul class=""><li id="8e71" class="ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg bi translated"><strong class="ir hi">体重更新:</strong></li></ul><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="e345" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">现在，剩下要做的就是编写一个例程，以我们上面讨论的算法方式使用这些函数。</p><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="f335" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">您将注意到的一件事是，我们上述例程的第一步是数据的最小-最大缩放。这样做是为了规范化数据集。由于每个输入要素覆盖不同的数值范围，算法在学习模式时会遇到困难。</p><p id="51f3" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">剩下的例行程序和我们讨论的一样。</p><p id="4a39" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">因为我们有一个小的数据集，我们可以运行它大量的时期。我们让我们的运行为默认值；10000.</p><pre class="lt lu lv lw fd mn mo mp mq aw mr bi"><span id="8b12" class="ms kr hh mo b fi mt mu l mv mw">%%time<br/>weights, out = train_logistic_regression(sample_x,sample_y)</span></pre><p id="aff9" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">跑步结束后，我们就有了最终更新的重量。</p><p id="ae66" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">是时候构建一些额外的函数来帮助我们的测试了。</p><ul class=""><li id="90bc" class="ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg bi translated"><strong class="ir hi">预测功能:</strong></li></ul><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="lx ly l"/></div></figure><ul class=""><li id="2d55" class="ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg bi translated"><strong class="ir hi">精度:</strong></li></ul><figure class="lt lu lv lw fd ii"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="4ec0" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">使用上面的辅助函数，我们看到我们的模型给出了75%的<strong class="ir hi">准确率。</strong></p><p id="9f75" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">这个数字可以通过调整超参数来提高，但这取决于您。</p><h1 id="207a" class="kq kr hh bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">结论:</h1><p id="db84" class="pw-post-body-paragraph jj jk hh ir b is lo jl jm iu lp jn jo iw lq jq jr iy lr jt ju ja ls jw jx jc ha bi translated">经过长途跋涉，我们终于到达了这次学习之旅的终点。在这个由2部分组成的系列中，我们学习了逻辑回归的数学知识，并将这些知识应用到一个真实的数据集。我们取得的结果还算可以接受，但是如果你调整一下学习速度和纪元数量，结果还会更好。</p><p id="9da3" class="pw-post-body-paragraph jj jk hh ir b is it jl jm iu iv jn jo iw jp jq jr iy js jt ju ja jv jw jx jc ha bi translated">*别忘了在这里阅读第1部分<a class="ae ji" href="https://writersbyte.com/logistic-regression-understanding-and-implementation-from-scratch-part-1-python-machine-learning/" rel="noopener ugc nofollow" target="_blank"/>*</p><ul class=""><li id="da75" class="ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg bi translated">如果你有任何建议/问题，请写在评论里*</li></ul><h2 id="3ee2" class="ms kr hh bd ks mx my mz kw na nb nc la iw nd ne le iy nf ng li ja nh ni lm nj bi translated">更像这样:</h2><div class="jy jz ez fb ka kb"><a href="https://writersbyte.com/datascience/chest-x-ray-pneumonia-classification-using-deep-neural-networks-with-keras/" rel="noopener  ugc nofollow" target="_blank"><div class="kc ab dw"><div class="kd ab ke cl cj kf"><h2 class="bd hi fi z dy kg ea eb kh ed ef hg bi translated">胸部x光肺炎检测使用深度卷积神经网络与Keras | Python …</h2><div class="ki l"><h3 class="bd b fi z dy kg ea eb kh ed ef dx translated">深度学习(DL)已经兴起很长一段时间了，它已被证明是一个巨大的帮助人们在一个…</h3></div><div class="kj l"><p class="bd b fp z dy kg ea eb kh ed ef dx translated">writersbyte.com</p></div></div><div class="kk l"><div class="nk l km kn ko kk kp in kb"/></div></div></a></div><div class="jy jz ez fb ka kb"><a href="https://writersbyte.com/programming/dbscan-clustering/" rel="noopener  ugc nofollow" target="_blank"><div class="kc ab dw"><div class="kd ab ke cl cj kf"><h2 class="bd hi fi z dy kg ea eb kh ed ef hg bi translated">从头开始实现DBSCAN聚类算法| Python - WritersByte</h2><div class="ki l"><h3 class="bd b fi z dy kg ea eb kh ed ef dx translated">世界上最有价值的资源不再是石油，但数据可能听起来令人惊讶，它是…</h3></div><div class="kj l"><p class="bd b fp z dy kg ea eb kh ed ef dx translated">writersbyte.com</p></div></div><div class="kk l"><div class="nl l km kn ko kk kp in kb"/></div></div></a></div><div class="jy jz ez fb ka kb"><a href="https://writersbyte.com/programming/knn-implementation-from-scratch-96-6-accuracy-python-machine-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="kc ab dw"><div class="kd ab ke cl cj kf"><h2 class="bd hi fi z dy kg ea eb kh ed ef hg bi translated">KNN分类器Python从头实现(96.6%准确率)|机器学习- WritersByte</h2><div class="ki l"><h3 class="bd b fi z dy kg ea eb kh ed ef dx translated">对于初学者来说，“机器学习”这个术语似乎非常复杂和困难。毫无疑问…</h3></div><div class="kj l"><p class="bd b fp z dy kg ea eb kh ed ef dx translated">writersbyte.com</p></div></div><div class="kk l"><div class="nm l km kn ko kk kp in kb"/></div></div></a></div></div></div>    
</body>
</html>