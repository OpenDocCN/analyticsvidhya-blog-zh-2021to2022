<html>
<head>
<title>Loss Functions Part-2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">损失函数第二部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/loss-functions-part-2-c9d0255cbcfc?source=collection_archive---------13-----------------------#2021-05-10">https://medium.com/analytics-vidhya/loss-functions-part-2-c9d0255cbcfc?source=collection_archive---------13-----------------------#2021-05-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="a9fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是<a class="ae jc" href="https://srinivask-bits.medium.com/loss-functions-part-1-17b2601031c1" rel="noopener">这个</a>的延续博客</p><h1 id="fddc" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">用于分类的损失函数</h1><p id="54e6" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">众所周知，对于回归问题，我们使用最小二乘误差作为损失函数。通过这种方法，我们得到一个凸损失函数，我们可以通过找到它的全局最小值来进行优化。但是当涉及到逻辑回归时，这个概念就完全改变了，最小二乘误差会给我们一个非凸的损失函数，它有不止一个局部极小值。这里，由于在逻辑回归假设中使用了非线性sigmoid函数，所以我们得到了波形曲线，因此它具有多个局部最小值，这对用于寻找最小值的梯度下降是不利的。</p><h1 id="127f" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">交叉熵损失</h1><p id="4e93" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">这是分类问题最常见的设置。交叉熵损失随着预测概率偏离实际标签而增加。其中一个重要的方面是，交叉熵损失会严重惩罚那些有把握但却是错误的预测。我们不能对所有错误的结果给予同等的重视。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/172dfc22572e40b97572683b3a374e76.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/0*IDFvfUHreEgvWzH3.png"/></div></figure><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ko"><img src="../Images/6f8f585371fb24f981607cd8b7c47f31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1140/format:webp/0*zZ6A0TpRpTC-wdqI.png"/></div></figure><p id="3ce0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，如果置信度低，同时预测到一个结果；如果置信度太高，同时预测到一个结果，但两次预测都是</p><p id="1c26" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假的。误差函数应该为具有更高置信度的预测使用高权重。二元交叉熵损失函数的如下证明。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kp"><img src="../Images/503c86ec83dfd0e8a69e21834621e351.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/0*i8n6ZrG1ekW1AUK6.jpg"/></div></figure><p id="926b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是寻找逻辑回归的复杂成本函数的梯度。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kq"><img src="../Images/a02567e59b1dca6490dde6cfc1ac6b88.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/0*qVpi-x_c1ufQQf7x.jpg"/></div></figure><h1 id="8b29" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">铰链损耗</h1><p id="daa7" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">对于支持向量机，我们使用铰链损失。铰链损耗训练分类器。铰链损耗的差异是凸的，但不可微。铰链损失惩罚超平面的错误一侧，但是因为它是不可微的，所以梯度或随机梯度下降，所以我们大部分时间使用交叉熵。</p></div></div>    
</body>
</html>