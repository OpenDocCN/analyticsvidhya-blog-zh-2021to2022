<html>
<head>
<title>GAN: Generative adversarial network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">甘:生成性对抗网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/gan-generative-adversarial-network-fbef2a96e183?source=collection_archive---------9-----------------------#2021-07-05">https://medium.com/analytics-vidhya/gan-generative-adversarial-network-fbef2a96e183?source=collection_archive---------9-----------------------#2021-07-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d247" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虚假新闻文章充斥几乎所有社交媒体平台的选举。想象一下，如果这些文章包含伴随的“虚假图像”和“虚假音频”，将会产生怎样的影响。在这样一个世界里，宣传可能会更容易传播。本质上，这些新的生成模型，<strong class="ih hj">有时间和数据，可以从几乎<em class="jd">任何</em>分布中生成非常令人信服的样本。</strong></p><p id="bbc3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GANs在诸如<strong class="ih hj"> <em class="jd">生成图像数据集的示例、生成逼真的照片、图像到图像翻译、文本到图像翻译、语义图像到照片翻译、人脸正面视图生成、生成新的人体姿态、人脸老化、视频预测、3D对象生成等情况下有大量的应用。</em> </strong></p><p id="d1bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">GAN是一种使用深度学习方法(如卷积神经网络)的生成建模方法。</p><p id="7fc7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成建模是机器学习中的一项无监督学习任务，它涉及自动发现和学习输入数据中的规律或模式，使得模型可以用于生成或输出新的示例，这些示例很可能是从原始数据集中提取的。</p><p id="ae7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">gan是一种训练生成模型的聪明方法，它通过将问题构建为具有两个子模型的监督学习问题:我们训练以生成新示例的生成器模型，以及尝试将示例分类为真实(来自领域)或虚假(生成)的鉴别器模型。</p><p id="8348" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">“生成对抗网络”</strong>甘采取了一种不同于其他类型神经网络的学习方法。GANs算法架构使用两个神经网络，称为<strong class="ih hj">生成器</strong>和<strong class="ih hj">鉴别器</strong>，它们相互“竞争”以产生想要的结果。生成器的工作是创建逼真的假图像，而鉴别器的工作是区分真实图像和假图像。如果两者都在高水平上发挥作用，结果就是图像看起来和现实生活中的照片一样。</p><p id="e0be" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自2014年Ian J. Goodfellow和合著者在文章《生成对抗网络》中提出以来，生成对抗网络取得了巨大的成功。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/06e1b5cff1cd7392aa42bf8b3d319b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EWIuMU5jeS789AOh"/></div></div></figure><h1 id="c574" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">最初为什么要开发GANs？</h1><p id="99ee" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">人们已经注意到，大多数主流神经网络可以很容易地被愚弄，通过在原始数据中仅添加少量噪声来对事物进行错误分类。令人惊讶的是，添加噪声后的模型在错误预测中的置信度比正确预测时更高。这种对手的原因是大多数机器学习模型从有限的数据量中学习，这是一个巨大的缺点，因为它容易<strong class="ih hj">过度拟合。</strong>同样，输入和输出之间的映射几乎是线性的。</p><p id="dfbe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">朴素贝叶斯</strong>是一个生成模型的例子，更常用作判别模型。</p><p id="f3d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，朴素贝叶斯通过汇总每个输入变量和输出类的概率分布来工作。当进行预测时，计算每个变量的每个可能结果的概率，组合独立的概率，并预测最可能的结果。反向使用时，可以对每个变量的概率分布进行采样，以生成新的可信(独立)特征值。</p><p id="88d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">生成模型的其他示例包括潜在狄利克雷分配(LDA)和高斯混合模型(GMM)。</p><p id="7173" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">深度学习方法可以作为生成模型。两个流行的例子包括受限玻尔兹曼机器，或RBM，和深度信念网络，或DBN。</p><p id="980d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">深度学习生成建模算法的两个现代例子包括变分自动编码器或VAE，以及生成对抗网络或GAN。</p><h1 id="371a" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">GANs是如何工作的？</h1><p id="7f3a" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">gan通过让两个神经网络相互对抗来学习数据集的概率分布。</p><p id="4779" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一个被称为<strong class="ih hj">生成器</strong>的神经网络生成新的数据实例，而另一个被称为<strong class="ih hj">鉴别器</strong>的神经网络评估它们的真实性；即鉴别器决定它检查的每个数据实例是否属于实际的训练数据集。</p><p id="47ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">与此同时，生成器正在创建新的合成/伪造图像，并将其传递给鉴别器。它这样做是希望它们也能被认为是真的，即使它们是假的。假图像是使用卷积的逆运算(称为转置卷积)从100维噪声(均匀分布在-1.0到1.0之间)生成的。</p><p id="892d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是GAN采取的步骤:</p><ul class=""><li id="5878" class="kt ku hi ih b ii ij im in iq kv iu kw iy kx jc ky kz la lb bi translated">生成器接收随机数并返回图像。</li><li id="e851" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">这个生成的图像与从实际的地面实况数据集中提取的图像流一起被输入鉴别器。</li><li id="0e62" class="kt ku hi ih b ii lc im ld iq le iu lf iy lg jc ky kz la lb bi translated">鉴别器接受真实和伪造的图像，并返回概率，一个介于0和1之间的数字，1代表对真实性的预测，0代表伪造。</li></ul><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lh"><img src="../Images/9ce8b4b7d76184bd399621a6e2f4bb0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1074/0*1VF9GG--TNLj5iik"/></div></figure><h1 id="56f4" class="jq jr hi bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">甘斯背后的数学</h1><p id="a43c" class="pw-post-body-paragraph if ig hi ih b ii ko ik il im kp io ip iq kq is it iu kr iw ix iy ks ja jb jc hb bi translated">鉴别器的工作是执行<strong class="ih hj">二元分类</strong>来检测真假，因此其<strong class="ih hj">损失函数是二元交叉熵</strong>。</p><p id="5e6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">发生器所做的是<strong class="ih hj">密度估计</strong>，从噪声到真实数据，并将其馈送给鉴别器以欺骗它。</p><p id="6620" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">设计中遵循的方法是将其建模为一个<strong class="ih hj">极小极大游戏</strong>。</p><p id="0170" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">成本函数:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es li"><img src="../Images/a20cb5a687432359034a8d9d7ddcff85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*e2evMbDC_FUUm1Zs"/></div></div></figure><p id="ce4e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">J(D) 中的<strong class="ih hj">第一项表示将实际数据提供给鉴别器，鉴别器将希望最大化预测一的对数概率，表明数据是真实的。</strong></p><p id="d377" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">第二项</strong>代表g产生的样本。</p><p id="c790" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，鉴别器想要最大化预测零的对数概率，这表明数据是假的。另一方面，生成器试图最小化鉴别器正确的对数概率。这个问题的解是博弈的一个均衡点，这个均衡点是鉴别器损失的一个鞍点。</p><p id="2676" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">目标函数</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es lj"><img src="../Images/47148570a349a36656c935aa8e27da1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1240/0*tjt_US4CVQVFwKyW"/></div></figure><p id="6481" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">甘斯建筑</strong></p><p id="e6aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">d()给出了给定样本来自训练数据x的概率。</p><p id="13ea" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于生成器，我们希望最小化log(1-D(G(z))，即当值D(G(z))很高时，D将假设G(z)只不过是X，这使得1-D(G(z))非常低，我们希望最小化它，甚至更低。</p><p id="b4d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于鉴别器，我们要最大化D(X)和(1-D(G(z))。所以D的最优状态会是P(x)=0.5。然而，我们想训练生成器G，使它为鉴别器D产生结果，这样D就不能区分z和x。</p><p id="bcba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在的问题是为什么这是一个极大极小函数？</p><p id="5bd9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是因为鉴别器试图最大化目标，而生成器试图最小化目标，由于这种最小化/最大化，我们得到了极大极小项。它们都通过交替<strong class="ih hj">梯度下降来一起学习。</strong></p><p id="0f3b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">尽管GAN的想法在理论上很简单，但要建立一个可行的模型却非常困难。在GAN中，有两个耦合在一起的深层网络，使得梯度的反向传播具有两倍的挑战性。</p><p id="857c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">深度卷积GAN (DCGAN) </strong>是演示如何构建实用GAN的模型之一，该GAN可以自学如何合成新图像。DCGAN非常类似于GAN，但特别关注于使用深度卷积网络来代替普通GAN中使用的全连接网络。</p><p id="e783" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷积网络有助于发现图像中的深度相关性，也就是说，它们寻找空间相关性。这意味着DCGAN将是图像/视频数据的更好选择，而<em class="jd"> GAN </em> s可以被视为DCGAN和许多其他架构<em class="jd"> (CGAN、CycleGAN、StarGAN和许多其他架构)</em>发展的一般理念。</p><p id="3a17" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">好了，这篇关于GANs的文章到此结束，在这里我们讨论了这个很酷的人工智能领域以及它是如何实际实现的。我希望你们喜欢读它。</p><p id="a966" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢您阅读这篇文章！！！</p><p id="a29a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p><p id="0f96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">参考:</p><p id="2834" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[1] X. Zhang、S. Karaman和S. Chang，“检测和模拟GAN伪图像中的伪像”，在Proc .2019年IEEE信息取证与安全国际研讨会。</p><p id="b204" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[2]托洛萨纳、鲁本、鲁本·维拉-罗德里格斯、朱利安·菲尔雷斯、艾塔米·莫拉莱斯和哈维尔·奥尔特加-加西亚。"深度伪装与超越:人脸操作与伪装检测综述."信息融合64(2020):131–148。</p><p id="a8fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[3]Heo，Yehjune。"基于生成对抗网络的指纹反欺骗限制."国际计算机与信息工程杂志15，第6期(2021):349–353。</p><p id="7a6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[4]笈多，维舒，西垣正胜，大垣哲。"使用生成对抗网络的无监督生物特征反欺骗."</p><p id="468f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[5]古德费勒、伊恩、让·普热-阿巴迪、迈赫迪·米尔扎、徐炳、戴维·沃德-法利、谢尔吉尔·奥泽尔、亚伦·库维尔和约舒阿·本吉奥。"生成性对抗网络。"神经信息处理系统进展27 (2014)。</p><p id="7a35" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[6]拉德福德，亚历克，卢克·梅斯，和苏密特·钦塔拉。"深度卷积生成对抗网络的无监督表示学习."arXiv预印本arXiv:1511.06434 (2015)。</p><p id="34ab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[7]杨，建伟，，李。"学习卷积神经网络进行人脸反欺骗."arXiv预印本arXiv:1408.5601 (2014)。</p><p id="ef43" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[8]<a class="ae lk" href="https://poloclub.github.io/ganlab/" rel="noopener ugc nofollow" target="_blank">https://poloclub.github.io/ganlab/</a></p><p id="d5cb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">[9]https://towards data science . com/the-math-behind-gans-generative-adversarial-networks-3828 f 3469 d9c</p></div></div>    
</body>
</html>