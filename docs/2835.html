<html>
<head>
<title>Convolution Neural Network (CNN) — Fundamental of Deep Learning — Idiot Developer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络(CNN)——深度学习的基础——白痴开发者</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/convolution-neural-network-cnn-fundamental-of-deep-learning-idiot-developer-3d1aa82e5c85?source=collection_archive---------9-----------------------#2021-05-19">https://medium.com/analytics-vidhya/convolution-neural-network-cnn-fundamental-of-deep-learning-idiot-developer-3d1aa82e5c85?source=collection_archive---------9-----------------------#2021-05-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="87c3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">卷积神经网络(CNN)用于解决广泛的视觉任务，如<a class="ae jc" href="https://idiotdeveloper.com/dog-breed-classification-using-transfer-learning-in-tensorflow/" rel="noopener ugc nofollow" target="_blank">图像分类</a>，物体检测，<a class="ae jc" href="https://idiotdeveloper.com/unet-segmentation-in-tensorflow/" rel="noopener ugc nofollow" target="_blank">语义分割</a>，等等。CNN由一系列具有非线性激活函数的卷积层和一些下采样层组成。这些CNN能够捕捉层次模式并产生图像表示。</p><p id="7b53" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">概述:</p><ol class=""><li id="4d46" class="jd je hh ig b ih ii il im ip jf it jg ix jh jb ji jj jk jl bi translated">什么是卷积神经网络？</li><li id="85d0" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">为什么卷积神经网络优于前馈神经网络？</li><li id="530c" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb ji jj jk jl bi translated">CNN的主要组成部分</li></ol><ul class=""><li id="26fc" class="jd je hh ig b ih ii il im ip jf it jg ix jh jb jr jj jk jl bi translated">卷积层</li><li id="9964" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb jr jj jk jl bi translated">活化层</li><li id="9460" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb jr jj jk jl bi translated">汇集层</li><li id="c5ca" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb jr jj jk jl bi translated">全连接层</li></ul><h1 id="c5e6" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">什么是卷积神经网络？</h1><p id="b65b" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">卷积神经网络(CNN)或简称ConvNets是一类<a class="ae jc" href="https://idiotdeveloper.com/what-is-deep-learning/" rel="noopener ugc nofollow" target="_blank">深度神经网络</a>，普遍用于可视化数据分析。该视觉数据可以是图像或视频的形式。CNN的灵感来自于哺乳动物的视觉皮层。它们是作为自然视觉感知的计算模型开发的，类似于人的视觉系统。CNN的应用有<a class="ae jc" href="https://idiotdeveloper.com/dog-breed-classification-using-transfer-learning-in-tensorflow/" rel="noopener ugc nofollow" target="_blank">图像分类</a>，物体检测<a class="ae jc" href="https://idiotdeveloper.com/unet-segmentation-in-tensorflow/" rel="noopener ugc nofollow" target="_blank">，语义分割</a>，<a class="ae jc" href="https://idiotdeveloper.com/unet-segmentation-with-pretrained-mobilenetv2-as-encoder/" rel="noopener ugc nofollow" target="_blank">医学图像分析</a>等等。</p><p id="aa6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">卷积神经网络(CNN)获取输入图像，对其执行一系列操作，然后将其分类到某些类别下(例如:猫或狗)。根据我们试图解决的问题的类型，结果会有所不同。在图像分类的情况下，我们得到一个标签(概率得分)。在语义分割的情况下，我们得到分割图，其中每个像素都标有类别标签。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kv"><img src="../Images/75a700b7a66372873026b9890a7907d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PsC-fRWWBc5Ogtci.jpg"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">识别手写数字的CNN。</figcaption></figure><p id="0c97" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">卷积神经网络(CNN)的基本架构由以下几层组成:</p><ul class=""><li id="1cb2" class="jd je hh ig b ih ii il im ip jf it jg ix jh jb jr jj jk jl bi translated">卷积层— CONV</li><li id="ae63" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb jr jj jk jl bi translated">激活层— ACT</li><li id="d073" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb jr jj jk jl bi translated">池层-池</li><li id="9b03" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb jr jj jk jl bi translated">全连接层— FC</li></ul><p id="a27d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所有这些层以某种组合方式用于构建卷积神经网络。对于图像分类任务，一般架构如下:</p><p id="4fb5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输入-&gt; [CONV -&gt; ACT -&gt; POOL] x N次-&gt; [FC -&gt; ACT] x M次-&gt;输出</p><h1 id="c72f" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">为什么卷积神经网络优于前馈神经网络？</h1><p id="6ceb" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">现在问题出现了，如果我们有一个前馈神经网络，为什么我们需要卷积神经网络？</p><p id="2c89" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">前馈神经网络也可以代替卷积神经网络用于图像分类。前馈神经网络将输入作为多个特征(批次、特征)。为此，我们需要将图像展平为一维表示，这样我们会丢失图像所表示的空间信息。为了利用这种空间信息，我们使用卷积神经网络。卷积神经网络将图像的批次作为输入，而不对其形状进行任何修改。卷积神经网络的输入形状是(批次、高度、宽度、通道)。</p><p id="3a17" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">前馈神经网络本质上非常密集，因为它们具有许多可训练的参数(权重)，这使得它们容易出现过拟合的问题。</p><p id="fa37" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在卷积神经网络的情况下，存在参数共享或权重共享，因此与前馈神经网络相比，它们具有非常少的参数，因此与前馈神经网络相比，它们在训练中花费较少的时间。</p><h1 id="6500" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">CNN的主要组成部分</h1><p id="36fb" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">众所周知，卷积神经网络是由一些相互堆叠的层组成的。这些层形成了卷积神经网络的构造块。</p><h1 id="f31b" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">卷积层</h1><p id="af72" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">卷积神经网络(CNN)的中心构建块是卷积层，它使网络能够通过在每层的局部感受域内融合空间和信道信息来构建信息特征。</p><p id="ac84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">卷积层由数学卷积运算组成，它需要两个输入，首先是图像矩阵和一个小的核矩阵。内核滑过输入图像并产生输出特征图。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kv"><img src="../Images/603c6400b64ba0169223e28d7c97ad88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NjtKS7NR45yPEHEE.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">卷积层的基本工作原理。</figcaption></figure><p id="c1cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">卷积运算的目的是从输入图像中提取诸如边缘、直线、曲线等高级特征。从广义上来说，我们可以说卷积层的作用是将图像简化为一种更容易处理的形式，而不丢失基本特征。</p><h1 id="0ecc" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">活化层</h1><p id="e8a6" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">激活层在神经网络中引入了非线性。ReLU(校正线性单元)是卷积神经网络中最常用的激活函数。它用于除输出图层之外的所有图层。输出层的激活函数取决于我们试图解决的问题的类型。与分类的情况一样，我们使用sigmoid表示单个类，使用softmax表示多个类。</p><h1 id="9d46" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">汇集层</h1><p id="3846" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">共用图层用于减少空间维度，即输入要素地图的高度和宽度。它有助于通过降维来减少处理特征图所需的计算资源。</p><p id="2387" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有两种主要类型的池:</p><ul class=""><li id="6d7e" class="jd je hh ig b ih ii il im ip jf it jg ix jh jb jr jj jk jl bi translated">最大池化</li><li id="b586" class="jd je hh ig b ih jm il jn ip jo it jp ix jq jb jr jj jk jl bi translated">平均池</li></ul><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es ll"><img src="../Images/bd9ea8ba1b10737b5958b038cf8c000c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*IezuUnTSrfsjsRef.jpg"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">两种类型的池:最大池和平均池。</figcaption></figure><p id="10a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个池操作需要一个内核大小和一个跨距值。内核大小决定了从特征图中提取值以创建新特征图的面片大小。步幅值帮助我们在特征图上移动。</p><h1 id="a939" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">全连接层</h1><p id="85a4" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">在一系列卷积层、激活层和汇集层之后，我们展平传入的特征地图，并将它们作为输入馈送到完全连接的层进行分类。</p><p id="6e20" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">完全连接的图层或密集图层采用展平的输入要素和一定数量的输出要素。</p><p id="9c60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如:</p><p id="ca9f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">池图层中要素的输入形状为(B，H，W，N)。现在，我们通过将特征图整形为(B，H*W*N)来展平它们。现在，我们将其输入全连接图层，输出要素的数量为O。全连接图层给出的要素地图的形状为(B，O)。</p><p id="88ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">之后，我们在完全连接的层的输出上应用激活函数，我们得到一个概率分数，该分数用于确定输入图像的标签。</p></div><div class="ab cl lm ln go lo" role="separator"><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr ls"/><span class="lp bw bk lq lr"/></div><div class="ha hb hc hd he"><p id="a196" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lt">原载于2021年5月19日https://idiotdeveloper.com</em><a class="ae jc" href="https://idiotdeveloper.com/convolution-neural-network-cnn-fundamental-of-deep-learning/" rel="noopener ugc nofollow" target="_blank"><em class="lt"/></a><em class="lt">。</em></p></div></div>    
</body>
</html>