<html>
<head>
<title>What Are The Odds? — Kernel Density Estimation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">几率有多大？—核密度估计</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/what-are-the-odds-kernel-density-estimation-75c9980931e4?source=collection_archive---------8-----------------------#2021-02-01">https://medium.com/analytics-vidhya/what-are-the-odds-kernel-density-estimation-75c9980931e4?source=collection_archive---------8-----------------------#2021-02-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/3a5be3c06bd30d1dd4e33b4164865089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*g5dZH5Lq4fu78JbyC3RQLQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">由作者创建</figcaption></figure><p id="efcd" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">很多时候，知道一组给定观察值的概率密度函数是非常有用的。不幸的是，大多数随机数据样本可能具有未知的密度函数，因此需要估计概率密度。</p><p id="bd92" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">进入<strong class="iv hi">核密度估计:</strong>一种估计随机变量密度函数的非参数方式。</p><p id="ee60" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在本帖中，我们将从理论和数学上解释内核密度估计，以及从头开始的Python实现！</p><h1 id="abeb" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">概观</h1><p id="2ed5" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">核密度估计(KDE)本质上是一种数据平滑方法，在数据分布上拟合一条平滑线。如前所述，这通常是为了估计给定分布的概率密度函数。事实上，人们可以从这个估计的概率密度中进行采样，并生成看起来像是来自与原始数据相同的分布的数据。</p><h1 id="db59" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">理论</h1><p id="6da2" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">作为非参数，KDE不考虑任何类型的基础分布，这意味着它不假设一组数据将有一个特定的形状或模型。更确切地说，正如它的名字所表明的，它使用一个<em class="ku">内核函数</em>来拟合一条穿过数据的平滑线。</p><h2 id="c60d" class="kv js hh bd jt kw kx ky jx kz la lb kb je lc ld kf ji le lf kj jm lg lh kn li bi translated">KDE描述</h2><p id="3e57" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">KDE算法可以表示为:</p><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es lj"><img src="../Images/164f63283094c5f4333512380aa54cef.png" data-original-src="https://miro.medium.com/v2/resize:fit:910/format:webp/0*eupqGiRle6YCllBZ.png"/></div></figure><p id="b8c2" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">其中<em class="ku"> K </em>是核函数，<em class="ku"> n </em>是观测值的个数，<em class="ku"> x </em>是特定的观测值。KDE本质上是以数据集中每个点为中心的分布的总和，其中要求和的分布是核概率密度函数。</p><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/16f2281659b58bef2bc68997e483d60a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*Msts5p9bDBW2UaYI.gif"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated"><a class="ae lp" href="https://www.vosesoftware.com/riskwiki/KernelCUdistribution.php" rel="noopener ugc nofollow" target="_blank">信用</a></figcaption></figure><p id="cae5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">还有一个参数，<em class="ku"> h，</em>称为带宽。带宽控制每个零件周围分布的跨度，进而影响分布的平滑度。</p><h2 id="31ee" class="kv js hh bd jt kw kx ky jx kz la lb kb je lc ld kf ji le lf kj jm lg lh kn li bi translated">带宽优化</h2><p id="3545" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">由于带宽控制着数据的总体拟合度，因此选择不当的带宽会导致估计过度平滑或平滑不足。因此，存在一个最佳带宽。</p><p id="e262" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">从表面上看，选择一个好的带宽值有一些通用的经验法则:</p><ul class=""><li id="7a4e" class="lq lr hh iv b iw ix ja jb je ls ji lt jm lu jq lv lw lx ly bi translated">由于数据的缺乏和/或稀疏，小数据集通常需要更高的带宽值，因此需要包含更多的点以获得足够的上下文。</li><li id="b06d" class="lq lr hh iv b iw lz ja ma je mb ji mc jm md jq lv lw lx ly bi translated">较大的数据集有更多的点，因此可以使用较低的带宽，因为良好的上下文需要较少的蔓延。</li></ul><p id="dff8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">还存在西尔弗曼的最优估计:</p><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es me"><img src="../Images/83fc846bf7294fff925a5a81559f4e43.png" data-original-src="https://miro.medium.com/v2/resize:fit:344/format:webp/0*8756sPkBufvebc9Y.png"/></div></figure><p id="fdf5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">其中<em class="ku"> h </em>为最佳带宽，<em class="ku"> m </em>为:</p><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mf"><img src="../Images/bd8cd0645bc0a72e21b189967d2dcfed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/0*d_aYT4bsVrFwHxJp.png"/></div></figure><p id="1304" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">当然，对于最佳带宽选择，还有更复杂的方法，但是它们远比本文的范围复杂。</p><h2 id="b1f5" class="kv js hh bd jt kw kx ky jx kz la lb kb je lc ld kf ji le lf kj jm lg lh kn li bi translated">核</h2><p id="51d7" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">核只是一个概率密度函数，它必须具有以下一组属性:</p><ul class=""><li id="4464" class="lq lr hh iv b iw ix ja jb je ls ji lt jm lu jq lv lw lx ly bi translated"><strong class="iv hi">对称性:</strong>一个核函数一定是对称的，于是<em class="ku"> k(x) </em> = <em class="ku"> k(-x) </em></li><li id="4886" class="lq lr hh iv b iw lz ja ma je mb ji mc jm md jq lv lw lx ly bi translated"><strong class="iv hi">非负</strong>:一个核函数必须有一个完全正的范围，因此对于域<strong class="iv hi"> {x ∈ R} </strong>这个范围必须是<strong class="iv hi"> {y ∈ R | y ≥ 0} </strong></li><li id="7902" class="lq lr hh iv b iw lz ja ma je mb ji mc jm md jq lv lw lx ly bi translated"><strong class="iv hi">面积必须为1: </strong>核函数的面积必须等于1</li></ul><h2 id="025e" class="kv js hh bd jt kw kx ky jx kz la lb kb je lc ld kf ji le lf kj jm lg lh kn li bi translated">普通内核</h2><p id="98c0" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">由于核本质上是概率密度函数，一些最常用的核是:</p><ul class=""><li id="feb1" class="lq lr hh iv b iw ix ja jb je ls ji lt jm lu jq lv lw lx ly bi translated">高斯核</li><li id="49f5" class="lq lr hh iv b iw lz ja ma je mb ji mc jm md jq lv lw lx ly bi translated">三角形内核</li><li id="deb8" class="lq lr hh iv b iw lz ja ma je mb ji mc jm md jq lv lw lx ly bi translated">Epanechnikov核</li></ul><h1 id="0dc6" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">履行</h1><p id="6355" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">我们将从头开始用Python实现KDE，并看一些例子。</p><p id="87f8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们将使用以下库:</p><pre class="lk ll lm ln fd mg mh mi mj aw mk bi"><span id="dea7" class="kv js hh mh b fi ml mm l mn mo">import numpy as np<br/>import matplotlib.pyplot as plt</span><span id="af46" class="kv js hh mh b fi mp mm l mn mo">from typing import *</span></pre><p id="8d89" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">首先，我们将创建一个函数，它可以生成一些我们可以在示例中使用的随机数据:</p><pre class="lk ll lm ln fd mg mh mi mj aw mk bi"><span id="01c9" class="kv js hh mh b fi ml mm l mn mo">def generate_random_data(num_points: int, n_randomization: int=3):<br/>    x = np.random.randn(num_points)<br/><br/>    for _ in range(n_randomization):<br/>        random_slice = int(np.random.rand() * num_points)</span><span id="f7df" class="kv js hh mh b fi mp mm l mn mo">        x[random_slice:] += np.random.randint(0, 10)<br/><br/>    return x</span></pre><p id="3269" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们现在可以画出一些我们产生的随机数据的例子。我们将为5000个数据点创建一个包含100个柱的直方图:</p><pre class="lk ll lm ln fd mg mh mi mj aw mk bi"><span id="151e" class="kv js hh mh b fi ml mm l mn mo">plt.hist(generate_random_data(5000), bins=100)<br/>plt.show()</span></pre><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mq"><img src="../Images/a8f1ca7c71f6770c8d427310fe9fae45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*py9UM-quYFQrwLW7NvIg4A.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">随机生成的示例</figcaption></figure><p id="5682" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">既然我们可以生成一些好的测试数据，我们将最终实现内核密度估计本身。在Python中，我们可以把它写成:</p><pre class="lk ll lm ln fd mg mh mi mj aw mk bi"><span id="d4a0" class="kv js hh mh b fi ml mm l mn mo">def kde(bandwith: float, data: List, kernel: Callable):<br/>    mixture = np.zeros(1000)<br/>    points = np.linspace(0, max(data), 1000)</span><span id="8e28" class="kv js hh mh b fi mp mm l mn mo">    for xi in data:<br/>        mixture += kernel(points, xi, bandwith)<br/><br/>    return mixture</span></pre><p id="a8fd" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">回想一下这个公式，我们看到它只是对数据中每一点的内核求和。</p><p id="f35c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在要使用它，我们显然需要一个内核函数。我们现在将实现最简单和最基本的内核函数作为概念证明。</p><p id="924a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">高斯核函数可以实现为:</p><pre class="lk ll lm ln fd mg mh mi mj aw mk bi"><span id="6885" class="kv js hh mh b fi ml mm l mn mo">def gaussian(x: Any, xi: float, bandwith: float):<br/>    exp_section = np.exp(-np.power(x - xi, 2.0))</span><span id="b8bb" class="kv js hh mh b fi mp mm l mn mo">    return exp_section / (2 * np.power(bandwith, 2.0)))</span></pre><p id="2fdf" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们现在可以把所有东西放在一起，对一些测试数据使用我们的KDE函数。出于可视化的目的，如果我们使用一些简单的测试数据，并绘制KDE函数中的每一个高斯函数，我们将看到如下所示:</p><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/c091ca1ecdf58274bcbf6e898cb08bbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XcpC_9Iz7zmzwkaGsVkapw.png"/></div></div></figure><p id="1db9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">毫不奇怪，我们看到每个数据点周围都是高斯分布的混合体(我们的核函数)。</p><p id="b83a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">现在我们已经看到了概念验证，让我们实际上在一些更复杂的测试数据上使用它:</p><pre class="lk ll lm ln fd mg mh mi mj aw mk bi"><span id="a5bb" class="kv js hh mh b fi ml mm l mn mo">dist = generate_random_data(500)</span><span id="6f7c" class="kv js hh mh b fi mp mm l mn mo">hist = np.histogram(dist, bins=50)[1]</span></pre><p id="94fc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">绘制测试分布图:</p><pre class="lk ll lm ln fd mg mh mi mj aw mk bi"><span id="c996" class="kv js hh mh b fi ml mm l mn mo">plt.figure(<br/>    figsize=(16, 10)<br/>)</span><span id="e7d1" class="kv js hh mh b fi mp mm l mn mo">plt.hist(dist, bins=50, <br/>         alpha=0.5, color='green', label='True Distribution')<br/>plt.show()</span></pre><p id="d233" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在这种情况下，我们的随机数据分布如下:</p><figure class="lk ll lm ln fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/bde75e8ef277ab0aaec11e779cc13d2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xToS9QQoOWPMg6THP398GA.png"/></div></div></figure><p id="4a35" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">应用我们的KDE:</p><pre class="lk ll lm ln fd mg mh mi mj aw mk bi"><span id="364c" class="kv js hh mh b fi ml mm l mn mo">points = kde(0.5, dist, gaussian)</span></pre><p id="7a5f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">绘制我们的估计分布图:</p><pre class="lk ll lm ln fd mg mh mi mj aw mk bi"><span id="bba7" class="kv js hh mh b fi ml mm l mn mo">plt.fill_between(np.linspace(0, max(dist), 1000), <br/>                 points, alpha=0.5, label='Estimated PDF')<br/><br/>plt.legend(loc='upper right')<br/>plt.show()</span></pre><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mr"><img src="../Images/e23267e03bf8e5cc398b2ff6521352e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*A9Y24ut-ppV6b9m0l6Cc4g.png"/></div></figure><p id="88fc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">正如我们所见，KDE对分布的估计相当准确。现在这个估计在技术上还不是一个概率密度，因为它的范围远远大于1。为了解决这个问题，我们需要做的就是将其规范化:</p><pre class="lk ll lm ln fd mg mh mi mj aw mk bi"><span id="9d86" class="kv js hh mh b fi ml mm l mn mo">points = kde(0.5, dist, gaussian)<br/>points /= np.abs(points).max(axis=0)  # Normalizing</span></pre><p id="8403" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">以下是标准化后我们的估计值:</p><figure class="lk ll lm ln fd ii er es paragraph-image"><div class="er es mr"><img src="../Images/2922b8a88ad5a9ea787d676eaeab9f8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*pYHrY11OmbWDK1JlRcUKkQ.png"/></div></figure><p id="85c8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">最后，我们有我们的概率密度函数估计！</p><h1 id="3308" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">结论</h1><p id="518f" class="pw-post-body-paragraph it iu hh iv b iw kp iy iz ja kq jc jd je kr jg jh ji ks jk jl jm kt jo jp jq ha bi translated">对给定分布的概率密度函数有一个粗略的估计比仅仅一个直方图更有价值。核密度估计是一个强大而简单的工具，可以帮助数据科学家对未知分布有更深入的了解。</p><h1 id="2e78" class="jr js hh bd jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko bi translated">进一步阅读/参考</h1><ul class=""><li id="4d74" class="lq lr hh iv b iw kp ja kq je ms ji mt jm mu jq lv lw lx ly bi translated"><a class="ae lp" href="https://www.mvstat.net/tduong/research/seminars/seminar-2001-05/" rel="noopener ugc nofollow" target="_blank">核密度估计简介</a></li><li id="fb89" class="lq lr hh iv b iw lz ja ma je mb ji mc jm md jq lv lw lx ly bi translated"><a class="ae lp" href="https://mathisonian.github.io/kde/" rel="noopener ugc nofollow" target="_blank"> KDE可视化</a></li><li id="d4a6" class="lq lr hh iv b iw lz ja ma je mb ji mc jm md jq lv lw lx ly bi translated"><a class="ae lp" href="https://www.real-statistics.com/distribution-fitting/kernel-density-estimation/" rel="noopener ugc nofollow" target="_blank">更多KDE信息</a></li><li id="3d07" class="lq lr hh iv b iw lz ja ma je mb ji mc jm md jq lv lw lx ly bi translated"><a class="ae lp" href="https://indico.cern.ch/event/485764/contributions/2005624/attachments/1250052/1843072/KDE_TanazA.Mohayai.pdf" rel="noopener ugc nofollow" target="_blank"> KDE幻灯片</a></li><li id="fc51" class="lq lr hh iv b iw lz ja ma je mb ji mc jm md jq lv lw lx ly bi translated"><a class="ae lp" href="https://www.itm-conferences.org/articles/itmconf/pdf/2018/08/itmconf_sam2018_00037.pdf" rel="noopener ugc nofollow" target="_blank">关于KDE及其应用的全面论文</a></li></ul></div></div>    
</body>
</html>