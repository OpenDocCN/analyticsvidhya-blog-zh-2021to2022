<html>
<head>
<title>Data Representation for performance improvement</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于性能改进的数据表示</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-representation-for-performance-improvement-c3e647d2787a?source=collection_archive---------13-----------------------#2021-04-23">https://medium.com/analytics-vidhya/data-representation-for-performance-improvement-c3e647d2787a?source=collection_archive---------13-----------------------#2021-04-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="4d73" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">调整您的特征以满足您的模型</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/aca80b461f424325bbfa7edb3c7e232a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*U5dqVtOT1GbxHD81"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">卢卡斯·布拉塞克在<a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="5278" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">在我的学习过程中，我意识到工程特征的概念更多的是一门艺术而不是科学，但是，有一些基本的概念是必须学习的。不同的作者试图给出在工程特性中重要的过程的简洁表示。本文将在这些先前工作的知识的基础上，通过一些实际的例子向前推进。</p><p id="8906" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">表示要素和提高模型性能有多种不同的方法。表示数据的理想方式不仅取决于数据，还取决于所用模型的类型。在本文中，我们将考察<strong class="jv hi">宁滨或离散化的方法、多项式特性和相互作用。</strong></p><p id="6d44" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">让我们深入研究一下。</p><p id="1b86" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">首先，我们需要数据！我们将使用sklearn 的<a class="ae js" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html" rel="noopener ugc nofollow" target="_blank"> dataset.make_regression函数来生成我们的回归数据。</a></p><p id="67bb" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">导入必要的库</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="54dd" class="kw if hh ks b fi kx ky l kz la">from sklearn.linear_model import LinearRegression<br/>from sklearn.tree import DecisionTreeRegressor<br/>import sklearn.datasets as datasets<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>from sklearn.preprocessing import OneHotEncoder<br/>from sklearn.preprocessing import PolynomialFeatures<br/>from sklearn.svm import SVR<br/>from sklearn.datasets import load_boston<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.preprocessing import MinMaxScaler</span></pre><p id="75df" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">由于make_regression函数使用线性函数生成数据，我们的线性模型可能会模拟得过于完美，这对实验不利。</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="d884" class="kw if hh ks b fi kx ky l kz la">data=datasets.make_regression(n_samples=100,n_features=1,noise=0.9,tail_strength=0.8,bias=0.9)<br/>X,y=data<br/>noise = np.random.normal(0,1,100).reshape(100,1) # Generate noise data<br/>X=X+noise # Add noise to the data</span></pre><p id="60f8" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">我们对数据拟合线性模型和决策树回归器。决策树模型可以模拟相对复杂的关系，如下所示</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="250e" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">预测强度的这种显示可以使用线性模型通过以模型更好理解的方式充分表示数据来建模。</p><p id="aec2" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">这是使用<strong class="jv hi">宁滨或离散化过程完成的。</strong>这包括将特征分割成多个特征。这类似于在matplolib中为绘制直方图创建条块的过程。</p><p id="0700" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">我们创建一组任意确定的箱数(艺术！)并根据数据集所属的箱对数据集进行分组。我们使用数据集的最小值和最大值作为边界来创建10个箱。使用NumPy可以方便地做到这一点，如下所示:</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="7bcc" class="kw if hh ks b fi kx ky l kz la">bin_ = np.linspace(-5, 5, 11)<br/>print("bin: {}".format(bin_))</span><span id="0db1" class="kw if hh ks b fi ld ky l kz la">bin: [-5. -4. -3. -2. -1.  0.  1.  2.  3.  4.  5.]</span></pre><p id="0d89" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">在这种情况下，第一个容器包含范围从-5到-4的数据，第二个容器包含范围从-3到-2的数据，依此类推。</p><p id="2a26" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">下一个过程包括将数据放入正确的箱中。这可以使用NumPy函数“数字化”来完成；</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="f61f" class="kw if hh ks b fi kx ky l kz la">find_bin = np.digitize(X, bins=bin_)</span></pre><p id="bdbe" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">这将数据的特征从连续值转换为离散值，这些离散值对它们所属的容器进行编码。</p><p id="8220" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">然后，我们使用onehotencoder将这些离散值转换为一键编码</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="657a" class="kw if hh ks b fi kx ky l kz la"># transform using the OneHotEncoder<br/>encoder = OneHotEncoder(sparse=False,handle_unknown='ignore')<br/># encoder.fit finds the unique values that appear in which_bin<br/>encoder.fit(find_bin)<br/># transform creates the one-hot encoding<br/>X_binned = encoder.transform(which_bin)</span></pre><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="ee49" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">上图显示了宁滨的强度，线性模型和决策树回归器预测每个输入的值相同，因此直接相互叠加，因为每个条柱内的特征是恒定的。</p><p id="c999" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">另一种改进特征表示的方法是使用多项式特征和交互(这是受其在统计建模中的使用的启发)。</p></div><div class="ab cl le lf go lg" role="separator"><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj lk"/><span class="lh bw bk li lj"/></div><div class="ha hb hc hd he"><p id="a139" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated"><strong class="jv hi">多项式和相互作用</strong></p><p id="37b5" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">为了添加交互式要素，我们将已入库的数据与原始要素相结合，并尝试对新数据进行建模</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="0e07" class="kw if hh ks b fi kx ky l kz la">X_combined = np.hstack([X, X_binned])</span></pre><p id="cd41" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">用线性回归对这种组合数据建模产生了这样的结果</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="6b90" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">线性模型试图基于组合的特征来学习不同箱处的不同偏移，然而斜率在箱之间似乎是相同的。为了改善这一点，让我们尝试一种不同的组合方法，我们添加一个产品交互</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="c16b" class="kw if hh ks b fi kx ky l kz la">X_product = np.hstack([X_binned, X * X_binned])</span></pre><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="dfda" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">该模型学习不同箱的不同斜率和偏移</p><p id="cb25" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">添加交互增加了模型学习斜率和偏移的能力，让我们检查多项式特征的使用</p><p id="2fd9" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated"><strong class="jv hi">多项式特征</strong></p><p id="5856" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">多项式函数由下式给出</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="278d" class="kw if hh ks b fi kx ky l kz la">f(x)=ax+bx^2+cx^3+dx^4....<br/> </span></pre><p id="9149" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">在我们的模型中使用多项式特征仅仅意味着使用所提供的原始特征的倍数，以便线性模型变成曲线并正确地对数据建模。</p><p id="84c4" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">如下所示</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="5b81" class="kw if hh ks b fi kx ky l kz la">poly = PolynomialFeatures(degree=5, include_bias=False)<br/>poly.fit(X)<br/>X_poly = poly.transform(X)</span></pre><p id="12ae" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">对新数据应用线性模型会产生以下结果</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lb lc l"/></div></figure><p id="a167" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">让我们将这个概念应用于scikit learn中提供的标准数据集；波士顿住房数据集</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="e7fb" class="kw if hh ks b fi kx ky l kz la">boston = load_boston()<br/>X_train, X_test, y_train, y_test = train_test_split(<br/>boston.data, boston.target, random_state=0)<br/># rescale data<br/>scaler = MinMaxScaler()<br/>X_train_scaled = scaler.fit_transform(X_train)<br/>X_test_scaled = scaler.transform(X_test)<br/>poly = PolynomialFeatures(degree=2).fit(X_train_scaled)<br/>X_train_poly = poly.transform(X_train_scaled)</span></pre><p id="59b4" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">使用岭回归对此数据集建模</p><pre class="jd je jf jg fd kr ks kt ku aw kv bi"><span id="1883" class="kw if hh ks b fi kx ky l kz la">ridge = Ridge().fit(X_train_scaled, y_train)<br/>print("Score without interactions: {:.3f}".format(<br/>ridge.score(X_test_scaled, y_test)))<br/>ridge = Ridge().fit(X_train_poly, y_train)<br/>print("Score with interactions: {:.3f}".format(<br/>ridge.score(X_test_poly, y_test)))</span><span id="3df4" class="kw if hh ks b fi ld ky l kz la"><strong class="ks hi">Score without interactions: 0.621<br/>Score with interactions: 0.753</strong></span></pre><p id="e35a" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">总之，要素的表示对提高线性模型的性能大有帮助，但是，由于要素工程是一门艺术，因此应谨慎使用，有多种方法可以实现这一点，但并不总是能提供更好的性能。</p><p id="8e27" class="pw-post-body-paragraph jt ju hh jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated">我很喜欢写这篇文章，我希望你也喜欢读它。</p></div></div>    
</body>
</html>