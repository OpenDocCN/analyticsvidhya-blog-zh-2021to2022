<html>
<head>
<title>Perceptron from (Almost) Zero and 3D Visualization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">来自(几乎)零和3D可视化的感知器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/perceptron-from-almost-zero-and-3d-visualization-4569f5d7fac3?source=collection_archive---------8-----------------------#2021-01-25">https://medium.com/analytics-vidhya/perceptron-from-almost-zero-and-3d-visualization-4569f5d7fac3?source=collection_archive---------8-----------------------#2021-01-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/f43554f61b652786f3b2e76f9a789f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*Hdrm9Jslk1_tsR_13PC9AA.png"/></div></figure><p id="cf87" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在之前的<a class="ae jj" rel="noopener" href="/analytics-vidhya/implementing-perceptron-learning-algorithm-to-solve-and-in-python-903516300b2f">帖子</a>中，我已经介绍了感知器算法来解决一个特定的问题(与门)。ideia的目的是了解算法是如何工作的，现在我们可以将其推广到解决任何l <a class="ae jj" href="https://en.wikipedia.org/wiki/Linear_separability#:~:text=In%20Euclidean%20geometry%2C%20linear%20separability,points%20as%20being%20colored%20red." rel="noopener ugc nofollow" target="_blank">早期可分的</a>问题(这就是标题中“几乎”的原因)。</p></div><div class="ab cl jk jl go jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="ha hb hc hd he"><p id="165e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">对我们以前在感知器上解决与门的工作的主要调整是概括我们的算法将接收的输入数量，因此它可以处理具有任意数量输入的数据集。也就是说，现在广义版本将能够找到<a class="ae jj" href="https://en.wikipedia.org/wiki/Hyperplane#:~:text=In%20geometry%2C%20a%20hyperplane%20is,are%20the%201%2Ddimensional%20lines." rel="noopener ugc nofollow" target="_blank">超平面</a>，而不是找到一条线来分隔空间。</p><figure class="jr js jt ju fd ii"><div class="bz dy l di"><div class="jv jw l"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated"><a class="ae jj" href="https://media.giphy.com/media/3o7qE1Thg4KxFpMGSk/giphy.gif" rel="noopener ugc nofollow" target="_blank">吉菲</a></figcaption></figure><p id="dbb3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">感知器的一般结构看起来像:</p><figure class="jr js jt ju fd ii er es paragraph-image"><div role="button" tabindex="0" class="kc kd di ke bf kf"><div class="er es kb"><img src="../Images/83009907791e9f1c9a632c537b380b45.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*--iJrr11FNJOx2RT9iUIQg.jpeg"/></div></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">作者图片</figcaption></figure><p id="6c4e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我已经把算法包装成一个类，用法分为三种方法:</p><ul class=""><li id="b00f" class="kg kh hh in b io ip is it iw ki ja kj je kk ji kl km kn ko bi translated"><strong class="in hi">初始化</strong> : __init__函数设置我们的感知器的输入长度、使用的激活函数(现在让我们使用经典的阶跃函数)、学习速率‘eta’(默认值=0.1)和使用的迭代次数(次数)(默认值=1000)。</li><li id="cf32" class="kg kh hh in b io kp is kq iw kr ja ks je kt ji kl km kn ko bi translated"><strong class="in hi">训练步骤</strong>:我们调用这个方法在训练数据集中运行学习算法。(二元分类问题，线性可分)。</li><li id="2b82" class="kg kh hh in b io kp is kq iw kr ja ks je kt ji kl km kn ko bi translated"><strong class="in hi">预测:</strong>最后，我们可以使用这种方法对一个训练集进行预测，它提供了一个评估算法性能的精度变量。</li></ul><p id="ecf5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">完整代码如下:</p><figure class="jr js jt ju fd ii"><div class="bz dy l di"><div class="ku jw l"/></div></figure><p id="06b1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">好了，为了看我们的算法在运行，让我们用获取一些数据。让我们加载<a class="ae jj" href="https://archive.ics.uci.edu/ml/datasets/iris" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a>并进行一些预测:</p><pre class="jr js jt ju fd kv kw kx ky aw kz bi"><span id="8453" class="la lb hh kw b fi lc ld l le lf">from sklearn import datasets<br/>import matplotlib.pyplot as plt</span><span id="71c6" class="la lb hh kw b fi lg ld l le lf">iris = datasets.load_iris()</span><span id="3675" class="la lb hh kw b fi lg ld l le lf">#divide into features and target variables<br/>X = iris.data[:100, ]<br/>Y = iris.target[:100]</span></pre><p id="270c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">Iris数据集为3种不同的鸢尾属植物(virginica、setosa和versicolor)提供了4个特征(萼片长度、萼片宽度、花瓣长度、花瓣宽度)。如果你看一下完整的数据集，每个类有三个不同的标签，</p><figure class="jr js jt ju fd ii er es paragraph-image"><div class="er es lh"><img src="../Images/0ded33bd2daa2f30ebd76a30603c6c0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*toZ7QEmiX_61y5SOIDIBYA.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">iris数据集类别</figcaption></figure><p id="19d5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了进行二元分类，我们在上面的X和Y数组中取了前100个条目。我们可以使用下面的函数来绘制特征:</p><pre class="jr js jt ju fd kv kw kx ky aw kz bi"><span id="47f7" class="la lb hh kw b fi lc ld l le lf"># Plot the training points<br/>def plot_iris(X1, X2,  Y, X1_label, X2_label):<br/>    plt.scatter(X1, X2, c=Y, cmap=plt.cm.Set1,<br/>                edgecolor='k')<br/>    plt.xlabel(X1_label)<br/>    plt.ylabel(X2_label)</span><span id="eff1" class="la lb hh kw b fi lg ld l le lf">plot_iris(X[:, 0], X[:, 1], Y, iris.feature_names[0], iris.feature_names[1])</span></pre><figure class="jr js jt ju fd ii er es paragraph-image"><div class="er es li"><img src="../Images/4f1ef8514bf857317df2f99c5c9180cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*TN_QTK9FjoZnJLRR2ZF7bg.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">作者</figcaption></figure><p id="42dc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">上图清楚地显示了0类和1类可以通过萼片宽度和萼片长度这两个特征进行线性分离。这与我们已经解决的与门问题类似。因此，让我们在感知器实现中再使用一个特性来解决这个问题。首先，我们在scikitlearn的帮助下将数据分成训练和测试:</p><pre class="jr js jt ju fd kv kw kx ky aw kz bi"><span id="d630" class="la lb hh kw b fi lc ld l le lf">from sklearn.model_selection import train_test_split</span><span id="6296" class="la lb hh kw b fi lg ld l le lf"># choosing three features to work with here: (X[:, :3])</span><span id="55fb" class="la lb hh kw b fi lg ld l le lf"><br/>X_train, X_test, y_train, y_test = train_test_split(X[:, :3], Y, test_size= 0.2)</span></pre><p id="4d08" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们可以在3d空间中可视化我们的数据:</p><figure class="jr js jt ju fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/65b46ebc3ba4cec421cf41e11ce06a2e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*12mMropAf8pIgneKTcgJQw.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">两个第一类的虹膜数据集(setosa和versicolor)</figcaption></figure><p id="874c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们实例化我们的感知器(您将需要创建激活函数来传递给类实例):</p><pre class="jr js jt ju fd kv kw kx ky aw kz bi"><span id="c760" class="la lb hh kw b fi lc ld l le lf">def step_function(x):<br/>    if x &gt; 0:<br/>        return 1<br/>    else:<br/>        return 0</span><span id="3694" class="la lb hh kw b fi lg ld l le lf">percep_iris = Perceptron(input_length=X_train.shape[1], eta=0.1, activ_f=step_function, epochs=1000)</span></pre><p id="c345" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们可以获得用‘percp _ iris . weight’随机初始化的权重，并绘制随机生成的平面:</p><figure class="jr js jt ju fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/f43554f61b652786f3b2e76f9a789f3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*Hdrm9Jslk1_tsR_13PC9AA.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">初始化生成的平面(作者)</figcaption></figure><p id="7ddc" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，让我们实际训练我们的算法:</p><pre class="jr js jt ju fd kv kw kx ky aw kz bi"><span id="faf1" class="la lb hh kw b fi lc ld l le lf">percep_iris.train(X_train, y_train)</span></pre><p id="9c41" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然后，您可以用测试集评估算法(您应该得到1的准确度，因为这是一个简单的问题)</p><pre class="jr js jt ju fd kv kw kx ky aw kz bi"><span id="c538" class="la lb hh kw b fi lc ld l le lf">percep_iris.predict(X_test, y_test)<br/>percep_iris.accuracy</span></pre><p id="5610" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们还可以用训练步骤中生成的正确权重来绘制新平面:</p><figure class="jr js jt ju fd ii er es paragraph-image"><div class="er es ie"><img src="../Images/5d4d0934b402191808f994a4243c7da3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1150/format:webp/1*Y228gXU43hy9SaP4qDnRlg.png"/></div><figcaption class="jx jy et er es jz ka bd b be z dx translated">用训练过的砝码分离平面</figcaption></figure><p id="8f15" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们可以看到，它确实分离了测试集的所有点，这就是为什么准确率为100%！</p></div><div class="ab cl jk jl go jm" role="separator"><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp jq"/><span class="jn bw bk jo jp"/></div><div class="ha hb hc hd he"><h1 id="df4d" class="lj lb hh bd lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me mf bi translated"><strong class="ak">结论</strong></h1><p id="d2f5" class="pw-post-body-paragraph il im hh in b io mg iq ir is mh iu iv iw mi iy iz ja mj jc jd je mk jg jh ji ha bi translated">回顾最经典的分类算法之一的快速帖子。我认为从零开始实现机器学习，即使是在非常基础的水平上，也是真正理解它们并进化到解决现实世界问题的最佳方式。任何问题，音乐会和评论家将不胜感激。你可以去我的<a class="ae jj" href="https://github.com/netofigueira/algorithms-sharing/blob/main/PerceptronClass.ipynb" rel="noopener ugc nofollow" target="_blank"> github </a>查看生成剧情的完整代码。</p><h1 id="9509" class="lj lb hh bd lk ll ml ln lo lp mm lr ls lt mn lv lw lx mo lz ma mb mp md me mf bi translated">参考</h1><p id="b561" class="pw-post-body-paragraph il im hh in b io mg iq ir is mh iu iv iw mi iy iz ja mj jc jd je mk jg jh ji ha bi translated">【https://matplotlib.org/3.1.1/gallery/mplot3d/scatter3d.html T4】</p><p id="1507" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">米切尔，T. M. (1997)。<em class="mq">机器学习</em>。纽约:麦格劳-希尔公司。国际标准书号:978–0–07–042807–2</p></div></div>    
</body>
</html>