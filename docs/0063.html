<html>
<head>
<title>“SimSiam” Paper Explained</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“暹罗”报解释说</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/simsiam-paper-explained-df3577cab49e?source=collection_archive---------6-----------------------#2021-01-03">https://medium.com/analytics-vidhya/simsiam-paper-explained-df3577cab49e?source=collection_archive---------6-----------------------#2021-01-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><blockquote class="ie if ig"><p id="3ca2" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated"><a class="ae jg" href="http://cvpr2021.thecvf.com/node/329" rel="noopener ugc nofollow" target="_blank">更新:陈和何的《探索简单的连体表示学习》获得了第21届最优秀论文荣誉奖。</a></p></blockquote><p id="7441" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">近年来，自我监督表征学习领域非常受欢迎，并已显示出在提高许多任务的性能方面非常有效。</p><p id="28b0" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">在这篇博文中，我们来了解一下人工智能研究院的陈和何的最新研究论文<strong class="ik hi">探索简单暹罗表征学习。</strong></p><p id="c165" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">如果你是一个熟悉自我监督学习和表征学习的高级读者，你可以直接跳到<strong class="ik hi">提出解决方案一节。</strong></p><h1 id="aafb" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">自我监督学习</h1><p id="ff2c" class="pw-post-body-paragraph ih ii hh ik b il ki in io ip kj ir is jh kk iv iw ji kl iz ja jj km jd je jf ha bi translated">顾名思义，它是一个学习算法家族，可以以自我监督的方式学习任务，即不需要手动标记数据。</p><h1 id="59de" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">表征学习</h1><p id="3668" class="pw-post-body-paragraph ih ii hh ik b il ki in io ip kj ir is jh kk iv iw ji kl iz ja jj km jd je jf ha bi translated">在表征学习中，我们为图像(或文本或音频)开发表征向量。假设有一张256x256大小的狗的图片，有三种颜色。该图像具有256x256x3张量形式的像素数据。在表示学习中，我们试图开发一个大小为1x1024(或任何合适的维度)的向量，它可以捕获关于图像的更高级别的抽象信息，而不仅仅是原始像素。</p><h1 id="0d77" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">自我监督表示学习</h1><p id="a377" class="pw-post-body-paragraph ih ii hh ik b il ki in io ip kj ir is jh kk iv iw ji kl iz ja jj km jd je jf ha bi translated">这是通过拍摄相似的图像(或文本或声音)并强制具有相似的表示向量来实现的。</p><h1 id="ec30" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">问题</h1><p id="1914" class="pw-post-body-paragraph ih ii hh ik b il ki in io ip kj ir is jh kk iv iw ji kl iz ja jj km jd je jf ha bi translated">简单的自我监督表示学习的问题是，在几个时期之后，该模型学习身份映射——对于所有图像，它输出相同的向量。这是因为我们希望表示向量相似。身份映射给出了相同的表示，因此模型的余弦相似性损失变成了<strong class="ik hi">零</strong>。</p><p id="7d50" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">尽管在训练过程中损失为零，但是所学习的表示是无用的，因为所有图像都得到相同的表示。</p><h1 id="2c3d" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">提出解决方案</h1><p id="3122" class="pw-post-body-paragraph ih ii hh ik b il ki in io ip kj ir is jh kk iv iw ji kl iz ja jj km jd je jf ha bi translated">自我监督表示学习中的折叠到身份映射的问题通过以下方式解决:</p><ul class=""><li id="16d9" class="kn ko hh ik b il im ip iq jh kp ji kq jj kr jf ks kt ku kv bi translated">论文中的阴性样本<strong class="ik hi"> SimCLR，和MoCo </strong>。这个想法是使用负样本，我们的损失函数不仅衡量相似图像的相似性，还衡量不同图像之间的差异。</li></ul><p id="300f" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">注1: <strong class="ik hi">有监督的对比学习</strong>也使用负样本，但不是自监督的，所以不提。</p><p id="4b2a" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">注2: <strong class="ik hi"> MoCo </strong>也使用移动平均法，但不仅限于此。</p><ul class=""><li id="4f85" class="kn ko hh ik b il im ip iq jh kp ji kq jj kr jf ks kt ku kv bi translated">论文在线聚类<strong class="ik hi"> SwAV。</strong>想法是对图像进行聚类，并将聚类用作正样本和负样本。</li><li id="aa88" class="kn ko hh ik b il kw ip kx jh ky ji kz jj la jf ks kt ku kv bi translated">文中均线<strong class="ik hi"> BYOL。</strong>想法是用一个带移动平均值的网络来代表相似的样本。这种方法不需要任何负样本。</li></ul><h1 id="34b6" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">这篇论文</h1><p id="75a9" class="pw-post-body-paragraph ih ii hh ik b il ki in io ip kj ir is jh kk iv iw ji kl iz ja jj km jd je jf ha bi translated">整篇论文的一句话概括就是</p><blockquote class="ie if ig"><p id="584f" class="ih ii ij ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf ha bi translated">没有动量编码器的BYOL。无负样本的SimCLR。无在线聚类的SWaV</p></blockquote><p id="a5ea" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">这篇论文的作者发现，即使在删除了所有添加的额外结构(如负样本、聚类和移动平均)以防止模型崩溃到身份映射之后。模型可以学习好的表示。</p><h1 id="2fba" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">怎么会？</h1><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lb"><img src="../Images/c58864bba420389331e33c7610e821ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uXpbZ3v_Z35rL47rnkhWTw.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx translated"><strong class="bd jm"> SimSiam </strong>的模型架构</figcaption></figure><p id="8b8c" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">只有<strong class="ik hi">停止-分级</strong>操作足以获得下游任务的比较结果。在stop-grad方法中，我们使流过该分支<strong class="ik hi">、</strong>的所有梯度为零，因此只有编码器-预测器分支在训练步骤得到更新。</p><p id="d68b" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">这种方法出奇的简单，并且显示出<strong class="ik hi">连体网络</strong>在开发表示方面具有强大的能力。</p><p id="0dfc" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">注arXiv update v3中的<strong class="ik hi"> BYOL </strong>论文在预训练阶段以10倍的学习速率做了300个时期的相同程序。这项工作是同时进行的，应该得到承认。</p><h1 id="da62" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">结果</h1><figure class="lc ld le lf fd lg er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lr"><img src="../Images/a323378bc45937dba7f890874d6697af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6dgh2KZaa7nSbsXuroQ8wA.png"/></div></div><figcaption class="ln lo et er es lp lq bd b be z dx translated">ImageNet分类任务的结果</figcaption></figure><p id="177d" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">很明显，<strong class="ik hi"> SimSiam </strong>的简单性在前100个纪元中比其他所有方法都更成功。同样显而易见的是，像<strong class="ik hi"> BYOL </strong>这样更先进的方法在训练更多的时期时更有优势。</p><p id="f76e" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">SimSiam 方法的一个巨大优势是批量较小，因此这种方法需要的计算资源非常少。</p><h2 id="ae41" class="ls jl hh bd jm lt lu lv jq lw lx ly ju jh lz ma jy ji mb mc kc jj md me kg mf bi translated">参考</h2><ol class=""><li id="5a49" class="kn ko hh ik b il ki ip kj jh mg ji mh jj mi jf mj kt ku kv bi translated"><strong class="ik hi">暹罗— </strong> <code class="du mk ml mm mn b"> Exploring Simple Siamese Representation Learning</code></li><li id="e2de" class="kn ko hh ik b il kw ip kx jh ky ji kz jj la jf mj kt ku kv bi translated"><strong class="ik hi"> SimCLR — </strong> <code class="du mk ml mm mn b">A Simple Framework for Contrastive Learning of Visual Representations</code></li><li id="de72" class="kn ko hh ik b il kw ip kx jh ky ji kz jj la jf mj kt ku kv bi translated"><strong class="ik hi">simclrv 2—</strong>T2】</li><li id="6697" class="kn ko hh ik b il kw ip kx jh ky ji kz jj la jf mj kt ku kv bi translated"><strong class="ik hi">BYOL—</strong>T3】</li></ol><p id="1836" class="pw-post-body-paragraph ih ii hh ik b il im in io ip iq ir is jh iu iv iw ji iy iz ja jj jc jd je jf ha bi translated">更多有趣的论文解释博文，请关注并分享。</p></div></div>    
</body>
</html>