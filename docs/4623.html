<html>
<head>
<title>ResNet — Understand and Implement from scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ResNet —了解并从头开始实施</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/resnet-understand-and-implement-from-scratch-d0eb9725e0db?source=collection_archive---------0-----------------------#2021-12-01">https://medium.com/analytics-vidhya/resnet-understand-and-implement-from-scratch-d0eb9725e0db?source=collection_archive---------0-----------------------#2021-12-01</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0e5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">人们在使用CNN时一定遇到过ResNets，或者至少听说过它，我们确实知道ResNets在大多数计算机视觉任务中表现很好，但是当我们已经有其他性能良好的架构时，为什么还需要这样的架构呢？为了回答这个问题，让我们了解Resnets之前使用的其他深度神经网络架构的缺点。</p><p id="9ab7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们认为神经网络越深，性能越好，但当研究人员用更深的神经网络进行实验时，发现向深度网络添加更多层并不总是增加其性能，而是降低其性能，这是由于非常深的神经网络中的消失梯度。因此，有人提出，向深度神经网络添加更多层应该提高其性能或保持不变，但绝不应该降低性能。为了实现这一点，他们提出了跳过连接/剩余连接的概念，通过使用这一概念，我们可以避免信息流的丢失。让我们了解一下什么是跳过连接。</p><h1 id="3027" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak">跳过连接/剩余连接</strong></h1><p id="84ac" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">跳过/剩余连接从<em class="kg"> (n-1)ᵗʰ </em>卷积层获取激活，并将其添加到<em class="kg"> (n+1)ᵗʰ </em>层的卷积输出，然后对该和应用ReLU，从而跳过<em class="kg"> nᵗʰ </em>层。</p><p id="5763" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图解释了跳过连接的工作原理。(这里我用f(x)来表示应用在x上的Relu，其中x是应用卷积运算后的输出)。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es kh"><img src="../Images/76470487d7436398a5d23ad4c00431dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*negMET6uK7bBLYaqMNpMNg.jpeg"/></div></figure><p id="c48e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">但这有什么帮助呢，简而言之，如果<em class="kg"> nᵗʰ </em>层没有学到任何东西，那么我们不会丢失任何信息，因为在<em class="kg"> (n+1)ᵗʰ </em>)我们在向前移动时也在使用<em class="kg"> (n-1)ᵗʰ </em>层的输出，然后对这个总和应用激活。</p><p id="8cc4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，如果网络不提供任何有用的信息或者根本不提供任何信息(即0 ),我们使网络能够跳过其间的一次ReLU激活，并且网络将使用先前的信息，从而保持一致的性能。无论如何，如果两层都提供了重要的信息，那么拥有先前的信息无论如何都会提高性能。</p><h1 id="b9ec" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak"> ResNet-18实施</strong></h1><p id="6388" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">为了简单起见，我们将实现Resent-18，因为它有较少的层，我们将在PyTorch中实现它，并将使用Batchnormalization、Maxpool和Dropout层。</p><p id="5a93" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是取自研究论文——图像识别的深度残差学习【链接到论文<a class="ae kp" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">】的Resnet-18的架构和层配置。</a></p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es kq"><img src="../Images/724a2a116ec5889a6f10db63e59f00fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rrlou8xyh7DeWdtHZk_m4Q.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">直接摘自《图像识别的深度残差学习》一文的ResNets架构</figcaption></figure><p id="c679" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们选择Conv3_x模块，并尝试了解其内部的情况。让我们用卷积和单位块来理解这一点。</p><p id="dac8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> Conv3_x使用卷积和标识块实现数据流</strong></p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es kz"><img src="../Images/894f826cd0d8a07cdcb51e37da3ce0a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1212/format:webp/1*o7IEqUjg318onKRAhqO0Tg.png"/></div></figure><p id="55b2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上图详细说明了56x56图像如何在Conv3_x模块中传播，现在我们来看看图像如何在这些模块中的每一步进行变换。</p><h1 id="f3ab" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">卷积块</h1><p id="2589" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">Conv3_x模块的输入是具有64个通道的shape (56x56)图像，第一个卷积层使用3x3内核和具有1x1填充的2x2跨距将图像转换为具有128个通道的(28x28)图像，并对其应用ReLU。第二卷积层以此图像为输入，输出相同形状的图像(28x28x128)。现在，为了应用残差/跳过连接，我们必须将Conv2_x模块的输出(56x56x64)与第二个卷积的输出(28x28x128)相加，为此，我们需要将Conv2_x输出转换为(28x28x128)，这是通过应用另一个具有1x1滤波器和2x2跨距的卷积来实现的，输入通道为64，输出通道为128。</p><p id="3784" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">简而言之，卷积模块负责使用卷积运算转换一个模块的输出，以便可以有效地将其与另一个卷积模块的输出相加。</p><p id="b1dd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">添加完成后，激活(ReLU)被应用于其输出，并被发送到标识块。</p><h1 id="03fa" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">身份块</h1><p id="1e14" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">单位块的输入和输出是相同的，因此为了应用剩余/跳过连接，我们不需要对卷积块的输出应用任何变换。因此，要应用Skip/Residual连接，我们只需将卷积模块的输出与Conv3_x模块中第四个卷积层的输出相加，然后对其应用ReLU。</p><p id="874d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在知道，每当需要调整输出以使应用残差连接成为可能时，我们就需要卷积模块，每当输入和输出相同时，我们就需要恒等模块。</p><h1 id="8226" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">使用Pytorch实现ResNet-18</h1><p id="f464" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">让我们定义一个实现ResNet18模型的类，模型配置和流将在__init__()函数中定义，前向传播将在forward()函数中定义。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="la lb l"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">ResNet-18 Pytorch实现</figcaption></figure><p id="6bc2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在让我们了解一下上面代码中的#BLOCK3 (Conv3_x)发生了什么。</p><ol class=""><li id="8117" class="lc ld hi ih b ii ij im in iq le iu lf iy lg jc lh li lj lk bi translated">块3从块2的输出“op2”获得输入，该输入将是形状为(56×56×64)的图像，对其应用卷积运算，其核大小为3×3，跨距为(2，2)，填充为(1，1)，并输出形状为(28×28×128)的图像，注意，这里跨距为2负责减小图像大小，现在对该输出应用Batchnormaliztion和ReLU。</li><li id="92df" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">下一层也是卷积层，但这次它有参数(内核大小(3x3)，填充(1，1)和步幅(1，1))，这些参数不会减小图像大小并保持不变，因此输出(28x28x128)图像，然后对其应用Batchnorm，让我们将此输出表示为“x”，现在如果查看forward()函数中的Block-3，可以看到在对“x”应用ReLU操作之前， 我们对“op2”应用卷积运算，这是块2的输出(调整op2的大小以匹配当前输出)，将其添加到“x ”,然后应用ReLU。 至此，我们已经使用卷积模块成功实现了跳过连接。让我们将该输出表示为op3_1。</li><li id="d22d" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">既然我们已经使用了卷积块，并且基于块-3的模型架构和输出，图像形状和大小在块-3中将不再改变，因此我们现在将使用标识块作为块-3的剩余一半。</li><li id="97e9" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">我们可以看到，在正向函数中，我们应用了Conv → Batchnorm → ReLU，然后是Conv → Batchnorm，我们得到了输出x，然后我们只需将卷积模块的输出“op3_1”与x相加，然后对其应用ReLU。注意，在整个标识块中，图像大小保持不变。</li><li id="8ce0" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">类似地，我们也可以创建所有其他块，唯一的例外是块2，其中图像大小在卷积块中甚至没有减小。这可以直接实现，或者我们甚至可以使用与stride (1，1)的卷积运算。</li><li id="bce6" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">对于输入层，我们使用Conv → Batchnorm → Maxpool，其中卷积内核大小为7x7，步长为2，填充为3，这将输入图像大小从(224x224x3)更改为(112x112x64)，然后Maxpool将其大小更改为(56x56x64)。</li><li id="638f" class="lc ld hi ih b ii ll im lm iq ln iu lo iy lp jc lh li lj lk bi translated">对于输出/分类层，我们使用完全连接的层，但在此之前，我们对Block5的输出应用平均池化操作，它将处于形状(7x7x512)，使用7x7过滤器大小和跨距1，将图像大小减小到(1x1x512)，然后我们对该输出进行整形/展平，以便它可以由完全连接的层使用。</li></ol><p id="b2ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">很好，现在你知道了我们如何实现ResNet，<strong class="ih hj"> <em class="kg">注意，我们可以为卷积和单位块创建函数，并多次调用它们，从而非常容易地创建更深层次的ResNet架构，而不是单独创建每个块。</em>T3】</strong></p><p id="80e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">实现后，我们可以直接创建这个类的对象，传递数据集的输出类的数量，并使用它在任何图像数据上训练我们的网络。</p><p id="6393" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">请访问以下链接，查看使用上述类构建ResNet-18模型的完整代码，并使用PyTorch对胸部X射线图像数据集进行训练，以对一个人是否患有肺炎进行分类。</p><div class="lq lr ez fb ls lt"><a href="https://www.kaggle.com/modojj/resnet18-from-scratch-pytorch" rel="noopener  ugc nofollow" target="_blank"><div class="lu ab dw"><div class="lv ab lw cl cj lx"><h2 class="bd hj fi z dy ly ea eb lz ed ef hh bi translated">ResNet18从零开始- Pytorch</h2><div class="ma l"><h3 class="bd b fi z dy ly ea eb lz ed ef dx translated">使用Kaggle笔记本电脑探索和运行机器学习代码|使用来自胸部x光图像的数据</h3></div><div class="mb l"><p class="bd b fp z dy ly ea eb lz ed ef dx translated">www.kaggle.com</p></div></div><div class="mc l"><div class="md l me mf mg mc mh kn lt"/></div></div></a></div></div></div>    
</body>
</html>