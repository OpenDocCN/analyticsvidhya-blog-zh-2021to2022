<html>
<head>
<title>Part 1: AlphaZero implementation for the game Onitama</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">第1部分:Onitama游戏的AlphaZero实现</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/part-1-alphazero-implementation-for-the-game-onitama-370afb1259e6?source=collection_archive---------1-----------------------#2022-02-20">https://medium.com/analytics-vidhya/part-1-alphazero-implementation-for-the-game-onitama-370afb1259e6?source=collection_archive---------1-----------------------#2022-02-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="b2b7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">AlphaZero怎么才能学会玩游戏？游戏Onitama的实现！</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/0271ff2622e943743a08a0bc1e0b90ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*66oKsWSn8fVBGyCD.png"/></div></div></figure><ul class=""><li id="6131" class="jo jp hh ig b ih ii il im ip jq it jr ix js jb jt ju jv jw bi translated">第二部分:很快</li><li id="f852" class="jo jp hh ig b ih jx il jy ip jz it ka ix kb jb jt ju jv jw bi translated">第三部分:很快</li></ul><p id="d0f3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们将了解游戏Onitama，以及AlphaZero的主要思想。alpha zero是一种深度强化学习算法，能够在没有人类信息的情况下学习玩游戏！</p><p id="1234" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我为Onitama游戏实现的AlphaZero可以在我的<a class="ae kc" href="https://github.com/Nicolas-Maurer/Onitama_AlphaZero" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到。</p><h1 id="bfc7" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">奥尼塔玛是什么？</h1><p id="bae7" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">Onitama是一个2人棋盘游戏，具有完美的信息和随机启动。棋盘大小为5x5，每个玩家以5枚棋子开始游戏(4枚棋子和一枚主棋子)。</p><p id="4112" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在游戏中，总共有16张卡片定义了棋子可能的移动。游戏开始时，从16张牌中抽出5张，每位玩家2张，剩下一张放在棋盘的一边。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lg"><img src="../Images/cd6ce17e849109aec9aa23525e803277.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*LihIIMfvwzBtn0HD.jpg"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">来源:https://www.ultraboardgames.com/onitama/game-rules.php<a class="ae kc" href="https://www.ultraboardgames.com/onitama/game-rules.php" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="4319" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每回合，每位玩家可以根据他们牌上的移动次数移动他们的兵。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lg"><img src="../Images/bf30b6ff3363cde6575fc27122d1ac48.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/0*nZhcLan9fG5pQIyO.jpg"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">来源:https://www.ultraboardgames.com/onitama/game-rules.php<a class="ae kc" href="https://www.ultraboardgames.com/onitama/game-rules.php" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="7078" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦选择了一张牌并开始移动，这张牌与旁边的那张交换，然后下一个玩家开始它的回合。</p><h2 id="24e7" class="ll ke hh bd kf lm ln lo kj lp lq lr kn ip ls lt kr it lu lv kv ix lw lx kz ly bi translated">要赢得游戏，你有两个选择:</h2><ul class=""><li id="d928" class="jo jp hh ig b ih lb il lc ip lz it ma ix mb jb jt ju jv jw bi translated">占领对手的主卒</li><li id="7d6d" class="jo jp hh ig b ih jx il jy ip jz it ka ix kb jb jt ju jv jw bi translated">将你的主卒移动到对手的神殿</li></ul><p id="50ef" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">既然我们知道了这个游戏的玩法，那就来看看AlphaZero算法是如何工作的吧！</p><h1 id="d75b" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">AlphaZero的主要思想:神经网络和MCTS。</h1><p id="6455" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">AlphaZero是一种强化学习算法，从<strong class="ig hi">自我游戏</strong>中学习，除了游戏规则之外<strong class="ig hi">没有人类信息</strong>。</p><p id="1bca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2016年，DeepMind推出了AlphaGo，这是第一个能够在围棋比赛中击败人类的算法。2018年，他们发布了新版本的AlphaGo Zero，通过从空白中学习除规则之外的一切，超越了AlphaGo。几个月后，他们将AlphaGo Zero推广到其他游戏，如国际象棋或日本象棋，他们称之为AlphaZero。</p><p id="206a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们来理解这个不可思议的算法的主要思想。这是我对《神奇的纸》<a class="ae kc" href="https://arxiv.org/pdf/1712.01815.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mc">用通用强化学习算法</em></a>【silver et al . 2017】通过自我对弈掌握棋和Shogi》的理解</p><h2 id="1adb" class="ll ke hh bd kf lm ln lo kj lp lq lr kn ip ls lt kr it lu lv kv ix lw lx kz ly bi translated">除了规则，AlphaZero可以自学所有东西，但是怎么学呢？</h2><p id="7a3d" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">AlphaZero由两个主要部分组成，一个<strong class="ig hi">神经网络和一个蒙特卡罗树搜索(MCTS) </strong>。这两个部分用于生成自玩游戏，即训练集。然后用训练集训练神经网络，循环再开始。</p><p id="cb76" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了产生自我游戏，神经网络和MCTS一起工作。神经网络用于评估位置、游戏状态，MCTS执行N次模拟以选择下一步棋。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es md"><img src="../Images/0f095edc38ff52c1c3060b390e15d13a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*iIGp0cooUh19e6aV.jpg"/></div></div></figure><h2 id="8a55" class="ll ke hh bd kf lm ln lo kj lp lq lr kn ip ls lt kr it lu lv kv ix lw lx kz ly bi translated">生成自玩游戏。</h2><p id="b55c" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">神经网络拥有<strong class="ig hi">两个头</strong>，一个给出棋盘的<strong class="ig hi">值</strong>，一个给出<strong class="ig hi">所有可能走法</strong>的输出<strong class="ig hi">策略</strong>。那么所有的非法移动都被过滤掉，并且策略被重新规范化以具有等于1的总和。</p><p id="77c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后MCTS会选择最好的一步棋。为此，MCTS执行<strong class="ig hi"> 4个步骤:</strong></p><ul class=""><li id="6397" class="jo jp hh ig b ih ii il im ip jq it jr ix js jb jt ju jv jw bi translated"><strong class="ig hi">选择</strong>:从根节点开始，依次选择最佳子节点，直到到达叶子节点。</li><li id="4a8e" class="jo jp hh ig b ih jx il jy ip jz it ka ix kb jb jt ju jv jw bi translated"><strong class="ig hi">展开</strong>:从选中的节点开始，为所有可能的移动创建子节点。</li><li id="489d" class="jo jp hh ig b ih jx il jy ip jz it ka ix kb jb jt ju jv jw bi translated"><strong class="ig hi">模拟</strong>:通常模拟由玩随机移动组成，直到游戏结束，但在我们的情况下，神经网络将预测棋盘的值。</li><li id="7206" class="jo jp hh ig b ih jx il jy ip jz it ka ix kb jb jt ju jv jw bi translated"><strong class="ig hi">反向传播</strong>:模拟的结果，用于更新父节点的信息。</li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es me"><img src="../Images/a075612303a18ae054da181b932dc90f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*hQaxMphjh4VQNx4-.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">来源:<a class="ae kc" href="https://en.wikipedia.org/wiki/Monte_Carlo_tree_search" rel="noopener ugc nofollow" target="_blank">维基百科</a></figcaption></figure><p id="12b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">选择是MCTS </strong>最重要的部分，最好的孩子是利用UCT ( <em class="mc">置信上限</em> 1 <em class="mc">应用于树木)</em>公式相继选出的。这就是神奇的地方，通过足够的训练，AlphaZero只会考虑最好的移动。</p><blockquote class="mf mg mh"><p id="d891" class="ie if mc ig b ih ii ij ik il im in io mi iq ir is mj iu iv iw mk iy iz ja jb ha bi translated">主要的困难是在勘探和开采之间选择正确的平衡。</p></blockquote><p id="7778" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在论文中，他们提到每个MCTS执行800次模拟。此外，树不会在移动之间重置，只会在游戏之间重置。</p><h2 id="3a02" class="ll ke hh bd kf lm ln lo kj lp lq lr kn ip ls lt kr it lu lv kv ix lw lx kz ly bi translated">培养</h2><p id="a4c3" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">在训练期间，AlphaZero移动在<strong class="ig hi">中被<strong class="ig hi">选择</strong>与根访问计数</strong>成比例，他们根据合法移动的平均数量将狄利克雷噪声添加到这些概率中。</p><p id="b803" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练神经网络以适应棋盘的值和MCTS给出的移动策略。随着时间的推移，它会学会避免非法和糟糕的举动。</p><h1 id="e984" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated"><strong class="ak">总之:</strong></h1><p id="4040" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">AlphaZero是一种深度强化学习算法，能够通过自我游戏学习玩许多不同的游戏，而无需事先的人类信息！这是可能的，因为神经网络和MCTS的结合正在一起工作。</p><h1 id="daaa" class="kd ke hh bd kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la bi translated">希望你喜欢这个故事！</h1><p id="a2f4" class="pw-post-body-paragraph ie if hh ig b ih lb ij ik il lc in io ip ld ir is it le iv iw ix lf iz ja jb ha bi translated">仅此而已！我希望你对这个帖子感兴趣，如果你想在接下来的部分得到通知，别忘了关注我！</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ml"><img src="../Images/ecb4ffc4e4c22048cb8d11f7aba1a360.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lp2zq7TAY4ZeJZg2.png"/></div></div></figure></div></div>    
</body>
</html>