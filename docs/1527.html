<html>
<head>
<title>Batching Strategies For LSTM Input</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">LSTM输入的批处理策略</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/batching-strategies-for-lstm-input-6f18089b1735?source=collection_archive---------10-----------------------#2021-03-06">https://medium.com/analytics-vidhya/batching-strategies-for-lstm-input-6f18089b1735?source=collection_archive---------10-----------------------#2021-03-06</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2d4b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如何在Pytorch中正确完成</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/441fbf9e4110a98cef927b0b7b92c1c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1eRhpO0DD0vEWMrh-neO0A.jpeg"/></div></div></figure><h1 id="4cc5" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">介绍</h1><p id="0b5e" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">使用RNN图层时，尤其是在处理不同大小的数据时，一个常见的问题就是批处理。众所周知，批量处理我们的数据有很多好处，但是仅仅考虑如何去做就会让人精神崩溃。</p><p id="aad8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一想到我们将不得不编写或从其他地方获取只有代码作者才理解的复杂而低效的代码，就感到恐怖！在其他一些时候，这是不可能的。嗯，我说不一定要这样。</p><p id="eb1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我将分享我在批处理数据时使用的一些策略。虽然我将在这里使用Pytorch，但同样的想法也适用于其他库。本文中使用的完整代码位于这个<a class="ae ks" href="https://github.com/judahsemi/Dino-Name-Generator" rel="noopener ugc nofollow" target="_blank"> Github库</a>中。</p></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="c913" class="jo jp hh bd jq jr la jt ju jv lb jx jy jz lc kb kc kd ld kf kg kh le kj kk kl bi translated">概观</h1><p id="437f" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">我将介绍我们深度学习过程中不同阶段的策略。所以我们可以专注于题目；我将使用我写的<a class="ae ks" rel="noopener" href="/analytics-vidhya/generating-dinosaur-names-with-pytorch-ee839e97bb76">上一篇文章</a>中的任务。但是，阅读它并不是必需的！</p><p id="b3e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将训练我们的模型来生成恐龙的名字；这是我们将使用的<a class="ae ks" href="https://gist.github.com/judahsemi/210d42e0410c122aa0e437861c46cf94" rel="noopener ugc nofollow" target="_blank">数据</a>。这是一个文本文件，在一个新的行中包含每个恐龙的名字。如果你需要我在这个任务中所做的事情，我可能已经在另一篇文章中谈到了。</p><p id="39b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就这样，让我们开始吧。</p></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="1bfc" class="jo jp hh bd jq jr la jt ju jv lb jx jy jz lc kb kc kd ld kf kg kh le kj kk kl bi translated">1.词汇</h1><p id="98c0" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">我们的策略列表中的第一个与我们如何定义我们的词汇有关。但是在我们开始之前，我们需要预处理我们的数据。目标是将每个恐龙的名字转换成它的字符列表，并将EOS(序列结束)标记附加到列表中。例如，亚琛龙的名字是:</p><pre class="jd je jf jg fd lf lg lh li aw lj bi"><span id="e8b9" class="lk jp hh lg b fi ll lm l ln lo">["a", "a", "c", "h", "e", "n", "o", "s", "a", "u", "r", "u", "s", "&lt;EOS&gt;"]</span></pre><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="d262" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">之后，我们创建我们的词汇表，它将包含英语字母表的26个字母、EOS标记和PAD(填充)标记，使我们的词汇表大小为28。然后我们创建两个字典；第一种方法将词汇表中的每个条目映射到一个惟一的整数，第二种方法正好相反。</p><p id="e741" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，在定义我们的词汇表时，我们<strong class="ig hi">最后添加PAD标记是非常重要的。这样做将使填充索引(它是填充令牌的索引)为27。稍后当我们定义我们的模型时，我会解释为什么我们要这样做。</strong></p></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="0d46" class="jo jp hh bd jq jr la jt ju jv lb jx jy jz lc kb kc kd ld kf kg kh le kj kk kl bi translated">2.数据加载</h1><p id="f659" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">批量处理数据的下一个(也是最明显的)阶段是获取几个长度相等的样本，然后将它们堆叠在一起。现在，有很多方法可以做到这一点，但我们想保持事情简单明了。我们要做的是<strong class="ig hi">用填充索引填充每个样本，直到它的长度等于我们的数据</strong>中最长的训练样本(X)的长度。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="b83f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们首先将已经处理过的数据中的每个字符转换为整数，同时，我们跟踪最长X的长度。我们很快就会看到，X比实际样本少1，这就是为什么我在更新max_seqlen时减1。当我们不想批处理数据时，batched参数允许我们跳过整个填充过程。</p><p id="d857" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来是__getitem__方法，我们从索引ix处的样本中截取X和Y。然后我们追加尽可能多的填充索引，使它们的长度等于max_seqlen，将它们转换成张量，最后返回它们。我们还<strong class="ig hi">在填充X之前存储它的大小</strong>。将来某个特定的Pytorch方法会需要它。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="dd5b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们创建一个batch_size为16的DataLoader对象，并将shuffle设置为True。如果上面的for循环产生一个错误，那么您可能正在做一些不同的事情。</p></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="f963" class="jo jp hh bd jq jr la jt ju jv lb jx jy jz lc kb kc kd ld kf kg kh le kj kk kl bi translated">3.模型定义</h1><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="3133" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们模型的__init__方法中，您会注意到我们将嵌入层的padding_idx参数设置为PAD索引。这将<strong class="ig hi">使填充索引处的嵌入成为零向量，并且还确保其梯度总是零</strong>。因此，与其他嵌入不同，当我们执行反向支持时，它不会改变。</p><p id="e15c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">还要注意的是，我们<strong class="ig hi">将线性层的输出特征数量设置为1——比词汇表大小</strong>小。现在，如果你还记得的话，我们故意让PAD token成为我们词汇中的最后一个。这样做的效果是，我们的模型将永远不会预测PAD指数作为答案。</p><p id="2093" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们将PAD index设置为其他值，如零(常见情况)，也可以实现这一点，但这样做会使结果很难解释。</p></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="d797" class="jo jp hh bd jq jr la jt ju jv lb jx jy jz lc kb kc kd ld kf kg kh le kj kk kl bi translated">4.前进传球</h1><p id="2456" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">通过我们的模型的正向传递(由于我们添加的填充)，我们必须<strong class="ig hi">屏蔽输入，这样LSTM层忽略每个样本的填充</strong>。这里，我们的正向传递完全是在我们模型的正向方法中定义的。它看起来和我们不进行批处理时的情况很相似，除了我们现在有两个奇怪命名的方法，让我们的生活轻松了100倍。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure><p id="6262" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些方法中的第一个，pack_padded_sequence，为我们做了屏蔽。它将我们的嵌入和批量中每个样本的真实长度作为输入；这是我们使用数据集类中的x_len的地方。然后，它执行所需的转换，并返回LSTM层理解的PackedSequence对象。</p><p id="d68e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请务必注意，LSTM图层的输出也是一个PackedSequence对象。现在，线性层不接受这个对象，所以我们需要先将其转换为张量。我们用第二种方法pad_packed_sequence来实现，它与第一种方法相反。</p></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="db35" class="jo jp hh bd jq jr la jt ju jv lb jx jy jz lc kb kc kd ld kf kg kh le kj kk kl bi translated">5.损失函数</h1><p id="e017" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">我们策略的最后一点是，<strong class="ig hi">在计算我们的损失时，我们忽略目标(Y)值与填充指数</strong>相同的指数。这是为了使它们不会影响我们的梯度，也不会影响我们模型的训练。当我们评估我们的模型时也是如此。如果我们不忽略它们，填充会增加我们不想要的噪声。</p><p id="d272" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">幸运的是，Pytorch的交叉熵损失函数可以为我们做到这一点。我们只需要将ignore_index参数设置为PAD index，就可以了。我还提供了一个例子，说明在没有ignore_index功能的情况下使用损失函数是如何做到这一点的。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lp lq l"/></div></figure></div><div class="ab cl kt ku go kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="ha hb hc hd he"><h1 id="5b3b" class="jo jp hh bd jq jr la jt ju jv lb jx jy jz lc kb kc kd ld kf kg kh le kj kk kl bi translated">结论</h1><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lr lq l"/></div></figure><p id="997f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你遵循这里列出的简单策略，我敢肯定你现在会尖叫。我还应该提到的是，我测试了非批处理VS批处理的单遍，它们都给出了相同的输出和损失。就好像我们从来没有对我们的数据进行批处理，却获得了批处理的所有好处。</p><p id="6c0a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们讨论的主要观点用粗体字表示；您可以浏览它们以获得摘要。当处理其他库或不同的序列数据(如音频、视频、信号等)时，这些相同的想法也适用。</p><p id="afe0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可以在我在本文开头发布的Github资源库中找到完整的代码，包括测试代码。</p><p id="5a18" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你喜欢这篇文章，请记得鼓掌，分享和关注我。感谢阅读！</p><div class="ls lt ez fb lu lv"><a href="https://unsplash.com/photos/-2vD8lIhdnw" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab dw"><div class="lx ab ly cl cj lz"><h2 class="bd hi fi z dy ma ea eb mb ed ef hg bi translated">JESHOOTS.COM在Unsplash上拍摄的照片</h2><div class="mc l"><h3 class="bd b fi z dy ma ea eb mb ed ef dx translated">下载JESHOOTS.COM的免费高清照片(@jeshoots)</h3></div><div class="md l"><p class="bd b fp z dy ma ea eb mb ed ef dx translated">unsplash.com</p></div></div><div class="me l"><div class="mf l mg mh mi me mj jm lv"/></div></div></a></div></div></div>    
</body>
</html>