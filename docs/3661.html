<html>
<head>
<title>Understanding Semantic Search— (Part 1: Introduction to Machine Reading Comprehension)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解语义搜索—(第1部分:机器阅读理解简介)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/open-domain-question-answering-series-part-1-introduction-to-reading-comprehension-question-1898c8c9560e?source=collection_archive---------4-----------------------#2021-07-16">https://medium.com/analytics-vidhya/open-domain-question-answering-series-part-1-introduction-to-reading-comprehension-question-1898c8c9560e?source=collection_archive---------4-----------------------#2021-07-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/333f5aec29f5bd85a2aa8f6ab9a77e4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*--QusSbjW1XXCQaoobEfxA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">作者照片:太浩湖之旅中我最喜欢的照片(2019年7月)</figcaption></figure><p id="0288" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">你有没有想过谷歌如何给我们的问题一个粒度的答案？</p><figure class="js jt ju jv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jr"><img src="../Images/557ecb2b443657df478b931ac49e5b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v0a6gTJ56D9Dnb3fjEXm0A.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">来自作者的截图</figcaption></figure><p id="68dc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">传统的搜索引擎只能给出与问题相关的网站。然而，由于机器阅读理解、迁移学习和语言建模方面的进步，当前的搜索引擎可以为每个问题提供粒度答案。在这篇文章中，我将介绍机器阅读理解。</p><p id="a748" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">机器阅读理解的任务是建立一个理解文章的系统来回答与之相关的问题。阅读理解模型的输入是一个问题和一个上下文/段落。模型的输出是文章的答案。</p><figure class="js jt ju jv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jw"><img src="../Images/ad02eb28e8be7c60e723c5ee66ed0b56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dC6jVLNKZiGKziajWQ22bw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">来自作者的截图</figcaption></figure><p id="ab87" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">建立任何好的机器学习模型都需要相关的高质量数据集。自2015年以来，已经发布了收集了超过100，000个样本(问题、段落和答案)的数据集。</p><figure class="js jt ju jv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jw"><img src="../Images/40abb0e617202a5a42900c47cceef211.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TgNt6cCEpuFFp3ZGjTiwzw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">阅读理解/问答数据集:<a class="ae jx" href="https://paperswithcode.com/task/question-answering" rel="noopener ugc nofollow" target="_blank">论文，代码</a></figcaption></figure><h2 id="6d1a" class="jy jz hh bd ka kb kc kd ke kf kg kh ki je kj kk kl ji km kn ko jm kp kq kr ks bi translated">小队:</h2><p id="6fd2" class="pw-post-body-paragraph it iu hh iv b iw kt iy iz ja ku jc jd je kv jg jh ji kw jk jl jm kx jo jp jq ha bi translated">斯坦福问答数据集(<a class="ae jx" href="https://rajpurkar.github.io/SQuAD-explorer/" rel="noopener ugc nofollow" target="_blank"> SQuAD </a>)是一个阅读理解数据集，由一组维基百科文章的众包构成的10万个问答对组成。每个问题的答案都是阅读文章中的一段文字。</p><figure class="js jt ju jv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ky"><img src="../Images/5b2bcc7aed392a24edb200704a5e54bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*jebAfMP_v2uk_srd"/></div></div></figure><p id="1f0c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">可以使用SQuAD构建神经问答模型(QA模型)。该模型采用提供的问题和相应的段落来预测段落中答案的开始和结束索引的概率。下图中的红色块表示高概率指数。</p><figure class="js jt ju jv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kz"><img src="../Images/d8dcf7f831e455402836553467bbd3a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8JqLPKzvTVC7zXO_o1bgBg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">截图来自作者:问答/阅读理解模型预测文章中答案的起止索引。图片创意致谢:<a class="ae jx" href="https://www.linkedin.com/in/branden-chan-59b291a8/" rel="noopener ugc nofollow" target="_blank">布兰登·陈</a></figcaption></figure><p id="2b6a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了使模型理解文本的上下文，我们使用语言模型将问题中的单词和段落转换成嵌入/向量。</p><figure class="js jt ju jv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es la"><img src="../Images/fd087b25dff8135f557207e7fa557984.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cA87Mt99e0EysJB5pvJcNQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">来自作者的截图</figcaption></figure><p id="285a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">语言模型是在大型数据集上训练的概率或统计模型，如Google books/Wikipedia dump/scraped网站，使用不同的深度学习神经网络架构来理解上下文并区分同一单词的不同含义。</p><h2 id="e622" class="jy jz hh bd ka kb kc kd ke kf kg kh ki je kj kk kl ji km kn ko jm kp kq kr ks bi translated"><strong class="ak">转移学习:</strong></h2><p id="fa8a" class="pw-post-body-paragraph it iu hh iv b iw kt iy iz ja ku jc jd je kv jg jh ji kw jk jl jm kx jo jp jq ha bi translated">迁移学习的想法是使用一个语言模型，并针对相关数据集(在我们的例子中是SQuAD)对该模型进行微调。</p><figure class="js jt ju jv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lb"><img src="../Images/a38dbf96aa72788a0f566d8268c1af6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4AWflgMFZGlUPwBGGHppRQ.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">来自<a class="ae jx" href="https://unsplash.com/" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>的<a class="ae jx" href="https://unsplash.com/@will0629" rel="noopener ugc nofollow" target="_blank">威尔·波拉达</a>的照片</figcaption></figure><h2 id="0069" class="jy jz hh bd ka kb kc kd ke kf kg kh ki je kj kk kl ji km kn ko jm kp kq kr ks bi translated"><strong class="ak">关于如何微调语言模型的技术理解:</strong></h2><p id="46e7" class="pw-post-body-paragraph it iu hh iv b iw kt iy iz ja ku jc jd je kv jg jh ji kw jk jl jm kx jo jp jq ha bi translated">BERT(来自Transformers的双向编码器表示)是由Google开发的基于transformer的语言模型，包含12个编码器堆栈(BERT Base)或24个编码器堆栈(BERT Large ),分别在Google Book语料库和Wikipedia语料库上训练。</p><p id="0e38" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了微调用于问答任务的BERT，我们可以在包含两个输出的BERT基础或大型架构的顶部添加单个线性层，一个用于预测起始索引位置，另一个用于预测结束索引位置。</p><p id="fb07" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">对模型进行微调后，最后一层的权重会根据任务进行更新(预测开始和结束索引)。我们可以预计初始层的权重变化较小，因为它们将具有BERT在谷歌图书语料库和维基百科语料库上预先训练时学习的一般表示。</p><p id="2c81" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">恭喜你，你完成了机器阅读理解入门。试试Allen NLP的机器阅读理解<a class="ae jx" href="https://demo.allennlp.org/reading-comprehension/bidaf-elmo" rel="noopener ugc nofollow" target="_blank">演示</a>。</p><p id="d14f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">在下一篇文章中，我们将讨论文本长文档的阅读理解。敬请关注开放领域问答系列更多文章！</p><p id="ab9c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">敬请关注理解语义搜索系列的更多文章！(点击了解本系列<a class="ae jx" rel="noopener" href="/@kaushikshakkari/list/9df1566193b0">中其他文章的更多信息)</a></p></div><div class="ab cl lc ld go le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ha hb hc hd he"><h2 id="fb05" class="jy jz hh bd ka kb kc kd ke kf kg kh ki je kj kk kl ji km kn ko jm kp kq kr ks bi translated">在<a class="ae jx" href="https://www.linkedin.com/in/kaushik-shakkari/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上加我。谢谢大家！</h2></div></div>    
</body>
</html>