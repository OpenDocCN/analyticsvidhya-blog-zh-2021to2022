<html>
<head>
<title>Redefining Cancer Treatment- The Memorial Sloan Way</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">重新定义癌症治疗——纪念斯隆之路</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/redefining-cancer-treatment-the-memorial-sloan-way-b71ef4eed284?source=collection_archive---------3-----------------------#2021-09-16">https://medium.com/analytics-vidhya/redefining-cancer-treatment-the-memorial-sloan-way-b71ef4eed284?source=collection_archive---------3-----------------------#2021-09-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/f31083da76d21428c2322731833a9a6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*2W6deFnCzDuJw33z.jpg"/></div></figure><p id="4684" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">每当患者出现癌症症状时，就取出癌症肿瘤并进行测序。肿瘤细胞中的遗传信息以DNA的形式储存。然后转录形成RNA，再翻译成蛋白质/氨基酸。在突变或DNA序列错误的情况下，产生的氨基酸受到影响，导致特定基因的变异。</p><p id="c344" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">该序列中可能存在数千种基因突变。我们需要区分恶性突变(导致肿瘤生长的驱动因素)和良性突变(过客)。</p><p id="15d8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们的目标是根据基于文本的临床文献的知识，将给定的基因变异对分类为9种癌症突变中的一种。</p><p id="8270" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">作为参考，每个分类标签对应于以下突变-</p><p id="4894" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">1:可能丧失功能</p><p id="21b6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">2:可能的功能增益</p><p id="71a0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">3:中性</p><p id="0961" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">4:功能丧失</p><p id="656b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">5:可能中立</p><p id="6aad" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">6:不确定</p><p id="ca87" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">7:功能增益</p><p id="a368" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">8:可能的功能转换</p><p id="8275" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">9:功能转换</p><h1 id="8f42" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">数据信息-</h1><p id="5e8c" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">数据收集自<a class="ae km" href="https://www.kaggle.com/c/msk-redefining-cancer-treatment#evaluation" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/MSK-重新定义-癌症-治疗#评测</a>。</p><p id="fc92" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">存在两个数据文件——一个包含关于基因突变的信息，另一个包含人类专家/病理学家用于分类基因突变的临床证据(文本)。</p><p id="e5bd" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这两个数据文件都有一个名为ID的公共列，可以在这个列上进行合并。</p><p id="8dd6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">每个文件的列-</p><p id="0385" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">文件1: training_variants (ID，Gene，Variations，Class)</p><p id="f4e4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">它的字段是</p><ul class=""><li id="e00b" class="kn ko hh in b io ip is it iw kp ja kq je kr ji ks kt ku kv bi translated"><strong class="in hi"> ID : </strong>用于将突变链接到临床证据的行的ID</li><li id="ab6f" class="kn ko hh in b io kw is kx iw ky ja kz je la ji ks kt ku kv bi translated"><strong class="in hi">基因:</strong>该基因突变所在的基因</li><li id="9331" class="kn ko hh in b io kw is kx iw ky ja kz je la ji ks kt ku kv bi translated"><strong class="in hi">变异:</strong>该突变的氨基酸变化</li><li id="0718" class="kn ko hh in b io kw is kx iw ky ja kz je la ji ks kt ku kv bi translated"><strong class="in hi">类别:</strong>1–9该基因突变被分类的类别</li></ul><p id="e727" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">文件2: training_text (ID，text)</p><figure class="lc ld le lf fd ii er es paragraph-image"><div class="er es lb"><img src="../Images/4be76c18bd209ad9c6672b39303bfabe.png" data-original-src="https://miro.medium.com/v2/resize:fit:814/format:webp/1*3jGSnL0BsihkdnJKb87APg.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">来自training_variants数据集的样本数据点</figcaption></figure><figure class="lc ld le lf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es lk"><img src="../Images/81852ce6a40df1749bc9e2cc259d5528.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tOhve8gThKdEWualuHFYFQ.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">来自training_text数据集的示例数据点。(当然，除了训练有素的病理学家，没有人能理解这一点！)</figcaption></figure><h1 id="abc5" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">业务限制-</h1><ul class=""><li id="e453" class="kn ko hh in b io kh is ki iw lp ja lq je lr ji ks kt ku kv bi translated">没有低延迟要求。(不需要像搜索引擎那样快速返回结果)</li><li id="ec6e" class="kn ko hh in b io kw is kx iw ky ja kz je la ji ks kt ku kv bi translated">可解释性是一个值得关注的问题。(病理学家需要验证模型预测特定类别的原因)</li><li id="477e" class="kn ko hh in b io kw is kx iw ky ja kz je la ji ks kt ku kv bi translated">错误可能会危及生命。</li><li id="91ed" class="kn ko hh in b io kw is kx iw ky ja kz je la ji ks kt ku kv bi translated">需要数据点属于每个类别的概率。(了解模型的置信度，决定是否进一步需要人体测试)。</li></ul><h1 id="cb09" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">机器学习问题的类型</h1><p id="9dbb" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">由于我们有9个类，这是一个多类分类问题。</p><h2 id="09bc" class="ls jk hh bd jl lt lu lv jp lw lx ly jt iw lz ma jx ja mb mc kb je md me kf mf bi translated">理想的绩效指标-</h2><p id="64de" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">多级对数损失</p><p id="4330" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">混淆矩阵</p><p id="2da5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">目标- </strong></p><p id="c5da" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">以预测每个数据点属于九个类别中的每一个的概率。</p><h1 id="0966" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">文本预处理-</h1><p id="dc54" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">如前所述，数据由两个CSV文件组成——一个用于变体，另一个用于文本。稍后将使用pd在一个公共ID列的基础上连接它们。merge()函数。</p><p id="7646" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">文本CSV文件不是用逗号分隔的，而是用||分隔的。这是通过在读取数据时使用分隔符='/|/| '来实现的。[/=转义字符]</p><p id="53d5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">使用NLTK库对文本数据进行预处理</p><ol class=""><li id="fda3" class="kn ko hh in b io ip is it iw kp ja kq je kr ji mg kt ku kv bi translated">任何特殊字符(除A-Z以外的字符(包括换行符)都被替换为单个空格字符。</li><li id="e514" class="kn ko hh in b io kw is kx iw ky ja kz je la ji mg kt ku kv bi translated">字母是小写的。</li><li id="31b7" class="kn ko hh in b io kw is kx iw ky ja kz je la ji mg kt ku kv bi translated">多个空格被一个空格取代。</li><li id="8ae9" class="kn ko hh in b io kw is kx iw ky ja kz je la ji mg kt ku kv bi translated">停用词移除。</li></ol><p id="77d0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们执行左外连接，因此我们一定会找到一些id，它们的文本字段将为空。这些文本字段由包含基因+' '+变异的字符串替换。</p><h1 id="da1e" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">数据分析-</h1><p id="6f36" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">训练-交叉验证-使用分层= y _标签以64:16:20的比例进行测试分割，以保持训练、cv、测试分割中的类别分布。</p><p id="35ee" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们绘制柱状图来显示每一部分中的类别分布。他们在每个阶层都有相似的百分比，因为这种划分是分层的。</p><figure class="lc ld le lf fd ii er es paragraph-image"><div class="er es mh"><img src="../Images/5c0a192886a1d3a28ba933aa73dc802e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1268/format:webp/1*dP5Fgx9X2gJG4zeYsXRjWw.png"/></div></figure><figure class="lc ld le lf fd ii er es paragraph-image"><div class="er es mi"><img src="../Images/0a3cacbf72dbaf35715de38a4c71f611.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/1*GfSeXP_RMktlBzt71MnKbA.png"/></div></figure><figure class="lc ld le lf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mj"><img src="../Images/adcb5670f63f3e035a38be5e8a7963de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1274/format:webp/1*DKyGzXyjRWHZtcy3aVxSDA.png"/></div></div></figure><p id="dedd" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">从上面的柱状图可以明显看出，数据集是不平衡的，类别7、4、1、2出现的频率更高。</p><h1 id="7079" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">随机模型-</h1><p id="d809" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">因为我们的KPI是可解释的对数损失，并且变化到无穷大，所以我们需要根据随机模型来判断我们的模型。</p><p id="cdec" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">对于交叉验证数据集和测试数据集中的每个数据点，我们使用np.random.rand(1，9)生成大小为9的数组，并将每个元素除以数组的总和，以便总概率达到1。</p><p id="b167" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在我们的例子中，随机模型生成的日志损失为2.5，作为基线。</p><p id="a50f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">绘制了随机模型的精度、召回和混淆矩阵。理想情况下，对角线元素应为1，非对角线元素应为0。</p><figure class="lc ld le lf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es mk"><img src="../Images/aaf05a97a00fae30ce609125d8b7743c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pDCbQRqyg7GDU5jtSW0T7g.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">随机模型的精度矩阵。注意，这里列sum=1，因为列在这里表示预测的类，precision定义了所有那些预测为k的类，实际上有多少是k</figcaption></figure><h1 id="808a" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">基因特征分析-</h1><p id="b1d8" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">使用value_counts()函数进行分类基因特征的单变量分析。有238种不同的基因，并绘制了它们的分布数量直方图。它显示了严重的偏态分布。</p><figure class="lc ld le lf fd ii er es paragraph-image"><div class="er es ml"><img src="../Images/0d8ca3d05db4bb9d71c6cbbb4aeef007.png" data-original-src="https://miro.medium.com/v2/resize:fit:1374/format:webp/1*rgvD4s3-LVtUSbTevcxbGQ.png"/></div></figure><h2 id="f5b2" class="ls jk hh bd jl lt lu lv jp lw lx ly jt iw lz ma jx ja mb mc kb je md me kf mf bi translated">编码基因特征-</h2><p id="8331" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">可以对分类特征进行两种类型的编码，一种是热编码，另一种是响应编码。</p><p id="b4c6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在one-hot-encoding中，每个特征由一个n维向量表示，其中n是该特征的唯一值的数量。同样在响应编码中，每个特征由n维向量表示，其中n是类别的数量。向量填充有基因特征属于9个类别之一的概率值(从整个数据集中捕获)。</p><p id="bb5a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">下面的代码用于构建所需的响应编码字典，其中关键字是分类变量，值是n(这里是9)维向量，每个向量对应于类别标签的概率。[学分:堆栈溢出]</p><pre class="lc ld le lf fd mm mn mo mp aw mq bi"><span id="14d8" class="ls jk hh mn b fi mr ms l mt mu">def get_gv_fea_dict(alpha, feature, df):</span><span id="b36a" class="ls jk hh mn b fi mv ms l mt mu"># value_count: it contains a dict like</span><span id="b8b5" class="ls jk hh mn b fi mv ms l mt mu"># print(train_df[‘Gene’].value_counts())</span><span id="d602" class="ls jk hh mn b fi mv ms l mt mu"># output:</span><span id="7362" class="ls jk hh mn b fi mv ms l mt mu"># {BRCA1 174</span><span id="94f6" class="ls jk hh mn b fi mv ms l mt mu"># TP53 106</span><span id="ce8d" class="ls jk hh mn b fi mv ms l mt mu"># EGFR 86</span><span id="7dc5" class="ls jk hh mn b fi mv ms l mt mu"># BRCA2 75</span><span id="6aa6" class="ls jk hh mn b fi mv ms l mt mu"># PTEN 69</span><span id="86bb" class="ls jk hh mn b fi mv ms l mt mu"># KIT 61</span><span id="3f62" class="ls jk hh mn b fi mv ms l mt mu"># BRAF 60</span><span id="a67b" class="ls jk hh mn b fi mv ms l mt mu"># ERBB2 47</span><span id="9af2" class="ls jk hh mn b fi mv ms l mt mu"># PDGFRA 46</span><span id="fb23" class="ls jk hh mn b fi mv ms l mt mu"># …}</span><span id="a4d8" class="ls jk hh mn b fi mv ms l mt mu"># print(train_df[‘Variation’].value_counts())</span><span id="544d" class="ls jk hh mn b fi mv ms l mt mu"># output:</span><span id="d4b8" class="ls jk hh mn b fi mv ms l mt mu"># {</span><span id="5fda" class="ls jk hh mn b fi mv ms l mt mu"># Truncating_Mutations 63</span><span id="d645" class="ls jk hh mn b fi mv ms l mt mu"># Deletion 43</span><span id="7d65" class="ls jk hh mn b fi mv ms l mt mu"># Amplification 43</span><span id="b9d8" class="ls jk hh mn b fi mv ms l mt mu"># Fusions 22</span><span id="fc31" class="ls jk hh mn b fi mv ms l mt mu"># Overexpression 3</span><span id="8d41" class="ls jk hh mn b fi mv ms l mt mu"># E17K 3</span><span id="82d1" class="ls jk hh mn b fi mv ms l mt mu"># Q61L 3</span><span id="f40d" class="ls jk hh mn b fi mv ms l mt mu"># S222D 2</span><span id="d110" class="ls jk hh mn b fi mv ms l mt mu"># P130S 2</span><span id="efa4" class="ls jk hh mn b fi mv ms l mt mu"># …</span><span id="8c41" class="ls jk hh mn b fi mv ms l mt mu"># }</span><span id="1a4d" class="ls jk hh mn b fi mv ms l mt mu">value_count = train_df[feature].value_counts()</span><span id="ed67" class="ls jk hh mn b fi mv ms l mt mu"># gv_dict : Gene Variation Dict, which contains the probability array for each gene/variation</span><span id="931c" class="ls jk hh mn b fi mv ms l mt mu">gv_dict = dict()</span><span id="d944" class="ls jk hh mn b fi mv ms l mt mu"># denominator will contain the number of time that particular feature occured in whole data</span><span id="ef6c" class="ls jk hh mn b fi mv ms l mt mu">for i, denominator in value_count.items():</span><span id="3e89" class="ls jk hh mn b fi mv ms l mt mu"># vec will contain (p(yi==1/Gi) probability of gene/variation belongs to perticular class</span><span id="8155" class="ls jk hh mn b fi mv ms l mt mu"># vec is 9 diamensional vector</span><span id="ee1b" class="ls jk hh mn b fi mv ms l mt mu">vec = []</span><span id="35cf" class="ls jk hh mn b fi mv ms l mt mu">for k in range(1,10):</span><span id="454e" class="ls jk hh mn b fi mv ms l mt mu"># print(train_df.loc[(train_df[‘Class’]==1) &amp; (train_df[‘Gene’]==’BRCA1')])</span><span id="2817" class="ls jk hh mn b fi mv ms l mt mu"># ID Gene Variation Class</span><span id="5983" class="ls jk hh mn b fi mv ms l mt mu"># 2470 2470 BRCA1 S1715C 1</span><span id="3af7" class="ls jk hh mn b fi mv ms l mt mu"># 2486 2486 BRCA1 S1841R 1</span><span id="b3b1" class="ls jk hh mn b fi mv ms l mt mu"># 2614 2614 BRCA1 M1R 1</span><span id="42b4" class="ls jk hh mn b fi mv ms l mt mu"># 2432 2432 BRCA1 L1657P 1</span><span id="dd8e" class="ls jk hh mn b fi mv ms l mt mu"># 2567 2567 BRCA1 T1685A 1</span><span id="db27" class="ls jk hh mn b fi mv ms l mt mu"># 2583 2583 BRCA1 E1660G 1</span><span id="2a71" class="ls jk hh mn b fi mv ms l mt mu"># 2634 2634 BRCA1 W1718L 1</span><span id="196b" class="ls jk hh mn b fi mv ms l mt mu"># cls_cnt.shape[0] will return the number of rows</span><span id="060f" class="ls jk hh mn b fi mv ms l mt mu">cls_cnt = train_df.loc[(train_df[‘Class’]==k) &amp; (train_df[feature]==i)]</span><span id="e6f0" class="ls jk hh mn b fi mv ms l mt mu"># cls_cnt.shape[0](numerator) will contain the number of time that particular feature occured in whole data</span><span id="e0c9" class="ls jk hh mn b fi mv ms l mt mu">vec.append((cls_cnt.shape[0] + alpha*10)/ (denominator + 90*alpha))</span><span id="b5ae" class="ls jk hh mn b fi mv ms l mt mu"># we are adding the gene/variation to the dict as key and vec as value</span><span id="abb7" class="ls jk hh mn b fi mv ms l mt mu">gv_dict[i]=vec</span><span id="7f74" class="ls jk hh mn b fi mv ms l mt mu">return gv_dict</span></pre><p id="2f2e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请注意拉普拉斯(加法)平滑也是如何执行的。这样做是为了确保非常小的值得到很好的处理，并且模型不会过度拟合。</p><blockquote class="mw mx my"><p id="f33e" class="il im mz in b io ip iq ir is it iu iv na ix iy iz nb jb jc jd nc jf jg jh ji ha bi translated">考虑特征“基因”的值“x”:</p><p id="a6f8" class="il im mz in b io ip iq ir is it iu iv na ix iy iz nb jb jc jd nc jf jg jh ji ha bi translated">对应于“x”的向量的第一个元素=(数据点属于类1的“x”出现的次数+ 10*alpha /总数据中“x”出现的次数+n * alpha)[其中n是类标签的数量，alpha是超参数]</p></blockquote><p id="c751" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">获取我们数据集的响应编码矩阵的代码-</p><pre class="lc ld le lf fd mm mn mo mp aw mq bi"><span id="519e" class="ls jk hh mn b fi mr ms l mt mu"># Get Gene variation feature</span><span id="0191" class="ls jk hh mn b fi mv ms l mt mu">def get_gv_feature(alpha, feature, df):</span><span id="7521" class="ls jk hh mn b fi mv ms l mt mu"># print(gv_dict)</span><span id="22b3" class="ls jk hh mn b fi mv ms l mt mu">#     {'BRCA1': [0.20075757575757575, 0.03787878787878788, 0.068181818181818177, 0.13636363636363635, 0.25, 0.19318181818181818, 0.03787878787878788, 0.03787878787878788, 0.03787878787878788],</span><span id="3e25" class="ls jk hh mn b fi mv ms l mt mu">#      'TP53': [0.32142857142857145, 0.061224489795918366, 0.061224489795918366, 0.27040816326530615, 0.061224489795918366, 0.066326530612244902, 0.051020408163265307, 0.051020408163265307, 0.056122448979591837],</span><span id="e71e" class="ls jk hh mn b fi mv ms l mt mu">#      'EGFR': [0.056818181818181816, 0.21590909090909091, 0.0625, 0.068181818181818177, 0.068181818181818177, 0.0625, 0.34659090909090912, 0.0625, 0.056818181818181816],</span><span id="0904" class="ls jk hh mn b fi mv ms l mt mu">#      'BRCA2': [0.13333333333333333, 0.060606060606060608, 0.060606060606060608, 0.078787878787878782, 0.1393939393939394, 0.34545454545454546, 0.060606060606060608, 0.060606060606060608, 0.060606060606060608],</span><span id="2503" class="ls jk hh mn b fi mv ms l mt mu">#      'PTEN': [0.069182389937106917, 0.062893081761006289, 0.069182389937106917, 0.46540880503144655, 0.075471698113207544, 0.062893081761006289, 0.069182389937106917, 0.062893081761006289, 0.062893081761006289],</span><span id="68de" class="ls jk hh mn b fi mv ms l mt mu">#      'KIT': [0.066225165562913912, 0.25165562913907286, 0.072847682119205295, 0.072847682119205295, 0.066225165562913912, 0.066225165562913912, 0.27152317880794702, 0.066225165562913912, 0.066225165562913912],</span><span id="14ee" class="ls jk hh mn b fi mv ms l mt mu">#      'BRAF': [0.066666666666666666, 0.17999999999999999, 0.073333333333333334, 0.073333333333333334, 0.093333333333333338, 0.080000000000000002, 0.29999999999999999, 0.066666666666666666, 0.066666666666666666],</span><span id="34f6" class="ls jk hh mn b fi mv ms l mt mu">#      ...</span><span id="b0fd" class="ls jk hh mn b fi mv ms l mt mu">#     }</span><span id="f7aa" class="ls jk hh mn b fi mv ms l mt mu">gv_dict = get_gv_fea_dict(alpha, feature, df)</span><span id="5b9a" class="ls jk hh mn b fi mv ms l mt mu"># value_count is similar in get_gv_fea_dict</span><span id="019d" class="ls jk hh mn b fi mv ms l mt mu">value_count = train_df[feature].value_counts()</span><span id="6faa" class="ls jk hh mn b fi mv ms l mt mu"># gv_fea: Gene_variation feature, it will contain the feature for each feature prob dist value in the data</span><span id="16a7" class="ls jk hh mn b fi mv ms l mt mu">gv_fea = []</span><span id="54a2" class="ls jk hh mn b fi mv ms l mt mu"># for every feature values in the given data frame we will check if it is there in the train data then we will add the feature to gv_fea</span><span id="8ee2" class="ls jk hh mn b fi mv ms l mt mu"># if not we will add [1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9] to gv_fea</span><span id="919e" class="ls jk hh mn b fi mv ms l mt mu">for index, row in df.iterrows():</span><span id="58ca" class="ls jk hh mn b fi mv ms l mt mu">if row[feature] in dict(value_count).keys():</span><span id="21e3" class="ls jk hh mn b fi mv ms l mt mu">gv_fea.append(gv_dict[row[feature]])</span><span id="18dd" class="ls jk hh mn b fi mv ms l mt mu">else:</span><span id="43e2" class="ls jk hh mn b fi mv ms l mt mu">gv_fea.append([1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9])</span><span id="2ec1" class="ls jk hh mn b fi mv ms l mt mu">#             gv_fea.append([-1,-1,-1,-1,-1,-1,-1,-1,-1])</span><span id="c3e7" class="ls jk hh mn b fi mv ms l mt mu">return gv_fea</span><span id="ac1e" class="ls jk hh mn b fi mv ms l mt mu"># Get Gene variation feature</span><span id="5950" class="ls jk hh mn b fi mv ms l mt mu">def get_gv_feature(alpha, feature, df):</span><span id="dae1" class="ls jk hh mn b fi mv ms l mt mu"># print(gv_dict)</span><span id="d1ee" class="ls jk hh mn b fi mv ms l mt mu">#     {'BRCA1': [0.20075757575757575, 0.03787878787878788, 0.068181818181818177, 0.13636363636363635, 0.25, 0.19318181818181818, 0.03787878787878788, 0.03787878787878788, 0.03787878787878788],</span><span id="d3bf" class="ls jk hh mn b fi mv ms l mt mu">#      'TP53': [0.32142857142857145, 0.061224489795918366, 0.061224489795918366, 0.27040816326530615, 0.061224489795918366, 0.066326530612244902, 0.051020408163265307, 0.051020408163265307, 0.056122448979591837],</span><span id="3c38" class="ls jk hh mn b fi mv ms l mt mu">#      'EGFR': [0.056818181818181816, 0.21590909090909091, 0.0625, 0.068181818181818177, 0.068181818181818177, 0.0625, 0.34659090909090912, 0.0625, 0.056818181818181816],</span><span id="3b3b" class="ls jk hh mn b fi mv ms l mt mu">#      'BRCA2': [0.13333333333333333, 0.060606060606060608, 0.060606060606060608, 0.078787878787878782, 0.1393939393939394, 0.34545454545454546, 0.060606060606060608, 0.060606060606060608, 0.060606060606060608],</span><span id="8734" class="ls jk hh mn b fi mv ms l mt mu">#      'PTEN': [0.069182389937106917, 0.062893081761006289, 0.069182389937106917, 0.46540880503144655, 0.075471698113207544, 0.062893081761006289, 0.069182389937106917, 0.062893081761006289, 0.062893081761006289],</span><span id="dbfb" class="ls jk hh mn b fi mv ms l mt mu">#      'KIT': [0.066225165562913912, 0.25165562913907286, 0.072847682119205295, 0.072847682119205295, 0.066225165562913912, 0.066225165562913912, 0.27152317880794702, 0.066225165562913912, 0.066225165562913912],</span><span id="7c9a" class="ls jk hh mn b fi mv ms l mt mu">#      'BRAF': [0.066666666666666666, 0.17999999999999999, 0.073333333333333334, 0.073333333333333334, 0.093333333333333338, 0.080000000000000002, 0.29999999999999999, 0.066666666666666666, 0.066666666666666666],</span><span id="9163" class="ls jk hh mn b fi mv ms l mt mu">#      ...</span><span id="d075" class="ls jk hh mn b fi mv ms l mt mu">#     }</span><span id="f9cc" class="ls jk hh mn b fi mv ms l mt mu">gv_dict = get_gv_fea_dict(alpha, feature, df)</span><span id="1138" class="ls jk hh mn b fi mv ms l mt mu"># value_count is similar in get_gv_fea_dict</span><span id="40b1" class="ls jk hh mn b fi mv ms l mt mu">value_count = train_df[feature].value_counts()</span><span id="58c2" class="ls jk hh mn b fi mv ms l mt mu"># gv_fea: Gene_variation feature, it will contain the feature for each feature prob dist value in the data</span><span id="a8d3" class="ls jk hh mn b fi mv ms l mt mu">gv_fea = []</span><span id="9902" class="ls jk hh mn b fi mv ms l mt mu"># for every feature values in the given data frame we will check if it is there in the train data then we will add the feature to gv_fea</span><span id="2599" class="ls jk hh mn b fi mv ms l mt mu"># if not we will add [1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9] to gv_fea</span><span id="d099" class="ls jk hh mn b fi mv ms l mt mu">for index, row in df.iterrows():</span><span id="0dc5" class="ls jk hh mn b fi mv ms l mt mu">if row[feature] in dict(value_count).keys():</span><span id="1dd6" class="ls jk hh mn b fi mv ms l mt mu">gv_fea.append(gv_dict[row[feature]])</span><span id="e433" class="ls jk hh mn b fi mv ms l mt mu">else:</span><span id="7a0c" class="ls jk hh mn b fi mv ms l mt mu">gv_fea.append([1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9])</span><span id="c61b" class="ls jk hh mn b fi mv ms l mt mu">#             gv_fea.append([-1,-1,-1,-1,-1,-1,-1,-1,-1])</span><span id="5d26" class="ls jk hh mn b fi mv ms l mt mu">return gv_fea</span></pre><p id="ac82" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">简单的一键编码适用于逻辑回归、线性SVM，而响应编码适用于朴素贝叶斯、随机森林等。这是因为线性模型可以比集合/森林模型更好地处理大维度。</p><p id="3654" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们需要推断基因特征有多有用。为此，仅使用基因特征作为属性建立模型，并检查对数损失是否小于2.5。</p><p id="33d9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">首先，SGD分类器(具有“对数”损失和l2正则化以及h-param调整)被用于一键编码的基因特征。除此之外，还使用了经过校准的分类器。这实质上实现了逻辑回归</p><p id="6943" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">使用网格搜索进行超参数调谐，并测量相应的训练、cv、测试日志损失。它比随机模型更好，并且不会过度拟合。因此，我们的基因特征非常有用。</p><p id="45b8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们必须检查基因特征是否稳定。稳定特征是其值在训练集、CV集和测试集之间有显著重叠的特征。如果不是这样，ML模型是不可能建立的。</p><p id="df46" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">计算训练、cv和测试日志损失。没有过度拟合意味着特征稳定。此外，我们观察到cv和测试数据中的大多数(90%以上)基因特征也存在于训练数据中。因此基因特征是稳定的。</p><h1 id="4777" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">变异特征分析-</h1><p id="d4bd" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">接下来，分析分类特征变化。</p><p id="3705" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为variation.value_counts()绘制的直方图显示了极度扭曲的数据。大多数值只出现一次！</p><figure class="lc ld le lf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es nd"><img src="../Images/157e83f574f3ab72c380f9d5be2cc9ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1344/format:webp/1*O0SrJVwghMKbJIIEzQfaxw.png"/></div></div></figure><p id="e14a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">CDF显示一个线性图。这意味着大多数特性的值计数都是1。</p><p id="1fcf" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，完成了一次热编码，然后是逻辑回归+校准CV。执行alpha的超参数调整。然而，可以看出，该模型确实过拟合，这是由特征不稳定性引起的。</p><p id="c310" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">集合中仅包含测试和cv df中约10%的变化点(训练df[变化])。因此，变化特征虽然有用，但并不稳定。</p><h1 id="4697" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">文本特征分析-</h1><p id="e757" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">现在，分析文本特征。也提出了同样的问题，</p><p id="c428" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在训练数据中有多少独特的单词？</p><p id="6fb3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">词频是如何分布的？</p><p id="946d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如何特征化文本字段？</p><p id="d854" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">文本特征在预测y_i中有用吗？</p><p id="7f83" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">文本特征在训练、测试和CV数据集中是否稳定？</p><p id="fab9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在训练逻辑回归+校正CV上，具有最优超参数的训练对数损失是好的。该模型没有真正过拟合，表明文本特征是稳定的。</p><figure class="lc ld le lf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es ne"><img src="../Images/c918526b7efac7bdb87e71e39e996cf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mj4a3GGPQDz4FgTUpX7Y1w.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">我们所有功能的度量比较</figcaption></figure><p id="3c68" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，我们的特征重要性是文本&gt;基因&gt;变异。这是从cv和测试数据测井损失值中推导出来的。</p><p id="eb14" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">测试数据中出现的95%以上的单词也出现在集合(训练数据)中。因此文本特征也是稳定的。</p><h1 id="a3ad" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">模特-</h1><p id="a462" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">接下来，我们进行适当的ML建模。</p><p id="b371" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">一键基因、变异、文本特征被水平堆叠并转换成csr矩阵。反应编码基因、文本、特征也是如此。</p><h2 id="292a" class="ls jk hh bd jl lt lu lv jp lw lx ly jt iw lz ma jx ja mb mc kb je md me kf mf bi translated">单热编码特征是55517维的，而响应编码仅仅是27维的。因此，一次性特征适合逻辑回归、线性SVM模型，而响应编码更适合KNN、Boosting、随机森林、决策树等。</h2><h2 id="5d62" class="ls jk hh bd jl lt lu lv jp lw lx ly jt iw lz ma jx ja mb mc kb je md me kf mf bi translated">具有一个热编码特征的多项式朴素贝叶斯</h2><p id="3192" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">水平堆叠的特征被馈入多项式朴素贝叶斯分类器+具有网格搜索的超参数调谐的校准分类器。</p><p id="9a13" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">测试日志损失不如仅使用文本特征的LR模型。此外，从精度和召回矩阵来看，该模型在构成大多数数据点的2-7和1-4类之间变得混乱。</p><p id="a928" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">根据业务需求，对于来自测试数据的特定查询点，使用predict_proba()来预测预测的标签和类的概率。</p><p id="ebf7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请注意，每当需要输出概率时，总是建议在基本学习器上使用校准的分类器，因为它校准概率值以匹配每个类的概率的预期分布。输出概率与预期的类别概率相差很大，尤其是在复杂的非线性模型的情况下。</p><h1 id="3bd8" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">具有响应编码特征的KNN分类器</h1><p id="8515" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">接下来，尝试具有响应编码特征的KNN。该模型的性能优于以前的朴素贝叶斯分类器。然而，在大多数班级2-7，1-4中仍然会出现混乱。但是少数类的性能(对数损失)更好。</p><p id="1f4f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了KNN的可解释性，使用model.kneighbours()函数来获得最近n个邻居的类。</p><h1 id="428b" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">具有类平衡和一个热点特征的逻辑回归</h1><p id="744f" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">接下来，SGD classifier(loss = ' log ' and class = ' balanced ')用于独热编码特征。这个模型给出了到目前为止最低的对数损失值。从混淆矩阵，我们观察到低密度类8，9也有好的结果。使用类平衡功能对类进行过采样。因此，平衡有助于提高少数类的精确度和召回率。</p><figure class="lc ld le lf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ll lm di ln bf lo"><div class="er es nf"><img src="../Images/2981588953f2cd05de4eb38f44991ea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GR5hxC9lzKogsWOzeeJ__A.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">类别平衡逻辑回归的回忆矩阵</figcaption></figure><h1 id="7740" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">线性SVM分类器，具有类平衡和一个热点特征</h1><p id="e604" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">接下来，实现一个SGDClassifier(loss='hinge '，class='balanced ')。准确性低于逻辑回归模型，但其他指标与LR的LinearSVM相当。</p><h1 id="7a4f" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">具有一键和响应编码特征的随机森林分类器-</h1><p id="8a2e" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">用超参数作为估计器的数目和树的最大深度来训练具有一热编码和响应编码的随机森林。对于这个模型，少数类的精度和召回率是1或接近1。然而，大多数类并没有被很好地分类。</p><p id="1568" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">响应编码过拟合的随机森林具有最高的对数损失。</p><h1 id="4ccf" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">堆积分类器-</h1><p id="3320" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">使用MLXtend库，现在尝试堆叠分类器。基础学习者逻辑回归、线性支持向量机和朴素贝叶斯分类器的概率输出被传递到最终的元分类器逻辑回归模型。</p><p id="f67f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">然而，堆叠模型面临可解释性的问题，并且训练数据在基本模型之间被分割。因此，单个模型的误差会增加。</p><p id="a336" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因此，在数据点较少的情况下，叠加不是最佳的。</p><p id="875c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">接下来，还使用了投票=“软”(即获取基础模型的概率输出)的多数投票分类器。</p><h1 id="6784" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated"><strong class="ak">部署- </strong></h1><p id="1de3" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">使用Flask开发了一个网页，并部署在Heroku上进行实时预测。不幸的是，Heroku突然停止了自由层。</p><p id="11b9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">网页运行的视频可以在GitHub项目链接上找到:</p><p id="abe4" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">https://github.com/Debadri3/Personalized-Cancer-Diagnosis<a class="ae km" href="https://github.com/Debadri3/Personalized-Cancer-Diagnosis" rel="noopener ugc nofollow" target="_blank"/></p><p id="b8c0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果你觉得这个项目有用，请慷慨鼓掌，并跟随我在媒体:【https://medium.com/@debadri3】T4。会真正帮助像我这样的崭露头角的作者！</p></div></div>    
</body>
</html>