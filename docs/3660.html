<html>
<head>
<title>Implementation of k-NN &amp; Machine Learning to Build Document Classification System in R</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实现k-NN和机器学习构建R语言文档分类系统</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/implementation-of-k-nn-machine-learning-to-build-document-classification-system-in-r-10e28e56c657?source=collection_archive---------3-----------------------#2021-07-16">https://medium.com/analytics-vidhya/implementation-of-k-nn-machine-learning-to-build-document-classification-system-in-r-10e28e56c657?source=collection_archive---------3-----------------------#2021-07-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/704ba3ee9f3ed3757667dd3d826ae8be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8F0rX1YutUXcckkuVTTEnQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">资料来源:多中心AX</figcaption></figure><p id="d277" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="jr">各位数据爱好者好！</em>T3】</strong></p><p id="940c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">前几天，当我在YouTube上寻找关于k-NN的有趣话题时，我看到了Tim D'Auria的一个很酷的教程，题为“</em> <a class="ae js" href="https://www.youtube.com/watch?v=j1V2McKbkLo" rel="noopener ugc nofollow" target="_blank"> <strong class="iv hi"> <em class="jr">如何用R语言构建一个文本挖掘、机器学习文档分类系统！</em> </strong> </a> <em class="jr">“就在那时，我决定把它付诸实践！</em></p><p id="62af" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">这次我们将尝试实现K-Nearest neighborhood(K-NN)算法和机器学习，在R/RStudio中构建一个文档分类系统。首先，让我们与这项技术结合起来！</em></p><h1 id="3c3b" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><em class="kr">k-最近邻(k-NN) </em></h1><p id="bbcb" class="pw-post-body-paragraph it iu hh iv b iw ks iy iz ja kt jc jd je ku jg jh ji kv jk jl jm kw jo jp jq ha bi translated"><em class="jr">k-最近邻算法是一种监督学习算法，其中新实例的结果根据大多数k-最近邻类别进行分类。该算法的目的是根据训练数据的属性和样本对新对象进行分类。k-最近邻算法使用邻域分类作为新实例值的预测值。</em></p><p id="eec3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">例如，假设我的数据集中有20名青少年的尺寸，那么我需要确定哪件衣服最适合他们。他们的学校只想要3种不同的尺寸，它们是小号(S)，中号(M)和大号(L)。所说的尺寸是身高和体重，然后我根据他们的尺寸将这些青少年分为3组。两天后，我发现一名青少年在测量时迟到了，现在我需要在不破坏现有数据的情况下将他归入其中一组。在这里，我可以使用k-NN来找到他在身体测量方面最近的邻居。</p><p id="c79c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">k-NN有3个步骤:(1)首先，我们必须确定我们将要计数的邻居的数量(k)，(2)计算每个邻居到对象的距离，然后按距离对结果排序，从最小到最大，(3)取(k)个最近的邻居，然后我们看每个邻居是否都包含在分类中。</em></p><p id="549f" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">在确定k的值时，</em> <strong class="iv hi"> <em class="jr">如果我们的分类数是偶数</em> </strong> <em class="jr">那么我们应该使用k的奇数值</em><strong class="iv hi"><em class="jr"/></strong><em class="jr">，而i </em> <strong class="iv hi"> <em class="jr"> f我们的分类数是奇数</em> </strong> <em class="jr">那么我们应该使用k的偶数值</em>  <em class="jr"/></p><h1 id="b467" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">机器学习</h1><p id="1196" class="pw-post-body-paragraph it iu hh iv b iw ks iy iz ja kt jc jd je ku jg jh ji kv jk jl jm kw jo jp jq ha bi translated">机器学习(ML)技术是一种被开发成能够在没有用户指导的情况下自我学习的机器。机器学习是基于统计、数学和数据挖掘等其他学科发展起来的，因此机器可以通过分析数据进行学习，而无需重新编程或排序。</p><p id="320e" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">在这种情况下，机器学习有能力用自己的命令获取现有数据。ML还可以研究现有的数据和它获得的数据，以便它可以执行某些任务。ML能做的任务也很多样，看他学什么。</em></p><p id="a667" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">A.监督学习</p><p id="9eb7" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">监督学习技术(Supervised learning technique)是一种可以应用于机器学习的技术，它可以通过给定某些标签来接收已经存在于数据中的信息。人们希望这种技术能为通过比较过去的学习经验而得出的结果提供一个目标。</em></p><p id="0969" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">B.无监督学习</p><p id="820c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">无监督学习技术是可以应用于机器学习的技术，这些机器学习用于没有可以直接应用的信息的数据。预计这种技术可以帮助发现未标记数据中隐藏的结构或模式。这与监督学习略有不同，因为你事先没有任何数据作为参考。</em></p><h1 id="2244" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">实现k-NN和机器学习构建文档分类系统</h1><p id="6879" class="pw-post-body-paragraph it iu hh iv b iw ks iy iz ja kt jc jd je ku jg jh ji kv jk jl jm kw jo jp jq ha bi translated"><em class="jr">现在我们已经掌握了k-NN &amp; ML的初步思路，让我们进入正题吧！我们要输入文档，建立系统，分类/预测文档属于谁(作者姓名)。通过识别文档的模式，该系统有望识别未标记的总统竞选演讲的发言者。</em></p><p id="572c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">答:我们要用巴拉克·欧巴马&amp;米特·罗姆尼的演讲作为我要分类的文件。您可以在此处获取演讲稿:  <a class="ae js" href="http://obamaspeeches.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="iv hi"> <em class="jr">奥巴马</em> </strong> </a> <strong class="iv hi"> <em class="jr">，</em> </strong> <a class="ae js" href="https://s3.documentcloud.org/documents/6768911/Romney-RemarksPreparedForDelivery.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iv hi"> <em class="jr">罗姆尼1 </em> </strong> </a> <strong class="iv hi">，</strong> <a class="ae js" href="https://www.pri.org/stories/2012-01-11/mitt-romney-new-hampshire-primary-victory-speech" rel="noopener ugc nofollow" target="_blank"> <strong class="iv hi"> <em class="jr">罗姆尼2</em></strong><strong class="iv hi"><em class="jr">(您也可以添加/替换其他候选人已有的演讲稿)。我们会把演讲内容复制到我的记事本上，然后以文本形式保存下来。txt)格式。</em>T41】</strong></a></p><p id="58c3" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">b .为每个脚本创建一个目录，并将它们存储到两个不同的文件夹中(一个给奥巴马&amp;一个给罗姆尼)。下面是我得到的:T3】</p><figure class="ky kz la lb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kx"><img src="../Images/67f9eb557139b85d83388d593e19941b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uLJnXX8l-seoPHb1UIWAug.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">示例:记事本显示“ObamaSpeeches1.txt”</figcaption></figure><figure class="ky kz la lb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kx"><img src="../Images/fd14173d124fa04f4de5baec15877e2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lP7-A0dzSlgrStqyU8lXyA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">例子:在奥巴马的文件夹里</figcaption></figure><figure class="ky kz la lb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kx"><img src="../Images/4eaba47d55992a08ed0b7ca24239657e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qDi487m-Q37DWUey3XcdSg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">例如:罗姆尼的文件夹</figcaption></figure><figure class="ky kz la lb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kx"><img src="../Images/7ae530fd9596882c59fbdbc649b91d0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VjxOSgqKfAqjWDJOUPkP0Q.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">文件夹的示例</figcaption></figure><p id="31bf" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">初始化我们的环境。我们需要向系统提供我们将要使用的库或目录的信息。从“tm”、“plyr”和“class”加载我们想要使用的库</p><p id="81f9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">库“tm”来自R的一个同名包，tm本身代表</em> <a class="ae js" href="https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iv hi"> <em class="jr">文本挖掘</em> </strong> </a> <strong class="iv hi"> <em class="jr">。</em></strong><em class="jr">TM中管理文档的主要结构是所谓的语料库，代表文本文档的集合。语料库是一个抽象的概念，可以同时存在多个实现。库“plyr”来自于</em><a class="ae js" href="https://cran.r-project.org/web/packages/plyr/plyr.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="iv hi"><em class="jr">PLYR</em></strong></a><em class="jr">包。这是一套解决一系列常见问题的工具:<em class="jr">你需要将一个大问题分解成可管理的部分，对每一部分进行操作，然后将所有部分重新组合在一起。然后，我们还需要激活“</em> <a class="ae js" href="https://cran.r-project.org/web/packages/class/class.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="iv hi"> <em class="jr">类</em> </strong> </a> <em class="jr">”库，该库包含用于分类的各种函数，包括k近邻、学习矢量量化和自组织映射。</em></em></p><blockquote class="lc ld le"><p id="5bde" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated"># initialize environment<br/>libs = c(" TM "，" plyr "，" class") <br/> lapply(libs，require，character.only = TRUE)</p></blockquote><p id="d21a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> d. <em class="jr">当你把文本数据读入R时，它偶尔会把它从文本/字符串/字符转换成名义/分类变量。我们不希望这种情况在这里发生，我们要保持现状。于是我们设置了参数“string as factors”</em>。</strong></p><blockquote class="lc ld le"><p id="498e" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#set options <br/>选项(stringsAsFactors = FALSE)</p></blockquote><p id="315d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">继续，让我们指定我们之前创建的目录的名称以及到达那里的路径。T50】</p><blockquote class="lc ld le"><p id="a9d9" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#设置参数<br/>候选人= c(“罗姆尼”、“奥巴马”)</p><p id="516d" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#获取我们目录的路径示例<br/>pathname = " D:/Ahsana ' s Archive/Peng antar DATA MINING/Text MINING&amp;class ification "</p></blockquote><p id="27ce" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> f. <em class="jr">然后我们会清理文字，因为发短信本来就很“脏”。为了让系统很好地运行，很多东西需要被“清理”。因为我们有两个候选人(奥巴马&amp;罗姆尼)，不妨做一个函数，这样它可以适用于几个候选人。</em>T3】</strong></p><p id="b401" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="jr">这个函数从我们所有的目录中提取所有的演讲，并将它们合并到每个语料库的一个候选中。</em> </strong></p><blockquote class="lc ld le"><p id="9bc4" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated"># clean text function<br/>clean corpus = function(corpus){ # pass in corpus<br/>corpus . tmp = TM _ map(corpus，remove punctuations删除标点符号<br/>corpus . tmp = TM _ map(corpus . tmp，strip white space)#删除空格<br/>corpus . tmp = TM _ map(corpus . tmp，content _ transformer(to lower))#小写</p><p id="3cd1" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#去掉没有太大意义的演讲部分<br/>corpus . tmp = TM _ map(corpus . tmp，removeWords，stopwords("english "))</p><p id="1a81" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#给出结果<br/>返回(corpus.tmp) <br/> }</p></blockquote><p id="aab8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> g. <em class="jr">当我们清理完文本后，我们将构建一个术语文档矩阵(TDM)，这个东西可以神奇地将文本转换成定量格式(我们可以分析它！)</em> </strong></p><blockquote class="lc ld le"><p id="a81b" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated"># build TDM<br/>generate TDM = function(cand，path){<br/>s . dir = sprintf(" % s/% s "，path，cand)# print to variables together<br/>s . cor = VCorpus(DirSource(directory = s . dir)，reader control = list(reader = read plain))<br/>s . cor . cl = clean Corpus(s . cor)#对corpus应用清理函数<br/>s . TDM = TermDocumentMatrix(s . cor . cl)</p><p id="8f0b" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#设置一个可接受的稀疏级别，并删除剩余的内容<br/>s . TDM = removeSparseTerms(s . TDM，0.7) <br/> result = list(name = cand，tdm = s.tdm) <br/> }</p><p id="7929" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">tdm = lapply(候选项，生成项dm，路径=路径名)</p></blockquote><p id="071c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">将每位候选人的名字附在TDM上。 </p><blockquote class="lc ld le"><p id="b096" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated"># attach name<br/>bindcindicadatetodtm = function(TDM){</p><p id="9e7c" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#将TDM转换为数字，每个语音为一行，每个术语为一列<br/>s . mat = t(data . matrix(TDM[[" TDM "]]))</p><p id="119f" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#将矩阵转换为数据帧<br/> s.df = as.data.frame(s.mat，stringsas factors = FALSE)<br/><br/>s . df = cbind(s . df，rep(tdm[["name"]]，nrow(s . df)))<br/>colnames(s . df)[ncol(s . df)]= " target candidate "<br/>return(s . df)<br/>}</p><p id="51d3" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">candTDM = lapply(tdm，bindccandidatetodtm)<br/>str(cand TDM)</p></blockquote><figure class="ky kz la lb fd ii er es paragraph-image"><div class="er es li"><img src="../Images/788bf5f6874e37bf9fee86f584e79d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:878/format:webp/1*Hb3QCvO03jp6v0igzyjsXA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">str(时分复用)</figcaption></figure><p id="22d9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们在这里看到的是每个术语的结构列表，它们在哪里，重复了多少次。</p><p id="aba9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> i. <em class="jr">将之前的矩阵堆叠在另一个之上，因为我们要将它们一次性放入我们的模型中。</em>T45】</strong></p><blockquote class="lc ld le"><p id="6753" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated"># stack<br/>TDM . stack = do . call(r bind . fill，candTDM)</p><p id="b58d" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#替换NA或将NA设置为零<br/>TDM . stack[is . NA(TDM . stack)]= 0<br/>head(TDM . stack)</p></blockquote><figure class="ky kz la lb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lj"><img src="../Images/263b648b659219023bbff50e57f5eb7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rexbZ1dJP0k6LVPAlc6yCA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">TDM.stack中的几个热门词汇</figcaption></figure><blockquote class="lc ld le"><p id="7230" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">nrow(tdm堆栈)<br/> ncol(tdm堆栈)</p></blockquote><figure class="ky kz la lb fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/81657b2b691d44bd65bc262b5383f9c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*pAZRTYUGYwtX-gVPd45RsA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">TDM.stack的行数和列数</figcaption></figure><p id="b544" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">因此，现在我们知道我们总共有12篇演讲，共有552个术语。</p><p id="1df0" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> j. <em class="jr">接下来，我们将创建一个保留样本。保留样本是来自数据集的随机样本，它被保留并且不用于模型拟合过程。在模型拟合到主要数据(“训练”数据)之后，它被应用到拒不接受的样本。这就对模型应用于新数据时的表现给出了一个公正的评估。</em> </strong></p><ul class=""><li id="8aa4" class="ll lm hh iv b iw ix ja jb je ln ji lo jm lp jq lq lr ls lt bi translated"><strong class="iv hi"> <em class="jr">注意:</em> </strong> <em class="jr"> </em> <strong class="iv hi"> <em class="jr">您实际上可以更改您希望包含在训练集中的行的百分比。列车组:测试组的常见组合为70% : 30%、80% : 20%或75% : 25%。对我来说，我将它设置为75%(稍后我会解释为什么)</em> </strong></li></ul><blockquote class="lc ld le"><p id="1401" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#拒绝</p><p id="8985" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#我们取75%的行来训练模型<br/>train . idx = sample(nrow(TDM . stack)，ceiling(nrow(TDM . stack)* 0.75))<br/>test . idx =(1:nrow(TDM . stack))[-train . idx]</p><p id="f17c" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">头(train.idx) <br/>头(test.idx)</p></blockquote><p id="c552" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> k. <em class="jr">建立k-NN模型。</em> </strong></p><blockquote class="lc ld le"><p id="cac7" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#k-NN模型<br/> tdm.cand = tdm.stack[，" target candidate "]<br/>TDM . stack . nl = TDM . stack[，！% "targetcandidate"]中的colnames(TDM . stack)%值</p><p id="5087" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">KNN . pred = KNN(TDM . stack . nl[train . idx，]，tdm.stack.nl[test.idx，]，<br/> tdm.cand[train.idx])</p></blockquote><p id="77ea" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了提高我们模型预测的准确性，我们建立了一个混淆矩阵。它基本上是一个矩阵，显示了我们的模型如何预测测试集与进行演讲的实际候选人。T29】</p><blockquote class="lc ld le"><p id="dbc5" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#准确性</p><p id="6a3f" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">#混淆矩阵，由预测结果和实际候选者组成<br/>conf . mat = table(" Predictions " = KNN . pred，Actual = TDM . cand[test . idx])<br/>conf . mat</p><p id="c022" class="it iu jr iv b iw ix iy iz ja jb jc jd lf jf jg jh lg jj jk jl lh jn jo jp jq ha bi translated">(精确度=总和(诊断(确认材料))/长度(测试. idx)*100)</p></blockquote><figure class="ky kz la lb fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/1b3b03eb137c51d4e817e1242bba3a04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*jBKQRB6Zghg6CwhMnggy1A.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">混淆矩阵的输出与模型的准确性</figcaption></figure><p id="6eb2" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">上面的混淆矩阵解释了我们的模型成功地预测了一个属于奥巴马的演讲&amp; 2个属于罗姆尼的演讲。如果我们计算一下，我们从测试集中总共3个语音中得到3个正确预测的语音，那么我们有(3/3)*100，这当然意味着100。我们模型的预测准确率是100%！找到了。</em></p><p id="6518" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">有人解释<em class="jr">(【十指交叉】)</em> </strong></p><p id="3e67" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">关于我为什么选择75% : 25%的训练集:测试集组合，我需要说一点。我也试过其他组合:</p><ul class=""><li id="4c19" class="ll lm hh iv b iw ix ja jb je ln ji lo jm lp jq lq lr ls lt bi translated"><em class="jr"> 50% : 50%给出了这个结果:</em></li></ul><figure class="ky kz la lb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lv"><img src="../Images/1b85a39c2089428e9df2c2af1c8d0052.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M1Sx6H1x4X4FyCIHLjhRdA.png"/></div></div></figure><p id="a960" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">让我们计算一下，在测试集中，我们从总共6个演讲中得到4个正确预测的演讲，那么我们有(4/6)*100 = 66，67(或大约这个数)。该模型预测的准确率为66，67% </em></p><ul class=""><li id="5bab" class="ll lm hh iv b iw ix ja jb je ln ji lo jm lp jq lq lr ls lt bi translated"><em class="jr"> 80% : 20%给出了这个结果:</em></li></ul><figure class="ky kz la lb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lw"><img src="../Images/293a3250505c06bdb2548acf6f4e2c73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5gzOXhh7sqZjlpK5E8sZSA.png"/></div></div></figure><p id="1abb" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">再次拿出你的计算器，我们从测试集中总共3个语音中得到2个正确预测的语音，那么我们有(2/3)*100 = 66，67。该模型预测的准确率为66，67% </p><p id="b5f1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="jr">我选择</em></strong><em class="jr">75%:25%组合的唯一原因是，与其他两个相比，它给出了</em> <strong class="iv hi"> <em class="jr">最高的精确度</em> </strong> <em class="jr">。不一定说明其他组合不好。它只是没有在我的设备上给出最好的结果(当然，它可能会在不同的设备上给出不同的结果)。</em></p><p id="51e8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">结论</strong></p><p id="afe1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><em class="jr">基于这个试验，结合ML的分类方法的一个弱点是它在不同设备上的表现可能不同。为了获得类似的结果，我们可以使用set.seed()设置一些随机数，然后将这些随机数作为训练集或测试集的索引。如果这仍然不能保证您得到类似的结果，请尝试检查您的R/RStudio的随机数生成器。另一个结果可能不同的方法的例子是安&amp; NNET。以下是k-NN的弱点:</em></p><ul class=""><li id="f9e8" class="ll lm hh iv b iw ix ja jb je ln ji lo jm lp jq lq lr ls lt bi translated"><em class="jr">准确性取决于数据的质量</em></li><li id="fa4c" class="ll lm hh iv b iw lx ja ly je lz ji ma jm mb jq lq lr ls lt bi translated"><em class="jr">对于大量数据，预测阶段可能会很慢</em></li><li id="0d63" class="ll lm hh iv b iw lx ja ly je lz ji ma jm mb jq lq lr ls lt bi translated"><em class="jr">对数据的规模和无关特性敏感</em></li><li id="d64a" class="ll lm hh iv b iw lx ja ly je lz ji ma jm mb jq lq lr ls lt bi translated"><em class="jr">要求高内存(需要存储所有的训练数据)</em></li><li id="3076" class="ll lm hh iv b iw lx ja ly je lz ji ma jm mb jq lq lr ls lt bi translated"><em class="jr">假设它存储了所有的训练，那么它的计算量可能会很大</em></li></ul><p id="8600" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">然而，k-NN使用邻域分类作为新查询的预测值。它有优点:非参数架构， <strong class="iv hi"> <em class="jr">简单强大</em> </strong> <em class="jr">，不需要训练时间。</em></p><p id="bb42" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> <em class="jr">本文就到此，希望对数据爱好者有所帮助！^^ </em> </strong></p><p id="7cc7" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">大大感谢:</strong></p><div class="mc md ez fb me mf"><a rel="noopener follow" target="_blank" href="/bee-solution-partners/cara-kerja-algoritma-k-nearest-neighbor-k-nn-389297de543e"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hi fi z dy mk ea eb ml ed ef hg bi translated">卡拉克尔贾算法k-最近邻(k-NN)</h2><div class="mm l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">尽管我们已经认识到了这一点，但我们比k-NN更清楚。</h3></div><div class="mn l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">medium.com</p></div></div><div class="mo l"><div class="mp l mq mr ms mo mt in mf"/></div></div></a></div><div class="mc md ez fb me mf"><a href="https://www.mygreatlearning.com/blog/knn-algorithm-introduction/" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hi fi z dy mk ea eb ml ed ef hg bi translated">KNN算法简介|什么是KNN算法？</h2><div class="mm l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">你在尝试机器学习吗？这里有一个最简单的机器语言算法的快速介绍- KNN…</h3></div><div class="mn l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">www.mygreatlearning.com</p></div></div><div class="mo l"><div class="mu l mq mr ms mo mt in mf"/></div></div></a></div><div class="mc md ez fb me mf"><a href="https://www.projectrhea.org/rhea/index.php/KNN-K_Nearest_Neighbor_OldKiwi#:~:text=K%20Nearest%20Neighbors%20%28KNN%29&amp;text=The%20KNN%20uses%20neighborhood%20classification,classification%20and%20estimation%20are%20slow." rel="noopener  ugc nofollow" target="_blank"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hi fi z dy mk ea eb ml ed ef hg bi translated">KNN-K最近邻OldKiwi - Rhea</h2><div class="mm l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">在ECE662课程背景下创建的页面。k最近邻(KNN)分类器不使用任何模型来拟合…</h3></div><div class="mn l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">www.projectrhea.org</p></div></div><div class="mo l"><div class="mv l mq mr ms mo mt in mf"/></div></div></a></div><div class="mc md ez fb me mf"><a href="https://stackoverflow.com/questions/21657575/what-does-this-mean-in-lme4-function-dataptr-not-provided-by-package-rcpp" rel="noopener  ugc nofollow" target="_blank"><div class="mg ab dw"><div class="mh ab mi cl cj mj"><h2 class="bd hi fi z dy mk ea eb ml ed ef hg bi translated">这在lme4中意味着什么:程序包' Rcpp '不提供函数' dataptr '</h2><div class="mm l"><h3 class="bd b fi z dy mk ea eb ml ed ef dx translated">感谢贡献一个堆栈溢出的答案！请务必回答问题。提供详细信息并分享…</h3></div><div class="mn l"><p class="bd b fp z dy mk ea eb ml ed ef dx translated">stackoverflow.com</p></div></div><div class="mo l"><div class="mw l mq mr ms mo mt in mf"/></div></div></a></div><figure class="ky kz la lb fd ii"><div class="bz dy l di"><div class="mx my l"/></div></figure></div></div>    
</body>
</html>