<html>
<head>
<title>Implementing the BigGAN model architecture with Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Tensorflow实现BigGAN模型架构</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/implementing-the-biggan-model-architecture-with-tensorflow-8360ff094357?source=collection_archive---------7-----------------------#2021-03-25">https://medium.com/analytics-vidhya/implementing-the-biggan-model-architecture-with-tensorflow-8360ff094357?source=collection_archive---------7-----------------------#2021-03-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2c08" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">论文<a class="ae jc" href="https://arxiv.org/abs/1809.11096" rel="noopener ugc nofollow" target="_blank">“高保真自然图像合成的大规模GAN训练”提出的概念和方法参见<a class="ae jc" rel="noopener" href="/analytics-vidhya/key-concepts-of-biggan-training-and-assessing-large-scale-image-generation-4c8303dcf73f">本帖</a>。</a></p><h1 id="5c61" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">机器规格的限制</h1><p id="ff21" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">显然，最初的BigGAN模型是在具有巨大计算能力和内存的环境中训练出来的。在Colab中执行256x256 biggan无论如何都会崩溃，至少批处理大小大于4。尽管在我们的本地环境中它不太可能是可训练的，但是我们将回顾如何实现本文中提出的技术和模型架构。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kg"><img src="../Images/b2dc59628ef2cd93fa453e29489b67c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YO6_TLXHZB-B0Hqd3gLYrw.png"/></div></div><figcaption class="ks kt et er es ku kv bd b be z dx translated">摘自<a class="ae jc" href="https://www.reddit.com/r/MachineLearning/comments/b461zt/p_want_to_train_your_own_biggan_on_just_48_gpus/" rel="noopener ugc nofollow" target="_blank"> Reddit </a></figcaption></figure><h1 id="7c24" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">履行</h1><p id="0984" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">这篇文章的完整代码可在<a class="ae jc" href="https://colab.research.google.com/drive/1WGG8d22KoxXWBThYOeFDcHvt_z9EirHV" rel="noopener ugc nofollow" target="_blank">这里</a>获得，尽管在执行时会产生OOM(内存不足)或ResourceExhaustedError。</p><p id="fe00" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们首先实现本文中使用的自定义层。有条件的批量标准化意味着批量标准化的先前均值和方差集参数被设置为神经网络的输出。在这种情况下，它是基于潜在切片z的级联向量和类嵌入来调节的。该层学习线性映射以输出具有尺寸通道号的两个向量，每个向量替换原始批量归一化的均值和方差。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="kw kx l"/></div></figure><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es ky"><img src="../Images/bfb5a948f347248a2fc969e44bd7fa9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*-LPCWXdbawYrEZQy.png"/></div></div></figure><p id="d82c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们实现非线性模块或自我关注模块。该块生成两个映射:f、g，并将softmax激活应用于f*g以生成注意力映射，并将该映射应用于图像h的另一个映射。最后，随后应用一个卷积层o并生成最终输出。自我注意中的s张量消耗了非常大的内存，因为分配给s的矩阵是(bs，h*w，h*w ),因此是ResourceExhaustedError的核心原因。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="80a2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们基于上述预定义的层来定义残差块。两个剩余块都实现了跳过连接，并且由两个卷积组成。先前定义的ConditionalBatchNormalization在生成器中用于应用类和噪声信息。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="d554" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">同样，基于定义的剩余块和自定义层，我们定义了一个128x128的BigGAN生成器模型。我们连接5个剩余块，并馈送共享类嵌入的级联向量和噪声潜在向量的切片。非线性块以64×64的分辨率放置。Colab实现中也实现了256x256模型(只需要稍微调整一下超参数)。由于多重噪声投射，发电机架构的结果图是混乱的。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="a387" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们定义了128x128 BigGAN鉴别器模型。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="0c71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还实现了铰链损耗的训练。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="e142" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们绘制了一些比根的示例图像。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="kw kx l"/></div></figure><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="er es kz"><img src="../Images/f6170d26e7c9b831dbf00357be8ec30b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2TjaXFXnerzPBW3uxvPujw.png"/></div></div></figure><p id="5a14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们根据<a class="ae jc" href="https://keras.io/examples/generative/dcgan_overriding_train_step/" rel="noopener ugc nofollow" target="_blank">这个</a> Keras教程来定义训练循环。我们重写了tf.Keras.Model的compile和train_step函数，我强烈推荐去看看。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="2221" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们尝试训练模型，尽管由于ResourceExhaustedError或内核崩溃而失败。</p><figure class="kh ki kj kk fd kl"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="639a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果--&gt;</p><p id="0094" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">————————<br/>resource exhaust error trace back(最近一次调用last)<br/>&lt;&lt;模块&gt;()<br/>9)<br/>10<br/>—&gt;11 gan . fit(train _ dataset . batch(128)，epochs=epochs</p><p id="60cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我们回顾了</p><ul class=""><li id="9a4a" class="la lb hh ig b ih ii il im ip lc it ld ix le jb lf lg lh li bi translated">如何在Tensorflow中实现生成网络的条件批量规范化和自关注？</li><li id="76e7" class="la lb hh ig b ih lj il lk ip ll it lm ix ln jb lf lg lh li bi translated">如何在Tensorflow中实现BigGAN模型架构？</li></ul><p id="2801" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">BigGAN-deep架构也可以通过对该代码的剩余块进行少量修改来轻松实现。当我获得8个GPU的配额权限并分享结果时，我会尝试在谷歌云平台中训练这些代码。</p></div></div>    
</body>
</html>