<html>
<head>
<title>Ensemble Method: AdaBoost</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集成方法:AdaBoost</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ensemble-method-adaboost-712547c7e2c7?source=collection_archive---------11-----------------------#2021-06-23">https://medium.com/analytics-vidhya/ensemble-method-adaboost-712547c7e2c7?source=collection_archive---------11-----------------------#2021-06-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="0825" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，您将了解什么是boosting以及AdaBoost的工作原理。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/8dc683487714ec4f8601d61f2fda7235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ojr51_pcODmS1MmWLkgF9A.jpeg"/></div></div></figure><h1 id="6b3a" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">什么是助推？</h1><p id="deaa" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">Boosting也称为假设Boosting，是一种将几个弱学习器组合成一个强学习器的集成方法。boosting背后的主要逻辑是每个模型/学习者都试图纠正其前任。</p><p id="5499" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有许多可用的升压方法，但最常用的是:</p><ol class=""><li id="88ce" class="kr ks hh ig b ih ii il im ip kt it ku ix kv jb kw kx ky kz bi translated">AdaBoost。</li><li id="d2aa" class="kr ks hh ig b ih la il lb ip lc it ld ix le jb kw kx ky kz bi translated">梯度推进。</li></ol><h1 id="c79e" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">adaboost算法</h1><p id="efed" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">AdaBoost是如何工作的？正如我们所知，对于boosting，学习者试图纠正其前任，一种方法是给予前任不适合的训练实例更多的关注。</p><p id="90f9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Adaboost中，每个训练实例和每个学习者/模型都被分配了权重，我们将在本节的后面查看权重是如何分配和更新的。</p><p id="2b05" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，为了构建AdaBoost分类器，第一基本分类器被训练并用于对训练集进行预测。然后增加错误分类的训练实例的相对权重。使用更新的权重训练第二分类器，并且再次对训练集进行预测，权重被更新，等等。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lf"><img src="../Images/ac1feb0a0a18c91b4865a6a5042febd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gf0ifraaFvG6fmgRLZcetQ.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">adaboost算法</figcaption></figure><p id="1038" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上图显示了moons数据集上五个连续预测因子的决策边界。第一个分类器在训练集训练后得到一些错误的预测，所以我们提高它们的权重。第二个分类器在这些情况下做得更好，依此类推。</p><p id="22ee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦训练了所有预测器，集成就可以进行非常类似于打包或粘贴的预测，除了预测器根据它们在加权训练集上的整体准确性而具有不同的权重。</p><h2 id="c0b2" class="lk jp hh bd jq ll lm ln ju lo lp lq jy ip lr ls kc it lt lu kg ix lv lw kk lx bi translated">权重是如何分配和更新的？</h2><p id="9cde" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">让我们仔细看看Adaboost算法。每个实例权重<em class="ly"> w(i) </em>初始设置为<em class="ly"> 1/m </em> (m为实例数)。训练第一预测器，并在训练集上计算其加权误差率<em class="ly"> r1 </em>。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lz"><img src="../Images/55de7016813030d88baed2b044a408bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ja4IlkDmDlTEGLKe0hvy4Q.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">权差</figcaption></figure><p id="12b1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">加权误差(r)是寻找模型/学习器的权重和更新权重的最重要的项。</p><p id="1dde" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">预测器的权重<em class="ly"> αj </em>然后使用下面所示的等式来计算:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ma"><img src="../Images/63f8f21e118186b834921d1b4dd5473b.png" data-original-src="https://miro.medium.com/v2/resize:fit:416/format:webp/1*hnlBS0Wyr2-kMrLHri4PYQ.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">预测权重</figcaption></figure><p id="4b49" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中<em class="ly"> η </em>是学习率超参数(默认为1)。预测器越精确，其权重就越高。如果只是随机猜测，那么它的权重将接近于零。然而，如果它经常是错误的(即，不如随机猜测准确)，那么它的权重将是负的。</p><p id="2913" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，使用下面的等式更新实例权重，提升错误分类的实例:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mb"><img src="../Images/ee87595ed49ad88d9317a8b6aad27973.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*MVnifXXs3CdLeHVCnS_VzQ.png"/></div><figcaption class="lg lh et er es li lj bd b be z dx translated">实例权重更新</figcaption></figure><p id="27de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，所有实例权重被归一化，即除以所有实例权重的总和。</p><p id="cbd5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，使用更新的权重训练新的预测器，并且重复整个过程。</p><p id="d622" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了进行预测，AdaBoost只需计算所有预测器的预测值，并使用预测器权重αj对它们进行加权。预测类是获得大多数加权投票的类。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mc"><img src="../Images/89e16e78fd7886758003024b7a832ab4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1272/format:webp/1*jOM1iGMnA79XIvTr0LhxVQ.png"/></div></div><figcaption class="lg lh et er es li lj bd b be z dx translated">预测值</figcaption></figure><p id="3ed0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的代码使用Scikit-Learn的<strong class="ig hi"> AdaBoostClassifier </strong>类(正如您所料，还有一个<strong class="ig hi"> AdaBoostRegressor </strong>类)基于200个决策树桩训练一个AdaBoost分类器。决策树桩是一棵max_depth=1的<strong class="ig hi">决策树</strong>——换句话说，一棵由一个决策节点和两个叶节点组成的树。这是AdaBoostClassifier类的默认基本估计量:</p><pre class="jd je jf jg fd md me mf mg aw mh bi"><span id="3cae" class="lk jp hh me b fi mi mj l mk ml">from sklearn.ensemble import AdaBoostClassifier</span><span id="661f" class="lk jp hh me b fi mm mj l mk ml">ada_clf = AdaBoostClassifier(<br/>DecisionTreeClassifier(max_depth=1), n_estimators=200,<br/>algorithm="SAMME.R", learning_rate=0.5)</span><span id="0a79" class="lk jp hh me b fi mm mj l mk ml">ada_clf.fit(X_train, y_train)</span></pre><h1 id="6836" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">关于作者</h1><p id="3fb3" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">我是Mustafa Sidhpuri，一名积极上进的数据科学家，有着自由职业数据科学家的经历。热衷于构建解决问题的模型。相关技能包括<strong class="ig hi">机器学习、解决问题、编程和创造性思维</strong>。</p><div class="mn mo ez fb mp mq"><a href="https://github.com/Mustisid13" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hi fi z dy mv ea eb mw ed ef hg bi translated">Mustisid13 -概述</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">学习计算机科学和工程(最后一年)在ITM宇宙Vadodara块或报告六月七月八月九月十月十一月…</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">github.com</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne jm mq"/></div></div></a></div><div class="mn mo ez fb mp mq"><a href="https://www.linkedin.com/in/mustafa13/" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab dw"><div class="ms ab mt cl cj mu"><h2 class="bd hi fi z dy mv ea eb mw ed ef hg bi translated">穆斯塔法·西德普里- ITM宇宙-印度古吉拉特邦| LinkedIn</h2><div class="mx l"><h3 class="bd b fi z dy mv ea eb mw ed ef dx translated">查看Mustafa Sidhpuri在全球最大的职业社区LinkedIn上的个人资料。穆斯塔法的学历在列…</h3></div><div class="my l"><p class="bd b fp z dy mv ea eb mw ed ef dx translated">www.linkedin.com</p></div></div><div class="mz l"><div class="nf l nb nc nd mz ne jm mq"/></div></div></a></div></div></div>    
</body>
</html>