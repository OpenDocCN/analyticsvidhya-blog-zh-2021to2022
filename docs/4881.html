<html>
<head>
<title>AWS SageMaker: Train, Deploy and Update a Hugging Face BERT Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">AWS SageMaker:训练、部署和更新拥抱脸BERT模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/aws-sagemaker-train-deploy-and-update-a-hugging-face-bert-model-eeefc8211368?source=collection_archive---------0-----------------------#2022-07-02">https://medium.com/analytics-vidhya/aws-sagemaker-train-deploy-and-update-a-hugging-face-bert-model-eeefc8211368?source=collection_archive---------0-----------------------#2022-07-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="7b2e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">#拥抱脸#AWS #BERT #SageMaker #Mlops</p><p id="7baa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">诸如<a class="ae jc" href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf" rel="noopener ugc nofollow" target="_blank"> tf-idf </a>、<a class="ae jc" href="https://en.wikipedia.org/wiki/Word2vec" rel="noopener ugc nofollow" target="_blank"> word2vec </a>或<a class="ae jc" href="https://en.wikipedia.org/wiki/Bag-of-words_model" rel="noopener ugc nofollow" target="_blank"> bag-of-words (BOW) </a>的NLP技术用于生成可用于训练文本分类模型的词嵌入特征。他们在许多NLP任务中非常成功，但是当单词出现在不同的上下文中时，他们并不总是准确地捕捉单词的意思。</p><p id="b2d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们在文本分类任务中借助<a class="ae jc" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> BERT </a>取得了更好的结果，因为它能够更准确地编码不同上下文中单词的含义。</p><p id="9a3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://docs.aws.amazon.com/sagemaker/index.html" rel="noopener ugc nofollow" target="_blank">亚马逊SageMaker </a>使开发人员能够在云中创建、训练、部署和监控机器学习模型。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/55812174287a6902b1da6b0f4631129b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*OJASmddRA3PS6Thy.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片来自<a class="ae jc" href="https://aws.amazon.com/" rel="noopener ugc nofollow" target="_blank"> AWS </a></figcaption></figure><p id="933d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">目录</strong></p><ol class=""><li id="a089" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb jy jz ka kb bi translated">问题陈述</li><li id="ae22" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">目标</li><li id="c7d9" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">资料组</li><li id="d3e9" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">亚马逊SageMaker培训</li><li id="9746" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">用于SageMaker模型训练的AWS实例类型</li><li id="07fd" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">使用按需实例的模型训练</li><li id="3d3a" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">使用spot实例的模型训练</li><li id="55fe" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">SageMaker端点上的模型部署</li><li id="4573" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">更新SageMaker模型端点</li><li id="00d1" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">结论和参考文献</li></ol><p id="408e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，这篇文章的目的不是建立一个健壮的模型，而是如何在SageMaker上训练一个HuggingFace BERT模型。让我们详细介绍一下每个步骤。</p><p id="be8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 1。问题陈述</strong></p><p id="0a73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">推特已经成为紧急时刻的重要沟通渠道。智能手机的普及使人们能够实时宣布他们正在观察的紧急情况。正因为如此，越来越多的机构对有计划地监控Twitter感兴趣(即救灾组织和新闻机构)。</p><p id="a4cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">更多详情<a class="ae jc" href="https://www.kaggle.com/c/nlp-getting-started/overview" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="01a2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。目标</strong></p><p id="0eb0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Kaggle竞赛数据集，由关于灾难的虚假和真实推文组成。任务是对推文进行分类。</p><p id="7844" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。数据集</strong></p><p id="6cfb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://www.kaggle.com/competitions/nlp-getting-started/data?select=train.csv" rel="noopener ugc nofollow" target="_blank">数据集</a>由贴有标签的虚假和真实推文组成。标签在“目标”栏中提供。有几个特征，尽管为了这篇博文的目的，我们将只使用“文本”字段来表示推文的文本。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kh"><img src="../Images/b0f52079a0a07af687db1d7afd937374.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gxF8e0_XZzt6TRvq.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片来自Kaggle数据集(作者截图)</figcaption></figure><p id="c7dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请参考本<a class="ae jc" href="https://github.com/Vinayaks117/AWS-SageMaker-Examples.git" rel="noopener ugc nofollow" target="_blank"> git repo </a>以及数据准备和EDA。让我们专注于使用AWS SageMaker训练一个HuggingFace BERT模型。</p><p id="ba9b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 4。亚马逊SageMaker培训</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ki"><img src="../Images/d9cb72846061de1d7b71b3b1ca0c9b48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4PRPoJGaN85Aridj.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片来自<a class="ae jc" href="https://aws.amazon.com/" rel="noopener ugc nofollow" target="_blank"> AWS </a></figcaption></figure><ul class=""><li id="71f1" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb kj jz ka kb bi translated">当SageMaker培训作业开始时，SageMaker准备实例(在本文中使用“ml.m5.xlarge”实例)进行培训。</li><li id="c972" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">SageMaker从亚马逊S3下载或读取输入数据，使用这些数据来训练模型。</li><li id="9e49" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">SageMaker从Amazon Elastic Container Registry(<code class="du kk kl km kn b">ECR</code>)提取模型训练实例容器(在本文中使用Pytorch容器，但我们也可以使用HuggingFace和TensorFlow容器)，然后来自S3的训练数据可用于模型训练实例容器，请参见<a class="ae jc" href="https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html" rel="noopener ugc nofollow" target="_blank">预构建的SageMaker Docker深度学习图像</a>。</li><li id="164d" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">一旦模型训练完成，模型训练作业就将模型工件保存回训练作业配置中指定的输出S3位置。</li><li id="f874" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">当我们准备好部署一个模型时，SageMaker创建新的ML实例(在本文中使用“ml.m4.xlarge”实例)，从ECR中提取模型推理容器(使用Pytorch容器),然后从S3中提取这些模型工件以用于实时模型推理。</li></ul><p id="cbdc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 5。SageMaker上用于模型训练的AWS实例类型:</strong></p><p id="c57c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们了解一下可以在AWS SageMaker上用于模型训练的AWS实例的类型。</p><p id="ce93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">答:按需实例:</strong></p><ul class=""><li id="18c8" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb kj jz ka kb bi translated">我们告诉AWS SM (SageMaker)我们需要哪种EC2实例类型以及它们的数量，然后按需创建适当的实例，一旦训练工作完成，就自动配置和终止。</li><li id="b501" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">按需实例在我们需要时可用，我们需要按小时支付使用时间的费用。</li><li id="9e4b" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">按需实例保持不间断，直到我们终止实例或培训作业完成。</li></ul><p id="b445" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> b. Spot实例:</strong></p><ul class=""><li id="dd04" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb kj jz ka kb bi translated">这是一种对闲置EC2实例(空闲容量)的拍卖/投标。</li><li id="0a1a" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">如果我们的投标价格≥市场(现货)价格(根据需求和供应实时变化)，那么将启动现货实例。</li><li id="a358" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">如果空闲容量耗尽或现货价格变得高于投标价格，那么现货实例在通知或警告的2分钟内被终止。</li><li id="fea5" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">与在AWS SageMaker中使用按需实例相比，EC2 spot实例帮助我们降低了高达90%的机器学习培训成本。</li></ul><p id="7b8d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 6。使用按需实例的模型训练</strong></p><p id="3b09" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们专注于使用AWS SageMaker按需实例训练HuggingFace BERT模型。</p><p id="2fa7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">模型训练脚本</strong></p><p id="fcc3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用<a class="ae jc" href="https://pytorch.org/hub/huggingface_pytorch-transformers" rel="noopener ugc nofollow" target="_blank"> PyTorch-Transformers库</a>，它包含PyTorch实现和许多NLP模型的预训练模型权重，包括BERT。</p><p id="0d1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的训练脚本应该将在训练期间学到的模型工件保存到一个名为<code class="du kk kl km kn b">model_dir</code>的文件路径中，正如SageMaker PyTorch映像所规定的那样。培训完成后，保存在<code class="du kk kl km kn b">model_dir</code>中的模型工件将由SageMaker上传到S3，并可在S3进行部署。</p><p id="3391" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将这个脚本保存在一个名为<code class="du kk kl km kn b">train_deploy.py</code>的文件中，并将该文件放在一个名为<code class="du kk kl km kn b">code/</code>的目录中。完整的训练脚本可以在<code class="du kk kl km kn b">code/</code>下查看。</p><p id="dca1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看看离<code class="du kk kl km kn b">train_deploy.py</code>几个街区的地方</p><p id="735b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">导入必要的库</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="cc51" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">定义记录器并加载BERT记号赋予器</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="1989" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">众所周知，PyTorch提供了一个解决方案，通过使用DataLoader的自动批处理来并行化数据加载过程。Dataloader用于并行加载数据，因为这样可以提高速度并节省内存。让我们来训练和测试数据加载器。</p><p id="e87c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">获取列车数据加载器</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="cd42" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">获取测试数据加载器</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="63d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">定义、训练BERT模型并保存微调后的模型</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="163f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">使用亚马逊SageMaker上的按需实例进行模型训练</strong></p><p id="8d30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Amazon SageMaker Python SDK 使得在Amazon SageMaker中使用PyTorch估计器运行PyTorch脚本变得更加容易。</p><p id="c502" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们使用<code class="du kk kl km kn b">PyTorch</code>估计器类来训练我们的模型。在创建我们的评估者时，我们确保指定一些事情:</p><ul class=""><li id="24da" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb kj jz ka kb bi translated">我们PyTorch脚本的名字。它包含我们的训练脚本，该脚本从输入通道加载数据，用超参数配置训练，训练模型，并保存模型。它还包含在推理过程中加载和运行模型的代码。</li><li id="b5ac" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated"><code class="du kk kl km kn b">source_dir</code>:我们的培训脚本和requirements.txt文件的位置。“requirements.txt”列出了您想在脚本中使用的包。</li><li id="3135" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated"><code class="du kk kl km kn b">framework_version</code>:我们要用的PyTorch版本</li></ul><p id="4209" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">创建评估器后，我们调用fit()，启动一个训练作业。我们使用亚马逊S3 URIs，在那里我们上传了训练数据。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kq"><img src="../Images/457047555f4d4562f901379c3199d2bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yHGUuIJ7DdiP1MiO.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片来自<a class="ae jc" href="https://aws.amazon.com/" rel="noopener ugc nofollow" target="_blank"> AWS </a></figcaption></figure><p id="e225" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">此时，SageMaker将使用AWS ECR中提供的内置PyTorch Docker映像创建ml.m5.xlarge培训实例。然后，它将从S3 bucket下载数据和配置文件到SageMaker实例，并开始训练作业。</p><p id="4bd3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">创建一个评估对象，开始按需实例训练</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="6773" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以通过查看下面的<em class="kr">Amazon sage maker&gt;Training jobs</em>来监控我们培训工作的状态。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kq"><img src="../Images/7556d6ee7c2e55ff2c8e8a319c7c0eca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*caxZismv5m4ZZWwM.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">培训工作(作者截图)</figcaption></figure><p id="7b8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们应该看到类似于下面的日志，让您了解培训工作的状态。日志显示在笔记本中，也可以在AWS CloudWatch日志中找到，以供将来参考。</p><pre class="je jf jg jh fd ks kn kt ku aw kv bi"><span id="440c" class="kw kx hh kn b fi ky kz l la lb">2022-05-14 09:13:19 Starting - Starting the training job...<br/>2022-05-14 09:13:42 Starting - Preparing the instances for trainingProfilerReport-1652519599: InProgress<br/>......<br/>2022-05-14 09:14:42 Downloading - Downloading input data...<br/>2022-05-14 09:15:02 Training - Downloading the training image...<br/>2022-05-14 09:15:50 Training - Training image download completed. Training in progress...<br/>.........<br/>.........<br/>.........<br/>Train Epoch: 1 [0/5709 (0%)] Loss: 0.752307<br/>INFO:__main__:Train Epoch: 1 [0/5709 (0%)] Loss: 0.752307<br/>Train Epoch: 1 [3200/5709 (56%)] Loss: 0.518363<br/>INFO:__main__:Train Epoch: 1 [3200/5709 (56%)] Loss: 0.518363<br/>Average training loss: 0.473186<br/>INFO:__main__:Average training loss: 0.473186<br/>Test set: Accuracy: 0.825221<br/>INFO:__main__:Test set: Accuracy: 0.825221Train Epoch: 2 [0/5709 (0%)] Loss: 0.367052<br/>INFO:__main__:Train Epoch: 2 [0/5709 (0%)] Loss: 0.367052<br/>Train Epoch: 2 [3200/5709 (56%)] Loss: 0.313773<br/>INFO:__main__:Train Epoch: 2 [3200/5709 (56%)] Loss: 0.313773<br/>Average training loss: 0.356163<br/>INFO:__main__:Average training loss: 0.356163<br/>Test set: Accuracy: 0.824115Saving tuned model.<br/>INFO:__main__:Test set: Accuracy: 0.824115<br/>INFO:__main__:Saving tuned model.<br/>2022-05-14 10:15:36,540 sagemaker-training-toolkit INFO     Reporting training SUCCESS<br/><br/>2022-05-14 10:16:16 Uploading - Uploading generated training model<br/>2022-05-14 10:17:16 Completed - Training job completed<br/>ProfilerReport-1652519599: NoIssuesFound<br/>Training seconds: 3755<br/>Billable seconds: 3755</span></pre><p id="27af" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用SageMaker训练了一个具有2个时期的BERT模型来演示模型训练，我们看到测试集上的准确率为82.41%，完成模型训练所需的时间为3755秒，因此我们只需支付3755秒。</p><p id="5b1f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们肯定可以通过使用基于GPU的实例来改善这一时间，由于我的AWS自由层帐户的资源限制，我尝试了基于CPU的实例。</p><p id="9b35" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 7。使用spot实例的模型训练(托管Spot训练)</strong></p><ul class=""><li id="6ed6" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb kj jz ka kb bi translated">如前所述，使用spot实例的模型训练可以优化训练模型的成本，比按需实例高90%。SageMaker代表我们管理现场中断。</li><li id="d879" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">管理现场培训在所有培训配置中都可用:单实例培训、分布式培训和自动模型调整</li><li id="c9ed" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">如果我们需要更多的容量并需要自己采取行动，EC2 spot实例可以被中断或在任何时候被要求。中断导致培训工作需要更长时间开始或完成。</li><li id="41c5" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">别担心，AWS SageMaker是一个完全托管的服务，它会自动处理流程。</li></ul><pre class="je jf jg jh fd ks kn kt ku aw kv bi"><span id="d1a4" class="kw kx hh kn b fi ky kz l la lb">. Interrupting the training job<br/>. Obtaining adequate spot capacity again<br/>. Either restarting or resuming the training job</span></pre><ul class=""><li id="3a78" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb kj jz ka kb bi translated">当spot实例被中断时，我们需要使用检查点来避免从头开始训练作业。</li></ul><p id="e27b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">管理现场培训参数:</strong></p><p id="3bf2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">a.use_spot_instances = True</p><p id="ce54" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">b.max_run =培训作业应该运行多长时间。</p><p id="945f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">c.max_wait =训练作业的总持续时间=训练时间+我们准备等待spot实例可用的时间。</p><p id="3778" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">创建一个评估对象，并开始受管理的现场培训</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="4e53" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">再来看模特培训的现状。</p><pre class="je jf jg jh fd ks kn kt ku aw kv bi"><span id="4422" class="kw kx hh kn b fi ky kz l la lb">2022-05-14 12:15:48 Starting - Starting the training job...<br/>2022-05-14 12:15:49 Starting - Launching requested ML instancesProfilerReport-1652530547: InProgress<br/>......<br/>2022-05-14 12:17:14 Starting - Preparing the instances for training.........<br/>2022-05-14 12:18:42 Downloading - Downloading input data...<br/>2022-05-14 12:19:08 Training - Training image download completed. Training in progress.<br/>.........<br/>.........<br/>.........<br/>Train Epoch: 1 [0/5709 (0%)] Loss: 0.752307<br/>INFO:__main__:Train Epoch: 1 [0/5709 (0%)] Loss: 0.752307<br/>Train Epoch: 1 [3200/5709 (56%)] Loss: 0.518363<br/>INFO:__main__:Train Epoch: 1 [3200/5709 (56%)] Loss: 0.518363<br/>Average training loss: 0.473186<br/>INFO:__main__:Average training loss: 0.473186<br/>Test set: Accuracy: 0.825221<br/>INFO:__main__:Test set: Accuracy: 0.825221Train Epoch: 2 [0/5709 (0%)] Loss: 0.367052<br/>INFO:__main__:Train Epoch: 2 [0/5709 (0%)] Loss: 0.367052<br/>Train Epoch: 2 [3200/5709 (56%)] Loss: 0.313773<br/>INFO:__main__:Train Epoch: 2 [3200/5709 (56%)] Loss: 0.313773<br/>Average training loss: 0.356163<br/>INFO:__main__:Average training loss: 0.356163<br/>Test set: Accuracy: 0.824115Saving tuned model.<br/>INFO:__main__:Test set: Accuracy: 0.824115<br/>INFO:__main__:Saving tuned model.<br/>2022-05-14 12:55:39,669 sagemaker-training-toolkit INFO     Reporting training SUCCESS<br/><br/>2022-05-14 12:55:53 Uploading - Uploading generated training model<br/>2022-05-14 12:56:54 Completed - Training job completed<br/>ProfilerReport-1652530547: NoIssuesFound<br/>Training seconds: 2282<br/>Billable seconds: 508<br/>Managed Spot Training savings: 77.7%</span></pre><p id="d8cf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上一步中，我们使用具有2个时期的按需实例训练了一个BERT模型，完成模型训练花费了3755秒，计费秒数= 3755。</p><p id="4372" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过查看上面的日志，托管spot实例培训在2282秒内完成，计费秒数= 508。</p><p id="931a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">哇..有管理的现场培训可以节省高达77.7%的培训成本</p><p id="338c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 8。SageMaker端点上的模型部署</strong></p><p id="1613" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在训练我们的模型之后，我们在Amazon SageMaker端点上托管它。为了让端点加载模型并提供预测，我们在<code class="du kk kl km kn b">train_deploy.py</code>中实现了一些方法。</p><ul class=""><li id="bb7b" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb kj jz ka kb bi translated"><code class="du kk kl km kn b">model_fn()</code>:定义的函数，用于加载保存的模型，并返回一个可用于模型服务的模型对象。SageMaker PyTorch模型服务器通过调用model_fn来加载我们的模型。</li><li id="1a92" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated"><code class="du kk kl km kn b">input_fn()</code>:解串并准备预测输入。在这个例子中，我们的请求体首先被序列化为JSON，然后被发送到模型服务端点。因此，在<code class="du kk kl km kn b">input_fn()</code>中，我们首先反序列化JSON格式的请求体，并将输入作为<code class="du kk kl km kn b">torch.tensor</code>返回，这是BERT所要求的。</li><li id="7325" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated"><code class="du kk kl km kn b">predict_fn()</code>:进行预测并返回结果。</li></ul><p id="6fa9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了部署我们的端点，我们调用PyTorch估计器对象上的<code class="du kk kl km kn b">deploy()</code>,传入我们想要的实例数量和实例类型:</p><pre class="je jf jg jh fd ks kn kt ku aw kv bi"><span id="2032" class="kw kx hh kn b fi ky kz l la lb">predictor <strong class="kn hi">=</strong> estimator<strong class="kn hi">.</strong>deploy(initial_instance_count<strong class="kn hi">=</strong>1, instance_type<strong class="kn hi">=</strong>"ml.m4.xlarge")</span></pre><p id="c0d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">estimator.deploy()方法在后台做3件事。</p><p id="95fe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">a.在sagemaker上注册一个模型:为模型定义一个名称，并关联到存储模型工件的s3位置。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kq"><img src="../Images/147eafd79c1c6a4f82574aba9e66246a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*UKPUYgTmY6b95JUr.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">SageMaker模型(作者截图)</figcaption></figure><p id="cab6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">b.创建端点配置:Sagemaker为不同的目的创建模型托管端点配置——A/B测试、开发与生产版本等。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kq"><img src="../Images/c4193dfb25f963af41ad6425b4b0c22b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*n6QajEm6RPlHvC2P.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">SageMaker端点配置(作者截图)</figcaption></figure><p id="d810" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">c.创建端点:最后，它创建一个用于预测的端点。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kq"><img src="../Images/db4a6c7c2afa69899572600f37f3804d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*uJncVXXsIZdBeQaP.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">SageMaker端点(作者截图)</figcaption></figure><p id="ed61" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们查看上述端点的配置细节，我们会发现SageMaker上的注册模型被附加到这个端点，这意味着端点使用SageMaker上的注册模型来服务模型预测。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kq"><img src="../Images/cd2a391eae4daa07a6808a8a4c5fd075.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xGa0zzFjgpV9FQ-w.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">SageMaker端点生产变体(作者截图)</figcaption></figure><p id="137c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">模型预测/推理</strong></p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="6276" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">推理结果</strong>:</p><pre class="je jf jg jh fd ks kn kt ku aw kv bi"><span id="2bc2" class="kw kx hh kn b fi ky kz l la lb">predicted_labels: ['Not a disaster', 'Real disaster', 'Real disaster']I met my friend today by accident ---&gt; Not a disaster<br/>Frank had a severe head injury after the car accident last month ---&gt; Real disaster<br/>Just happened a terrible car crash ---&gt; Real disaster</span></pre><p id="7095" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 9。更新SageMaker模型端点</strong></p><p id="722b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们都知道机器学习是一个高度迭代的过程。当我们在从事任何数据科学项目时，数据科学家和ML工程师经常训练成千上万个不同的模型，以寻求最大的准确性。事实上，算法、数据集和训练参数(即超参数)的组合数量是无限的。</p><p id="b968" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，让我们用更新的超参数(历元= 3)值训练一个BERT模型，看看模型性能是否得到改善。</p><p id="2874" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们发现模型性能的改进，那么我们可以更新现有的SageMaker模型端点。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="d5a4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">再来看模特培训的现状。</p><pre class="je jf jg jh fd ks kn kt ku aw kv bi"><span id="a474" class="kw kx hh kn b fi ky kz l la lb">2022-05-14 10:28:20 Starting - Starting the training job...<br/>2022-05-14 10:28:46 Starting - Preparing the instances for trainingProfilerReport-1652524100: InProgress<br/>......<br/>2022-05-14 10:29:46 Downloading - Downloading input data...<br/>2022-05-14 10:30:06 Training - Downloading the training image.....<br/>.........<br/>.........<br/>.........Train Epoch: 1 [0/5709 (0%)] Loss: 0.752307<br/>INFO:__main__:Train Epoch: 1 [0/5709 (0%)] Loss: 0.752307<br/>Train Epoch: 1 [3200/5709 (56%)] Loss: 0.518363<br/>INFO:__main__:Train Epoch: 1 [3200/5709 (56%)] Loss: 0.518363<br/>Average training loss: 0.473186<br/>INFO:__main__:Average training loss: 0.473186<br/>Test set: Accuracy: 0.825221<br/>INFO:__main__:Test set: Accuracy: 0.825221Train Epoch: 2 [0/5709 (0%)] Loss: 0.367052<br/>INFO:__main__:Train Epoch: 2 [0/5709 (0%)] Loss: 0.367052<br/>Train Epoch: 2 [3200/5709 (56%)] Loss: 0.313773<br/>INFO:__main__:Train Epoch: 2 [3200/5709 (56%)] Loss: 0.313773<br/>Average training loss: 0.356163<br/>INFO:__main__:Average training loss: 0.356163<br/>Test set: Accuracy: 0.824115<br/>INFO:__main__:Test set: Accuracy: 0.824115Train Epoch: 3 [0/5709 (0%)] Loss: 0.345569<br/>INFO:__main__:Train Epoch: 3 [0/5709 (0%)] Loss: 0.345569<br/>Train Epoch: 3 [3200/5709 (56%)] Loss: 0.371484<br/>INFO:__main__:Train Epoch: 3 [3200/5709 (56%)] Loss: 0.371484<br/>Average training loss: 0.274791<br/>INFO:__main__:Average training loss: 0.274791<br/><br/>2022-05-14 11:59:06 Uploading - Uploading generated training modelTest set: Accuracy: 0.826327<br/>INFO:__main__:Test set: Accuracy: 0.826327<br/>Saving tuned model.<br/>INFO:__main__:Saving tuned model.<br/>2022-05-14 11:59:03,716 sagemaker-training-toolkit INFO     Reporting training SUCCESS<br/><br/>2022-05-14 12:00:12 Completed - Training job completed<br/>Training seconds: 5438<br/>Billable seconds: 5438</span></pre><p id="a575" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过观察上述结果，用纪元= 3训练的模型比用纪元= 2训练的模型表现得更好。因此，让我们看看如何更新现有的SageMaker模型端点。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ko kp l"/></div></figure><p id="6b23" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用sm_client.create_model()方法在SageMaker上注册一个模型。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kq"><img src="../Images/6ec573a32736b469a95c45f61ae4ca65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DnQT7eXtF1eRbB0w.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">SageMaker模型(作者截图)</figcaption></figure><p id="9629" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们查看现有端点的配置详细信息(py torch-training-2022–05–14–10–19–37–926 ),我们会发现SageMaker上最新注册的模型连接到了现有端点。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kq"><img src="../Images/4e1541907f88bfd1199751b0fffb7652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qAv5qbKH5KM-oPSe.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">SageMaker端点生产变体(作者截图)</figcaption></figure><p id="30b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">再来看推断结果。</p><p id="c192" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">推理结果</strong>:</p><pre class="je jf jg jh fd ks kn kt ku aw kv bi"><span id="598c" class="kw kx hh kn b fi ky kz l la lb">predicted_labels: ['Not a disaster', 'Real disaster', 'Real disaster']I met my friend today by accident ---&gt; Not a disaster<br/>Frank had a severe head injury after the car accident last month ---&gt; Real disaster<br/>Just happened a terrible car crash ---&gt; Real disaster</span></pre><p id="2dfa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 10。结论</strong></p><ul class=""><li id="6cc4" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb kj jz ka kb bi translated">希望这篇文章可以帮助你利用亚马逊SageMaker的力量，使用亚马逊内置的深度学习容器，在你自己的数据上训练，部署和更新拥抱脸BERT模型。</li><li id="a2a5" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">我们经历了Amazon SageMaker培训过程，了解了如何使用按需实例和现场实例来培训模型。</li><li id="2e5b" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">与按需实例相比，使用spot实例的模型训练可以节省高达90%的训练模型的成本。</li><li id="0080" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">我们都知道机器学习是一个高度迭代的过程。当模型性能有所改进时，如何更新超参数并更新SageMaker模型端点。</li><li id="8ae3" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated">最后，我们必须清理SageMaker端点以避免收费。</li></ul><p id="1d51" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章的完整源代码可以在<a class="ae jc" href="https://github.com/Vinayaks117/AWS-SageMaker-Examples/blob/main/01_Train%2C%20Deploy%20and%20Update%20a%20Huggingface%20BERT%C2%A0model/BERT-Disaster-Tweets-Prediction.ipynb" rel="noopener ugc nofollow" target="_blank"> github repo </a>找到</p><p id="6695" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参考文献</strong></p><ul class=""><li id="0d9e" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb kj jz ka kb bi translated"><a class="ae jc" href="https://www.youtube.com/watch?v=D9Qo5OpG4p8" rel="noopener ugc nofollow" target="_blank">亚马逊SageMaker上的变形金刚和伯特介绍</a></li><li id="ec5a" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated"><a class="ae jc" href="https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html" rel="noopener ugc nofollow" target="_blank">使用PyTorch和SageMaker Python SDK </a></li><li id="19a8" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated"><a class="ae jc" href="https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-containers-frameworks-deep-learning.html" rel="noopener ugc nofollow" target="_blank">用于深度学习的预构建SageMaker Docker映像</a></li><li id="07aa" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated"><a class="ae jc" href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-checkpoints.html" rel="noopener ugc nofollow" target="_blank">使用亚马逊SageMaker中的检查点</a></li><li id="ce88" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb kj jz ka kb bi translated"><a class="ae jc" href="https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html" rel="noopener ugc nofollow" target="_blank">在亚马逊SageMaker管理现场培训</a></li></ul></div><div class="ab cl lc ld go le" role="separator"><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh li"/><span class="lf bw bk lg lh"/></div><div class="ha hb hc hd he"><p id="900c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢阅读！！如果你有任何问题，随时联系我。</p></div></div>    
</body>
</html>