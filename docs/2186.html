<html>
<head>
<title>Sentiment Analysis in Five Steps using AutoML</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用AutoML的五步情感分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sentiment-analysis-in-five-steps-using-automl-d16feeab2a36?source=collection_archive---------6-----------------------#2021-04-11">https://medium.com/analytics-vidhya/sentiment-analysis-in-five-steps-using-automl-d16feeab2a36?source=collection_archive---------6-----------------------#2021-04-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/4bc35b0c3036f4d254fa50e0dea74e41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sX8RTrKJUq18HMkWASl7vg.jpeg"/></div></div></figure><h1 id="e871" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">自动机器学习</h1><p id="7c69" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated"><strong class="jp hi">自动化机器学习</strong> ( <strong class="jp hi"> AutoML </strong>)是将机器学习应用于现实世界问题的任务自动化的过程。AutoML涵盖了从原始数据集到可部署的机器学习模型的完整管道。AutoML是作为一种基于人工智能的解决方案提出来的，以应对应用机器学习的日益增长的挑战。AutoML的高度自动化允许非专家利用机器学习模型和技术，而不需要他们成为机器学习专家。端到端应用机器学习的自动化过程还提供了产生更简单的解决方案、更快地创建这些解决方案以及通常优于手工设计模型的模型的优势。AutoML已用于比较预测模型中每个因素的相对重要性。</p><p id="df88" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">多年来，研究人员通过开发AutoKeras、AutoSklearn等工具，甚至是WEKA和H2o等无编码平台，开发出了自动化流程的方法。</p><p id="f616" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">一个这样的自动化领域是自然语言处理领域。随着AutoNLP的发展，现在用很少的基本代码行建立一个类似情感分析的模型并获得良好的输出是非常容易的。有了这样的自动化，它允许每个人都成为机器学习社区的一部分，而不是将机器学习仅限于开发人员和工程师。</p><p id="21d4" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在本文中，我们将学习<a class="ae kq" rel="noopener" href="/p/d16feeab2a36#5ba8">经典NPL </a>和<a class="ae kq" rel="noopener" href="/p/d16feeab2a36#94dc"> AutoNLP </a>，并使用AutoNLP实现一个带有twitter数据集的情感分析模型。</p><h2 id="181c" class="kr iq hh bd ir ks kt ku iv kv kw kx iz jy ky kz jd kc la lb jh kg lc ld jl le bi translated">如果您已经熟悉NLP的基础知识，请转到<a class="ae kq" rel="noopener" href="/p/d16feeab2a36#94dc">部分2 </a></h2><h1 id="5ba8" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated"><strong class="ak">第一部分</strong></h1><p id="cf4a" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated"><strong class="jp hi">什么是经典NLP？</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es lf"><img src="../Images/c1b610e297c98126079d46e8ed9140c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*ieNOCULRNoxA6EbqcjSTng.png"/></div></figure><p id="85d7" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">一般来说，在将文本数据输入到我们的模型中时，我们会执行一组过程来清理数据，然后将它们转换成数字格式。在进行自动化之前，我们先讨论其中的一些。</p><p id="3e26" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">一些文本预处理技术，</p><ul class=""><li id="d123" class="lk ll hh jp b jq kl ju km jy lm kc ln kg lo kk lp lq lr ls bi translated">标记化</li><li id="6533" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated">词汇化</li><li id="6e9c" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated">删除标点符号和停用词</li><li id="1327" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated">词性标注</li><li id="cef5" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated">实体识别</li></ul><p id="43bc" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">从非结构化文本数据中分析、解释和构建模型是数据科学家工作的重要组成部分。许多深度学习应用程序，如自然语言处理(NLP)，都围绕着文本数据的操作。</p><p id="3b76" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">例如，你是一家商业公司，推出了一个新网站或基于移动应用的服务。现在，您有了包含您产品的客户评论的数据，并且您希望使用机器学习算法对这些评论进行消费者情绪分析。</p><p id="72d5" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">然而，为了使这些数据结构化并在算法上可行，我们需要对其进行预处理。</p><p id="99af" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">因此，在这里我们将学习文本数据的各种基本预处理技术。我们将与Python中的<strong class="jp hi"> spaCy库</strong>合作，这是众多库(如<strong class="jp hi"> nltk </strong>、<strong class="jp hi"> gensim </strong>等)中的一个。)用于文本转换。</p><p id="35b9" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">标记化:</strong></p><p id="2d49" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">标记化是将文本分割成称为标记的片段的过程，同时忽略标点符号("、"、")等字符。, "!"等。)和空格。spaCy的功能允许我们通过两种方式来标记文本-</p><ul class=""><li id="1769" class="lk ll hh jp b jq kl ju km jy lm kc ln kg lo kk lp lq lr ls bi translated">单词标记化</li><li id="8019" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk lp lq lr ls bi translated">句子标记化</li></ul><p id="5035" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">下面是对我们的文本进行单词标记的示例代码。</p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="34fd" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">结果</h1><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="4eb9" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">注意我们是如何得到包含单词和标点符号的记号列表的。在这里，算法将像<strong class="jp hi">和</strong>这样的缩写识别为两个不同的单词；“are”和“‘nt’”。</p><p id="7848" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">如果我们愿意，我们也可以获得句子标记化(将文本分成句子)。然而，我们必须在“nlp”模块中包含一个预处理管道，以便它能够区分单词和句子。</p><p id="31c1" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">下面是对我们的文本进行句子标记的示例代码。</p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="9447" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">结果</h1><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="b29b" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">标记化是预处理中的一个基本步骤，它有助于区分单词或句子的边界，并为进一步的预处理技术(如词条化等)转换我们的文本。</p><h1 id="275e" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">词汇化:</h1><p id="0bc9" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">词汇化是自然语言处理中文本预处理的重要步骤。它处理单词的结构或形态分析，并将单词分解成基本形式或“词条”。<br/>例如，词语<em class="ma">行走</em>、<em class="ma">行走</em>、<em class="ma">行走</em>、<em class="ma">行走</em>表示共同的活动，即<em class="ma">行走</em>。由于它们有不同的拼写结构，我们的算法很难区别对待它们。因此，这些将在一个引理下处理。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div class="er es mb"><img src="../Images/995dc8e8c6907e57b61f1f8992ba6a83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/0*e7I1ALBf33RjV8Q1.jpg"/></div></figure><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mc"><img src="../Images/d29846f67d3af58377ad14305cca86f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GePBK0y5l-i34mze.jpg"/></div></div></figure><p id="d018" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们可以使用spaCy的内置方法对我们的文本进行词条化。</p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="c892" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">结果</h1><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="4ee1" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">你可以清楚地看到，像<em class="ma">运行</em>这样的词被分解成了它们的词条，即<em class="ma">运行</em>。词汇化极大地增强了我们的文本，以便更好更快地优化。</p><h1 id="e3c4" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">删除停用词</h1><p id="eea5" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">在处理文本数据时，我们会遇到许多对我们的分析没有太大用处的数据实例，因为它们对我们的数据没有任何意义/相关性。这些可以是代词(像<em class="ma">我</em>、<em class="ma">你</em>等。)或者像<em class="ma">是，是，曾经是</em>等词。</p><p id="16fb" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">这些字叫做<strong class="jp hi">停止字</strong>。我们可以使用spaCy中内置的停用词来过滤我们的文本。</p><p id="ac0d" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">spaCy的内置停用词表可以被视为如下-</p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="e12f" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">结果</h1><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="6b41" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">现在，我们可以使用token对象的“is_stop”属性从示例文本中过滤出停用词。</p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="4aef" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">结果</strong></p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="3179" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">你可以对比一下上面两个列表，注意到诸如<em class="ma"> down，the，with </em>和<em class="ma"> my </em>都被去掉了。现在，类似地，我们也可以使用字符串对象的“isalpha”方法和列表理解来删除文本中的标点符号。</p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="d53e" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">结果</strong></p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="6dcf" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">您可以观察到两个列表之间的差异。的确，空间使我们的工作变得相当容易。</p><h1 id="5fbf" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">词性标注</h1><p id="eb40" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">一个单词的<strong class="jp hi">词性</strong>定义了该单词在文档中的功能。例如，在文本<em class="ma">中，Robin是一个精明的程序员</em>,“Robin”是一个专有名词，而“精明”是一个形容词。</p><p id="0eed" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们将使用spacy的<strong class="jp hi"> en_core_web_sm </strong>模块进行词性标注。</p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="5c4b" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">结果</strong></p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="f867" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">谢谢你在文字处理上陪了我这么久。<br/>相信我，下一部分将会非常简单和强大，所有之前讨论过的步骤都将被自动处理，我们只需要传递原始文本数据。让我们深入了解AutoNLP:)</p><h1 id="94dc" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">第2部分:什么是AutoNLP？</h1><p id="2481" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">使用AutoML的概念，AutoNLP有助于自动化探索性数据分析的过程，如词干化、标记化、词条化等。它还有助于文本处理和为给定数据集选择最佳模型。AutoNLP是在AutoVIML下开发的，auto viml代表自动变体可解释ML。AutoNLP的一些功能包括:</p><ol class=""><li id="49f5" class="lk ll hh jp b jq kl ju km jy lm kc ln kg lo kk md lq lr ls bi translated"><strong class="jp hi">数据清理:</strong>整个数据集可以发送到模型，而无需执行任何过程，如矢量化。它甚至会自动填充缺失的数据并清理数据。</li><li id="59c4" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk md lq lr ls bi translated"><strong class="jp hi">使用特征工具库进行特征提取:</strong>特征工具是另一个很棒的库，可以帮助以任何简单的方式进行特征工程和提取。</li><li id="0532" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk md lq lr ls bi translated"><strong class="jp hi">模型性能和图形自动生成:</strong>只需设置verbose，即可显示模型图形和性能。</li><li id="5f0f" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk md lq lr ls bi translated"><strong class="jp hi">特征约简是自动的:</strong>对于庞大的数据集，选择最佳特征和执行EDA变得很困难。但这由AutoNLP负责。</li></ol><h1 id="bf74" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">AutoNLP的实施</h1><p id="3435" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">现在让我们使用autoNLP为twitter数据集实现一个情感分析模型。如果没有autoNLP，数据必须首先进行矢量化、词干化和词条化，最后在训练前转换为词云。但是有了autoNLP，我们只需要简单的五个步骤。</p><p id="8729" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">安装AutoNLP: </strong></p><p id="521b" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">要安装它，我们可以使用一个简单的pip命令。因为AutoNLP属于autoviml，所以我们需要安装它。</p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="815f" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">数据</strong><em class="ma">:</em><a class="ae kq" href="https://raw.githubusercontent.com/Vijayvj1/twitter-sentiment-analysis-1/master/train.csv" rel="noopener ugc nofollow" target="_blank"><em class="ma">https://raw . githubusercontent . com/vijayvj 1/Twitter-情操-分析-1/master/train.csv </em> </a></p><p id="b416" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">安装完成后，我们可以继续为项目下载数据集。我将使用twitter数据集，因为我们正在进行情感分析。完成后，让我们装载驱动器并查看我们的数据集。</p><blockquote class="me mf mg"><p id="80ef" class="jn jo ma jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">现在，一切就绪，让我们启动自动模式。是的，很简单，只有5个步骤..继续数。</p></blockquote><p id="acc2" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">第一步:</strong></p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div><figcaption class="mk ml et er es mm mn bd b be z dx translated">数据导入</figcaption></figure><p id="6eb5" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">第二步:</strong></p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div><figcaption class="mk ml et er es mm mn bd b be z dx translated">导入库并定义训练测试分割</figcaption></figure><p id="e008" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">第三步:</strong></p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div><figcaption class="mk ml et er es mm mn bd b be z dx translated">定义功能和目标</figcaption></figure><p id="d464" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">第四步:</strong></p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div><figcaption class="mk ml et er es mm mn bd b be z dx translated">自动NLP</figcaption></figure><p id="d4c0" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">现在你会看到一系列的图表，几分钟后你会看到训练输出。</p><p id="3a67" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">这些图表详细显示了训练过程中的可视化效果。它显示字数，密度和字符数以及。随着培训的进行，这些图表会发生变化，这是最终的输出。所有的标点符号和标签都会被自动删除，它们的密度也会显示在图表中。</p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mo"><img src="../Images/d2ff91022405728c2d2936b223863488.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pVVwd1px-9uDXzE9R5Zsvw.png"/></div></div><figcaption class="mk ml et er es mm mn bd b be z dx translated">自动NLP结果</figcaption></figure><blockquote class="me mf mg"><p id="102a" class="jn jo ma jp b jq kl js jt ju km jw jx mh kn ka kb mi ko ke kf mj kp ki kj kk ha bi translated">我们需要考虑n元语法、超参数优化、特征大小、算法选择等吗..,?没有自动NLP会照顾他们..，喝杯咖啡，直到他们结束！</p></blockquote><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mp"><img src="../Images/67e24373b17b4e22b3fe4905f44e043c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9ViaELjUjrjhKPFUj9NPYA.png"/></div></div><figcaption class="mk ml et er es mm mn bd b be z dx translated">NLP管道日志</figcaption></figure><p id="3da7" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">第五步:</strong></p><p id="d5de" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">最后，你可以做预测..是的，完成了！！</p><figure class="lg lh li lj fd ii"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="ba89" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">结论</h1><p id="f8ed" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">我们看到了如何使用AutoNLP使模型构建变得非常容易，从而执行情感分析。不仅如此，它还自动预处理数据，并为数据集的不同方面提供可视化。因此，自动化使得构建复杂的模型变得容易。</p><p id="94c6" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">如果你想了解更多关于机器学习的知识，请继续阅读我的博客:</p><ol class=""><li id="1438" class="lk ll hh jp b jq kl ju km jy lm kc ln kg lo kk md lq lr ls bi translated"><strong class="jp hi">音频数据增强:</strong><a class="ae kq" href="https://vijay-anandan.medium.com/lets-augment-a-audio-data-part-1-5ab5f6a87bae" rel="noopener">https://vijay-anandan . medium . com/lets-augment-a-Audio-Data-part-1-5a b5 f 6a 87 BAE</a></li><li id="8373" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk md lq lr ls bi translated"><strong class="jp hi">语音数据的情感分析:</strong><a class="ae kq" href="https://vijay-anandan.medium.com/sentiment-analysis-of-voice-data-64533a952617" rel="noopener">https://vijay-anandan . medium . com/personance-Analysis-of-Voice-Data-64533 a 952617</a></li><li id="22ee" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk md lq lr ls bi translated"><strong class="jp hi">对极度不平衡的数据集进行重采样:</strong><a class="ae kq" href="https://vijay-anandan.medium.com/how-to-resample-an-imbalanced-datasets-8e413dabbc21" rel="noopener">https://vijay-anandan . medium . com/how-to-re-sample-an-unbalanced-datasets-8e 413 dabb 21</a></li><li id="3c5e" class="lk ll hh jp b jq lt ju lu jy lv kc lw kg lx kk md lq lr ls bi translated"><strong class="jp hi">神经网络在深度学习中到底是如何工作的:</strong><a class="ae kq" rel="noopener" href="/analytics-vidhya/how-do-neural-networks-really-work-in-the-deep-learning-72f0e8c4c419">https://medium . com/analytics-vid hya/How-Do-Neural-Networks-Really-Work-in-the-Deep-Learning-72f 0 e 8 C4 c419</a></li></ol><p id="3cc6" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">【领英:<a class="ae kq" href="https://www.linkedin.com/in/vijay-anadan/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/vijay-anadan/</a></p><div class="mq mr ez fb ms mt"><a href="https://www.linkedin.com/in/vijay-anadan/" rel="noopener  ugc nofollow" target="_blank"><div class="mu ab dw"><div class="mv ab mw cl cj mx"><h2 class="bd hi fi z dy my ea eb mz ed ef hg bi translated">Vijay Anandan -助理工程师- Cognizant | LinkedIn</h2><div class="na l"><h3 class="bd b fi z dy my ea eb mz ed ef dx translated">好奇心驱动的数据科学家，渴望利用机器学习和数据分析来提取有意义的…</h3></div><div class="nb l"><p class="bd b fp z dy my ea eb mz ed ef dx translated">www.linkedin.com</p></div></div><div class="nc l"><div class="nd l ne nf ng nc nh in mt"/></div></div></a></div></div></div>    
</body>
</html>