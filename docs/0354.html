<html>
<head>
<title>How to detect an obsolete model?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何检测一个过时的模型？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-detect-an-obsolete-model-ac5a25f2fa54?source=collection_archive---------11-----------------------#2021-01-13">https://medium.com/analytics-vidhya/how-to-detect-an-obsolete-model-ac5a25f2fa54?source=collection_archive---------11-----------------------#2021-01-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="4069" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">你听说过协变量漂移吗？无论如何，本文将向您介绍它是什么，以及如何使用它来引起您对模型过时的注意</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/56e9bbe46eae513810a3d2092586f0af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fJfuRUicsWm9pE_k"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">图片由<a class="ae jm" href="https://unsplash.com/@araltasher?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Aral Tasher </a>在<a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="b848" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="kj">在现实世界中，用于训练模型的数据和用于预测的数据之间可能会发生很多变化。特别是如果训练和预测是在不同的时间范围内完成的话。这些变化是由协变量漂移现象定义的。它对应于训练集和预测集之间模型的解释变量的分布差异。</em></p><h2 id="4f8b" class="kk kl hh bd km kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">介绍</h2><p id="58d4" class="pw-post-body-paragraph jn jo hh jp b jq lf ii js jt lg il jv jw lh jy jz ka li kc kd ke lj kg kh ki ha bi translated">本文的目标不是给你一个详细的解决方案来克服你的模型过时，而只是如何检测它。事实上，这是第一步。</p><p id="a5c4" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">检测模型过时与检测协变量漂移直接相关。这意味着能够在某个值(称为<strong class="jp hi">漂移系数</strong>)达到某个阈值时发出警报。这个阈值可以任意选择。基于经验研究，您可以认为<strong class="jp hi">如果协变量的计算系数超过0.2 </strong>，则协变量会显著漂移。</p><p id="d9ee" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">协变量是模型用来预测目标值的变量。例如，当试图预测足球队在下一场比赛中的进球数(目标值)时，之前的进球数和获得的红牌数是协变量。这些值可能会随着时间的推移而改变，这取决于团队的表现。</p><p id="ec8c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为了计算协变量的漂移系数，有两种方法:</p><ul class=""><li id="bda8" class="lk ll hh jp b jq jr jt ju jw lm ka ln ke lo ki lp lq lr ls bi translated">使用统计指数</li><li id="e4be" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">使用统计模型</li></ul><p id="9826" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">对于这两种方法，其思想是测量两个样本之间特征的分布差异。第一个样本是训练集，第二个样本是预测集。</p><h2 id="d237" class="kk kl hh bd km kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">例子</h2><p id="363f" class="pw-post-body-paragraph jn jo hh jp b jq lf ii js jt lg il jv jw lh jy jz ka li kc kd ke lj kg kh ki ha bi translated">为了说明这两种方法，我们将使用一个包含汽车比赛信息的数据集。这个数据集允许一个模型根据不同的变量来预测一辆汽车是否会登上领奖台:汽车的速度，加速度，重量，操控性，牵引力，涡轮和比赛期间的天气。我们将关注那些作为预测模型协变量的变量。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ly"><img src="../Images/62af00c0673f1f285d8f03976b68fd58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qVSqLYAPxuS35AOza-gWVA.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">赛车数据集(640行x 8列)</figcaption></figure><p id="4233" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">首先，让我们导入实现这些方法所需的所有包。</p><pre class="ix iy iz ja fd lz ma mb mc aw md bi"><span id="e577" class="kk kl hh ma b fi me mf l mg mh">import seaborn as sns<br/>from sklearn.model_selection import train_test_split<br/>import pandas as pd<br/>import numpy as np</span></pre><p id="283d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">将数字特征和分类特征分开将是有用的。</p><pre class="ix iy iz ja fd lz ma mb mc aw md bi"><span id="27d6" class="kk kl hh ma b fi me mf l mg mh">numerical_features = ['speed', 'acceleration', 'weight', 'handling', 'traction', 'turbo']<br/>categorical_features = ['weather']</span></pre><p id="5c82" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">然后，从数据集创建两个样本。当然，在真实的用例中，您将使用您的人口样本(如果不是全部)和新收集的数据。</p><pre class="ix iy iz ja fd lz ma mb mc aw md bi"><span id="6ea6" class="kk kl hh ma b fi me mf l mg mh">train, test = train_test_split(df, test_size=0.3)</span></pre><p id="83b3" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在让我们画出每个特征的样本分布。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mi"><img src="../Images/f05801d5a762a7518b72f42405fe9b23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zC15wzVohki-8lt5FqG6NA.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">速度、重量和天气变化最大</figcaption></figure><p id="8c08" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">关于上面的图，我们可以看到速度、重量和天气这些变量在视觉上是漂移的。</p><p id="b96e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，我们将借助统计指数和机器学习方法，通过测量这些分布差异来了解如何自动检测它。</p><h2 id="eb4e" class="kk kl hh bd km kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">统计指数法</h2><p id="406f" class="pw-post-body-paragraph jn jo hh jp b jq lf ii js jt lg il jv jw lh jy jz ka li kc kd ke lj kg kh ki ha bi translated">在统计学中，<strong class="jp hi">群体稳定性指数</strong>用于衡量一个变量在两个不同样本中的分布差异。下面是公式:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mj"><img src="../Images/48de8084bd55fbea94a51174c5be3ccf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i2GD3p3yPDxSgPito0D4PA.jpeg"/></div></div></figure><p id="8399" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">更详细地说，实际百分比对应于第一个样本中某个类变量的百分比，而第二个样本中的预期百分比相同。要获得PSI，必须对所有classes变量的括号内表达式求和。</p><p id="eaa9" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这个公式可以很容易地应用于分类变量。</p><p id="5342" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">以下是分类特征PSI计算的实现:</p><pre class="ix iy iz ja fd lz ma mb mc aw md bi"><span id="b717" class="kk kl hh ma b fi me mf l mg mh">def calculate_psi_categorical(actual, expected):<br/>    actual_perc = actual.value_counts()/len(actual)<br/>    expected_perc = expected.value_counts()/len(expected)</span><span id="9b17" class="kk kl hh ma b fi mk mf l mg mh">    actual_classes = list(actual_perc.index) <br/>    expected_classes = list(expected_perc.index)</span><span id="eb57" class="kk kl hh ma b fi mk mf l mg mh">    PSI = 0<br/>    classes = set(actual_classes + expected_classes)</span><span id="fed2" class="kk kl hh ma b fi mk mf l mg mh">for c in classes:<br/>        final_actual_perc = actual_perc[c] if c in actual_classes else 0.00001<br/>        final_expected_perc = expected_perc[c] if c in expected_classes else 0.00001<br/>        PSI += (final_actual_perc - final_expected_perc)*np.log(final_actual_perc/final_expected_perc)</span><span id="e321" class="kk kl hh ma b fi mk mf l mg mh">    return PSI</span></pre><p id="be49" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">然而对于数字来说就变得更难了。事实上，我们需要一个有类的变量，这不是数字特征的情况。因此，为了将这些公式应用于数值变量，您需要将区间用作类。</p><p id="fc07" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">以下是使用统计指数方法获取数字特征漂移系数的步骤:</p><ul class=""><li id="f76f" class="lk ll hh jp b jq jr jt ju jw lm ka ln ke lo ki lp lq lr ls bi translated">将你的第一个样本分成指定数量的区间(对于小数据集至少比记录数量低10倍)</li><li id="910b" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">计算样本中每个间隔内记录百分比</li><li id="3537" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">获得所有区间的截止点</li><li id="4895" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">将截止点应用于第二个样本</li><li id="dc8d" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">计算样本中每个间隔内记录百分比</li><li id="d9be" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">根据记录值的百分比，用其中一个统计指标计算漂移系数</li></ul><p id="493a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为了计算数字特征的PSI，我建议你使用Matthew Burke在GitHub上提出的一个高效实现:<a class="ae jm" href="https://github.com/mwburke/population-stability-index/blob/master/psi.py" rel="noopener ugc nofollow" target="_blank">https://GitHub . com/MW Burke/population-stability-index/blob/master/PSI . py</a></p><p id="117a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">以下是赛车数据集的代码示例:</p><pre class="ix iy iz ja fd lz ma mb mc aw md bi"><span id="232e" class="kk kl hh ma b fi me mf l mg mh">psis = []</span><span id="a53b" class="kk kl hh ma b fi mk mf l mg mh">#Using the above implementation to compute PSI's categorical feature<br/>for feature_name in categorical_features:<br/>   <strong class="ma hi"> psi = calculate_psi_categorical(train[feature_name], test[feature_name])</strong><br/>    psis.append(psi)</span><span id="e5f4" class="kk kl hh ma b fi mk mf l mg mh">#Using the github implementation to compute PSI's numerical features<br/>for feature_name in numerical_features:<br/>   <strong class="ma hi"> psi = calculate_psi(train[feature_name], test[feature_name], buckettype='bins', buckets=buckets, axis=0)</strong><br/>    psis.append(psi)</span><span id="cd23" class="kk kl hh ma b fi mk mf l mg mh">#Plot each feature's PSI value<br/>height = psis<br/>bars = numerical_features<br/>y_pos = np.arange(len(bars))<br/>plt.barh(y_pos, height)<br/>plt.axvline(x=0.2,color='red')<br/>plt.yticks(y_pos, bars)<br/>plt.xlabel("PSI")<br/>plt.show()</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ml"><img src="../Images/522b54de20eb9ed30247e63d52f77433.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4O4xzcOjfPurOxlLedApYA.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">变量天气、重量和速度已超过漂移阈值</figcaption></figure><p id="5f95" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这种方法的一个巨大优点是计算速度快。然而，所获得的指数是没有界限的，PSI的范围在0和无穷大之间。</p><h2 id="2216" class="kk kl hh bd km kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">统计模型方法</h2><p id="9746" class="pw-post-body-paragraph jn jo hh jp b jq lf ii js jt lg il jv jw lh jy jz ka li kc kd ke lj kg kh ki ha bi translated">为了通过机器学习来检测协变量漂移，需要进行一些建模。</p><p id="9e4d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这个想法是建立一个模型，根据它的值来预测一个特征属于哪个样本。因此，该模型是一个二元分类模型，因为我们比较两个样本之间的特征分布。你也可能已经猜到了模型只由一个解释变量定义。</p><p id="04bb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">下面是使用机器学习方法的程序</p><ul class=""><li id="1760" class="lk ll hh jp b jq jr jt ju jw lm ka ln ke lo ki lp lq lr ls bi translated">在您的两个示例中添加一个新列“ORIGIN”</li><li id="d029" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">根据所属样本，如“训练”或“测试”,用标签填写“原点”</li><li id="4555" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">连接两个样本，使所有记录都在一个数据集中</li><li id="92e4" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">将数据集分为80%和20%两部分</li><li id="5143" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">用其中一个特征的最大集合训练一个模型来预测“起源”</li><li id="6836" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated">计算漂移系数:由于马太相关系数，基于最小集合评估你的模型</li></ul><p id="4316" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为了得到漂移系数，建议你使用Catboost算法。这种算法的优点是，您不必对模型的分类变量进行虚拟化，您将直接获得每个变量的一个漂移系数。在其他情况下，每个天气等级都有一个漂移系数。</p><p id="0ab6" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">下面是使用汽车比赛数据实现的方法:</p><pre class="ix iy iz ja fd lz ma mb mc aw md bi"><span id="5013" class="kk kl hh ma b fi me mf l mg mh">from catboost import Pool, CatBoostClassifier</span><span id="69aa" class="kk kl hh ma b fi mk mf l mg mh">mccs = []<br/>for feature_name in numerical_features+categorical_features:<br/>    is_categorical = feature_name == "weather"</span><span id="0c1f" class="kk kl hh ma b fi mk mf l mg mh">    train_dataset = Pool(data=lg_set[feature_name].to_numpy(),<br/>                         label=lg_set['ORIGIN'].to_numpy(),<br/>                         cat_features=[0] if is_categorical else [])</span><span id="f992" class="kk kl hh ma b fi mk mf l mg mh">    eval_dataset = Pool(data=sm_set[feature_name].to_numpy(),<br/>                         label=sm_set['ORIGIN'].to_numpy(),<br/>                         cat_features=[0] if is_categorical else [])</span><span id="f459" class="kk kl hh ma b fi mk mf l mg mh">    # Initialize CatBoostClassifier<br/>    model = CatBoostClassifier(iterations=10,<br/>                               learning_rate=0.2,<br/>                               depth=2,<br/>                               loss_function='Logloss',   auto_class_weights="Balanced")<br/>    # Fit model<br/>    model.fit(train_dataset)<br/>    # Get predicted classes<br/>    preds_class = model.predict(eval_dataset)</span><span id="5736" class="kk kl hh ma b fi mk mf l mg mh">mccs.append(matthews_corrcoef(sm_set['ORIGIN'].to_numpy(), preds_class))</span><span id="e0cc" class="kk kl hh ma b fi mk mf l mg mh">#Plot each feature's PSI value<br/>height = mccs<br/>bars = numerical_features+categorical_features<br/>y_pos = np.arange(len(bars))<br/>plt.barh(y_pos, height)<br/>plt.yticks(y_pos, bars)<br/>plt.axvline(x=0.2,color='red')<br/>plt.xlabel("PSI")<br/>plt.xlim(0,1)<br/>plt.show()</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mm"><img src="../Images/cb562c728d601bb6b72f36f3d9b3f800.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ldRS8xrHAvf1DCS1kH3qgg.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">变量天气、重量和速度已超过漂移阈值</figcaption></figure><p id="a26a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这种方法提供了一个有界漂移系数。MCC范围在-1和1之间。然而，与统计索引方法相比，为每个特征训练一个模型可能非常慢。</p><h2 id="7ceb" class="kk kl hh bd km kn ko kp kq kr ks kt ku jw kv kw kx ka ky kz la ke lb lc ld le bi translated">下一步是什么？</h2><p id="bb5f" class="pw-post-body-paragraph jn jo hh jp b jq lf ii js jt lg il jv jw lh jy jz ka li kc kd ke lj kg kh ki ha bi translated">使用上述方法之一获得每个特征的漂移系数后，您可以筛选出大于0.2的漂移系数。这将给你模型的漂移特征。</p><p id="98e2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在本文中，我们没有讨论协变量漂移对模型性能的影响，也没有考虑特征的重要性。当然，一个不太重要的特性会危险地漂移，它对性能的影响不会像一个非常重要的特性那样大。</p><p id="9359" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">检测到漂移特征后，您应该对其进行调查，并采取措施降低其对模型性能的影响。有时，在真实世界的用例中，隐含着一个收集问题。在这种情况下，您应该对漂移特征的采集方法进行修正。在其他情况下，改变学习方法、在更近的时间框架上重新训练模型、移除那些特征或者至少降低它们在模型中的重要性可以减少漂移影响。</p><p id="4a23" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">参考资料:</p><ul class=""><li id="2175" class="lk ll hh jp b jq jr jt ju jw lm ka ln ke lo ki lp lq lr ls bi translated"><a class="ae jm" href="https://www.lexjansen.com/wuss/2017/47_Final_Paper_PDF.pdf" rel="noopener ugc nofollow" target="_blank">https://www.lexjansen.com/wuss/2017/47_Final_Paper_PDF.pdf</a></li><li id="3a89" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated"><a class="ae jm" href="https://mwburke.github.io/data%20science/2018/04/29/population-stability-index.html" rel="noopener ugc nofollow" target="_blank">https://MW Burke . github . io/data % 20 science/2018/04/29/population-stability-index . html</a></li><li id="b425" class="lk ll hh jp b jq lt jt lu jw lv ka lw ke lx ki lp lq lr ls bi translated"><a class="ae jm" href="https://blog.bigml.com/2014/01/03/simple-machine-learning-to-detect-covariate-shift/" rel="noopener ugc nofollow" target="_blank">https://blog . bigml . com/2014/01/03/simple-machine-learning-to-detect-co variate-shift/</a></li></ul><p id="de24" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">感谢您的阅读！</strong></p></div></div>    
</body>
</html>