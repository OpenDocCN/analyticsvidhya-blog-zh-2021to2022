<html>
<head>
<title>Building a Classification Model using Pyspark in Databricks.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Databricks中使用Pyspark构建分类模型。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-a-classification-model-using-pyspark-in-databricks-909646147b57?source=collection_archive---------7-----------------------#2021-07-15">https://medium.com/analytics-vidhya/building-a-classification-model-using-pyspark-in-databricks-909646147b57?source=collection_archive---------7-----------------------#2021-07-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/8514e4bb403068c4dce21141440a21bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:844/format:webp/1*aT4xgrRqhGqbRvTpSssQAw.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自谷歌图片。</figcaption></figure><p id="ca03" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一种解决方案可以是……。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es jo"><img src="../Images/b4a2ef3d61bc61e674e60dad33fbc926.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tKzr_QiZXYEzWFsh30K76Q.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片来自谷歌</figcaption></figure><p id="bcf5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">大数据，大数据无处不在，设计和建模的并行化是一个解决方案。如今许多工具和技术正在被使用。为了参与到这个数据解决方案的旅程中来，作为我好奇心的一部分，我试图深入研究PySpark( Python + Spark)和databricks。因此，我开始学习机器学习设计的步骤和方法。</p><p id="060d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">虽然这是我第一次使用PySpark设计模型，但我发现它非常有趣，而且与数据科学领域相关。让我们来看看分类的简单演示。</p><p id="8428" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">数据集</strong>:数据集是从Kaggle平台上采集的。下面是链接:【https://www.kaggle.com/uciml/glass<a class="ae jx" href="https://www.kaggle.com/uciml/glass" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="0725" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">问题陈述</strong>:问题陈述是利用给定的矿物浓度作为独立特征对玻璃的种类进行分类。目标变量是“类型”。嗯，我们可以使用任何工具设计模型，对于使用Databricks平台来说，这个模型可能非常小，但是为了让它进行试验，我选择从它开始。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es jy"><img src="../Images/fde46a93ea1531f11bfddbd64c78b5ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xn6meB4bnhoMQR35ry0-_g.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图片:数据集的一瞥</figcaption></figure><p id="6b6c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">在数据砖块平台中执行</strong></p><p id="84fc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了执行设计过程，我使用了免费的Databricks社区版本。</p><p id="0c5b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> a)获取数据</strong></p><p id="d495" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一旦我们将数据上传到数据砖平台，并创建一个集群。我们可以轻易拿到笔记本。笔记本的以下命令块显示了文件位置、类型以及正在读入数据帧(df)的数据。当我们提到inferSchema=True时，数据帧中的特征被推断为它们的对应类型。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es jz"><img src="../Images/b2d0d1d7e7dda291dcccb96df705b850.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LneVQmDWBwRmZCHfWK0p5g.png"/></div></div></figure><p id="786b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这就是数据在笔记本中的显示方式。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es ka"><img src="../Images/2a2a8f8cd529a73d9f2d7e4dbee89447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvxPJYKwNDv9nSahMZnftQ.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">图像:数据块中的数据集</figcaption></figure><p id="b1ca" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> b)数据理解</strong></p><p id="9122" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">printSchema()显示了数据的细节。除了目标变量是整数之外，其他变量都是双精度类型。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es kb"><img src="../Images/3fea3b5e4b39402792140513e824f29f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*ELay3IhvZdF9TymDQgRrEg.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">数据类型</figcaption></figure><p id="1a7a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在下面的代码片段中，显示了“Type”中标签的变量中不同值的数量。因此，我们知道数据集中记录了六种类型的眼镜。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es kc"><img src="../Images/bd5305337f1ddc617aa122110d4e5bad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*P9Z8ti1fzRwvhdjr6RM3EQ.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">dataframe的类型变量的不同值</figcaption></figure><p id="b8f2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> c)数据组装和转换</strong></p><p id="088e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用VectorAssembler对用于预测的特征进行分组，这里所有独立特征(矿物浓度)作为输入列给出，我们得到一个包含每个样本的特征向量的列。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kd"><img src="../Images/b27b591e9b1c92024a2adb0a488d0c76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XCh-5rkBWuwieSI2ZGTjYA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">使用矢量汇编程序</figcaption></figure><p id="e11d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">从上面我们可以看出，浓度的值是变化的，因此使用特征库中的MinMaxScaler()来归一化值的分布，如下所示。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es ke"><img src="../Images/97e02b4d93b9cba9188c86e828f1aaac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7KG25t99ETwumodDGOK7qg.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">价值观的正常化</figcaption></figure><p id="b17a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下图显示了要素标准化后输出的显示方式。注意:这一步只是提供使用PySpark的规范化技术的知识。一般来说，在使用树模型(接下来将在下一节中出现)时，我们不需要对特性进行缩放，因为基于树的算法是基于面向分区创建的。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kf"><img src="../Images/a997e1be9545b004a105db2aaecdf8e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y2SqgiPYwIOELuPWZ7eABw.png"/></div></div></figure><p id="c154" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">正如我们所知，目标变量被推断为整数，但实际上它们本质上是分类的，因此我在特性上使用StringIndexer()来标记它，如下所示。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kg"><img src="../Images/57a0fac2ce6ca290314e0edd510b2d54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kQ6BkA1dlMiBRzaJaZpRzA.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">数据转换</figcaption></figure><p id="5909" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将所有转换后的标注与原始要素进行比较，以检查是否有任何遗漏。</p><p id="071b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> d)数据分割</strong></p><p id="18a7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">使用PySpark库的randomSplit()命令将数据分成75%的训练数据和25%的测试数据。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es kh"><img src="../Images/3091dc26a498f77ff70bfcf88c7c8fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*IT-nnek4nhgK1OYKM5IzNw.png"/></div></figure><p id="ad9f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下图显示了训练数据中要素的数据类型。在测试数据中也发现了类似的情况。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div class="er es ki"><img src="../Images/7e647ccdd075b473e405974234fdf836.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*cHnBUKXOMimDiotEE2mEVw.png"/></div></figure><p id="9e38" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> e)模型分类和评价。</strong></p><p id="cc63" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了保持模型简单，我使用了maxdepth=10的RandomForest分类器。我们可以使用Pyspark的Mlib包中定义的任何模型。下面的代码片段显示了随机森林分类器的初始化，以及如何使用rfModel.transform()对测试数据进行预测</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kj"><img src="../Images/5687f3802946665281e56828742a4db2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hnuQv0D3OdVzBkaMpVQKvQ.png"/></div></div><figcaption class="im in et er es io ip bd b be z dx translated">模型设计和预测</figcaption></figure><p id="9ba8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">模型建立后，pyspark有一个评估库，我们可以根据问题陈述和模型类型从中选择任何评估者。在这里，模型是在准确性的基础上进行评估的，尽管我在这里只展示了一个演示的准确性，我还检查了模型预测的“f1得分”和“精确度”。两个分数都显示了大约0.86的值。在第一次尝试中，模型评估的准确度约为0.857。labelCols字段将包含要预测的列名。</p><figure class="jp jq jr js fd ij er es paragraph-image"><div role="button" tabindex="0" class="jt ju di jv bf jw"><div class="er es kk"><img src="../Images/386386f7763f8a4490d31d3c9557f4e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8v1zSnycf40cLQHHINx-xA.png"/></div></div></figure><p id="d069" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这是我第一次尝试使用PySpark和databricks，但是了解数据以及如何在各种环境中使用数据真的很好。任何建设性的反馈都是最受欢迎的！！！。</p></div></div>    
</body>
</html>