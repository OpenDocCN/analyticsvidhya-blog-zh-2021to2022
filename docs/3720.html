<html>
<head>
<title>Evaluation Metrics for Classification Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">分类模型的评估标准</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/evaluation-metrics-for-classification-models-e2f0d8009d69?source=collection_archive---------1-----------------------#2021-07-20">https://medium.com/analytics-vidhya/evaluation-metrics-for-classification-models-e2f0d8009d69?source=collection_archive---------1-----------------------#2021-07-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="f086" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">评估分类模型时广泛使用的最常见指标</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/40303049dfd6ee620d2bfec015411bcc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*drpRquRpCdsT8Y7W"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">Ernesto Velázquez 在<a class="ae jn" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><h1 id="8884" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated">介绍</h1><p id="b41c" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">评估指标用于衡量模型的质量。机器学习最重要的课题之一就是如何评估你的模型。当你建立你的模型时，衡量它预测你的预期结果有多准确是非常重要的。</p><p id="5a6d" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">对于不同的机器学习算法，我们有不同的评估指标。对于评估分类模型，我们使用分类度量，对于评估回归模型，我们使用回归度量。在本文中，我将只讨论分类指标。在我们深入研究评估指标之前，让我们先谈谈一些基础知识:</p></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="44b5" class="jo jp hi bd jq jr lo jt ju jv lp jx jy io lq ip ka ir lr is kc iu ls iv ke kf bi translated">一些热身:……</h1><p id="b138" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">对于<strong class="ki hj">监督的</strong>和<strong class="ki hj">非监督的</strong>机器学习算法，都有各种评估指标。</p><p id="fe0a" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated"><strong class="ki hj">监督学习</strong> -我们已经标记了输入，任务是通过训练模型来预测标记的输出。这些算法进一步分为两类:分类和回归</p><ul class=""><li id="f33f" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated"><strong class="ki hj">分类:</strong>根据一些输入，预测一个类别。<strong class="ki hj"> </strong>这些问题试图将一个数据点归类到一个特定的类别/类中。这里，目标结果将是一个离散/分类值，如是/否、垃圾邮件/非垃圾邮件等。例如，客户是否会拖欠贷款。</li><li id="ac48" class="lt lu hi ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated"><strong class="ki hj">回归:</strong>根据一些输入，预测某个数字。这些问题使用输入变量，通过仅使用训练数据来预测连续值。在这里，目标结果总是数量/实际值，如时间序列数据、销售数字、身高、体重等。例如，他们客户的预期违约金额或房屋价格是多少？</li></ul><p id="3187" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated"><strong class="ki hj">无监督学习</strong>——这些算法帮助我们分析和聚类未标记的数据集。我们没有任何目标标签。这些算法帮助我们发现数据中隐藏的模式。</p><p id="970a" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated"><strong class="ki hj">训练/验证/测试分割:</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mh"><img src="../Images/e36f4c70cf6270e41f08cc283b254e72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*kNv1ue6w7axeQI2y.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://datascience.stackexchange.com/questions/61467/clarification-on-train-test-and-val-and-how-to-use-implement-it" rel="noopener ugc nofollow" target="_blank"> Stackexchange </a></figcaption></figure><p id="0cde" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">在我们深入研究指标之前，我们有一定的<strong class="ki hj">模型评估程序</strong>。我们需要知道一个模型对样本外数据的概括能力有多强。</p><ul class=""><li id="64ef" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated"><strong class="ki hj">在相同的数据上训练和测试:</strong>当你在相同的数据上训练和测试时，你将会过度拟合训练数据，它也不会泛化。</li></ul><blockquote class="mi mj mk"><p id="9d8c" class="kg kh ml ki b kj lc ij kl km ld im ko mm le kr ks mn lf kv kw mo lg kz la lb hb bi translated">评估模型时，最好不要在整个数据集上训练模型。</p></blockquote><ul class=""><li id="96cb" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated"><strong class="ki hj">训练和测试分割:</strong>典型的训练/测试分割是将70%的数据用于训练，30%的数据用于测试。评估您的模型以找到模型的最佳参数很重要，但我们不能使用此测试集进行评估，因为我们得到的参数可能是最佳的，但不一定能很好地概括。</li></ul><blockquote class="mi mj mk"><p id="4803" class="kg kh ml ki b kj lc ij kl km ld im ko mm le kr ks mn lf kv kw mo lg kz la lb hb bi translated">最好将数据分成两部分，即训练集和测试集。最好将数据分成三部分，即训练、验证和测试集。</p></blockquote><ul class=""><li id="959b" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated"><strong class="ki hj">训练/验证/测试分割:</strong>为了在构建和调整模型的同时评估您的模型，我们需要创建第三个子集，即验证集。这种划分是将60%的数据用于训练，20%的数据用于验证，20%的数据用于测试。验证集用于评估具有不同超参数值的模型的性能。它还用于检测训练阶段的过度拟合。</li></ul><blockquote class="mi mj mk"><p id="03bf" class="kg kh ml ki b kj lc ij kl km ld im ko mm le kr ks mn lf kv kw mo lg kz la lb hb bi translated">在进行分割之前打乱数据是很有用的，这样每个分割都可以准确地表示数据。</p></blockquote><p id="cd3e" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">让我们深入研究一下指标。</p></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="694a" class="jo jp hi bd jq jr lo jt ju jv lp jx jy io lq ip ka ir lr is kc iu ls iv ke kf bi translated">为什么我们需要评估指标？</h1><p id="aede" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">评估指标可以帮助您评估模型的性能，监控生产中的ML系统，并控制模型以满足您的业务需求。</p><p id="9bbe" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">我们的目标是创建和选择一个对样本外数据给出高精度的模型。使用多个评估指标来评估您的模型是非常重要的，因为一个模型可能使用一个评估指标的一个度量表现良好，而使用另一个评估指标的另一个度量表现不佳。</p></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="be1b" class="jo jp hi bd jq jr lo jt ju jv lp jx jy io lq ip ka ir lr is kc iu ls iv ke kf bi translated">分类评估指标</h1><p id="ac6e" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">在这里，我将讨论一些用于评估模型的常见分类指标。</p><h1 id="389a" class="jo jp hi bd jq jr js jt ju jv jw jx jy io jz ip ka ir kb is kc iu kd iv ke kf bi translated"><strong class="ak">分类精度:</strong></h1><p id="ea62" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">模型评估最简单的标准是准确性。它是一个数据集的正确预测数与预测总数的比率。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mp"><img src="../Images/40629460341298dd120c6d36c12c3060.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/0*DIEn1lXhNseGGAco.gif"/></div></figure><blockquote class="mi mj mk"><p id="fdf2" class="kg kh ml ki b kj lc ij kl km ld im ko mm le kr ks mn lf kv kw mo lg kz la lb hb bi translated">当目标类平衡良好时，精度是有用的，但对于不平衡的类，精度不是一个好的选择。</p></blockquote><p id="8ccd" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">例如，有两个目标类的数据集包含100个样本。在我们的训练数据中，98个样本属于A类，2个样本属于B类，我们的模型将给我们98%的准确率。这就是为什么我们需要查看更多的指标来获得更好的结果。</p><p id="ad5b" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这里，我们用python实现了准确性:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/4784762de1ad77871d3aa561f2845ede.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q8ZsH-sUjc4XOV_FMcMcqg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">计算精确度</figcaption></figure><p id="050b" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">准确性让我们对模型预测的可信度有了一个总体的了解。这一指标无视错误类别和类型之间的差异。这就是为什么它对不平衡数据集不够好的原因。</p></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="701f" class="jo jp hi bd jq jr lo jt ju jv lp jx jy io lq ip ka ir lr is kc iu ls iv ke kf bi translated">对数损失或对数损失:</h1><p id="98c7" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">当分类器的输出是数字概率而不是类标签时，可以使用Log Loss。对数损失衡量的是来自使用预测器而非真实标签的额外噪声的不可预测性。</p><p id="6a49" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated"><strong class="ki hj">二元分类器的对数损失:</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mr"><img src="../Images/8eff7b87b39de16396c7a39b0597fc13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ty7D6fffk6Tn5-fr.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://stackoverflow.com/questions/58776695/how-to-calculate-the-log-loss-metric-in-scala-spark" rel="noopener ugc nofollow" target="_blank"> Stackoverflow </a></figcaption></figure><p id="40fc" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated"><strong class="ki hj">多类分类的测井损失:</strong></p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ms"><img src="../Images/39cc3cc9cf28e261fea0b07624b1eb27.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/0*OIMdQ5UWmj7rlc2n.gif"/></div></div></figure><p id="efaa" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">考虑，N个样本属于M类。在哪里，</p><p id="a98b" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">y_ij表示样本I是否属于类j</p><p id="e2c0" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">p_ij表示样本I属于类j的概率</p><h2 id="f460" class="mt jp hi bd jq mu mv mw ju mx my mz jy kp na nb ka kt nc nd kc kx ne nf ke ng bi translated">它是如何工作的？</h2><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mr"><img src="../Images/b047a210fb8c6e264c705ba275110525.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*r83ICDHSxAfNyMEg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated"><a class="ae jn" href="https://emilyswebber.github.io/LogLoss/" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><p id="151c" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">上图是实际(目标)和预测的概率。</p><ul class=""><li id="8bb0" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated">上图描绘了一个糟糕的预测，因为实际概率和预测概率之间的巨大差异给我们带来了巨大的对数损失。在这里，函数惩罚模型确信的错误答案。</li><li id="eabb" class="lt lu hi ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">下图描绘了一个很好的预测，因为预测的概率接近实际概率，这给了我们一个小的对数损失。这里，该函数奖励模型确信的正确答案。</li></ul><p id="fb03" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">对数损失没有上限，它存在于范围[0，∞)内。最小化日志损失为分类器提供了更高的准确性。</p><p id="a675" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这里，我们有一个日志丢失的scikit-learn实现:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/46817f6bc92d004771a154d130a1f546.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aVjk4v4btCnXvuKay-X5RQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">计算日志损失</figcaption></figure></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="5ee3" class="jo jp hi bd jq jr lo jt ju jv lp jx jy io lq ip ka ir lr is kc iu ls iv ke kf bi translated">混淆矩阵:</h1><p id="f7ca" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">混淆矩阵或错误矩阵是一个表格，它显示了与测试集中的实际分类相比，模型做出的正确和错误预测的数量，或者正在出现的错误类型。</p><p id="6c87" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">此矩阵描述了分类模型对真实值已知的测试数据的性能。它是一个n*n矩阵，其中n是类的数量。这个矩阵可以在对测试数据进行预测之后生成。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nh"><img src="../Images/350099e1e00f4b33913e03aeff3b2854.png" data-original-src="https://miro.medium.com/v2/resize:fit:1398/0*l30v6Id3wZrw8FAO"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://alearningaday.blog/2016/09/14/confusion-matrix/" rel="noopener ugc nofollow" target="_blank">alearningday</a></figcaption></figure><p id="4679" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这里，列表示测试数据中实际分类的计数，而行表示模型预测分类的计数。</p><blockquote class="mi mj mk"><p id="d989" class="kg kh ml ki b kj lc ij kl km ld im ko mm le kr ks mn lf kv kw mo lg kz la lb hb bi translated">让我们以一个分类问题为例，我们预测一个人是否患有糖尿病。让我们给目标变量一个标签:</p><p id="abd5" class="kg kh ml ki b kj lc ij kl km ld im ko mm le kr ks mn lf kv kw mo lg kz la lb hb bi translated"><strong class="ki hj"> 1: </strong>一个人有糖尿病| <strong class="ki hj"> 0: </strong>一个人没有糖尿病</p></blockquote><p id="824d" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">执行分类预测时，可能会出现四种结果:</p><ul class=""><li id="58d1" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated"><strong class="ki hj">真阳性(TP): </strong>实际阳性和预测阳性的结果数。</li></ul><p id="3f02" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">例如:在这种情况下，一个人实际上患有糖尿病(1)，而模型预测此人患有糖尿病(1)。</p><ul class=""><li id="e8df" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated"><strong class="ki hj">真阴性(TN): </strong>实际阴性和预测阴性的结果数。</li></ul><p id="72e8" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">例如:在这种情况下，一个人实际上没有糖尿病(0)，而模型预测这个人没有糖尿病(0)。</p><ul class=""><li id="6e71" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated"><strong class="ki hj">假阳性(FP): </strong>实际为阴性但预测为阳性的结果数。这些错误也被称为<strong class="ki hj">1型错误。</strong></li></ul><p id="8b43" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">例如:在这种情况下，一个人实际上没有糖尿病(0)，但模型预测此人患有糖尿病(1)。</p><ul class=""><li id="56a8" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated"><strong class="ki hj">假阴性(FN): </strong>实际阳性但预测为阴性的结果数。这些错误也被称为<strong class="ki hj">类型2错误。</strong></li></ul><p id="2132" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">例如:在这种情况下，一个人实际上患有糖尿病(1)，但模型预测此人没有糖尿病(0)。</p><p id="464a" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">正反指的是预测本身。真假是指预测的正确性。</p><p id="ea3c" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这里，我们有一个混淆矩阵的scikit-learn实现:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/f50f8a136fe445d134cb45ce08dc340a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hxd_NCZJsj9luELMJWMN3Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">计算混淆矩阵</figcaption></figure><blockquote class="mi mj mk"><p id="7850" class="kg kh ml ki b kj lc ij kl km ld im ko mm le kr ks mn lf kv kw mo lg kz la lb hb bi translated">来自Scikit-learn官方文档:</p><p id="c7d3" class="kg kh ml ki b kj lc ij kl km ld im ko mm le kr ks mn lf kv kw mo lg kz la lb hb bi translated">对角线元素表示预测标签等于真实标签的点的数量，而非对角线元素是那些被分类器错误标记的点。混淆矩阵的对角线值越高越好，表明有许多正确的预测。</p></blockquote><h2 id="5bad" class="mt jp hi bd jq mu mv mw ju mx my mz jy kp na nb ka kt nc nd kc kx ne nf ke ng bi translated">我们可以从混淆矩阵中得到4个分类指标:</h2><h2 id="d9c3" class="mt jp hi bd jq mu mv mw ju mx my mz jy kp na nb ka kt nc nd kc kx ne nf ke ng bi translated">1.)精度:</h2><p id="e52a" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">也可以根据二元分类的正和负来计算:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ni"><img src="../Images/c8cb7643143ff26de4d87d01d73cba39.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/0*fGfNMrQjBae4mP9C.png"/></div></figure><p id="ff7d" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">它没有给我们太多关于假阳性和假阴性分布的信息。</p><p id="fdf5" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这里是一个scikit-learn实现的准确度分数:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/e4d676eb7bb27c76fcff22f53967177d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BX8RaRWYg5gHLNNiA-5_cQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">计算准确度分数</figcaption></figure><h2 id="2517" class="mt jp hi bd jq mu mv mw ju mx my mz jy kp na nb ka kt nc nd kc kx ne nf ke ng bi translated">2.)精度或阳性预测值(PPV):</h2><p id="e0c9" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">它是真阳性与模型预测的所有阳性的比率。这对于倾斜和不平衡的数据集非常有用。模型预测的假阳性越多，精确度就越低。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nj"><img src="../Images/e93917503cddfc91fdffbc8ddc6878eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/0*CmLJJbuJtBS1CA5D.png"/></div></figure><p id="bd3a" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">例如，我们对20名患者进行了医学测试，测试发现其中8人患有该疾病。在通过测试识别的8个中，5个实际上患有该疾病(真阳性)，而另外3个没有(假阳性)。我们后来发现，该测试遗漏了另外4名被证明患有该疾病的患者(假阴性)。</p><p id="556b" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这些值是TP=5，FP=3，FN=4，TN=8。</p><p id="f751" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">精度= 5/5+3 = 0.625</p><p id="2aff" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这是一个scikit-learn实现的Precision:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/d8ee3b4b17b9fc9a13ef2ea53f17e36f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YybmlMGoihSXOLEs3xkq_A.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">计算精确度分数</figcaption></figure><h2 id="1b7d" class="mt jp hi bd jq mu mv mw ju mx my mz jy kp na nb ka kt nc nd kc kx ne nf ke ng bi translated">3.)回忆或敏感度或真阳性率(TPR):</h2><p id="1297" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">它是真阳性与数据集中所有阳性的比率。它测量模型检测阳性样本的能力。模型预测的假阴性越多，召回率就越低。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nk"><img src="../Images/5b3b61fecb603fdaefc6870fdb499cea.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/0*kqF3PhMMNaMWDnlr.png"/></div></figure><p id="7c27" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">根据前面的精度示例，值为TP=5，FP=3，FN=4，TN=8。</p><p id="e5f3" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">回忆= 5/5+4 = 0.56</p><p id="10e1" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">下面是一个scikit-learn实现的回忆:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/881db5c95794c6fbc400cb25762600a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bOYGrUvQsMhsjtYtL16RqA.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">计算召回分数</figcaption></figure><ul class=""><li id="9ce7" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated">精度考虑了阳性和阴性样本的分类方式，但召回在其计算中仅考虑阳性样本。换句话说，精确度依赖于负样本和正样本，但是召回率仅依赖于正样本(并且独立于负样本)。</li><li id="9324" class="lt lu hi ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">精度考虑样本何时被分类为<em class="ml">阳性</em>，但不关心正确分类<em class="ml">所有</em>阳性样本。召回关心的是正确分类<em class="ml">所有</em>阳性样本，但不关心一个阴性样本是否被分类为阳性。</li></ul><h2 id="12ca" class="mt jp hi bd jq mu mv mw ju mx my mz jy kp na nb ka kt nc nd kc kx ne nf ke ng bi translated">4.)F1-得分或F-测量:</h2><p id="ea90" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">这是一个结合了精确度和召回率的单一指标。F1分数越高，我们模型的性能越好。F1分数的范围是[0，1]。</p><p id="72fb" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">F1分数是精确度和召回率的加权平均值。只有在精确度和召回率都很高的情况下，分类器才会得到高F值。该指标只支持具有相似精度和召回率的分类器。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nl"><img src="../Images/12026f0426130e6f3f8cbc80f4f61c78.png" data-original-src="https://miro.medium.com/v2/resize:fit:848/format:webp/0*QTxXh0usOzRsgK1i.png"/></div></figure><p id="22b1" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">这是F1分数的scikit-learn实现:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/1d414f8177d156be403836b2d69138d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uzrq3A1siQBe7QnIv_KxZw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">计算f1分数</figcaption></figure><h2 id="c82e" class="mt jp hi bd jq mu mv mw ju mx my mz jy kp na nb ka kt nc nd kc kx ne nf ke ng bi translated">特例:因子为β的F分数</h2><p id="c07f" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">F1分数是总体F分数的一般化情况。总体F分数有一个因子β，它定义了精确度/召回率对评估的影响程度:</p><ul class=""><li id="dbbc" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated">β &lt; 1: Precision oriented evaluation</li><li id="e3dc" class="lt lu hi ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">β &gt; 1:面向回忆的评价</li></ul><p id="8256" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">F1分数是一个广义的情况，其中β是1，意味着精确度和召回率是平衡的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nm"><img src="../Images/dcbaeec6582d23aca2602f41035b9918.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/0*69fFb9DQro6ShxZj.png"/></div></figure><p id="73cf" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">下面是F-beta分数的scikit-learn实现:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/aa0ef01d3d13ca2f2360ba600350a4bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*c3tnjGYXUL3eJaFraLJ3OQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">计算fbeta分数</figcaption></figure></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="f01f" class="jo jp hi bd jq jr lo jt ju jv lp jx jy io lq ip ka ir lr is kc iu ls iv ke kf bi translated">ROC曲线:</h1><p id="1f52" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated"><strong class="ki hj"> ROC曲线(接收器操作特性曲线)</strong>是示出分类模型的性能的曲线图。对于我们的预测模型，这是一种使用不同的决策阈值(用于决定预测是标记为“真”还是“假”的阈值)来可视化真阳性率(TPR)和假阳性率(FPR)之间的权衡的方法。</p><p id="9259" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">该阈值用于控制TPR和FPR之间的权衡。提高阈值通常会提高精确度，但会降低召回率。</p><p id="3b35" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">首先，让我们看看TPR和FPR:-</p><ul class=""><li id="3725" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated"><strong class="ki hj">真阳性率(TPR /灵敏度/召回率):</strong>真阳性率对应于所有阳性数据点中被正确认为是阳性的阳性数据点的比例。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es nn"><img src="../Images/c5b81e7670b30455a19eef4675fcf77e.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/0*eo8DI2xhCfceyWEn.gif"/></div></figure><ul class=""><li id="53a1" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated"><strong class="ki hj">假阳性率(FPR): </strong>假阳性率对应于所有阴性数据点中被误认为阳性的阴性数据点的比例。</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es no"><img src="../Images/5eacad19eb01051852aade3ac999a6ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/0*xpo4Rz9LQXmyZfBV.png"/></div></figure><p id="e706" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">它们都具有在[0，1]范围内的值，这些值是在不同的阈值下计算的。</p><blockquote class="mi mj mk"><p id="6bbc" class="kg kh ml ki b kj lc ij kl km ld im ko mm le kr ks mn lf kv kw mo lg kz la lb hb bi translated">完美的分类器将具有高的真阳性率值和低的假阳性率值。</p></blockquote><p id="65f0" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">下面是代表更精确模型的ROC曲线:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es np"><img src="../Images/664288d2a93778d4d886481531f23cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/0*CR1L_wNQbbzEU1Ej.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:<a class="ae jn" href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" rel="noopener ugc nofollow" target="_blank">维基百科</a></figcaption></figure><ul class=""><li id="48db" class="lt lu hi ki b kj lc km ld kp lv kt lw kx lx lb ly lz ma mb bi translated">任何ROC曲线在随机猜测分类器线上的模型都可以被认为是更好的模型。</li><li id="463e" class="lt lu hi ki b kj mc km md kp me kt mf kx mg lb ly lz ma mb bi translated">任何ROC曲线低于随机猜测分类器线的模型都可以被断然拒绝。</li></ul><p id="e827" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">该曲线绘制了不同分类阈值下的TPR和FPR，但是这是低效的，因为我们必须在不同的阈值下评估我们的模型。有一种有效的基于排序的算法可以为我们提供这些信息，这就是AUC。</p><p id="9bdd" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">下面是ROC曲线的scikit-learn实现:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/493741e821d2bdf5db8fe2977cf67d66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QX_9LxCT7sBpWVztOZ5HGg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">计算ROC曲线</figcaption></figure></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="28a1" class="jo jp hi bd jq jr lo jt ju jv lp jx jy io lq ip ka ir lr is kc iu ls iv ke kf bi translated">AUC:</h1><p id="127f" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">一个<strong class="ki hj"> AUC(曲线下面积)</strong>或ROC曲线下面积，因此该术语是roc_auc的简称。</p><p id="84fd" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">AUC是一种通过使用单个数字来总结图表的指标。它用于二进制分类问题。</p><p id="c94f" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">注意:AUC是在曲线上给出点的函数。</p><blockquote class="mi mj mk"><p id="ba16" class="kg kh ml ki b kj lc ij kl km ld im ko mm le kr ks mn lf kv kw mo lg kz la lb hb bi translated">AUC等于分类器对随机正例的排序高于随机负例的概率。</p></blockquote><p id="76d0" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">以下是AUC的scikit-learn实现:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mq"><img src="../Images/bdedcffbf9d1ef93bad50efb510de6d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ecC-Q_McMi60gv9FrIyb3Q.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">计算AUC</figcaption></figure><p id="f4e0" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">AUC有助于比较不同的模型，因为它总结了整个ROC曲线的数据。AUC的范围是[0，1]。值越大，我们模型的性能越好。</p></div><div class="ab cl lh li gp lj" role="separator"><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm ln"/><span class="lk bw bk ll lm"/></div><div class="hb hc hd he hf"><h1 id="ac62" class="jo jp hi bd jq jr lo jt ju jv lp jx jy io lq ip ka ir lr is kc iu ls iv ke kf bi translated">结论</h1><p id="db4d" class="pw-post-body-paragraph kg kh hi ki b kj kk ij kl km kn im ko kp kq kr ks kt ku kv kw kx ky kz la lb hb bi translated">在这篇文章中，我们学到了很多东西。我们了解到，准确性只是模型性能的一部分，尤其是当数据不平衡或误报影响较大时，反之亦然。我们讨论了其他一些被广泛使用的通用指标。</p><p id="30af" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">查看scikit-learn官方文档，了解本文未涉及的其他指标。</p><p id="7b17" class="pw-post-body-paragraph kg kh hi ki b kj lc ij kl km ld im ko kp le kr ks kt lf kv kw kx lg kz la lb hb bi translated">sci kit-learn:<a class="ae jn" href="https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics" rel="noopener ugc nofollow" target="_blank">https://sci kit-learn . org/stable/modules/model _ evaluation . html # class ification-metrics</a></p></div></div>    
</body>
</html>