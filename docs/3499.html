<html>
<head>
<title>Cross Validation in Machine Learning using StatsModels and Sklearn with Logistic Regression Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用StatsModels和Sklearn与逻辑回归示例在机器学习中进行交叉验证</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cross-validation-in-machine-learning-using-python-4d0f335bec83?source=collection_archive---------3-----------------------#2021-07-05">https://medium.com/analytics-vidhya/cross-validation-in-machine-learning-using-python-4d0f335bec83?source=collection_archive---------3-----------------------#2021-07-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="742d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本教程中，我们将学习什么是机器学习中的交叉验证，以及如何使用<code class="du jc jd je jf b">StatModels</code>和<code class="du jc jd je jf b">Sklearn</code>包在python中实现。</p><figure class="jh ji jj jk fd jl er es paragraph-image"><div role="button" tabindex="0" class="jm jn di jo bf jp"><div class="er es jg"><img src="../Images/55626d47413f108a3418717ee06b607b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5fnn2iyhBOOealAsDSk1JQ.jpeg"/></div></div></figure><h2 id="2397" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">什么是交叉验证，为什么我们需要它？</h2><p id="efd3" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">交叉验证是机器学习中的一种重采样方法。为了理解交叉验证，我们需要首先回顾训练错误率和测试错误率之间的区别。</p><p id="a155" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">训练错误率</strong>是由训练模型的相同数据产生的平均错误(分类问题中的错误分类率)。</p><p id="a5a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相比之下，<strong class="ig hi">测试错误率</strong>是对未知测试数据集(也称为验证数据集)使用训练模型产生的平均错误</p><p id="99b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在没有测试数据的情况下，我们无法判断我们的模型在看不见的数据上是否同样有效，这是任何机器学习问题的最终目标。当拟合/训练的模型用于看不见的数据时，使用测试数据来估计平均误差的过程被称为交叉验证。简而言之，我们在看不见的数据上交叉验证我们的预测，因此命名为“交叉验证”</p><h2 id="1e27" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">交叉验证的类型</h2><p id="ab37" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">交叉验证有三种主要类型。一些文章提到bootstrap是一种交叉验证方法，但我个人不认为bootstrap是一种交叉验证方法。</p><ul class=""><li id="e18e" class="kt ku hh ig b ih ii il im ip kv it kw ix kx jb ky kz la lb bi translated">验证集方法</li></ul><p id="fa05" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种方法是最简单的。只需将数据分为两部分，即训练数据集和测试数据集。在训练数据集上训练您的模型，并在测试数据集上运行验证。这种方法可能会有问题，因为您假设您的测试数据代表整个数据，这在实践中可能会被违反。因此，您的测试误差估计可能非常不稳定。此外，由于机器学习方法往往在较少的观察值上训练时表现更差，这表明验证集错误率可能倾向于高估测试错误率。</p><ul class=""><li id="4aab" class="kt ku hh ig b ih ii il im ip kv it kw ix kx jb ky kz la lb bi translated">留一交叉验证:</li></ul><p id="4555" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">顾名思义，您在训练模型时会从训练数据中留下一个观察值。从技术上来说，这种方法和上面的一样，但是在你的测试数据集中只有一行。不同的是，您通过运行for循环重复这个实验，并在每次迭代中取1行作为测试数据，得到尽可能多的行的测试误差，最后取误差的平均值。理想情况下，您应该运行n次for循环(其中n =样本大小)。此时，您已经可以识别这里的问题了。当您的数据很大时，这种方法可能非常低效。</p><ul class=""><li id="e96c" class="kt ku hh ig b ih ii il im ip kv it kw ix kx jb ky kz la lb bi translated">k倍交叉验证:</li></ul><p id="ca30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是上述两种类型的混合体。我们将数据分成k个折叠，并运行k次for循环，每次将一个折叠作为每次迭代的测试数据集，并最终计算平均错误率(或准确度)。</p><p id="99a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将在本教程中使用验证集方法和k-Fold。</p><h1 id="5c77" class="lc jt hh bd ju ld le lf jy lg lh li kc lj lk ll kf lm ln lo ki lp lq lr kl ls bi translated">应用</h1><p id="5928" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">让我们动手做一些编码工作。你兴奋吗？</p><p id="86bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我也是！</p><h2 id="cf2e" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">问题设置</h2><p id="6fff" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">我们将使用心脏数据集，使用数据集中的所有预测因子来预测心脏病发作的概率。在这样做的时候，我们还想使用交叉验证来估计该部分中描述的逻辑回归模型的测试误差。</p><h2 id="40bb" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">数据集信息:</h2><p id="68de" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">我从机器学习和智能系统中心获取了这个数据集</p><p id="c3b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae lt" href="https://archive.ics.uci.edu/ml/datasets/Heart+Disease" rel="noopener ugc nofollow" target="_blank">https://archive.ics.uci.edu/ml/datasets/Heart+Disease</a></p><p id="ac07" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">。该数据库包含76个属性，但所有发表的实验都提到使用其中14个属性的子集。特别是，克利夫兰数据库是迄今为止唯一被ML研究人员使用的数据库。“目标”字段是指患者是否存在心脏病。它是从0(不存在)到4的整数值。“目标”字段是指患者是否存在心脏病。这是一个整数值，0 =没有心脏病发作的可能性/可能性较小，1 =心脏病发作的可能性较大。</p><p id="5c34" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">属性信息:</strong></p><p id="3647" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">仅使用了14个属性:</p><ol class=""><li id="9aea" class="kt ku hh ig b ih ii il im ip kv it kw ix kx jb lu kz la lb bi translated">第三名(年龄)</li><li id="393e" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">#4(性)</li><li id="3e09" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">#9 (cp)</li><li id="ff48" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">第十名(trestbps)</li><li id="07bf" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">#12 (chol)</li><li id="319c" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">第16位</li><li id="1474" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">第19名(休息心电图)</li><li id="9708" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">第32位(塔拉奇)</li><li id="f7ca" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">第38名(exang)</li><li id="85ed" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">第40名(旧峰)</li><li id="7723" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">#41(坡度)</li><li id="3f4d" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">第44名(加拿大)</li><li id="0ed8" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">第51名</li><li id="9086" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb lu kz la lb bi translated">#58(目标)(预测属性)</li></ol><p id="2a5f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，该数据集有一些缺失数据。为了简单起见，我们将只尝试<em class="ks">完整的案例分析</em>。</p><pre class="jh ji jj jk fd ma jf mb mc aw md bi"><span id="13c1" class="js jt hh jf b fi me mf l mg mh">import pandas as pd<br/>import numpy as np</span><span id="6afb" class="js jt hh jf b fi mi mf l mg mh">df = pd.read_csv('heart.csv')</span><span id="89ff" class="js jt hh jf b fi mi mf l mg mh">df.head()</span></pre><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="ab fe cl mj"><img src="../Images/48cc8342345be181c95ea4e775deaadd.png" data-original-src="https://miro.medium.com/v2/format:webp/1*6pQhZfVrApLHjlqQ_eimSw.png"/></div></figure><h2 id="cc06" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">使用统计模型的物流回归模型</h2><p id="2bdc" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">查看初始模型拟合的最简单和更优雅的方式(与<code class="du jc jd je jf b">sklearn</code>相比)是使用<code class="du jc jd je jf b">statsmodels</code>。我喜欢它只用一行代码生成的摘要报告。</p><pre class="jh ji jj jk fd ma jf mb mc aw md bi"><span id="4d43" class="js jt hh jf b fi me mf l mg mh">from statsmodels.formula.api import logit</span><span id="2cd6" class="js jt hh jf b fi mi mf l mg mh">fit_logit = logit("target ~ age + sex + cp + trestbps +	chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal", df).fit()</span><span id="e104" class="js jt hh jf b fi mi mf l mg mh">print(fit_logit.summary())</span><span id="4660" class="js jt hh jf b fi mi mf l mg mh">Optimization terminated successfully.<br/>         Current function value: 0.348904<br/>         Iterations 7<br/>                           Logit Regression Results                           <br/>==============================================================================<br/>Dep. Variable:                 target   No. Observations:                  303<br/>Model:                          Logit   Df Residuals:                      289<br/>Method:                           MLE   Df Model:                           13<br/>Date:                Sun, 04 Jul 2021   Pseudo R-squ.:                  0.4937<br/>Time:                        19:07:27   Log-Likelihood:                -105.72<br/>converged:                       True   LL-Null:                       -208.82<br/>Covariance Type:            nonrobust   LLR p-value:                 7.262e-37<br/>==============================================================================<br/>                 coef    std err          z      P&gt;|z|      [0.025      0.975]<br/>------------------------------------------------------------------------------<br/>Intercept      3.4505      2.571      1.342      0.180      -1.590       8.490<br/>age           -0.0049      0.023     -0.212      0.832      -0.050       0.041<br/>sex           -1.7582      0.469     -3.751      0.000      -2.677      -0.839<br/>cp             0.8599      0.185      4.638      0.000       0.496       1.223<br/>trestbps      -0.0195      0.010     -1.884      0.060      -0.040       0.001<br/>chol          -0.0046      0.004     -1.224      0.221      -0.012       0.003<br/>fbs            0.0349      0.529      0.066      0.947      -1.003       1.073<br/>restecg        0.4663      0.348      1.339      0.181      -0.216       1.149<br/>thalach        0.0232      0.010      2.219      0.026       0.003       0.044<br/>exang         -0.9800      0.410     -2.391      0.017      -1.783      -0.177<br/>oldpeak       -0.5403      0.214     -2.526      0.012      -0.959      -0.121<br/>slope          0.5793      0.350      1.656      0.098      -0.106       1.265<br/>ca            -0.7733      0.191     -4.051      0.000      -1.147      -0.399<br/>thal          -0.9004      0.290     -3.104      0.002      -1.469      -0.332<br/>==============================================================================</span></pre><h2 id="0703" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">简要模型解释</h2><p id="aef3" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">我们看到<code class="du jc jd je jf b">sex, cp, thalach, exang, oldpeak, ca, and thal</code>变量与心脏病发作显著相关(在这个问题上我们没有推断出因果关系)。</p><h2 id="d054" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">使用验证数据集方法的交叉验证</h2><p id="1f6c" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">让我们将数据分成两组，即训练和测试</p><pre class="jh ji jj jk fd ma jf mb mc aw md bi"><span id="1d3c" class="js jt hh jf b fi me mf l mg mh">from sklearn.model_selection import train_test_split</span><span id="e32c" class="js jt hh jf b fi mi mf l mg mh"># splitting our dataset into train and test datasets.</span><span id="272e" class="js jt hh jf b fi mi mf l mg mh">train, test = train_test_split(df, test_size = 0.3, random_state = 1)</span></pre><p id="5057" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们在训练数据上拟合模型，看看测试错误率。</p><pre class="jh ji jj jk fd ma jf mb mc aw md bi"><span id="c921" class="js jt hh jf b fi me mf l mg mh">fit_logit_train = logit("target ~ age + sex + cp + trestbps + chol + fbs + restecg + thalach + exang + oldpeak + slope + ca + thal", train).fit()</span><span id="d8ec" class="js jt hh jf b fi mi mf l mg mh">train_pred = fit_logit_train.predict(test)<br/><br/># converting probability to labels</span><span id="e2d1" class="js jt hh jf b fi mi mf l mg mh">def convert_prob_to_label(prob, cutoff = 0.5):<br/>    label = None<br/>    if prob &gt; cutoff:<br/>        label = 1<br/>    else:<br/>        label = 0<br/>    return label<br/><br/>pred_labels = list(map(convert_prob_to_label, train_pred))<br/>pred_labels = np.asarray(pred_labels)</span><span id="4ad2" class="js jt hh jf b fi mi mf l mg mh">Optimization terminated successfully.<br/>         Current function value: 0.317208<br/>         Iterations 8</span><span id="db88" class="js jt hh jf b fi mi mf l mg mh">from sklearn.metrics import confusion_matrix<br/>conf_matrix = confusion_matrix(test.target, pred_labels)</span></pre><p id="3a1e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从上面的混淆矩阵，我们可以计算错误分类率为</p><pre class="jh ji jj jk fd ma jf mb mc aw md bi"><span id="e643" class="js jt hh jf b fi me mf l mg mh">mis_rate = (conf_matrix[[1],[0]].flat[0] + conf_matrix[[0],[1]].flat[0])/len(test)</span><span id="572e" class="js jt hh jf b fi mi mf l mg mh">print(f"Misclassification rate = {mis_rate :.3f}")</span></pre><blockquote class="mk ml mm"><p id="ad3e" class="ie if ks ig b ih ii ij ik il im in io mn iq ir is mo iu iv iw mp iy iz ja jb ha bi translated">错误分类率= 0.220</p></blockquote><p id="e060" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们得到了一个误差率为22%的好模型。请注意，我们没有运行任何模型选择(模型选择超出了本文的范围)。然而，这种测试错误分类率可能是由于机会，并可能取决于测试数据。因此，我们可能高估了测试错误率。为了获得更稳定的测试误差/错误分类率的估计，我们可以使用k-fold交叉验证。</p><h2 id="683d" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">使用Sklearn的k-Fold交叉验证</h2><p id="62c1" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">当运行k-Fold交叉验证时，我们需要注意两个关键参数。</p><ul class=""><li id="c84c" class="kt ku hh ig b ih ii il im ip kv it kw ix kx jb ky kz la lb bi translated">折叠的次数:我们需要知道折叠的次数。实际上，对于中等大小的数据，5到10倍就足够了。过多的折叠可能会导致结果的高度变化。</li><li id="4fe0" class="kt ku hh ig b ih lv il lw ip lx it ly ix lz jb ky kz la lb bi translated">重复次数:我们可以根据需要多次进行实验。根据我们现有的计算能力，我们可以在这里选择一个大的数字。这里越大越好。</li></ul><p id="1718" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于这个特定的问题，我在100次试验中使用KFold交叉验证五次来计算平均错误分类率。</p><p id="92ba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">**请注意，统计模型没有自己的交叉验证库。**</p><pre class="jh ji jj jk fd ma jf mb mc aw md bi"><span id="12c7" class="js jt hh jf b fi me mf l mg mh">from sklearn.model_selection import RepeatedKFold<br/>from sklearn.linear_model import LogisticRegression<br/>from sklearn.model_selection import cross_val_score<br/>X = df.loc[ : , ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']]<br/>y = df[['target']]<br/><br/>cv = RepeatedKFold(n_splits=5, n_repeats= 100, random_state=1)<br/>model = LogisticRegression()<br/><br/># getting misclassification rate<br/>scores = 1 - cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)</span><span id="b8b2" class="js jt hh jf b fi mi mf l mg mh">import seaborn as sns<br/>ax = sns.histplot(x=scores, kde=True)</span></pre><figure class="jh ji jj jk fd jl er es paragraph-image"><div class="ab fe cl mj"><img src="../Images/df5549afaa99335eb565b1bf8bcea02c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*cZ0O5Y8O0kGJwDtIvHXtGg.png"/></div></figure><p id="5bc2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的直方图清楚地向我们展示了测试误差的可变性。与其提供单一的测试误差估计值，不如提供测试误差的平均值和标准误差，以便做出决策。</p><h2 id="9c05" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">结论</h2><pre class="jh ji jj jk fd ma jf mb mc aw md bi"><span id="41b0" class="js jt hh jf b fi me mf l mg mh">print(f"Mean of misclassification error rate in test date is, {np.mean(scores) : .3f} with standard deviation = {np.std(scores) : .4f} ")</span></pre><blockquote class="mk ml mm"><p id="a9db" class="ie if ks ig b ih ii ij ik il im in io mn iq ir is mo iu iv iw mp iy iz ja jb ha bi translated">测试数据中错误分类错误率的平均值为0.167，标准偏差= 0.0424</p></blockquote><p id="af29" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总之，我们的错误分类率是16.7%。在本文中，我们了解了交叉验证如何帮助我们获得稳定且更稳健的测试误差估计。在下一篇博客中，我们将使用bootstrap方法做类似的事情。</p></div></div>    
</body>
</html>