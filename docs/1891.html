<html>
<head>
<title>Deep Learning: Creating an Image Classifier using PyTorch with CIFAR-10</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习:使用PyTorch和CIFAR-10创建图像分类器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-learning-creating-an-image-classifier-using-pytorch-with-cifar-10-f603659722b2?source=collection_archive---------5-----------------------#2021-03-24">https://medium.com/analytics-vidhya/deep-learning-creating-an-image-classifier-using-pytorch-with-cifar-10-f603659722b2?source=collection_archive---------5-----------------------#2021-03-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/870cfad768e92033b0f7a925e4975743.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D1Ad88vyJeknpF2Jq4VK1g.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated"><a class="ae it" href="https://www.futura-sciences.com/tech/definitions/intelligence-artificielle-deep-learning-17262/" rel="noopener ugc nofollow" target="_blank">https://www . Futura-sciences . com/tech/definitions/intelligence-artifielle-deep-learning-17262/</a></figcaption></figure><blockquote class="iu iv iw"><p id="e0a9" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ha bi translated">请注意，本文分为两部分。第一部分，也就是你现在正在阅读的部分，是关于创建图像分类器的。第二部分是关于模型的操作和部署。你可以在这里找到<a class="ae it" rel="noopener" href="/analytics-vidhya/deep-learning-loading-and-operationalizing-our-model-13c4da002225">。本文末尾提供了更多的信息。谢谢！</a></p></blockquote><p id="2231" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">起初，这些人工智能，机器学习，深度学习的东西听起来像一些机器代码之类的东西，很可怕。如果这就是你现在的处境，那么我也曾经是你的处境。在做了一些工作后，我发现这并不可怕。希望在你读完之后，你会同意我的观点。</p><p id="b05b" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">在这篇文章中，我们将着眼于建立一个图像分类器。耶！你说对了，图像分类器。不要害怕，我们会经历所有的步骤，肯定会很有趣。</p><p id="5e95" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">我们将PyTorch nn模块用于在CIFAR-10数据上训练和测试我们的模型。CIFAR代表加拿大高级研究所。10代表数据集中包含的10类图像，即:飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船、卡车。所以基本上我们的模型将能够处理这些项目。你可以从<a class="ae it" href="https://www.kaggle.com/pankrzysiu/cifar10-python" rel="noopener ugc nofollow" target="_blank"> kaggle </a>下载数据集。</p></div><div class="ab cl jz ka go kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="ha hb hc hd he"><blockquote class="iu iv iw"><p id="8d49" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ha bi translated">你可以看看其他的数据集。请随意查看<a class="ae it" href="https://pytorch.org/vision/stable/datasets.html#torchvision-datasets" rel="noopener ugc nofollow" target="_blank">这里的</a>。</p><p id="8be8" class="ix iy iz ja b jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv ha bi translated">也有一些预训练的模型。到目前为止，在CIFAR-10数据集上训练和测试的性能最好的模型是<a class="ae it" href="https://arxiv.org/pdf/1811.06965.pdf" rel="noopener ugc nofollow" target="_blank"> GPipe </a>，准确率为99.0%。本文的目的不是要击败这种准确性，我们只是想让自己动手构建自己的内部神经网络。</p></blockquote></div><div class="ab cl jz ka go kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="ha hb hc hd he"><p id="a0f4" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">当涉及到构建神经网络时，主要包括三个步骤；</p><ul class=""><li id="b0a5" class="kg kh hh ja b jb jc jf jg jw ki jx kj jy kk jv kl km kn ko bi translated">准备和探索我们的数据</li><li id="6e33" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated">建设和培训以及</li><li id="7666" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated">测试。</li></ul><h1 id="b3ed" class="ku kv hh bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">准备和探索</h1><p id="d20c" class="pw-post-body-paragraph ix iy hh ja b jb ls jd je jf lt jh ji jw lu jl jm jx lv jp jq jy lw jt ju jv ha bi translated">重要的是，我们要看到我们处理的是什么样的数据。然后，我们必须将数据分成两部分，一部分用于训练，另一部分用于测试。通常是80%比20%，但这取决于你。</p><p id="e09f" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">下面是必要的导入，以便我们加载和划分数据。</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="0418" class="mg kv hh mc b fi mh mi l mj mk">import torchvision</span><span id="01d1" class="mg kv hh mc b fi ml mi l mj mk">import torchvision.transforms as transforms</span></pre><p id="4e33" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">然后，我们创建集合和加载器</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="9914" class="mg kv hh mc b fi mh mi l mj mk">data_dir = './data' # directory of the cifar-10 data you downloaded</span><span id="e4a5" class="mg kv hh mc b fi ml mi l mj mk">transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])<br/></span><span id="c3dd" class="mg kv hh mc b fi ml mi l mj mk">trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)</span><span id="4ba3" class="mg kv hh mc b fi ml mi l mj mk">train_loader = torch.utils.data.DataLoader(trainset, batch_size=5, shuffle=True, num_workers=2)</span><span id="b95f" class="mg kv hh mc b fi ml mi l mj mk">testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)</span><span id="0c41" class="mg kv hh mc b fi ml mi l mj mk">test_loader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False, num_workers=2)</span><span id="29b7" class="mg kv hh mc b fi ml mi l mj mk"># The 10 classes in the dataset<br/>classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')</span></pre><p id="2629" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">现在，让我们研究一下训练集和测试集的数据…</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="b4f2" class="mg kv hh mc b fi mh mi l mj mk"># to get the length of the taindata<br/>print(len(trainset))</span><span id="a9fb" class="mg kv hh mc b fi ml mi l mj mk"># get sample of train data and see length<br/>sample = next(iter(trainset))<br/>print(len(sample))</span><span id="8063" class="mg kv hh mc b fi ml mi l mj mk"># get the image and it's label<br/>image, label = sample<br/>print(type(image))<br/>print(type(label))</span><span id="2bc2" class="mg kv hh mc b fi ml mi l mj mk"># view image shape<br/>image.shape</span><span id="677b" class="mg kv hh mc b fi ml mi l mj mk"># length of test data<br/>print(len(testset))</span></pre><p id="b5ef" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">现在我们已经看到了一些基本的统计数据，让我们来看看来自训练和测试加载器的一些图片</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="8341" class="mg kv hh mc b fi mh mi l mj mk">import matplotlib.pyplot as plt<br/>import numpy as np</span><span id="f6aa" class="mg kv hh mc b fi ml mi l mj mk"># train_loader images<br/>dataiter = iter(train_loader)<br/>batch = next(dataiter)<br/>labels = batch[1][0:5]<br/>images = batch[0][0:5]</span><span id="ce54" class="mg kv hh mc b fi ml mi l mj mk">for i in range(5):<br/>    print(classes[labels[i]])<br/>    image = images[i].numpy()<br/>    plt.imshow(np.rot90(image.T, k=3))<br/>    plt.show()</span><span id="d45e" class="mg kv hh mc b fi ml mi l mj mk"># test_loader images<br/>dataiter = iter(test_loader)<br/>batch = next(dataiter)<br/>labels = batch[1][0:5]<br/>images = batch[0][0:5]</span><span id="e813" class="mg kv hh mc b fi ml mi l mj mk">for i in range(5):<br/>    print(classes[labels[i]])<br/>    image = images[i].numpy()<br/>    plt.imshow(np.rot90(image.T, k=3))<br/>    plt.show()</span></pre><p id="a162" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">此时，我们至少在一定程度上了解了我们的数据。喜欢的话可以多探索。</p><h1 id="b9f1" class="ku kv hh bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">建造和训练</h1><p id="dfe6" class="pw-post-body-paragraph ix iy hh ja b jb ls jd je jf lt jh ji jw lu jl jm jx lv jp jq jy lw jt ju jv ha bi translated">既然我们已经探索了我们的数据，让我们建立我们的模型。为了刷新，nn是不同层的组合，以提出ur架构。你可以在这里探索不同的torch.nn图层<a class="ae it" href="https://pytorch.org/docs/stable/nn.html" rel="noopener ugc nofollow" target="_blank">。如果我们必须在这里讨论不同的层和它们的功能，这确实是一个很长的话题，所以我鼓励你看看</a><a class="ae it" href="https://pytorch.org/docs/stable/nn.html" rel="noopener ugc nofollow" target="_blank">这个链接</a>来了解更多关于它们的信息。为了不让事情变得复杂，我将与你分享我的架构(经过一些改进)。可以随意修改和探索。</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="a9d9" class="mg kv hh mc b fi mh mi l mj mk">import torch<br/>import torch.nn as nn<br/>import torch.nn.functional as F</span><span id="e46f" class="mg kv hh mc b fi ml mi l mj mk">class Net(nn.Module):<br/>    def __init__(self):<br/>        super(Net, self).__init__()<br/>        self.conv1 = nn.Conv2d(3, 32, 3)<br/>        self.conv2 = nn.Conv2d(32, 64, 3)<br/>        self.conv3 = nn.Conv2d(64, 128, 3)<br/>        self.pool = nn.MaxPool2d(2, 2)<br/>        self.fc1 = nn.Linear(128 * 2 * 2, 128)<br/>        self.fc2 = nn.Linear(128, 64)<br/>        self.fc3 = nn.Linear(64, 32)<br/>        self.fc4 = nn.Linear(32, 10)<br/>        self.dropout1 = nn.Dropout(p=0.2, inplace=False)</span><span id="ece3" class="mg kv hh mc b fi ml mi l mj mk">    def forward(self, x):<br/>        x = self.pool(F.relu(self.conv1(x)))<br/>        x = self.dropout1(x)<br/>        x = self.pool(F.relu(self.conv2(x)))<br/>        x = self.dropout1(x)<br/>        x = self.pool(F.relu(self.conv3(x)))<br/>        x = self.dropout1(x)<br/>        x = x.view(-1, 128 * 2 * 2)<br/>        x = F.relu(self.fc1(x))<br/>        x = F.relu(self.fc2(x))<br/>        x = F.relu(self.fc3(x))<br/>        x = self.fc4(x) #output layer<br/>        <br/>        return x</span></pre><p id="9aed" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">现在让我们实例化模型类。</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="4290" class="mg kv hh mc b fi mh mi l mj mk">model = Net()</span></pre><p id="825f" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">我相信你一定听说过GPU。如果不是仍然很酷。GPU(图形处理单元)主要用于游戏电脑，以提供高视频处理能力。我们希望利用这一强大的资源来训练我们的模型。其实并不是一定要用GPU。CPU是可以工作的，只是它慢很多，需要更多的时间来训练和测试。花那么多时间也可能会影响模型的性能。</p><p id="c198" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">因此，我们将检查运行代码的当前机器上是否存在GPU，否则，我们使用CPU。</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="606f" class="mg kv hh mc b fi mh mi l mj mk">device = 'cuda' if torch.cuda.is_available() else 'cpu'<br/>model.to(device)</span></pre><p id="4ddd" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">我们现在指定我们的损失函数。神经网络使用随机梯度下降进行预训练，因此我们必须选择一个损失函数，这将有助于优化。这让人困惑吗？如果是这样，我鼓励你看看<a class="ae it" href="https://machinelearningmastery.com/loss-and-loss-functions-for-training-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>，里面讨论了损失函数。此外，你可以看看其他一些损失函数，你可以在这里使用<a class="ae it" href="https://ruder.io/optimizing-gradient-descent/" rel="noopener ugc nofollow" target="_blank"/>。</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="38c5" class="mg kv hh mc b fi mh mi l mj mk">criterion = nn.CrossEntropyLoss()</span><span id="49ca" class="mg kv hh mc b fi ml mi l mj mk"># Stochastic gradient descent: to perform parameter update for each training sample<br/>optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)</span></pre><p id="e101" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">现在我们可以开始模型的训练了。</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="ee24" class="mg kv hh mc b fi mh mi l mj mk">epoch_losses = [] # using this to record the training loss so that we can plot it against the epoch</span><span id="c96f" class="mg kv hh mc b fi ml mi l mj mk">model.train()<br/>for epoch in range(20):<br/>    running_loss = 0.0<br/>    saved_loss = 0.0</span><span id="8b22" class="mg kv hh mc b fi ml mi l mj mk">    for i, data in enumerate(train_loader, 0):<br/>        # get inputs and labels and convert to appropriate device<br/>        inputs, labels = data<br/>        inputs, labels = inputs.to(device), labels.to(device)<br/>        <br/>        # zero the parameter gradients<br/>        optimizer.zero_grad()</span><span id="3017" class="mg kv hh mc b fi ml mi l mj mk">        outputs = model(inputs)<br/>        loss = criterion(outputs, labels)<br/>        loss.backward()<br/>        optimizer.step()<br/>        <br/>        # print stats<br/>        running_loss += loss.item()<br/>        if i % 2000 == 1999:  # print every 2000 mini-batches<br/>            print('%d, %5d| loss: %.3f' %(epoch+1, i+1, running_loss/2000))<br/>            saved_loss = running_loss<br/>            running_loss = 0.0<br/>    epoch_losses.append(saved_loss/10000)<br/>print('Training done!')  # print when finished training</span></pre><p id="2b3b" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">请随意花些时间看看上面的代码，以防乍一看不太清楚。</p><p id="8fba" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">现在让我们画一个图表，显示我们的训练损失和时期。</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="f875" class="mg kv hh mc b fi mh mi l mj mk">epochs = range(1,21)</span><span id="a343" class="mg kv hh mc b fi ml mi l mj mk">plt.plot(epochs, epoch_losses, 'g', label='Training loss')<br/>plt.title('Trainingloss')<br/>plt.xlabel('Epochs')<br/>plt.ylabel('Loss')<br/>plt.legend()<br/>plt.show()</span></pre><p id="8e30" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">让我给你看一个曲线应该是什么样子的例子:</p><figure class="lx ly lz ma fd ii er es paragraph-image"><div class="er es mm"><img src="../Images/770ed5fdddaf50e2d185742de258a95a.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*lxrsCkyKx4UTj9uqF5B2gQ.png"/></div></figure><p id="9922" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">注意曲线是如何趋近于零的。损失越低，模型预测得越好。通常，曲线上的最低点是模型可以很好预测的地方。如果曲线开始增加，这意味着我们的模型是过度拟合。通常，在曲线开始增加的情况下，我们调整时期的数量，以便我们的模型只训练诅咒最低的时期的数量。这样，我们可以为我们的模型获得一些好的性能(准确性)。</p><p id="465b" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">就我而言，我只训练了20个纪元。从我的曲线来看，它表明曲线有可能变低(减少损失)，从而提高模型性能。你可以试着自己增加纪元的数量。你怎么想呢?</p><h1 id="d2d3" class="ku kv hh bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">测试模型</h1><p id="8808" class="pw-post-body-paragraph ix iy hh ja b jb ls jd je jf lt jh ji jw lu jl jm jx lv jp jq jy lw jt ju jv ha bi translated">既然模型已经训练好了，我们就该测试了。我们将使用我们之前创建的test_loader。我们想测量模型的准确性。</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="ae93" class="mg kv hh mc b fi mh mi l mj mk">total = 0<br/>correct = 0</span><span id="ecc9" class="mg kv hh mc b fi ml mi l mj mk">model.eval() # out our model in evaluation mode</span><span id="e8e1" class="mg kv hh mc b fi ml mi l mj mk">with torch.no_grad():<br/>    for data in test_loader:<br/>        images, labels = data<br/>        images, labels = images.to(device), labels.to(device)<br/>        outputs = model(images)<br/>        _, predicted = torch.max(outputs.data, 1)<br/>        total += labels.size(0)<br/>        correct += (predicted == labels).sum().item()<br/>print('Accuracy: %d %%' % (100 * correct / total))</span></pre><p id="6bb6" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">从我自己的部分来说，运行测试后，我得到了75%的准确率。这是一个不错的准确性。但是肯定可以改进。</p><p id="9ea6" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">如果您想测试对特定图像的预测，请查看blow片段。</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="ecbd" class="mg kv hh mc b fi mh mi l mj mk">dataiter = iter(testloader)<br/>images, labels = dataiter.next()</span><span id="f058" class="mg kv hh mc b fi ml mi l mj mk">print('Truth: ', ' '.join('%5s' % classes[labels[j]] for j in range(5)))<br/>outputs = net(images)</span><span id="b6c8" class="mg kv hh mc b fi ml mi l mj mk"># Output prediction<br/>_, predicted = torch.max(outputs, 1)<br/>print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(5)))</span></pre><p id="0526" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">现在您可以方便地保存模型了。</p><pre class="lx ly lz ma fd mb mc md me aw mf bi"><span id="bac1" class="mg kv hh mc b fi mh mi l mj mk">checkpoint = {'model': model,<br/>            'state_dict': model.state_dict(),<br/>            'optimizer' : optimizer.state_dict()}</span><span id="2dcb" class="mg kv hh mc b fi ml mi l mj mk">torch.save(checkpoint, 'checkpoint.pth')</span></pre><p id="3b6f" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">如果你想加载模型并在其他地方重用，你可以使用<a class="ae it" href="https://pytorch.org/docs/stable/generated/torch.load.html" rel="noopener ugc nofollow" target="_blank"> torch.load </a>函数。它将模型检查点文件作为参数。</p><p id="3e89" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">就这样…</p></div><div class="ab cl jz ka go kb" role="separator"><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke kf"/><span class="kc bw bk kd ke"/></div><div class="ha hb hc hd he"><h1 id="dcf7" class="ku kv hh bd kw kx mn kz la lb mo ld le lf mp lh li lj mq ll lm ln mr lp lq lr bi translated">额外的</h1><p id="b8a9" class="pw-post-body-paragraph ix iy hh ja b jb ls jd je jf lt jh ji jw lu jl jm jx lv jp jq jy lw jt ju jv ha bi translated">如果您想部署该模型，以便它可以作为服务使用，我想给您一点提示。</p><p id="2f4c" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">您可以提供一个云服务器，您将在其中加载您的模型，您有一个简单的RESTFul flask或fastapi API，它接收图像，然后将图像加载到您的模型，获得预测，并将响应发送回用户。</p><p id="ea60" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">请注意，图像的大小可能不同，因此您必须调整图像的大小，以便您的模型可以处理图像，否则模型将无法正常工作。</p><p id="434e" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">希望你不会再看到深度学习的东西变得很奇怪。</p><p id="fc57" class="pw-post-body-paragraph ix iy hh ja b jb jc jd je jf jg jh ji jw jk jl jm jx jo jp jq jy js jt ju jv ha bi translated">非常感谢您的阅读。</p><h1 id="a52b" class="ku kv hh bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">第二部分</h1><p id="d3c3" class="pw-post-body-paragraph ix iy hh ja b jb ls jd je jf lt jh ji jw lu jl jm jx lv jp jq jy lw jt ju jv ha bi translated">你可以在<a class="ae it" rel="noopener" href="/analytics-vidhya/deep-learning-loading-and-operationalizing-our-model-13c4da002225">这里</a>阅读<strong class="ja hi">深度学习部分:加载并操作我们的模型</strong>。</p><h1 id="67ea" class="ku kv hh bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">参考</h1><ul class=""><li id="6e4a" class="kg kh hh ja b jb ls jf lt jw ms jx mt jy mu jv kl km kn ko bi translated"><a class="ae it" href="https://deeplizard.com/learn/video/mUueSPmcOBc" rel="noopener ugc nofollow" target="_blank">神经网络编程——用PyTorch进行深度学习</a></li><li id="aa38" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated"><a class="ae it" href="https://www.kaggle.com/pankrzysiu/cifar10-python" rel="noopener ugc nofollow" target="_blank"> CIFAR-10 Python </a></li><li id="5268" class="kg kh hh ja b jb kp jf kq jw kr jx ks jy kt jv kl km kn ko bi translated"><a class="ae it" href="https://ruder.io/optimizing-gradient-descent/" rel="noopener ugc nofollow" target="_blank">梯度下降优化算法概述</a></li></ul></div></div>    
</body>
</html>