<html>
<head>
<title>Implementing under &amp; over autoencoders using PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PyTorch实现欠/过自动编码器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/implementing-under-over-autoencoders-using-pytorch-4ddaf458947e?source=collection_archive---------2-----------------------#2021-05-20">https://medium.com/analytics-vidhya/implementing-under-over-autoencoders-using-pytorch-4ddaf458947e?source=collection_archive---------2-----------------------#2021-05-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/d76e034be460d8c2ffbef70f0393e403.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SyLW-TLN5NLKPEpo"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@cebbbinghaus?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">克里斯托弗·罗宾·艾宾浩斯</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h1 id="22d1" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">介绍</h1><p id="bce5" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">Autoencoder是一种神经网络，它使用编码器将数据转换为潜在空间中更有效的表示，然后尝试使用解码器从潜在空间中导出原始数据。应用于信息流的瓶颈或约束避免了编码器和解码器之间的数据的直接复制，因此网络学习保持数据的最通用和最有效的表示，同时忽略噪声或临时模式。</p><p id="bda6" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">可以使用numpy在python中从头开始实现自动编码器，这需要手动实现渐变框架。然而，<a class="ae iu" href="https://en.wikipedia.org/wiki/Differentiable_programming" rel="noopener ugc nofollow" target="_blank">可区分编程</a>在python中是可用的，通过高效的框架，如<a class="ae iu" href="https://en.wikipedia.org/wiki/PyTorch" rel="noopener ugc nofollow" target="_blank"> PyTorch </a>，它们将用于本文。</p><h1 id="b515" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">短暂参观建筑</h1><p id="2778" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">正如我在<a class="ae iu" rel="noopener" href="/@jha-vikas/under-and-over-autoencoders-3d695f428c1a">文章</a>中所描述的，查看自动编码器的许多方法之一是基于隐藏/中间层或潜在空间维度来表征它们。如果通过限制隐藏/中间层的维度来应用autoencoder中的信息流瓶颈，那么它是欠autoencoder，否则它是过autoencoder。在后一种情况下，通过在输入数据中引入噪声，或者修改损失函数，减少潜在空间表示可以存在的有效空间，来应用信息瓶颈。</p></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><h1 id="3df9" class="iv iw hi bd ix iy ld ja jb jc le je jf jg lf ji jj jk lg jm jn jo lh jq jr js bi translated">数据</h1><p id="960b" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">【torch的DataLoader 用于为多个批处理创建数据集上的可迭代/映射样式。torchvision包含包含转换方法的<em class="li">转换</em>模块。可以将它们链接在一起，一次性对图像应用所有变换。MNIST数据集中的像素值的范围是-1到+1，从0到1。</p><figure class="lj lk ll lm fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><p id="16ae" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">PyTorch期望数据是形式的(批量大小、通道、高度、宽度)。如果数据是某种其他形式的，应该执行适当的转换，使其成为所需的形式。</p><p id="6b40" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">还要注意，torch.nn.Functional(通常作为F导入)包含一些有用的函数，如可以使用的激活函数和卷积运算。然而，这些是<strong class="jv hj">而不是</strong>全层。所以，要指定一个层，应该使用torch.nn.module。</p></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><h1 id="ece6" class="iv iw hi bd ix iy ld ja jb jc le je jf jg lf ji jj jk lg jm jn jo lh jq jr js bi translated">全连接和卷积自动编码器</h1><p id="2274" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">自动编码器将以两种方式实现，全连接网络和循环网络。前者权重更大，可以在大多数类型的数据中实现。CNN适用于以多维数组形式出现的信号/输入，并具有三个主要属性:局部性(值之间存在强局部相关性)、平稳性(信号的属性会自我重复，因此可以使用共享权重)和<strong class="jv hj"> </strong>合成性(特征以分层方式合成图像，证明使用多层来识别不同的细节层次是合理的)。</p><h2 id="a875" class="lp iw hi bd ix lq lr ls jb lt lu lv jf ke lw lx jj ki ly lz jn km ma mb jr mc bi translated">模型架构:全连接自动编码器</h2><p id="9a87" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">我们定义从父类<code class="du md me mf mg b">nn.Module</code>继承的Autoencoder类。输入是大小为<code class="du md me mf mg b">28x28</code>的张量(因为MNIST图像的大小为<code class="du md me mf mg b">28x28</code>)。编码器和解码器层在Autoencoder类中指定。正向传递定义为数据先通过编码器，然后通过解码器。向前传递后的输出与输入进行比较，给出损耗。由于像素强度是连续的，所以这里将均方误差作为损失函数。对于分类数据，像交叉熵这样的损失函数会更合适。</p><figure class="lj lk ll lm fd ij"><div class="bz dy l di"><div class="ln lo l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">完全连接的自动编码器。根据隐藏层的大小，它可以低于或高于自动编码器</figcaption></figure><h2 id="3d4b" class="lp iw hi bd ix lq lr ls jb lt lu lv jf ke lw lx jj ki ly lz jn km ma mb jr mc bi translated">模型架构:通用自动编码器</h2><p id="b67f" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">convulational autoencoder的架构与此类似，不同之处在于，它不是提供一个具有指定通道和批次大小的长单个向量(因此是一个三维向量)，而是提供一个具有批次大小、通道、高度和宽度的四维向量。</p><figure class="lj lk ll lm fd ij"><div class="bz dy l di"><div class="ln lo l"/></div></figure><h2 id="ad1f" class="lp iw hi bd ix lq lr ls jb lt lu lv jf ke lw lx jj ki ly lz jn km ma mb jr mc bi translated">训练循环</h2><p id="7625" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">这是用于训练任何神经网络的典型训练循环:</p><ul class=""><li id="b076" class="mh mi hi jv b jw kr ka ks ke mj ki mk km ml kq mm mn mo mp bi translated">图像被移动到设备(CPU或GPU)。计算输出。</li><li id="791f" class="mh mi hi jv b jw mq ka mr ke ms ki mt km mu kq mm mn mo mp bi translated">基于输出，计算损耗。</li><li id="5a74" class="mh mi hi jv b jw mq ka mr ke ms ki mt km mu kq mm mn mo mp bi translated">梯度被归零。</li><li id="9fdd" class="mh mi hi jv b jw mq ka mr ke ms ki mt km mu kq mm mn mo mp bi translated">实现反向传播和累加。</li><li id="2000" class="mh mi hi jv b jw mq ka mr ke ms ki mt km mu kq mm mn mo mp bi translated">Optimizer.step()在学习率的指导下，将权重移动到梯度方向的相反方向。</li></ul><figure class="lj lk ll lm fd ij"><div class="bz dy l di"><div class="ln lo l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">自动编码器的训练循环</figcaption></figure></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><h1 id="33cf" class="iv iw hi bd ix iy ld ja jb jc le je jf jg lf ji jj jk lg jm jn jo lh jq jr js bi translated">结果</h1><h2 id="c45c" class="lp iw hi bd ix lq lr ls jb lt lu lv jf ke lw lx jj ki ly lz jn km ma mb jr mc bi translated">欠自动编码器</h2><p id="0e31" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">对于与<code class="du md me mf mg b">28x28=784</code>的输入维度相比，隐藏层/潜在空间维度为30的欠自动编码器，在20个时期之后，我们得到MSE的以下减少:</p><pre class="lj lk ll lm fd mv mg mw mx aw my bi"><span id="10f4" class="lp iw hi mg b fi mz na l nb nc">epoch [1/20], loss:0.1892<br/>epoch [2/20], loss:0.1600<br/>epoch [3/20], loss:0.1274<br/>epoch [4/20], loss:0.1137<br/>…..<br/>epoch [18/20], loss:0.0520<br/>epoch [19/20], loss:0.0558<br/>epoch [20/20], loss:0.0574</span></pre><figure class="lj lk ll lm fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nd"><img src="../Images/299a3a30646df1833014849c1c12c0b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*32YtebG6-vTcVeqwVZPwDw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自欠自动编码器的图像</figcaption></figure><p id="85a1" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">顶行显示实际的图像，底行显示相应的重新创建的图像。正如我们所看到的，在第三列和第四列的情况下，娱乐不是很清楚。</p><figure class="lj lk ll lm fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ne"><img src="../Images/a9ed5808414e6b19ab7a2e74d5fa4ba5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X3G3Lfa_a5uIWxyV8s77bQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">欠自动编码器的编码器线性层中的权重</figcaption></figure><p id="befc" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">查看编码的线性层的一些权重，很明显存在看起来只是随机噪声的权重(第一行的第四列和第二行的第三列)，在激活中没有模式。其他权重似乎在捕捉一些模式。</p><p id="c5fd" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">让我们将它们与over-autoencoder的输出进行比较。</p><h2 id="bfa8" class="lp iw hi bd ix lq lr ls jb lt lu lv jf ke lw lx jj ki ly lz jn km ma mb jr mc bi translated">过度自动编码器</h2><p id="a18a" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">考虑隐藏层/潜在空间维度为500的过度自动编码器。但是，由于我们知道输入数据的维数是<code class="du md me mf mg b">28x28=784</code>，这怎么能称为over-autoencoder呢？答案在于输入的有效维度。超过80%的输入图像像素对图像的数值没有贡献。因此，输入层的有效尺寸仅为150左右，这是图像中有效像素的平均数量。周围区域大部分是黑暗的。</p><figure class="lj lk ll lm fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ne"><img src="../Images/51fedbae04b573258adeb3a1b98b366f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GUfNYv1rhqbEJva5Bx28NQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自自动编码器的图像</figcaption></figure><p id="fe76" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">有三行来自自动编码器的图像。顶行是被破坏的输入，即被馈送到自动编码器的图像(在添加噪声之后)。第二行显示重建的图像，第三行显示损坏前的实际输入图像。</p><p id="1d03" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">即使通过目视检查，很明显过自动编码器比欠自动编码器执行得更好。如果看一下损失值，这一论断会变得更加清晰:</p><pre class="lj lk ll lm fd mv mg mw mx aw my bi"><span id="14da" class="lp iw hi mg b fi mz na l nb nc">epoch [1/20], loss:0.0702<br/>epoch [2/20], loss:0.0594<br/>epoch [3/20], loss:0.0551<br/>epoch [4/20], loss:0.0519<br/>epoch [5/20], loss:0.0534<br/>epoch [6/20], loss:0.0463<br/>....<br/>epoch [16/20], loss:0.0415<br/>epoch [17/20], loss:0.0416<br/>epoch [18/20], loss:0.0423<br/>epoch [19/20], loss:0.0400<br/>epoch [20/20], loss:0.0407</span></pre><p id="e3ff" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">过度自动编码器比不足自动编码器收敛得更快。甚至最终的损失值也低于欠自动编码器。这是因为输入被扩展到更高维度的空间，在那里它可以以多得多的方式移动，以使模型适合实际的流形，即使在数据流方面存在约束时也是如此。对于欠自动编码器，我们从一个更高维的超空间移动到一个更低维的空间，在那里的移动受到更多的限制。</p><figure class="lj lk ll lm fd ij er es paragraph-image"><div class="er es nf"><img src="../Images/2de1d9acce04cb963d602e1da015b6dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*yLpRHHLerLWXxYBdCGXHtA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">用于过自动编码器的编码器的线性层中的权重</figcaption></figure><p id="fe98" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">重量似乎也学会了更好的表达方式，几乎没有重量缺少任何模式。</p><h2 id="aa6d" class="lp iw hi bd ix lq lr ls jb lt lu lv jf ke lw lx jj ki ly lz jn km ma mb jr mc bi translated">卷积自动编码器</h2><p id="b581" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">这里介绍的卷积自动编码器也是一种过度自动编码器，因为1通道数据被移动到16通道。此外，由于CNN层专门用于图像类型数据，因此与上述自动编码器相比，它们更适合。考虑各时期的损失值:</p><pre class="lj lk ll lm fd mv mg mw mx aw my bi"><span id="0782" class="lp iw hi mg b fi mz na l nb nc">epoch [1/20], loss: 0.0497<br/>epoch [2/20], loss: 0.0227<br/>epoch [3/20], loss: 0.0172<br/>epoch [4/20], loss: 0.0143<br/>epoch [5/20], loss: 0.0124<br/>epoch [6/20], loss: 0.0114<br/>epoch [7/20], loss: 0.0105<br/>epoch [8/20], loss: 0.0088<br/>...<br/>epoch [16/20], loss: 0.0050<br/>epoch [17/20], loss: 0.0045<br/>epoch [18/20], loss: 0.0043<br/>epoch [19/20], loss: 0.0040<br/>epoch [20/20], loss: 0.0038</span></pre><p id="8324" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">正如所预期的，与基于传统全连接层的欠编码器和过编码器相比，损耗迅速降低并达到低得多的值。</p><figure class="lj lk ll lm fd ij er es paragraph-image"><div class="er es ng"><img src="../Images/7be5eb388ba5cad9d66695c8f25fccd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*tsdVsmgVa7w1-kpQPhR43g.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自convulation-auto encoder的图像</figcaption></figure><p id="8a76" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">对生成图像的视觉检查证实了我们的假设。这三行分别代表作为输入发送到编码器的噪声数据、生成的干净输出和实际的干净输入。</p></div><div class="ab cl kw kx gp ky" role="separator"><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb lc"/><span class="kz bw bk la lb"/></div><div class="hb hc hd he hf"><h1 id="fec1" class="iv iw hi bd ix iy ld ja jb jc le je jf jg lf ji jj jk lg jm jn jo lh jq jr js bi translated">结论</h1><p id="0a43" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq hb bi translated">基于MNIST数据集上的实现和结果，很明显，过自动编码器优于欠自动编码器，因为它有更大的潜在空间，可以更准确地对流形建模。然而，它也更容易过度拟合。</p><p id="33ab" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">另一方面，卷积自动编码器(也是过度自动编码器)优于基于全连接层的自动编码器，因为它们考虑了图像的属性，以提取手头数据的更好表示。</p><p id="f4ce" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">在上面提到的所有自动编码器中，有一个缺陷是它们将输入多维空间中的一个点映射到流形上的一个点。然而，通过将点映射到流形中的向量场而不是离散点来进行概括会更好，这将给出更平滑的流形映射。变分自动编码器(VAE)通过引入条件分布来实现，该条件分布具有作为潜在表示的点值的平均值和一些方差。我们将在后续文章中研究VAEs。</p><p id="6462" class="pw-post-body-paragraph jt ju hi jv b jw kr jy jz ka ks kc kd ke kt kg kh ki ku kk kl km kv ko kp kq hb bi translated">完整剧本:<a class="ae iu" href="https://github.com/jha-vikas/pyTorch-implementations" rel="noopener ugc nofollow" target="_blank">https://github.com/jha-vikas/pyTorch-implementations</a></p></div></div>    
</body>
</html>