<html>
<head>
<title>Logistic Regression.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">逻辑回归。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/logistic-regression-c5a6c047363e?source=collection_archive---------7-----------------------#2021-05-28">https://medium.com/analytics-vidhya/logistic-regression-c5a6c047363e?source=collection_archive---------7-----------------------#2021-05-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="4731" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归是一种分类算法，用于将观察值分配给一组离散的类。与输出连续数值的线性回归不同，逻辑回归使用逻辑sigmoid函数转换其输出，以返回一个概率值，该概率值可映射到两个或多个离散类。</p><p id="92f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，下面给出了不同的输入变量，如温度、湿度和风，我们的模型可以预测输出。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/19554c398d6755ea032af9775ad11a17.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*4qcbqy-Mf6V-e1Ky.png"/></div></div></figure><p id="b3cf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">与线性回归的比较:</strong></p><p id="0fb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">给出学习时间和考试分数的数据。线性回归和逻辑回归可以预测不同的事情:</p><p id="663c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">线性回归:</strong>在0到100的范围内，线性回归可以帮助我们预测学生的考试成绩。线性回归的预测是连续的(一个范围内的数字)。</p><p id="e45e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">逻辑回归:</strong>我们可以用逻辑回归来决定一个学生是否会及格。逻辑回归的预测是离散的(只允许特定的值或类别)。还可以查看支持模型分类的概率分数。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jo"><img src="../Images/71c8541fd41355fc71a91ca218f26177.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/0*xkDrQ-_V13-M2Vsv.png"/></div></figure><p id="b43e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">逻辑回归的类型:</strong></p><p id="fc6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通常，逻辑回归是指具有二元目标变量的二元逻辑回归，但是可以有两类以上的目标变量可以被它预测。基于这些类别的数量，逻辑回归可以分为以下类型</p><p id="7212" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">二元或二项式</strong></p><p id="afcc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这种分类中，因变量只有两种可能的类型，要么是1，要么是0。例如，这些变量可能代表成功或失败，是或否，赢或输等。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jp"><img src="../Images/40da13b7381bf49ee4a0c16685c05469.png" data-original-src="https://miro.medium.com/v2/resize:fit:510/format:webp/0*V4z91Qo8TXK2sHRQ.png"/></div></figure><p id="f235" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">多项式</strong></p><p id="c1ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这种分类中，因变量可以有3个或更多可能的无序类型或没有数量意义的类型。例如，这些变量可能代表“A型”或“B型”或“C型”。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jq"><img src="../Images/bca5c174cfda27a3a68d48200df2a0d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/0*fnJlrK2DIALDgXlZ.png"/></div></figure><p id="0bab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">序数</strong></p><p id="f054" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这种分类中，因变量可以有3个或更多可能的有序类型或具有数量重要性的类型。例如，这些变量可以表示“差”或“好”、“非常好”、“优秀”，并且每个类别可以具有像0、1、2、3这样的分数。</p><p id="9320" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">逻辑回归中的假设:</strong></p><p id="4a87" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归没有做出基于普通最小二乘算法的线性回归和一般线性模型的许多关键假设，特别是关于线性、正态性、同方差和测量水平。</p><p id="ae7b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1.逻辑回归不需要因变量和自变量之间的线性关系。</p><p id="9bdd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.误差项(残差)不需要正态分布。</p><p id="5561" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.不需要同质性。</p><p id="2307" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.逻辑回归中的因变量不是在区间或比率尺度上测量的。</p><p id="d8e6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，其他一些假设仍然适用。</p><p id="6382" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">二元逻辑回归要求因变量是二元的，而有序逻辑回归要求因变量是有序的。</p><p id="c0dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归要求观察值相互独立。换句话说，观察值不应该来自重复的测量或匹配的数据。</p><p id="f151" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归要求自变量之间很少或没有多重共线性。这意味着独立变量之间的相关性不应该太高。</p><p id="19d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归假设独立变量和对数比值呈线性。尽管该分析不要求因变量和自变量线性相关，但要求自变量与对数概率线性相关。</p><p id="6277" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归通常需要大样本量。一般的指导方针是，对于模型中的每个独立变量，至少需要10个具有最不频繁结果的案例。</p><p id="5dbf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，如果你有5个独立变量，你最不频繁结果的预期概率是0.10，那么你需要的最小样本量是500 (10*5 / .10)。</p><p id="08e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">不同的回归算法:</strong></p><p id="29ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有各种各样的回归技术可以用来做预测。这些技术基于三个指标:自变量的数量、因变量的类型和回归线的形状。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jr"><img src="../Images/45a640b64083bca7cdfee3f13f5032a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:620/format:webp/0*nvCeBTpt6gfzW0iK.png"/></div></figure><p id="1142" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 1。</strong> <strong class="ig hi">线性回归</strong></p><p id="5d73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。</strong> <strong class="ig hi">逻辑回归</strong></p><p id="9504" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。</strong> <strong class="ig hi">岭回归</strong></p><p id="5c8b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 4。</strong> <strong class="ig hi">拉索回归</strong></p><p id="0d46" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 5。</strong> <strong class="ig hi">多项式回归</strong></p><p id="205a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">6。 <strong class="ig hi">贝叶斯线性回归</strong></p><p id="2aca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 7。</strong> <strong class="ig hi">逐步回归</strong></p><p id="800e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 8。</strong> <strong class="ig hi">弹力网回归</strong></p><p id="d23b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 9。</strong> <strong class="ig hi">支持向量回归</strong></p><p id="26e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 10。</strong> <strong class="ig hi">随机森林回归</strong></p><p id="6e08" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 11。决策树回归</strong></p><p id="6d50" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">线性回归:</strong></p><p id="bb0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">线性回归是一种预测性建模技术，可以发现自变量和因变量(连续变量)之间的关系。</p><p id="8b46" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当只有一个输入变量(x)时，该方法被称为简单线性回归。当有多个输入变量时，统计学文献通常将该方法称为多元线性回归。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es js"><img src="../Images/cc80d814bf88a7b1985471c25be72326.png" data-original-src="https://miro.medium.com/v2/resize:fit:512/format:webp/0*bgSKfwkX50Lwbaas.png"/></div></figure><p id="f930" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">逻辑回归:</strong></p><p id="f71c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归是回归分析技术的一种，当因变量为离散变量时使用。逻辑回归是最流行的机器学习算法之一，属于监督学习技术。它用于使用一组给定的独立变量来预测分类因变量。</p><p id="9e85" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归预测分类因变量的输出。因此，结果必须是分类值或离散值。它可以是是或否，0或1，真或假，等等。但是它给出的不是0和1的精确值，而是介于0和1之间的概率值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jt"><img src="../Images/3f76d839febb50a800a9c7a6a5156d74.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/0*cchn78VrzyEmOS5R.png"/></div></figure><p id="da56" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归计算由以下等式给出:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ju"><img src="../Images/b64e38b7b700f54d3e47494050ea7253.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/0*ddE2cXbx2GHg02Fi.png"/></div></figure><p id="1585" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">岭回归:</strong></p><p id="d1a9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">岭回归是一种分析多重共线性数据的技术。当多重共线性发生时，最小二乘估计是无偏的，但是它们的方差很大，因此它们可能远离真实值。通过给回归估计增加一定程度的偏差，岭回归减少了标准误差。当自变量高度相关时，使用这种方法。</p><p id="950d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">执行L2正则化，即等价于系数大小的平方的惩罚。</p><p id="2068" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最小化目标= LS Obj + α *(系数的平方和)</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jv"><img src="../Images/574e16622272d6806fd8ab5c07e64b95.png" data-original-src="https://miro.medium.com/v2/resize:fit:700/format:webp/0*w5PhiZwWeornOm_o.png"/></div></figure><p id="8b25" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">岭是如此强大的回归方法，其中模型不太容易过度拟合。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jw"><img src="../Images/ad66657f8737ccc4147483017b96083d.png" data-original-src="https://miro.medium.com/v2/resize:fit:634/format:webp/0*oE_dZ_CU_d3mqfsz.png"/></div></figure><p id="c459" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">拉索回归:</strong></p><p id="fa01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">LASSO(最小绝对收缩选择算子)，很像岭，减少了因变量的数量，在岭回归的类似情况下，如果惩罚项很大，系数可以减少到零，使特征选择更容易。LASSO使用L1正则化技术。</p><p id="fa65" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">LASSO通常在我们拥有大量特征时使用，因为它会自动进行特征选择。结果，系数值变得更接近零，这在岭回归的情况下不会发生。</p><p id="6086" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">LASSO采用了简单的屏蔽(阈值)技术，并选择了一个用于最终模型实现的协变量子集。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jx"><img src="../Images/4c6e4e6e4c22599df12c8a6f64bb34b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/0*JlAiyOvZCODzP6H-.png"/></div></figure><p id="9973" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是代表套索回归方法的等式:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jy"><img src="../Images/3b377817ef95033b5de7d04fb9175b9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/0*6p9Ogsen1ZYAikAF.png"/></div></figure><p id="a2df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">多项式回归:</strong></p><p id="f20a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">多项式回归，自变量和因变量之间的关系，也就是X和Y，用n次表示。</p><p id="3442" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为估计量，它是一个线性模型。最小均方方法也用于多项式回归。多项式回归中穿过所有数据点的最佳拟合线不是直线，而是曲线，这取决于X的幂或n的值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jz"><img src="../Images/d694e754a185432668d635296a3684ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:596/format:webp/0*lsVZPKdO8GWYNd0h.png"/></div></figure><p id="7a58" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">多项式回归可以由下面的等式表示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ka"><img src="../Images/2fef64121928cbaf606402cd45007668.png" data-original-src="https://miro.medium.com/v2/resize:fit:326/format:webp/0*fsBBAjGoFWKVBuF6.png"/></div></figure><p id="7d6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">贝叶斯线性回归:</strong></p><p id="0ffa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">贝叶斯回归是机器学习中的一种回归类型，它使用贝叶斯定理来找出回归系数的值。在这种回归方法中，确定特征的后验分布，而不是寻找最小二乘法。贝叶斯线性回归类似于线性回归和岭回归，但比简单的线性回归更稳定。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kb"><img src="../Images/7d9ef3328e9c1d31bf05c271befa79b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/0*ZJ3uDl69sjyiivzo.png"/></div></figure><p id="5638" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">逐步回归:</strong></p><p id="4313" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它常用于满足回归模型和自然执行的预测模型。每向前一步，变量就会从一组描述性变量中增加或减少。</p><p id="45b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">前向选择执行连续添加变量以检查性能，并在不需要改进到一定程度时停止。</p><p id="0051" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">向后消除包括一次删除变量，直到没有多余的变量被删除而没有相当大的损失。双向消除是上述两种方法的混合。</p><p id="88b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">弹力网回归:</strong></p><p id="1aaf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当高度相关的预测因子联合出现在模型中时，岭回归和套索回归的混合会产生分组效应。建议在预测值的数量远大于观测值的数量时使用。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kc"><img src="../Images/cc4d16ae154e11ca8cd3c7b56036ca85.png" data-original-src="https://miro.medium.com/v2/resize:fit:824/format:webp/0*D14QgctT_17jZaiq.png"/></div></figure><p id="0baf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">支持向量回归:</strong></p><p id="894f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">支持向量回归(SVR)使用与SVM相同的原理，但用于回归问题。</p><p id="db36" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它试图找到一条线/超平面(在多维空间中)来分隔这两个类。然后，它根据新点是位于超平面的正侧还是负侧来对新点进行分类，这取决于要预测的类别。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kd"><img src="../Images/1d5057c75a4770e9a227a0366b82fd7f.png" data-original-src="https://miro.medium.com/v2/resize:fit:494/format:webp/0*QhjV9iQJ0nb96MZn.png"/></div></figure><p id="ad2d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">随机森林回归:</strong></p><p id="771d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">随机森林回归是一种监督学习算法，使用集成学习方法进行回归。集成学习方法是一种结合来自多个机器学习算法的预测来做出比单个模型更准确的预测的技术。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ke"><img src="../Images/3f4c6be1a4b4feb169186deeeb3e8c19.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/0*uWAUsxrgSmdziR_O.png"/></div></figure><p id="1354" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">决策树回归:</strong></p><p id="0efe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一个最好的和最常用的监督学习方法是基于树的算法。它们使预测建模具有更高的准确性、更好的稳定性，并且易于解释。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kf"><img src="../Images/97a99ec221dc6c0553e49e08c99d1fac.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/0*CrHRzonCXuDwY-3L.png"/></div></figure><p id="6b1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">逻辑回归的度量:</strong></p><p id="c013" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们完成构建您的模型后，有多个指标将帮助我们评估模型的准确性。</p><p id="bdf7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1.混淆矩阵</p><p id="e49a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.F1分数</p><p id="9d42" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.增益和提升图表</p><p id="1581" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.科尔莫戈罗夫·斯米尔诺夫图表</p><p id="0d9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.AUC-ROC</p><p id="6ce1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">6.原木损失</p><p id="01b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">7.基尼系数</p><p id="29b3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">8.和谐—不和谐比率</p><p id="f94b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">9.均方根误差</p><p id="42d3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">10.均方根对数误差</p><p id="3802" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">11.R平方/调整的R平方</p><p id="f1f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 1。混乱矩阵:</strong></p><p id="9ab3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">混淆矩阵是一个N×N矩阵，其中N是被预测的类的数量。对于手头的问题，我们有N=2，因此我们得到一个2×2矩阵。对于混淆矩阵，您需要记住以下几个定义:</p><p id="77da" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">准确性:正确预测总数的比例。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kg"><img src="../Images/916773961d12bd6cc0b41424a49cac83.png" data-original-src="https://miro.medium.com/v2/resize:fit:900/format:webp/0*TqK-NJ3TQ33Rs-2R.png"/></div></figure><p id="91df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">阳性预测值或精确度:被正确识别的阳性病例的比例。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kh"><img src="../Images/8939ffd756b5d6793b5b201f6136d814.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/0*NhZ7xgYjsa1_pri5.png"/></div></figure><p id="30b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">阴性预测值:被正确识别的阴性病例的比例。</p><p id="4002" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">敏感性或回忆:被正确识别的实际阳性病例的比例。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ki"><img src="../Images/e0e285d6a5734f6bcebcbed4b7016f58.png" data-original-src="https://miro.medium.com/v2/resize:fit:684/format:webp/0*CVzf1TCHm9GLQgbX.png"/></div></figure><p id="7abd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">特异性:被正确识别的实际阴性病例的比例。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kj"><img src="../Images/709dd72ac1fdbe1fc61011b55bbc2b80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/0*tMYC9OwkqsaESDVj.png"/></div></figure><p id="0917" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。F1得分:</strong></p><p id="9d3d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是精度和召回率的调和平均值，并且给出了比精度度量更好的错误分类情况的度量。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kk"><img src="../Images/f25d0c2921fc98db8d5fb3f9ad87b4e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:940/format:webp/0*TBBHd9sLpTGkTRfi.png"/></div></figure><p id="bd25" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们使用调和平均值，因为它不利于极值。</p><p id="f504" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总结F1分数和准确性之间的差异，</p><p id="85eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当真阳性和真阴性更重要时使用准确度，而当假阴性和假阳性至关重要时使用F1分数。</p><p id="627a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当类别分布相似时，可以使用精确度，而当存在不平衡的类别时，F1-score是更好的度量，如上例所示。</p><p id="ccbf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在大多数现实生活的分类问题中，存在不平衡的类分布，因此F1-score是评估我们的模型的更好的度量。</p><p id="5567" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 3。增益和升力图表:</strong></p><p id="5401" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">增益和提升图主要用于检查概率的排序。</p><p id="e090" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是构建提升/增益图的步骤:</p><p id="3cf9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第一步:计算每次观察的概率。</p><p id="e021" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第二步:按降序排列这些概率。</p><p id="f02d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第三步:建立十分位数，每个组有将近10%的观察值。</p><p id="d3c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第4步:计算好(有响应者)、差(无响应者)和总的每十分位数的响应率</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kl"><img src="../Images/432ba77991cbdf90e028fadd6cb81ea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:482/format:webp/0*PY1dbh8_A8mHzKBO.png"/></div></figure><p id="890e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">提升/增益图广泛用于活动目标问题。这告诉我们，在特定的活动中，我们可以将目标客户锁定在哪个十分位数。此外，它告诉你有多少反应，你期望从新的目标基地。</p><p id="6424" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 4。科洛莫戈罗夫·斯米尔诺夫图表:</strong></p><p id="386e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">K-S或Kolmogorov-Smirnov图衡量分类模型的性能。更准确地说，K-S是正分布和负分布之间分离程度的度量。如果分数将人群分成两个独立的组，其中一组包含所有的阳性，另一组包含所有的阴性，则K-S为100。</p><p id="c50f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一方面，如果模型不能区分阳性和阴性，那么就好像模型从总体中随机选择病例。K-S应该是0。在大多数分类模型中，K-S将落在0和100之间，并且该值越高，该模型就越能更好地将阳性病例与阴性病例分开。</p><p id="6421" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 5。ROC曲线下面积(AUC — ROC): </strong></p><p id="b3b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用ROC曲线的最大优点是独立于应答者比例的变化。</p><p id="8b8a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们先来了解一下什么是ROC(受试者工作特性)曲线。如果我们看下面的混淆矩阵，我们观察到对于一个概率模型，我们得到每个度量的不同值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es km"><img src="../Images/1c63cec054c24cf915eb82ac63ad764b.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/format:webp/0*gH7FOt0HDYIEdZQ1.png"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kn"><img src="../Images/5742944e9b30b9ad039e3118201c5a67.png" data-original-src="https://miro.medium.com/v2/resize:fit:60/0*LMyPtxDVf7S5Tx0M"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ko"><img src="../Images/5432b815741752a62974d909c59f0b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*IvESx3-kE4cXLmUY.png"/></div></figure><p id="7237" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ROC曲线是灵敏度和(1-特异性)之间的图。(1-特异性)也称为假阳性率，灵敏度也称为真阳性率。以下是手头案例的ROC曲线。</p><p id="de80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 6。日志丢失:</strong></p><p id="d442" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">AUC ROC考虑预测的概率来确定我们模型的性能。然而，AUC ROC有一个问题，它只考虑概率的顺序，因此，它不考虑模型预测样本更可能为正的更高概率的能力。在这种情况下，我们可以使用对数损失，它只不过是每个实例的校正预测概率对数的负平均值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kp"><img src="../Images/11358b44cbe5c4eb82af54e262c62e97.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/0*WQNcjX7t9BBz-2D5.png"/></div></figure><p id="7bd5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 7。基尼系数:</strong></p><p id="ab60" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基尼系数有时用于分类问题。基尼系数可以直接从AUC ROC数导出。基尼系数只不过是ROC曲线和对角线之间的面积与上面三角形的面积之比。以下是使用的公式:</p><p id="3d63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基尼= 2*AUC — 1</p><p id="31ea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 8。和谐-不和谐比率:- </strong></p><p id="25f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它是任何分类预测问题的最重要的度量之一。符合率超过60%就是好模型。在决定目标客户数量时，通常不使用该指标。它主要用于评估模型的预测能力。</p><p id="843c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 9。均方根误差(RMSE): - </strong></p><p id="7cc9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是回归问题中最常用的评估指标。它遵循一个假设，即误差是无偏的，并遵循正态分布。</p><p id="369e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在RMSE有几个关键点需要考虑:</p><p id="077f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">“平方根”的力量使这一指标能够显示大量偏差。</p><p id="ff09" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该度量的平方性质有助于提供更稳健的结果，从而防止抵消正负误差值。</p><p id="8502" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它避免了使用绝对误差值，这在数学计算中是非常不希望的。</p><p id="74b3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与平均绝对误差相比，RMSE给出更高的权重并惩罚大的误差。</p><p id="d6eb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">RMSE误差可以计算如下:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kq"><img src="../Images/e8048c6724794bcf4e576e63c88e2069.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/0*vzYIM74rXOfSRL79.png"/></div></figure><p id="2751" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中，N是观察总数。</p><p id="89e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 10。均方根对数误差:- </strong></p><p id="2604" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了计算这个，我们取预测值和实际值的对数。当预测值和真实值都是巨大的数字时，如果我们不想惩罚预测值和实际值之间的巨大差异，通常会使用RMSLE。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jt"><img src="../Images/e5a6e5526dcfab4554ec3a707d44bc1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/0*AJhAw36dvaeFFI11.png"/></div></figure><p id="1ea3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果预测值和实际值都很小，那么RMSE和RMSLE是相同的。</p><p id="dbb7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果预测值或实际值大:RMSE &gt; RMSLE。</p><p id="8ecc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果预测值和实际值都很大:RMSE &gt; RMSLE。</p><p id="a3aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 11。r平方:- </strong></p><p id="414a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在分类问题的情况下，如果模型的精确度为0.8，我们将衡量我们的模型相对于随机模型的精确度为0.5。因此，随机模型可以作为一个基准。在RMSE指标中，我们没有可以比较的基准。</p><p id="9e04" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">R的平方可以计算如下:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kr"><img src="../Images/93dbec9c4d3fe8266179ea6bb072b236.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/0*PYD94ek-dSx7Bqpi.png"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ks"><img src="../Images/3b92f60cd163dafe9674c6aaaeaebf77.png" data-original-src="https://miro.medium.com/v2/resize:fit:580/format:webp/0*iTBg5RVTC6O0vN4Q.png"/></div></figure><p id="db0c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">MSE(模型):预测值与实际值的均方误差。</p><p id="1d31" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">MSE(基线):平均预测值与实际值的均方误差。</p><p id="bfdd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">参考资料:</strong> <a class="ae kt" href="https://www.analyticssteps.com/blogs/7-types-regression-technique-you-should-know-machine-learning" rel="noopener ugc nofollow" target="_blank">分析报告</a>，<a class="ae kt" href="https://www.upgrad.com/blog/types-of-regression-models-in-machine-learning/" rel="noopener ugc nofollow" target="_blank">升级报告</a>，<a class="ae kt" href="https://www.statisticssolutions.com/assumptions-of-logistic-regression/" rel="noopener ugc nofollow" target="_blank">统计报告</a>。</p></div></div>    
</body>
</html>