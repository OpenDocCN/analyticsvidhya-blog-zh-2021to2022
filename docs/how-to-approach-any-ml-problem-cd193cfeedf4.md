# 如何处理任何 ML 问题

> 原文：<https://medium.com/analytics-vidhya/how-to-approach-any-ml-problem-cd193cfeedf4?source=collection_archive---------5----------------------->

![](img/efbb10a913f82501e6d243da3d131ef8.png)

首先，我真的要感谢媒体社区，这些年来我从这个门户网站获得了大量的知识。其次，我写这篇文章是为了给我自己和任何正在寻找一条结构化的途径来处理任何 ML 用例的人提供参考。

关于这篇文章的另一个注意事项是，这篇文章将描述你的工具箱中可能有的各种工具以及何时使用它们。这篇文章不一定会深入到每件事背后的数学细节，但有点像你手头上整个 ML 问题的清单(当然不是详尽的清单)，一旦你有了那个想法，那么我会敦促你进入进一步的细节。

# 1.解释数据集和问题

第一步可以只是对数据有一个高层次的理解。试着找出一些简单问题的答案。

这些特征意味着什么？

数据是如何收集的，收集数据的目的是什么(这将有助于您了解任何采样异常)？

我们是否已经知道我们要寻找什么，或者我们需要自己放下这个问题？(我们试图解决什么样的问题——受监督的、不受监督的、规定的还是重新实施的)

# 2.描述性分析

让我们试着做一些基本的描述性分析。查看数据中存在的所有特征——本质上是分类的、数字的还是顺序的。

这看起来是一小步，但是它可以给你很多关于数据的直觉。让我们看看泰坦尼克号数据集中的例子，了解一下数据是什么样子的。

[](https://www.kaggle.com/c/titanic/data) [## 泰坦尼克号——灾难中的机器学习

### 从这里开始！预测泰坦尼克号上的生存并熟悉 ML 基础知识

www.kaggle.com](https://www.kaggle.com/c/titanic/data) ![](img/4bee7e8fd42e2b66ed012e421f4c49d6.png)

仅仅通过做这种基本的描述性特征分析，Kaggle 上泰坦尼克号数据集最高投票核的作者就能够收集到以下推论。

*   总样本为 891 人，占泰坦尼克号上实际乘客人数(2224 人)的 40%。
*   大约 38%的样本存活，代表了 32%的实际存活率。
*   大多数乘客(> 75%)没有和父母或孩子一起旅行。
*   将近 30%的乘客在飞机上有兄弟姐妹和/或配偶。
*   票价差别很大，很少有乘客(< 1%)支付高达 512 美元。

从分类特征中可以得出类似的推论。

最后，尝试对数据进行一些可视化处理，以了解数据的含义——看看数据是否不平衡，或者是否可以从特征中识别出某种回归，无论是目标变量还是任何其他变量，等等。这一步我尽量含糊。

# 3.检查缺少的值

大多数模型无法处理缺失值，即使它们能够处理，也几乎总是需要我们自己处理它们，因为我们将能够基于比任何只将它们视为数字的 ML 模型更符合逻辑的方法来估算或删除记录。

在继续处理缺失值之前，尝试逐个要素地找出数据集中缺失了多少值。以结构化的表格形式总结和整理你的数据。

为了处理丢失的值，我们通常会尝试做以下事情之一

1.  删除记录
    a .删除特征——当数据集中有大量缺失值时，可能会出现发现整个特征毫无用处的情况，但这同样取决于该特征是什么——医院账单索赔中的程序代码可能有许多空值，我们仍然可以利用这些数据是有意义的——我们不应该删除它，但另一方面，收入作为一个缺失值超过 40%的特征并不十分有用。
    作为一个常规做法，我总是试图保留该功能，直到并且除非超过 40%的数据丢失，但再次感知数据代表什么——但总是试图争取保留它——丢弃该功能意味着我们可能会丢失一些有价值的信息。
    b .删除一行——如果对于一行，我们没有大部分列的值，通常删除该行是个好主意。也许应该使用包含异常值的列进行异常值检测或初始描述性分析，但不要将其输入到模型中。垃圾进来就是垃圾出去。
2.  插补
    在这里，我们试图用各种方法对这些值进行插补，这在不同的用例中会有很大的不同。对这些值的估算没有具体的规则，但这些是我见过的一些方法。
    1。均值、中值、众数或用 0/常数估算
    2。线性回归
    3。k 最近邻
    4。多变量插补采用链式方程(小鼠)
    5。使用深度学习的插补法( [Datawig](https://github.com/awslabs/datawig) )
    有一篇关于插补法的非常好的文章，你可以浏览一下——作者介绍了这些方法的利弊:

[](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779) [## 弥补缺失数据的 6 种不同方法(数据插补，附实例)

### 统计估算数据集中缺失值的常用策略。

towardsdatascience.com](https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779) 

# 4.离群点检测

因此，顾名思义，异常值是会使您的模型向一个方向或另一个方向倾斜的值，因为极端值并不能真实地描述一般情况。我们试图不让模型从这些极端值中学习任何东西。

以下是处理异常值检测的一些常用方法。

1.  z 得分-一些可视化技术-四分位数分析-KDE
2.  数据库扫描
3.  隔离森林

下面这篇文章非常准确，并且与我在实践中看到的方法完全一致。

[](https://towardsdatascience.com/a-brief-overview-of-outlier-detection-techniques-1e0b2c19e561) [## 离群点检测技术概述

### 什么是离群值，如何处理？

towardsdatascience.com](https://towardsdatascience.com/a-brief-overview-of-outlier-detection-techniques-1e0b2c19e561) 

# 5.EDA —特征工程—一种热编码— PCA

尽管最后两个部分——处理缺失值和异常值检测也属于 EDA，但我还是将它们列在本节之前，以保持需要完成的时间顺序。

现在进入整个 ML 模型创建中最耗时的部分，探索性数据分析和特征工程。

在此阶段，我们需要解决数据中的以下问题:

1.  让我们的 ML 模型的数据尽可能简单——例如，如果我们将年龄作为一个连续的数字，可以创建 5 个条块，并以有序的方式标记它们。
2.  注意分类特征——找出分类特征在本质上是否是有序的，在这种情况下，我们可以使用***标签编码*** *g* 。如果不是，那么我们可能需要继续进行一个热编码 ，然后是一个热编码列上的 *PCA* 或 *SVD* 。另请注意，很多时候，一个热编码会分解您的要素，即使在此基础上的 **PCA 或 SVD** 也无法减少列的大小-在这种情况下，只需对要素内的值进行一次热编码，超过某个阈值的值进行一次热编码将是有用的-可能只需要占 10，000 个过程中 95%值的前 50 个过程。(如果你不知道我上面列出的任何技术，我建议你在这个阶段阅读这些技术)
    *一个重要的注意事项——总是在一个热编码之后检查你的训练数据和测试数据的大小，它应该匹配。*
3.  特征工程——在第二步中，一键编码和主成分分析的缺点是特征的可解释性急剧下降。想象一下，创建一个检测癌细胞的模型，却不能告诉医生模型预测的依据，这看起来很糟糕。另一方面，特征工程学是很好解释的——也许对你的模型来说，身体质量指数是一个很好的度量，而不仅仅是个人的身高。
4.  特征扩展——对于一个只懂数字和数学的 ML 模型来说，我们帮助提供一些功能知识是有意义的。在我们想要预测房子价格的场景中，卧室的数量和平方英尺的面积一样重要。否则，模型会更重视一个特性，而可能完全忽略另一个。尽管没有像基于决策树的模型那样的缩放数据，有些模型仍然表现良好，但继续缩放数据几乎总是明智的。有两种流行的缩放数据的方式:
    ***归一化*** 通常意味着将值重新缩放到[0，1]的范围内。 ***标准化*** 通常意味着重新调整数据，使其平均值为 0，标准差为 1(单位方差)。
    请通读这篇文章，了解何时使用哪种方法:

[](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf) [## 标准化与规范化—定量分析

### 停止使用 Sklearn 的 StandardScaler 作为默认的特征缩放方法，可以使你的精度提高 7%!

towardsdatascience.com](https://towardsdatascience.com/normalization-vs-standardization-quantitative-analysis-a91e8a79cebf) 

5.训练测试拆分—将数据拆分为训练和测试数据。通常的做法是 80 %的数据为训练数据，20%为测试数据。

# 6.拟合模型并调整模型的参数和超参数

现在，一旦我们对我们所拥有的功能类型感到满意，并且已经做了所有我们可以做的事情，以便以正确的格式获得我们的功能，就到了我们需要尝试不同模型并看看哪一个性能最好的时候了。

至此，我们应该已经知道我们手头的问题是哪一种——受监督的、不受监督的、指令性的还是重新执行的。

在这一点上，有一个关于哪种模型通常在哪种数据上表现更好的总体想法是很好的，例如，决策树能够很好地处理非线性数据，类似地，SVM 能够很好地处理稀疏数据。尝试不同的模型会有所帮助，但一定要从简单的模型开始，看看它的表现如何。这将有助于计算出我们的数据中存在多少信息——即使是一个简单的模型也能给出相当不错的结果，我的 EDA 过程是成功的。此外，复杂性的逐渐增加将有助于您解释为什么某些模型比其他模型表现更好，以及在哪些特定场景中表现更好。例如，为了解决一个自然语言处理问题，从一个简单的朴素贝叶斯分类器开始，如果表现不好，那么就去找 LSTM 或者 CNN。

## 超参数调谐

现在是任何模型训练的重要部分——调整超参数。如果你是模型训练的新手，我建议你花点时间阅读每个模型背后的数学工作原理，然后继续阅读该模型的所有超参数。根据我的经验，我甚至多次看到数据科学家会直接尝试使用 ***网格搜索方法*** 来搜索模型，并能够得出相当不错的结果，但这不是正确的方法(或最佳模型)。

虽然网格搜索是一种非常有效的方法，但可能会出现这样一种情况:如果您知道模型背后的数学原理，您可能永远也不会选择该模型，即使是出于考虑，您最终也会调整无法处理您正在处理的数据类型的超参数。

关于随机森林或 SVM 以及其他 ML 模型的超参数调优，以及激活函数如何工作，有许多优秀的文章，激活函数通常是模型超参数性能的关键。

## 正规化

正则化是模型创建和训练的一部分，但它是一个重要的概念，值得单独列出一小部分。这个主题直接来自著名的偏差-方差权衡问题，正则化试图为我们解决这个问题。

[](https://towardsdatascience.com/balancing-bias-and-variance-to-control-errors-in-machine-learning-16ced95724db) [## 平衡偏差和方差以控制机器学习中的错误

### 在机器学习的世界里，准确性就是一切。您努力通过调整和…使您的模型更加精确

towardsdatascience.com](https://towardsdatascience.com/balancing-bias-and-variance-to-control-errors-in-machine-learning-16ced95724db) 

***这种技术不鼓励学习更复杂或更灵活的模型，以避免过度拟合的风险。***

下面的帖子将有助于你理解正规化的类型

[](https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a) [## 机器学习中的正则化

### 训练机器学习模型的一个主要方面是避免过度拟合。该模型将有一个低…

towardsdatascience.com](https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a) 

# 7.模型度量和验证

一旦模型根据数据进行了训练，我们将尝试根据某些标准对模型进行比较(这是您使用测试数据的地方)，这也是您实际衡量模型表现的时候。有多种方法，以下是最常见的方法:

分类问题:

1.  混淆矩阵
2.  第一类错误
3.  第二类错误
4.  准确(性)
5.  回忆或真阳性率或敏感度
6.  精确
7.  特征
8.  F1 分数
9.  ROC 曲线- AUC 评分
10.  PR 曲线

回归问题:

1.  均方误差
2.  均方根误差(RMSE)
3.  平均绝对误差
4.  调整后的均方根误差

*请记住，在不同的用例中，您的衡量标准可能会有所不同。我们可能希望在某种情况下减少假阴性，放弃准确性可能是可以接受的。*

# 8.处理过度配合或配合不足

**过度拟合**是一种建模错误，当一个函数过于紧密地拟合一组有限的数据点时就会出现这种错误

当我们的模型不能捕捉数据的潜在趋势时，我们称之为欠拟合。

**过拟合和欠拟合**破坏了我们**机器学习模型的准确性。**

这个问题的解决方案是在模型创建步骤中提供的，通常使用以下三个步骤来减少模型中的过拟合和欠拟合。

1.  在 ANN 中删除图层
2.  正则化参数
3.  交叉验证

[](/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250) [## 第 7 章欠拟合、过拟合及其解决方案

### 机器学习系列！！！

medium.com](/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250) 

# 9.模型漂移

最后，我想指出一个在模型创建工作流程中被多次忽略的重要概念。随着时间的推移，当模型不像以前那样准确时，就会发生模型漂移，这可能是由于各种原因——模型从未见过的模式变化，或者是我们的模型过于天真，无法理解其细微差别的新情况。

我们主要可以将模型漂移分为两种类型:

数据漂移和概念漂移。我强烈建议你在这里阅读这篇小文章。

[https://mlopshowto . com/what-is-model-drift-and-how-it-can-negative-effect-your-machine-learning-investment-ce 7 F5 B9 B6 a 37](https://mlopshowto.com/what-is-model-drift-and-how-it-can-negatively-affect-your-machine-learning-investment-ce7f5b9b6a37)

*但最后，同样的解决方案是保持您的模型更新，并在您能够收集到越来越多的数据时将其公开。这样，模型就不会忘记时间的变化。*

# 结论

最后，我想指出的是，很多时候解决一个 ML 用例没有正确或错误的解决方案，但是有一个通用的结构模式需要遵循。即使没有定义边界，任何 ML 模型都是由它背后的一些数学定义的，最常见的是由一些概率计算的味道定义的，因此如果没有结构方法，它就没有多大意义。

这肯定不是我在上面列出的一个详尽的方法，但应该给任何致力于解决任何数据科学问题的个人提供方向。

希望你喜欢它，如果你觉得这里有什么可以改进的地方，请在评论中告诉我。