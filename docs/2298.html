<html>
<head>
<title>Malicious webpage classification using machine learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于机器学习的恶意网页分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/malicious-webpage-classification-using-machine-learning-607e2aecab2?source=collection_archive---------7-----------------------#2021-04-17">https://medium.com/analytics-vidhya/malicious-webpage-classification-using-machine-learning-607e2aecab2?source=collection_archive---------7-----------------------#2021-04-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="707f" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="4f14" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">基于ML的应用已经有很长一段时间了，我们看到它在几乎所有领域的使用，让它预测分数，推荐系统，股票市场和列表永远继续下去。我们使用机器学习来分类网页是否是恶意的。这有助于我们了解网站，我们也可以保护我们的信息不被窃取。因此，在下一节中，我将解释用于网页分类的算法和代码。</p><h1 id="8e74" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">代码解释</h1><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ka"><img src="../Images/c0b5e934c7446ffbfd7a8dddec6ba37c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*AOKVxzu-HfeSDbi-40eLPw.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">导入必要的库</figcaption></figure><p id="189e" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">这段代码导入了预处理数据集和预测网页URL是否恶意所需的必要库和功能。</p><p id="07da" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi"> Pandas </strong> - Pandas需要从其目录中加载数据集，对测试数据、训练数据和测试标签进行必要的预处理和分离。</p><p id="ac66" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi"> Matplotlib </strong> — Matplotlib是数据可视化所必需的，以了解数据中潜在的有趣趋势，并相应地对其进行处理。</p><p id="65d1" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi"> re </strong> - re是正则表达式的简写符号，我们在数据集的预处理过程中使用它来删除停用词、点、‘www’&amp;等。</p><p id="adaf" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi">Train _ test _ split</strong>——我们导入它是为了将我们的数据分割成适当比例的测试和训练数据。最鼓励的测试和训练数据比例分别是20%和80%。</p><p id="c9d5" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi"> TFIDFVectorizer- </strong> TF-IDF是词频逆文档频率的缩写。这是将文本转换成有意义的数字表示的非常常见的算法，该数字表示用于拟合预测的机器算法。</p><p id="9d46" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi">计数矢量器</strong> —用于将一组文本文档转换为术语/标记计数的矢量。它还支持在生成矢量表示之前对文本数据进行预处理。</p><p id="5eb0" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi"> LogisticRegression，MultinomialNB- </strong>预先训练的ML库，将用于预测网页是否是恶意的。</p><p id="e14a" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi">混淆矩阵，分类报告</strong>——我们用它来了解我们的ML算法在数据集上的性能，以及改进其性能的必要修正</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es kr"><img src="../Images/dad23ecee321d2e4fca50384b5a51eb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*dSXjtc8n6zCmLqlf_Swl1g.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">数据集的分割</figcaption></figure><p id="aa40" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">这段代码从目录中加载数据集。然后，我们将数据集“url”的特定数据指定为测试URL，以查看预处理完成得如何。在后续行中，我们导入Sklearn库的train_test_split，将数据集分成80%的训练数据集和20%的测试数据集。我们将变量“labels”分配给训练数据的“class”列，而将“test_labels”分配给测试数据的class列。然后，我们在控制台中打印训练数据样本和测试数据样本的编号，如下所示:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ks"><img src="../Images/3d2440f08c57b6cfd209934dccb8a6fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:434/format:webp/1*GcmHXxn3KF9hiWoLdfaRTQ.png"/></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es kt"><img src="../Images/42260e71582e6fcf0c0e9ea57bcc4b51.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*KoTjCXy7wBKXm21pkeUa_A.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">绘制数据趋势</figcaption></figure><p id="4b37" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">这段代码分别用于可视化训练数据和测试数据中好的和坏的URL的数量。我们使用熊猫功能来计算好的和坏的网址。块的上部对训练数据中的好的和坏的url进行计数，而块的下部对测试数据中的好的和坏的url进行计数。计数过程由“pd.value_counts”继续执行。使用'。我们以条形图的形式描述好的和坏的URL的数量。然后，我们指定某些参数，如fontsize、rotation，以使条形图的标题具有一定的大小，我们使用参数“kind=bar”将图形指定为条形图的形式。我们对测试数据也做同样的事情。这是我们得到的表示:</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ku"><img src="../Images/f42494b2a6178595913fb7ae91294f98.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*JtIW2LaAKZcwop0peZUe-A.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">测试数据集</figcaption></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es kv"><img src="../Images/437dc51a71abf031b0575394e60e8f81.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*1zS2jMAyUm53Sf0AyJ-RWw.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">训练数据集</figcaption></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es kw"><img src="../Images/1526d1ae0064bd2f7de9835522cfff05.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*VDQz2VRO5Z8oE9O0QZ-zjQ.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">url的预处理</figcaption></figure><p id="632e" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">我们定义了一个函数来对URL中的文本进行必要的预处理。</p><p id="f8f2" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi"> tokens = re.split('[/-]'，url) </strong></p><p id="e04d" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">只要有“/”或“-”，这行代码就会拆分url。接下来我们有一个</p><p id="6260" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">for循环，遍历数据中的每个URL</p><p id="f325" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi">如履薄冰(“)&gt; = 0: dot_split = i.split(' . ')</strong></p><p id="de17" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">这一行代码检查url中的点，如果发现点，它立即将url分成两部分，即域名和扩展名。</p><p id="5de1" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi">如果“com”在dot_split: </strong></p><p id="011d" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi"> dot_split.remove("com") </strong></p><p id="deb3" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi">如果“www”在dot_split: </strong></p><p id="8aae" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi">dot _ split . remove(" www ")</strong></p><p id="a74b" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">此块删除预处理后的URL中的扩展名，如“www”和“com ”,只返回网页的名称，因为它们不添加任何上下文。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es kx"><img src="../Images/ef9be47e1deae2d4ba2c39cfbceb0656.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*w-UgIoiRDyQB0WD86lBBkw.png"/></div></figure><p id="2f62" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">为了测试对数据集的预处理做得有多好，我们调用了在最后一个块中定义的函数来预处理我们在后面阶段已经声明的一个测试URL。我们引入了一个叫做计数矢量器和TFIDF矢量器的功能。标记化是从文本数据中移除停用词并使其适合预测建模的过程。我们配备了TFIDF和计数矢量器功能。CountVectorizer用于将文本文档的集合转换为术语/标记计数的向量。而TFIDF矢量器将文本数据转换成ML模型可以理解的数字。我们在训练和测试数据中执行这两种矢量化方法。我们得到的后来的结果是在代表数据中的每一个文本的大范围的值上。我们的ML模型无法学习如此大的值，因此我们应用fit_transform()和transform()来缩放特定范围内的数据参数，并学习数据集的输入特征的均值和方差。拟合方法计算平均值和方差，转换使用平均值和方差来转换数据中的所有要素。使用转换方法，我们可以使用从我们的训练数据计算的相同的均值和方差来转换我们的测试数据。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ky"><img src="../Images/44be3c196d189379e30d78d7abf7d659.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*CPd1vv3ED_ONnBu6YZp3eA.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">生成预测报告</figcaption></figure><p id="751e" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">为了生成ML算法在数据集上的性能报告，我们定义了一个函数，该函数生成一个热图以获得混淆矩阵，该矩阵说明了召回率和精确度，给出了关于多少假阴性、假阳性、真阴性和真阳性的读数。在标题中，我们打印了分数，即我们的模型的准确性分数，如下所示。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es kz"><img src="../Images/dcf743cb0c93d2c71d75eb90968e5fdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:542/format:webp/1*VWdwZr43wG7Ynb4nFzgIBw.png"/></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es la"><img src="../Images/5c85042497e73ee605d11791e989400b.png" data-original-src="https://miro.medium.com/v2/resize:fit:560/format:webp/1*RwEvoxVPEVA1YTMcWwl0dA.png"/></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es lb"><img src="../Images/5ea632c4078604e72414f38bf450d5d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*XvdjkX9SplK5B9SJGKDIww.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">为ML模型定义一个对象</figcaption></figure><p id="d9db" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">在对数据做了所有必要的预处理之后，我们已经准备好将数据输入到ML模型中。我们使用多项式朴素贝叶斯和逻辑回归作为我们的模型来预测url是否是恶意的。我们定义MNB并将其放入矢量化的URL中作为输入数据，将标签作为预测输出。然后我们生成一个分数来告诉我们的模型的准确性，并预测URL是否是恶意的，随后我们调用函数“classification_report”并生成相应的报告。我们对逻辑回归也做同样的事情。</p><p id="8e43" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated"><strong class="je hi">代码结论</strong></p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es lc"><img src="../Images/cc0cc336da1c1c65a91ff6302cf8833e.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*CGvCS0CM8isL46SQxHudPw.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">多项式朴素贝叶斯报告</figcaption></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ld"><img src="../Images/04e03eb7fe2083a7f70a42155337e969.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*Hvg5Qwh9jL39_xSKVzqPZw.png"/></div><figcaption class="ki kj et er es kk kl bd b be z dx translated">逻辑回归报告。</figcaption></figure><h1 id="8f10" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">查全率和查准率的平衡</strong></h1><p id="621b" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">在诸如信用卡欺诈检测/肿瘤分类的情况下，即使单个病例被错误分类，也会变成严重的问题，因为如此多的金钱或生命可能会处于危险之中。因此，在这种情况下，我们需要做的是在召回率和精确度之间取得平衡。对于像这样的情况，我们需要有一个高的召回分数，因为它告诉我们我们的模型做出预测和从数据集中的实际阳性中分类出真阳性的准确程度。通过F1评分，我们可以在查准率和查全率之间取得平衡。</p><p id="9534" class="pw-post-body-paragraph jc jd hh je b jf km jh ji jj kn jl jm jn ko jp jq jr kp jt ju jv kq jx jy jz ha bi translated">如果感兴趣，请点击“喜欢”按钮:))</p></div></div>    
</body>
</html>