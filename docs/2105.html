<html>
<head>
<title>Portfolio Optimization using Reinforcement Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用强化学习的投资组合优化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/portfolio-optimization-using-reinforcement-learning-1b5eba5db072?source=collection_archive---------2-----------------------#2021-04-05">https://medium.com/analytics-vidhya/portfolio-optimization-using-reinforcement-learning-1b5eba5db072?source=collection_archive---------2-----------------------#2021-04-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5644" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用RL建立3只股票的最优投资组合，并与基于投资组合理论的方法进行比较</p></div><div class="ab cl jd je gp jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="hb hc hd he hf"><p id="7566" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">强化学习可以说是人工智能中最酷的分支。它已经证明了自己的实力:震惊世界，击败了国际象棋、围棋甚至DotA 2的世界冠军。</p><p id="c7d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用RL进行股票交易一直是数据科学家的圣杯。股票交易吸引了我们的想象力，因为它容易获得，并且错误地引用卡迪B的话，我们喜欢钻石，我们喜欢美元😛。</p><p id="231e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用机器学习进行股票交易有几种方式。一种方法是使用预测技术来预测股票的走势，并构建一些基于启发式的机器人，使用预测来做出决策。另一种方法是构建一个机器人，它可以观察股票走势，并直接建议采取行动——买入/卖出/持有。这是强化学习的完美用例，因为我们通常只有在交易结束时才知道我们行动的累积结果。</p><h2 id="db1f" class="jk jl hi bd jm jn jo jp jq jr js jt ju iq jv jw jx iu jy jz ka iy kb kc kd ke bi translated">问题陈述</h2><p id="61f2" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">我将把它表述为一个投资组合优化问题:</p><blockquote class="kk kl km"><p id="9cb2" class="if ig kn ih b ii ij ik il im in io ip ko ir is it kp iv iw ix kq iz ja jb jc hb bi translated">给定3只不同股票的历史记录，我们如何每天在这些股票之间分配固定金额的资金，以使回报的可能性最大化。</p></blockquote><p id="4607" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">目标是为建立投资组合制定政策(战略)。投资组合本质上是在各种股票之间分配可用资源。然后，随着时间的推移，随着新信息的出现，策略需要重组投资组合。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div class="er es kr"><img src="../Images/624cc38206a68d7cc5c9839c0b63c3ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1114/format:webp/1*2SsVy90fMd-Zl2RddYDl7Q.png"/></div></figure><p id="edbf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，政策应该能够选择最优的投资组合(分配)。</p><p id="9b0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的解决方案是开发一个强化学习模型——一个通过观察每只股票的指标在每个时间步分配股票的代理。然后，我们将这种RL策略与Markowitz的有效边界方法进行比较——这种方法与“直觉”一起可能是大多数资产经理采用的方法。</p><p id="1bd4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="kn">强化学习快速笔记:</em> </strong></p><p id="a9de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">强化学习处理设计与<em class="kn">“环境”</em>交互的<em class="kn">“代理”</em>，并通过系统的试错法自学如何<em class="kn">“解决”</em>环境。一个环境可以是一个游戏，比如国际象棋或赛车，或者甚至可以是一个任务，比如解决一个迷宫或实现一个目标。代理是执行活动的机器人。</p><p id="5198" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">代理人通过与环境互动获得“回报”。代理人学习执行所需的“行动”,以最大化它从环境中获得的回报。如果代理累积了某个预定义的奖励阈值，则认为环境已解决。这种书呆子式的谈话是我们如何教机器人玩超人象棋或双足机器人走路的。</p><p id="912b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将设计一个代理，使用某种策略与交易环境互动，以最大化投资组合的价值。在这里，行动将是代理决定维持什么投资组合(例如，30%股票A，30%股票B，30%股票C，10%现金分割)。然后，代理人会收到该行为的正或负奖励(投资组合分配)。代理反复修改它的策略，直到它为给定的环境状态找出最佳的行动。</p><h2 id="f23f" class="jk jl hi bd jm jn jo jp jq jr js jt ju iq jv jw jx iu jy jz ka iy kb kc kd ke bi translated"><strong class="ak">实验设置:</strong></h2><p id="ef80" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">我设计了一个自定义环境来模拟实际的交易过程。代理可以通过以下方式与环境交互:</p><ol class=""><li id="4d18" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated">环境提供了对其当前状态的观察结果——3个种群的指标</li><li id="1b6c" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">代理将动作传递给环境。行动是建议的投资组合分配，例如，总价值的10%为现金，30%为股票1，30%为股票2，30%为股票3</li><li id="078a" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">环境以一个时间步长改变状态，并返回新的状态，以及与先前投资组合相关联的回报(值的改变)</li></ol><p id="baab" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">重复步骤1到3，直到剧集完成。每一步结束时获得的奖励之和就是总奖励。目标是在一集结束时最大化总奖励。</p><p id="6042" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一集的大小设置为500个时间步长。这是从650，000+时间步长的数据集中随机切片的。每次初始化环境时，都会选择整个数据集的不同部分。这将防止代理记住环境。环境的每次运行都会有所不同。此外，代理的培训和评估是在不同的环境下进行的。所以代理从一部分数据中学习一个策略。然后在数据集的不同部分评估策略。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/47ec56827e402354cc90d0f8190e73e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nCUWuQ-dkNmxLDPh62K-LQ.png"/></div></div><figcaption class="ls lt et er es lu lv bd b be z dx translated">环境的每次初始化都会选取数据集的不同随机切片</figcaption></figure><p id="5525" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在使用该设置评估RL算法和Markowitz模型。</p><h2 id="2706" class="jk jl hi bd jm jn jo jp jq jr js jt ju iq jv jw jx iu jy jz ka iy kb kc kd ke bi translated">结果:</h2><h2 id="77d8" class="jk jl hi bd jm jn jo jp jq jr js jt ju iq jv jw jx iu jy jz ka iy kb kc kd ke bi translated">强化学习</h2><p id="9e33" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">在这里，我们将使用现成的Actor Critic模型的未调优的懒惰实现。为此，我们将使用tensorflow发布的tf-agents框架。请检查<a class="ae lw" href="https://github.com/kvsnoufal/portfolio-optimization" rel="noopener ugc nofollow" target="_blank">我的github </a>的完整代码和培训细节。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es lx"><img src="../Images/61dacc01b3f660e56b87b29c44013d15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KhaumfNnPUNwU9sc4UUHww.png"/></div></div><figcaption class="ls lt et er es lu lv bd b be z dx translated">训练演员-评论家模型超过2000次迭代</figcaption></figure><p id="0066" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">车型评价:</strong></p><p id="d372" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">评估超过100次的环境运行，</p><p id="6f12" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">平均回报率:+20%</p><h2 id="7bf1" class="jk jl hi bd jm jn jo jp jq jr js jt ju iq jv jw jx iu jy jz ka iy kb kc kd ke bi translated">马科维茨的有效边界</h2><p id="aa1c" class="pw-post-body-paragraph if ig hi ih b ii kf ik il im kg io ip iq kh is it iu ki iw ix iy kj ja jb jc hb bi translated">这种方法提出了一个评估投资组合风险和回报的框架。</p><p id="039d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">投资组合的回报是我们可以从该投资组合中预期的每个时间步的平均回报。</p><p id="f209" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">风险是每日回报的标准差。这给出了股票波动性的一个度量。</p><p id="2b46" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过绘制每个投资组合的风险和回报，资产经理可以做出明智的投资决策。</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ly"><img src="../Images/996ba15b655150f90e9aea41fb09af59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uic5Jy8kE1zMlPdT_SGj-w.png"/></div></div></figure><p id="d74b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有效边界线显示了给定风险组合的最高回报。</p><p id="e04d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于我们的评估，我们设计了一个代理人，从基于前30个时间步的表现在每个时间步计算的有效边界图中选择一个中等风险高回报的投资组合。</p><p id="2ede" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">平均回报率:-1%</p><p id="72e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们在这里可以看到，有效边界似乎对我们挑选的股票无效。大概是因为我们挑的股票波动性大。</p><p id="33fb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">比较</strong></p><p id="3d41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是同一环境中两种策略的对比:</p><figure class="ks kt ku kv fd kw er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es lz"><img src="../Images/b1608fafa87a53bdfc27497bfa913178.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oYjZJN9veE4grpIx8FUQpw.png"/></div></div></figure><ol class=""><li id="0b2c" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated">RL的投资组合增长到160%，Markowitz的收缩到96%</li><li id="ec49" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">我们看到两种算法都在股票3上分配了大量资金，这是因为股票3的价值非常低且稳定。因此，价值的小幅增长可以带来巨大的回报(%)，而不会带来波动风险。</li><li id="68eb" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">我们看到，在波动性增加或所有股票都在下跌时，RL决定通过出售股票和增加手头的现金来对冲损失——当我们没有启用卖空选项时，这是非常明智的策略。</li><li id="000b" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">总的来说，RL策略似乎是识别价格的小幅飙升，并立即利用这一点。</li></ol><p id="ec0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们的实验中，我们看到RL始终优于Markowitz的方法。</p><blockquote class="kk kl km"><p id="79df" class="if ig kn ih b ii ij ik il im in io ip ko ir is it kp iv iw ix kq iz ja jb jc hb bi translated">不用说，这些结果被认为是轶事。这些实验是在不切实际的假设下进行的，并且是在一个精心挑选的小样本空间中进行的——这并不完全接近真实世界的交易。我们忽略了几个因素，比如交易中的时滞、交易成本、卖空、对冲损失等等。</p></blockquote><p id="f69b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae lw" href="https://github.com/kvsnoufal/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Github回购</strong></a>:<a class="ae lw" href="https://github.com/kvsnoufal/portfolio-optimization" rel="noopener ugc nofollow" target="_blank">https://github.com/kvsnoufal/portfolio-optimization</a></p><p id="1187" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">巨人的肩膀</strong></p><ol class=""><li id="7d26" class="kz la hi ih b ii ij im in iq lb iu lc iy ld jc le lf lg lh bi translated"><a class="ae lw" href="https://www.sciencedirect.com/science/article/pii/S0957417420302803" rel="noopener ugc nofollow" target="_blank">https://www . science direct . com/science/article/pii/s 0957417420302803</a></li><li id="65d2" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><a class="ae lw" href="https://arxiv.org/abs/1706.10059" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1706.10059</a></li><li id="61cf" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><a class="ae lw" href="https://en.wikipedia.org/wiki/Modern_portfolio_theory" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Modern_portfolio_theory</a></li><li id="b7a5" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">https://www.youtube.com/watch?v=1jQPP3RfwMI&amp;ab _ channel = JeffHeaton</li><li id="cad6" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><a class="ae lw" href="https://www.tensorflow.org/agents/overview" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/agents/overview</a></li><li id="e6ee" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated"><a class="ae lw" href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_12_05_apply_rl.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/jeffheaton/t81 _ 558 _ deep _ learning/blob/master/t81 _ 558 _ class _ 12 _ 05 _ apply _ rl . ipynb</a></li><li id="a442" class="kz la hi ih b ii li im lj iq lk iu ll iy lm jc le lf lg lh bi translated">阿米尔-寻求指导和建议</li></ol><p id="477f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="kn">免责声明:我不是投资顾问。这不被认为是购买或出售股票、债券或进行任何其他证券交易的财务建议。在做出任何和所有投资决定之前，进行自己的尽职调查，或咨询有执照的财务顾问或经纪人。</em></p><blockquote class="kk kl km"><p id="8f5d" class="if ig kn ih b ii ij ik il im in io ip ko ir is it kp iv iw ix kq iz ja jb jc hb bi translated"><strong class="ih hj"> <em class="hi">关于作者</em> </strong></p><p id="453d" class="if ig kn ih b ii ij ik il im in io ip ko ir is it kp iv iw ix kq iz ja jb jc hb bi translated"><em class="hi">我在阿联酋迪拜控股公司工作，是一名数据科学家。你可以在kvsnoufal@gmail.com联系我或者在https://www.linkedin.com/in/kvsnoufal/联系我</em></p></blockquote></div></div>    
</body>
</html>