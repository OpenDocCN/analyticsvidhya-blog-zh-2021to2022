<html>
<head>
<title>New to Neural Networks?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络新手？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/new-to-neural-networks-544ca4d6dacd?source=collection_archive---------10-----------------------#2021-07-08">https://medium.com/analytics-vidhya/new-to-neural-networks-544ca4d6dacd?source=collection_archive---------10-----------------------#2021-07-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="d7a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它们比你想象的要简单！</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/f531c4c40e9a7765054b32b71b52cc74.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8c8xKZwl5GY8xsjNLWeOhQ.jpeg"/></div></div></figure><h1 id="bf37" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">介绍</h1><p id="c9d8" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">神经网络已经存在一段时间了。Warren McCulloh和Walter Pitts早在1943年就写了一篇论文，思考动物神经元的内部工作方式，并提出了一种解释神经元如何工作的方法，即通过构建一个使用电路构建的简单神经网络。</p><p id="2f6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，在此后的近80年里——神经网络不仅仅是一个获得一个点的对象——它们是我们所拥有的最通用和最灵活的计算算法。</p><p id="3a27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">尽管神经网络在现实世界应用中取得了早期的成功，如伯纳德·维德罗和斯坦福大学的马尔西安·霍夫的ADALINE和MADALINE(自1959年以来一直在使用的模型)，但多年来我们已经意识到神经网络很棒，但它们不是一切的解决方案！</p><p id="2d2a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">还有一个事实是，神经网络(尽管这个名字可能会给你一种矛盾的直觉)是对实际神经元工作方式的过度简化，在解释我们的大脑如何工作时几乎没有什么作用。</p><p id="25ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我们意识到我们能够用更复杂的架构和更深层次的神经网络来训练算法时，机器学习的世界发生了革命性的变化，因为我们得到了更强大的硬件-产生了深度学习-训练深度神经网络及其变体的艺术，这是不断给予的礼物！</p><p id="d2bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自动驾驶汽车(特斯拉Model S？)、假新闻检测器、垃圾邮件分类检测、自然语言处理、AI助手(Cortana、Alexa、Bixby、Siri、Google Assistant等。)、对象识别和检测、图像检测和识别、医疗保健(通过语义分割预测癌症和其他肿瘤、检测儿童的发育抑制)、图像和视频增强、对原始单色图像着色、深度伪造和深度伪造检测、从图像数据合成视频以及帧增强和分辨率放大、文本到语音和语音识别、文本和语言翻译、字符识别(ocr主要用于检测笔迹，想想google lens)、游戏和游戏中的NPC、零玩家游戏、场景和图像描述/字幕和数据分析以及天气/作物产量预测。</p><p id="ef6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个清单可以一直列下去，而且看不到尽头。机会是——如果你有一项任务，你有足够的数据，并且想要模仿甚至超过人类表现的出色表现，你可以用深度神经网络或它的某种变体来实现它。</p><p id="8d77" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">【注意:我写这篇文章是假设读者对矩阵代数和微分学有基本的了解，但是如果你不懂任何数学(术语、方程等。)不用担心！你可以随时停下来查找资料，或者在需要帮助的时候伸出援手！此外，图表是由你真正用MS paint制作的，我不是最好的艺术家，所以请原谅我]</p></div><div class="ab cl kr ks go kt" role="separator"><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw"/></div><div class="ha hb hc hd he"><h1 id="ec3a" class="jo jp hh bd jq jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl bi translated">分解神经网络</h1><p id="fa6b" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">神经网络由4个重要组件组成:</p><p id="b2ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">(一)输入层</p><p id="bf6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">(二)隐藏层</p><p id="2992" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈢参数(权重、偏差)</p><p id="0086" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈣输出层</p><p id="b7d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们更详细地看一看它们。</p><p id="9633" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">输入图层:</em> </strong></p><p id="5934" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先是我们的输入层。假设我们有一个映射输入值x1，x2，x3，x4的任务。xm到目标输出值y1，y2，y3，y4…ym，其中m是我们数据集中的样本数(1个样本= 1对(x，y))。</p><p id="695f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">基于这些假设，我们的输入层可能如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es le"><img src="../Images/78bbb92c7c6b48d5d3715248b6a21ee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:890/format:webp/1*gMhiWHEyLNKH_zwTv7Kh1g.png"/></div><figcaption class="lf lg et er es lh li bd b be z dx translated">每个元素包含一个来自示例(x，y)的输入值x</figcaption></figure><p id="6a95" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">隐藏层:</em> </strong></p><p id="26d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的每一个输入元素都输入到下一层——隐藏层的每一个神经元中。</p><p id="1a83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们称隐藏层为“隐藏”，因为我们不知道它们的值。我们能从一个隐藏层得到的只是输入给它的信息和它的神经元产生的输出。这是真正的奇迹发生的地方，一个隐藏层或多个隐藏层给我们的神经网络增加了非线性(稍后将详细介绍)。</p><p id="2f65" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，为了简单起见，让我们在这个例子中保持一个隐藏层。我们的输入层应该输入到我们的隐藏层-</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lj"><img src="../Images/de6baf647683c0b40e77e75c9d21f112.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*q6dzlyIznYY4NH5Y8EyOTA.png"/></div></div><figcaption class="lf lg et er es lh li bd b be z dx translated">输入层馈入隐藏层</figcaption></figure><p id="d39c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，请注意我们隐藏层中的最后一个神经元是如何标记为a(j)的——这是因为隐藏层不需要与输入层具有相同数量的元素。在一个隐藏层中，你可以有3个、5个、10个、20个、100个或者任何你想要的数量的神经元。你也可以在每个隐藏层中有不同数量的神经元。</p><p id="fefb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">参数和激活:</em> </strong></p><p id="5168" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们为每个输入分配一个数值，称为“权重”，记为“w”。这是一个参数，可以认为是我们神经网络的控制值。我们还花时间添加另一个称为“偏差”的参数，并表示为“b”到每一层，这是一个常量值，如我们将添加到线性函数中。</p><p id="ade8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们来谈谈这里的“a”，它代表激活——我们隐藏层中的神经元正在进行的计算。</p><p id="8ff7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于维数为(nx，m)的输入矩阵X(或X = [ x1，x2，x3，…。xm]每个x本身是nx行的列向量)，我们有一个称为预激活参数的东西(表示为“z”)。</p><p id="02f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">z = x*w + b</p><p id="b5a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们可以使用这个预激活参数来计算来自我们神经元的激活，这成为它的输出，并被馈送到它后面的层。所以，来自我们神经元的激活(a)是:</p><p id="7b75" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">a = activation_function(z)，其中activation_function()是我们选择的用于处理“z”的数学函数，这很重要，您选择的激活函数会影响您的神经网络的性能。</p><p id="57c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一些常用的激活函数有sigmoid、tanh、softmax和relu。每一个都有不同的应用，根据你的需求，你可以设计你的神经网络来隐藏不同的激活函数。</p><p id="6d7c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，如果我们为上面的示例隐藏层选择sigmoid激活函数，则:</p><p id="3570" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">a = 1/(1 + e^(-z))</p><p id="2fdb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中e是指数常数e (e ≈ 2.718)。</p><p id="0549" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">输出层:</em> </strong></p><p id="58d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的输出层由单个神经元组成。这个神经元将通过接收激活a1、a2…a(j ),然后产生输出ŷ.，对我们的原始输入数据进行预测</p><p id="fd14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中，ŷ = a1*w1+a2*w2……a(j)*w(j)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lk"><img src="../Images/a0cabc01402f107e9caeeb805dea0496.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*-RLhsjn0O1O7XNDJGkmDJA.png"/></div></figure><p id="6c6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就是这样，这些都是神经网络的元素。但是等等！我们还没有真正看到他们的行动，那里有很多有趣的事情要谈，所以让我们接下来看看。</p></div><div class="ab cl kr ks go kt" role="separator"><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw"/></div><div class="ha hb hc hd he"><h1 id="94a5" class="jo jp hh bd jq jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl bi translated">训练神经网络</h1><p id="790a" class="pw-post-body-paragraph ie if hh ig b ih km ij ik il kn in io ip ko ir is it kp iv iw ix kq iz ja jb ha bi translated">训练神经网络也是一个循序渐进的过程，我们可以将此过程分为以下步骤:</p><p id="d285" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈠数据收集和预处理</p><p id="23ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">(二)初始化参数</p><p id="b3c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈢向前传球</p><p id="c334" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈣计算成本</p><p id="f618" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈤向后传球</p><p id="d8ca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈥更新参数</p><p id="f0cf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈦业绩优化和基准测试</p><p id="35d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">数据采集和预处理:</em> </strong></p><p id="84bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是训练的第一个方面，也是经常被严重低估的一个方面，不仅仅是训练神经网络，而是训练你想要建立的任何人工智能模型。一旦你脑子里有了一个问题陈述，例如，“确定一幅图像是否包含一支笔”，你就可以专注于这项任务需要什么样的数据。</p><p id="adf1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">用于检测图像中笔的数据集将包含各种笔的图像以及没有笔的图像。多种颜色、角度、类型、大小和方向将会有所帮助——你应该有一个多样化的数据集，除非你的特定问题需要一个受限的数据集(非常罕见)。</p><p id="dd0b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们把数据分成三个数据集-</p><p id="60e7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈠训练数据集(约98%的可用数据)</p><p id="f583" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈡发展数据集(1%)</p><p id="5582" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">㈢测试数据集(1和)</p><p id="322c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可能听说过60–20–20训练-开发-测试分割，如果您无法访问大量数据(少于10，000个示例)，这是合理的，但是对于一个相当大的数据集，比如说100，000或1，000，000甚至1百万以上，您不需要200，000个示例的开发和测试集，10，000个示例就足够了。</p><p id="3f4d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，把dev集合想象成一个集合，从多个模型中测量性能，你将为你的问题选择最好的一个。测试集用于检查过度拟合/欠拟合(也称为偏差/方差检查，稍后将详细介绍)。</p><p id="3be1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">出于时间的考虑，我将省略这一部分的更多细节，因为老实说，以数据为中心的人工智能是未来，数据采集、分割和两者之间的一切都值得单独撰写一篇文章。</p><p id="e0ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">初始化参数:</em> </strong></p><p id="aea9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们必须将权重“w”初始化为随机值。这样做是因为如果我们的权重被初始化为零或相同的值，我们所有的隐藏层都变得过时-当值通过它们时，它们一遍又一遍地计算相同的值。这叫做对称状态，我们想要打破对称，我们想要把它扔到地上，粉碎成碎片。当我们将w初始化为随机值时，对称破缺可以实现。</p><p id="bc19" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以将偏置项“b”初始化为零，因为它们对对称态没有直接贡献。将它们初始化为零不会损害我们的神经网络。</p><p id="e3af" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">向前传球:</em> </strong></p><p id="f23c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以，你已经走了这么远，你理解了神经网络的各个部分。你还制定了一个你想自动化/学习的任务，希望你有足够的数据。</p><p id="66d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在您将参数w初始化为随机值并将b初始化为零之后，我们就可以开始我们的正向传播了。</p><p id="d6ee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将来自训练集x的输入值提供给输入层。这产生了预激活参数z，z=x*w(转置)+ b。</p><p id="ec97" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦我们的隐藏层计算了这个预激活参数的激活，它就把这些值传递给输出层。我们神经网络的预测被计算成ŷ.</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lk"><img src="../Images/b780c554da1f06f7d2b2c491387c0499.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*1DoqLVr6Na4ZPkOrBlq0BA.png"/></div></figure><p id="7531" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这结束了一次向前传球。现在，是时候进入正题了-</p><p id="e46a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">计算成本:</em> </strong></p><p id="15b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">“损失”是与我们的训练数据示例(x，y)中的目标输出“y”相比时，由我们的神经网络生成的预测中存在的误差的度量</p><p id="70c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">L( ŷ，y)=-y *对数(ŷ)-(1-y)*log(1- ŷ)</p><p id="4b10" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这也称为逻辑损失函数，您还可以使用其他类型的损失函数。</p><p id="81b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">成本函数就是在我们整个训练集上计算的损失。这可以定义为:</p><p id="9862" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">J(w，b) =(对于i=1…m)(∑I[-y(I)* log(ŷ(i))-(1-y(i))*log(1- ŷ(i))])/m</p><p id="ecc4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">概括地说，我们训练神经网络的目标是获得最大的准确性，并将误差降低到尽可能低的值。从而最小化成本函数。</p><p id="9e3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">向后传递:</em> </strong></p><p id="d11e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦我们有了成本，我们就可以计算参数“𝛿w”和“𝛿b".”的偏导数这是使用反向传播算法实现的，该算法本身值得单独发表一篇文章(或几篇文章)。</p><p id="5c10" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本质上，</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lk"><img src="../Images/16e1a978cafa419c85867d458da70bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*WOePuHOopB71S-LYyiC-LQ.png"/></div></figure><p id="30b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于层l，</p><p id="0d4b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">𝛿a =[-y(1)/a(1)+((1-y(1))/(1-a(1)))-y(2)/a(2)+((1-y(2))/(1-a(2)))……-y(m)/a(m)+((1-y(m))/(1-a(m)))]</p><p id="5337" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">𝛿Z[l] = 𝛿A[l] *激活_ fn _一阶_导数[l](Z[l])</p><p id="1234" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">𝛿w[l]=(𝛿z[l]*a[l-1]transposed)/m</p><p id="8fbc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">𝛿b[l] = [𝛿Z[l]沿排求和]/m</p><p id="685c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">𝛿a[l-1 = 𝛿z[l]*w[l]transposed</p><p id="3d1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意:同样，如果数学现在还不清楚，我将进行反向传播，这是一种推导，并在未来的文章中更详细地讨论它——现在，如果太难，你可以从表面上看这些方程。</p><p id="600c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">更新参数:</em> </strong></p><p id="443e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是更新网络参数。这可以通过使用以下等式来实现:</p><p id="035c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于层“l”:</p><p id="0575" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">learning_rate*𝛿W[l]</p><p id="a289" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">learning_rate*𝛿b[l]</p><p id="95f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">学习率也可以表示为α。</p><p id="3bbc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过计算参数的偏导数(也称为梯度)来最小化成本的过程是使用反向传播来完成的，但是随后对成本执行这种更新和优化是使用诸如批量梯度下降(这里使用)之类的优化算法来完成的。</p><p id="4370" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其他常用的优化算法有Adam、小批量梯度下降、带动量的梯度下降。</p><p id="aebe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个历元是一批训练数据训练的完成。</p><p id="2be1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里使用的批量梯度下降优化算法使用整个训练数据集作为“批量”,因此当我们迭代训练数据集时，推断训练的迭代等于一个时期。</p><p id="70a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ld">性能优化:</em>T3】</strong></p><p id="0b26" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">经过多次训练后(你可以点击并尝试找到正确的数字)，你最终得到一个模型，这个模型是为你希望它执行的任务而训练的。</p><p id="f915" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是它在这项任务中的表现取决于它的误差有多低，以及它的精确度有多高。在你完成训练后，错误分析是适当的。确保你的模型不会过紧或过紧。</p></div><div class="ab cl kr ks go kt" role="separator"><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw"/></div><div class="ha hb hc hd he"><h1 id="82d2" class="jo jp hh bd jq jr ky jt ju jv kz jx jy jz la kb kc kd lb kf kg kh lc kj kk kl bi translated">深度神经网络:</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ll"><img src="../Images/d7dd11cc2ba603351785ce5b3d5afa16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qixa0tMO8LoW-Nru3VHtHg.png"/></div></div></figure><p id="7ac8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">既然我们已经看到了神经网络是如何构建和训练的，让我们来谈谈浅层和深层神经网络。简而言之，我们通常将具有多达2个隐藏层的神经网络称为浅神经网络，将具有两个以上隐藏层的神经网络称为深神经网络。</p><p id="6b85" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面所有的方程都是为“l”层写的，因此适用于深度神经网络，那些不适用的方程可能也适用于深度神经网络。</p><p id="ebc4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就是这样。这就是你开始学习神经网络所需要的所有介绍性信息。不要忘了使用它们，试着用你觉得舒服的任何语言自己实现一个神经网络！</p></div></div>    
</body>
</html>