<html>
<head>
<title>A Machine Learning Roadmap to Naive Bayes</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">朴素贝叶斯的机器学习路线图</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-machine-learning-roadmap-to-naive-bayes-66437a48d9f3?source=collection_archive---------26-----------------------#2021-01-17">https://medium.com/analytics-vidhya/a-machine-learning-roadmap-to-naive-bayes-66437a48d9f3?source=collection_archive---------26-----------------------#2021-01-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1f79" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">朴素贝叶斯</em> </strong> <em class="jc">是一种基于</em> <strong class="ig hi"> <em class="jc">贝叶斯定理</em> </strong> <em class="jc">的概率机器学习算法，用于多种分类任务。</em></p><p id="96b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">在本文中，我们将理解朴素贝叶斯算法及其基本概念，以便在理解中没有怀疑的余地。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/fa23a098170508c0be3e48e1a8bdce5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nZa89O2scG3MAe_uv83ulA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">图片来源:Becoming.ai</figcaption></figure><p id="fbcb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">朴素贝叶斯是一种简单但惊人强大的概率机器学习算法，用于预测建模和分类任务。</em></p><p id="c221" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">朴素贝叶斯的一些典型应用有<strong class="ig hi"> <em class="jc">垃圾邮件过滤</em></strong><strong class="ig hi"><em class="jc"/></strong><strong class="ig hi"><em class="jc">文档分类</em> </strong>等。这是一种流行的算法，主要是因为它可以很容易地用代码编写，并且可以很快做出预测，这反过来又增加了解决方案的可扩展性。</p><blockquote class="jt ju jv"><p id="b1d7" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">传统上，朴素贝叶斯算法被认为是基于实践的应用程序的首选算法，主要用于需要对用户请求做出即时响应的情况。</p><p id="f859" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">它是根据托马斯·贝叶斯牧师的作品改编的，因此得名。在开始学习朴素贝叶斯之前，重要的是要了解贝叶斯学习，什么是“条件概率”和“贝叶斯规则”。</p></blockquote><p id="5e3f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">贝叶斯学习是一种<em class="jc">监督学习技术</em>，其目标是建立一个具有目标属性具体定义的分类标签分布模型。朴素贝叶斯是基于应用贝叶斯定理和每一对特征之间独立性的<strong class="ig hi"> <em class="jc">朴素</em> </strong>假设。</p><p id="f2ba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">让我们通过一些例子从理解条件概率的原语开始:</em> </strong></p><h2 id="4836" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated"><strong class="ak">例一</strong></h2><p id="c2a3" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">假设你有一枚硬币和一个骰子。当你掷硬币时，得到正面或反面的机会是均等的。所以你可以说得到正面的概率或者得到反面的概率是50%。</p><p id="8857" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在如果你掷骰子，从6个数字中得到1的概率是1/6 = 0.166。骰子上其他数字的概率也是一样的。</p><h2 id="8ed4" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">实施例二</h2><p id="7059" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated"><em class="jc">考虑另一个打牌的例子。你被要求从这副牌中挑选一张牌。给定一张红心牌，你能猜出得到国王的概率吗？</em></p><p id="839b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里给定的条件是牌是红心，所以分母必须是13 <em class="jc">(一副牌有13颗红心)</em>而不是52。由于红心里面只有一张k，所以如果这张牌是红心，那么它是k的概率是<strong class="ig hi"> 1/13 = 0.077 </strong>。</p><p id="2ea2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">所以当你说</em> <strong class="ig hi"> <em class="jc">条件概率</em></strong><em class="jc"/><strong class="ig hi"><em class="jc">一个给定B </em> </strong> <em class="jc">时，指的是一个给定B已经发生的概率。这是典型的</em> <strong class="ig hi"> <em class="jc">条件概率的例子。</em> </strong></p><p id="0116" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">数学上</em>，给定B的<em class="jc">条件概率</em>可以定义为:</p><p id="f252" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc"> P(A和B) / P(B) </em> </strong></p><h1 id="0619" class="kz ka hh bd kb la lb lc kf ld le lf kj lg lh li km lj lk ll kp lm ln lo ks lp bi translated">贝叶斯定理</h1><p id="20f9" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated"><em class="jc">贝叶斯定理帮助你根据与前一事件有对应关系的任何事件的先验知识来检查一个事件的概率。它的用途主要是在概率论和统计学中。</em></p><blockquote class="jt ju jv"><p id="e71d" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">例如，如果我们有一些先验信息，如房屋周围的设施，与在不知道房屋位置的情况下做出的另一个评估相比，可以更好地计算出房屋价格高的概率。</p></blockquote><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="3616" class="jz ka hh lr b fi lv lw l lx ly">P(A|B) = <strong class="lr hi">[</strong>P(B|A)P(A)<strong class="lr hi">]</strong>/<strong class="lr hi">[</strong>P(B)<strong class="lr hi">]</strong></span></pre><p id="d39d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">上面的等式显示了贝叶斯定理的基本表示，其中A和B是两个事件:</em></p><p id="7eca" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"><em class="jc">P(A | B)</em></strong><em class="jc">:</em>事件A发生的条件概率，假定B已经发生。这被称为<strong class="ig hi"> <em class="jc">后验概率。</em> </strong></p><p id="c62b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc"> P(A)和P(B)</em></strong><em class="jc">:</em>A和B彼此没有任何对应关系的概率。</p><p id="b042" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"><em class="jc">P(B | A)</em></strong><em class="jc">:</em>事件B发生的条件概率，给定A已经发生。</p><p id="1e30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">对应于机器学习算法，贝叶斯定理可以被重新表述为:</em></p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="e46d" class="jz ka hh lr b fi lv lw l lx ly">posterior = (prior x likelihood) / (evidence)</span></pre><blockquote class="jt ju jv"><p id="14ac" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">考虑一种情况，其中属性的数量是n，响应是一个布尔值。即<strong class="ig hi">真</strong>或<strong class="ig hi">假</strong>。属性是分类的(本例中有两个类别)。您需要为实例和响应空间中的所有值训练分类器。</p></blockquote><p id="1dfe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个例子在大多数机器学习算法中实际上是不可能的，因为你需要计算<strong class="ig hi"> 2∗(2^n-1) </strong>参数来学习这个模型。这意味着对于30个布尔属性，你需要学习超过30亿个参数，这是不现实的。</p><h1 id="ba24" class="kz ka hh bd kb la lb lc kf ld le lf kj lg lh li km lj lk ll kp lm ln lo ks lp bi translated">朴素贝叶斯分类器</h1><p id="5b63" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">机器学习中的朴素贝叶斯分类器是一类基于贝叶斯定理的简单概率机器学习模型。<em class="jc">简单来说，就是一种假设预测器之间相互独立的分类技术。</em></p><p id="349d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">朴素贝叶斯分类器通过对训练数据集做出<strong class="ig hi"> <em class="jc">条件依赖</em> </strong>的假设来降低贝叶斯分类器的复杂性。</p><blockquote class="jt ju jv"><p id="54a6" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">假设给定变量X，Y和Z，当且仅当给定Z，X的概率分布独立于Y的值时，X将有条件地独立于Y，这是条件依赖的假设。</p><p id="f434" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">换句话说，你也可以说，给定Z，X和Y是有条件独立的当且仅当，X出现的知识没有提供关于Y出现的可能性的信息，反之亦然，给定Z出现。这个假设是朴素贝叶斯中术语<strong class="ig hi">朴素</strong>背后的原因。</p></blockquote><p id="f33e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">考虑到n个不同的属性，可能性可以写成:</em></p><pre class="je jf jg jh fd lq lr ls lt aw lu bi"><span id="5826" class="jz ka hh lr b fi lv lw l lx ly">              n          <br/>P(X₁...Xₙ|Y) = π P(Xᵢ|Y)<br/>              i=1</span></pre><p id="ddf5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">数学表达式中:</em></p><p id="ea78" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc"> X </em> </strong>代表<strong class="ig hi"> <em class="jc">属性</em></strong>&amp;<strong class="ig hi"><em class="jc">Y</em></strong>代表<strong class="ig hi"> <em class="jc">响应变量。</em>T25】</strong></p><blockquote class="jt ju jv"><p id="98fa" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">所以，<strong class="ig hi"> P(X|Y) </strong>变成等于给定Y的每个属性的概率分布的乘积。</p></blockquote><h2 id="8d18" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated"><strong class="ak">最大化后验概率</strong></h2><p id="5d6e" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">如果想求Y的多个值的<strong class="ig hi"> P(Y|X) </strong>的后验概率，需要计算Y的所有不同值的表达式。</p><blockquote class="jt ju jv"><p id="8b59" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">让我们假设一个新的实例变量<strong class="ig hi"> X_NEW </strong>。在给定<strong class="ig hi"> X_NEW </strong>的观察属性和从训练数据集估计的分布P(Y)和<strong class="ig hi"> P(X|Y) </strong>的情况下，您需要计算Y取任何值的概率。</p></blockquote><p id="2815" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了根据为<strong class="ig hi"> P(Y|X) </strong>获得的不同值预测响应变量，您需要考虑一个<em class="jc">可能值</em>或这些值的<em class="jc">最大值。</em></p><blockquote class="jt ju jv"><p id="c4c8" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">因此，这种方法被称为<strong class="ig hi">最大化后验概率</strong>。</p></blockquote><h2 id="e735" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated"><strong class="ak">最大化可能性</strong></h2><p id="0ce4" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">如果您假设响应变量是<em class="jc">均匀分布的</em>，这意味着它获得任何响应的可能性是相等的，那么您可以简化朴素贝叶斯算法。</p><blockquote class="jt ju jv"><p id="2d16" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">这种假设的优点是先验的或P(Y)变成一个常数值。</p></blockquote><p id="7217" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于先验和证据变得独立于响应变量，它们可以从等式中移除。</p><blockquote class="jt ju jv"><p id="95ae" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">所以，最大化后验概率就变成了最大化似然问题。</p></blockquote><h1 id="671d" class="kz ka hh bd kb la lb lc kf ld le lf kj lg lh li km lj lk ll kp lm ln lo ks lp bi translated">如何用朴素贝叶斯模型进行预测？</h1><blockquote class="jt ju jv"><p id="d0e6" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">考虑这样一种情况，你有1000种水果，要么是“香蕉”，要么是“苹果”，要么是“其他”。这些将是变量y的可能类别。</p></blockquote><p id="d850" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">以下X个变量的数据均为二进制(0和1): </em></p><ul class=""><li id="3b09" class="lz ma hh ig b ih ii il im ip mb it mc ix md jb me mf mg mh bi translated"><strong class="ig hi">长<em class="jc"/>长</strong></li><li id="753a" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated"><strong class="ig hi"><em class="jc"/></strong></li><li id="025f" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated"><strong class="ig hi"> <em class="jc">黄色</em> </strong></li></ul><p id="3735" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">训练数据集将如下所示:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mn"><img src="../Images/d79baf57fcf144e0009de29641eba006.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t72oWMb3RE4mt2TqS3ciaA.png"/></div></div></figure><p id="29ea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">现在让我们总结训练数据集以形成如下计数表:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mo"><img src="../Images/fc6b8e49eb5f7031ba945ed983d8ea9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8-zhYyrq0BOnES_M3D01Lg.png"/></div></div></figure><p id="9859" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">分类器的主要任务是在已知三个属性<em class="jc">(长、甜、黄)</em>的情况下，预测给定的水果是<em class="jc">【香蕉】</em>还是<em class="jc">【苹果】</em>还是<em class="jc">【其他】</em>。</p><p id="226c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">考虑这样一种情况，给你一个又长又甜的黄色水果，你需要预测它是什么类型的水果。</p><blockquote class="jt ju jv"><p id="f520" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">这种情况类似于只有在已知定型数据集中的X属性时才需要预测Y的情况。使用朴素贝叶斯可以很容易地解决这个问题。</p></blockquote><p id="a135" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你需要做的事情是计算3个概率，即成为香蕉或苹果或其他的概率。概率最大的那个会是你的答案。</p><p id="8ae1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">第一步</em> </strong></p><p id="667b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，您需要计算每个水果类别在所有水果中所占的比例，这是每个水果类别的先验概率。</p><p id="4932" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">先验概率可以从训练数据集计算:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mp"><img src="../Images/b160cfaa8edbb7a06326c142cf2cad5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*u2z_7vC2Mth-IpUbni10eg.png"/></div></figure><p id="3797" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练数据集包含1000条记录。其中，你有500个香蕉，300个苹果和200个其他的。所以先验分别是0.5，0.3，0.2。</p><p id="c4f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">第二步</em> </strong></p><p id="6d1c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其次，你需要计算证据进入分母的概率。它只是所有X的P与X的乘积:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/331256084a7650b6f076efa26095b406.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*LQbApxi9fas6ym7tGleSGA.png"/></div></figure><p id="e62e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">第三步:</em> </strong></p><p id="caf4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">第三步是计算证据可能性的概率，它只不过是3个属性的条件概率的乘积。</p><p id="c123" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">香蕉的可能性概率:</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mr"><img src="../Images/008a23b1106f8d7740d1ae4b3e1894b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/format:webp/1*coFy_rX_tQPj6uViL34srw.png"/></div></figure><p id="c7e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，香蕉的总体可能性概率将是上述三者的乘积，即0.8 * 0.7 * 0.9 = 0.504。</p><p id="d065" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">第四步:</em> </strong></p><p id="e6c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后一步是将所有3个方程代入朴素贝叶斯的数学表达式，以获得概率。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ms"><img src="../Images/1093c8dcf95a34cba3b4be4b77106613.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_S6xgL_a2gkXgS94iYLdNQ.png"/></div></div></figure><blockquote class="jt ju jv"><p id="2469" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">以类似的方式，你也可以计算“苹果”和“其他”的概率。分母在所有情况下都是一样的。</p></blockquote><p id="8633" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc"> Banana得到的概率最高，所以那会被认为是预测类。</em>T49】</strong></p><h2 id="65e7" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">朴素贝叶斯分类器的类型</h2><p id="d1af" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated"><em class="jc">下面提到了朴素贝叶斯分类器的主要类型:</em></p><ul class=""><li id="c3ff" class="lz ma hh ig b ih ii il im ip mb it mc ix md jb me mf mg mh bi translated"><strong class="ig hi"><em class="jc"/></strong><em class="jc"/>—这类分类器通常用于文档分类问题。它检查文档是否属于特定的类别，如体育、技术或政治等，然后对它们进行相应的分类。</li></ul><blockquote class="jt ju jv"><p id="35b7" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">在这种技术中用于分类的预测因子是文档中出现的单词的频率。</p></blockquote><ul class=""><li id="c7e7" class="lz ma hh ig b ih ii il im ip mb it mc ix md jb me mf mg mh bi translated"><strong class="ig hi"> <em class="jc">补充朴素贝叶斯</em> </strong> —这基本上是多项式朴素贝叶斯的改编，特别适合不平衡数据集。</li><li id="680b" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated"><strong class="ig hi"> <em class="jc">伯努利朴素贝叶斯</em> </strong> <em class="jc"> </em> —该分类器也类似于多项式朴素贝叶斯，但预测器不是单词，而是布尔值。用于预测类变量的参数只接受yes或no值，</li></ul><blockquote class="jt ju jv"><p id="ffe8" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">例如，一个单词是否出现在文本中。</p></blockquote><ul class=""><li id="1a54" class="lz ma hh ig b ih ii il im ip mb it mc ix md jb me mf mg mh bi translated"><strong class="ig hi"> <em class="jc">核外朴素贝叶斯</em> </strong> <em class="jc"> </em> —该分类器用于处理大规模分类问题，对于这些问题，完整的训练数据集可能不适合存储。</li><li id="a343" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated"><strong class="ig hi"> <em class="jc">高斯朴素贝叶斯</em> </strong> <em class="jc"> </em> —在高斯朴素贝叶斯中，预测值采用连续值，假设它是从高斯分布中采样的。它也被称为正态分布。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mt"><img src="../Images/49a1b772e549dc3884aa0e779f5942d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*EPTLDqPY79m9nalu5BSMvA.png"/></div></figure><blockquote class="jt ju jv"><p id="98e1" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">更多关于<strong class="ig hi">概率分布</strong> — <strong class="ig hi"> </strong> <a class="ae mu" rel="noopener" href="/datadriveninvestor/mathematics-for-machine-learning-part-5-8df72392ec10"> <strong class="ig hi">机器学习数学第五部分</strong> </a></p></blockquote><h1 id="145e" class="kz ka hh bd kb la lb lc kf ld le lf kj lg lh li km lj lk ll kp lm ln lo ks lp bi translated">利弊</h1><p id="3784" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">朴素贝叶斯算法有它的优点也有它的缺点</p><h2 id="45f1" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">赞成的意见</h2><ul class=""><li id="7582" class="lz ma hh ig b ih ku il kv ip mv it mw ix mx jb me mf mg mh bi translated">预测训练数据集的类别是容易且快速的。</li><li id="3d7c" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">它在多类预测中表现良好。</li><li id="7eda" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">在假设独立变量的情况下，与其他模型(如逻辑回归)相比，它表现得更好。</li><li id="b4ed" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">它需要较少的训练数据。</li><li id="663e" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">与数字变量相比，它在分类输入变量的情况下表现更好。</li></ul><h2 id="0082" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">骗局</h2><ul class=""><li id="24ad" class="lz ma hh ig b ih ku il kv ip mv it mw ix mx jb me mf mg mh bi translated">在分类变量具有未在训练数据集中观察到的类别的情况下，该模型无法做出预测，并为其分配0(零)概率。</li></ul><blockquote class="jt ju jv"><p id="a76c" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">这就是所谓的'<strong class="ig hi">零频率'</strong>。您可以使用<strong class="ig hi">拉普拉斯估计来解决这个问题。</strong></p></blockquote><ul class=""><li id="a109" class="lz ma hh ig b ih ii il im ip mb it mc ix md jb me mf mg mh bi translated">由于朴素贝叶斯被认为是一个糟糕的估计量，所以概率输出没有被认真对待。</li><li id="01b8" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated">朴素贝叶斯的工作原理是假设独立的预测因子，但是实际上不可能得到一组完全独立的预测因子。</li></ul><h2 id="fee4" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">拉普拉斯校正</h2><p id="1835" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">当您有一个包含许多属性的模型时，整个概率可能会变为零，因为其中一个要素的值为零。</p><p id="2be8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了克服这种情况，您可以将零变量的计数增加到一个小值，就像分子中的值一样，这样整体概率就不会为零。</p><blockquote class="jt ju jv"><p id="c22c" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">这种类型的校正被称为<strong class="ig hi">拉普拉斯校正。</strong>通常，所有的朴素贝叶斯模型都使用这个实现作为参数。</p></blockquote><h2 id="864b" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">应用程序</h2><p id="ac8d" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">朴素贝叶斯分类器在现实生活中有很多应用，下面提到一些:</em> </strong></p><ul class=""><li id="6554" class="lz ma hh ig b ih ii il im ip mb it mc ix md jb me mf mg mh bi translated"><strong class="ig hi"> <em class="jc">实时预测</em> </strong> —它是一个快速而热切的机器学习分类器，因此用于实时进行预测。</li><li id="1d55" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated"><strong class="ig hi"> <em class="jc">多类预测</em> </strong> —可以预测目标变量的多类概率。</li><li id="3477" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated"><strong class="ig hi"> <em class="jc">文本分类/垃圾邮件过滤/情感分析</em> </strong> —因其多类问题和独立性原则，多用于文本分类问题。它们还用于识别垃圾邮件，以及识别社交平台上的负面和正面客户情绪。</li><li id="d846" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated"><strong class="ig hi"> <em class="jc">推荐系统</em> </strong> —结合朴素贝叶斯分类器和协同过滤构建推荐系统。它过滤看不见的信息，并使用机器学习和数据挖掘技术预测用户是否喜欢给定的资源。</li></ul><h2 id="05c5" class="jz ka hh bd kb kc kd ke kf kg kh ki kj ip kk kl km it kn ko kp ix kq kr ks kt bi translated">改进模型</h2><p id="b02f" class="pw-post-body-paragraph ie if hh ig b ih ku ij ik il kv in io ip kw ir is it kx iv iw ix ky iz ja jb ha bi translated">你可以通过下面的提示来提高朴素贝叶斯模型的能力</p><ol class=""><li id="30af" class="lz ma hh ig b ih ii il im ip mb it mc ix md jb my mf mg mh bi translated"><em class="jc">使用类似于BoxCox和YeoJohnson的变换对变量进行变换，以使连续特征符合正态分布。</em></li><li id="9f44" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb my mf mg mh bi translated"><em class="jc">使用拉普拉斯校正处理X变量中的零值，并预测零频率问题的测试数据集类别。</em></li><li id="60db" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb my mf mg mh bi translated"><em class="jc">检查相关特征并移除高度相关的特征，因为它们在模型中被投票两次，可能导致过度膨胀。</em></li><li id="8de4" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb my mf mg mh bi translated"><em class="jc">将不同的功能组合在一起，打造出一款直观的新产品。</em></li><li id="9a19" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb my mf mg mh bi translated"><em class="jc">根据业务知识，为算法提供更现实的先验概率。使用整体方法，如装袋和增压，以减少差异。</em></li></ol><h1 id="4708" class="kz ka hh bd kb la lb lc kf ld le lf kj lg lh li km lj lk ll kp lm ln lo ks lp bi translated">其他资源和参考</h1><div class="mz na ez fb nb nc"><a href="https://tp6145.medium.com/naive-bayes-from-scratch-c0c93ed4b826" rel="noopener follow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hi fi z dy nh ea eb ni ed ef hg bi translated">从零开始的朴素贝叶斯</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">在统计学中，朴素贝叶斯分类器是一类简单的“概率分类器”,它基于应用贝叶斯分类器</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">tp6145.medium.com</p></div></div><div class="nl l"><div class="nm l nn no np nl nq jn nc"/></div></div></a></div><div class="mz na ez fb nb nc"><a href="https://github.com/tanvipenumudy/Winter-Internship-Internity/blob/main/Day%2013%20-%20Naive%20Bayes/Day-13%20Notebook%20%28Naive%20Bayes%29.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nd ab dw"><div class="ne ab nf cl cj ng"><h2 class="bd hi fi z dy nh ea eb ni ed ef hg bi translated">tanvipenumudy/Winter-实习-实习</h2><div class="nj l"><h3 class="bd b fi z dy nh ea eb ni ed ef dx translated">存储库跟踪每天分配的工作-tanvipenumudy/Winter-实习-实习</h3></div><div class="nk l"><p class="bd b fp z dy nh ea eb ni ed ef dx translated">github.com</p></div></div><div class="nl l"><div class="nr l nn no np nl nq jn nc"/></div></div></a></div><blockquote class="jt ju jv"><p id="b262" class="ie if jc ig b ih ii ij ik il im in io jw iq ir is jx iu iv iw jy iy iz ja jb ha bi translated">希望你喜欢并充分利用这篇文章！敬请关注我即将发布的博客！如果你觉得我的内容有帮助/有帮助，请确保<strong class="ig hi">鼓掌</strong>和<strong class="ig hi">跟随</strong>！</p></blockquote></div></div>    
</body>
</html>