<html>
<head>
<title>Tracking and Monitoring Transformers with MLFoundry</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用MLFoundry跟踪和监控变压器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tracking-and-monitoring-transformers-with-mlfoundry-460a3b860600?source=collection_archive---------1-----------------------#2022-03-21">https://medium.com/analytics-vidhya/tracking-and-monitoring-transformers-with-mlfoundry-460a3b860600?source=collection_archive---------1-----------------------#2022-03-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="b764" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">TrueFoundry使用MLFoundry高效跟踪和监控用于财务情绪分析的变压器模型</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/3781f5c148f9039659ccd1eb1d816919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rV5vZWZGW5xiqp70"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">来源:<a class="ae jm" href="https://www.catchpoint.com/blog/digital-monitoring-offer" rel="noopener ugc nofollow" target="_blank"> Catchpoint数字监控:在不影响质量的前提下提供最低成本的选择</a></figcaption></figure><p id="991c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">近年来，自然语言处理(NLP)在金融应用中变得越来越流行。股票/外汇市场预测、波动性建模、资产分配、业务分类构建、信用评分、首次公开发行(IPO)估值以及其他应用都在其中。这个金融领域中的一个常见任务(或者说子任务，可以为前面提到的一些任务提供<em class="kj">特性</em>)是<strong class="jp hi"> <em class="kj">金融情绪分析(FSA) </em> </strong> <em class="kj">。</em>FSA的目标是对金融文本进行分类，以表达对特定论点的看涨或看跌意见。</p><p id="3c76" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在这个NLP的新时代，像FSA这样的任务也受到了变形金刚统治地位的冲击。像<a class="ae jm" href="https://arxiv.org/pdf/1908.10063.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="kj">芬伯特</em> </a>这样的模型与以前的方法相比表现明显更好。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><p id="b38c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在本教程中，我们将探索如何使用<a class="ae jm" href="https://simpletransformers.ai/docs/usage/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi"> <em class="kj">简单变形器</em> </strong> </a>库轻松微调任何用于FSA任务的预调整变形器。然后，我们将通过改变参数和基本模型并使用<a class="ae jm" href="https://truefoundry.gitbook.io/mlfoundry/" rel="noopener ugc nofollow" target="_blank"><strong class="jp hi"><em class="kj">ml foundry</em></strong></a>跟踪相关信息来迭代实验。我们将使用MLFoundry Web应用程序创建一个定制的模型演示，可以与他人共享或向用户展示。</p><p id="fd0f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">所以，让我们开始吧！</p><p id="9dd7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi"><em class="kj">Tl；dr: </em> </strong> <em class="kj">如果您希望只查看我们在本文中涉及的所有工作实现，请参考本笔记本的</em><a class="ae jm" href="https://gist.github.com/tezansahu/a22dd2e4d880d4fc2e308e36795219a2" rel="noopener ugc nofollow" target="_blank"><em class="kj"/></a><em class="kj">。尽管GitHub gists在本文中被用作代码片段，但是如果直接复制，它们可能不会像预期的那样工作。随时参考</em> <a class="ae jm" href="https://gist.github.com/tezansahu/a22dd2e4d880d4fc2e308e36795219a2" rel="noopener ugc nofollow" target="_blank"> <em class="kj">提到的笔记本</em> </a> <em class="kj">以防你面临这样的问题。</em></p><h1 id="2dc8" class="kr ks hh bd kt ku kv kw kx ky kz la lb in lc io ld iq le ir lf it lg iu lh li bi translated">预赛</h1><p id="92ab" class="pw-post-body-paragraph jn jo hh jp b jq lj ii js jt lk il jv jw ll jy jz ka lm kc kd ke ln kg kh ki ha bi translated">我们首先为这个项目创建一个虚拟环境，并安装必要的库:</p><pre class="ix iy iz ja fd lo lp lq lr aw ls bi"><span id="5185" class="lt ks hh lp b fi lu lv l lw lx">matplotlib==3.5.1<br/>mlfoundry==0.2.7<br/>mlfoundry-ui==0.1.4<br/>numpy==1.21.5<br/>pandas==1.4.1<br/>scikit-learn==0.24.2<br/>simpletransformers==0.63.4<br/>torch==1.10.2</span></pre><blockquote class="ly lz ma"><p id="c883" class="jn jo kj jp b jq jr ii js jt ju il jv mb jx jy jz mc kb kc kd md kf kg kh ki ha bi translated"><strong class="jp hi">注:</strong>建议使用一些GPU访问来训练变压器模型，因为它们很大，否则需要相当长的训练时间。使用Google Colab可能是一个可行的解决方案。</p></blockquote><p id="9b1c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">接下来，我们需要创建一个IPython笔记本并导入所需的库。可选地，我们也可以清除CUDA中的缓存。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="ae1d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们不需要在PyTorch中显式地设置<code class="du mg mh mi lp b">device</code>,因为<code class="du mg mh mi lp b">simpletransformers</code>库会自动处理并默认使用GPU。</p><h1 id="afc5" class="kr ks hh bd kt ku kv kw kx ky kz la lb in lc io ld iq le ir lf it lg iu lh li bi translated">基于简单变形器的财经新闻情感分析</h1><h2 id="1e31" class="lt ks hh bd kt mj mk ml kx mm mn mo lb jw mp mq ld ka mr ms lf ke mt mu lh mv bi translated">探索和处理数据集</h2><p id="0b44" class="pw-post-body-paragraph jn jo hh jp b jq lj ii js jt lk il jv jw ll jy jz ka lm kc kd ke ln kg kh ki ha bi translated">对于本教程，我们使用从Kaggle 获得的经过处理的<a class="ae jm" href="https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news" rel="noopener ugc nofollow" target="_blank"><em class="kj">financialphasebank</em>数据。该数据集包含了散户投资者眼中的财经新闻标题的观点。<code class="du mg mh mi lp b">all-data.csv</code>文件包含两栏，<em class="kj">情感</em>和<em class="kj">新闻标题</em>。情绪可以是消极的、中性的或积极的。因此，FSA任务被视为多类分类问题。</a></p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="792c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">由于简单的Transformers库要求数据位于至少有两列的Pandas DataFrames中，这两列被命名为<code class="du mg mh mi lp b">text</code>(类型为<code class="du mg mh mi lp b">str</code>)和<code class="du mg mh mi lp b">labels</code>(类型为<code class="du mg mh mi lp b">int</code>)，因此我们在将数据分成训练&amp;评估集之前进行了所需的处理。</p><h2 id="cb35" class="lt ks hh bd kt mj mk ml kx mm mn mo lb jw mp mq ld ka mr ms lf ke mt mu lh mv bi translated">为FSA训练一个BERT模型</h2><p id="ba39" class="pw-post-body-paragraph jn jo hh jp b jq lj ii js jt lk il jv jw ll jy jz ka lm kc kd ke ln kg kh ki ha bi translated">我们定义一个简单的训练函数，它接受模型的规范来创建一个<code class="du mg mh mi lp b">ClassificationModel</code>，以及训练超参数来执行训练循环。我们还通过利用<code class="du mg mh mi lp b">scikit-learn</code>使用<em class="kj">微F1 </em>和<em class="kj">准确度</em>分数来评估模型。</p><p id="3193" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">作为拥抱面部库的包装器，简单变形金刚通过抽象掉所需的繁重工作，使这一切变得极其简单。因此，我们只用3-4条语句就可以创建、训练和评估我们的转换器。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="b70a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在<code class="du mg mh mi lp b">ClassificationModel</code>的构造函数中，第一个参数是<em class="kj"> model_type，</em>第二个是<em class="kj"> model_name </em>，第三个是数据中的标签数(设置为<code class="du mg mh mi lp b">3</code>是因为我们有三个情绪)。目前，Simple Transformers支持可用类型中的<a class="ae jm" href="https://simpletransformers.ai/docs/classification-specifics/#supported-model-types" rel="noopener ugc nofollow" target="_blank">作为<em class="kj"> model_type。</em><em class="kj">model _ name</em>可以是</a><a class="ae jm" href="https://huggingface.co/models" rel="noopener ugc nofollow" target="_blank">拥抱脸</a>上的任意一款。</p><p id="a3e4" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">训练完模型后，我们使用<code class="du mg mh mi lp b">eval_model()</code>对其进行评估。该函数返回以下内容:</p><ul class=""><li id="c432" class="mw mx hh jp b jq jr jt ju jw my ka mz ke na ki nb nc nd ne bi translated">一个<code class="du mg mh mi lp b">dict</code>包含评估数据集的性能指标(默认为Matthews相关系数和损失，以及我们定义的微F1和准确性)</li><li id="321f" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nb nc nd ne bi translated">每个评估实例的模型输出的<code class="du mg mh mi lp b">list</code></li><li id="96df" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nb nc nd ne bi translated">A <code class="du mg mh mi lp b">list</code>模型预测不正确的输入</li></ul><p id="51fe" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">经过训练的模型检查点存储在<code class="du mg mh mi lp b">training_args['output_dir']</code>中。</p><p id="398e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="kj">有许多超参数可以根据您的要求进行更改。完整列表及其默认值如下:</em></p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="feab" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在实际向<code class="du mg mh mi lp b">trainModel()</code>函数提供所需参数之前，我们将引入MLFoundry来设置我们实验所需的跟踪。</p><h1 id="fe76" class="kr ks hh bd kt ku kv kw kx ky kz la lb in lc io ld iq le ir lf it lg iu lh li bi translated">引入MLFoundry进行跟踪和监控</h1><p id="8b7d" class="pw-post-body-paragraph jn jo hh jp b jq lj ii js jt lk il jv jw ll jy jz ka lm kc kd ke ln kg kh ki ha bi translated">MLFoundry是由<a class="ae jm" href="https://truefoundry.com/" rel="noopener ugc nofollow" target="_blank"><strong class="jp hi"><em class="kj">true foundry</em></strong></a>创建的ML监控和实验跟踪解决方案，它允许用户跟踪他们的实验、模型、度量、数据&amp;特征。具有参数、数据集和指标的唯一组合的每个实验被认为是一个<strong class="jp hi"> <em class="kj">运行</em> </strong>，并且多个这样的运行可以被逻辑地分组为一个<strong class="jp hi"> <em class="kj">项目</em> </strong>。每个运行都有一个唯一的<strong class="jp hi"> <em class="kj"> run_id </em> </strong>，但也可以赋予一个<strong class="jp hi"> <em class="kj"> run_name </em> </strong>以便于引用。稍后，可以使用交互式仪表板检查和比较这些运行。</p><h2 id="4858" class="lt ks hh bd kt mj mk ml kx mm mn mo lb jw mp mq ld ka mr ms lf ke mt mu lh mv bi translated">用MLFoundry记录实验细节</h2><p id="1520" class="pw-post-body-paragraph jn jo hh jp b jq lj ii js jt lk il jv jw ll jy jz ka lm kc kd ke ln kg kh ki ha bi translated">首先，我们导入MLFoundry并初始化API。然后，我们创建我们的项目(名为<code class="du mg mh mi lp b">financial-sentiment-analysis</code>),第一次运行名为<code class="du mg mh mi lp b">bert_3epochs</code>。这个实验将涉及对三个时期的BERT模型进行微调。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="306e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这将在项目目录中创建一个<code class="du mg mh mi lp b">mlf/</code>文件夹，其中包含MLFoundry记录的各种运行的所有信息。</p><p id="e661" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，我们修改我们的<code class="du mg mh mi lp b">trainModel()</code>函数，接受一次运行作为输入，并记录所有需要的信息(参数、数据集、指标和数据集统计)。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><ul class=""><li id="a658" class="mw mx hh jp b jq jr jt ju jw my ka mz ke na ki nb nc nd ne bi translated">为了记录<strong class="jp hi"> <em class="kj">训练&amp;评估数据集</em> </strong>，我们使用<code class="du mg mh mi lp b"><a class="ae jm" href="https://truefoundry.gitbook.io/mlfoundry/api-doc/mlfoundry/mlfoundryrun/log_dataset" rel="noopener ugc nofollow" target="_blank">log_dataset()</a></code></li><li id="d2c5" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nb nc nd ne bi translated">我们把<strong class="jp hi"> <em class="kj">型号规格</em> </strong>(型号和名称)记录下来，连同<strong class="jp hi"> <em class="kj">超参数</em> </strong>作为字典使用<code class="du mg mh mi lp b">l<a class="ae jm" href="https://truefoundry.gitbook.io/mlfoundry/api-doc/mlfoundry/mlfoundryrun/log_params" rel="noopener ugc nofollow" target="_blank">og_params()</a></code></li><li id="5530" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nb nc nd ne bi translated">使用<code class="du mg mh mi lp b"><a class="ae jm" href="https://truefoundry.gitbook.io/mlfoundry/api-doc/mlfoundry/mlfoundryrun/log_metrics" rel="noopener ugc nofollow" target="_blank">log_metrics()</a></code>记录包含我们的评估集(准确性和微f1)上的<strong class="jp hi"> <em class="kj">性能指标</em> </strong>的字典。</li><li id="b375" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nb nc nd ne bi translated">使用<code class="du mg mh mi lp b"><a class="ae jm" href="https://truefoundry.gitbook.io/mlfoundry/api-doc/mlfoundry/mlfoundryrun/log_dataset_stats" rel="noopener ugc nofollow" target="_blank">log_dataset_stats()</a></code>记录时，与我们的数据  t相关的各种<strong class="jp hi"> <em class="kj">指标，以及<strong class="jp hi"> <em class="kj">统计数据</em> </strong>如计数器、摘要、直方图和最频繁的值都是使用<code class="du mg mh mi lp b"><a class="ae jm" href="https://docs.whylabs.ai/docs/" rel="noopener ugc nofollow" target="_blank">whylogs</a></code>自动估算的。</em></strong></li></ul><p id="04fc" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，我们以字典的形式设置超参数以及模型规范，并为之前定义的运行调用<code class="du mg mh mi lp b">trainModel()</code>函数。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="4b52" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这将从预训练的<code class="du mg mh mi lp b">bert-base-uncased</code>模型加载权重，并根据三个时期提供的超参数对其进行微调。</p><h2 id="3935" class="lt ks hh bd kt mj mk ml kx mm mn mo lb jw mp mq ld ka mr ms lf ke mt mu lh mv bi translated">在MLFoundry仪表盘中导航</h2><p id="8bf4" class="pw-post-body-paragraph jn jo hh jp b jq lj ii js jt lk il jv jw ll jy jz ka lm kc kd ke ln kg kh ki ha bi translated">一旦培训完成，我们可以通过从项目文件夹(包含<code class="du mg mh mi lp b">mlf/</code>文件夹)中运行命令<code class="du mg mh mi lp b">mlfoundry ui</code>来查看<a class="ae jm" href="https://truefoundry.gitbook.io/mlfoundry/mlfoundry-dashboard" rel="noopener ugc nofollow" target="_blank"> MLFoundry仪表板</a>中的所有记录信息。默认情况下，这将在<code class="du mg mh mi lp b">localhost:4200</code>上启动仪表板(我们可以通过运行<code class="du mg mh mi lp b">export STREAMLIT_SERVER_PORT=&lt;your-preferred-port&gt;</code>来更改端口)。</p><p id="c382" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在<strong class="jp hi"> <em class="kj">单次运行视图</em> </strong>下，选择<code class="du mg mh mi lp b">financial-sentiment-analysis</code>为<strong class="jp hi"> <em class="kj">项目名称</em> </strong>和<code class="du mg mh mi lp b">bert_3epochs</code>为<strong class="jp hi"> <em class="kj">运行名称</em> </strong>。现在，我们可以使用不同的选项卡来检查有关已跟踪的特定运行的所有信息:</p><ul class=""><li id="d91c" class="mw mx hh jp b jq jr jt ju jw my ka mz ke na ki nb nc nd ne bi translated"><strong class="jp hi"> <em class="kj">模型健康</em> </strong>部分显示了评估数据集上当前模型的性能指标。这些包括混淆矩阵(因为这是一个多类分类任务)以及其他相关的图。</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nk"><img src="../Images/0070c64b20331e85b1ebeea6c3e9a167.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MTPNRBmfHIGOD8TEFFS64Q.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">模型运行状况部分显示了bert _时期运行的各种用户生成和自动生成的指标</figcaption></figure><ul class=""><li id="bb75" class="mw mx hh jp b jq jr jt ju jw my ka mz ke na ki nb nc nd ne bi translated"><strong class="jp hi"> <em class="kj"> Data Health </em> </strong>部分包含与我们的数据集相关的各种统计信息，可用于了解数据质量，并在以后有数据更改时将其与其他数据集进行比较。</li><li id="c212" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nb nc nd ne bi translated"><strong class="jp hi"> <em class="kj">特征健康</em> </strong>部分显示基于输入特征的标签和预测值的数值分布。对于我们的例子，只有一个名为<em class="kj"> headline </em>的输入特征，包含金融新闻标题。</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nl"><img src="../Images/a300daf9157d5080fbfa49e8e5673a57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SYd8DLi11btmv-qovBAWKQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">特征健康部分显示了bert _时期运行的标签和预测的类的数字特征分布</figcaption></figure><ul class=""><li id="8940" class="mw mx hh jp b jq jr jt ju jw my ka mz ke na ki nb nc nd ne bi translated"><strong class="jp hi"> <em class="kj">运行详细信息</em> </strong>部分显示为运行记录的所有参数和指标，还允许用户查看数据集和其他与跟踪的运行相关的工件。</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nm"><img src="../Images/0a462e1be95d22cb85275b3c74a8cb39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KIML3cpmmmgd0V43HgRP9Q.png"/></div></div></figure><p id="caf5" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们看到，经过三个时期的训练，我们微调的BERT模型可以达到0.82  的<strong class="jp hi"> <em class="kj">精度和0.82 </em> </strong>的<strong class="jp hi"> <em class="kj">微F1得分。</em></strong></p><h1 id="3d07" class="kr ks hh bd kt ku kv kw kx ky kz la lb in lc io ld iq le ir lf it lg iu lh li bi translated">使用MLFoundry高效跟踪和比较多个实验</h1><p id="25a0" class="pw-post-body-paragraph jn jo hh jp b jq lj ii js jt lk il jv jw ll jy jz ka lm kc kd ke ln kg kh ki ha bi translated">现在，我们将看到为特定任务试验不同的模型和参数是多么容易，同时能够通过在同一项目中创建不同的运行来跟踪所有相关信息以供参考。</p><p id="5b8d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为了通过改变超参数来演示实验，我们创建了一个名为<code class="du mg mh mi lp b">bert_5epochs</code>的新运行，并将其与<code class="du mg mh mi lp b">training_args</code>字典一起传递给<code class="du mg mh mi lp b">trainModel()</code>函数(这一次，字典中<code class="du mg mh mi lp b">num_train_epochs</code>的值被设置为<code class="du mg mh mi lp b">5</code>而不是<code class="du mg mh mi lp b">3</code>和<code class="du mg mh mi lp b">model_params</code>(不变)。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="f233" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为了说明不同变压器架构在实验中的使用，我们创建了一个名为<code class="du mg mh mi lp b">roberta</code>的新运行。这一次，我们保持<code class="du mg mh mi lp b">training_args</code>与前一次运行(使用<code class="du mg mh mi lp b">5</code>周期)相同，并更改<code class="du mg mh mi lp b">model_params</code>以使用预训练的RoBERTa的权重来代替BERT。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="6530" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">一旦这些模型的训练完成，我们再次进入MLFoundry仪表板，通过选择<em class="kj">单次运行视图</em>下的特定<em class="kj"> run_name </em>来检查跟踪的信息。既然我们有多个运行，我们也可以在<strong class="jp hi"> <em class="kj">运行比较</em> </strong>下比较它们。</p><p id="8f69" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">可以使用<em class="kj"> run_id </em>或<em class="kj"> run_name </em>选择要比较的跑步，后者更方便<em class="kj">。</em></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es nn"><img src="../Images/378c226376142e956da8a0a9fa1f8116.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XVTbLBP20RN5Pgvc-_SFpg.png"/></div></div></figure><ul class=""><li id="6463" class="mw mx hh jp b jq jr jt ju jw my ka mz ke na ki nb nc nd ne bi translated">当训练更多的时期时，BERT模型显示出更好的准确性</li><li id="45da" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nb nc nd ne bi translated"><strong class="jp hi"> <em class="kj">罗伯塔</em> </strong>模型给出了<strong class="jp hi"><em class="kj"/></strong><strong class="jp hi"><em class="kj">的最佳精度0.866 </em> </strong></li></ul><p id="2502" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">向下滚动，我们还可以看到每次运行跟踪的所有性能指标的合并图。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es no"><img src="../Images/939a243b092780e01ca88e1da318a738.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xGhYMXSlDJVWLUYAsM6BzA.png"/></div></div></figure><h1 id="a5ba" class="kr ks hh bd kt ku kv kw kx ky kz la lb in lc io ld iq le ir lf it lg iu lh li bi translated">使用MLFoundry Web应用程序的模型演示</h1><p id="b74c" class="pw-post-body-paragraph jn jo hh jp b jq lj ii js jt lk il jv jw ll jy jz ka lm kc kd ke ln kg kh ki ha bi translated">了解了使用MLFoundry对transformer模型进行迭代实验、跟踪和比较的过程后，我们现在希望向更广泛的受众展示我们的最佳模型(即RoBERTa)的性能。这就是<strong class="jp hi"><em class="kj">ml foundry Web App</em></strong>派上用场的地方。</p><p id="8e62" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为此，我们可以创建一个独立的web应用程序文件，该文件将使用<code class="du mg mh mi lp b">log_webapp_file()</code>在适当的运行中注册。因为我们想为我们的RoBERTa模型制作演示，我们将这个文件命名为<code class="du mg mh mi lp b">streamlit_roberta.py</code>(也可以命名为其他名称)。在这个文件中，我们首先需要编写一个函数，该函数可以加载一个保存的简单Transformer模型，并使用加载的模型为输入的金融新闻标题预测情绪。然后，我们需要初始化MLFoundry客户端，创建一个运行，并通过向它提供预测函数、输入和输出类型(这里，我们只有一个输入和一个输出，每个类型都是<code class="du mg mh mi lp b">text</code>)来调用运行中的<code class="du mg mh mi lp b">webapp()</code>。这在仪表板上定义了一个模型演示界面。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="cc58" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">回到我们训练模型的笔记本，我们可以向<code class="du mg mh mi lp b">mlf_run_3</code>注册这个文件，它跟踪我们基于RoBERTa的实验的所有信息。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="48f0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在仪表板中，当我们可以选择<code class="du mg mh mi lp b">roberta</code> run并打开<strong class="jp hi"> <em class="kj"> Model Demo </em> </strong>部分时，我们会看到一个交互式演示(类似于《拥抱脸》中的<em class="kj"> Model Card </em>),它利用我们保存的RoBERTa检查点来预测金融新闻标题的情绪。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es np"><img src="../Images/980ba36a3eb2be69c064f66eed1421f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4Y0R5TUKHg3uBv-ilRqzeQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">金融新闻标题被我们微调的roberta模型正确分类为“正面”的示例，如MLFoundry Web应用程序中的“RoBERTa”所示</figcaption></figure><p id="cfd7" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="kj">由于这个web app是使用</em><a class="ae jm" href="https://streamlit.io/" rel="noopener ugc nofollow" target="_blank"><em class="kj">Streamlit</em></a><em class="kj">构建的，我们可以将</em> <code class="du mg mh mi lp b"><em class="kj">streamlit</em></code> <em class="kj">导入到</em> <code class="du mg mh mi lp b"><em class="kj">streamlit_roberta.py</em></code> <em class="kj">文件中，并使用它来添加其他元素(例如，添加可解释性等。)添加到该模型演示仪表板，以便进行定制。</em></p><h1 id="ef8b" class="kr ks hh bd kt ku kv kw kx ky kz la lb in lc io ld iq le ir lf it lg iu lh li bi translated">结束语</h1><p id="45d9" class="pw-post-body-paragraph jn jo hh jp b jq lj ii js jt lk il jv jw ll jy jz ka lm kc kd ke ln kg kh ki ha bi translated">在本教程中，我们最初看到了如何使用简单的转换器轻松地为NLP任务(如金融情绪分析)训练转换器模型。后来，我们使用MLFoundry来跟踪不同实验的参数、指标、数据集和统计数据，我们通过改变一些超参数和模型架构来执行这些实验。最后，我们还创建了一个web应用程序来演示我们训练好的模型如何预测金融新闻标题的情绪。</p><p id="f3b8" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">有关本教程中提到的库的文档的更多细节，请随意查看下面的参考资料部分。请在下面的评论区留下任何反馈或建议。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><p id="fd51" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><a class="ae jm" href="http://truefoundry.com/" rel="noopener ugc nofollow" target="_blank"> <em class="kj"> TrueFoundry </em> </a> <em class="kj">正在为依赖开放标准的ML管道构建最快的框架之一，</em> <strong class="jp hi"> <em class="kj">通过他们的自动化后模型管道节省了数据科学团队30–40%的时间</em> </strong> <em class="kj">。欢迎</em> <a class="ae jm" href="https://truefoundry.com/contact" rel="noopener ugc nofollow" target="_blank"> <em class="kj">报名，提前获得TrueFoundry的ML监控和自动缩放解决方案</em> </a> <em class="kj">！</em></p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><p id="f812" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="kj">特赞萨胡上</em><a class="ae jm" href="https://www.linkedin.com/in/tezan-sahu/" rel="noopener ugc nofollow" target="_blank"><em class="kj">LinkedIn</em></a><em class="kj">和</em><a class="ae jm" href="https://github.com/tezansahu" rel="noopener ugc nofollow" target="_blank"><em class="kj">GitHub</em></a><em class="kj">。</em></p><h1 id="5086" class="kr ks hh bd kt ku kv kw kx ky kz la lb in lc io ld iq le ir lf it lg iu lh li bi translated">参考</h1><ol class=""><li id="10df" class="mw mx hh jp b jq lj jt lk jw nq ka nr ke ns ki nt nc nd ne bi translated"><a class="ae jm" href="https://aclanthology.org/2020.coling-main.85.pdf" rel="noopener ugc nofollow" target="_blank">金融情绪分析:常见错误和银弹调查| aclanthology.org</a></li><li id="6ec1" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nt nc nd ne bi translated"><a class="ae jm" href="https://simpletransformers.ai/" rel="noopener ugc nofollow" target="_blank">简易变形金刚</a></li><li id="8c26" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nt nc nd ne bi translated"><a class="ae jm" rel="noopener" href="/swlh/simple-transformers-multi-class-text-classification-with-bert-roberta-xlnet-xlm-and-8b585000ce3a">简单的变形金刚——使用BERT、RoBERTa、XLNet、XLM和DistilBERT进行多类文本分类|作者:thi Lina Rajapakse | The Startup | Medium</a></li><li id="b934" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nt nc nd ne bi translated"><a class="ae jm" href="https://truefoundry.gitbook.io/mlfoundry/" rel="noopener ugc nofollow" target="_blank"> MLFoundry | gitbook.io </a></li><li id="45ce" class="mw mx hh jp b jq nf jt ng jw nh ka ni ke nj ki nt nc nd ne bi translated"><a class="ae jm" rel="noopener" href="/@nikunjbajaj/truefoundrys-ml-monitoring-experiment-tracking-solution-ba5ad9c6cbe6"> TrueFoundry的ML监控&amp;实验跟踪解决方案| Nikunj Bajaj | Medium</a></li></ol></div></div>    
</body>
</html>