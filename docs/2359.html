<html>
<head>
<title>Table detection and Tabular data extraction from Scanned Document Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从扫描文档图像中检测表格和提取表格数据</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-learning-model-for-end-to-end-table-detection-and-tabular-data-extraction-from-scanned-3eec3dce354c?source=collection_archive---------0-----------------------#2021-04-20">https://medium.com/analytics-vidhya/deep-learning-model-for-end-to-end-table-detection-and-tabular-data-extraction-from-scanned-3eec3dce354c?source=collection_archive---------0-----------------------#2021-04-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/06f96d14fc1c0a22fe402aa6f5ccf21a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bW6E4w4EbCREORaGHPnGRw.jpeg"/></div></div></figure><p id="e8ed" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，pdf或doc文件形式的扫描照片被上传用于验证。因此，员工过去习惯于从文档中手动提取申请人的详细信息，这既繁琐又耗时，因此增加了人力成本和低效的数据处理时间。因此，人们发现有必要借助数字图书馆从文档中抽取信息。</p><p id="0a20" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们基本上是在寻找任何有用的信息，如果它存在于<br/>表格子图像中。因此，需要对图像进行数字化处理，以便计算机能够对其进行处理，从而对DL进行实验。不同图像中的表格结构的变化以及用结构标识可视地分离表格使得这非常具有挑战性。</p><h1 id="719d" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">目录:</h1><blockquote class="km kn ko"><p id="45e8" class="iq ir kp is b it iu iv iw ix iy iz ja kq jc jd je kr jg jh ji ks jk jl jm jn hb bi translated">1.商务问题<br/> 2。TableNet架构简介<br/> 3。ML配方<br/> 4。探索性数据分析:<br/> 5。绩效指标<br/> 6。我的方法<br/> 7。模型<br/> 8的演练。数据提取<br/> 9。部署<br/> 10。未来工作<br/> 11。参考</p></blockquote><h1 id="0470" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated"><strong class="ak"> 1。业务问题:</strong></h1><p id="b731" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">如今，随着手机和扫描仪广泛用于拍照和上传文档，人们发现提取所需信息的非结构化文件(即以表格形式包含有用信息的文件)的需求非常迫切。从表格数据中提取信息是具有挑战性的，这使得深度学习的最新技术得以发挥。从这个问题中我们遇到两件事。一个是从文档中检测出准确的表格，另一个是成功地从中提取数据。</p><p id="f7da" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">成功地完成这项任务还没有完成，因为检测表是容易的部分，但是从结构(行和列)中提取数据是困难的部分。在这个案例研究中，我们将讨论深度学习TableNet:一种新颖的端到端深度学习模型，用于表格检测和结构识别。</p><h1 id="6bb9" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">2.TableNet架构简介:</h1><p id="ecac" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">根据业务问题陈述，我们的输入是模型的图像文件，我们将获得两个输出，即关于表检测和表格结构(行和列)识别。它是对表格子图像的逐像素检测，而表格结构识别包括对检测到的表格中的各个行和列进行分割。该模型由编码器和解码器两部分组成。预训练的VGG19模型被引入作为基线编码器模型。</p><p id="08f0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这两个分支从作为解码器输入的编码输出出来，最终分别预测表区域的分割和表区域内的列的分割。当涉及训练时，共享的公共层权重由从编码器和解码器接收的梯度频繁更新，并且每个解码器层的权重单独更新。在此基础上训练预训练的VGG19模型可以提高性能。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ky"><img src="../Images/c9efc4107be085f4bb268c1496392032.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zlNXldwcJ9cGKu8bZ3Y7OQ.jpeg"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">TableNet架构</figcaption></figure><p id="4939" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">可视化看起来像下面给出的东西。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/06f96d14fc1c0a22fe402aa6f5ccf21a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bW6E4w4EbCREORaGHPnGRw.jpeg"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">可视化TableNet</figcaption></figure><p id="4182" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">该架构旨在预测两个输出，即桌子检测和结构识别。仅检测列输出可能会导致大量误报，并且输出可能不符合实际情况。因此，检测表格的卷积滤波器由列检测滤波器增强，因此也有助于检测列。</p><p id="099f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，从上面显示的架构来看，两个解码器共享公共的编码器层。编码器的输出被引入作为解码器功能的输入，接着是卷积层，然后与来自编码器层的第四最大池层连接。然后，使用编码器的第三个最大池层将其上采样为所需形状，并执行连接，随后是上采样层，最后是Conv2DTranspose，以满足模型输入的形状。</p><h1 id="59aa" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">3.毫升配方:</h1><p id="521a" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">它是实际结果与预测结果之间的像素级比较。它还说明了模型预测表结构的准确程度。因此，这是一个分类问题。</p><h2 id="f540" class="lh jp hi bd jq li lj lk ju ll lm ln jy jb lo lp kc jf lq lr kg jj ls lt kk lu bi translated">数据源:</h2><ol class=""><li id="f5a1" class="lv lw hi is b it kt ix ku jb lx jf ly jj lz jn ma mb mc md bi translated">IC Dar _ 2017 _ table _ dataset:<a class="ae me" href="https://github.com/mawanda-jun/TableTrainNet/tree/master/dataset" rel="noopener ugc nofollow" target="_blank">https://github . com/ma Wanda-jun/TableTrainNet/tree/master/dataset</a></li><li id="16a1" class="lv lw hi is b it mf ix mg jb mh jf mi jj mj jn ma mb mc md bi translated">旱獭数据集:【https://www.icst.pku.edu.cn/cpdp/sjzy/index.htm T2】</li></ol><h2 id="ef55" class="lh jp hi bd jq li lj lk ju ll lm ln jy jb lo lp kc jf lq lr kg jj ls lt kk lu bi translated">数据描述:</h2><p id="a391" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">由图像及其相应的标注组成，标注指示图像中表格的坐标。图像在。bmp格式，而注释文件在。xml文件。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es mk"><img src="../Images/caaf5a003211a2d294478f2d3fff0156.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*_11CrONdif3HOVJCzyOJ4w.jpeg"/></div></figure><p id="cda2" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">ICDAR 2017的图像总数与对应的注释文件相同。marmot数据集总共缺少14个注释文件。</p><h1 id="b280" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">4 .探索性数据分析:</h1><h2 id="e160" class="lh jp hi bd jq li lj lk ju ll lm ln jy jb lo lp kc jf lq lr kg jj ls lt kk lu bi translated">我们将检查土拨鼠数据集:</h2><p id="0b64" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">显示来自marmot数据集的随机图像文件:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ml"><img src="../Images/392ee94836c7e932bdd94bce61660eef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*44wZTnhX9jJlJUpmGna30A.jpeg"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">原象</figcaption></figure><p id="364c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">显示相应的表和列掩码:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mm"><img src="../Images/2eb56989673570a0405700b529d8e8c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/format:webp/1*C74LtHLt9hnF7CdwoAjCBg.jpeg"/></div></div></figure><p id="f5df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">绘制代表整个图像的高度和宽度范围的图形:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mn"><img src="../Images/fedf4d8925cfa45a12d984d84f6f5384.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SzCgmStyjEcg6VTmHsXl9Q.jpeg"/></div></div></figure><p id="6edc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">图像的高度范围在600–1000之间，宽度范围在800–1000之间。我们将重塑图像为1024 * 1024，因为模型的输入应该具有所需的相同形状。</p><h2 id="8f9b" class="lh jp hi bd jq li lj lk ju ll lm ln jy jb lo lp kc jf lq lr kg jj ls lt kk lu bi translated">现在，我们将检查ICDAR-2017的另一个数据集:</h2><p id="b6db" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">显示来自ICDAR-2017数据集的随机图像文件:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mo"><img src="../Images/d67b781abf6e668c54a5a7e51435be9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-c9rHwiUOiRPilpVur5uiQ.jpeg"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">原象</figcaption></figure><p id="d769" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">显示相应的表格掩码:</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/5281c215594de8223ab136d3e97c27d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*MapjBEZb0ExeyigIYKvoog.jpeg"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">桌面遮罩</figcaption></figure><p id="acb6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">不幸的是，从注释文件中，我们只能提取表掩码。根据研究论文，ICDAR-2017数据集用于测试目的，而marmot数据集用于训练模型。</p><h1 id="549c" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">5.绩效指标:</h1><p id="185c" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">模型的性能通过f1分数、精确度和召回率进行了验证。</p><h1 id="e2d5" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">6.我的方法:</h1><p id="f0a5" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">在仔细阅读了我上面提到的研究论文后，我提出了第一种方法。根据业务问题陈述，我们必须预测表掩码和结构(行和列)识别。因为有两个数据集，其中一个数据集用于训练模型，另一个数据集用于测试模型。根据我绘制的高度和宽度图，我们需要将所有图像的大小调整为1024 * 1024。首先，我们需要从注释文件中提取表和列掩码，我们需要将它与预测的输出进行比较。</p><p id="92d1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">模型架构由编码器和解码器两部分组成。我们使用预训练的VGG19直到瓶颈，该瓶颈通过具有ReLU激活的两个(1×1)卷积层进一步扩展，随后是概率为0.8的丢弃层。解码器的两个分支由此而来。编码器的输出被引入作为解码器功能的输入，接着是卷积层，然后与来自编码器层的第四最大池层连接。然后，使用编码器的第三个最大池层将其上采样为所需形状，并执行连接，随后是上采样层，最后是Conv2DTranspose，以满足模型输入的形状。</p><p id="8153" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">根据研究论文，我们被指示使用Adam作为优化器，参数β1 = 0.9，β2 = 0.999，ε= 1e-08。我们需要创建一个单独的文件，其中存储了所有文件，包括图像及其对应的表以及列掩码。在数据管道时，我们将从给定的位置获取文件，并且必须批量创建数据加载器。我们需要使用TensorFlow API创建数据管道，该API在内部发送数据来训练模型并加快性能。</p><p id="f414" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于数据非常少，我们需要将marmot数据集分成几组，并以9:1的比例进行测试。f1分数、精确度和召回率验证了模型性能。由于数据较少，我们必须用较大的历元来训练模型，并且必须最大化f1分数。</p><h1 id="af0d" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">7 .到模型的漫游:</h1><p id="8f0d" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">因为我们知道平板电脑模型有两个输出，所以我们需要使用TensorFlow API创建数据管道，这样它就应该输入图像及其对应的遮罩，以便与结果进行比较。因此，下面给出的代码是创建数据加载器的整个数据管道。</p><figure class="kz la lb lc fd ij"><div class="bz dy l di"><div class="mq mr l"/></div><figcaption class="ld le et er es lf lg bd b be z dx translated">模型的数据管道</figcaption></figure><p id="80a3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">增加了VGG19预训练模型，直到瓶颈作为带有一点点卷积层的基线模型。形状为1024 * 1024的输入图像被传递到模型，并且两个输出被期望从模型中输出。第一个输出是表格掩码，检测该表格是否存在于给定图像中，第二个输出是列掩码，识别表格中的行和列。</p><p id="dcda" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">执行两个输出背后的想法是，如果没有表检测，列掩码输出可能会导致假阳性的增加，这会破坏模型，我们可能无法从表中获得数据。因此，表检测增强了列解码器识别正确的行和列的能力。</p><p id="b9a3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">所以下面给出的是关于模型创建的代码。</p><figure class="kz la lb lc fd ij"><div class="bz dy l di"><div class="mq mr l"/></div></figure><h2 id="5fc3" class="lh jp hi bd jq li lj lk ju ll lm ln jy jb lo lp kc jf lq lr kg jj ls lt kk lu bi translated">显示训练图:</h2><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ms"><img src="../Images/b7cec843560cb75f7f515d912fab1034.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l1iWbiXizB5een7MJE4lXg.jpeg"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">表掩码、列掩码和总体损失的训练图</figcaption></figure><p id="57e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">首先，两个是关于表和列掩码的损失，最后一个是关于训练和测试数据集的总体损失。该图绘制在损失和时期数之间。从图表中我们可以看出，在历元达到75历元之后，所有曲线的损耗都是稳定的。列检测中的损失是波动的，直到最后，这意味着必须进一步进行训练。</p><p id="2d11" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在用200个时期训练模型之后，这些是预测的输出模型。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mt"><img src="../Images/e924654e075dda813740ee7393c6a0c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3YJJXzWRks0IQGuPnD2MRA.jpeg"/></div></div></figure><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mu"><img src="../Images/6f830a854bd4b6c735113aac37e1e60c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Y6NVLH4_XC9nnBZVlN2LlQ.jpeg"/></div></div></figure><h2 id="7644" class="lh jp hi bd jq li lj lk ju ll lm ln jy jb lo lp kc jf lq lr kg jj ls lt kk lu bi translated">原始图像:</h2><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es mv"><img src="../Images/1ce7efae38bdb559348a6cb5acf555a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*v2jDBh1nYpO6phi1j0aUJQ.jpeg"/></div></figure><h2 id="b866" class="lh jp hi bd jq li lj lk ju ll lm ln jy jb lo lp kc jf lq lr kg jj ls lt kk lu bi translated">预测图像:</h2><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mw"><img src="../Images/3ee4804987bc24cfee77c134a098f322.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AxIT4pQcUgIqxibWMZhaWg.png"/></div></div></figure><p id="e4ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因为性能指标将通过精确度、召回率和f1分数来验证模型工作的效率。</p><p id="6327" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">下面是给定模型的结果。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es mx"><img src="../Images/0666a6005b3c9bf58a5c4c550ac76b63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*Xi41RAa1CzL0ql9FUdnM4Q.jpeg"/></div></figure><p id="7730" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">将平板电脑模型与AlexNet进行比较，看看平板电脑与另一个模型相比表现如何。</p><h1 id="1ca5" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">应用AlexNet:</h1><figure class="kz la lb lc fd ij"><div class="bz dy l di"><div class="mq mr l"/></div></figure><p id="45ac" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用200个时期训练模型后，有输出模型在预测。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es my"><img src="../Images/15001efa651384c3dc7a826e6371a21f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tx9nYPHs2RRVztjr6CfROQ.jpeg"/></div></div></figure><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mz"><img src="../Images/8b43fe7e2526c846967df828b5d34654.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_k51bvTY5brdPrWEOHq40Q.jpeg"/></div></div></figure><p id="e2fe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以下是给定型号的结果。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es na"><img src="../Images/c9311f353fd2249e5d02acb79ef0d4b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*uRoAeAskE5VPh3-i-NlK2w.jpeg"/></div></figure><p id="6e3f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我已经尝试了AlexNet编码器架构，并与解码器合并，以预测表和列掩码。AlexNet的相应精度、召回率和f1值并没有比TableNet有所提高。与TableNet相比，有效性损失更大。</p><h1 id="dc26" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">8.数据提取:</h1><p id="0a9d" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">在训练TableNet模型并找出最佳权重后，主要任务之一是预测图像中是否存在表格，如果存在，则以CSV文件的形式从表格中提取信息。</p><p id="3222" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，对于给定的图像，下面给出的是来自预测表图像的CSV文件。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es nb"><img src="../Images/9fb7af8a9656e577f036d5e78ac4276d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zNy4_kubLxOlldYv05tvUw.jpeg"/></div></div><figcaption class="ld le et er es lf lg bd b be z dx translated">相应预测图像的csv文件</figcaption></figure><h1 id="9189" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">9.部署:</h1><p id="4ab4" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">我使用Flask来部署这个DL模型。</p><figure class="kz la lb lc fd ij"><div class="bz dy l di"><div class="nc mr l"/></div></figure><h1 id="37c3" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">10.未来工作:</h1><p id="0333" class="pw-post-body-paragraph iq ir hi is b it kt iv iw ix ku iz ja jb kv jd je jf kw jh ji jj kx jl jm jn hb bi translated">我用200个纪元训练了TableNet模型，这比研究论文要求的要少得多。因此，准确性受到了影响，但模型仍然为表掩码提供了95%的f1值，为列掩码提供了86%的f1值。由于GPU支持有限，我无法运行更多的epochs来提高f1分数，因此从图像中预测的表格会与实际表格有一点偏差，此外，它还会直接影响将表格转换为CSV文件。</p><p id="dea0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">按照研究论文推荐的程序，我们需要将模型训练到5000个历元，以便提高效率。所以未来我想利用GPU的支持，用大量的历元来训练模型。</p><p id="9835" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">用marmot数据集训练模型，总文件数为495，这在我们训练深度学习模型时过低。将来，如果有更多的可用数据，我会训练这个模型。</p><p id="b3f6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">发现所有的marmot文件都是模糊的，所以模型不能正确地预测表格，这可能是不能正确预测表格的原因。Tesseract OCR(pytesserac)更适合高分辨率图像，因为我们有低分辨率的图像，因此我们可以看到，对于一些表格图像，tessera CT OCR无法将图像正确转换为文本。</p><p id="e93d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，总之，包含大量数据的高分辨率图像以及高GPU支持可以极大地提高模型性能。这是我将来想做的几件作品。</p><h1 id="efef" class="jo jp hi bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">11.参考</h1><ol class=""><li id="7102" class="lv lw hi is b it kt ix ku jb lx jf ly jj lz jn ma mb mc md bi translated"><a class="ae me" href="https://arxiv.org/pdf/2001.01469.pdf" rel="noopener ugc nofollow" target="_blank"> TableNet:深度学习模型，用于从扫描的文档图像中进行端到端的表格检测和表格数据提取</a></li><li id="ff87" class="lv lw hi is b it mf ix mg jb mh jf mi jj mj jn ma mb mc md bi translated">图像分割|张量流核心</li></ol><div class="nd ne ez fb nf ng"><a href="https://www.tensorflow.org/tutorials/images/segmentation" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">图像分割|张量流核心</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">本教程的重点是图像分割的任务，使用一个修改的U-Net。到目前为止，您已经看到了图像…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">www.tensorflow.org</p></div></div><div class="np l"><div class="nq l nr ns nt np nu io ng"/></div></div></a></div><p id="cd45" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.进行端到端案例研究</p><div class="nd ne ez fb nf ng"><a href="https://www.appliedaicourse.com/" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">应用课程</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">我们知道转行是多么具有挑战性。我们的应用人工智能/机器学习课程被设计为整体学习…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">www.appliedaicourse.com</p></div></div><div class="np l"><div class="nv l nr ns nt np nu io ng"/></div></div></a></div><p id="55a9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">你可以从我下面的GitHub链接查看这个案例研究的所有细节:</strong></p><div class="nd ne ez fb nf ng"><a href="https://github.com/tiwaridipak103/Table_extraction" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">tiwaridipak 103/Table _ extraction</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">它是一个深度学习模型，用于从扫描的文档图像中进行端到端的表格检测和表格数据提取…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">github.com</p></div></div><div class="np l"><div class="nw l nr ns nt np nu io ng"/></div></div></a></div><p id="adcf" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">我的LinkedIn </strong>:</p><div class="nd ne ez fb nf ng"><a href="https://www.linkedin.com/in/dipak-kr-tiwari/" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">迪帕克Kr。Tiwari -培训生-应用人工智能课程| LinkedIn</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">查看Dipak Kr。蒂瓦里在全球最大的职业社区LinkedIn上的个人资料。迪帕克Kr。有3个工作列在…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">www.linkedin.com</p></div></div><div class="np l"><div class="nx l nr ns nt np nu io ng"/></div></div></a></div></div></div>    
</body>
</html>