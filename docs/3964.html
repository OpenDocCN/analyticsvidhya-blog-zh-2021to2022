<html>
<head>
<title>MNIST Handwritten Digit Recognition Using Pytorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Pytorch的MNIST手写数字识别</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/training-mnist-handwritten-digit-data-using-pytorch-5513bf4614fb?source=collection_archive---------0-----------------------#2021-08-14">https://medium.com/analytics-vidhya/training-mnist-handwritten-digit-data-using-pytorch-5513bf4614fb?source=collection_archive---------0-----------------------#2021-08-14</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/f99f40d5b55b5237a0657f72e1e601db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*AzqsTFA8Ccf2ZC5_.jpg"/></div></div></figure><blockquote class="iq ir is"><p id="af62" class="it iu iv iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">数据概述</strong></p></blockquote><p id="0f5e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">MNIST数据集由60，000幅手写数字图像组成。其中每个图像的大小为28×28。在这里，MNIST代表修改后的国家标准与技术研究所。它包括从0到9的10个不同的类别。这意味着我们要处理的问题是多类分类问题。在这个博客上，你将了解Pytorch的基本实现。</p><p id="ac0b" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">步骤1 :-导入必要的库&amp;参数初始化</strong></p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="04f7" class="ke kf hi ka b fi kg kh l ki kj"><strong class="ka hj">import torch<br/>import torchvision<br/>import numpy as np<br/>import pandas as pd<br/>import matplotlib.pyplot as plt<br/>import torch.nn as nn<br/>from torchvision.transforms import transforms<br/>import torch.nn.functional as F</strong></span></pre><p id="c828" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">初始化参数</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="0a57" class="ke kf hi ka b fi kg kh l ki kj">input_size=784   #28X28 pixel of image<br/>hidden_size1=200 #size of 1st hidden layer(number of perceptron)<br/>hidden_size2=150 #size of second hidden layer<br/>hidden_size3=100 #size of third hidden layer<br/>hidden_size=80   #size of fourth hidden layer<br/>output =10       #output layer<br/>bach_size=100<br/>lr_rate=0.01<br/></span></pre><p id="3fd3" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">步骤2:-使用Pytorch数据集和数据加载器加载数据集</strong></p><p id="328e" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">MNIST数据集已经存在于火炬视觉库中。</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="fd81" class="ke kf hi ka b fi kg kh l ki kj">train_dataset=torchvision.datasets.MNIST('/content',train=True,trans<br/>              forms=transforms.ToTensor(),download=True)</span></pre><ol class=""><li id="6c23" class="kk kl hi iw b ix iy jb jc js km jt kn ju ko jr kp kq kr ks bi translated">“/content”:保存/下载数据的目录…</li><li id="d8ff" class="kk kl hi iw b ix kt jb ku js kv jt kw ju kx jr kp kq kr ks bi translated">train = True:-数据集将被用作进一步操作的训练示例。</li><li id="c970" class="kk kl hi iw b ix kt jb ku js kv jt kw ju kx jr kp kq kr ks bi translated">转变。ToTensor():将图像数据集转换为张量………</li></ol><p id="0710" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">4.download=True:-将从Pytorch集合中下载数据</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="b720" class="ke kf hi ka b fi kg kh l ki kj">test_dataset=torchvision.datasets.MNIST('/content',train=False,     <br/>              transforms=transforms.ToTensor(),download=False)</span></pre><p id="69ec" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">将列车数据加载器和测试数据加载器用于进一步操作。</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="0ae5" class="ke kf hi ka b fi kg kh l ki kj">train_dataloader=torch.utils.data.DataLoader(dataset=train_dataset, <br/>                                  batch_size=100,shuffle=True)<br/>train_dataloader=torch.utils.data.DataLoader(dataset=test_dataset, <br/>                                  batch_size=100,shuffle=True)</span></pre><p id="d788" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在这里，我们已经通过使用数据加载器解决了数据过载问题，我们将只从大型数据集中传递固定的一批数据。</p><p id="eb76" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">让我们看看已经批量传递的数据data的形状</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="da4b" class="ke kf hi ka b fi kg kh l ki kj">data=iter(train_dataloader)<br/>samples,labels=next(data)<br/>print(f"number of samples{samples.shape}")<br/>print(f"number of labels {labels.shape}")</span><span id="416a" class="ke kf hi ka b fi ky kh l ki kj">[out]&gt;&gt;shape of samplestorch.Size([100, 1, 28, 28])<br/>       shape of labels torch.Size([100])</span></pre><p id="6f6b" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">步骤3:-打印数据集的图像</strong></p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="3c60" class="ke kf hi ka b fi kg kh l ki kj">plt.figure(figsize=(10,8))<br/>for i in range(10):<br/>    plt.subplot(2,5,i+1)<br/>    plt.imshow(samples[i][0],cmap='BuPu')<br/>plt.show()</span></pre><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kz"><img src="../Images/5f2651995723aff3b5951a1d2da00045.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ltxmIYQnZF0dH0ndSpvZeA.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图像输出</figcaption></figure><p id="26ce" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">步骤4:-定义培训管道</strong></p><p id="2f51" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">培训管道设计将包括以下三个步骤:</p><ol class=""><li id="d557" class="kk kl hi iw b ix iy jb jc js km jt kn ju ko jr kp kq kr ks bi translated">用激活函数取输入尺寸、隐尺寸和输出尺寸设计神经网络</li><li id="0d67" class="kk kl hi iw b ix kt jb ku js kv jt kw ju kx jr kp kq kr ks bi translated">为特定问题构建损失和优化函数</li><li id="e77b" class="kk kl hi iw b ix kt jb ku js kv jt kw ju kx jr kp kq kr ks bi translated">训练循环包括三个步骤:- a .正向传递:- a .给出预测b .反向传递:-梯度和c .权重更新</li></ol><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="4299" class="ke kf hi ka b fi kg kh l ki kj">class MNIST(nn.Module):<br/>    def __init__(self,input_size,hidden_size1,hidden_size2<br/>                       ,hidden_size3,hidden_size,output):<br/>        super(MNist,self).__init__()<br/>        self.f_connected1=nn.Linear(input_size,hidden_size1)<br/>        self.f_connected2=nn.Linear(hidden_size1,hidden_size2)<br/>        self.f_connected3=nn.Linear(hidden_size2,hidden_size3)<br/>        self.f_connected4=nn.Linear(hidden_size3,hidden_size)<br/>        self.out_connected=nn.Linear(hidden_size,output)</span><span id="793f" class="ke kf hi ka b fi ky kh l ki kj">def forward(self,x):<br/>        out=F.relu(self.f_connected1(x)) <br/>        out=F.relu(self.f_connected2(out))<br/>        out=F.relu(self.f_connected3(out))<br/>        out=F.relu(self.f_connected4(out))<br/>        out=self.out_connected(out)<br/>        return out</span></pre><p id="7993" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><code class="du le lf lg ka b">nn.module</code>:-py torch中的<code class="du le lf lg ka b">nn.module</code>帮助我们创建人工神经网络。<code class="du le lf lg ka b">nn.Linear </code>使特征和神经元之间的线性连接&amp; <code class="du le lf lg ka b">Torch.nn.functional</code>模块由所有的激活函数和输出函数组成(例如:- relu，leaky relu，softmax，sigmoid等。)不，我们已经成功地建立了神经网络和正向传递。</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="eb94" class="ke kf hi ka b fi kg kh l ki kj">Mnist_model=MNIST(input_size,hidden_size1,hidden_size2<br/>                       ,hidden_size3,hidden_size,output)<br/>#calling the object that has been created inside MNIST class</span></pre><p id="df64" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">打印所有用于创建神经网络的参数。权值和偏差被认为是神经网络的参数。</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="ae3e" class="ke kf hi ka b fi kg kh l ki kj">print(Mnist_model.paramaters)</span></pre><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/18f34eea3e7d0b3d99d52c81fc7491ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*llY1YfiWUPfYyWHo7v-SfQ.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">图:结果</figcaption></figure><p id="d002" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">模型的构造损耗及优化</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="aed8" class="ke kf hi ka b fi kg kh l ki kj">loss=nn.CrossEntropyLoss()<br/>optimizer=torch.optim.Adam(Mnist_model.parameters(),lr=lr_rate)</span></pre><p id="76ef" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">现在我们将建立一个训练循环，它包括预测结果的前向传递，梯度的后向传递，最后权重将被更新。</p><p id="cdbc" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">由于我们在上面已经看到了训练样本的形状，即[100，1，28，28]，我们需要将样本形状转换为[100，28*28]。因此，我们的第一步将是重塑样本的大小，然后我们将再次进行进一步的训练过程。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/03d3dc3889a35284fabee507c936c698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dLqmsgiVkqE1x157Z--erA.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">训练图像</figcaption></figure><p id="528c" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">让我们在验证数据集上检查模型的准确性。在我们的例子中，验证数据集应该是test_dataloader。</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="c409" class="ke kf hi ka b fi kg kh l ki kj">with torch.no_grad():<br/>    n_correct=0<br/>    n_samples=0<br/>    for images,labels in test_dataloader:<br/>        images=images.reshape(-1,784)<br/>        output=Mnist_model(images)<br/>        labels=labels<br/>        _,prediction=torch.max(output,1)<br/>        n_samples=labels.shape[0]<br/>        n_correct=(prediction==labels).sum().item()<br/>   accuracy=(n_correct/n_samples)*100</span></pre><p id="845d" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">在这个模型上，我在验证集上获得了97%的准确率。</p><p id="26fd" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">让我们预测一下结果</p><pre class="jv jw jx jy fd jz ka kb kc aw kd bi"><span id="3273" class="ke kf hi ka b fi kg kh l ki kj">predicted=[]<br/>with torch.no_grad():<br/>    n_correct=0<br/>    n_samples=0<br/>    for images,labels in test_dataloader:<br/>        images=images.reshape(-1,784)<br/>        output=Mnist_model(images) #applying the model we have built<br/>        labels=labels<br/>        _,prediction=torch.max(output,1)<br/>        predicted.append(prediction)<br/>print(prediction)</span></pre><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/b5ce623b43a8b62ee113de6b006ab833.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*apiY6e0QHFROQn6hQyG1XA.png"/></div></div><figcaption class="la lb et er es lc ld bd b be z dx translated">决赛成绩</figcaption></figure><p id="c274" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated"><strong class="iw hj">结论:- </strong></p><p id="d5e4" class="pw-post-body-paragraph it iu hi iw b ix iy iz ja jb jc jd je js jg jh ji jt jk jl jm ju jo jp jq jr hb bi translated">希望你喜欢这个博客，请给我们宝贵的反馈，以便进一步改进。这个博客的灵感来自python工程师视频，请不要错过观看视频，以便更好地理解。不断探索不断学习……..</p></div></div>    
</body>
</html>