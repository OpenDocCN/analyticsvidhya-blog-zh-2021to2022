<html>
<head>
<title>Data Scraping Using Scrapy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Scrapy进行数据收集</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-scraping-ae8f94a592d7?source=collection_archive---------10-----------------------#2021-05-10">https://medium.com/analytics-vidhya/data-scraping-ae8f94a592d7?source=collection_archive---------10-----------------------#2021-05-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/68df63ed798c215c116710d0cf60db3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fch3cyEicuRuofHo.png"/></div></div></figure><p id="1917" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">今天我要讨论一个非常有趣的话题。</p><p id="a1cc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">使用Scrapy进行数据抓取。</p><p id="8ce7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，我们的任务是删除2010年至2020年间F1比赛的相关数据。</p><p id="2ad9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">你可以看一下网站-<a class="ae jn" href="https://www.formula1.com/en/results.html/2020/races.html" rel="noopener ugc nofollow" target="_blank"><em class="jo"/></a></p><p id="111c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以首先，我们需要在你的系统中安装Scrapy。</p><p id="e93f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">使用</p><p id="bb63" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">&gt;&gt; !pip安装Scrapy来安装它，一旦你安装了它，你可以进一步移动。</p><p id="039d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你必须开始这个项目，命令是-</p><p id="54aa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">&gt; &gt; scrapy startproject <name_of_the_project/></p><figure class="jq jr js jt fd ii er es paragraph-image"><div class="er es jp"><img src="../Images/1804f105060aa45e49bf73ee6e7f7539.png" data-original-src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*NW7yzVkR6ZTg4VjxSA8neQ.png"/></div></figure><p id="72fc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在目录中导航，并在spiders目录中创建新文件。</p><p id="da76" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Ex- Link.py</p><p id="1045" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一旦你有了你的文件，你就可以开始写代码了。</p><p id="927e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">但是，但是在此之前，让我们看一下我们将要废弃的数据。请注意，这是一个重要的步骤，需要非常小心地执行。</p><p id="4666" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以，</p><figure class="jq jr js jt fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ju"><img src="../Images/750d866475ea10a901e5454eccc58a58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DmmO5yFthDugDi18hhszQ.png"/></div></div></figure><p id="9ad4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这样的东西会出现在你面前。你可以观察到我们每年都有一些比赛，如果你点击任何特定的比赛，你会看到类似这样的结果。</p><figure class="jq jr js jt fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jv"><img src="../Images/0c35a67fc7f27579f83baef421b99820.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*J2S61w2NzcdFd0oxyDtSyQ.png"/></div></div></figure><p id="8e41" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">注意-我们需要2010-2020年期间每场比赛的数据。</p><p id="c514" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们的第一个任务是提取每场比赛的链接，为此我们需要废弃每场比赛的链接的第一页。</p><figure class="jq jr js jt fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jw"><img src="../Images/7b290f4d1a888cabfacefcd177201ae7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cc-gHed-GcZMm2BfY1pbsQ.png"/></div></div></figure><p id="1ec7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这几行代码将帮助您提取2010年至2020年间发生的每场比赛的链接。</p><p id="ca18" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我先向您介绍一下代码。</p><p id="daf0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">首先你必须导入Scrapy并给类和变量命名。注意从命令行运行代码时将使用该名称。</p><p id="314c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在你有了一组url，由于网站的限制，我手动抓取了这些URL。</p><p id="39d7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以在提取10个链接后，我把它们放在我的URL中。此后，我开始了一个循环，一次删除一页。</p><p id="c0c1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们定义了一个函数parse来帮助我们提取数据，因此通过使用选择器，我们提取了2010年至2020年之间发生的每个比赛页面的链接。</p><p id="6b12" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，在代码之后，您需要执行这个命令来抓取链接。</p><p id="6dfa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">&gt; &gt; scrapy爬网链接-o links.json</p><p id="21b7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这个命令将抓取您的数据并保存在json formate中。</p><p id="4653" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">有了所有的链接之后，现在是提取实际数据的时候了。</p><figure class="jq jr js jt fd ii er es paragraph-image"><div class="er es jx"><img src="../Images/e7502399e02fd25ed1167fc96fbda003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1380/format:webp/1*dBnqRTwyWKEV4Mg0nqSyUw.png"/></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">剩余的代码将和以前一样，但你必须添加所有的爬行链接。</figcaption></figure><p id="d71f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在再次使用选择器，您可以选择您想要抓取的特定数据，并将数据保存在您的机器中。</p><p id="e9a3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">&gt;&gt;刺儿头爬行<name> -o <name_1>。json</name_1></name></p><p id="4a6c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这将抓取我们的目标数据。</p><p id="6ec4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">注意—</p><ol class=""><li id="e908" class="kc kd hh ir b is it iw ix ja ke je kf ji kg jm kh ki kj kk bi translated">在抓取之前，你必须对HTML和css有一点了解，因为这将有助于你使用选择器。</li><li id="6d3b" class="kc kd hh ir b is kl iw km ja kn je ko ji kp jm kh ki kj kk bi translated">&gt;&gt;刺儿壳<link/></li></ol><p id="e5e4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这个命令是一个救命符，因为它帮助您使用选择器，并且将帮助您只提取相关的数据。</p><p id="a1b2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">雅皮士，你已经抓取并保存了你想要的数据。</p><p id="3635" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以，在这篇文章中，我用Scrapy带你浏览了网络爬行。</p><p id="5c9c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你没有得到这个，请不要感到沮丧，你需要先在一个简单的网站上试试你的手，然后再回来你会得到它。在这个例子中，我们首先抓取链接，然后抓取那些页面上的数据。</p><p id="4abc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我试图在一篇精确而简短的文章中解释网络爬行，如果你有进一步的疑问，你可以参考Scrapy的文档。</p><p id="cc3d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">谢谢你读出来，如果你喜欢这个帖子，你可以激励我一些👏。</p><p id="60b7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">文档链接-<a class="ae jn" href="https://docs.scrapy.org/en/latest/" rel="noopener ugc nofollow" target="_blank">https://docs.scrapy.org/en/latest/</a></p></div></div>    
</body>
</html>