<html>
<head>
<title>Face Recognition and ArcFace: Additive Angular Margin Loss for Deep Face Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">人脸识别和ArcFace:深度人脸识别的附加角裕度损失</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/face-recognition-and-arcface-additive-angular-margin-loss-for-deep-face-recognition-44abc56916c?source=collection_archive---------0-----------------------#2021-08-10">https://medium.com/analytics-vidhya/face-recognition-and-arcface-additive-angular-margin-loss-for-deep-face-recognition-44abc56916c?source=collection_archive---------0-----------------------#2021-08-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><blockquote class="if ig ih"><p id="262a" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated">最广泛使用的多类分类损失函数是分类交叉熵损失，也称为SoftMax损失，即SoftMax激活之后是交叉熵损失。但是，它是否明确地最大化了类的可分性？</p></blockquote><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es jh"><img src="../Images/64fa433e835f9fe786d36c515a61bddc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RXO1jsfF6ZfOYsp0IB165A.jpeg"/></div></div></figure><p id="f5f3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">在本文中，您将发现一种ArcFace方法，这种方法可以获得用于人脸识别的高区分度特征。阅读本文后，您将了解:</p><ul class=""><li id="4cde" class="jw jx hi il b im in iq ir jt jy ju jz jv ka jg kb kc kd ke bi translated">人脸识别任务是如何工作的。</li><li id="df1d" class="jw jx hi il b im kf iq kg jt kh ju ki jv kj jg kb kc kd ke bi translated">如何计算人脸匹配？</li><li id="3b87" class="jw jx hi il b im kf iq kg jt kh ju ki jv kj jg kb kc kd ke bi translated">SoftMax和ArcFace的直观区别。</li><li id="9fa8" class="jw jx hi il b im kf iq kg jt kh ju ki jv kj jg kb kc kd ke bi translated">弧面的几何解释。</li><li id="68e7" class="jw jx hi il b im kf iq kg jt kh ju ki jv kj jg kb kc kd ke bi translated">ArcFace背后的数学。</li></ul><p id="73fe" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">本文假设您已经熟悉用于多类分类、检测和SoftMax损失的卷积神经网络概念，并重点关注人脸识别任务和ArcFace方法。</p><h1 id="5492" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">人脸识别任务</strong></h1><p id="12aa" class="pw-post-body-paragraph ii ij hi il b im li io ip iq lj is it jt lk iw ix ju ll ja jb jv lm je jf jg hb bi translated">在我们深入研究ArcFace方法之前，让我们首先了解一下人脸识别任务是如何工作的，以及我们为什么需要它。</p><p id="9d23" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">人脸识别</strong>是识别或验证图像中一张或多张人脸的任务。我们希望在图像中识别人脸的原因有很多:机场安检可以验证乘客的面部与其护照上的面部是否匹配，脸书可以识别并标记图像中的人，在工作场所，我们希望只允许授权人员进入。</p><p id="e2f6" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">验证任务</strong>是比较两张人脸并检查它们是否是同一个人的任务。</p><p id="357d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated"><strong class="il hj">识别任务</strong>是将给定的人脸与存储的人脸数据库进行比较和识别的任务。</p><p id="f41f" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">人脸识别的过程通常包括3个主要步骤:检测图像中的人脸、特征提取和人脸匹配。</p><h1 id="f657" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">人脸匹配</strong></h1><h2 id="71bf" class="ln kl hi bd km lo lp lq kq lr ls lt ku jt lu lv ky ju lw lx lc jv ly lz lg ma bi translated"><strong class="ak">特征嵌入</strong></h2><p id="b476" class="pw-post-body-paragraph ii ij hi il b im li io ip iq lj is it jt lk iw ix ju ll ja jb jv lm je jf jg hb bi translated">用于分类的典型CNN包括特征提取和分类。在训练期间，模型学习独特的面部特征，并在特征提取过程中产生特征嵌入。一旦训练完成，就可以跳过分类部分，对每张人脸图像产生特征嵌入，就像一个数字“指纹”。考虑嵌入向量的另一种方法是将高维数据转换成相对低维的数据。</p><p id="b05b" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">这些嵌入帮助我们通过使用余弦相似性或两个向量之间的平方距离来理解两个人之间是否存在相似性。</p><p id="9b95" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">同一个人的两个不同图像的向量将具有高相似性和低距离，而不同人的两个图像将具有低相似性和大平方距离。</p><p id="40d2" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">现在，给定两张人脸图像，在我们检测并裁剪人脸后，我们可以通过ArcFace模型处理它们，这将产生两个特征嵌入。一旦我们得到两个嵌入向量，我们将能够计算它们之间的余弦相似度或平方距离，并确定这两幅图像是否是同一个人。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mb"><img src="../Images/57fd5421e903d5fdf92e91cddac7819b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/0*ZxKny8DLFLp1kkDk.png"/></div><figcaption class="mc md et er es me mf bd b be z dx translated">人脸验证的通用流水线，其中分类器损失函数用于训练，相似性判别式用于获得最终的验证精度，来源:<a class="ae mg" href="https://www.researchgate.net/publication/323025952_Exponential_Discriminative_Metric_Embedding_in_Deep_Learning" rel="noopener ugc nofollow" target="_blank">深度学习中的指数判别式度量嵌入</a></figcaption></figure><h2 id="49d9" class="ln kl hi bd km lo lp lq kq lr ls lt ku jt lu lv ky ju lw lx lc jv ly lz lg ma bi translated"><strong class="ak">余弦相似度</strong></h2><p id="f22c" class="pw-post-body-paragraph ii ij hi il b im li io ip iq lj is it jt lk iw ix ju ll ja jb jv lm je jf jg hb bi translated">余弦相似度的范围在-1和1之间。在内积空间中，这是两个向量之间的方向(而不是大小)相似性的度量，这两个向量不是零向量。余弦相似度等于两个向量之间的余弦，并且与两个归一化向量之间的内积相同:</p><ul class=""><li id="5955" class="jw jx hi il b im in iq ir jt jy ju jz jv ka jg kb kc kd ke bi translated">如果两个向量方向相同，余弦相似度为1</li><li id="b1c9" class="jw jx hi il b im kf iq kg jt kh ju ki jv kj jg kb kc kd ke bi translated">如果两个向量成90度角，余弦相似度为0</li><li id="48ec" class="jw jx hi il b im kf iq kg jt kh ju ki jv kj jg kb kc kd ke bi translated">如果它们相反，那么余弦相似度是-1</li></ul><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mh"><img src="../Images/8830c475b13d9c7271399f16cf89aa7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VqFvjmVXAQvpOR9dw9thCA.gif"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">ArcFace的人脸识别演示，来源:<strong class="bd km"/><a class="ae mg" href="https://www.youtube.com/watch?v=y-D1tReryGA&amp;t=16s" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=y-D1tReryGA&amp;t = 16s</a></figcaption></figure><p id="92b1" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">边界框旁边的条是余弦相似度，表示人脸图像的内方差。</p><h1 id="4854" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak"> SoftMax vs ArcFace </strong></h1><p id="2d94" class="pw-post-body-paragraph ii ij hi il b im li io ip iq lj is it jt lk iw ix ju ll ja jb jv lm je jf jg hb bi translated">在标准分类网络中，通常在网络的末端使用SoftMax和分类交叉熵损失。SoftMax将数字转换成概率。对于每个对象，它给出了每个类的概率总和为1。一旦训练完成，选择概率最高的类。分类交叉熵损失计算两个概率分布之间的差异，并在训练期间的反向传播过程中被最小化。</p><p id="b7c9" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">SoftMax的缺点是它不能产生安全余量，这意味着边界有点模糊。我们希望同一个人的两幅图像的向量尽可能相似，两个不同的人的两幅图像的向量尽可能不同。这意味着我们想创造利润，就像SVM一样。</p><p id="aef3" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">看看下面的例子。这里，我们看到MNIST数字的特征嵌入。值得注意的是，与Arcface要素嵌入相比，SoftMax要素的边界相对模糊:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mi"><img src="../Images/8ba4b87933449d128810e51ed48d21ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1jXgpebPQDwdwSyQQAMTkA.png"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">https://github.com/4uiiurz1/keras-arcface/，ArcFace vs SoftMax，来源:<a class="ae mg" href="https://github.com/4uiiurz1/keras-arcface/" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mh"><img src="../Images/f51f87425fc42c9141f497d57ffa8d8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*kzNbn7AsD9WjS0Hh_ZjlBA.gif"/></div></div><figcaption class="mc md et er es me mf bd b be z dx translated">用ArcFace学习了MNIST的功能，来源:<a class="ae mg" href="https://youtu.be/tgnitF1irVM" rel="noopener ugc nofollow" target="_blank">https://youtu.be/tgnitF1irVM</a></figcaption></figure><h1 id="a321" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">弧面的几何解释</strong></h1><p id="18df" class="pw-post-body-paragraph ii ij hi il b im li io ip iq lj is it jt lk iw ix ju ll ja jb jv lm je jf jg hb bi translated">ArcFace不使用欧几里得距离，而是计算超球面上的测地线距离。测地线空间是所有距离都由轨道测量的空间。两点之间获得的轨迹称为测地线轨迹。它描述了两点之间的最短距离，也称为测地线距离。</p><p id="5e94" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">在下图中，我们可以看到ArcFace的几何解释:</p><p id="6a7c" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">(a)角度和弧边之间的直观对应。弧面的角边对应于超球面上的测地线距离&amp;弧边。</p><p id="7334" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">(b)蓝色和绿色点代表来自两个不同类别的嵌入特征。ArcFace可以直接在类之间施加角度(弧)边距。</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mj"><img src="../Images/cfcc8dd09c9c739434b7898fe45fd5c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*FkaRHM2BLhlVYTS-6veDKg.png"/></div><figcaption class="mc md et er es me mf bd b be z dx translated">来源:<a class="ae mg" href="https://deepai.org/publication/arcface-additive-angular-margin-loss-for-deep-face-recognition" rel="noopener ugc nofollow" target="_blank"> DeepAI </a></figcaption></figure><h1 id="8062" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">弧面背后的数学原理</strong></h1><p id="f6f4" class="pw-post-body-paragraph ii ij hi il b im li io ip iq lj is it jt lk iw ix ju ll ja jb jv lm je jf jg hb bi translated">这是SoftMax损失函数，通常用于多类分类任务:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mk"><img src="../Images/55d4bd135727daea7b304a81e1031e1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*poRNzVG8LJepFE7FMCh41g.png"/></div></div></figure><p id="8754" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">这是弧面损失函数:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es ml"><img src="../Images/9238d72b21d5e53de877920de9430ad6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oawars-kBswaFOHycGXxoQ.png"/></div></div></figure><p id="00b7" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">您可以看到，两个损失函数之间的唯一差异是logit，即SoftMax的功效，并且余量被添加到地面真实值。</p><p id="0896" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">让我们观察一下如何从SoftMax logit进入ArcFace logit。</p><p id="fa32" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">为方便起见，假设偏差为零。使用计算两个向量之间角度的公式，我们知道两个向量之间的内积等于以下表达式:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mm"><img src="../Images/fe6efad9a2a4aba540f226313a4c23c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*JpzLx9E0l3yMJe2y34vKIw.png"/></div></figure><p id="50ef" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">我们想提取θ。为此，我们将w和x归一化，使它们的大小都为1:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mn"><img src="../Images/435ada723d84acc6c875cb12244a0bc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/1*nEr-zIBXH415rtHHSU_CgQ.png"/></div></figure><p id="af0e" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">我们得到了这个等式:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mo"><img src="../Images/adfd27431d7fa4e18870bf0e6ef58fcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:250/format:webp/1*34ycdvppAv25sTbkJJgkvQ.png"/></div></figure><p id="384d" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">为了提取theta，我们计算两边的arccos并获得theta:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mp"><img src="../Images/990f69bbc02ada46fa76ad0811dd687e.png" data-original-src="https://miro.medium.com/v2/resize:fit:524/format:webp/1*H1t_l5jYOwWLXsVgJtE1ow.png"/></div></figure><p id="48b9" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">现在，我们给角度加上余量，例如0.5，并计算它的余弦。最终，我们将此乘以<strong class="il hj"> <em class="ik"> s </em> </strong>，例如，超球面上的半径为30，我们得到弧面的logit:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div class="er es mq"><img src="../Images/9caca78b509cde27dbe4f671367a2391.png" data-original-src="https://miro.medium.com/v2/resize:fit:290/format:webp/1*ztW6iMFVsnaapMEfLag_Lw.png"/></div></figure><p id="5b86" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">在下图中，您可以看到弧面损失的构成，步骤如上所述:</p><figure class="ji jj jk jl fd jm er es paragraph-image"><div role="button" tabindex="0" class="jn jo di jp bf jq"><div class="er es mr"><img src="../Images/aff44f338efbeda7d8b0a0d4ef561040.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EC4Nb__wuWV4jumQHwm9WA.png"/></div></div></figure><p id="7057" class="pw-post-body-paragraph ii ij hi il b im in io ip iq ir is it jt iv iw ix ju iz ja jb jv jd je jf jg hb bi translated">归一化x和w很重要！它基本上迫使预测仅依赖于角度，因此嵌入分布在半径s内的超球面上。</p><h1 id="63f4" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">结论</strong></h1><p id="9d40" class="pw-post-body-paragraph ii ij hi il b im li io ip iq lj is it jt lk iw ix ju ll ja jb jv lm je jf jg hb bi translated">我们已经讨论了人脸识别任务和ArcFace方法。在实践中，弧面损失改变了SoftMax的logit，并且由于它与超球面上的测地线距离的精确对应，它具有清晰的几何解释。由于归一化的权重和特征，弧面损失最大化了裕度，即超球面上测地线空间的决策边界。它获得用于人脸识别的高鉴别特征，并且可以容易地以可忽略的计算开销来实现。</p><h1 id="3061" class="kk kl hi bd km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">参考</h1><blockquote class="if ig ih"><p id="7f1a" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated"><a class="ae mg" href="https://arxiv.org/pdf/1801.07698.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1801.07698.pdf</a></p><p id="d7c3" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated"><a class="ae mg" href="https://machinelearningmastery.com/introduction-to-deep-learning-for-face-recognition/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/人脸识别深度学习简介/ </a></p><p id="6c23" class="ii ij ik il b im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg hb bi translated"><a class="ae mg" rel="noopener" href="/apache-mxnet/onnx-model-zoo-developing-a-face-recognition-application-with-onnx-models-64eeeddb9c7a">https://medium . com/Apache-mxnet/onnx-model-zoo-developing-a-face-recognition-application-with-onnx-models-64 eed db 9 c7a</a></p></blockquote></div></div>    
</body>
</html>