<html>
<head>
<title>Building Classification Model with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用Python构建分类模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-classification-model-with-python-9bdfc13faa4b?source=collection_archive---------1-----------------------#2021-01-29">https://medium.com/analytics-vidhya/building-classification-model-with-python-9bdfc13faa4b?source=collection_archive---------1-----------------------#2021-01-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="1a58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">嗨！在这篇文章中，我将讲述用Python创建自己的分类模型的基础。我将尝试从准备数据、训练模型、优化模型以及如何保存数据以备后用，一步步向您解释和演示。这篇文章是我一直在做的一个迷你系列的第二部分，如果你没有读过我以前的关于使用Python进行多元线性回归的文章，一定要去看看。</p><p id="e210" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以试着用笔记本<a class="ae jd" href="https://colab.research.google.com/github/rafiag/DTI2020/blob/main/004_Classification_Bank_Marketing_Dataset_(Assignment).ipynb" rel="noopener ugc nofollow" target="_blank">跟随这里的</a>，祝你好运，玩得开心！</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="be79" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">介绍</h1><p id="08aa" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在机器学习中，分类是基于包含类别成员已知的观察值(或实例)的训练数据集，识别新观察值属于一组类别(子群体)中的哪一个的问题。分类问题的几个例子是:(a)决定接收的电子邮件是垃圾邮件还是有机电子邮件；(b)基于观察到的患者特征(年龄、血压、某些症状的存在或不存在等)指定对患者的诊断。)</p><p id="d170" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将使用来自Kaggle的<a class="ae jd" href="https://www.kaggle.com/janiobachmann/bank-marketing-dataset" rel="noopener ugc nofollow" target="_blank">银行营销数据集</a>建立一个模型，根据一些属性来预测某人是否会存款。我们将尝试使用不同的算法决策树、随机森林、朴素贝叶斯和K近邻来构建4个不同的模型。在建立每个模型后，我们将对它们进行评估，并比较哪个模型最适合我们的情况。然后，我们将尝试通过使用GridSearch调整模型的超参数来优化我们的模型。最后，我们将保存来自数据集的预测结果，然后保存我们的模型以供重用。</p><p id="620b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们将加载一些基本库，如Pandas和NumPy，然后对其中一些库进行一些配置。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="8325" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">数据预处理</h1><p id="50ae" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在我们开始创建第一个模型之前，我们首先需要加载和预处理。这一步确保了我们模型将会得到一个好的数据来学习，正如他们所说的“一个模型只有当它的数据好的时候才是好的”。如下所述，数据预处理将被分成几个步骤。</p><h2 id="9828" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">加载数据</h2><p id="ab34" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在第一步中，我们将加载已经上传到我的GitHub上的数据集，以便于处理。从数据集文档中找到<a class="ae jd" href="https://archive.ics.uci.edu/ml/datasets/Bank+Marketing" rel="noopener ugc nofollow" target="_blank">这里</a>我们可以看到下面是我们数据中的列列表:</p><p id="fbf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输入变量:</p><ol class=""><li id="4dfd" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lo lp lq lr bi translated">年龄(数字)</li><li id="a71a" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">作业:作业类型(分类:“管理。”、'蓝领'、'企业家'、'女佣'、'管理'、'退休'、'自雇'、'服务'、'学生'、'技术员'、'失业'、'未知')</li><li id="8204" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">婚姻:婚姻状况(分类:“离婚”、“已婚”、“单身”、“未知”)；注意:“离婚”是指离婚或丧偶)</li><li id="a2b9" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">教育(分类:'基础. 4y '，'基础. 6y '，'基础. 9y '，'高中'，'文盲'，'专业.课程'，'大学.学位'，'未知')</li><li id="f71c" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">违约:有信用违约？(分类:“否”、“是”、“未知”)</li><li id="8cfa" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">住房:有住房贷款吗？(分类:“否”、“是”、“未知”)</li><li id="9d94" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">贷款:有个人贷款？(分类:“否”、“是”、“未知”)</li><li id="053b" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">联系人:联系人通信类型(分类:“手机”、“电话”)</li><li id="752d" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">月份:一年中的最后一个联系月份(分类:'一月'，'二月'，'三月'，…，'十一月'，'十二月')</li><li id="1485" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">星期几:一周的最后一个联系日(分类:“星期一”、“星期二”、“星期三”、“星期四”、“星期五”)</li><li id="d48d" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">duration:上次联系持续时间，以秒为单位(数字)。重要注意事项:该属性对输出目标有很大影响(例如，如果duration=0，则y='no ')。然而，在执行呼叫之前，持续时间是未知的。还有，结束通话后y显然是已知的。因此，该输入应仅用于基准测试目的，如果目的是获得现实的预测模型，则应丢弃。</li><li id="c761" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">活动:在此活动期间为此客户执行的联系次数(数字，包括最后一次联系)</li><li id="714c" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">pdays:从上一个活动中最后一次联系客户后经过的天数(数字；999表示之前没有联系过客户)</li><li id="0f5a" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">上一次:在此活动之前为此客户执行的联系次数(数字)</li><li id="e55a" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated">poutcome:之前营销活动的结果(分类:“失败”、“不存在”、“成功”)</li></ol><p id="b5a8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">输出变量(期望目标):</p><ul class=""><li id="4d97" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">y:客户有没有订定期存款？(二进制:“是”、“否”)</li></ul><p id="1666" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根据数据集文档，我们需要删除“持续时间”列，因为在实际情况下，持续时间只有在标签列已知后才是已知的。这个问题可以被认为是“数据泄漏”,其中预测因子包括在你进行预测时不可用的数据。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es ly"><img src="../Images/61393f3e946a110abe21ead4f3566cf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nrwmb23MZSqiDToyHSWY4Q.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">我们将要处理的数据样本</figcaption></figure><h2 id="5e54" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">阶级分布</h2><p id="1463" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在将我们的数据输入模型之前，要确保的另一件重要事情是数据的类别分布。在我们的例子中，期望类被分成两种结果，“是”和“否”，50:50的类分布可以被认为是理想的。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><pre class="ko kp kq kr fd mj mk ml mm aw mn bi"><span id="a730" class="kv jm hi mk b fi mo mp l mq mr">no     5873<br/>yes    5289<br/>Name: deposit, dtype: int64</span></pre><p id="ee82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们所看到的，我们的班级分布或多或少是相似的，不完全是50:50的分布，但仍然足够好。</p><h2 id="375e" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">缺少值</h2><p id="dc80" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在继续之前，最后要检查的是缺少的值。在某些情况下，我们的数据可能在某些列中有丢失的值，这可能是由一些原因造成的，如人为错误。我们可以使用Pandas的<code class="du ms mt mu mk b">is_null()</code>函数来检查任何缺失的数据，然后使用<code class="du ms mt mu mk b">sum()</code>函数来查看每一列中缺失值的总数。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><pre class="ko kp kq kr fd mj mk ml mm aw mn bi"><span id="6489" class="kv jm hi mk b fi mo mp l mq mr">age          0<br/>job          0<br/>marital      0<br/>education    0<br/>default      0<br/>balance      0<br/>housing      0<br/>loan         0<br/>contact      0<br/>day          0<br/>month        0<br/>campaign     0<br/>pdays        0<br/>previous     0<br/>poutcome     0<br/>deposit      0<br/>dtype: int64</span></pre><p id="b7e4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从结果来看，我们可以确信我们的数据没有丢失值，并且是完好的。如果您的数据中确实有缺失值，您可以通过插补来解决，或者根据您的具体情况完全删除该列。<a class="ae jd" href="https://www.kaggle.com/dansbecker/handling-missing-values" rel="noopener ugc nofollow" target="_blank">这里的</a>是一个关于如何处理数据集中缺失值的Kaggle课程的链接。</p><h2 id="ee7f" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">缩放数字数据</h2><p id="42c7" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">接下来，我们将缩放我们的数字数据，以避免可能严重影响我们模型的异常值。使用sklearn的<code class="du ms mt mu mk b">StandardScaler()</code>函数，我们可以缩放包含数字数据的每个列。将使用以下公式进行缩放:</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mv"><img src="../Images/4691dfbb97b780b681b179c3ba2afb5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mAdE4v5KxtFk6eIhodSLdw.png"/></div></div></figure><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mw"><img src="../Images/160e611eff45ebe1eeca57a6dafb26fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*98DpyW5357OVMtb60fZ_5A.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">我们的数据在缩放数字列后</figcaption></figure><h2 id="e5a7" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">编码分类数据</h2><p id="c326" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">与数字数据一样，我们也需要对我们的分类数据进行预处理，从单词到数字，使其更容易被计算机理解。为此，我们将使用sklearn提供的<code class="du ms mt mu mk b">OneHotEncoder()</code>。基本上，它将从以下内容转换一个分类列:</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es mx"><img src="../Images/e7228bda8c583d2c7067abaf972a8caf.png" data-original-src="https://miro.medium.com/v2/resize:fit:238/format:webp/1*XG_-v9TXVV5ICZXw394dtw.png"/></div></figure><p id="f049" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="my">…变成这样… </em></p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es mz"><img src="../Images/04e05b7341833de3c9c724cf7573a7bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:886/format:webp/1*TPnC2lS4BuhMQ-NuVhzgYg.png"/></div></figure><p id="3d75" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这个代码单元中，我们还将通过分别用1和0替换“是”和“否”来对标签列进行编码。我们可以通过对<code class="du ms mt mu mk b">deposit</code>列应用简单的lambda/in-line函数来做到这一点。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><h2 id="ec6d" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">为训练和测试拆分数据集</h2><p id="1512" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">为了完成我们的数据预处理步骤，我们将把数据分成两个数据集，训练和测试。在这种情况下，因为我们有足够的数据，我们将按照80:20的比例分割数据，分别用于训练和测试。这将导致我们的训练数据有8929行，测试数据有2233行。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><pre class="ko kp kq kr fd mj mk ml mm aw mn bi"><span id="0e99" class="kv jm hi mk b fi mo mp l mq mr">Shape of training feature: (8929, 50) <br/>Shape of testing feature: (2233, 50)<br/>Shape of training label: (8929,) <br/>Shape of testing feature: (2233,)</span></pre></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="f1a2" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">系统模型化</h1><p id="c3eb" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在确保我们的数据是好的和准备好的之后，我们可以继续建立我们的模型。在这本笔记本中，我们将尝试用不同的算法构建4个不同的模型。在这一步中，我们将使用sklearn设置的默认参数为每个算法创建一个基线模型，在构建完所有4个模型后，我们将对它们进行比较，看哪一个最适合我们的情况。</p><p id="9e0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了评估我们的模型，我们将使用混淆矩阵作为评估的基础。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es na"><img src="../Images/b3cf5dac3eba5d88779e8f4b2291b052.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_s1PEAEV9FNmYJWr.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">来源:<a class="ae jd" href="https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826" rel="noopener" target="_blank">你的多类机器学习模型的混淆矩阵(面向数据科学)</a></figcaption></figure><p id="71df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中:TP =真正；FP =假阳性；TN =真阴性；FN =假阴性。</p><p id="d491" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将使用以下6个指标来评估模型:</p><ul class=""><li id="a861" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">准确性:真实结果占检查案例总数的比例。</li></ul><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es nb"><img src="../Images/8084f5cbcb1c4a71d94734a42fdb988a.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*tMJ8tD9T-erbX07X7Eub_w.png"/></div></figure><ul class=""><li id="dc47" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">精度:用于计算所有预测为正的数据中有多少比例的数据实际上是正的。</li></ul><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es nc"><img src="../Images/d7a9dd237445dc4cb197c2d638977748.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*TXRhFjYrZ7sFDDJx0XgFdQ.png"/></div></figure><ul class=""><li id="f893" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">召回:用于计算有多少比例的实际阳性被正确分类。</li></ul><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es nd"><img src="../Images/edd1a79f4e5c71028255f1f273789ffd.png" data-original-src="https://miro.medium.com/v2/resize:fit:564/format:webp/1*lYWzRQFCczu7QdIWZeDyAA.png"/></div></figure><ul class=""><li id="c0d9" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">F1分数:介于0和1之间的数字，是精确度和召回率的调和平均值。</li></ul><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es ne"><img src="../Images/c581bb3ed5b4a123a058ad9049dca0c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/format:webp/1*DjZ3uqQOH3-calW-rZbF6g.png"/></div></figure><ul class=""><li id="22d0" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">Cohen Kappa评分:Cohen的Kappa评分衡量两个评分者之间的一致程度，他们各自将N个项目分为C个互斥的类别。</li></ul><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es nf"><img src="../Images/c97313fcf56ba897dff7a28ee4644b01.png" data-original-src="https://miro.medium.com/v2/resize:fit:428/format:webp/1*xp4THdGoun1WFN_5I0dyuw.png"/></div></figure><p id="7adb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中，Po是分配给任何样本的标签一致的经验概率(观察到的一致率)，Pe是当两个注释者随机分配标签时的预期一致。Pe是使用每个标注者在类标签上的经验先验来估计的。</p><ul class=""><li id="8ef8" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">曲线下面积(AUC):表示正类概率与负类概率的分离程度</li></ul><p id="a098" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种情况下，我们希望将重点放在我们模型的回忆值上，因为在我们的问题中，我们应该尽可能多地预测实际的正面结果。因为对<strong class="ih hj">实际上</strong>想要存款的客户的错误分类可能意味着机会/收入的损失。</p><p id="f150" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面我们将定义一个辅助函数来评估每个训练好的模型，并使用上面提到的指标，将分数保存到一个变量中。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><p id="9259" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我在本文前面说过的，我将尝试建立4种不同的模型:决策树、随机森林、朴素贝叶斯和K近邻。在我们开始之前，下面是每个算法的简单定义和它们是如何工作的。如果你不熟悉上述任何一种算法，在继续之前，你一定要试着阅读更多关于它们的深入解释。</p><h2 id="5b72" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">决策图表</h2><p id="70f1" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">决策树是一种树形图，用于确定行动方案。树的每个分支代表一个可能的决定、事件或反应。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es ng"><img src="../Images/4f66f5a30e3056537e48767e1ac45bf5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Ob7TKF89noXTDzeC.PNG"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">来源:Telkom数字人才孵化器—数据科学家模块5(分类)</figcaption></figure><p id="84ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">优势:</p><ul class=""><li id="b585" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">它可用于回归和分类任务，并且很容易查看它赋予输入要素的相对重要性。</li><li id="ac33" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">它也被认为是一种非常方便和易于使用的算法，因为它的默认超参数通常会产生良好的预测结果。</li></ul><p id="7497" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">缺点:</p><ul class=""><li id="0996" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">许多树会使算法变慢并且对于实时预测无效。更准确的预测需要更多的树，这导致模型更慢。</li><li id="a6a9" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">它是一个预测性的建模工具，而不是描述性的工具。</li></ul><h2 id="e20c" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">随机森林</h2><p id="08d7" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">随机森林或随机决策森林是一种通过在训练阶段构建多个决策树来运行的方法。大多数树的决定被选为最终决定。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es nh"><img src="../Images/6abb1fa8e6b3b0a041ef2bcd8181491f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*frGzV-L4pYzENgz9.PNG"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">来源:<a class="ae jd" href="https://www.simplilearn.com/tutorials/machine-learning-tutorial/random-forest-algorithm" rel="noopener ugc nofollow" target="_blank">随机森林算法(Simplilearn) </a></figcaption></figure><p id="2434" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">优势:</p><ul class=""><li id="daec" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">它可用于回归和分类任务，并且很容易查看它赋予输入要素的相对重要性。</li><li id="064a" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">它也被认为是一种非常方便和易于使用的算法，因为它的默认超参数通常会产生良好的预测结果。</li></ul><p id="a6e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">缺点:</p><ul class=""><li id="2d1d" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">许多树会使算法变慢并且对于实时预测无效。更准确的预测需要更多的树，这导致模型更慢。</li><li id="3054" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">它是一个预测性的建模工具，而不是描述性的工具。</li></ul><h2 id="cd6b" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated"><strong class="ak">朴素贝叶斯</strong></h2><p id="f33c" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">朴素贝叶斯是一种构造分类器的简单技术:将类别标签分配给问题实例的模型，表示为特征值的向量，其中类别标签是从一些有限集中提取的。不存在用于训练这种分类器的单一算法，而是基于共同原则的一系列算法:所有朴素贝叶斯分类器假定给定类变量，特定特征的值独立于任何其他特征的值。下面是贝叶斯定理公式:</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es ni"><img src="../Images/91c65dc83c632b65faa0b045b2440df9.png" data-original-src="https://miro.medium.com/v2/resize:fit:558/format:webp/1*PwPAVSt9hL5Ifw58C_FEoA.png"/></div></figure><p id="318a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，假设:</p><ul class=""><li id="eb1e" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">医生知道50%的情况下脑膜炎会导致颈部僵硬</li><li id="f72f" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">任何患者先前患脑膜炎的概率是1/50，000</li><li id="6c73" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">任何患者颈部僵硬的先验概率为1/20</li></ul><p id="e471" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么颈部僵硬的患者同时患有脑膜炎的概率是:</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es nj"><img src="../Images/48a21405cf0252387a4655ecdee43adc.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*a2btEw6XgELzkkT7bTCn_Q.png"/></div></figure><h2 id="bf3f" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">k-最近邻</h2><p id="f112" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">k-最近邻(KNN)通过从训练数据中找到k个最近邻来对新数据进行分类，然后根据其大多数邻居来决定类别。例如，在下图中，k=3时，它的大多数邻居被分类为B，但当k=7时，大多数将变为a。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es nk"><img src="../Images/e773547e7db8a82e0fd617f2d00a4b6e.png" data-original-src="https://miro.medium.com/v2/resize:fit:694/0*-kJQaBJmo0326Heq.PNG"/></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">来源:Telkom数字人才孵化器—数据科学家模块5(分类)</figcaption></figure><p id="4b9d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">优势:</p><ul class=""><li id="3d4e" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">易于实施的简单技术</li><li id="597b" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">建筑模型很便宜</li><li id="e9e8" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">极其灵活的分类方案</li></ul><p id="df0b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">缺点:</p><ul class=""><li id="ade5" class="lj lk hi ih b ii ij im in iq ll iu lm iy ln jc lx lp lq lr bi translated">对未知记录进行分类相对昂贵</li><li id="b270" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">需要计算k个最近邻的距离</li><li id="6b9a" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">计算量大，尤其是当训练集变大时</li><li id="1b48" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lx lp lq lr bi translated">噪声或不相关特征的存在会严重降低精确度</li></ul><h2 id="7201" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">建筑模型</h2><p id="bf6b" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在了解了每个模型的工作原理之后，让我们尝试使用之前的训练数据集来训练我们的模型。下面是示例代码，使用决策树来拟合我们的模型，并使用我们之前创建的帮助函数来评估模型。每个算法的完整代码可以在笔记本<a class="ae jd" href="https://colab.research.google.com/github/rafiag/DTI2020/blob/main/004_Classification_Bank_Marketing_Dataset_(Assignment).ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><pre class="ko kp kq kr fd mj mk ml mm aw mn bi"><span id="1896" class="kv jm hi mk b fi mo mp l mq mr">Accuracy: 0.6336766681594268<br/>Precision: 0.6215953307392996<br/>Recall: 0.598314606741573<br/>F1 Score: 0.6097328244274809<br/>Cohens Kappa Score: 0.2648219403033133<br/>Area Under Curve: 0.6322045136712157</span><span id="52ba" class="kv jm hi mk b fi nl mp l mq mr">Confusion Matrix:<br/>[[776 389]<br/>[429 639]]</span></pre><h2 id="d77d" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">模型比较</h2><p id="513e" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在构建了所有的模型之后，我们现在可以比较每个模型的表现了。为此，我们将创建两个图表，第一个是分组条形图，显示我们模型的准确度、精确度、召回率、f1值和kappa值，第二个是折线图，显示我们所有模型的AUC。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es nm"><img src="../Images/209f62c2234a79984162581ba04eac08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7dbqO_D7y3NInoIFD8f-Eg.png"/></div></div></figure><p id="b290" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的图中我们可以看到，我们的随机森林模型在我们评估的6个指标中的5个指标上领先于其他模型，除了精度。所以我们可以假设随机森林是解决我们问题的正确选择。</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="c1c5" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">模型优化</h1><p id="e318" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在本笔记本的下一部分，我们将通过调整scikit-learn库中的hyper参数来优化我们的RandomForest模型。找到最佳参数后，我们将通过与之前的基线模型进行比较来评估我们的新模型。</p><h2 id="840d" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">使用GridSearchCV调整超参数</h2><p id="0d92" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">我们将使用sklearn的<code class="du ms mt mu mk b">GridSearchCV</code>功能来为我们的模型找到最佳参数。我们将提供我们的基线模型(名为<code class="du ms mt mu mk b">rf_grids</code>)、评分方法(在我们的例子中，我们将使用前面解释过的recall)，以及我们希望用我们的模型尝试的各种参数值。然后，<code class="du ms mt mu mk b">GridSearchCV</code>函数将遍历每个参数组合，找到最佳评分参数。</p><p id="ee31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该功能还允许我们使用交叉验证来训练我们的模型，其中在每次迭代中，我们的数据将被分成5个(数量可以从参数中调整)折叠。然后，模型将在4/5折叠的数据上进行训练，留下最终折叠作为验证数据，该过程将重复5次，直到我们的所有折叠都被用作验证数据。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es nn"><img src="../Images/e07fc65b59824f83ea9a6959fadf07e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1Hm4B-eM4R8ARRIm.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">来源:<a class="ae jd" href="https://www.kaggle.com/alexisbcook/cross-validation" rel="noopener ugc nofollow" target="_blank">交叉验证(Kaggle) </a></figcaption></figure><p id="633b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要查看哪个参数组合效果最好，我们可以从网格搜索对象中访问<code class="du ms mt mu mk b">best_params_</code>属性。</p><p id="7ed1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="my">注意:提供的组合越多，过程需要的时间就越长。或者，您也可以尝试</em> <code class="du ms mt mu mk b"><em class="my">RandomizedSearchCV</em></code> <em class="my">来随机选择指定数量的参数，这样可以加快运行时间。</em></p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><pre class="ko kp kq kr fd mj mk ml mm aw mn bi"><span id="8f73" class="kv jm hi mk b fi mo mp l mq mr">{'max_depth': 50,<br/> 'max_features': 2,<br/> 'min_samples_leaf': 3,<br/> 'min_samples_split': 8,<br/> 'n_estimators': 100}</span></pre><h2 id="526b" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">评估优化模型</h2><p id="c611" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">找到模型的最佳参数后，我们可以访问GridSearchCV对象的<code class="du ms mt mu mk b">best_estimator_</code>属性，将优化后的模型保存到名为<code class="du ms mt mu mk b">best_grid</code>的变量中。在下一步中，我们将使用助手函数计算6个评估指标，并将其与基础模型进行比较。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><pre class="ko kp kq kr fd mj mk ml mm aw mn bi"><span id="fa7b" class="kv jm hi mk b fi mo mp l mq mr">Accuracy: 0.7174205105239588<br/>Precision: 0.7635705669481303<br/>Recall: 0.5926966292134831<br/>F1 Score: 0.6673695308381655<br/>Cohens Kappa Score: 0.42844782511519086<br/>Area Under Curve: 0.7785737249039559</span><span id="4cca" class="kv jm hi mk b fi nl mp l mq mr">Confusion Matrix:<br/>[[969 196]<br/>[435 633]]</span></pre><h2 id="0835" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">模型比较</h2><p id="a1bc" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">下面的代码将绘制与之前相同的图，只是使用了我们最初的随机森林模型和它的优化版本。它还将打印每个评估指标的变化，以帮助我们了解我们的优化模型是否比原始模型工作得更好。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es no"><img src="../Images/03efc03f962073c76ad85bdca8e385e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gFWZtMv_sxjWPYTlsjymRQ.png"/></div></div></figure><pre class="ko kp kq kr fd mj mk ml mm aw mn bi"><span id="f5fd" class="kv jm hi mk b fi mo mp l mq mr">Change of 0.37% on accuracy.<br/>Change of 2.79% on precision.<br/>Change of -3.89% on recall.<br/>Change of -0.96% on F1 score.<br/>Change of 0.95% on Kappa score.<br/>Change of 0.84% on AUC.</span></pre><p id="6990" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">结果表明，优化后的模型性能比原始模型稍好。优化后的模型在6个指标中有4个指标有所提高，但在其他指标上表现较差，尤其是召回率下降了-3.89%。因为我们希望专注于预测尽可能多的实际正值，所以我们应该坚持使用我们的原始预测模型，因为它具有更高的召回分数。</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="58fa" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">输出</h1><p id="e32b" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">我们有了模型，接下来呢？作为数据科学家，能够开发具有良好可重用性的模型是非常重要的。在这最后一部分，我将解释如何基于新数据创建预测，以及如何使用<code class="du ms mt mu mk b">joblib </code>保存(和加载)您的模型，这样您就可以在生产中使用它，或者保存它供以后使用，而不必重复整个过程。</p><h2 id="0499" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">做预测</h2><p id="cd38" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">在此步骤中，我们将使用随机森林模型预测原始数据集中所有行的预期结果，然后将其保存到csv文件中，以便于将来访问。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es np"><img src="../Images/ab25810577a485e2a8ae4170a009d4ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_RQtMeMJ4iEDyAvhQ1mUTg.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">具有预测结果的新数据集</figcaption></figure><h2 id="35b0" class="kv jm hi bd jn kw kx ky jr kz la lb jv iq lc ld jz iu le lf kd iy lg lh kh li bi translated">保存模型</h2><p id="22e3" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">我们可以保存我们的模型，以便进一步的模型重用。然后可以将该模型加载到另一台机器上进行新的预测，而无需再次进行整个训练过程。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="e3d1" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">结论</h1><p id="30f4" class="pw-post-body-paragraph if ig hi ih b ii kj ik il im kk io ip iq kl is it iu km iw ix iy kn ja jb jc hb bi translated">对于一个简单的模型，我们可以看到我们的模型在分类数据方面做得很好。但是我们的模型仍然有一些弱点，特别是在召回指标上，我们只得到大约60%。这意味着我们的模型只能检测到60%的潜在客户，而漏掉另外40%。使用<code class="du ms mt mu mk b">GridSearchCV</code>优化模型后，结果并没有太大的不同，这意味着我们已经达到了这个模型的极限。为了提高我们的性能，我们可以尝试研究另一种算法，如<code class="du ms mt mu mk b">GradientBoostingClassifier</code>。</p><p id="fb94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">感谢您的阅读，希望对您有所帮助！如果你有任何建议或问题，请随时留下评论(鼓掌肯定会被赞赏！)</p></div><div class="ab cl je jf gp jg" role="separator"><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj jk"/><span class="jh bw bk ji jj"/></div><div class="hb hc hd he hf"><h1 id="6fb1" class="jl jm hi bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">参考</h1><ol class=""><li id="32df" class="lj lk hi ih b ii kj im kk iq nq iu nr iy ns jc lo lp lq lr bi translated">Telkom数字人才孵化器—数据科学家模块5(分类)</li><li id="a78a" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated"><a class="ae jd" href="https://scikit-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"> Scikit-learn文档</a></li><li id="e93d" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated"><a class="ae jd" href="https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226" rel="noopener" target="_blank">每个数据科学家都必须知道的5个分类评估指标</a></li><li id="d3c3" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated"><a class="ae jd" href="https://python-graph-gallery.com/11-grouped-barplot/" rel="noopener ugc nofollow" target="_blank">Python图形库—分组条形图</a></li><li id="10f8" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated"><a class="ae jd" href="https://towardsdatascience.com/confusion-matrix-for-your-multi-class-machine-learning-model-ff9aa3bf7826" rel="noopener" target="_blank">你的多类机器学习模型的混淆矩阵</a></li><li id="f2e5" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated"><a class="ae jd" href="https://www.simplilearn.com/tutorials/machine-learning-tutorial/random-forest-algorithm" rel="noopener ugc nofollow" target="_blank">随机森林算法</a></li><li id="31cd" class="lj lk hi ih b ii ls im lt iq lu iu lv iy lw jc lo lp lq lr bi translated"><a class="ae jd" href="https://www.kaggle.com/alexisbcook/cross-validation" rel="noopener ugc nofollow" target="_blank">交叉验证</a></li></ol></div></div>    
</body>
</html>