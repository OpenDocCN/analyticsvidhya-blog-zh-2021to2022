<html>
<head>
<title>Linear Regression for Data Science — With Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学的线性回归—使用Python</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/linear-regression-for-data-science-with-python-eeb3407abf9d?source=collection_archive---------21-----------------------#2021-05-28">https://medium.com/analytics-vidhya/linear-regression-for-data-science-with-python-eeb3407abf9d?source=collection_archive---------21-----------------------#2021-05-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="8965" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">线性回归是数据科学中数据驱动的决策过程的基石。</p><p id="18cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jc translated">数据科学家和统计学家共同承担一项任务，即根据一个或一组变量(称为预测器)来预测一个输出变量(称为目标变量)。统计学和数据科学之间最紧密的联系莫过于预测领域。线性回归被证明是提取目标输出和预测值之间关联的有力工具。使用线性回归，我们的目的不仅在于量化关系的强度，还在于量化这种关系的性质。换句话说，通过使用线性回归，我们可以预测一组给定预测因子的未知输出。在大数据领域，线性回归既用于预测，也用于解释(剖析)。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es jm"><img src="../Images/56b9dd73c3de05efef19af7a018692fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Isxn4wZqzy8yNaZfeKPnCA.png"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">预测(<a class="ae kc" href="https://www.amazon.com/Prediction-Machines-Economics-Artificial-Intelligence/dp/1633695670" rel="noopener ugc nofollow" target="_blank">来源</a>)</figcaption></figure><p id="96b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们旨在阐明线性回归及其在数据科学领域的应用。为了展示实用性，我们采用python语言对给定的数据集进行线性回归。用于此目的的数据集是<em class="jl">医疗费用个人数据集。</em>你可以从Kaggle网站找到数据集，<a class="ae kc" href="https://www.kaggle.com/mirichoi0218/insurance" rel="noopener ugc nofollow" target="_blank">这里</a>。为了更好地解释数据集，它由六个不同的预测值和一个名为<code class="du kd ke kf kg b">charges</code>的目标结果组成。这是每个人需要支付的医疗保险金额。每一行都包含贡献者端的数据。<code class="du kd ke kf kg b">age</code>、<code class="du kd ke kf kg b">sex</code>和<code class="du kd ke kf kg b">bmi</code>(身体质量函数)不言自明。<code class="du kd ke kf kg b">children</code>是每个贡献者所拥有的家属人数。最后，<code class="du kd ke kf kg b">smoker</code>和<code class="du kd ke kf kg b">region</code>分别表示吸烟状态和居住地点。下图显示了前五条记录的数据快照。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es kh"><img src="../Images/757bacf000a8f928ddc4f73542a9eb54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_9H0j4VPRg5h_o-ac1P4BQ.png"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">数据集的前五行</figcaption></figure><p id="e432" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">预测器有<code class="du kd ke kf kg b">age</code>、<code class="du kd ke kf kg b">sex</code>、<code class="du kd ke kf kg b">bmi</code>、<code class="du kd ke kf kg b">children</code>、<code class="du kd ke kf kg b">smoker</code>和<code class="du kd ke kf kg b">region</code>。目标值是费用。预测任务的目的是根据预测值预测费用。你可以找到一些连续型和一些离散型或分类型的预测因子。目标变量是连续类型。这就是为什么我们试图利用线性回归来预测费用。在电荷是分类类型的情况下，我们应该使用分类算法来预测目标值。</p><h1 id="096a" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">简单线性回归</h1><p id="db87" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">我们从简单的线性回归开始。简单线性回归估计如果单个预测值改变一定的量，目标变量将改变多少。简单线性回归的公式如下</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ll"><img src="../Images/e68bccf87b1efbaa626113101d0d4289.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*uaFrT3ty71TQy4qs0DpCHw.png"/></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">简单线性回归</figcaption></figure><p id="759a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">符号“<em class="jl"> b^ </em> 0”称为<em class="jl">截距</em>(或常数)，符号“<em class="jl"> b^ </em> 1”为<em class="jl"> X </em>的<em class="jl">斜率</em>。符号“Y^i”是估计值，称为拟合值。真实值“Yi”和拟合值“Y^i”之间的差异称为残差或预测误差。</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es lm"><img src="../Images/e5dc01fd89adfc355e23815a5e420dfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*mn2b9EpPcngkYw-SW-YF4w.png"/></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">残差</figcaption></figure><p id="b47e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">检查残差揭示了模型评估中的重要措施。下面将介绍用于简单线性回归的python代码。</p><pre class="jn jo jp jq fd ln kg lo lp aw lq bi"><span id="0fed" class="lr kj hh kg b fi ls lt l lu lv">#Simple Linear regression of charges V.S. bmi</span><span id="ef2b" class="lr kj hh kg b fi lw lt l lu lv">predictors = ['bmi']<br/>outcome = 'charges'</span><span id="e1cc" class="lr kj hh kg b fi lw lt l lu lv">model = LinearRegression()<br/>model.fit(df[predictors], df[outcome])</span><span id="9c8e" class="lr kj hh kg b fi lw lt l lu lv">print(f'Intercept: {model.intercept_:.3f}')<br/>print(f'Coefficient Exposure: {model.coef_[0]:.3f}')</span><span id="24b3" class="lr kj hh kg b fi lw lt l lu lv">fitted = model.predict(df[predictors])<br/>residuals = df[outcome] - fitted</span><span id="6143" class="lr kj hh kg b fi lw lt l lu lv">ax = df.plot.scatter(x='bmi', y='charges', figsize=(15, 10))<br/>ax.plot(df.bmi, fitted, linewidth=5, color='k', label=f'simple linear regression: charges = {model.intercept_:.3f} + {model.coef_[0]:.3f}bmi')<br/>for x, yactual, yfitted in zip(df.bmi, df.charges, fitted): <br/>    ax.plot((x, x), (yactual, yfitted), '--', color='C1')</span><span id="6577" class="lr kj hh kg b fi lw lt l lu lv">plt.tight_layout()<br/>plt.legend()<br/>plt.show()</span></pre><figure class="jn jo jp jq fd jr er es paragraph-image"><div role="button" tabindex="0" class="js jt di ju bf jv"><div class="er es lx"><img src="../Images/34e9b1ca8dbe166d9fc1bb3b11246ea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4jgGAfT6MhQVBmjiQzq6qg.png"/></div></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">简单线性回归</figcaption></figure><p id="d334" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在简单的线性回归中，要看电荷和<code class="du kd ke kf kg b">bmi</code>的关系是什么，可以看到截距分别是1193，斜率是394。橙色垂直虚线表示残差，即回归线建议值与实际值之间的差异。通过拟合直线，我们实际上试图最小化这些差异的总和。这就是所谓的最小二乘法。最小二乘简单地定义为残差平方和。采用平方而不是简单差分的原因是不同符号的不同残差不会相互抵消。最后，平方使得理论上推导拟合线比例如差值的绝对值的情况更容易。在解释模型时，我们可以说<code class="du kd ke kf kg b">bmi</code>增加一个单位导致费用增加394个单位。当考虑<code class="du kd ke kf kg b">bmi</code>值时，截距实际上是满足电荷平均值的调整。否则，当<code class="du kd ke kf kg b">bmi</code>为零时，说电荷值是没有意义的，因为<code class="du kd ke kf kg b">bmi</code> =0是没有意义的。显然，我们可以将同样的方法扩展到所有预测指标，以分析与目标结果的关系。</p><h1 id="6fd8" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">多元线性回归</h1><p id="caf9" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">与仅使用一个单一预测值的简单线性回归相比，在多元线性回归中，多个预测值可用于预测目标输出。因此，不是一个单一的系数，我们将有多个系数，每个预测值一个。多元线性回归的一般形式如下所示</p><figure class="jn jo jp jq fd jr er es paragraph-image"><div class="er es ly"><img src="../Images/8700227f793a4fa6342e475957914fda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*3kizu430kCXPSOm9SFFGBA.png"/></div><figcaption class="jy jz et er es ka kb bd b be z dx translated">多元线性回归</figcaption></figure><p id="b556" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中“p”表示预测值的总数,“e”是残差。在深入多元回归之前，我们需要处理分类预测因子，也就是因子变量。我们需要找到一种方法来转换因子变量，以便在多元回归中得到理解。<em class="jl">因子</em>变量，也称为<em class="jl">分类</em>变量，取有限数量的离散值。二元(是/否)变量，也称为<em class="jl">指标</em>变量，是因子变量的特例。例如，<em class="jl">性别</em>和<em class="jl">吸烟者</em>的预测因子都是二元变量。最常见的方法是将一个变量转换成一组二进制的虚拟变量。其他形式的编码方法有</p><ul class=""><li id="580b" class="lz ma hh ig b ih ii il im ip mb it mc ix md jb me mf mg mh bi translated"><strong class="ig hi">参考编码</strong>:统计学家使用的最常见的编码类型，其中某一因素的某一水平用作参考，其他因素与该水平进行比较[1]。</li><li id="01f7" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated"><strong class="ig hi">一个热编码器:</strong>在这种类型的编码器中，所有因子级别都被保留。虽然对某些机器学习算法有用，但这种方法不适用于多元线性回归。</li><li id="3cf2" class="lz ma hh ig b ih mi il mj ip mk it ml ix mm jb me mf mg mh bi translated"><strong class="ig hi">偏差编码:</strong>一种编码类型，将每个水平与总体平均值进行比较，而不是与参考水平进行比较。</li></ul><p id="bb01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在使用任何类型的编码时，尤其是一次性编码，我们应该小心地将所有级别的因素变量包含在编码中。包含所有级别的因子变量会导致被称为<strong class="ig hi">多重共线性</strong>的不利影响，从而导致模型中的错误解释。</p></div><div class="ab cl mn mo go mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ha hb hc hd he"><blockquote class="mu mv mw"><p id="33a6" class="ie if jl ig b ih ii ij ik il im in io mx iq ir is my iu iv iw mz iy iz ja jb ha bi translated">在回归设置中，具有<em class="hh"> P </em>不同水平的因子变量通常由只有<em class="hh"> P- </em> 1列的矩阵表示。这是因为回归模型通常包含截距项。使用截距，一旦定义了<em class="hh"> P- </em> 1二进制文件的值，那么<em class="hh"> P- </em> th的值就是已知的，可以认为是多余的。添加第<em class="hh"> P- </em>列将导致多重共线性错误[1]。</p></blockquote></div><div class="ab cl mn mo go mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="ha hb hc hd he"><p id="3afb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为此，在python实现中，我们将应用这个建议。在某些情况下，应用编码(如独热编码)可能会生成如此多的伪变量。在这种情况下，您应该决定包含所有级别的因子变量是否有帮助。您可以使用一种方法，例如根据标准(如残差)将不同的级别组合成一个级别。对于顺序起关键作用的有序因子变量，将因子变量转换为数值变量将保留包含在顺序中的信息，如果将其转换为因子，这些信息将会丢失。例如，对于具有诸如<em class="jl">小</em>、<em class="jl">中</em>和<em class="jl">大</em>的值的有序因子变量，这些值可以被编码为1、2、3或1、3、5，这取决于差异的强度。</p><p id="0b81" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于我们的保险数据集的多元线性回归，python实现如下:</p><pre class="jn jo jp jq fd ln kg lo lp aw lq bi"><span id="9bdb" class="lr kj hh kg b fi ls lt l lu lv">predictors = ['age', 'sex', 'bmi', <br/>              'children', 'smoker', 'region']<br/>outcome = 'charges'<br/>df_encoded = pd.get_dummies(df[predictors], drop_first=True)</span><span id="a81a" class="lr kj hh kg b fi lw lt l lu lv">df_lm_factor = LinearRegression()<br/>df_lm_factor.fit(df_encoded, df[outcome])</span><span id="5714" class="lr kj hh kg b fi lw lt l lu lv">print(f'Intercept: {df_lm_factor.intercept_:.3f}') <br/>print('Coefficients:')</span><span id="ed0e" class="lr kj hh kg b fi lw lt l lu lv">for name, coef in zip(X.columns, df_lm_factor.coef_):<br/>    print(f' {name}: {coef}')</span></pre><p id="051f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出将是:</p><pre class="jn jo jp jq fd ln kg lo lp aw lq bi"><span id="1a01" class="lr kj hh kg b fi ls lt l lu lv">[output]:<br/>Intercept: -11938.539<br/>Coefficients:<br/> age: 256.85635253734864<br/> bmi: 339.1934536108373<br/> children: 475.5005451491269<br/> sex_male: -131.3143593951132<br/> smoker_yes: 23848.534541912835<br/> region_northwest: -352.9638994246546<br/> region_southeast: -1035.0220493878253<br/> region_southwest: -960.0509913008365</span></pre><p id="aa8e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">解释多元线性回归不像一元线性回归那样简单明了，尤其是因子变量。基于上述代码的输出，系数是预测器与目标的关系的指示。例如，<code class="du kd ke kf kg b"><em class="jl">age</em></code> <em class="jl"> </em>系数为257表明年龄增加一个单位，费用增加257个单位。对于因子变量，应解释为与参考水平相比。例如,<code class="du kd ke kf kg b">sex_male</code>系数为-131，表示男性对目标产量的影响比女性低131。同样，对于<code class="du kd ke kf kg b">smoker_yes</code>来说，吸烟者=是的效果比不吸烟者高23848倍。</p><p id="9749" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后但同样重要的是，回归方程本身并不能证明因果关系的方向。这是从更广泛的理解，如领域知识，引导我们选择因果关系的正确方向。</p><h1 id="2f1e" class="ki kj hh bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">参考</h1><p id="1ad3" class="pw-post-body-paragraph ie if hh ig b ih lg ij ik il lh in io ip li ir is it lj iv iw ix lk iz ja jb ha bi translated">[1]布鲁斯、彼得、安德鲁·布鲁斯和彼得·格德克。<em class="jl">数据科学家实用统计学:使用R和Python的50多个基本概念</em>。奥莱利媒体，2020。</p></div></div>    
</body>
</html>