<html>
<head>
<title>Code Diaries: Text Prediction (n-grams)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">代码日记:文本预测(n-grams)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/code-diaries-text-prediction-n-grams-e3aa4d5325a2?source=collection_archive---------2-----------------------#2021-04-16">https://medium.com/analytics-vidhya/code-diaries-text-prediction-n-grams-e3aa4d5325a2?source=collection_archive---------2-----------------------#2021-04-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2b8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自然语言处理，也称为NLP，是计算机科学的一个子领域，它允许计算机理解人类语言。当你发短信时，你会使用键盘上方的建议词吗？那要感谢NLP！</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/9e33cf6cfe374632e5402b61d464f76f.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*hSxTtizQ4r6u86tswcGfIA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated"><a class="ae jo" href="https://www.iphonefaq.org/archives/973893" rel="noopener ugc nofollow" target="_blank">https://www.iphonefaq.org/archives/973893</a></figcaption></figure><p id="980d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">NLP无处不在:信息提取、情感分析、机器翻译(例如Google translate)、垃圾邮件检测、自动填充和聊天机器人等等。</p><blockquote class="jp"><p id="c2e8" class="jq jr hh bd js jt ju jv jw jx jy jb dx translated">本文将简要介绍NLP，并描述我使用n-gram语言模型构建文本预测程序的过程。</p></blockquote><p id="f9b3" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated">人类语言是不断进化的，有许多细微差别/歧义。</p><p id="1dd8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">"那个女人用伞打了一个男人。"可以有两种解释:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ke"><img src="../Images/70d3791d0a252bd484937da704c96428.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*-43iENu4t03cvjE3j6qf3g.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">感谢我的艺术技巧</figcaption></figure><p id="db2e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的句子被称为<strong class="ig hi">崩溃开花</strong>，一个语义模糊的句子。使NLP变得困难的其他因素包括但不限于非标准英语，例如Twitter上的推文以及随着社交媒体发展起来的“unfriend”和“unfollow”等新词。</p><p id="2f57" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">NLP的基础是一个<strong class="ig hi">语言模型</strong>，它计算一个句子或单词序列的概率。</p><p id="f37a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">比如“猫在睡觉”这句话比“猫很友好”(至少在我看来)更容易出现。开个玩笑，再来一个:“猫在睡觉”或者“猫在跳舞”。我想我们大多数人都会同意这一点；)</p><p id="159e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些句子的概率可以表示为:</p><blockquote class="jp"><p id="b9b9" class="jq jr hh bd js jt ju jv jw jx jy jb dx translated">P("猫在<em class="kf">睡觉"</em> ) &gt; P("猫在<em class="kf">跳舞</em>")</p></blockquote><p id="e4ad" class="pw-post-body-paragraph ie if hh ig b ih jz ij ik il ka in io ip kb ir is it kc iv iw ix kd iz ja jb ha bi translated">其中，基于我们的常识，句子“猫在睡觉”的概率P大于句子“猫在跳舞”。</p><p id="a517" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个相同的例子可以应用于制作一个<strong class="ig hi"> n-gram语言模型</strong>，该模型预测来自训练语料库的N个标记(单词)序列的概率。</p><p id="5f65" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我用三元语法语言模型训练了我的文本预测程序。</p><pre class="jd je jf jg fd kg kh ki kj aw kk bi"><span id="23f1" class="kl km hh kh b fi kn ko l kp kq"><a class="ae jo" href="https://github.com/jadessechan/Text-Prediction.git" rel="noopener ugc nofollow" target="_blank">https://github.com/jadessechan/Text-Prediction.git</a></span></pre><p id="f8b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我使用了<strong class="ig hi">马尔可夫假设</strong>，其中每个单词的出现基于前两个单词的出现(对于三元模型)。</p><p id="ff83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Python的<strong class="ig hi"> re库</strong>是一个很好的工具，用于在训练语言模型之前对语料库进行正则表达式解析。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kr ks l"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">我如何使用re和unicode库预处理我的语料库</figcaption></figure><p id="5a94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对文本进行预处理对于删除不必要的字符至关重要，比如数字、标点符号和大写字母。根据您的NLP任务，您可能需要删除停用词(例如，冠词“a”、“the”等)。NLTK库有一个您可以使用的列表。但是，我没有删除我的语料库中的停用词，因为这将使文本预测输出更加连贯。</p><div class="jd je jf jg fd ab cb"><figure class="kt jh ku kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><img src="../Images/579ec9b87a8dc03ecd38448b6b63073a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1242/format:webp/1*vTQJpYeR75vy36ygcTuaHA.png"/></div></figure><figure class="kt jh ld kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><img src="../Images/19ff91eb4e07aff07dea2f3fe352e224.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*J9aCOOrT-bIpEmk1ipHk2A.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx le di lf lg translated"><strong class="bd lh">左</strong>:未删除停用词。<strong class="bd lh">右:</strong>停用词删除</figcaption></figure></div><p id="0c7c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在文本可以进行标记化了！<strong class="ig hi"> NLTK库</strong>提供了大量的函数来帮助各种NLP过程。在我的例子中，我使用<em class="li"> ngrams() </em>将我的文本分割成三元模型</p><pre class="jd je jf jg fd kg kh ki kj aw kk bi"><span id="7f4a" class="kl km hh kh b fi kn ko l kp kq">trigrams = list(nltk.ngrams(text, 3, pad_left=True, pad_right=True, left_pad_symbol='&lt;s&gt;', right_pad_symbol='&lt;/s&gt;'))</span></pre><blockquote class="lj lk ll"><p id="a5e5" class="ie if li ig b ih ii ij ik il im in io lm iq ir is ln iu iv iw lo iy iz ja jb ha bi translated">pad_left和pad_right标记一个句子的开始和结束。</p><p id="bdf1" class="ie if li ig b ih ii ij ik il im in io lm iq ir is ln iu iv iw lo iy iz ja jb ha bi translated"><strong class="ig hi"> &lt; s &gt; </strong>我热爱计算机科学！<strong class="ig hi">&lt;/s&gt;T11】</strong></p><p id="9bf9" class="ie if li ig b ih ii ij ik il im in io lm iq ir is ln iu iv iw lo iy iz ja jb ha bi translated">三元模型是一个句子的三个单词或记号的序列。</p><p id="4613" class="ie if li ig b ih ii ij ik il im in io lm iq ir is ln iu iv iw lo iy iz ja jb ha bi translated">“<s>我爱”，“计算机科学</s>”</p></blockquote><p id="e0ab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">填充句子有助于表明某个单词出现在句子开头或结尾的可能性有多大。</p><p id="042e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当处理大型数据集时，比如《爱丽丝梦游仙境》语料库，我进行了<strong class="ig hi">探索性数据分析，</strong>这样我就可以总结出我的文本的主要特征。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kr ks l"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">关于语料库的n元语法信息</figcaption></figure><p id="057d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，我使用NLTK的<em class="li"> FreqDist() </em>来获得我的三元模型的频率分布，并将它们可视化在一个线图上。然后我打印了前5个三元模型。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lp"><img src="../Images/012262afaa1412a7c7b91ece85cfdb35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E5b8s_rCgJwo4XQxob00ew.png"/></div></div></figure><p id="fd6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，虽然NLTK库非常有用，但是文档理解起来有点困难。我经常发现自己花更多的时间试图理解NLTK，而不是编码。这发生在我使用NLTK的语言模型接口来寻找<strong class="ig hi">最大似然估计</strong>的时候，这实质上是寻找给定模型的概率分布。我最终做了一个条件频率分布，因为我理解NLTK用于实现它们的底层概念和数据结构。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kr ks l"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">计算前面有两个单词(w1和w2)的单词(w3)的概率</figcaption></figure><p id="2714" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">默认字典是<em class="li"> ConditionaFreqDist() </em>的底层数据结构，并计算共现和键值对的频率。它存储三元模型中前两个单词(w1，w2)之后的一个单词(w3)的计数。如果w3的计数不存在，则使用默认值。默认字典类似于Java中带有GetOrDefault()的映射。</p><p id="3d9e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了让我的文本预测程序模拟真实世界的场景，我根据一个<strong class="ig hi">加权随机概率</strong>将预测附加到用户的输入中，其中每个预测的单词根据其频率进行加权，并根据其相对权重随机选择。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="kr ks l"/></div></figure><p id="3c31" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">就是这样！用户可以决定继续向初始短语添加单词或终止程序。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es lq"><img src="../Images/82261ffce75bb9233c4ef3597ae7673e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*obXZ_rjMYeLC_d039F7SNA.png"/></div></div></figure><p id="42d7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">文本预测只是NLP如何应用于现实场景的一个小例子。其他用例包括情感分析、垃圾邮件检测和聊天机器人！现在，许多NLP任务是用机器学习技术实现的，但是使用统计方法/模型是理解基础计算的完美基础。概率、语言学和计算机科学的世界走到了一起，形成了这个不断发展、引人入胜的自然语言处理主题！</p></div></div>    
</body>
</html>