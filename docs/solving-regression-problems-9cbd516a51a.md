# è§£å†³å›å½’é—®é¢˜

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/solving-regression-problems-9cbd516a51a?source=collection_archive---------14----------------------->

![](img/a3c12037d484432767f29a4918ef3ea6.png)

ç”±[è‚¯å¾·å°”](https://unsplash.com/@hikendal?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„çš„ç…§ç‰‡

```
Dataset Used: [https://www.kaggle.com/mirichoi0218/insurance](https://www.kaggle.com/mirichoi0218/insurance)
My Noteboo[k: https://www.kaggle.com/tanishsawant2002/regression-85-score](https://www.kaggle.com/tanishsawant2002/regression-85-score)
```

æ•°æ®é›†æè¿°:(æ‘˜è‡ª Kaggle)

# è¯­å¢ƒ

Brett Lantz çš„ Machine Learning with R æ˜¯ä¸€æœ¬ä»‹ç»ä½¿ç”¨ R è¿›è¡Œæœºå™¨å­¦ä¹ çš„ä¹¦ï¼Œæ®æˆ‘æ‰€çŸ¥ï¼ŒPackt Publishing ä¸ä¼šåœ¨ç½‘ä¸Šæä¾›å…¶æ•°æ®é›†ï¼Œé™¤éä½ è´­ä¹°è¿™æœ¬ä¹¦å¹¶åˆ›å»ºä¸€ä¸ªç”¨æˆ·å¸æˆ·ï¼Œå¦‚æœä½ ä»å›¾ä¹¦é¦†å€Ÿé˜…è¿™æœ¬ä¹¦æˆ–ä»æœ‹å‹é‚£é‡Œå€Ÿä¹¦ï¼Œè¿™å¯èƒ½ä¼šæ˜¯ä¸€ä¸ªé—®é¢˜ã€‚æ‰€æœ‰è¿™äº›æ•°æ®é›†éƒ½åœ¨å…¬å…±é¢†åŸŸï¼Œä½†åªéœ€è¦ä¸€äº›æ¸…ç†å’Œé‡æ–°ç¼–ç ï¼Œä»¥ç¬¦åˆä¹¦ä¸­çš„æ ¼å¼ã€‚

# å†…å®¹

åˆ—

*   å¹´é¾„:ä¸»è¦å—ç›Šäººçš„å¹´é¾„
*   æ€§åˆ«:ä¿é™©æ‰¿åŒ…å•†æ€§åˆ«ï¼Œå¥³ï¼Œç”·
*   bmi:èº«ä½“è´¨é‡æŒ‡æ•°ï¼Œæä¾›å¯¹èº«ä½“çš„äº†è§£ï¼Œä½“é‡ç›¸å¯¹äºèº«é«˜ç›¸å¯¹è¾ƒé«˜æˆ–è¾ƒä½ï¼Œ
    ä½“é‡çš„å®¢è§‚æŒ‡æ•°(kg / m ^ 2)ä½¿ç”¨èº«é«˜ä¸ä½“é‡çš„æ¯”ç‡ï¼Œç†æƒ³å€¼ä¸º 18.5 è‡³ 24.9
*   å„¿ç«¥:å¥åº·ä¿é™©è¦†ç›–çš„å„¿ç«¥äººæ•°/å—æŠšå…»äººäººæ•°
*   å¸çƒŸè€…:å¸çƒŸ
*   åœ°åŒº:å—ç›Šäººåœ¨ç¾å›½çš„å±…ä½åŒºï¼Œä¸œåŒ—ï¼Œä¸œå—ï¼Œè¥¿å—ï¼Œè¥¿åŒ—ã€‚
*   è´¹ç”¨:ç”±å¥åº·ä¿é™©æ”¯ä»˜çš„ä¸ªäººåŒ»ç–—è´¹ç”¨

# æ‰¿è®¤

æ•°æ®é›†å¯åœ¨ GitHub [è¿™é‡Œ](https://github.com/stedy/Machine-Learning-with-R-datasets)è·å¾—ã€‚

# çµæ„Ÿ

ä½ èƒ½å‡†ç¡®é¢„æµ‹ä¿é™©è´¹ç”¨å—ï¼Ÿ

å¥½äº†ï¼Œå…³äºæ•°æ®é›†å·²ç»è¯´å¾—å¤Ÿå¤šäº†ï¼Œç°åœ¨è®©æˆ‘ä»¬å¼€å§‹ç ”ç©¶ç†ŠçŒ«å§ã€‚

è®©æˆ‘ä»¬å°†æ•°æ®ä½œä¸ºç†ŠçŒ«æ•°æ®æ¡†æ¶å¯¼å…¥

```
df = pd.read_csv("/kaggle/input/insurance/insurance.csv")
df.head(10) 
```

![](img/e7bd1339f20f52389d55f78cc556fa2b.png)

è¾“å‡º

æˆ‘é€šå¸¸å–œæ¬¢å°†åˆ—åå­˜å‚¨ä¸ºåˆ—è¡¨ã€‚(å› ä¸ºæŸäº›åŠŸèƒ½å°†æ¥å¯èƒ½ä¼šæ”¹å˜)ã€‚

```
cols = list(df.columns)
```

æè¿°æ•°å­—ç‰¹å¾

```
df.describe().T
```

![](img/fc1bf6c2812ce31b7159c494b325d0d9.png)

è¾“å‡º

æ£€æŸ¥ç¼ºå°‘çš„å€¼

```
df.isna().sum()
```

![](img/756bb2c8cefe2f36efa7dd855cb2ca02.png)

è¾“å‡º

datasetğŸ¥³ğŸ¥³ä¸­æ²¡æœ‰ç¼ºå¤±å€¼

é€šè¿‡ä½¿ç”¨ [seaborn çš„](https://seaborn.pydata.org/) pairplot å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å¿«é€ŸæŸ¥çœ‹æ¯ä¸ªç‰¹æ€§ä¹‹é—´çš„å…³ç³»ã€‚

(Seaborn æ˜¯åŸºäº [matplotlib](https://matplotlib.org/) çš„ Python æ•°æ®å¯è§†åŒ–åº“ã€‚å®ƒæä¾›äº†ä¸€ä¸ªé«˜å±‚æ¬¡çš„ç•Œé¢æ¥ç»˜åˆ¶æœ‰å¸å¼•åŠ›çš„å’Œä¿¡æ¯ä¸°å¯Œçš„ç»Ÿè®¡å›¾å½¢ã€‚)

```
import seaborn as sns
import matplotlib.pyplot as pltsns.pairplot(df)
plt.show()
```

![](img/6de86f202474f9b1ff39b8f741c9cc3a.png)

é…å¯¹å›¾

é€šè¿‡è§‚å¯Ÿæ•°æ®é›†ï¼Œå¯ä»¥æ¸…æ¥šåœ°çœ‹åˆ°â€œæ€§åˆ«â€ã€â€œåœ°åŒºâ€å’Œâ€œå¸çƒŸè€…â€æ˜¯å­—ç¬¦ä¸²æ•°æ®ç±»å‹åˆ—ï¼Œå¯ä»¥è¿›è¡Œçƒ­ç¼–ç ã€‚

Panda çš„ get_dummies()æ–¹æ³•å¯ä»¥ç”¨äºæ­¤ç›®çš„ã€‚

```
df["sex"] = pd.get_dummies(df["sex"])
df["smoker"] = pd.get_dummies(df["smoker"])
df["region"] = pd.get_dummies(df["region"])
df.head()
```

![](img/5610843533f20791f2d35a563171f490.png)

ç°åœ¨æ•°æ®è¢«å¾ˆå¥½åœ°ç¼–ç äº†ã€‚

æˆ‘ä»¬å·²ç»å®Œæˆäº†é¢„å¤„ç†ï¼Œå‡†å¤‡å¼€å§‹æ„å»ºæ¨¡å‹ã€‚

ä½†æ˜¯ç­‰ç­‰ï¼Œè¿˜æœ‰ä¸€ä¸ªæ›´å…³é”®çš„æ­¥éª¤ã€‚(åˆ†å‰²æ•°æ®é›†)

é™¤äº†â€œè´¹ç”¨â€ä¹‹å¤–çš„æ‰€æœ‰åˆ—éƒ½å¯ä»¥æ·»åŠ åˆ°åŠŸèƒ½è¡¨ä¸­ã€‚

```
X = df[set(cols)-set(["charges"])]
y = df["charges"]
```

å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒå’Œæµ‹è¯•:

```
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)
```

å»ºç­‘æ¨¡å‹:

åœ¨è¿™é‡Œï¼Œæˆ‘å°†è®¸å¤šæ¨¡å‹æ·»åŠ åˆ°é˜µåˆ—ä¸­ï¼Œä»¥ä¾¿äºæ¯”è¾ƒæ€§èƒ½ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå›å½’å¾—åˆ†ç”¨ [r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) æˆ–è¯¯å·®å¹³æ–¹æ¥è¡¡é‡ã€‚

```
from sklearn import linear_model

reg = linear_model.LinearRegression()
elas = linear_model.ElasticNet()
lasso = linear_model.Lasso()
huber = linear_model.HuberRegressor()

models = [reg, elas, lasso, huber]

print(reg)for model **in** models:
    print(model)
    model.fit(X_train, y_train)
    print(model.score(X_test, y_test))
```

![](img/787d54d9b0199c2b32c0458f78f12093.png)

æ¨¡å‹åç§°:åˆ†æ•°

**ä½¿ç”¨ RandomForestRegressor:**

```
from sklearn.ensemble import RandomForestRegressor

rr = RandomForestRegressor(n_estimators=200, n_jobs = 6, verbose = True)
rr.fit(X_train, y_train)
rr.score(X_test, y_test)
```

![](img/b6e15f34b0c3cddd689fc44cc3e83048.png)

**ä½¿ç”¨ XGBRegressor:**

```
xgb = XGBRegressor()
xgb.fit(X_train, y_train)
xgb.score(X_test, y_test)
```

![](img/e0f405dac06714994adcefb670d7db42.png)

å¾—åˆ†

**xbgrf å›å½’å™¨:**

```
 from xgboost import XGBRFRegressor

xgbrf = XGBRFRegressor()
xgbrf.fit(X_train, y_train)
xgbrf.score(X_test, y_test)
```

![](img/4bac16df918b5d36e68a5c5093ca7665.png)

å¾—åˆ†

æ£€æŸ¥ r2_score:

r(å†³å®šç³»æ•°)å›å½’å¾—åˆ†å‡½æ•°ã€‚

æœ€ä½³å¾—åˆ†å¯èƒ½æ˜¯ 1.0ï¼Œä¹Ÿå¯èƒ½æ˜¯è´Ÿæ•°(å› ä¸ºæ¨¡å‹å¯èƒ½ä¼šä»»æ„æ¶åŒ–)ã€‚å¿½ç•¥è¾“å…¥ç‰¹å¾ï¼Œå§‹ç»ˆé¢„æµ‹ y çš„æœŸæœ›å€¼çš„å¸¸æ•°æ¨¡å‹çš„ R å€¼ä¸º 0.0ã€‚

```
from sklearn.metrics import r2_scorefor model in models:
    print("-----------------------------------")
    print(r2_score(y_test, model.predict(X_test)))
```

![](img/912215f55bbd83507be3e47e5ce41322.png)

è¾“å‡º

ç»“è®º:

**XBGRFRegressor ç»™å‡ºäº†æœ€å¥½çš„ r2_scoreã€‚**

è¿™å°±æ˜¯æˆ‘ä»¬éœ€è¦åšçš„ä¸€åˆ‡ğŸ˜ƒã€‚

æ­å–œä½ ï¼æˆ‘ä»¬å·²ç»æˆåŠŸåœ°å»ºç«‹äº†ä¸€ä¸ªé¢„æµ‹åŒ»ç–—è´¹ç”¨çš„æ¨¡å‹ã€‚ğŸ‰ğŸŠ