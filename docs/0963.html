<html>
<head>
<title>Decision Tree🌳 using Python(for Regression)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策图表🌳使用Python(用于回归)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/decision-tree-using-python-for-regression-ecf0ccd8884e?source=collection_archive---------7-----------------------#2021-02-08">https://medium.com/analytics-vidhya/decision-tree-using-python-for-regression-ecf0ccd8884e?source=collection_archive---------7-----------------------#2021-02-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="4aeb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">决策树是实践中最常用的算法，背后的原因是它可以用于回归和分类。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/7d5ab69f8bc7ade7aa253e38a2e184dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5_tu5rwtYxH8ZbVE2m95uA.jpeg"/></div></div></figure><p id="b7ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">决策树是一种决策支持工具，它使用决策及其可能结果(包括偶然事件结果、资源成本和效用)的树状模型。这是显示只包含条件控制语句的算法的一种方式。</p><p id="feda" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后我会提供一个我的Kaggle笔记本的链接。</p><p id="bc23" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">现在让我们编码吧！！！</strong></p><h2 id="44e5" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">1.数据集:</h2><p id="1244" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">该数据集与葡萄牙“Vinho Verde”葡萄酒的红色和白色变种相关。它有十二列。所有数值均基于物理化学测试。</p><p id="ade5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">链接:<a class="ae ko" href="https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/UC IML/red-wine-quality-cortez-et-al-2009</a></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kp"><img src="../Images/69262479f1ee9376cf5f7aad3235befe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BZgFaWh5av1eAguCCVqdIA.png"/></div></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">红葡萄酒和白葡萄酒质量数据集</figcaption></figure><h2 id="4c7b" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">2.图书馆:</h2><p id="b032" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">我们将使用Pandas、Numpy和Scikit-learn库。我们将从Scikit-learn导入<strong class="ig hi"> DecisionTreeRegressor </strong>类来训练我们的数据集。</p><pre class="jd je jf jg fd ku kv kw kx aw ky bi"><span id="6b15" class="jo jp hh kv b fi kz la l lb lc"># importing the libraries<br/>import pandas as pd<br/>import numpy as np</span><span id="d821" class="jo jp hh kv b fi ld la l lb lc"># Reading the dataset using pandas librarie<br/>dataset = pd.read_csv('name_of_dataset.csv')</span></pre><h2 id="42ad" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">3.探索性数据分析(EDA):</h2><p id="8b84" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">现在，我们将研究我们的数据集，检查它是否有任何缺失值，我们有什么类型的数据？对分类数据进行编码等。</p><ul class=""><li id="d12e" class="le lf hh ig b ih ii il im ip lg it lh ix li jb lj lk ll lm bi translated"><strong class="ig hi">数据集的形状和类型:</strong></li></ul><pre class="jd je jf jg fd ku kv kw kx aw ky bi"><span id="9003" class="jo jp hh kv b fi kz la l lb lc"># shape of the dataset<br/>print(dataset.shape)<br/># Type of the dataset<br/>print(dataset.dtypes)</span></pre><ul class=""><li id="3fbe" class="le lf hh ig b ih ii il im ip lg it lh ix li jb lj lk ll lm bi translated"><strong class="ig hi">检查空值:</strong></li></ul><pre class="jd je jf jg fd ku kv kw kx aw ky bi"><span id="1c42" class="jo jp hh kv b fi kz la l lb lc"># checking for the null value<br/>print(dataset.isna().sum())<br/># Counting the number of null values<br/>print(dataset.isna().sum().sum())</span></pre><ul class=""><li id="bbbb" class="le lf hh ig b ih ii il im ip lg it lh ix li jb lj lk ll lm bi translated"><strong class="ig hi">对分类数据进行编码:</strong></li></ul><p id="9378" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过使用dtypes函数，我们知道我们的数据集只包含浮点和整数值，所以我们不必对上述数据集使用编码。</p><pre class="jd je jf jg fd ku kv kw kx aw ky bi"><span id="db62" class="jo jp hh kv b fi kz la l lb lc"># encoding the categorical data<br/>dataset = pd.get_dummies(dataset)</span></pre><h2 id="fbe8" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">4.因变量和自变量(矩阵):</h2><p id="38a4" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">为了训练我们的数据集，我们需要指定因变量和自变量。因变量将包含我们的输出列，反之亦然。</p><pre class="jd je jf jg fd ku kv kw kx aw ky bi"><span id="621e" class="jo jp hh kv b fi kz la l lb lc"># independent variables<br/>X = dataset.iloc[:, :-1].values<br/># dependent variable<br/>y = dataset.iloc[:, -1:].values</span></pre><h2 id="1b94" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">5.拆分数据集:</h2><p id="3b58" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">我们将把数据集分成训练集和测试集。训练集将拥有大部分数据，因为我们将在该数据集上训练我们的模型，而测试集将拥有少量数据，因此我们只能将其用于测试目的。</p><pre class="jd je jf jg fd ku kv kw kx aw ky bi"><span id="48ad" class="jo jp hh kv b fi kz la l lb lc"># spliting the dataset<br/>from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test  = train_test_split(X, y,                    test_size=0.2, random_state = 0)</span></pre><h2 id="e547" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">6.特征缩放:</h2><p id="a3b6" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">使用特征缩放，我们将归一化自变量的范围。</p><pre class="jd je jf jg fd ku kv kw kx aw ky bi"><span id="41e1" class="jo jp hh kv b fi kz la l lb lc"># using feature scaling<br/>from sklearn.preprocessing import StandardScaler<br/>X_sc = StandardScaler()<br/>X_train = X_sc.fit_transform(X_train)</span></pre><h2 id="54e2" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">7.训练数据集:</h2><p id="4b9d" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">是时候训练我们的数据集了，我们将使用来自树模块的DecisionTreeRegressor类。</p><pre class="jd je jf jg fd ku kv kw kx aw ky bi"><span id="6944" class="jo jp hh kv b fi kz la l lb lc"># training the dataset<br/>from sklearn.tree import DecisionTreeRegressor<br/>regrassor = DecisionTreeRegressor(random_state = 0)<br/>regrassor.fit(X_train, y_train)</span></pre><h2 id="e8aa" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">8.预测结果:</h2><p id="0148" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">训练模型后，我们将使用测试数据预测结果</p><pre class="jd je jf jg fd ku kv kw kx aw ky bi"><span id="2ccf" class="jo jp hh kv b fi kz la l lb lc"># predictzing the result<br/>pred = regrassor.predict(X_sc.transform(X_test))</span></pre><h2 id="1ff1" class="jo jp hh bd jq jr js jt ju jv jw jx jy ip jz ka kb it kc kd ke ix kf kg kh ki bi translated">9.精确度:</h2><p id="1521" class="pw-post-body-paragraph ie if hh ig b ih kj ij ik il kk in io ip kl ir is it km iv iw ix kn iz ja jb ha bi translated">现在，我们来看看我们的算法有多精确？</p><pre class="jd je jf jg fd ku kv kw kx aw ky bi"><span id="d189" class="jo jp hh kv b fi kz la l lb lc"># Accuracy of the algorithm<br/>from sklearn.metrics import accuracy_score<br/>print(accuracy_score(y_test, pred))</span></pre><p id="b25b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Kaggle笔记本链接:</p><div class="ln lo ez fb lp lq"><a href="https://www.kaggle.com/rahulkadam0909/decision-tree" rel="noopener  ugc nofollow" target="_blank"><div class="lr ab dw"><div class="ls ab lt cl cj lu"><h2 class="bd hi fi z dy lv ea eb lw ed ef hg bi translated">决策图表</h2><div class="lx l"><h3 class="bd b fi z dy lv ea eb lw ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用红酒质量数据</h3></div><div class="ly l"><p class="bd b fp z dy lv ea eb lw ed ef dx translated">www.kaggle.com</p></div></div><div class="lz l"><div class="ma l mb mc md lz me jm lq"/></div></div></a></div><blockquote class="mf"><p id="cd3d" class="mg mh hh bd mi mj mk ml mm mn mo jb dx translated">编码快乐！！！</p></blockquote></div></div>    
</body>
</html>