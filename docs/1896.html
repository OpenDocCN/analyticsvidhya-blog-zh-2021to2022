<html>
<head>
<title>What dog breed am I?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我是什么品种的狗？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/what-dog-breed-am-i-851240060b68?source=collection_archive---------10-----------------------#2021-03-24">https://medium.com/analytics-vidhya/what-dog-breed-am-i-851240060b68?source=collection_archive---------10-----------------------#2021-03-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="9f3a" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">使用深度学习的人或狗图像的狗品种分类</h2></div><h2 id="fe9b" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">问题陈述</h2><p id="f84e" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">这个项目的想法是双重的。</p><ul class=""><li id="7031" class="kn ko hh jw b jx kp ka kq jh kr jl ks jp kt km ku kv kw kx bi translated">一个是识别传递给算法的图像中是否有狗，并对狗的种类进行分类。</li><li id="6540" class="kn ko hh jw b jx ky ka kz jh la jl lb jp lc km ku kv kw kx bi translated">其次，如果图像中没有狗，但有人类，那么算法必须将人类的面部分类为目标标签中最接近的可能物种。</li></ul><h2 id="6bb3" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">战略已实施</h2><p id="fe26" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">使用CNN训练神经网络模型。卷积神经网络(CNN)是一种广泛用于图像识别和分类的神经网络。我们使用CNN实现了两种架构，一种是具有3个conv2d层的朴素卷积网络，另一种架构是resnet50，其最后几层(迁移学习)经过修改以适合该问题。</p><figure class="le lf lg lh fd li er es paragraph-image"><div class="er es ld"><img src="../Images/23269cd78f0e60935e389be396f89bac.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/1*mvAtFCACe86_bc2Lf_McJQ.png"/></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">使用右图像作为输入的模型的性能，以及模型分类为的标签的示例之一。右图像源unsplash.com</figcaption></figure><h2 id="096f" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">数据</h2><p id="f106" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">这个项目是为我的Udacity数据科学家纳米学位。数据由Udacity提供给我们。数据包含</p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="15ca" class="iw ix hh lq b fi lu lv l lw lx">133 total dog categories.<br/>8351 total dog images.<br/><br/>6680 training dog images.<br/>835 validation dog images.<br/>836 test dog images.</span></pre><p id="0e2d" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们也有人脸检测的人类图像。</p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="9b5a" class="iw ix hh lq b fi lu lv l lw lx">13233 total human images.</span></pre><h2 id="f1e2" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">系统模型化</h2><p id="c46e" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated"><strong class="jw hi">人脸检测</strong></p><p id="13f5" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">对于人脸检测，我们将使用OpenCV 的<a class="ae mb" href="http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html" rel="noopener ugc nofollow" target="_blank">哈尔级联。</a></p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="a2f8" class="iw ix hh lq b fi lu lv l lw lx">face_cascade = cv2.CascadeClassifier(‘haarcascades/haarcascade_frontalface_alt.xml’)</span></pre><p id="9943" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们为面部检测创建了一个函数，以便在代码的不同部分使用它。这个函数接收一个图像路径，检查图像是否有一个或多个人脸，并返回True或False。</p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="7c70" class="iw ix hh lq b fi lu lv l lw lx">def face_detector(img_path):<br/>    img = cv2.imread(img_path)<br/>    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br/>    faces = face_cascade.detectMultiScale(gray)<br/>    return len(faces) &gt; 0</span></pre><p id="7044" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated"><strong class="jw hi">警犬探测</strong></p><p id="ca93" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">现在，我们已经完成了面部检测，我们想看看我们的图像是否有狗。为了检测狗，我们将使用一个预先训练的resnet50。</p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="2533" class="iw ix hh lq b fi lu lv l lw lx">def ResNet50_predict_labels(img_path):<br/>    # returns prediction vector for image located at img_path<br/>    img = preprocess_input(path_to_tensor(img_path))<br/>    return np.argmax(ResNet50_model.predict(img))<br/>def dog_detector(img_path):<br/>    prediction = ResNet50_predict_labels(img_path)<br/>    return ((prediction &lt;= 268) &amp; (prediction &gt;= 151))</span></pre><p id="f424" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">狗检测器函数获取图像并调用ResNet50_predict_labels函数，该函数使用ResNet50模型来预测图像的标签。如果图像包含一只狗，返回的标签的索引将在151和268之间(包括151和268)。你可以在这里查看resnet50可以预测的所有标签的索引<a class="ae mb" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="97b4" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们现在可以从图像中检测到人和狗。下一步是训练一个深度学习模型，用于对狗的品种进行分类。但在此之前，我们必须确保我们所有的图像在所有像素上都是一致的。所以我们把所有这些图片除以255来重新调整比例</p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="deaa" class="iw ix hh lq b fi lu lv l lw lx">train_tensors = paths_to_tensor(train_files).astype('float32')/255<br/>valid_tensors = paths_to_tensor(valid_files).astype('float32')/255<br/>test_tensors = paths_to_tensor(test_files).astype('float32')/255</span></pre><p id="e4a8" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated"><strong class="jw hi">模型架构</strong></p><p id="cd11" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们创建了两个模型。一个从零开始使用基本的朴素架构，另一个我们使用预训练的resnet50模型，并添加了一些层来适应我们的问题。</p><p id="107e" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated"><strong class="jw hi">朴素的建筑</strong></p><p id="0b32" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们先来看看幼稚的架构。</p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="cfcb" class="iw ix hh lq b fi lu lv l lw lx">model = Sequential(<br/> [<br/> <br/> Conv2D(16,(2,2), activation=’relu’, input_shape=(224,224,3)),<br/> Dropout(0.3),<br/> MaxPooling2D((2,2)),<br/> Conv2D(32,(2,2), activation=’relu’),<br/> Dropout(0.3),<br/> MaxPooling2D((2,2)),<br/> Conv2D(64,(2,2), activation=’relu’),<br/> Dropout(0.3),<br/> MaxPooling2D((2,2)),<br/> Flatten(),<br/> Dense(133, activation=’relu’)<br/> <br/> ])</span></pre><p id="b39a" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们有2维卷积层，下降和最大池层。接近尾声时，我们有一个扁平化层之前，我们应用密集层，以获得图像的输出标签。</p><p id="7e96" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated"><strong class="jw hi"> Resnet50架构</strong></p><p id="c450" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们将在下面的测试部分展示朴素架构的表现。但在此之前，我们将看看我们将训练的另一个模型，由于其复杂的结构和层数，该模型将表现得更好。这可能不总是正确的，但在这种情况下，它会表现得更好。让我们来看看我们可以添加到resnet 50模型中的内容，以便针对我们的问题对其进行定制。</p><p id="65d5" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们首先加载已经为这个特定数据编译的瓶颈特性。您可以下载。npz文件如下图所示<a class="ae mb" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogResnet50Data.npz" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="c9ef" class="iw ix hh lq b fi lu lv l lw lx">bottleneck_features = np.load('bottleneck_features/DogResnet50Data.npz')<br/>train_Resnet50 = bottleneck_features['train']<br/>valid_Resnet50 = bottleneck_features['valid']<br/>test_Resnet50 = bottleneck_features['test']</span></pre><p id="6419" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">为了定义我们想要在此模型末尾添加的层，我们将创建一个顺序模型。</p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="fea1" class="iw ix hh lq b fi lu lv l lw lx">Resnet50_model = Sequential()<br/>Resnet50_model.add(GlobalAveragePooling2D(input_shape=train_Resnet50.shape[1:]))<br/>Resnet50_model.add(Dense(133, activation='softmax'))</span></pre><p id="946a" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们编译并适应我们的架构。让我们来看看他们的个人表现。</p><h2 id="b2b2" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">结果</h2><p id="6a48" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated"><strong class="jw hi">朴素的建筑</strong></p><p id="b8fc" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们训练朴素架构5个时代。下面是模型的训练细节。</p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="8cd6" class="iw ix hh lq b fi lu lv l lw lx">Train on 6680 samples, validate on 835 samples<br/>Epoch 1/5<br/>6660/6680 [============================&gt;.] - ETA: 0s - loss: 15.4370 - acc: 0.0104Epoch 00001: val_loss improved from inf to 15.75039, saving model to saved_models/weights.best.from_scratch.hdf5<br/>6680/6680 [==============================] - 30s 5ms/step - loss: 15.4390 - acc: 0.0103 - val_loss: 15.7504 - val_acc: 0.0132<br/>Epoch 2/5<br/>6660/6680 [============================&gt;.] - ETA: 0s - loss: 15.5520 - acc: 0.0120Epoch 00002: val_loss did not improve<br/>6680/6680 [==============================] - 29s 4ms/step - loss: 15.5514 - acc: 0.0121 - val_loss: 15.7563 - val_acc: 0.0084<br/>Epoch 3/5<br/>6660/6680 [============================&gt;.] - ETA: 0s - loss: 15.2091 - acc: 0.0143Epoch 00003: val_loss improved from 15.75039 to 15.02195, saving model to saved_models/weights.best.from_scratch.hdf5<br/>6680/6680 [==============================] - 29s 4ms/step - loss: 15.2070 - acc: 0.0142 - val_loss: 15.0220 - val_acc: 0.0144<br/>Epoch 4/5<br/>6660/6680 [============================&gt;.] - ETA: 0s - loss: 15.5074 - acc: 0.0078Epoch 00004: val_loss did not improve<br/>6680/6680 [==============================] - 31s 5ms/step - loss: 15.5093 - acc: 0.0078 - val_loss: 16.0409 - val_acc: 0.0048<br/>Epoch 5/5<br/>6660/6680 [============================&gt;.] - ETA: 0s - loss: 16.0358 - acc: 0.0051Epoch 00005: val_loss did not improve<br/>6680/6680 [==============================] - 32s 5ms/step - loss: 16.0361 - acc: 0.0051 - val_loss: 16.0409 - val_acc: 0.0048</span></pre><p id="012b" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">当用以前看不到的数据测试时，朴素的架构导致1.4%的测试准确度。老实说是不能用的。我们来看看resnet50机型表现如何。</p><p id="8a82" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated"><strong class="jw hi"> Resnet50架构</strong></p><p id="897d" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我们为这个模型训练了20个时期。下面是训练输出。与之前的模型相比，该模型在测试数据上的性能要高得多。我们能够在以前看不到的数据上看到81.3%的准确性，这是一个相当大的飞跃。</p><p id="07e0" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">(下面的训练过程显示了前5个和后5个时期，以免本文篇幅过长。)</p><pre class="le lf lg lh fd lp lq lr ls aw lt bi"><span id="54f8" class="iw ix hh lq b fi lu lv l lw lx">Train on 6680 samples, validate on 835 samples<br/>Epoch 1/20<br/>6540/6680 [============================&gt;.] - ETA: 0s - loss: 1.6424 - acc: 0.6009Epoch 00001: val_loss improved from inf to 0.77969, saving model to saved_models/weights.best.Resnet50.hdf5<br/>6680/6680 [==============================] - 2s 270us/step - loss: 1.6224 - acc: 0.6049 - val_loss: 0.7797 - val_acc: 0.7593<br/>Epoch 2/20<br/>6560/6680 [============================&gt;.] - ETA: 0s - loss: 0.4371 - acc: 0.8623Epoch 00002: val_loss improved from 0.77969 to 0.66353, saving model to saved_models/weights.best.Resnet50.hdf5<br/>6680/6680 [==============================] - 1s 224us/step - loss: 0.4381 - acc: 0.8620 - val_loss: 0.6635 - val_acc: 0.8036<br/>Epoch 3/20<br/>6460/6680 [============================&gt;.] - ETA: 0s - loss: 0.2664 - acc: 0.9150Epoch 00003: val_loss did not improve<br/>6680/6680 [==============================] - 1s 224us/step - loss: 0.2628 - acc: 0.9160 - val_loss: 0.6948 - val_acc: 0.7820<br/>Epoch 4/20<br/>6540/6680 [============================&gt;.] - ETA: 0s - loss: 0.1775 - acc: 0.9462Epoch 00004: val_loss improved from 0.66353 to 0.64685, saving model to saved_models/weights.best.Resnet50.hdf5<br/>6680/6680 [==============================] - 1s 224us/step - loss: 0.1784 - acc: 0.9460 - val_loss: 0.6468 - val_acc: 0.8156<br/>Epoch 5/20<br/>6440/6680 [===========================&gt;..] - ETA: 0s - loss: 0.1243 - acc: 0.9632Epoch 00005: val_loss did not improve<br/>6680/6680 [==============================] - 1s 223us/step - loss: 0.1243 - acc: 0.9623 - val_loss: 0.6880 - val_acc: 0.8120</span><span id="48da" class="iw ix hh lq b fi mc lv l lw lx">...</span><span id="b500" class="iw ix hh lq b fi mc lv l lw lx">Epoch 16/20<br/>6620/6680 [============================&gt;.] - ETA: 0s - loss: 0.0092 - acc: 0.9980Epoch 00016: val_loss did not improve<br/>6680/6680 [==============================] - 1s 222us/step - loss: 0.0091 - acc: 0.9981 - val_loss: 0.8508 - val_acc: 0.8228<br/>Epoch 17/20<br/>6620/6680 [============================&gt;.] - ETA: 0s - loss: 0.0071 - acc: 0.9982Epoch 00017: val_loss did not improve<br/>6680/6680 [==============================] - 1s 222us/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.8501 - val_acc: 0.8359<br/>Epoch 18/20<br/>6500/6680 [============================&gt;.] - ETA: 0s - loss: 0.0066 - acc: 0.9980Epoch 00018: val_loss did not improve<br/>6680/6680 [==============================] - 2s 225us/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.8925 - val_acc: 0.8240<br/>Epoch 19/20<br/>6500/6680 [============================&gt;.] - ETA: 0s - loss: 0.0060 - acc: 0.9983Epoch 00019: val_loss did not improve<br/>6680/6680 [==============================] - 2s 225us/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.9231 - val_acc: 0.8299<br/>Epoch 20/20<br/>6500/6680 [============================&gt;.] - ETA: 0s - loss: 0.0064 - acc: 0.9980Epoch 00020: val_loss did not improve<br/>6680/6680 [==============================] - 2s 225us/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.9584 - val_acc: 0.8216</span></pre><h2 id="9899" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">丰富</h2><p id="821d" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">对模型的改进可以使其取得更显著的效果。他们中的一些人可以使用</p><ol class=""><li id="f391" class="kn ko hh jw b jx kp ka kq jh kr jl ks jp kt km md kv kw kx bi translated">数据扩充</li><li id="58ab" class="kn ko hh jw b jx ky ka kz jh la jl lb jp lc km md kv kw kx bi translated">狗的特殊特征</li><li id="3072" class="kn ko hh jw b jx ky ka kz jh la jl lb jp lc km md kv kw kx bi translated">平衡数据集</li><li id="886b" class="kn ko hh jw b jx ky ka kz jh la jl lb jp lc km md kv kw kx bi translated">不同历元数的训练。</li></ol><p id="159e" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">我可能还会创建一个网络应用程序，只是为了好玩。所以也期待一下:)</p><h2 id="1f2c" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">结论</h2><p id="04ac" class="pw-post-body-paragraph ju jv hh jw b jx jy ii jz ka kb il kc jh kd ke kf jl kg kh ki jp kj kk kl km ha bi translated">这是一个有趣的项目，我感谢Udacity让我走了这么远。为了保持博客的最小规模，我添加了最重要的代码部分，这将有助于更好的阅读体验。然而，如果你想自己玩代码。你可以在我的<a class="ae mb" href="https://github.com/ghemareddy97/Capstone-Dog-Identification-App-Udacity" rel="noopener ugc nofollow" target="_blank"> Github简介</a>里找到笔记本。如果你有任何意见或问题，我总是喜欢阅读和回答，所以请让我知道你的想法。</p><p id="ee50" class="pw-post-body-paragraph ju jv hh jw b jx kp ii jz ka kq il kc jh ly ke kf jl lz kh ki jp ma kk kl km ha bi translated">P.S .上图是实际分类。右边的人被归类为巴比隆，所以我加了一个可爱的例子。你们觉得这个分类怎么样？</p></div></div>    
</body>
</html>