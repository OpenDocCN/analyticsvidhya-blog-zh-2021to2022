<html>
<head>
<title>Improving YOLOv4 accuracy on detecting common objects</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提高YOLOv4检测常见物体的准确性</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/improving-yolov4-accuracy-on-detecting-common-objects-38f3baa5041c?source=collection_archive---------0-----------------------#2021-05-29">https://medium.com/analytics-vidhya/improving-yolov4-accuracy-on-detecting-common-objects-38f3baa5041c?source=collection_archive---------0-----------------------#2021-05-29</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/2bb14cffbdece358ef2d56771ca6d72a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D2vvs4ALqZ6fQO9n1PlA5A.jpeg"/></div></div></figure><p id="f0f8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">YOLOv4带有80个内置的对象类，它能够检测到这些对象类。我一直试图用YoloV4和Darknet检测公共网络摄像头上的人。我的经验是，当人距离摄像机<strong class="ir hi">、T2光照条件</strong>异常或者人站在<strong class="ir hi">特殊背景</strong>前面时，预先训练的模型不能正确地检测到人。为了提高人物检测的准确性，我决定在YoloV4的基础上建立自己的模型。</p><h1 id="b7d0" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">YOLO和暗网</h1><p id="b89d" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">为了理解YOLOv4是如何工作的，我们必须谈一点关于Darknet的事情。<br/>YOLO是一种物体检测算法，有一些实现，包括Pytorch、Keras和Darknet。<br/> Darknet本身，根据<a class="ae kq" href="https://pjreddie.com/darknet/" rel="noopener ugc nofollow" target="_blank">它自己的描述</a>“一个用C和CUDA编写的开源神经网络框架。它速度快，易于安装，支持CPU和GPU计算。”</p><h1 id="b4bb" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">从源代码构建OpenCV和Darknet</h1><p id="d079" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">为了在暗网上执行自定义对象检测，我们必须在我们的模型上进行训练。为此，我们必须从它们的源代码构建Darknet和OpenCV。在像我这样的Windows 10机器上，这意味着我们必须生产必要的产品。dll和。exe文件。</p><blockquote class="kr ks kt"><p id="92ca" class="ip iq ku ir b is it iu iv iw ix iy iz kv jb jc jd kw jf jg jh kx jj jk jl jm ha bi translated">请注意本章的内容。这是整个过程中最无聊但又不得不做的部分:)<br/>如果你只对物体检测部分感兴趣，你可以跳过。</p></blockquote><h2 id="00f5" class="ky jo hh bd jp kz la lb jt lc ld le jx ja lf lg kb je lh li kf ji lj lk kj ll bi translated">从源代码构建OpenCV</h2><p id="f98e" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">我在之前的文章中详细描述了如何在Windows 10环境下从源代码构建OpenCV。</p><div class="lm ln ez fb lo lp"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/object-detection-on-public-webcam-with-opencv-and-yolov4-9ed51d5896a9"><div class="lq ab dw"><div class="lr ab ls cl cj lt"><h2 class="bd hi fi z dy lu ea eb lv ed ef hg bi translated">基于OpenCV和YOLOv4的公共摄像头目标检测</h2><div class="lw l"><h3 class="bd b fi z dy lu ea eb lv ed ef dx translated">公共网络摄像头可以是对象检测的一个很好的数据源。让我展示一下我是如何用YOLOv4和OpenCV做到这一点的…</h3></div><div class="lx l"><p class="bd b fp z dy lu ea eb lv ed ef dx translated">medium.com</p></div></div><div class="ly l"><div class="lz l ma mb mc ly md in lp"/></div></div></a></div><p id="b005" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了从源代码构建OpenCV，您必须遵循相同的步骤，除了您必须在生成项目文件之前在CMake GUI中设置一个额外的属性:<em class="ku"> BUILD_opencv_world。</em>您可以勾选该属性，并按照上述文章中的教程继续后续步骤。</p><h2 id="9138" class="ky jo hh bd jp kz la lb jt lc ld le jx ja lf lg kb je lh li kf ji lj lk kj ll bi translated">从源代码构建暗网</h2><p id="a8ea" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">我按照CodingBug频道的<a class="ae kq" href="https://www.youtube.com/watch?v=FE2GBeKuqpc" rel="noopener ugc nofollow" target="_blank">这个</a>惊人的一步一步的教程从源代码构建Darknet。在这里，我只是总结了下面的步骤，为进一步参考检查以上链接的视频。</p><p id="e37e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">从<a class="ae kq" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank"> Darknet的github页面</a>下载源代码为。zip文件并解压到一个新文件夹<em class="ku"> darknet </em>。</p><p id="04da" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">提取时。将CUDA目录中的cuDNN dll复制到<em class="ku">darknet/build/darknet/x64</em>文件夹中。对我来说，它是“<em class="ku">c:\ Program Files \ NVIDIA GPU Computing Toolkit \ CUDA \ v 11.2 \ bin \ cud nn 64 _ 8 . dll</em>”，但它可能会因您的CUDA版本和GPU支持的架构而异。</p><p id="af73" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">转到OpenCV构建文件夹，复制<em class="ku">install/x64/vc16/bin/OpenCV _ world *。dll </em>放入<em class="ku">darknet/build/darknet/x64</em>文件夹。</p><p id="65fa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">打开<em class="ku">darknet/build/darknet/darknet . vcx proj</em>文件进行编辑，在两个地方设置你的CUDA版本:<em class="ku">$(VCTargetsPath)\ build customizations \ CUDA</em><strong class="ir hi"><em class="ku">11.2</em></strong><em class="ku">。道具</em>和<em class="ku">$(VCTargetsPath)\ build customizations \ CUDA</em><strong class="ir hi"><em class="ku">11.2</em></strong><em class="ku">. targets .<br/></em>我的是11.2如上图所示但你的可能不同。</p><p id="4cd3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">同样，对<em class="ku">darknet/build/darknet/yolo _ CPP _ dll . vcx proj</em>做同样的操作。</p><blockquote class="kr ks kt"><p id="a80c" class="ip iq ku ir b is it iu iv iw ix iy iz kv jb jc jd kw jf jg jh kx jj jk jl jm ha bi translated"><strong class="ir hi">注</strong> : <em class="hh">为我所用。道具和。目标文件在Visual Studio文件夹</em>的$(VCTargetsPath)\ build customizations<em class="hh">中丢失:c:\ Program Files(x86)\ Microsoft Visual Studio \ 2019 \ Community \ MSBuild \ Microsoft \ VC \ v 160 \ build customizations \<em class="hh">因此我必须从CUDA目录</em>c:\ Program Files \ NVIDIA GPU Computing Toolkit \ CUDA \ v 11.2 \ extras \ Visual _ Studio _ integration \ MSBuild extensions<em class="hh">中复制它们。</em></em></p></blockquote><p id="185b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在用Visual Studio打开<em class="ku">darknet/build/darknet/yolo _ CPP _ dll . vcx proj</em>。首先，在菜单栏中将解决方案配置<strong class="ir hi">从Debug改为Release/X64 </strong>。然后在解决方案浏览器中，右击<em class="ku"> yolo_cpp_dll </em>并点击<em class="ku"> Build </em>。</p><p id="56fc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一旦构建成功完成，用Visual Studio打开<em class="ku">darknet/build/darknet/darknet . SLN</em>。在建造暗网之前，你必须设置一些属性。右击暗网并选择属性。<br/>现在设置以下属性:</p><ul class=""><li id="aad6" class="me mf hh ir b is it iw ix ja mg je mh ji mi jm mj mk ml mm bi translated">将OpenCV包含文件夹添加到包含路径的<em class="ku">C/c++/General/Additional Include directory</em>属性中。对我来说，包含路径是<em class="ku"> &lt; opencv根目录&gt;\ build \ install \ include \；</em></li><li id="3b39" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated">将OpenCV lib文件夹添加到包含路径的<em class="ku">链接器/通用/附加库目录</em>属性中。对我来说，lib路径是<em class="ku"> &lt; opencv根目录&gt;\ build \ install \ x64 \ vc16 \ lib \</em></li><li id="55d3" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated">从<em class="ku">C/c++/预处理器/预处理器定义</em>的列表中删除<em class="ku"> CUDNN_HALF </em></li><li id="891d" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated">从<em class="ku">CUDA C/c++/设备/代码生成</em>中移除<em class="ku"> compute_75、sm_75 </em></li></ul><p id="294b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一旦这些都完成了，右键点击<em class="ku">解决方案浏览器</em>中的<em class="ku">暗网</em>并点击<em class="ku">构建。</em>当构建完成后，你会在<em class="ku">darknet/build/darknet/x64</em>文件夹<em class="ku">中找到darknet.exe。</em></p><h2 id="6db7" class="ky jo hh bd jp kz la lb jt lc ld le jx ja lf lg kb je lh li kf ji lj lk kj ll bi translated">测试暗网构建</h2><p id="e25a" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">为了测试我们刚刚构建的Darknet，从darknet github页面下载<a class="ae kq" href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights" rel="noopener ugc nofollow" target="_blank"> yolov4.weights </a>文件到<em class="ku">Darknet/build/Darknet/x64</em>文件夹。<br/>现在在Anaconda提示符下发出以下命令:</p><pre class="ms mt mu mv fd mw mx my mz aw na bi"><span id="a54b" class="ky jo hh mx b fi nb nc l nd ne">darknet.exe detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights</span></pre><p id="deb8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在控制台上显示Darknet神经网络层的不同信息后，Darknet会提示输入要检测的对象的图像名称。您可以提供<em class="ku">dog.jpg</em>作为x64文件夹中的默认测试图像。或者您可以使用任意图像。如果您成功构建了Darknet，您应该会得到类似的输出:</p><figure class="ms mt mu mv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nf"><img src="../Images/d0ecb533831b72ad6e645d1b9405d2a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-whL6QRVz77Hk56NJhdMcw.png"/></div></div><figcaption class="ng nh et er es ni nj bd b be z dx translated">暗网构建测试映像</figcaption></figure><p id="7701" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在我们有了预训练模型，但这次我们想要一个定制模型，与原始预训练模型相比，它具有更好的识别人和车的能力。<br/>那么让我们来构建这个定制模型。</p><h1 id="9688" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">用Roboflow注释图像</h1><h2 id="014d" class="ky jo hh bd jp kz la lb jt lc ld le jx ja lf lg kb je lh li kf ji lj lk kj ll bi translated">从网络摄像头收集训练图像</h2><p id="2398" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">任何自定义模型都需要对图像进行训练。因为是街景，我决定只检测人、汽车和公共汽车。所以我的模型将只包含3个类。<br/>出于训练目的，我从我在<a class="ae kq" rel="noopener" href="/analytics-vidhya/object-detection-on-public-webcam-with-opencv-and-yolov4-9ed51d5896a9">上一篇文章</a>中使用的Pula公共网络摄像头收集了数百张图像。</p><blockquote class="kr ks kt"><p id="feb8" class="ip iq ku ir b is it iu iv iw ix iy iz kv jb jc jd kw jf jg jh kx jj jk jl jm ha bi translated">为了收集图像，我使用了一个脚本，每30秒从<strong class="ir hi">的网络摄像头中捕捉一帧。我跑了几个小时，包括白天和晚上。它给了我数百张照片。此外，我还内置了一个机制，这样当我按下<strong class="ir hi">键时，它也会捕捉图像</strong>。当屏幕上发生一些不寻常的事情，可能会混淆模型时，我用它来捕捉图像。然后我整理出那些包含人、汽车或公共汽车的帧，并使用大约200张图像进行训练。</strong></p></blockquote><figure class="ms mt mu mv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/e3f2474179c74eca88dd595ad871756e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FJYeWS17OxDH4lX_AbgfRQ.jpeg"/></div></div><figcaption class="ng nh et er es ni nj bd b be z dx translated">来自街道网络摄像头的样本训练图像</figcaption></figure><h2 id="ba43" class="ky jo hh bd jp kz la lb jt lc ld le jx ja lf lg kb je lh li kf ji lj lk kj ll bi translated">利用机器人流程</h2><p id="3350" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">以前我使用开源的LabelImg工具进行图像标注，但是这次我想尝试一些不同的东西，一些可能比LabelImg有更多功能的东西。我决定尝试一下我之前听说过的机器人流程。使用Roboflow的免费版本，您可以为您的项目注释1000张图像。在不详细介绍Roboflow的情况下，让我列出它们最吸引我的功能:</p><ul class=""><li id="e1f2" class="me mf hh ir b is it iw ix ja mg je mh ji mi jm mj mk ml mm bi translated"><strong class="ir hi">标签辅助</strong>:在Coco v1模型的帮助下，在各种置信度下，帮助标注已知对象。它大大减少了注释时间。</li><li id="b6c0" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated"><strong class="ir hi">缩放</strong>:它有助于标注小物体，你可以将原始图像放大4000%</li><li id="1ecb" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated"><strong class="ir hi">标记空图像</strong>:只需点击一个按钮，您就可以轻松创建没有任何可检测对象的图像。这些图像对于模型识别信息的缺乏是有用的</li><li id="0f03" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated"><strong class="ir hi">在训练、测试和验证集之间轻松移动图像</strong>:难以解读的图像可用于验证</li><li id="8af5" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated"><strong class="ir hi">数据集健康检查</strong>:您可以检查您的数据集是否缺少注释或不平衡的类，无论您的任何类是过多还是过少</li><li id="b0e9" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated"><strong class="ir hi">以多种格式导出数据集</strong>:只需点击一个按钮，即可以Yolo Darknet格式导出数据集，但支持大多数主要的图像注释格式，包括Pascal VOC、Tensorflow TFRecord或Yolo格式的Keras和Pytorch等。</li></ul><figure class="ms mt mu mv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nk"><img src="../Images/49dfaab4ba25a262c733b6972b0a511a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k6syMkFEtmBZe1GalHYsGw.png"/></div></div><figcaption class="ng nh et er es ni nj bd b be z dx translated">Roboflow注释工具的实际应用</figcaption></figure><h1 id="6087" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">用于自定义对象检测的训练暗网</h1><h2 id="fd4a" class="ky jo hh bd jp kz la lb jt lc ld le jx ja lf lg kb je lh li kf ji lj lk kj ll bi translated">为训练准备数据集</h2><p id="ea6c" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">当我完成注释后，我以Yolo Darknet格式从Roboflow中导出了我的数据集。出于训练的目的，我选择了416 x 416像素的图像大小，这是Yolov4支持的大小之一。</p><blockquote class="kr ks kt"><p id="89ad" class="ip iq ku ir b is it iu iv iw ix iy iz kv jb jc jd kw jf jg jh kx jj jk jl jm ha bi translated">我选择这个较低的分辨率来加快训练。为了稍微提高精确度，您可以使用更大的图像尺寸512x512或608x608，但这将需要更长的训练时间。</p></blockquote><p id="1263" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下载数据集后，我有一个类似的文件夹结构:</p><pre class="ms mt mu mv fd mw mx my mz aw na bi"><span id="8c8c" class="ky jo hh mx b fi nb nc l nd ne">- train<br/>|--- file1.jpg<br/>|--- file1.txt<br/>|--- file2.jpg<br/>|--- file2.txt<br/>- valid<br/>|--- file1.jpg<br/>|--- file1.txt<br/>|--- file2.jpg<br/>|--- file2.txt<br/>- test<br/>|--- file1.jpg<br/>|--- file1.txt<br/>|--- file2.jpg<br/>|--- file2.txt</span></pre><p id="c051" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">所以我有一个<em class="ku"> train </em>、<em class="ku"> valid </em>和<em class="ku"> test </em>文件夹，其中包含图像和相应的文本文件，这些文件在图像上标记了类及其边界框。<br/>然后我创建了一个新文件夹‘pula ’,并将整个数据集复制到该文件夹下的<em class="ku">darknet \ build \ darknet \ x64 \ data \ pula</em>中</p><p id="ff4a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">出于训练目的，我们需要一个文本文件中所有图像文件路径的列表。<br/>为此，我准备了一个小的Python脚本，为训练集和验证集(我现在忽略的测试集)生成这样的文本文件:</p><pre class="ms mt mu mv fd mw mx my mz aw na bi"><span id="782c" class="ky jo hh mx b fi nb nc l nd ne">import glob</span><span id="e13e" class="ky jo hh mx b fi nl nc l nd ne">for dataset in ['train','valid']:<br/>    imglist = glob.glob("data/pula/%s/*.jpg" % dataset, recursive=False)<br/>    <br/>    with open("data/pula/%s.txt" % dataset, 'w', encoding = 'utf-8') as f:<br/>        for img in imglist:<br/>            img = img.replace("\\", "/")<br/>            f.write(img + '\n')</span></pre><p id="c743" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">文件的内容看起来像这样:</p><pre class="ms mt mu mv fd mw mx my mz aw na bi"><span id="ba84" class="ky jo hh mx b fi nb nc l nd ne">data/pula/train/timed_000000259_jpg.rf.24168a1d896b1c57c717ee217e967582.jpg<br/>data/pula/train/timed_000000262_jpg.rf.c98c33d813c019b4e4d64ebb076b94f1.jpg<br/>data/pula/train/timed_000000263_jpg.rf.3c3b031aa46817f2248aad0f65041d1c.jpg<br/>data/pula/train/timed_000000534_jpg.rf.4b77175b4b83fa2cff5b9714e6f70353.jpg<br/>data/pula/train/timed_000000823_jpg.rf.aa55800b7d72d13e0e9e3ec1e64845e9.jpg<br/>...</span></pre><p id="3781" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后将<em class="ku"> coco.names </em>和<em class="ku"> coco.data </em>复制到<em class="ku">darknet \ build \ darknet \ x64 \ data</em>下，并使用新的名称。我用了<em class="ku"> pula.names </em>和<em class="ku"> pula.data </em>然后内容是这样的:</p><pre class="ms mt mu mv fd mw mx my mz aw na bi"><span id="a3cd" class="ky jo hh mx b fi nb nc l nd ne">pula.data</span><span id="d318" class="ky jo hh mx b fi nl nc l nd ne">classes= 3<br/>train  = data/pula/train.txt<br/>valid  = data/pula/valid.txt<br/>names = data/pula.names<br/>backup = backup/</span></pre><p id="ca50" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ku">。数据</em>文件描述了你有多少个类，在哪里可以找到训练和验证集，类的名称是什么，以及临时训练文件必须存储在哪个备份文件夹中。</p><pre class="ms mt mu mv fd mw mx my mz aw na bi"><span id="905f" class="ky jo hh mx b fi nb nc l nd ne">pula.names</span><span id="1941" class="ky jo hh mx b fi nl nc l nd ne">bus<br/>car<br/>person</span></pre><p id="49f6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ku">。names </em>文件只包含类名，与您在Roboflow导出的<em class="ku"> _darknet.labels </em>文件中看到的顺序相同。</p><h2 id="8322" class="ky jo hh bd jp kz la lb jt lc ld le jx ja lf lg kb je lh li kf ji lj lk kj ll bi translated">为训练准备暗网</h2><p id="bd78" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">准备好图像数据集后，我们必须向Darknet添加一些配置，以便能够根据我们自己的数据进行训练。</p><p id="8434" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">首先，复制<em class="ku">darknet \ build \ darknet \ x64 \ CFG \ yolov 4-custom . CFG</em>，使用类似<em class="ku"> yolov4-pula.cfg. <br/> </em>的新名称，我只更改了以下参数，但是您可以自由地更改它们中的任何一个，直到您知道自己在做什么为止:)</p><pre class="ms mt mu mv fd mw mx my mz aw na bi"><span id="3b26" class="ky jo hh mx b fi nb nc l nd ne"># refer to <a class="ae kq" href="https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects" rel="noopener ugc nofollow" target="_blank">https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects</a></span><span id="e460" class="ky jo hh mx b fi nl nc l nd ne">subdivisions=32</span><span id="cc87" class="ky jo hh mx b fi nl nc l nd ne"># this should match your training image size<br/>width=416<br/>height=416</span><span id="3d5d" class="ky jo hh mx b fi nl nc l nd ne"># this should be 2000 * number of classes<br/>max_batches = 6000</span><span id="2139" class="ky jo hh mx b fi nl nc l nd ne"># this should be 80% and 90% percent of max_batches respectively<br/>steps=4800,5400</span><span id="168a" class="ky jo hh mx b fi nl nc l nd ne"># for all [yolo] layers set the number of classes<br/>classes=3</span><span id="e75d" class="ky jo hh mx b fi nl nc l nd ne"># for all [convolutional] layers right before the [yolo] layers change the number of filters to (number of classes + 5) * 3<br/>filters=24</span></pre><p id="c50d" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后从<a class="ae kq" href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137" rel="noopener ugc nofollow" target="_blank">这里</a>下载预先训练好的YoloV4权重文件到<em class="ku">dark net \ build \ dark net \ x64</em>文件夹。</p><p id="27f6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，您可以使用以下命令开始训练Darknet:</p><pre class="ms mt mu mv fd mw mx my mz aw na bi"><span id="8b97" class="ky jo hh mx b fi nb nc l nd ne">darknet.exe detector train data/pula.data cfg/yolov4-pula.cfg yolov4.conv.137</span></pre><p id="3879" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我在我的NVIDIA GeForce RTX 2080 GPU上进行了大约5个小时的培训。在培训过程中，您可以看到一张图表，显示随着批次的增加，损耗是如何减少的。</p><figure class="ms mt mu mv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nm"><img src="../Images/ad7ecc80770f46411adb2cca063b86ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oirdup1Xqf-EQX5Zpjtjvg.png"/></div></div><figcaption class="ng nh et er es ni nj bd b be z dx translated">YoloV4训练期间的损耗图</figcaption></figure><h1 id="bdf1" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">在OpenCV中使用模型</h1><p id="89f3" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">要在OpenCV中使用这个新训练的模型进行对象检测，您只需替换。姓名，。cfg和。在我的github库中找到的<a class="ae kq" href="https://github.com/dschwalm/deeplearning/blob/master/opencv/yolov4_webcam.py" rel="noopener ugc nofollow" target="_blank">检测脚本中的权重文件，以及这些文件的新版本。</a></p><h1 id="d220" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">评估结果</h1><p id="296c" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">有两种方法可以评估结果:</p><ul class=""><li id="1038" class="me mf hh ir b is it iw ix ja mg je mh ji mi jm mj mk ml mm bi translated">通过模型统计评估</li><li id="c56a" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated">通过在检测过程中实际观察模型进行评估</li></ul><p id="a50a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">至于统计数据，您可以使用以下命令让Darknet为您准备一些统计数据:</p><pre class="ms mt mu mv fd mw mx my mz aw na bi"><span id="8b24" class="ky jo hh mx b fi nb nc l nd ne">darknet.exe detector map data/pula.data cfg/yolov4-pula.cfg backup/yolov4-pula_final.weights</span></pre><p id="0db8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这应该为您提供一些类似的统计数据:</p><figure class="ms mt mu mv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nn"><img src="../Images/43ca092dde52ca5a0f22e4e41552d5c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*BPQ3G3D0T57I9qEP8h94Mw.png"/></div></div><figcaption class="ng nh et er es ni nj bd b be z dx translated">YoloV4性能统计</figcaption></figure><p id="9541" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">通过分析这些统计数据，您可以看到该模型在检测汽车方面表现出色，平均精度为93.38%。对于人来说，这一比例约为80%，而对于公共汽车来说，这一比例约为71%。这不是很好，但与默认模型相比，这绝对是一个进步。</p><p id="b000" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们看看模型的运行情况。我上传了一个6分钟的视频到Youtube上。</p><figure class="ms mt mu mv fd ii"><div class="bz dy l di"><div class="no np l"/></div></figure><p id="8848" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一般来说，我对结果比默认模型更满意。但是，仍然会出现一些问题:</p><ul class=""><li id="748e" class="me mf hh ir b is it iw ix ja mg je mh ji mi jm mj mk ml mm bi translated">人有时是不会被发现的，尤其是在背景中</li><li id="c92d" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated">有时，公共汽车站的一部分被检测为人</li><li id="d698" class="me mf hh ir b is mn iw mo ja mp je mq ji mr jm mj mk ml mm bi translated">当两个人走得很近时，他们会被认为是一个人</li></ul><p id="2393" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这些问题可以通过更多的训练图像来解决-</p></div><div class="ab cl nq nr go ns" role="separator"><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv nw"/><span class="nt bw bk nu nv"/></div><div class="ha hb hc hd he"><h1 id="5ff4" class="jn jo hh bd jp jq nx js jt ju ny jw jx jy nz ka kb kc oa ke kf kg ob ki kj kk bi translated">结论</h1><p id="c8f1" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">感谢您通读我的文章。如您所见，如果您想用Darknet创建您自己的定制YoloV4模型，您需要做一些无聊的样板任务，比如从源代码构建OpenCV和Darknet。当注释图像时，事情开始变得更加令人兴奋。你会发现一些有趣的情况，你可能想准备你的模型，使它更健壮。<br/>在你完成培训并看到你的模型实际工作后，那是相当令人满意的:)<br/>所以我鼓励你开始你自己的项目，并在评论中告诉我进展如何。</p></div></div>    
</body>
</html>