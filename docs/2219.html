<html>
<head>
<title>Exploring and Implementing a Contemporary CNN+LSTM Image Captioning Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">探索和实现当代CNN+LSTM图像字幕模式</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/exploring-and-implementing-a-contemporary-cnn-lstm-image-captioning-model-17ca8e01a2b9?source=collection_archive---------19-----------------------#2021-04-12">https://medium.com/analytics-vidhya/exploring-and-implementing-a-contemporary-cnn-lstm-image-captioning-model-17ca8e01a2b9?source=collection_archive---------19-----------------------#2021-04-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="4646" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其他主题包括管理海量数据集和重建他人开发的复杂模型。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/bbfbf54d8a75af3f2239ed6913344976.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6OZT6YC36eFFc-_BiL3bzg.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated"><a class="ae js" href="https://uploads6.wikiart.org/images/m-c-escher/metamorphosis-ii.jpg" rel="noopener ugc nofollow" target="_blank">https://uploads 6 . wiki art . org/images/m-c-escher/变态-ii.jpg </a></figcaption></figure><h1 id="d1c2" class="jt ju hh bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated">再引入</h1><p id="ad46" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">正如我们在<a class="ae js" rel="noopener" href="/analytics-vidhya/deep-learning-for-molecular-translation-b032b90750bc">最初的博客文章</a>中所述，我们目前正在研究、检查和修改深度学习模型，其目的是将骨架公式中表示的分子结构图转换为相应的国际化学标识符(InChI)形式，以便机器学习算法可以更快更有效地解析以前发表的论文和文章，并且可以更容易地记录其中存在的化学成分。[1]</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kw"><img src="../Images/37a91d6794c07053181933b52d0efec7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1ZSfMpp17OtTXe6zSOO8CA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">分子结构图及其对应的英制标签</figcaption></figure><p id="da6c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这将使现代科学家能够更好地获得以前建立的化学，这些化学目前在标准数据库中极难搜索到。希望是，如果可以产生一个复杂的模型，将这些分子图像准确地转换为正确的InChI字符串表示，该领域将能够减少与不完美信息相关的无谓损失，这种信息会导致潜在的冗余研究和发现。新的深度学习方法将使这些模型能够帮助化学公司在研发方面节省大量资金，并将帮助化学等科学领域以更快的速度前进。[1]</p><p id="8a24" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了实现将图像翻译成相应文本字符串的目标，我们将研究一种称为自动图像字幕的技术。正如您可能会怀疑的那样，这个过程远比简单地将图像分类到有限的可能类别更复杂，因为我们试图生成一个特定分子结构所特有的可变长度字符串，因此，为了完成这项任务，我们需要一个更加复杂的模型架构。总的想法是，我们必须使用CNN从图像表示向下到线性特征空间，然后将线性特征空间馈送到一系列LSTM层，这些层将产生期望的预测序列数据输出。由于时间限制和这个问题的高度技术性，我们将专注于探索、研究和修改已经存在的模型，而不是自己从头开始构建它们，我们将在下面阐明和讨论这个项目的范围。不过，总的来说，这种CNN+LSTM模式是我们将尝试实施的解决图像字幕问题的方法和策略。[2]</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kx"><img src="../Images/b9c17893d8cd114ea976c73648a74b99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*670U1iBhcbd9A91Z-B57LA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">自动图像字幕的通用架构[2]</figcaption></figure></div><div class="ab cl ky kz go la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ha hb hc hd he"><h1 id="850e" class="jt ju hh bd jv jw lf jy jz ka lg kc kd ke lh kg kh ki li kk kl km lj ko kp kq bi translated">项目大纲和范围</h1><p id="1b5c" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">这个项目希望实现两个主要目标。正如我们在再次介绍中提到的，我们的第一个目标是通过广泛的研究、学习和复制各种公共笔记本中定义的管道来学习更多关于自动图像字幕的知识。我们相信仔细地走完这个过程本身就是一个令人满意的探索，并且从理解像分子翻译这样复杂的任务的最佳可用代码中可以学到很多东西。在阅读了几本笔记本，确定了常见的障碍，并仔细调查了最成功的管道之后，我们决定使用<a class="ae js" href="https://www.kaggle.com/markwijkhuizen/tensorflow-tpu-training-baseline-lb-16-92" rel="noopener ugc nofollow" target="_blank"> Mark Wijkuizen在Kaggle上的笔记本</a>作为我们项目的焦点。他的过程不仅全面，而且非常适合我们的背景，因为它基于TensorFlow并使用了课堂上介绍的各种技术。此外，他的管道在我们希望更深入理解的熟悉概念和我们希望从零开始学习的全新技术之间提供了一种健康的平衡。当我们通过复制Mark的流程创建基础模型时，我们遇到了以下问题:</p><p id="130c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据预处理</p><ul class=""><li id="5fab" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">装载和清洁(稍后讨论)</li><li id="723f" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">定义词汇映射</li><li id="2ce0" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">探索性数据分析</li><li id="8960" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">图像增强(斑点去除、裁剪、遮蔽等。)</li><li id="1be2" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">转换为TFRecords格式</li></ul><p id="f9f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型构建</p><ul class=""><li id="f12f" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb lp lq lr ls bi translated">解码TFRecords</li><li id="e31f" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">创建训练和验证数据集</li><li id="4234" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">定义编码器、注意力和解码器</li><li id="0783" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">构建模型架构(稍后讨论)</li><li id="bd09" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">学习率调度程序</li><li id="c5df" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">定义损耗和Levenshtein距离</li><li id="7366" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">培训日志和历史</li><li id="784f" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb lp lq lr ls bi translated">预言；预测；预告</li></ul><p id="5ad3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的第二个目标是使用课堂上讨论的概念和技术对我们的基本模型进行明显的改进。这将是我们最后一篇博文的主题。在这篇文章中，我们主要关注基本模型的构建。由于Mark的笔记本提供了这一过程的完整文档，因此我们不会详细讨论上述每个组件。相反，我们给出了数据加载和清理过程中的一些收获，我们的模型架构的总结，以及一些初步的结果。</p></div><div class="ab cl ky kz go la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ha hb hc hd he"><h1 id="b121" class="jt ju hh bd jv jw lf jy jz ka lg kc kd ke lh kg kh ki li kk kl km lj ko kp kq bi translated">数据加载和清理</h1><p id="d1c4" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">在构建任何模型之前，仔细考虑数据加载和清理过程总是很重要的。在我们的<a class="ae js" rel="noopener" href="/analytics-vidhya/the-conclusion-to-classifying-cassava-leaf-diseases-using-convolutional-neural-networks-4dc6e5c7b5a0">中期项目</a>中，我们利用TFRecords格式将我们的数据加载到模型中。TFRecords是一种二进制存储格式，专门用于加快TensorFlow中内置模型的性能和训练时间，即使只有大约20，000幅训练图像，重新格式化数据所带来的便利和效率提升也是显著的。</p><p id="862c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在发现我们有多达240万张训练图像可用于这项任务后，很明显我们将重新审视这种格式。然而，与木薯叶Kaggle竞赛不同，BMS分子翻译竞赛没有以TFRecords格式提供其训练数据。幸运的是，Mark的笔记本提供了一种从零开始执行这种转换过程的简明方法(事实上，这是我们选择复制他的过程的主要原因)，但是，即使这样，为转换准备图像也不是一项简单的任务。[3]</p><p id="5945" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于我们在Google Colab中完成了所有的编码工作，我们面临着两种选择。我们要么必须将所有数据上传到压缩文件夹中的Google Drive，然后解压缩该文件夹，要么首先解压缩包含我们数据的文件夹，然后将图像批量上传到我们的驱动器。虽然第一种策略会更简单，但Colab Pro没有足够的磁盘空间来解压缩文件夹，而不会中途崩溃。因此，我们被迫批量上传图像，然后将其转换为TFRecords格式。</p><p id="089a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，仅仅加载和清理数据就花了几天时间，凸显了这个经常被忽视的过程的重要性。即使在我们的数据被正确格式化为TFRecords之后，我们也必须想办法通过谷歌云存储(GCS)将其上传到云中，以使训练过程与TPUs兼容。不用说，模型的好坏取决于它的数据，而且不得不花更多的时间准备数据而不是训练实际的模型，这种情况并不少见。我们认为记录我们在这方面的努力是很重要的，因为我们从其他资源(如媒体文章)中学到了很多关于如何正确预处理数据的知识。我们希望这一部分能够为其他人提供有用的见解，帮助他们在未来在大型数据集上训练模型。</p><p id="491e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于那些对图像清理和词汇映射过程的技术方面感兴趣的人，我们建议参考所附的笔记本，但这里我们将给出一个非常简短的概述。</p><p id="28fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了定义与我们的问题空间相关的标记词汇，我们可以简单地运行不同的InChI训练字符串标签，并使用下面的代码块提取所有唯一的字符。请注意，我们还必须手动添加特殊的词汇外(OOV)标记'<start>'、<end>'和“<pad>'，因为模型将需要这些来解释和处理可变长度的字符串。</pad></end></start></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ly"><img src="../Images/ea47faa9491937b805ed621d90fc4317.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/1*i1hrUNduR7iOr-6QOVO8wQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">定义记号的词汇</figcaption></figure><p id="593c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦定义了词汇表，我们就可以创建将记号映射到数字的字典，反之亦然，我们应该将它保存为pickle文件，以便将其存储在GCS中，并能够从其他笔记本中访问它。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lz"><img src="../Images/b18337eefaa3257484b9b2b4bc4b9c5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KnskznR5TSWqMUzn-gXp_w.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">字典将记号映射到数字，反之亦然</figcaption></figure><p id="893c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在转到本节的最后一个主题，当谈到图像清理时，我们只想稍微润色一下图的质量，因为有些图中填充了无关的像素，或者有些线没有完全连接，或者有许多未使用的空间没有携带相关信息，所以大多数预处理都涉及尝试从图像中删除任何噪声，锐化结构线的分辨率，并将图像裁剪为更合适的大小。有关详细信息，请参见代码，但这里描述的是预处理的效果。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ma"><img src="../Images/df808d830799764cc370d47185c3cf63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d3zEkbpfu9CP8OrDM8DuVw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">处理前后的分子结构图像示例</figcaption></figure></div><div class="ab cl ky kz go la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ha hb hc hd he"><h1 id="763e" class="jt ju hh bd jv jw lf jy jz ka lg kc kd ke lh kg kh ki li kk kl km lj ko kp kq bi translated">模型架构</h1><p id="f669" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">随着数据加载和清理部分的完成，我们现在可以将注意力转向被训练和用于解决这个复杂的图像字幕问题的实际模型。正如在第一部分中提到的，我们要使用的一般架构是一个预先训练的CNN，上面添加了LSTM层，以便从图像生成到文本生成。现在为了更清楚地定义这一点，我们将把注意力集中在<a class="ae js" href="https://www.kaggle.com/markwijkhuizen/tensorflow-tpu-training-baseline-lb-16-92" rel="noopener ugc nofollow" target="_blank"> Mark的笔记本</a>中呈现的模型上。虽然该模型可以概念化为具有两个不相交的部分，CNN基层和LSTM层，但我们实际上可以更准确地描述它的编码器和解码器框架，以及这两个组件如何通过注意力连接。为了依次介绍这些元素，让我们首先解释编码器和与之相关的CNN。</p><p id="6b13" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">编码器是模型的一部分，它将获取预训练CNN的扁平输出，并将这些嵌入到隐藏状态中，该隐藏状态随后将用于帮助解码，并生成最终的预测文本字符串输出。对于该模型，CNN incorporated是具有预训练的“嘈杂学生权重”的EfficientNetB0，这将产生将被展平并在编码器中使用的特征图。这个EfficientNetB0将产生包含14x8特征图的1280个通道，因此，一旦这些被展平，我们将有1280x112维的输出。这些将成为编码器的输出。编码器的结构可以在下面的代码块中看到，并且还提供了一个输出示例。在这种情况下，我们的批量大小为2，因此形状将为(2，1280，112)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mb"><img src="../Images/334949b3d33894790329a146d2fe1fc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mIt-W5ND_7tEDrJFnnIAJQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">编码器类</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mc"><img src="../Images/a26ab502d5488061951dd159a439f8ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qF3tqSmPkF_XOc1IzIm3KA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">编码器架构</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es md"><img src="../Images/05cd05725627890bf1f05d243fe2966b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TWGLoB-Ta0xx4iCB6hzGOQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">编码器输出形状</figcaption></figure><p id="5856" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在定义了编码器之后，我们现在必须考虑如何以适当的方式将注意力应用于这些隐藏状态，以便为解码器提取最相关的信息。在这个模型中，我们将使用Bahdanau注意类，权重应用于隐藏状态和编码器值。在乘以权重之后，我们将取两个分量之和，对它们应用tanh激活，并在对所有序列令牌取softmax之前对它们进行缩放，以确定哪些位置产生与解码器预测最相关的结果。从下面定义关注类的代码和输出的形状可以看出，我们将为序列中的每个元素获得一个关注权重值，在这种情况下，它等于通道的数量(1280)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es me"><img src="../Images/95c43e4ec7f4bf4c171b45600fd5148f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tu-hmmJMZmXOwMboMjSTpA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">巴赫达瑙注意班</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mf"><img src="../Images/9ea6f0ed8076cdb97f2eb1e0c7427a0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O1Gz3WeE-GDGHUIRHy-HYQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">注意力输出形状</figcaption></figure><p id="41b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">定义了注意力模式后，我们剩下要做的就是构建解码器，并将三部分结合在一起。解码器的结构比其他两个要复杂得多，我们强烈建议您查看上面提到的笔记本或本文末尾列出的Github库，但我们不打算在这里深入讨论细节，以免陷入太多的技术问题。[4]本质上，关键点是解码器将在编码器的最终状态被初始化，并且它将把嵌入的字符和来自注意机制的上下文连接到LSTM层，该层然后将创建隐藏状态和当前预测值。总的来说，该过程将导致从词汇表的41种可能性中预测出一个字符，并且该预测值将被用作下一时间步的嵌入字符。从下面的概述中可以看出解码器的架构，并且还显示了其输出形状的示例。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mg"><img src="../Images/5538f1964d46bee79e47ff045fa5723f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KR6zuxMEt1dIaEdGUXDlTQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">解码器架构</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mh"><img src="../Images/399f9097a293fcc5b944e07d3518bd9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*00MGg1gQSKRiCgR7eLGoHQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">解码器输出形状</figcaption></figure><p id="6892" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦我们这样配置了我们的模型，我们就能够开始在我们的数据的一个小子集上训练它，以确保一切都正常工作，并产生合理的输出。我们还没有扩大模型正在训练的数据集的规模，但我们在这一点上已经经历了足够的训练，我们能够看到这个过程中的一些一般趋势，并可以分享我们将在此基础上发展的初步发现。</p></div><div class="ab cl ky kz go la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ha hb hc hd he"><h1 id="ed66" class="jt ju hh bd jv jw lf jy jz ka lg kc kd ke lh kg kh ki li kk kl km lj ko kp kq bi translated">初步结果</h1><p id="ce48" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">在这一点上，我们已经能够让我们的模型可靠地产生结果，没有任何故障或错误，但是，由于我们迄今为止以尽可能精益的方式训练它，只是为了获得概念的证明，我们将能够在下周对其进行显著改进，我们当前的结果并不特别有意义或令人信服。在我们的分钟数据(子)集上训练模型，我们实现了下面描述的初始训练指标。第一个感兴趣的度量是训练损失，在这种情况下被定义为稀疏分类交叉熵。正如你从前面的图表中看到的，正如我们所预期的，随着时间的推移，损失在稳步减少，但鉴于我们当前的培训流程是多么精益，我们显然还有巨大的改进空间。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mi"><img src="../Images/0703243a6be67e36955b0c78750c4be9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-u1LWYbbggy4eV2N14qnBA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">整个时期的训练损失</figcaption></figure><p id="af1c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在训练过程中，我们还可以可视化定义为稀疏分类准确性的训练准确性，并且我们还发现它正在如我们所希望和预期的那样增加。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mj"><img src="../Images/1e4e296afc5295fa2d8b8bc8ae8602c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*p50eKeZnqGvm1aIdTP8l7w.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">整个时期的训练精度</figcaption></figure><p id="ead4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了更具体地了解模型的功能和输出形式，我们还可以在预测标签和真实标签旁边绘制输入图像，如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mk"><img src="../Images/1e671cae532d552e2b17ac12d7195d61.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-aUFnbi2zvGMDVOuo0q9Rg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">样本图像及其相应的预测和实际标签</figcaption></figure><p id="8c40" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如您所看到的，预测的字符串有几个区域看起来与实际字符串的区域大致相似，但它也陷入了一个循环，在中间反复输出3个字母的“PBb”。这显然并不理想，但也完全在意料之中，因为我们还没有真正能够在任何大量数据上训练我们的模型。因此，虽然这些初步结果在这一点上并不特别有意义，因为我们刚刚建立了我们的精益概念验证模型，现在我们已经建立了我们的管道并且模型正常工作，我们可以采取必要的下一步措施，为我们的模型提供更合适的数据量来进行训练，并从中学习更多实质性的重要关系。</p></div><div class="ab cl ky kz go la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ha hb hc hd he"><h1 id="ca36" class="jt ju hh bd jv jw lf jy jz ka lg kc kd ke lh kg kh ki li kk kl km lj ko kp kq bi translated">后续步骤</h1><p id="5a21" class="pw-post-body-paragraph ie if hh ig b ih kr ij ik il ks in io ip kt ir is it ku iv iw ix kv iz ja jb ha bi translated">随着我们进入该项目的最后一周，我们的主要重点是扩大我们的训练和验证数据集的规模，并能够在更适当的信息量上训练模型。开始时，当试图正确地组织和管理提供给我们的大量数据来解决这个问题时，有许多困难，但是，现在我们已经更牢固地掌握了如何以TFRecords的形式方便地操作、存储和传输图像文件，这应该是一种相对简单的方法来显著提高我们的模型的性能。除此之外，更重要的是，我们现在终于能够将我们自己的想法和贡献添加到我们现有的模型架构中了。目前，正在实现的模型是在这个<a class="ae js" href="https://www.kaggle.com/markwijkhuizen/tensorflow-tpu-training-baseline-lb-16-92" rel="noopener ugc nofollow" target="_blank"> Kaggle笔记本</a>中找到的模型的略微修改的复制品，但是，现在我们已经完成了所有的重建和调试，我们可以开始根据课堂上介绍的理论和想法对它进行积极的修改。这是这个项目令人兴奋的部分，也是我们能够从数据管理和清理过渡到应用真正的深度学习技术来尝试并建立一个复杂任务的现有模型的点。</p><p id="0fdb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们期待继续取得进步，进一步了解这些强大的深度学习工具，使我们能够解决像这样的有意义的问题，我们很高兴能够更接近我们的目标，即识别和开发一个能够成功地将分子结构图转化为相应的InChI标签表示的模型。请继续关注我们下周的最后一期节目！</p><p id="396e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个项目的代码可以在我们的<a class="ae js" href="https://github.com/ethan21814/TensorFlow-Bros-Final-Project" rel="noopener ugc nofollow" target="_blank"> Github资源库</a>中找到。</p></div><div class="ab cl ky kz go la" role="separator"><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld le"/><span class="lb bw bk lc ld"/></div><div class="ha hb hc hd he"><p id="bdfc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">关于作者:Ethan Huang和我(Griffin McCauley)都是布朗大学应用数学专业的大三学生。此外，我是男子大学越野队和田径队的成员，也是经济系的助教，伊森是NFL平台Starting Eleven的主席和学术导师。</p><p id="8ce1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">鸣谢:该项目基于百时美施贵宝-分子翻译Kaggle竞赛(【https://www.kaggle.com/c/bms-molecular-translation】T4)，是数据科学倡议硕士项目中布朗大学数据2040课程(数据科学中的深度学习和专题)的一部分。</p><p id="e430" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">参考资料:</p><ol class=""><li id="89a1" class="lk ll hh ig b ih ii il im ip lm it ln ix lo jb ml lq lr ls bi translated"><a class="ae js" href="https://www.kaggle.com/c/bms-molecular-translation" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/bms-molecular-translation</a></li><li id="e05f" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb ml lq lr ls bi translated"><a class="ae js" href="https://www.analyticsvidhya.com/blog/2018/04/solving-an-image-captioning-task-using-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2018/04/solving-an-image-captioning-task-using-deep-learning/</a></li><li id="d5d8" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb ml lq lr ls bi translated"><a class="ae js" href="https://www.kaggle.com/markwijkhuizen/advanced-image-cleaning-and-tfrecord-generation" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/markwijkhuizen/advanced-image-cleaning-and-TF record-generation</a></li><li id="c1e9" class="lk ll hh ig b ih lt il lu ip lv it lw ix lx jb ml lq lr ls bi translated"><a class="ae js" href="https://www.kaggle.com/markwijkhuizen/tensorflow-tpu-training-baseline-lb-16-92" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/markwijkhuizen/tensor flow-TPU-培训-基线-lb-16-92 </a></li></ol></div></div>    
</body>
</html>