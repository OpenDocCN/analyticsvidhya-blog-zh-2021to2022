<html>
<head>
<title>Using Twitter Data to explore the Impact of Covid-19 in Africa</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用推特数据探索新冠肺炎在非洲的影响</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/using-twitter-data-to-explore-the-impact-of-covid-19-in-africa-bdb8d3adf346?source=collection_archive---------17-----------------------#2021-06-30">https://medium.com/analytics-vidhya/using-twitter-data-to-explore-the-impact-of-covid-19-in-africa-bdb8d3adf346?source=collection_archive---------17-----------------------#2021-06-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/af209519673c4f6227dbf587b4ebeebe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vi7SS09LOS5ag47CdMFkWg.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">在<a class="ae it" href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上由<a class="ae it" href="https://unsplash.com/@muthengimbuvi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> muthengi mbuvi </a>拍摄的照片</figcaption></figure><p id="9c50" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从2019年12月开始，全世界都在对抗一种叫做冠状病毒的传染病。随着行动限制和居家命令的实施，Twitter等社交媒体平台已成为用户相互保持联系的唯一手段和表达他们对疫情的担忧、意见和感受的渠道。在这些充满挑战的时期，人们使用Twitter来感谢一线卫生工作者，并在困难时期相互扶持。另一方面，Twitter也是大量错误信息和负面推文的地方，对这种疾病产生了不必要的焦虑。</p><p id="753d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这篇文章中，我选择通过使用Twitter数据的仪表板来探索COVID19对人们生计的影响。我们构建的系统将让我们深入了解COVID19对人们生活的影响。该系统将有助于了解人们对COVID 19的知识、态度和看法。它将揭示人们对covid19的一些常见误解，从而有助于抗击该疾病的努力，如疫苗的有效分发。</p><p id="4d55" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在本文的最后，我们将建立一个使用Twitter数据的系统。这些数据是使用关键词“covide19”和“非洲”收集的。将会有一个全自动的MLOps管道，使用推文的情绪和推文中讨论的主题来分析Twitter应用程序数据。最后，我们将部署一个控制面板，让我们能够使用Streamlit来研究调查结果。</p><h1 id="8451" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">GitHub链接</h1><div class="kq kr ez fb ks kt"><a href="https://github.com/eandualem/Twitter-Data-Analysis" rel="noopener  ugc nofollow" target="_blank"><div class="ku ab dw"><div class="kv ab kw cl cj kx"><h2 class="bd hi fi z dy ky ea eb kz ed ef hg bi translated">ean dualem/Twitter-数据分析</h2><div class="la l"><h3 class="bd b fi z dy ky ea eb kz ed ef dx translated">从2019年12月开始，全世界都在对抗一种叫做冠状病毒的传染病。与……</h3></div><div class="lb l"><p class="bd b fp z dy ky ea eb kz ed ef dx translated">github.com</p></div></div><div class="lc l"><div class="ld l le lf lg lc lh in kt"/></div></div></a></div><h1 id="4254" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">数据析取</h1><p id="21e3" class="pw-post-body-paragraph iu iv hh iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr ha bi translated">如前所述，我们将使用从Twitter收集的数据，使用关键字“covide19”和“Africa”。数据采用JSON格式，包含6532行。我们首先从JSON文件中提取pandas数据帧。一个<strong class="iw hi">数据帧</strong>是一个二维大小可变的、潜在异构的表格数据结构，带有标记轴(行和列)。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="f783" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">函数read_json读取json文件，并返回包含单个tweets的JSON列表。TweetDfExtractor类将tweets JSON解析成pandas数据帧。在这里，我从高音数据中提取了15列。提取列后，我们创建一个包含15列的zip文件。然后，我们使用pandas生成一个数据帧，并将其保存到名为“processed_tweet_data.csv”的文件中。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lt"><img src="../Images/634e3d8bbe8e992400198574ace54989.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WxzRzdypuCuHKKo6pDYwKA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">从json提取的数据</figcaption></figure><h1 id="9eb8" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">方法</h1><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lu"><img src="../Images/2486fe470b76a52ad29637a0c418cd5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u-SwE0GBTu9ChRi1NJwUjg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">系统设计</figcaption></figure><p id="4593" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在我们有了熊猫数据框中的数据。我们可以谈谈整个系统。对于这个项目，我们将遵循MLOps级别1，即ML管道自动化。MLOps是一个工程学科，旨在统一ML系统开发(dev)和ML系统部署(Ops ),以标准化和简化生产中高性能模型的持续交付。</p><p id="5300" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">该架构将允许快速实验，并且使用基于使用Travis的实时管道触发器的新数据，在生产中自动训练该模型。</p><h1 id="dd67" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">数据预处理</h1><p id="8798" class="pw-post-body-paragraph iu iv hh iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr ha bi translated">在探索或创建模型之前，我们需要对数据进行预处理。删除不需要的列或从一些列中提取特定数据，清理包含实际tweet文本的original_text列，最后将所有列转换为正确的数据类型。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="628f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面是使用Clean_Tweets类进行预处理要做的事情列表。</p><ul class=""><li id="be51" class="lv lw hh iw b ix iy jb jc jf lx jj ly jn lz jr ma mb mc md bi translated">使用熊猫读取processed_tweet_data.csv文件。</li></ul><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="fd0d" class="mj jt hh mf b fi mk ml l mm mn">tweets = pd.read_csv("../processed_tweet_data.csv")</span></pre><ul class=""><li id="af0c" class="lv lw hh iw b ix iy jb jc jf lx jj ly jn lz jr ma mb mc md bi translated">如果数据框中有任何重复，我们将删除它们。</li></ul><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="6f02" class="mj jt hh mf b fi mk ml l mm mn">ct = Clean_Tweets()<br/>tweets = ct.drop_duplicate(tweets)</span></pre><ul class=""><li id="df1c" class="lv lw hh iw b ix iy jb jc jf lx jj ly jn lz jr ma mb mc md bi translated">删除非英语推文和lang专栏。在放弃非英语推文后，我们不再需要阿郎专栏。</li></ul><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="ca80" class="mj jt hh mf b fi mk ml l mm mn">tweets = ct.remove_non_english_tweets(tweets)<br/>tweets.drop(['lang'], axis=1, inplace=True)</span></pre><ul class=""><li id="aac6" class="lv lw hh iw b ix iy jb jc jf lx jj ly jn lz jr ma mb mc md bi translated">从original_text列中删除链接、标点符号、数字和特殊字符。</li></ul><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="1830" class="mj jt hh mf b fi mk ml l mm mn">tweets = ct.remove_links(tweets)<br/>tweets = ct.remove_special_characters(tweets)</span></pre><ul class=""><li id="ef0f" class="lv lw hh iw b ix iy jb jc jf lx jj ly jn lz jr ma mb mc md bi translated">数据集中有两种类型的hashtags。那些在hashtag列中的和那些在original_text中提到的。我们将清理两者，并在单独的列中输出主题。</li></ul><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="lr ls l"/></div></figure><ul class=""><li id="54b9" class="lv lw hh iw b ix iy jb jc jf lx jj ly jn lz jr ma mb mc md bi translated">我们从user_mantiodsns列中提取屏幕名称，从source列中提取设备。</li></ul><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="lr ls l"/></div></figure><ul class=""><li id="0758" class="lv lw hh iw b ix iy jb jc jf lx jj ly jn lz jr ma mb mc md bi translated">将包含文本的所有列转换为小写。</li></ul><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="ae55" class="mj jt hh mf b fi mk ml l mm mn">tweets = ct.to_lower(tweets)</span></pre><ul class=""><li id="7dea" class="lv lw hh iw b ix iy jb jc jf lx jj ly jn lz jr ma mb mc md bi translated">将所有列转换为正确的数据类型</li></ul><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="8e1b" class="mj jt hh mf b fi mk ml l mm mn">tweets = ct.convert_to_string(tweets)<br/>tweets = ct.convert_to_numbers(tweets)<br/>tweets = ct.convert_to_boolean(tweets)<br/>tweets = ct.convert_to_numbers(tweets)</span></pre><ul class=""><li id="adfa" class="lv lw hh iw b ix iy jb jc jf lx jj ly jn lz jr ma mb mc md bi translated">填写缺失的值</li></ul><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="26df" class="mj jt hh mf b fi mk ml l mm mn">tweets["possibly_sensitive"].fillna(False, inplace=True) tweets["place"].fillna(" ", inplace=True)</span></pre><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mo"><img src="../Images/e74de43984d96799cb527d122c6fd4b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V7gkrtwhjIlShAaBDeSCuQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">清洗后的数据帧</figcaption></figure><p id="e7f2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">以上所有步骤都在<a class="ae it" href="https://github.com/eandualem/Twitter-Data-Analysis/blob/main/notebooks/preprocessing.ipynb" rel="noopener ugc nofollow" target="_blank">预处理. ipynb </a>笔记本中用数据探索和可视化进行了详细解释。我们通过将最终数据框保存到clean_tweets.csv来结束本节。</p><h1 id="485a" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">数据探索和可视化</h1><p id="3dab" class="pw-post-body-paragraph iu iv hh iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr ha bi translated">现在让我们试着深入了解一下这些数据。例如，谁是最热门的推文作者，一个人平均发了多少条推文，推文中最常提到的词，使用的热门推文标签，极性(“积极”、“消极”、“中立”)比率。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mp"><img src="../Images/bc0162ee1fcc8931773e89a95c2c199f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8XVwIRGXXlQRl4Jz5yaHxQ.png"/></div></div></figure><p id="9db0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正如我们所见，原作者的平均值是1.24，这意味着大多数推文来自独特的个人，除了一个离群者，他在总共5248条推文中发了530条。这是有问题的，因为我们不希望一个人的观点影响我们的模型。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mq"><img src="../Images/31d6c03c782aae6b94e515a5e61297fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ie5XJNLBSz9aVwjGl9fR6g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">Tweets极性反对他们的受欢迎程度。</figcaption></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mr"><img src="../Images/8a1419d48330edab24a35b3f667c99a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ch4PHIAvPMX0zNe8jBvMUQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">推特的主观性与受欢迎程度相反。</figcaption></figure><p id="febf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以看到积极的推文有最多的转发、收藏、关注者和朋友。客观的推文拥有最多的收藏夹、关注者和朋友。客观的推文转发次数最多。我们的数据集中没有非常主观的推文，这将是我们的问题之一。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ms"><img src="../Images/d01836a47c526b7face613f4ec602ff4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iR_BXne11aNI45Ga4thJ5w.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">反对原作者的推文极性。</figcaption></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mt"><img src="../Images/8a3ed8e1340a3e14200bacbd55c1d664.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-VU_E3qz4EJKz2jTwr_Lng.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">推文的极性与制造它们的设备相反。</figcaption></figure><p id="a0d0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">上面两个图显示了原创作者的数量和产生推文的设备的数量。我们可以从设备名称疫苗查找器中看到，我们收到了500多条推文，都是负面的。这意味着一半的负面推文来自这个设备。如果你还记得的话，我们已经在一些推文中发现了一个异常值。名为“puneupdater”的用户正在使用该设备。这意味着一个人发了几乎一半的负面推文，1277条中的530条。</p><p id="1cec" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是一个很大的数据流。好消息是，当数据发生变化时，我们的系统会自动重新训练。该系统将能够重新培训和服务于新的模式。我在<a class="ae it" href="https://github.com/eandualem/Twitter-Data-Analysis/blob/main/notebooks/preprocessing.ipynb" rel="noopener ugc nofollow" target="_blank">预处理. ipynb </a>笔记本里做了更多的探索和可视化。</p><h1 id="19cc" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">主题建模</h1><p id="a9bc" class="pw-post-body-paragraph iu iv hh iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr ha bi translated">主题建模是一种无监督的机器学习技术，能够扫描一组文档，检测其中的单词和短语模式，并自动聚类单词组和最能表征一组文档的类似表达。</p><p id="409a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们从主题建模开始，因为它不需要预先定义的标签列表。这意味着我们不是在训练以前被人类分类的数据。</p><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="6a12" class="mj jt hh mf b fi mk ml l mm mn">df = pd.DataFrame(columns=['clean_text'])<br/>df['clean_text'] = tweets['original_text']</span></pre><p id="32e3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们已经完成了大部分预处理步骤。在这里，我们将继续删除停用词。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mu"><img src="../Images/c0be495691a4c48d2a4d743caf57b48d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VkuFQuHzQLqbwL3yNtLg8w.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">文档中的前10个单词</figcaption></figure><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="de65" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">此图像显示了文档中的前10个单词。正如我们所看到的，大多数都是停用词。我们删除它们是因为它们不影响文本的语义，并且经常(但不总是)这样做可以提高模型的性能。</p><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="a510" class="mj jt hh mf b fi mk ml l mm mn">sentence_list = [sent for sent in df['clean_text']] <br/>word_list = [sent for sent in sentence_list]</span></pre><p id="2f95" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在下一步是标记化。<strong class="iw hi">记号化</strong>是一种将一段文本分割成称为记号的更小单元的方法。这里，标记可以是单词、字符或子单词。在这里，我们将推文标记成单词。</p><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="8d6a" class="mj jt hh mf b fi mk ml l mm mn">lemmatizer = WordNetLemmatizer()<br/>word_list_lematized = []<br/>for w in word_list:<br/>  word_list_lematized.append([lemmatizer.lemmatize(x) for x in w])</span></pre><p id="c13d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">然后我们做词条释义，这是一个将单词的屈折形式组合在一起的过程。词元化允许我们将这些词作为一个单独的项目来分析，通过词的词元来识别。</p><p id="b9bc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有两种主要的主题建模方法。<em class="mv">潜在语义分析(LSA)和潜在狄利克雷分配(LDA)。两者都基于</em>相同的潜在假设:分布假设(即相似的主题使用相似的词)和统计混合假设(即文档谈论几个主题)，可以确定统计分布。如果你想深入了解这个主题，有一个关于Federico Pascual的<a class="ae it" href="https://monkeylearn.com/blog/introduction-to-topic-modeling/" rel="noopener ugc nofollow" target="_blank">主题建模</a>的博客。</p><p id="0ca4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里，我们将使用LDA将我们语料库中的每条tweet映射到一组主题，这些主题涵盖了tweet中的大量单词。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="0fb2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">结果:</strong></p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mw"><img src="../Images/ad379e320cdc7eebc7ca26c464c47866.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JrGHIrJuUFh_GkjDX7UVvA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">通过LDA执行的主题建模的可视化</figcaption></figure><h1 id="ec31" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">情感分析</h1><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="bf59" class="mj jt hh mf b fi mk ml l mm mn"><strong class="mf hi"># Import the libraries</strong><br/>import tweepy<br/>from textblob import TextBlob<br/>from wordcloud import WordCloud<br/>import pandas as pd<br/>import numpy as np<br/>import re<br/>import matplotlib.pyplot as plt<br/>plt.style.use('fivethirtyeight')</span></pre><p id="6277" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> <em class="mv">“情感分析</em> </strong> <em class="mv">:对一段文字中所表达的观点进行计算识别和分类的过程，尤其是为了确定作者对某一特定话题、产品等的态度。是积极的，消极的，还是中性的。”—牛津英语词典</em></p><p id="910e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将建立一个模型，可以分析我们预处理的推文，并能够判断推文背后的情绪。</p><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="6958" class="mj jt hh mf b fi mk ml l mm mn">df = pd.DataFrame(columns=['clean_text', 'polarity'])<br/>df['clean_text'] = tweets['original_text']<br/>df['polarity'] = tweets['polarity']</span></pre><p id="02ab" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们首先创建一个包含纯文本和极性列的新数据框。</p><pre class="ln lo lp lq fd me mf mg mh aw mi bi"><span id="3245" class="mj jt hh mf b fi mk ml l mm mn">def text_category(p):<br/>  if p &gt; 0:<br/>    return "positive"<br/>  elif p &lt; 0:<br/>    return "negative"<br/>  else:<br/>    return "neutral"</span><span id="1881" class="mj jt hh mf b fi mx ml l mm mn">df["polarity"] = df["polarity"].apply(text_category)<br/>df = df[df['polarity'] != 'neutral']</span></pre><p id="7474" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里，我们使用text_category函数将极性从float转换为category数据。然后，我们删除了中性极性的推文。这将允许我们创建一个模型，将推文分类为正面或负面。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="5682" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里，我们首先构建一个名为scoremap的列。它将正极性映射为1，负极性映射为0。然后我们将输入数据(cleaned_text)和输出数据(score_map)分离为(X，y)。最后，在将数据分成训练数据和验证数据之后，我们使用函数train_and_showscore来训练模型。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="bb83" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">结果:</strong>训练准确率为1.0，验证准确率为0.96。这表明模型过度拟合。考虑到我们在数据探索部分的数据中发现的流程，这是意料之中的。</p><h1 id="2bb5" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">细流</h1><p id="a712" class="pw-post-body-paragraph iu iv hh iw b ix li iz ja jb lj jd je jf lk jh ji jj ll jl jm jn lm jp jq jr ha bi translated"><a class="ae it" href="https://streamlit.io/" rel="noopener ugc nofollow" target="_blank"> Streamlit </a>是一个开源的Python库，可以轻松创建和共享漂亮的定制web应用程序，用于机器学习和数据科学。在这里，我们通过使用Streamlit构建一个web应用程序来完成我们的工作。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="c328" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面是创建存储Pandas数据框的表的模式。有用于在MySQL数据库中存储clean_data.csv和在文件夹<a class="ae it" href="https://github.com/eandualem/Twitter-Data-Analysis/tree/main/mysql%20and%20streamit" rel="noopener ugc nofollow" target="_blank"> mysql_and_streamit </a>中创建Streamlight web app的类。这是来自网络应用的一些页面。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es my"><img src="../Images/6f756880fea6982e7145c521aaf29cfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UwhesXiQNRXGnu4M_qjcGw.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mz"><img src="../Images/c38e34e8e2bdfc93edc842434e9ac62b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U55TiL0EuYGNZIZBIjRVsA.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es na"><img src="../Images/cd8b4abc5e255800f9f8f5cbaec3564c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jVCG8d5F3d1KKmrak4e5yA.png"/></div></div></figure></div><div class="ab cl nb nc go nd" role="separator"><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng nh"/><span class="ne bw bk nf ng"/></div><div class="ha hb hc hd he"><p id="9031" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[1]:谷歌。机器学习中的连续交付和自动化管道。<a class="ae it" href="https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning" rel="noopener ugc nofollow" target="_blank">https://cloud . Google . com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning</a></p><p id="1aaa" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[2]:费德里科·帕斯夸尔(2019年9月26日)。主题建模:导论。<a class="ae it" href="https://monkeylearn.com/blog/introduction-to-topic-modeling/" rel="noopener ugc nofollow" target="_blank">https://monkey learn . com/blog/introduction-to-topic-modeling/</a>。</p><p id="a5e3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">[3]:哈什特·泰亚吉。什么是m lops——入门必备知识。<a class="ae it" href="https://towardsdatascience.com/what-is-mlops-everything-you-must-know-to-get-started-523f2d0b8bd8" rel="noopener" target="_blank">https://towards data science . com/what-is-mlops-everything-you-must-know-to-get-started-523 f 2d 0 b 8 BD 8</a>。</p></div></div>    
</body>
</html>