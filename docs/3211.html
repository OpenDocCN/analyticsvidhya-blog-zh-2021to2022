<html>
<head>
<title>Grammatical Error Correction Using Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用神经网络的语法错误纠正</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/grammatical-error-correction-using-neural-networks-aaf3e9fc91c?source=collection_archive---------1-----------------------#2021-06-19">https://medium.com/analytics-vidhya/grammatical-error-correction-using-neural-networks-aaf3e9fc91c?source=collection_archive---------1-----------------------#2021-06-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/020e61312523763c35cf55e96687a366.png" data-original-src="https://miro.medium.com/v2/resize:fit:1370/format:webp/0*hfLIlRjjQPUwBxY3.png"/></div><figcaption class="il im et er es in io bd b be z dx translated"><a class="ae ip" href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10489-020-01980-1&amp;psig=AOvVaw21ox4DuMEecL90mkal2FS2&amp;ust=1624187307808000&amp;source=images&amp;cd=vfe&amp;ved=0CAwQ3YkBahcKEwjInuG2x6PxAhUAAAAAHQAAAAAQAw" rel="noopener ugc nofollow" target="_blank">来源</a></figcaption></figure><h1 id="a5f0" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">目录</h1><blockquote class="jo jp jq"><p id="e007" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">1.介绍</p><p id="a5c5" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">2.商业问题</p><p id="4fdf" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">3.文献评论</p><p id="5cf7" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">4.数据集概述</p><p id="0568" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">5.将商业问题映射到机器学习问题</p><p id="21f7" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">6.数据清理</p><p id="79b8" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">7.探索性数据分析</p><p id="5587" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">8.准备好数据模型</p><p id="7ead" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">9.建模</p><p id="07f1" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">10.最佳模型的误差分析</p><p id="7e45" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">11.最终管道和部署</p><p id="f239" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">12 .未来的工作</p><p id="1e4e" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">13.参考</p><p id="b8b0" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">14.结束注释</p></blockquote><h1 id="a7ee" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">1-简介</h1><p id="3d1b" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">当你读到这句话<strong class="ju hi"> <em class="jt">“她喜欢在公园里玩，每周都来这里”你会怎么想</em> </strong>如果你懂英语，你可能会说这个句子语法不正确，正确的句子应该是<strong class="ju hi"> <em class="jt">“她喜欢在公园玩，每周都来这里。”</em>T9】</strong></p><p id="88be" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">嗯，对我们来说并不太难，如果我们懂英语，但是我们能让计算机理解并纠正一个不正确的句子吗？</p><p id="e978" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">现在你可能想知道为什么我需要这样做。嗯，答案是，每个人都需要它，无论你是给客户写邮件，还是为理想的工作写求职信，还是参与社交媒体帖子，拼写或语法错误会分散注意力，使提议看起来不专业，我们肯定希望避免这种情况，以留下好印象。</p><p id="7ce5" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">现在明显的问题是，我们如何做到这一点？</p><p id="d026" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">为了做到这一点，在自然语言处理文献中有各种各样的技术，从基于规则的分类方法到最先进的深度学习方法。</p><p id="bee4" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">在这篇博客中，我将使用神经网络来解决这个问题，并指导你建立一个端到端的管道。</p><p id="3d39" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi">先决条件- </strong>我已经假设读者熟悉深度学习概念，但是我仍然对几乎每个概念都给出了直观的解释，并且我还提供了关于某个主题的另一个博客链接以了解更多细节。</p><h1 id="bb5e" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">2-业务问题</h1><h2 id="5250" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">2.1-问题描述</h2><p id="74a8" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">语法错误纠正是自动纠正文本中语法错误的任务。</p><p id="8eff" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">语法纠错系统将错误的句子作为输入，并期望发现所有上述错误，将句子转换成正确的版本。例如–</p><ul class=""><li id="1544" class="lm ln hh ju b jv jw jz ka ks lo ku lp kw lq kp lr ls lt lu bi translated"><strong class="ju hi">错误句子1:<em class="jt"/></strong><em class="jt">她昨晚看见汤姆在公园被警察抓住了</em></li><li id="df9d" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated"><strong class="ju hi">纠正句子1:<em class="jt"/></strong><em class="jt">她昨晚看见汤姆在公园被警察抓住了</em></li><li id="5cc8" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated"><strong class="ju hi">错误句子二:<em class="jt"/></strong><em class="jt">这不只是你的事。”</em></li><li id="7850" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated"><strong class="ju hi">第二句纠正:<em class="jt"/></strong><em class="jt">关你屁事。”</em></li></ul><h2 id="de47" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">2.2-业务用例</h2><p id="8f96" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">句子纠正系统有许多应用，其中一些如下:</p><ul class=""><li id="37db" class="lm ln hh ju b jv jw jz ka ks lo ku lp kw lq kp lr ls lt lu bi translated">母语学生以及第二语言学习者可以使用语法纠错系统作为写作工具来帮助他们提高写作水平。</li><li id="bad8" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated">句子纠正系统可以作为许多应用程序的后期编辑器，如机器翻译。</li><li id="057a" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated">它也可以用在文字处理器中检查写作中的语法错误。即使在写这篇博客的时候，我也在使用语法纠错系统。</li></ul><h2 id="0b5a" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">2.3-业务限制</h2><ul class=""><li id="12f6" class="lm ln hh ju b jv kq jz kr ks ma ku mb kw mc kp lr ls lt lu bi translated"><strong class="ju hi">严格的延迟限制</strong>因为这是一个交互式应用程序，我们希望尽可能快地对用户做出响应。</li><li id="d19e" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated"><strong class="ju hi">可解释性部分很重要</strong>，因为用户不会问为什么你的模型会做出这样的预测，但是有一个可解释的模型是很好的，因为它有助于我们理解模型的行为。</li></ul><h2 id="0929" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">2.4-业务指标</h2><p id="85de" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">业务指标定义了项目的成功或失败，它有助于评估项目可能产生的业务影响。</p><p id="23dd" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我们应该选择一个业务指标，使其与我们的绩效指标密切相关。</p><p id="5c48" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">对于这个问题，我把业务度量作为“在句子总数中，有多少句子被我们的系统完美地纠正了”。</p><h1 id="88fa" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">3-文献调查</h1><p id="5c7f" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">我参考了这篇名为<strong class="ju hi">语法错误检查系统:方法回顾和新兴方向</strong>的论文，做了大量的文献调查，可以在这里<a class="ae ip" href="https://www.researchgate.net/publication/344160222_Recent_Trends_in_the_Use_of_Deep_Learning_Models_for_Grammar_Error_Handling" rel="noopener ugc nofollow" target="_blank">找到</a></p><p id="27bd" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">在本文中，作者展示了以前使用多种方法的语法错误纠正系统，从基于<strong class="ju hi">规则的</strong>、<strong class="ju hi">基于句法的</strong>等旧学派方法到一些现代方法，如<strong class="ju hi">统计建模</strong>、<strong class="ju hi">基于机器学习的方法</strong>，它们还包括最近最先进的<strong class="ju hi">基于深度学习的方法</strong>，其中包括递归神经网络。</p><p id="e3a9" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi">下面我总结了所有的技巧:</strong></p><p id="f612" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> <em class="jt">基于规则:</em> </strong>基于规则的检查使用一组预定义的规则(错误模式)来匹配文本。所有的规则都是手工开发的。如果文本与其中一个规则匹配，则认为它是错误的。</p><p id="0aa5" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><em class="jt">上述方法的优点:</em>易于理解和扩展，规则可以增量添加。</p><p id="4b75" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><em class="jt">上述方法的缺点:</em>随着不同错误案例的出现，语法的复杂性增加，这需要大量的劳动和专业知识</p><p id="7f90" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> <em class="jt">基于句法:</em> </strong>在这种方法中，对文本的词法和句法进行全面分析。它需要一个词汇数据库、一个词法分析器和一个解析器。根据语言的语法，解析器给每个句子一个语法树结构。如果完全解析不成功，这意味着文本是错误的。</p><p id="02f4" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><em class="jt">上述方法的优点:</em>如果定义的语法覆盖了语言的所有潜在句法规则，语法检查器将能够检测出所有不正确的句子，而不管错误的性质如何。</p><p id="d3e6" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><em class="jt">上述方法的缺点</em>:不可能向用户指定确切的错误是什么。为了克服这个问题，需要额外的规则。</p><p id="603a" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> <em class="jt">统计建模:</em> </strong>它是通过在大量句子上训练模型，并根据训练语料库中观察到的单词组合的计数，为一个新的单词序列分配一个概率，从而获得语言学知识的任务。</p><p id="3161" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">在语料库中经常出现的常见的和更可能的序列可以被认为是正确的，而不常见的序列可能包含错误。</p><p id="63a8" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><em class="jt">上述方法的优点</em> <strong class="ju hi"> <em class="jt"> : </em> </strong>不需要很深的语法知识，可以用来开发与语言无关的系统。</p><p id="3280" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><em class="jt">上述方法的缺点</em> <strong class="ju hi"> <em class="jt"> : </em> </strong>它需要非常大的语料库，并且得到的结果难以理解。</p><p id="f77b" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> <em class="jt">基于机器学习(分类)</em> </strong>在这种方法中，训练分类器来学习特定词类的模型，以处理特定的错误类型。</p><p id="9b7a" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">它使用错误站点的直接上下文中的标记作为特征，例如n-grams和语法关系。这些特征被嵌入到向量中，并且使用朴素贝叶斯和支持向量机等来训练分类器。</p><p id="7dff" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><em class="jt">上述方法的优点</em> <strong class="ju hi"> <em class="jt"> : </em> </strong>使用这种方法，通过将文本中的原始单词与模型预测的最合适的候选单词进行匹配，来检测和纠正先前未发现的错误。</p><p id="2f93" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><em class="jt">上述方法的缺点</em> <strong class="ju hi"> <em class="jt"> : </em> </strong>由于每个分类器纠正单一类型的错误，这忽略了句子中单词之间的依赖关系。</p><p id="1027" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> <em class="jt">基于深度学习:</em> </strong>这种方法越来越受欢迎，因为与机器学习不同，深度学习模型不需要特征工程，因为神经网络可以自动学习它们。</p><p id="466b" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">这是一个很大的优势，因为特征工程在时间方面要求很高，并且还需要领域专业知识。</p><p id="1908" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">bahdanau等人提出的注意机制架构被Yuan和Briscoe用于使用RNNs执行从不正确的句子到格式良好的句子的序列到序列映射。</p><p id="707c" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><a class="ae ip" href="https://arxiv.org/abs/1603.09727" rel="noopener ugc nofollow" target="_blank">谢等人</a>也在字符级使用了<a class="ae ip" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank"> bahdanau注意机制</a>而不是单词级的序列对序列神经模型，因为单词级模型有OOV词的问题。虽然该模型处理OOV词，但它不能有效地利用词级信息。</p><p id="063a" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><em class="jt">上述方法的优点:</em>同样的架构可以用来构建独立于语言的GEC系统。</p><p id="0739" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><em class="jt">上述方法的缺点</em> <strong class="ju hi"> <em class="jt"> : </em> </strong>优质训练数据稀缺。</p><h1 id="6ba6" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">4:数据集概述</h1><p id="484f" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">这个问题的最大挑战之一是高质量大型数据集的可用性，但幸运的是，对于英语来说，我获得了合理数量的数据。</p><p id="a1e5" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">要获取数据，我们可以使用以下方法:-</p><p id="2697" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> 4.1-收集所有公开可用的数据集- </strong>少数此类数据集为“<em class="jt">计算语言学协会(ACL)数据”、“参加剑桥大学出版社(CLC-FCE)提供的第一个英语证书的英语学习者的考试脚本”、“新加坡国立大学英语学习者语料库(NUCLE)”、“AESW数据”</em>和“<em class="jt"> Lang-8英语学习者数据集语料库”</em>。</p><p id="6ebf" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> 4.2-在正确的句子中产生人为错误- </strong>这可以通过编写程序在正确的句子中故意犯一些语法错误，给出不正确的标点符号，替换句子中一个单词的一两个字符串等来实现。基本上，这里的想法是从正确的句子中创建一个不正确的句子。</p><p id="f7cc" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">这样做的一个主要缺点是，很难通过计算来复制这些错误，而这将由一个不太懂英语的人来完成。</p><p id="8b9c" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> 4.3-手动创建数据集- </strong>我们并不太重视这一部分，但我们应该意识到，所有好的数据集，如Imagenet、SQUAD等，都是经过数千小时的手动工作手动标记的，只有这样才有可能得出好的结果。</p><p id="915f" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">对于这个问题，我选择了Lang-8语料库的学习者英语数据集，因为由于计算能力有限，为了建立第一次切割模型，这种数据量是足够合理的，它超过了所有其他数据集的总和。</p><p id="67c3" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我从<a class="ae ip" href="https://docs.google.com/forms/d/e/1FAIpQLSflRX3h5QYxegivjHN7SJ194OxZ4XN_7Rt0cNpR2YbmNV-7Ag/viewform" rel="noopener ugc nofollow" target="_blank">这个来源</a>中获取了这个数据，它是M2格式的，由一行后跟S组成，表示原句，而一行后跟A表示编辑注释一个不正确的句子有不止一个注释</p><p id="6f4b" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">数据格式示例:</p><p id="6eeb" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">昨晚我看电视时听到了一句话。<br/> A 8 9|||R:动词:时态|||正在观看|||必选| | |-无-|||0</p><p id="34da" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我们认识才半年，但他的课很有趣。A 13 14|||R:名词:NUM | | | lessons | | | REQUIRED | |-NONE-| | | 0<br/>A 14 15 | | | R:动词:SVA | | | were | | | REQUIRED | |-NONE-| | | | 0</p><p id="55cd" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">lang8.train.auto.bea19.m2文件大小为144 MB，包含1037562个句子</p><p id="3754" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">为了从上面的数据集中提取一对正确的和不正确的句子，可以使用下面的代码片段。</p><h1 id="cd0c" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">5-将业务问题映射到机器学习问题</h1><h2 id="8fb1" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">5.1-机器学习问题的类型</h2><p id="befa" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">在这种情况下，输入是一个语法不正确的句子，输出是一个语法正确的句子，所以我们可以把这个问题公式化为一个序列到序列的学习问题。</p><h2 id="6e40" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">5.2-绩效指标</h2><p id="ca26" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">在文献调查中，我发现有一堆性能度量标准，如<em class="jt">胶水分数</em>、<em class="jt"> F1分数</em>、<em class="jt"> m平方</em>等，但每种度量标准都有自己的优点和局限性。这个问题我选了<em class="jt">胶分。</em></p><p id="50c7" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> GLEU score: </strong>为了计算GLUE score，我们取输出和目标序列中的所有子序列1、2、3或4个标记，然后计算召回率和精度，召回率是目标序列中匹配n-gram的数量与总n-gram的数量之比，精度是生成的输出序列中匹配n-gram的数量与总n-gram的数量之比。</p><p id="e15a" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> GLEU评分简单来说就是召回率和准确率的最小值。</strong></p><p id="0370" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">它的范围在0到1之间，0表示最差的胶合分数，1表示最好的胶合分数。</p><p id="7888" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">GLEU评分可用于评估模型在训练和推理过程中的表现。</p><h2 id="3c4b" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">5.3-列车测试分离</h2><p id="f426" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">在继续之前，让我们将数据集分为训练、交叉验证和测试数据，我们将对训练数据本身进行所有分析。</p><p id="2097" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我保留80%的数据用于训练，10%用于交叉验证，剩下的10%用于测试数据。</p><h1 id="dad9" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">6-数据清理</h1><p id="76e6" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated"><em class="jt">“垃圾进，垃圾出”——</em>是机器学习圈子里的老生常谈。任何从事机器学习的人都知道，数据的质量是决定结果质量的一个重要参数。</p><h2 id="6c58" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">6.1-以合适的格式存储数据</h2><p id="7de2" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">正如我们上面讨论的，给定的数据集是m2格式的，所以我们将把它转换成一对正确和不正确的句子，然后把它存储为一个CSV文件。</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h2 id="f865" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">6.2-删除同一对正确和不正确的句子</h2><p id="4bf6" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">当我手动分析数据时，我发现有些句子有相同的一对正确和错误的句子。</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="bd00" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">移除后，我们只剩下1037562个句子中的498362个。</p><h2 id="7df3" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">6.3-检查重复值和空值</h2><p id="a9dd" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">数据集中存在空值和重复值，因此我们应该删除它们。</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="f6aa" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">删除重复和空值后，我们剩下496339个句子。</p><h2 id="17d8" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">6.4-从数据集中删除垃圾字符</h2><p id="a455" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">数据集中有许多字符不是英语的一部分，所以我们将删除它们，为此我们将使用正则表达式。</p><p id="cc4f" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">在像情感分析这样的NLP任务中，我们可以做更多的文本清理和预处理，如词干提取、停用词移除、将每个字符转换成小写字母等。但是这些步骤对我们的问题是不敬的。</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h1 id="760a" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">7-探索性数据分析</h1><p id="a24d" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated"><strong class="ju hi">探索性数据分析</strong>是对数据进行初步调查的过程，以发现模式，发现异常，并找到有助于建模和业务决策的有意义的模式。</p><p id="1b82" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">在今天的世界中，模型被美化了很多(特别是对于数据科学的初学者)，但是如果你做了适当的数据清理、ed a和特征工程(特别是对于ML模型)，你的简单模型可以胜过疯狂的集合。</p><p id="6b13" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我希望你现在已经明白EDA的重要性了，所以开始做吧。</p><h2 id="ec56" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">7.1-分析句子的长度</h2><p id="cbef" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">让我们绘制PDF，并对正确句子的长度进行百分位数分析。</p><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mj"><img src="../Images/0ee2f387265a3fdcfe52954f21f2c6be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kxu5JQtfbQcJv6fczYOjxQ.png"/></div></div></figure><p id="0a03" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">基于PDF，我们可以看到大多数句子长度小于50，极少数句子长度超过50。</p><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mo"><img src="../Images/42c218c960a029976ed1d3d61374b487.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*moFPPXlAACYWD6d8fzlXgg.png"/></div></div></figure><p id="2047" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">基于百分位数分析，我们可以看到90%的输出(正确)句子长度小于22，99%的输出句子长度小于38。</p><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mp"><img src="../Images/e465b0230af00bc2d8f13cc60dabc48f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x1sazEqQ8vDWKPVlKpuTEw.png"/></div></div></figure><p id="dfba" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">基于PDF，我们可以看到大多数句子的长度小于50，极少数句子的长度超过50，这里的行为与输出句子相同</p><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mq"><img src="../Images/f7d590cb69e1219e5a8cdbc7efff85f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sLnrRhpI06HAaphFARy9Hg.png"/></div></div></figure><p id="01a4" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">基于百分位数分析，我们可以看到90%的输入(正确)句子长度小于23，99%的输出句子长度小于38。</p><p id="2f78" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">因此，我们将从数据集中删除那些长度超过25的句子，我们也可以将阈值限制保持在38，但这在计算上将是昂贵的。</p><h2 id="e440" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">句子中的独特单词(正确的句子)</h2><p id="1f08" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">独特单词对模型具有显著影响，因为模型的参数数量将随着独特单词数量的增加而增加。</p><p id="9c1f" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">如果在给定输入和先前单词的情况下，我们选择具有最大概率的单词时，唯一的单词更多，那么即使是推断也会很麻烦。</p><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mr"><img src="../Images/56fbc8793998b8ce914698484e035c01.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cVjQe-w8yJvUZ0v0P1EFhw.png"/></div></div></figure><p id="9235" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我们可以看到，在输入和输出句子中分别有87564，68105个唯一词</p><h2 id="57f5" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">使用词云的频繁词分析</h2><p id="bbe6" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">单词云是一种用于表示文本数据的数据可视化技术，其中每个单词的大小指示其频率或重要性。</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="ea4e" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">现在我们来分别看一下输出和输入句子的词云输出</p><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es ms"><img src="../Images/f40ed1eac0f610ab6927ae26b6fec8af.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pnaLy-CBR1jqY-VKEZ4c0Q.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated"><strong class="bd is">输出(正确)句子的词云</strong></figcaption></figure><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mt"><img src="../Images/a3ccce385af27f64f37567107f18e4e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fkUPkbdYLq_vobPJC48XBA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated"><strong class="bd is">用于输入(不正确)句子的词云</strong></figcaption></figure><p id="f700" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">基于词云，我们可以看到，像“今天”、“喜欢”、“想要”、“想”这样的词在输入和输出句子语料库中出现频率最高。</p><h1 id="870c" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">8-准备好数据模型</h1><p id="fab4" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">让我们对数据进行一些转换，使其适合输入到模型中。</p><h2 id="941e" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">8.1-添加句首和句尾标记</h2><p id="3a69" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">对于我们的问题，编码器解码器似乎是一种合适的架构，在这种架构中，编码器逐字获取输入句子，然后解码器将“句子开始”令牌作为输入，并进行预测，该预测被发送到解码器的输入，用于下一个时间戳，并且该过程继续，直到解码器预测“句子结束”。</p><p id="fd0b" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">因此，我们将分别在输出句子的开头和结尾添加“@”来表示“句子的开始”(这将是解码器输入)，并添加“$”来表示“句子的结尾”(这将是解码器输出)。</p><p id="c5d8" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">例如，在对句子“我很好”进行上述操作后，解码器输入将是“@我很好”，解码器输出将是“我很好$”</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h2 id="2987" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">8.2-标记化和填充</h2><p id="9749" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">在进行数据清理之后，我们已经扔掉了垃圾数据，并且在进行EDA之后，我们对我们的数据有了更好的理解，但是我们的数据仍然是文本形式的，这既不适合馈送到深度学习模型，</p><p id="cb3b" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">让我们对数据进行标记，这意味着每个唯一的单词将被分配给一个唯一的整数，我们将标记输入和输出，因为两者都是文本，但对于情感分析等任务，我们只需要标记输入，对于图像字幕，我们只需要标记输出。</p><p id="bd3b" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">标记化真的很简单，Keras提供了一个内置函数来做这件事。完成标记化之后，我们还将保存这个标记化器，以便在运行时使用。</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="ff70" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">这里我使用了char_level = True，因为我将把它用于字符级模型，但对于单词级模型，我们将保持它为False。</p><p id="7bac" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">现在，我们的输入和输出句子有不同的长度，所以将用零填充较短的句子，使长度相等，这样我们就可以批量训练它们，否则我们将不得不保持批量大小为1，训练将非常慢。</p><p id="9fcb" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">通过使用内置函数，可以在Keras中轻松完成填充。</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h2 id="6009" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">8.3-将文本转换为矢量</h2><p id="ca25" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">在标记化之后，我们的数据集是整数的形式，但是它们仍然没有语义，并且单词的语义对于NLP相关的任务非常重要。</p><p id="a4a8" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">现在我们将它们转换成向量，这样这些词就有了语义，例如，让我们用三个词苹果，香蕉和老虎，这里苹果和香蕉的向量之间的距离与老虎相比要小，因为苹果和香蕉都是水果，而老虎是完全不同的。</p><p id="c626" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">现在，为了做到这一点，我们可以使用预训练的单词嵌入，如<strong class="ju hi">手套、</strong> <strong class="ju hi">单词到vec </strong>、<strong class="ju hi">快速文本</strong>嵌入，或者我们可以使用<strong class="ju hi"> Keras嵌入层</strong>。</p><p id="11c6" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">对于这个问题，我将同时使用嵌入层和快速文本嵌入，这将在下一节讨论。</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h1 id="ba7d" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">9-建模</h1><p id="6739" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">现在我们已经到了真正有趣的开始部分，所以现在我们将尝试多种模型，但这里需要注意的重要一点是，虽然我在实际解决这个现实世界的问题时只使用了深度学习，但我们应该尝试使用我上面描述的所有方法的组合。</p><p id="33b2" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我们将从一个简单的模型开始，然后转向更复杂的模型，因为模型越复杂，它的性能就越好，但同样，在性能与训练和推理时间之间有一个权衡，复杂的模型也很难生产。</p><h2 id="cd26" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">9.1-编码器解码器字级模型</h2><p id="ca50" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">编码器解码器模型由LSTM或GRU单元组成，编码器读取输入序列，并以隐藏和单元状态的形式总结信息，用于初始化解码器，并在初始字处将<em class="jt">句子开始标记</em>传递给解码器，我们期望模型预测序列中的下一个字。</p><p id="1adc" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">现在，我们应该将这个预测的单词作为输入传递给下一个时间戳中的解码，但这仅在推断期间完成，在训练期间，我们使用<a class="ae ip" href="https://machinelearningmastery.com/teacher-forcing-for-recurrent-neural-networks/" rel="noopener ugc nofollow" target="_blank">教师强制</a>。</p><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/1988552dbc737b496c7f5d66ebdb20ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*7Qij1rBrhM2W8pbuVjiR6w.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">来源:<a class="ae ip" href="https://towardsdatascience.com/sequence-to-sequence-model-introduction-and-concepts-44d9b41cd42d" rel="noopener" target="_blank">https://towards data science . com/sequence-to-sequence-model-introduction-and-concepts-44d 9 b41 CD 42d</a></figcaption></figure><p id="a9d5" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">让我们使用Keras中的自定义模型来实现这个模型</p><p id="0bd6" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">定义编码器类别</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="5b57" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">定义解码器类别</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="b5d3" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">定义编码器-解码器类</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="4d0a" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">定义模型参数并训练模型</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/283affe1f77668bfeb69f75a562ea6ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*whXjVsbw-1wglXbM2DD_Lw.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">模型摘要</figcaption></figure><p id="bee7" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">损失与纪元图</p><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es mv"><img src="../Images/7d428dd73e7f5c20b785787fa33243f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*v7hEgLQWwCzuo7kevckjtA.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">蓝线表示CV，红线表示训练损失</figcaption></figure><p id="0358" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">根据测试数据获得的损耗和胶合分数是0.74和0.17</p><h2 id="d27c" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">9.2:编码器解码器字符级模型</h2><p id="cb46" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">我们也将尝试使用字符级模型，因为它比单词级模型有一些优势，例如:</p><p id="3851" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">它可以处理词汇表之外单词(这些单词存在于训练数据中，但不存在于测试数据中)</p><p id="38fc" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">与单词级模型相比，参数的数量更少，因为唯一字符的数量非常少(我们的数据集为63个)</p><p id="c6e2" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">这个代码几乎与单词级模型相同，这就是为什么我不写代码，你可以参考我的<a class="ae ip" href="https://github.com/mridul1012/Grammatical-Error-Correction-with-Neural-Networks" rel="noopener ugc nofollow" target="_blank"> Github </a>简介。</p><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/3be02dea09e3e244068be7b498249d07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*UEewEB-s7JgoxOxZSg2cNg.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">模型摘要</figcaption></figure><p id="2acd" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我已经用256个LSTM细胞和1024的批量训练了25个纪元。</p><p id="945d" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">根据测试数据获得的损耗和胶合分数是0.17和0.21</p><h2 id="ab72" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">9.3:具有快速文本嵌入的编码器解码器字级模型</h2><p id="0ff6" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">我们也将尝试快速文本嵌入，因为它有如下一些优点:</p><p id="7333" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">可训练参数总数减少</p><p id="70a7" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">各种尺寸(50、100、200、300)可用于预拉伸嵌入，并可根据需要使用。</p><p id="661a" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">当训练数据较少时，最好使用预训练嵌入。</p><p id="66ae" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">对于代码部分没有重大变化，所以我只显示编码器的相关代码，同样可以用于解码器。</p><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/410b3d3cbe2aaf286a97f4bbcc21c84b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*fRbzQnGD0L761OFEQ_D4iA.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">模型摘要</figcaption></figure><p id="832f" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">损失与纪元图</p><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/cb0dd15afac8973370b7a30ac93f33ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:718/format:webp/1*xgLDseJkr3AyC-YFfsF2UA.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">培训损失(在培训时，我忘记传递CV数据，所以这只是培训损失)</figcaption></figure><p id="44d9" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我已经用64个LSTM单元(最好使用200个以上的单元，但由于计算限制，我只使用了64个)和1024的批量训练了50个纪元。</p><p id="8fdf" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">根据测试数据获得的损耗和胶合分数是0.57和0.26</p><h2 id="d0e3" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">9.4:基于注意力的单词级模型</h2><p id="4bde" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">到目前为止，没有一个模型给出令人满意的结果，现在让我们尝试一些复杂的模型，这些模型已经在其他类似的NLP任务中被证明是好的，如机器翻译。</p><p id="e6ad" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">为此，由于计算限制，我尝试了Luong attention的点评分功能，尽管您可以尝试bahdanu attention和general and concat评分功能。</p><p id="3849" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">所以简单讨论一下注意机制的工作。</p><p id="6018" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">在编码器/解码器模型中，我们只使用最后一个隐藏状态来初始化解码器，这是编码器/解码器的主要问题，对于较长的句子来说更为严重。</p><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mx"><img src="../Images/373873c5073f55e58225e3248dff3a14.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dlUGLDyQp9r_pUEtlTYA_A.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">来源:https://blog.floydhub.com/attention-mechanism/<a class="ae ip" href="https://blog.floydhub.com/attention-mechanism/" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="bed4" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">注意力模型通过使用来自每个时间戳的编码器的隐藏状态来解决这个问题，同时对每个单词进行预测(关于注意力的更多细节请参考这个漂亮的<a class="ae ip" href="https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/" rel="noopener ugc nofollow" target="_blank">博客</a>)。)</p><p id="8c89" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">让我们使用自定义层在Keras中实现注意力模型。</p><p id="17b4" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">注意，编码器与编码器-解码器相同，因此我们将从解码器开始。</p><p id="983e" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">关注层(点评分功能)</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="364a" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">一步解码器</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="7a0c" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">解码器类别:-</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="dceb" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">编码器-解码器类别:-</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/286d9ce6fbe91da9df2579e70346e933.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*rpbIqc4qFpztB30OjKXcHw.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">模型摘要</figcaption></figure><p id="bf3b" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我已经用64个LSTM细胞和256的批量训练了100个纪元。</p><p id="c59b" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">根据测试数据获得的损耗和胶合分数是0.64和0.53</p><h2 id="46f6" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">9.5:使用1D CNN编码器的基于注意力的单词级模型</h2><p id="dc18" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">从注意力模型中获得的结果是好的，但是让我们通过使我们的模型更加复杂来进一步改进它。</p><p id="f94d" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">为此，我们将增加一个与LSTM单元平行的1D CNN层，并将两个输出(来自LSTM和CNN)相加，并使用该输出来初始化我们的解码器。</p><p id="7a40" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">在解码器中，将没有变化，我们将像以前一样只关注LSTM细胞。</p><p id="ce64" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">下面是修改后的编码器的代码片段。</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es my"><img src="../Images/88fd38b65274cecd0f0e4a409a796b12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IgznRw2o54IpUBEdi-aQfA.png"/></div></div></figure><p id="48bd" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">损失与纪元图</p><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es mz"><img src="../Images/cb15f4162a02a0f06496275cdbad008f.png" data-original-src="https://miro.medium.com/v2/resize:fit:734/format:webp/1*1zKmbGdCVneyNTezVvEdJw.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">蓝线表示CV，红线表示训练损失</figcaption></figure><p id="c1c5" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我已经用128个LSTM细胞和512的批量对此进行了10个时期的训练。</p><p id="66ce" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">根据测试数据获得的损耗和胶合分数是2.09和0.12</p><p id="2b43" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">由于10个纪元后模型表现不佳，我没有进一步训练它。</p><h2 id="9e49" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">9.6:基于注意的词级模型，三角学习率</h2><p id="e3ae" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">到目前为止，我们已经使用了初始学习率为0.001的Adam optimizer，但这里有一些问题:</p><p id="3cf2" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我们的模型对初始学习率敏感，并且为了找出初始学习率，需要大量的超参数调整，这显然需要时间和计算资源，即使在所有这些之后，也不能保证模型将下降到低损失区域。</p><p id="2026" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">因此，为了解决这个问题，我们可以使用三角学习率，在这种情况下，我们将学习率限制在下限和上限之间，学习率在它们之间振荡。</p><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es na"><img src="../Images/df678c32a5656fc8b2f4387ffa0e9eba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/0*MXYojfN21MVG73OE.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">来源:<a class="ae ip" href="https://www.pyimagesearch.com/2019/07/29/cyclical-learning-rates-with-keras-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">https://www . pyimagesearch . com/2019/07/29/cyclic-learning-rates-with-keras-and-deep-learning/</a></figcaption></figure><p id="fa7f" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">完成实验后，当学习率达到最佳时，损失会急剧下降，如果你提高或降低学习率，损失可能会再次增加。</p><figure class="md me mf mg fd ii er es paragraph-image"><div class="ab fe cl nb"><img src="../Images/fb86ddf7884c128b1671a6e65732cfe5.png" data-original-src="https://miro.medium.com/v2/format:webp/1*VAmbyfpR0_-gP0oIla0Vjw.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">来源:<a class="ae ip" href="https://www.datacamp.com/community/tutorials/cyclical-learning-neural-nets" rel="noopener ugc nofollow" target="_blank">https://www . data camp . com/community/tutorials/cyclic-learning-neural-nets</a></figcaption></figure><p id="11bb" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">因此，这个最优学习率可以用作全局学习率，并且模型可以被再次训练，这减少了在尝试多个学习率时浪费的时间。</p><p id="4261" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">关于三角学习率的更多细节，你可以参考<a class="ae ip" href="https://www.pyimagesearch.com/2019/07/29/cyclical-learning-rates-with-keras-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">这个</a>和<a class="ae ip" href="https://www.datacamp.com/community/tutorials/cyclical-learning-neural-nets" rel="noopener ugc nofollow" target="_blank">这个</a>博客。</p><p id="92b8" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">要使用三角学习率，我们可以在Keras中实现自定义回调。</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="5418" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">损失与纪元图</p><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es nc"><img src="../Images/0eae88a942ca828dd2aca16a0e53659b.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*MmxdMk3YwzVNAqr3xuDaLg.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">蓝线表示CV，红线表示训练损失</figcaption></figure><p id="42d4" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">最初，我用128个LSTM细胞和512个批量训练了10个时期。</p><p id="9118" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">在所有模型中，根据测试数据获得的损耗和胶合分数最差。</p><p id="e2a2" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">由于10个纪元后模型表现不佳，我没有进一步训练它。</p><h1 id="c7ee" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">10:最佳模型的误差分析</h1><h2 id="8e69" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">10.1:总结所有实验</h2><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es nd"><img src="../Images/cae01725e2cec5114b32c7d9a3644a39.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*qD5v12SdbG-ykx8howufcA.png"/></div></figure><p id="f597" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">因此，我们最好的模型是注意力模型，所以现在我们将对此模型进行错误分析，以找出数据和胶水分数之间的模式。</p><h2 id="1dfd" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">10.2:胶水分数的箱线图和百分位数分析</h2><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es ne"><img src="../Images/9a74ee0d9a688598a18467cb2a9bb863.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d6wHJ1I7RcYdSfRgBd6lEA.png"/></div></div></figure><figure class="md me mf mg fd ii er es paragraph-image"><div class="er es nf"><img src="../Images/782ef6b7f86fba2d034a5009983b0160.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*9rTJ-VU9Cq4r3pksFaQfMw.png"/></div></figure><h2 id="f338" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated"><strong class="ak">观察结果</strong></h2><p id="93e5" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">1-最小胶合分数为0 <br/> 2-最大胶合分数为1 <br/> 3-胶合分数中值为0.52 <br/> 4-胶合分数的IQR范围从0.33到0.7</p><h2 id="4397" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">结论</h2><p id="ed9f" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">基于以上分析，我们将胶水分数分为三类:低、中、高</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h2 id="0f76" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">观察</h2><p id="5080" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">1-基于低、中、高胶合分数的输入句子的平均长度分别是10.56、11.9和12.03</p><p id="3816" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">2-基于低、中、高胶合分数的输入句子的中值长度分别是10.0、11、12</p><h2 id="89f6" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">10.3:总单词和唯一单词的分析</h2><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es ng"><img src="../Images/64e041bc35e57c3707e6bd480e6aa9d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oho7auQA0EcySV_g9TMJ3w.png"/></div></div></figure><h2 id="5859" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">10.4:分析一对不正确和正确句子之间的常用词</h2><figure class="md me mf mg fd ii er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es nh"><img src="../Images/3bb7562a21f8903c29fee22c3ee393a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m5maTKLNeOV5U-yrNSfdnQ.png"/></div></div></figure><h2 id="14f4" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">10.5:误差分析总结</h2><p id="1b44" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">1-基于低、中、高胶合分数的输入句子的平均长度是10.56、11.9、12.03。<br/> 2 -基于低、中、高胶合分数的输入句子的中值长度是10.0、11、12。<br/> 3 -低中高胶字唯一号分别为1200，1408，935。<br/> 4 -低、中、高胶合分数不正确和正确句子对之间的平均共同单词数分别为10.04、11.17和11.3。</p><h1 id="6c4e" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">11-最终管道和部署</h1><p id="ebb0" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">定义推理的预测函数:-</p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h2 id="e252" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">做预测</h2><blockquote class="jo jp jq"><p id="8fbc" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">今天我收到了我的一个郎朋友发来的消息</p><p id="ec96" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated"><strong class="ju hi">模型预测- </strong>今天收到郎的一个朋友发来的消息</p><p id="b70e" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">但是我今天必须参加托业考试</p><p id="69e3" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">但是我今天必须参加托业考试</p><p id="c1a0" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">我和丈夫每个周末都去杂货店购物</p><p id="11d7" class="jr js jt ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">模型预测- 我和丈夫每个周末都去杂货店购物</p></blockquote><p id="e05d" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我已经使用Flask在我的本地系统上部署了这个模型。</p><p id="1bbd" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi">烧瓶应用:- </strong></p><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="mh mi l"/></div></figure><h2 id="353a" class="ky ir hh bd is kz la lb iw lc ld le ja ks lf lg je ku lh li ji kw lj lk jm ll bi translated">工作演示:-</h2><figure class="md me mf mg fd ii"><div class="bz dy l di"><div class="ni mi l"/></div><figcaption class="il im et er es in io bd b be z dx translated">工作演示</figcaption></figure><p id="05ca" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">注意-视频中显示的预测并非对所有句子都准确。</p><h1 id="808a" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">12-未来的工作</h1><p id="0b53" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">计算能力和更大的数据集是我在研究这个问题时面临的两个主要问题。</p><p id="3107" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">因此，下面是一些可以实现更好结果的工作。</p><ul class=""><li id="57bf" class="lm ln hh ju b jv jw jz ka ks lo ku lp kw lq kp lr ls lt lu bi translated">可以使用更复杂的模型基于变压器的模型，其已经在其他序列中被证明是最先进的，以对像机器翻译这样的学习任务进行排序。</li><li id="7957" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated">通过用更多的超参数调谐来增加LSTM单元的数量，该模型可以被训练用于更多的时期。</li><li id="2da4" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated">在大量数据的基础上建立模型。</li><li id="8f2d" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated">在所有的模型中，我使用了简单的LSTM，但是也可以使用双向lstm。</li></ul><h1 id="ec91" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">13-参考文献</h1><ul class=""><li id="f08e" class="lm ln hh ju b jv kq jz kr ks ma ku mb kw mc kp lr ls lt lu bi translated"><a class="ae ip" href="https://arxiv.org/abs/1508.04025" rel="noopener ugc nofollow" target="_blank">基于注意力的神经机器翻译的有效方法</a></li><li id="a191" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated"><a class="ae ip" href="https://docs.google.com/forms/d/e/1FAIpQLSflRX3h5QYxegivjHN7SJ194OxZ4XN_7Rt0cNpR2YbmNV-7Ag/viewform" rel="noopener ugc nofollow" target="_blank">学习者英语数据集Lang-8语料库</a></li><li id="e393" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated"><a class="ae ip" href="https://www.cl.cam.ac.uk/research/nl/bea2019st/#data" rel="noopener ugc nofollow" target="_blank">构建教育应用2019共享任务:语法纠错</a></li><li id="f5e1" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated"><a class="ae ip" href="https://fasttext.cc/" rel="noopener ugc nofollow" target="_blank">快速正文</a></li><li id="86a1" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated"><a class="ae ip" href="https://www.appliedaicourse.com/course/11/Applied-Machine-learning-course" rel="noopener ugc nofollow" target="_blank">应用人工智能课程</a></li><li id="8255" class="lm ln hh ju b jv lv jz lw ks lx ku ly kw lz kp lr ls lt lu bi translated"><a class="ae ip" href="https://www.researchgate.net/publication/344160222_Recent_Trends_in_the_Use_of_Deep_Learning_Models_for_Grammar_Error_Handling" rel="noopener ugc nofollow" target="_blank">深度学习模型用于语法错误处理的最新趋势</a></li></ul><h1 id="434d" class="iq ir hh bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">14.结束注释</h1><p id="01a2" class="pw-post-body-paragraph jr js hh ju b jv kq jx jy jz kr kb kc ks kt kf kg ku kv kj kk kw kx kn ko kp ha bi translated">这就把我们带到了这篇文章的结尾。</p><p id="56a3" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我希望你喜欢这个博客，这是我的第一个博客，所以请提供你的反馈，我一定会考虑并努力改进这个博客。</p><p id="ec81" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">我要感谢整个应用人工智能团队和我的导师乌代先生在整个项目期间对我的指导。</p><p id="20d1" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> Github库</strong></p><p id="c2b6" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">请查看该项目的完整代码。</p><div class="nj nk ez fb nl nm"><a href="https://github.com/mridul1012/Grammatical-Error-Correction-with-Neural-Networks" rel="noopener  ugc nofollow" target="_blank"><div class="nn ab dw"><div class="no ab np cl cj nq"><h2 class="bd hi fi z dy nr ea eb ns ed ef hg bi translated">用神经网络纠正语法错误</h2><div class="nt l"><h3 class="bd b fi z dy nr ea eb ns ed ef dx translated">通过创建一个关于……的帐户，为使用神经网络进行语法纠错的开发做出贡献</h3></div><div class="nu l"><p class="bd b fp z dy nr ea eb ns ed ef dx translated">github.com</p></div></div><div class="nv l"><div class="nw l nx ny nz nv oa ij nm"/></div></div></a></div><p id="6d7f" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated"><strong class="ju hi"> LinkedIn个人资料</strong></p><p id="1a22" class="pw-post-body-paragraph jr js hh ju b jv jw jx jy jz ka kb kc ks ke kf kg ku ki kj kk kw km kn ko kp ha bi translated">如果你喜欢我的工作或对这个项目有任何疑问，随时通过LinkedIn联系我。</p><div class="nj nk ez fb nl nm"><a href="https://www.linkedin.com/in/mridul-agrawal-ai/" rel="noopener  ugc nofollow" target="_blank"><div class="nn ab dw"><div class="no ab np cl cj nq"><h2 class="bd hi fi z dy nr ea eb ns ed ef hg bi translated">Mridul Agrawal -机器学习培训生-应用人工智能课程| LinkedIn</h2><div class="nt l"><h3 class="bd b fi z dy nr ea eb ns ed ef dx translated">查看Mridul Agrawal在全球最大的职业社区LinkedIn上的个人资料。Mridul有一份工作列在他们的…</h3></div><div class="nu l"><p class="bd b fp z dy nr ea eb ns ed ef dx translated">www.linkedin.com</p></div></div><div class="nv l"><div class="ob l nx ny nz nv oa ij nm"/></div></div></a></div></div></div>    
</body>
</html>