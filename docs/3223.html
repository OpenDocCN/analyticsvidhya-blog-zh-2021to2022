<html>
<head>
<title>Generating Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">生成图像</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/generating-images-b8d54835de59?source=collection_archive---------13-----------------------#2021-06-19">https://medium.com/analytics-vidhya/generating-images-b8d54835de59?source=collection_archive---------13-----------------------#2021-06-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="e261" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">简介</strong></h1><p id="2453" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">这篇博客讨论了用一个应用程序生成图像的问题。想法是通过模型为给定的样本图像生成相同的图像。应用程序是使用模型架构并完成遮挡(半填充)图像。一个基本的编码器-解码器和深度CNN编码器-解码器模型从零开始实现，在三个数据集上进行训练和分析。该分析还基于为每个数据集找到图像的良好大小的隐藏表示，其可用于应用。</p><h1 id="e0cd" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak"> <em class="kb">相关作品</em> </strong></h1><p id="4152" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">一些众所周知的图像生成方法是自动编码器、生成对抗网络(GANs)、自动回归模型(PixelRNN、PixelCNN)、DRAW。</p><p id="480a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><a class="ae kh" href="https://arxiv.org/pdf/1910.07737.pdf" rel="noopener ugc nofollow" target="_blank">自回归模型</a>试图通过估计数据密度来模拟数据分布。直观上，它用于预测给定的先前输入序列的下一个序列。</p><p id="482e" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><a class="ae kh" href="https://arxiv.org/pdf/1406.2661.pdf" rel="noopener ugc nofollow" target="_blank">生成对抗网络</a>是生成模型。两个模型通过对抗过程同时训练。生成器学习生成真实的图像，而鉴别器学习区分<br/>真实和虚假的图像。鉴别器的作用是决定图像是来自真实数据集还是来自生成器。</p><p id="c159" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><a class="ae kh" href="https://arxiv.org/pdf/1502.04623.pdf" rel="noopener ugc nofollow" target="_blank">深度再现细心作家(DRAW) </a>建筑反映了向更自然的图像创作模式迈进了一步，在这种模式下，场景的各个部分彼此独立地创建，近似的草图随着时间的推移而不断完善。一对递归神经网络形成了DRAW架构的基础:编码器网络压缩训练期间呈现的实际图像，解码器网络在接收代码后重建图像。从开始到结束使用随机梯度下降来训练组合系统，损失函数是数据对数似然性的变化上限。解码器和编码器是DRAW中的循环网络，因此可以进行代码样本序列的交换。解码器的先前输出被馈送到编码器，这允许它基于解码器到目前为止的行为发送代码。网络可以决定写什么，在哪里写，在哪里读。</p><p id="8dda" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">填充被遮挡的图像依赖于先前的像素。换句话说，它是一个基于序列的问题，CNN架构模型可能捕捉不到序列，但是PixelRNN是一种基于上一个像素预测下一个像素的模型。</p><p id="d3e3" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将使用深度CNN编码器-解码器模型。由于填充遮挡图像是一个序列问题，我们可以通过将编码器作为CNN，将LSTM作为解码器来修改模型。参考<a class="ae kh" href="https://arxiv.org/pdf/1801.05141.pdf" rel="noopener ugc nofollow" target="_blank">LSTM图像去噪</a></p><h1 id="d128" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">数据集描述:</strong></h1><p id="28cb" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">使用的三个数据集是MINST digit、标记的野生人脸(LFW)深漏斗和CIFAR-100。我们不关心所有数据集的标签。MNIST的数据包含60，000个样本。LFW数据集包含了5749个人的13233张脸。CIFAR-100数据包含60，000个样本，其中50，000个作为训练数据，10，000个作为测试数据。这些数据集用于各种图像识别任务，但我们将主要关注在将它们存储在较小的维度后重新创建它们。</p><h1 id="3043" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">型号:</strong></h1><p id="7f6a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">为了分析，创建了基本的编码器-解码器模型以及基于深度CNN的模型。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ki"><img src="../Images/be8824f126e57023045c9c3162893a5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:442/format:webp/1*qUDw6r5rlINBf5j4EjYz9g.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">编码器和解码器的模型结构</figcaption></figure><p id="d726" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">基本编解码器型号:</strong></p><p id="753a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">基本编码器-解码器模型(基本模型)由编码器和解码器组成。编码器具有输入层、平坦层和密集层。我们将输入输入到输入层，然后将图像展平并输入到密集层。在密集层中，我们可以为图像的内部表示指定潜在维度值。解码器具有输入层、密集层和整形层。密集层的大小与输入图像的尺寸的乘积相同。解码器将潜在维度值作为解码器输入层的输入。它被送到致密层，最后，我们对图像进行整形，使其成为三维的。</p><p id="1cf4" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">基本模型的编码器图为</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ku"><img src="../Images/27aceea238c17e70dc253fc831577ca9.png" data-original-src="https://miro.medium.com/v2/resize:fit:466/format:webp/1*drV70iCnk_lDk2Vx8Uq79Q.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图1.1基本型号的编码器</figcaption></figure><p id="00f7" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">基本模型的解码器图</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es kv"><img src="../Images/7127546923bc472aeea8b689594573bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:470/format:webp/1*pFJogXzuorndwBe4Z-t1Ow.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图1.2基本模型的解码器</figcaption></figure><p id="6b22" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">基本模型的代码如下</p><figure class="kj kk kl km fd kn"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="5829" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">深度CNN模型:</strong></p><p id="c38c" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">该模型的架构与基本模型相同，即编码器-解码器。在编码器中，我们堆叠了四个卷积层和池层，使图像变平，并以密集层结束。在密集层中，我们提供了潜在维度值来表示。我们使用的激活函数是'<em class="ky"> relu </em>'。每个卷积层的内核大小为(3，3)，填充也相同。每个卷积层的输出分别是32、64、128、256。</p><p id="30d6" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在解码器中，我们要对卷积层进行撤销操作，即转置卷积。卷积层提取图像的一部分并产生一个数字，而转置卷积提取数字并产生图像的一部分。解码器的第一层有一个输入层，它采用编码器中指定的潜在维度的形状。接下来，将它连接到单元数等于原始图像大小的乘积的密集层。它随后被整形并被馈送到转置卷积层。我们堆叠四个Conv2DTranspose层，输出通道分别为128、64、32和3。“relu”被用作前三层的激活函数，由于最后一层是我们的最终图像，我们在那里不包括任何激活函数。</p><p id="2fac" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">深度CNN模型的代码和绘图(图2)如下:</p><figure class="kj kk kl km fd kn"><div class="bz dy l di"><div class="kw kx l"/></div></figure><p id="6e79" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">深度CNN模型的编码器</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es kz"><img src="../Images/ad4367003e4205c6a81c3951eb754a7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:610/format:webp/1*fswrae8q5w7lhs2QN7wBKw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图2.1深度CNN模型的编码器</figcaption></figure><p id="820f" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">深度CNN模型的解码器</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es la"><img src="../Images/ed3aec1c0c6e9f65e27d93b51458486e.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*6uWe8JLNUPq3NGdnj7Zp5A.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图2.2深度CNN模型的解码器</figcaption></figure><p id="b90c" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">因为我们在训练模型时生成图像，所以我们给出训练数据来代替模型的输入和输出。</p><p id="9353" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在用这些模型训练之后，我们为给定的样本重新创建了图像。应用部分是完成遮挡(半填充)图像。为此，我们创建了一个用于生成遮挡图像的函数，如图3所示。该任务的代码如下</p><figure class="kj kk kl km fd kn"><div class="bz dy l di"><div class="kw kx l"/></div></figure><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lb"><img src="../Images/a7ce13e4096845853b164b781c1ffc09.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*ph1s7vOZGj3yKN1yDwoRSQ.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图3，(上)明斯特数据，(中)LFW数据，(下)CIFAR数据的遮挡图像</figcaption></figure><p id="14a5" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">因此，在训练该模型时，我们将遮挡图像作为输入，将原始图像作为目标。</p><p id="b237" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在推理过程中，我们首先将输入图像提供给编码器，然后将编码器产生的输出作为输入提供给解码器。解码器根据我们正在解决的问题预测所需的输出。我们绘制出这些输出的图表。</p><p id="36be" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">结果:</strong></p><p id="fe82" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">如上所述，对三个数据集进行分析。我们希望找到最小的潜在维度尺寸，同时生成良好的图像。下面我们包括重建图像的图像和半填充图像的完成，训练和验证错误的绘图。误差指标是<em class="ky">均方误差，</em>和“<em class="ky">亚当</em>”是优化器。我们用不同的潜在大小和不同的数据集展示了所有这些。结果适用于基本和深度CNN模型。</p><p id="22a7" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将从MNIST的数据开始；一些样品是</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lc"><img src="../Images/1ecb0e3e5f38184aa161ec2ae5cb068c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*Ow4a3CnoQy4UifR4ksoCag.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图4，MNIST数据样本。</figcaption></figure><h1 id="6029" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">MNIST基本模型的结果</h1><p id="a63c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">潜在尺寸为32的基本模型的重建图像(图5)对于测试数据具有MSE = 0.017。</p><p id="7c7e" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">重建，潜在尺寸= 32 </strong></p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ld"><img src="../Images/e81f373f669818a83bd0be96d3177c52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*4mQO-0jcOVapxggAlYtkUA.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图5</figcaption></figure><h2 id="ffa9" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">遮挡图像，潜像尺寸:32</h2><p id="21c8" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于测试数据，完成具有32的潜在尺寸的基本模型的遮挡图像(图6)具有MSE = 0.023。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ld"><img src="../Images/c0b3e096c9236b2b654ac2b4d12a4a05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*hERq1NAAgcRId6vmt1HOfw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图6</figcaption></figure><h1 id="e511" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">MNIST深度模型的结果</h1><h2 id="e9ee" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated"><strong class="ak">重建，</strong>潜在尺寸:32</h2><p id="9ff4" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">潜在尺寸为32的深度模型的重建图像(图7)对于测试数据具有MSE = 0.0030。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ld"><img src="../Images/65ca8ef1afb28f2d84c9787616e96bf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*nozjFTPAdibBuu8lDldTbg.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图7</figcaption></figure><h2 id="25ca" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">遮挡，潜在尺寸:32</h2><p id="475d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于测试数据，完成潜在尺寸为32的深度模型的遮挡图像(图8)具有MSE = 0.015。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ld"><img src="../Images/de1d81fd4034e359ae048a33a1a616fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*1NS6Ck88Tp7nAzTWPOT13w.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图8</figcaption></figure><h2 id="816b" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">遮挡，潜在尺寸:128</h2><p id="b345" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于测试数据，完成潜在尺寸为128的深度模型的遮挡图像(图9)具有MSE = 0.0147。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ld"><img src="../Images/e217bc487e4c10d865f505386b944999.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*wrfiXFHjzJ96wLSQL07pzA.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图9</figcaption></figure><h2 id="b890" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">遮挡、潜在尺寸:512</h2><p id="4a19" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于测试数据，完成潜在尺寸为512的深度模型的遮挡图像(图10)具有MSE = 0.0146。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ld"><img src="../Images/645c481b4b200b3dac5138141a1db698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1072/format:webp/1*Vl5DeTj9hHDLHR26NoDjOg.png"/></div></figure><h1 id="c2eb" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">LFW基本模型的结果</h1><p id="4233" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">现在我们展示LFW数据集的图像。一些样品是</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es ls"><img src="../Images/64c1122646a0242c1d496a9a346ea08e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1288/format:webp/1*8Mz1OTY2zLJdAGag2akcWQ.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图11。LFW数据的原始样本</figcaption></figure><h2 id="b42a" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">重建，潜在尺寸:32</h2><p id="3987" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">潜在尺寸为32的基本模型的重建图像(图12)对于测试数据具有MSE = 0.0056。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lt"><img src="../Images/16b63fdc92cc0b909c5e6e0cd4701855.png" data-original-src="https://miro.medium.com/v2/resize:fit:986/format:webp/1*4gp86xI-jbpSIJKnTMSzYA.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图12</figcaption></figure><h2 id="6415" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">重建，潜在尺寸:32</h2><p id="9061" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于测试数据，完成具有32的潜在尺寸的基本模型的遮挡图像(图13)具有MSE = 0.0078。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lu"><img src="../Images/c207f9445b6cd90e7c3a34e59209624f.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*4J0UC6Lmpzj2KFfMeF9h9Q.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图13。(左)(上)遮挡样本，(中)填充样本(下)基本模型的原始样本，(右)训练和验证误差曲线</figcaption></figure><h1 id="db3b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">LFW深度模型的结果</h1><h2 id="173f" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">重建，潜在尺寸:16</h2><p id="183d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">潜在尺寸为16的深度模型的重建图像(图14)对于测试数据具有MSE = 0.0068如您所见，当深度模型的潜在维度小于基本模型的潜在维度时，基本模型的性能优于深度模型。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lv"><img src="../Images/d891f53d661ebe42b15a8feaf90f53d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*QyIEWsqP8UjxgJGSOWgwIw.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图14</figcaption></figure><h2 id="d513" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">重建，潜在尺寸:32</h2><p id="c6ed" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">潜在尺寸为32的深度模型的重建图像(图15)对于测试数据具有MSE = 0.0052。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lw"><img src="../Images/4af435be33fbc829ffc3aca2a55f6af2.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/format:webp/1*OcN91PCuEkJys0pUeAcSmA.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图15</figcaption></figure><h2 id="afda" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">重建，潜在尺寸:64</h2><p id="d5d3" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">潜在尺寸为64的深度模型的重建图像(图16)对于测试数据具有MSE = 0.0038。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lx"><img src="../Images/f89468160d62eae622f94057c4a3950a.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*pzfycoO8M4nbykARSKMotg.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图16</figcaption></figure><h2 id="e31d" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">遮挡、潜在尺寸:64，128，512</h2><p id="0d2f" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于测试数据，完成具有64的潜在尺寸的深度模型的遮挡图像(图17)具有MSE = 0.0080，尺寸128具有0.0076，尺寸512具有0.0078。</p><div class="kj kk kl km fd ab cb"><figure class="ly kn lz ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/c240adc1c49f1d654486f79f6b15db60.png" data-original-src="https://miro.medium.com/v2/resize:fit:682/format:webp/1*NBIaD0hGhuMU1PTaKGv0hQ.png"/></div></figure><figure class="ly kn mi ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/f646898773f9260dd0ac95999d3f886a.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*Ihe2EvVeCjFzSmX-TdxIXg.png"/></div></figure><figure class="ly kn mj ma mb mc md paragraph-image"><div role="button" tabindex="0" class="me mf di mg bf mh"><img src="../Images/dbf20173c12b98c1e34ac21cf151ca53.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*Zocd6esth9EsADBlZpDMTg.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx mk di ml mm translated">图17。(左)(上)遮挡样本，(中)完全填充样本(下)深度模型的原始样本，潜在大小分别为64、128、512</figcaption></figure></div><p id="5d9a" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">最后，我们展示了CIFAR数据的结果；一些样品是</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es lc"><img src="../Images/554ed5f90c0b345ddc15b8bd21c8ed3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*Y-AnJyJtIXKwbEXQQ3dN4g.png"/></div><figcaption class="kq kr et er es ks kt bd b be z dx translated">图18 CIFAR-100数据示例</figcaption></figure><h1 id="7b87" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">CIFAR基本模型的结果</h1><h2 id="d7f6" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">重建，潜在尺寸:32</h2><p id="a43e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">潜在尺寸为32的基本模型的重建图像(图19)对于测试数据具有MSE = 0.0132。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es mn"><img src="../Images/899d42b8f7d4d54189442f14f7fd0441.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*P5N_wqG4JJudgoQFjJIU-A.png"/></div></figure><h2 id="fda6" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">遮挡，潜在尺寸:32</h2><p id="454e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于测试数据，完成具有32的潜在尺寸的基本模型的遮挡图像(图21)具有MSE = 0.0232。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es mo"><img src="../Images/704c4687ed6437c659a63b3aec27f07a.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*0JLOJ7WuWpj5sv1sZctGNw.png"/></div></figure><h1 id="e886" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">CIFAR的深度模型结果</h1><h2 id="eec5" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">重建，潜在尺寸:32</h2><p id="e21a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">潜在尺寸为32的深度模型的重建图像(图20)对于测试数据具有MSE = 0.011。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es mp"><img src="../Images/7d47c37424beb6d7c64b254e9230293f.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*x00_h6u2RLup3yj2J9kYzw.png"/></div></figure><h2 id="124d" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">遮挡、潜在尺寸:64</h2><p id="fd9e" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于测试数据，完成潜在尺寸为64的深度模型的遮挡图像(图22)具有MSE = 0.0234。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es mn"><img src="../Images/29efe98327e18a91fd0139c3eb425157.png" data-original-src="https://miro.medium.com/v2/resize:fit:988/format:webp/1*xGb2pbFHwjSKEQMVTHI5OA.png"/></div></figure><h2 id="7471" class="le ig hi bd ih lf lg lh il li lj lk ip jo ll lm it js ln lo ix jw lp lq jb lr bi translated">遮挡，潜在尺寸:128</h2><p id="6b9b" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">对于测试数据，完成潜在尺寸为128的深度模型的遮挡图像(图23)具有MSE = 0.0231。</p><figure class="kj kk kl km fd kn er es paragraph-image"><div class="er es mq"><img src="../Images/95086d1c2fab004922e17c3b7b03ae35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/1*LxLMWzi-E051Jik2FKGc2w.png"/></div></figure><p id="b730" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">结论:</strong>与MNIST数据集的基本模型相比，深度模型的重建图像对于潜在尺寸32更好。对于给定的潜在值，深度模型的MSE之间的差异非常小。因此，该模型的MNIST数据的最小表示大小是32，即，我们可以用这个大小几乎完美地完成遮挡图像。对于LFW数据集，重建对于潜在大小为64的深度模型更好。遮挡图像问题的最佳潜在尺寸值是具有尺寸为32的基本模型。最后，对于CIFAR数据，必须使用大小为32的深度模型进行重新创建，基本模型也可以很好地与深度模型一起完成图像。由于这是一个序列问题，我们可以通过将LSTM序列模型作为解码器的一部分来扩展这个模型，以获得更好的结果。</p><p id="b686" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">所有的代码都可以在https://github.com/bodavijay24/Generating-Images的<a class="ae kh" href="https://github.com/bodavijay24/Generating-Images" rel="noopener ugc nofollow" target="_blank">找到</a></p><p id="8833" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated"><strong class="jf hj">参考文献:</strong></p><ol class=""><li id="d841" class="mr ms hi jf b jg kc jk kd jo mt js mu jw mv ka mw mx my mz bi translated">直接关注CNN-LSTM编解码器的图像去噪和恢复(<a class="ae kh" href="https://arxiv.org/pdf/1801.05141.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1801.05141.pdf</a></li><li id="701c" class="mr ms hi jf b jg na jk nb jo nc js nd jw ne ka mw mx my mz bi translated">Gregor，k .、Danihelka，I .、Graves，A .、Rezende，D. J .、和<br/> Wierstra，D. Draw:用于图像生成的递归神经网络<br/>，2015年。</li><li id="4517" class="mr ms hi jf b jg na jk nb jo nc js nd jw ne ka mw mx my mz bi translated">拉德福德，a .，梅斯，l .，钦塔拉，s .利用深度卷积生成的无监督表示学习<br/>对抗网络，2016年。</li><li id="2fbe" class="mr ms hi jf b jg na jk nb jo nc js nd jw ne ka mw mx my mz bi translated">van den Oord，a .，Kalchbrenner，n .，Vinyals，o .，Espeholt，<br/> L .，Graves，a .，和Kavukcuoglu，k .，使用pixelcnn解码器生成条件图像<br/>，2016年。</li><li id="cf31" class="mr ms hi jf b jg na jk nb jo nc js nd jw ne ka mw mx my mz bi translated">像素递归神经网络(<a class="ae kh" href="http://proceedings.mlr.press/v48/oord16.pdf" rel="noopener ugc nofollow" target="_blank">http://proceedings.mlr.press/v48/oord16.pdf</a>)</li></ol></div></div>    
</body>
</html>