# ä½¿ç”¨ Python é€šè¿‡æœºå™¨å­¦ä¹ æŠ€æœ¯é¢„æµ‹(è‡³å°‘å°è¯•)èµ„äº§å›æŠ¥

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/predicting-at-least-trying-asset-returns-with-machine-learning-techniques-using-python-1b0946100caf?source=collection_archive---------2----------------------->

## è¯•å›¾é€šè¿‡å¼ºåˆ¶ ML æ¨¡å‹æ¥è¶…è¶Šçº¯ç²¹çš„æœºä¼šï¼Œä»¥åŠä¸ºä»€ä¹ˆæˆ‘ä»¬æ²¡æœ‰è¿™æ ·åš

ç»Ÿè®¡å­¦å¯ä»¥ç”¨æ¥é¢„æµ‹ä»»ä½•æœ‰é¢„æµ‹å› å­çš„äº‹ç‰©ã€‚ç„¶è€Œï¼Œæœ‰æ•ˆå¸‚åœºå‡è¯´(EMH)æŒ‡å‡ºï¼Œè¿™ä¸æ˜¯èµ„äº§å›æŠ¥çš„æƒ…å†µï¼Œå› ä¸ºå¸‚åœºä»·æ ¼å°†åæ˜ ç°æœ‰çš„ä¿¡æ¯ï¼Œé™¤äº†å°‘æ•°ä¾‹å¤–(æ³•ç›å’Œé©¬å°”åŸºå°”ï¼Œ1970)ã€‚æ­¤å¤–ï¼Œé‰´äºåªæœ‰å°‘æ•°é€‰å®šçš„ç§¯æåŸºé‡‘å¯ä»¥æŒç»­è·‘èµ¢é€‰å®šçš„åŸºå‡†æŒ‡æ•°(é©¬å°”åŸºå°”ï¼Œ2005)ï¼Œæœ‰è¶³å¤Ÿçš„ç†ç”±ç›¸ä¿¡ï¼Œæœªæ¥ä»·æ ¼çš„å¯é¢„æµ‹æ€§å‡ ä¹æ˜¯ä¸å¯èƒ½çš„ï¼Œå› ä¸ºæ‰€æœ‰å·²çŸ¥çš„å’Œå¯ç”¨äºé¢„æµ‹ä»·æ ¼å’Œå‡»è´¥å¸‚åœºçš„ä¸œè¥¿éƒ½å·²ç»æ‰“æŠ˜äº†ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å›åˆ°äº†è‚¤æµ…çš„é¢„æµ‹ï¼ŒåŸºäºè¿æ°”çš„èƒœåˆ©ï¼Œå¹¶ä¸ºæ­¤ä»˜è´¹ã€‚

ç„¶è€Œï¼Œè¿˜æœ‰å¦ä¸€ç§ç›¸åçš„æ–¹å¼æ¥ç†è§£æœ‰æ•ˆå¸‚åœºã€‚è¿™æ˜¯ä¸€ä¸ªäº‹å®ï¼Œå‡è®¾æ‰€æœ‰ç›¸å…³ä¿¡æ¯éƒ½å·²ç»è¢«è´´ç°ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦å°è¯•ä»»ä½•ç±»å‹çš„é¢„æµ‹ï¼Œä»·æ ¼å°±æ˜¯æˆ‘ä»¬æ‰€éœ€è¦çš„ã€‚ä¾‹å¦‚ï¼Œç½‘ä¸Šæœ‰å‡ ç¯‡è®ºæ–‡è¡¨æ˜ï¼Œåº”ç”¨ä¸€ç»„æœºå™¨å­¦ä¹ æŠ€æœ¯å¯ä»¥è¾“å‡ºè¶…è¿‡ 80%å‡†ç¡®åº¦çš„æ–¹å‘é¢„æµ‹(Patelï¼ŒShahï¼ŒThakkarï¼Œ& Koetchaï¼Œ2014)ã€‚è¿™ç§ç²¾ç¡®åº¦ä¸å…¶ä»–ç­–ç•¥(å¦‚å‡¯åˆ©æ ‡å‡†)ç›¸ç»“åˆï¼Œå¯ä»¥äº§ç”Ÿç›¸å…³çš„ç»“æœã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘å°†å±•ç¤ºä¸‰ç§ä¸åŒçš„æœºå™¨å­¦ä¹ æŠ€æœ¯çš„ä»£ç ï¼Œå³:é€»è¾‘å›å½’å’Œè´å¶æ–¯åˆ†ç±»å™¨ã€å†³ç­–æ ‘å’Œæ”¯æŒå‘é‡æœºã€‚è¦é¢„æµ‹çš„èµ„äº§æœ‰:JP æ‘©æ ¹(JPM)ã€ç¾å›½é“¶è¡Œ(BAC)å’ŒèŠ±æ——é“¶è¡Œ(C)ã€‚å¯ä»¥é€šè¿‡æ‹Ÿåˆ/é¢„æµ‹ 2008 å¹´å¯¹è¿™ä¸‰å®¶é“¶è¡Œäº§ç”Ÿå·¨å¤§å½±å“çš„å±æœºæ¥è¿›è¡Œè¿›ä¸€æ­¥çš„ç ”ç©¶ï¼Œçœ‹çœ‹è¿™äº›æ¨¡å‹æ˜¯å¦ä¼šå‘ç”Ÿä»€ä¹ˆé…·çš„äº‹æƒ…ã€‚è‡³äºæˆ‘ä»¬çš„æ•°æ®ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Quandl çš„éšæ—¶é—´å˜åŒ–çš„è‚¡ç¥¨ä»·æ ¼æ•°æ®åº“ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆä¸€ä¸ªå¸¦æœ‰å»ºè®®çš„åˆ¶é€ æŒ‡æ ‡çš„è¡¨æ ¼ï¼Œå³:æ”¶ç›˜ä»·ã€å›æŠ¥ã€å›æŠ¥ç¬¦å·ã€åŠ¨é‡ã€10 å¤©ç®€å•ç§»åŠ¨å¹³å‡çº¿å’Œ 10 å¤©æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿ã€‚

**è®¾ç½®æˆ‘ä»¬çš„æ•°æ®**

åœ¨æˆ‘ä»¬å¼€å§‹å¹²é¢„æˆ‘ä»¬çš„æœºå™¨å­¦ä¹ æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘å°†åˆ›å»ºä¸‰ä¸ªæ•°æ®æ¡†ï¼Œæ¯ä¸ªèµ„äº§ä¸€ä¸ªã€‚é¦–å…ˆï¼Œæˆ‘å°†ä» Quandl åº“è·å–ä» 2014 å¹´ 1 æœˆ 1 æ—¥åˆ° 2018 å¹´ 1 æœˆ 1 æ—¥çš„æ”¶ç›˜ä»·(é‰´äºæˆ‘åœ¨ Quandl ä¸­çš„å…è´¹å¸æˆ·ï¼Œä¸èƒ½æ›´æ¥è¿‘å½“å‰æ—¥æœŸ)ã€‚ç„¶åï¼Œæˆ‘å°†é€šè¿‡è®¡ç®— D+0 å’Œ D-1 çš„ä»·æ ¼æ¯”ç‡çš„å¯¹æ•°æ¥ä¸ºæˆ‘ä»¬çš„å¯¹æ•°å›æŠ¥åˆ›å»ºä¸€ä¸ªåˆ—ã€‚ç„¶åï¼Œæˆ‘å°†ä¸ºæˆ‘ä»¬çš„æ»åå›æŠ¥åˆ›å»º 5 åˆ—ï¼Œå°å¿ƒåœ°åˆ é™¤æ— æ•ˆå€¼ï¼Œå¹¶å°†å®ƒä»¬æ”¾å…¥ D+0 çº¿ã€‚åŠ¨é‡æŸ±æ˜¯é€šè¿‡å‡å» D+0 å’Œ D-1 çš„ä»·æ ¼åˆ›å»ºçš„ï¼Œè€Œç®€å•å’Œç§»åŠ¨å¹³å‡çº¿æ˜¯ä¸ºè¿‡å» 10 å¤©åˆ›å»ºçš„ã€‚æœ€ç»ˆæ•°æ®æ¡†è¢«æˆªæ–­ï¼Œå› æ­¤æ•°æ®å°†ç¬¦åˆå…¬å¼æ‰€éœ€çš„å½¢çŠ¶ã€‚ä»£ç å¦‚ä¸‹æ‰€ç¤ºã€‚

```
import numpy as np
import pandas as pd
from numpy import inf
from pandas_datareader import data as web#Get close datadataJPM = pd.DataFrame(web.DataReader('AXP', data_source='quandl', start="2014-01-01", end="2018-01-01", access_key="Hvta3RUqWUHaHFkzfyEA")['Close'])
dataBAC = pd.DataFrame(web.DataReader('BAC', data_source='quandl', start="2014-01-01", end="2018-01-01", access_key="Hvta3RUqWUHaHFkzfyEA")['Close'])
dataC = pd.DataFrame(web.DataReader('C', data_source='quandl', start="2014-01-01", end="2018-01-01", access_key="Hvta3RUqWUHaHFkzfyEA")['Close'])#Create RETURN featuredataJPM["Returns"] = np.log(dataJPM.Close/dataJPM.Close.shift(-1))
dataBAC["Returns"] = np.log(dataBAC.Close/dataBAC.Close.shift(-1))
dataC["Returns"] = np.log(dataC.Close/dataC.Close.shift(-1))#Create 5 LAGGED DAILY RETURNSlags = 5
banks = [dataJPM, dataBAC, dataC]
col = []
for bank in banks:
    for lag in range(1,lags+1):
        col = 'ret_%d' % lag
        bank[col] = bank['Returns'].shift(-lag)#Remove NaNdataJPM.dropna(inplace=True)
dataBAC.dropna(inplace=True)
dataC.dropna(inplace=True)#Create MOMENTUM featuredataJPM["Momentum"] = dataJPM.Close - dataJPM.Close.shift(-1)
dataBAC["Momentum"] = dataBAC.Close - dataBAC.Close.shift(-1)
dataC["Momentum"] = dataC.Close - dataC.Close.shift(-1)#Create SIMPLE MOVING AVERAGE featuredataJPM["SMA10"] = (dataJPM.Close + dataJPM.Close.shift(-1) + dataJPM.Close.shift(-2) + dataJPM.Close.shift(-3) + dataJPM.Close.shift(-4) + dataJPM.Close.shift(-5) + dataJPM.Close.shift(-6) + dataJPM.Close.shift(-7) + dataJPM.Close.shift(-8) + dataJPM.Close.shift(-9))/10
dataBAC["SMA10"] = (dataBAC.Close + dataBAC.Close.shift(-1) + dataBAC.Close.shift(-2) + dataBAC.Close.shift(-3) + dataBAC.Close.shift(-4) + dataBAC.Close.shift(5) + dataBAC.Close.shift(-6) + dataBAC.Close.shift(-7) + dataBAC.Close.shift(-8) + dataBAC.Close.shift(-9))/10
dataC["SMA10"] = (dataC.Close + dataC.Close.shift(-1) + dataC.Close.shift(-2) + dataC.Close.shift(-3) + dataC.Close.shift(-4) + dataC.Close.shift(-5) + dataC.Close.shift(-6) + dataC.Close.shift(-7) + dataC.Close.shift(-8) + dataC.Close.shift(-9))/10#Create EXPONENTIAL MOVING AVERAGE featuredataJPM["EMA10"] = dataJPM["SMA10"]
dataBAC["EMA10"] = dataBAC["SMA10"]
dataC["EMA10"] = dataC["SMA10"]alpha = 0.5
dataJPM["EMA10"] = (dataJPM.Close-dataJPM.EMA10.shift(-1))*(alpha) + dataJPM.EMA10.shift(-1)
dataBAC["EMA10"] = (dataBAC.Close-dataBAC.EMA10.shift(-1))*(alpha) + dataBAC.EMA10.shift(-1)
dataC["EMA10"] = (dataC.Close-dataC.EMA10.shift(-1))*(alpha) + dataC.EMA10.shift(-1)dataJPMfinal = dataJPM.truncate(after="2014-01-27")
dataBACfinal = dataBAC.truncate(after="2014-01-27")
dataCfinal = dataC.truncate(after="2014-01-27")
```

ä¸ºäº†ç»™æˆ‘ä»¬çš„æ¨¡å‹ç¼–ç ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ Scikit Learn çš„åº“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ•°æ®å°†åœ¨éœ€è¦æ—¶ä½¿ç”¨ Scikit çš„æ ‡å‡†å®šæ ‡å™¨è¿›è¡Œæ ‡å‡†åŒ–ï¼Œä»¥é¿å…åˆ†é…ä¸æˆæ¯”ä¾‹çš„æƒé‡ï¼Œè¿™ä¼šä¸¥é‡å½±å“æˆ‘ä»¬æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚æ¥ä¸‹æ¥ï¼Œå¯¹äºæ‰€æœ‰æ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Scikit çš„ KFold å°†æˆ‘ä»¬çš„æ•°æ®åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œ4/5 ç”¨äºè®­ç»ƒï¼Œ1/5 ç”¨äºæµ‹è¯•ã€‚è¿™ç§æ‹†åˆ†å°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿæ›´å¥½åœ°è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹åœ¨å®æ—¶æƒ…å†µä¸‹ä¼šå¦‚ä½•å‘å±•ã€‚

**å…³äº PNL å›æµ‹çš„è¯´æ˜**

ä¸ºäº†æµ‹è¯•æˆ‘ä»¬çš„ç­–ç•¥ï¼Œæˆ‘ä»¬å°†ä¸ºæ¯ä¸ªæ¨¡å‹å’Œè‚¡ç¥¨ç»˜åˆ¶ä¸‰æ¡æ›²çº¿ã€‚ç¬¬ä¸€æ¡æ›²çº¿å°†ä»£è¡¨ä»»ä½•ç»™å®šè‚¡ç¥¨çš„å®Œå…¨å¤šå¤´è¢«åŠ¨å¤´å¯¸ï¼Œè¿™å¯ä»¥ä½œä¸ºåŸºå‡†:æˆ‘ä»¬å¾—åˆ°æ¯”è¿™æ¡æ›²çº¿æ›´é«˜çš„ç»“æœï¼Œæˆ‘ä»¬çš„ä¸»åŠ¨ç®¡ç†æ­£åœ¨äº§ç”Ÿ alphaã€‚æˆ‘ä»¬å°†ç»˜åˆ¶çš„ç¬¬äºŒæ¡çº¿æ˜¯å¯¹ç»™å®šç­–ç•¥çš„å®Œå…¨æŠ•èµ„å¤´å¯¸ï¼Œå³å…¨æŠ¼:æˆ‘ä»¬å°† 100%çš„èµ„æœ¬æ”¾åœ¨æˆ‘ä»¬æ¨¡å‹ä¸­ç»™å®šçš„ç­–ç•¥ä¸Šï¼Œå¹¶çº³å…¥ 100%çš„ç»“æœï¼Œæ— è®ºå®ƒä»¬æ˜¯ä¸Šæ¶¨è¿˜æ˜¯ä¸‹è·Œã€‚è¿™å¯ä»¥ç®€å•åœ°é€šè¿‡ç´¯åŠ æ‰€æœ‰å›æŠ¥çš„æ€»å’Œä¹˜ä»¥æˆ‘ä»¬çš„é¢„æµ‹ç¬¦å·æ¥å®ç°:å¦‚æœé¢„æµ‹å€¼ä¸º 1ï¼Œå›æŠ¥ä¸ºæ­£ï¼Œæˆ‘ä»¬å°±è·åˆ©ï¼›å¦‚æœ predictor æ˜¯-1ï¼Œå›æŠ¥æ˜¯è´Ÿçš„ï¼Œæˆ‘ä»¬ä¹Ÿæœ‰æ”¶ç›Šï¼›ä¸åŒçš„ç»“æœå¢åŠ äº†è´Ÿå›æŠ¥ã€‚

æˆ‘ä»¬çš„ç¬¬ä¸‰æ¡æ›²çº¿å°†è€ƒè™‘åŠå‡¯åˆ©ã€‚å‡¯åˆ©æ ‡å‡†æ˜¯èµŒæ³¨çš„å¤§å°ï¼Œä»¥ç™¾åˆ†æ¯”æˆ–æ€»èµ„æœ¬çš„å½¢å¼ç»™å‡ºï¼Œä½ åº”è¯¥åœ¨ä¸€ç³»åˆ—çš„èµŒæ³¨ä¸­ä¸‹æ³¨ä»¥æœ€å¤§åŒ–é¢„æœŸå›æŠ¥ã€‚è¿™æ˜¯é€šè¿‡å‡è®¾æˆ‘ä»¬çš„æ¨¡å‹æœ‰ä¸€å®šçš„ä¼˜åŠ¿ï¼Œå³èµ¢çš„æ¦‚ç‡ p é«˜äº 50%æ¥è®¡ç®—çš„ï¼›ç„¶åï¼Œå‡è®¾ç¬¬äºŒå¤©æ”¶ç›Šçš„åˆ†å¸ƒæ˜¯æ­£æ€çš„ï¼Œé€šè¿‡æ³°å‹’å±•å¼€å¼åŠå…¶å¯¼æ•°ç­‰äºé›¶ï¼Œæˆ‘ä»¬å¾—åˆ°äº†æœ€ä¼˜åˆ†é…ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œè€ƒè™‘ 1:1 (b=1)çš„å¶æ•°èµŒæ³¨ï¼Œæˆ‘ä»¬æœ‰:

![](img/7ad1948dd0305f46fe946c2a02ba245e.png)

å‡¯åˆ©å‡†åˆ™

é€šå¸¸ï¼Œå‡¯åˆ©ä¼šè§£å†³ç­–ç•¥ä¸­èµ„æœ¬åˆ†é…çš„æœ€ä½³ç™¾åˆ†æ¯”ã€‚ç„¶è€Œï¼Œè¿™ç§ç­–ç•¥å¾€å¾€ç»™å‡ºéå¸¸é«˜çš„æ ‡å‡†å·®ï¼Œè¿™åœ¨ä¸»åŠ¨ç®¡ç†å‹åŸºé‡‘ä¸­å¯èƒ½ä¼šå“è·‘æŠ•èµ„è€…ã€‚å› æ­¤ï¼Œç»ç†ä»¬å¯èƒ½ä¼šé€‰æ‹©ä½¿ç”¨åŠå‡¯åˆ©ï¼Œå› ä¸ºæˆ‘ä»¬çš„æ³°å‹’å±•å¼€æ˜¯æŠ›ç‰©çº¿(ä¸æ˜¯çœŸçš„ï¼Œä½†å¯¹æˆ‘ä»¬çš„è§£é‡Šæ¥è¯´è¶³å¤Ÿæ¥è¿‘)ï¼Œå¦‚æœæˆ‘ä»¬åªåˆ†é…æˆ‘ä»¬æ ‡å‡†çš„ä¸€åŠï¼Œæˆ‘ä»¬å°† sigma å‡å°‘ä¸€åŠï¼Œä½†å›æŠ¥ç‡ä»…å‡å°‘ 25%ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å–ç‚¹ï¼Œå¯ä»¥å®‰æ…°æˆ‘ä»¬çš„ç»ç†ï¼Œè€Œä¸ä¼šå“åˆ°æŠ•èµ„è€…ã€‚å› æ­¤ï¼Œåœ¨å¯¹æˆ‘ä»¬çš„ç­–ç•¥è¿›è¡Œå›æº¯æµ‹è¯•æ—¶ï¼Œæˆ‘ä»¬å°†è€ƒè™‘ä»¥ä¸‹å‡ ç‚¹ã€‚

![](img/3b74f024eb8d5b7f2e014edfb6b1d7be.png)

åŠå‡¯åˆ©:å¿ƒè„è¡°å¼±è€…

**è´å¶æ–¯åˆ†ç±»å™¨**

æˆ‘ä»¬å°†é€šè¿‡æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è¿›è¡Œé¢„æµ‹å›æŠ¥çš„ç¬¬ä¸€æ¬¡å°è¯•ã€‚è¿™ä¸ªåˆ†ç±»å™¨ä»ä¸€ä¸ªç®€å•çš„å‡è®¾å¼€å§‹ï¼Œå³æ•°æ®ä¸­çš„ç‰¹å¾ä¹‹é—´æ²¡æœ‰ç›¸å…³æ€§ï¼Œå¹¶ä½¿ç”¨è´å¶æ–¯å®šç†è¿›è¡Œåˆ†ç±»ã€‚y æ˜¯ up (1)å’Œ down (-1)çš„äºŒè¿›åˆ¶çŠ¶æ€ï¼Œx1ï¼Œâ€¦ï¼Œxn æ˜¯æˆ‘ä»¬çš„ç‰¹å¾å‘é‡ï¼Œæˆ‘ä»¬å¾—åˆ°å¦‚ä¸‹ã€‚

![](img/3b6cd92e9d9feb2bc397d3309f72e391.png)

å‡è®¾ä¸è€ƒè™‘å˜é‡ä¹‹é—´çš„ä¾èµ–æ€§ï¼Œåˆ†æ¯å‘é‡çš„æ¯ä¸ªç‰¹å¾çš„æ¦‚ç‡ä¿æŒä¸å˜ï¼Œå¹¶ä¸”æˆ‘ä»¬æƒ³è¦äºŒè¿›åˆ¶ç»“æœï¼Œæˆ‘ä»¬çš„ç­‰å¼å˜æˆå¦‚ä¸‹ã€‚

![](img/aecbe4b4ae1d047b604f7587b237ca1b.png)

è¯¥ç­‰å¼æ˜¯ç»™å®š y çš„ç‰¹å¾æ¦‚ç‡çš„æ‰€æœ‰æ¦‚ç‡ä¸ y çš„æ¦‚ç‡çš„ä¹˜ç§¯ã€‚ä¸€ç³»åˆ—æ¦‚ç‡çš„ä¹˜ç§¯å¯èƒ½å¯¼è‡´ä¸‹æº¢ï¼Œè¿™ä¿ƒä½¿æˆ‘ä»¬åœ¨å®è·µä¸­ä½¿ç”¨å¯¹æ•°æ¦‚ç‡ä¹‹å’Œçš„æŒ‡æ•°ã€‚ç”±æ­¤äº§ç”Ÿçš„å¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼Œå¦‚æœä»»ä½•ğ‘ƒ(ğ‘¥ğ‘– |ğ‘¦ç¢°å·§ä¸ºé›¶ï¼Œæˆ‘ä»¬çš„æ–¹ç¨‹å°†æ€»æ˜¯è¿”å›é›¶ï¼Œå› æ­¤æˆ‘ä»¬çš„æ¨¡å‹å°†é€šè¿‡ä½¿ç”¨å¹³æ»‘å˜é‡æ¥å¹³æ»‘æˆ‘ä»¬çš„æ¦‚ç‡ï¼Œè¿™å°†ä½¿ä»»ä½•é›¶æ¦‚ç‡ç¨å¾®è¶…è¿‡é›¶ã€‚

ä¸åŒçš„è´å¶æ–¯åˆ†ç±»å™¨æ–¹æ³•å¯¹ç‰¹å¾çš„æ¦‚ç‡åˆ†å¸ƒåšå‡ºä¸åŒçš„å‡è®¾ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é«˜æ–¯å˜é‡ï¼Œå‡è®¾æ­£æ€åˆ†å¸ƒçš„æ¦‚ç‡ã€‚ä»£ç å¦‚ä¸‹æ‰€ç¤ºã€‚

```
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
gnb = GaussianNB()
cols = ['Momentum', 'SMA10', 'EMA10', 'ret_1', 'ret_2', 'ret_3', 'ret_4', 'ret_5']scaler = StandardScaler()
scaler.fit(dataBACfinal)dataBACfinalScaled = pd.DataFrame(scaler.transform(dataBACfinal))
dataBACfinalScaled.columns = ['Close', 'Returns', 'ret_1', 'ret_2', 'ret_3', 'ret_4', 'ret_5', 'Momentum', 'SMA10', 'EMA10']y = dataBACfinal["Returns"].values
X = dataBACfinalScaled[cols].shift(-1).fillna(0).values
kf = KFold(n_splits=5, shuffle=True)
kf.get_n_splits(X)for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]gnb.fit(pd.DataFrame(X_train), np.sign(y_train))dfyGNB = pd.DataFrame(y_test)
dfyGNB.columns = ["Returns"]
dfyGNB['NB_pred'] = gnb.predict(pd.DataFrame(X_test))
dfyGNB['log_p1'] = pd.DataFrame(gnb.predict_proba(pd.DataFrame(X_test)))[0]
dfyGNB['log_p2'] = pd.DataFrame(gnb.predict_proba(pd.DataFrame(X_test)))[1]
dfyGNB['log_p3'] = pd.DataFrame(gnb.predict_proba(pd.DataFrame(X_test)))[2]
dfyGNB['p'] = dfyGNB[['log_p1', 'log_p2', 'log_p3']].max(axis=1)
```

**PNL å›æº¯æµ‹è¯•**

ç„¶åï¼Œä¸ºäº†æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬ç»˜åˆ¶äº†ä»¥ä¸‹å†…å®¹

```
dfyGNB['NB_returns'] = dfyGNB['Returns'] * dfyGNB['NB_pred']
dfyGNB["Kelly_NB_returns"] = dfyGNB['Returns'] * dfyGNB['NB_pred'] * (((2*(dfyGNB['p']))-1)/2)
dfyGNB[['Returns', 'NB_returns', 'Kelly_NB_returns']].cumsum().apply(np.exp).plot(figsize=(10, 6))
```

è¿™å°±äº§ç”Ÿäº†ä¸‹é¢è¿™ä¸ªä¸èµ·çœ¼çš„å›¾å½¢ã€‚

![](img/9bb8a2b072ed5a8575b0b6a133d623e8.png)

NB é€€è´§â€” JPM

é€šè¿‡è®¡ç®—æ¯ä¸€æ¬¡æˆ‘ä»¬æ·»åŠ ä¸€ä¸ªæ­£ç»“æœçš„æ¬¡æ•°ï¼Œå¹¶é™¤ä»¥æ’­æ”¾æ¬¡æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°æˆ‘ä»¬çš„æ¨¡å‹åœ¨è¿™æ¬¡æµ‹è¯•ä¸­çš„å‡†ç¡®æ€§ã€‚

```
sum(1 for x in dfyGNB['NB_returns'] if x > 0)/len(dfyGNB['NB_returns'])
```

48.48%çš„å‡†ç¡®ç‡ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åŸºæœ¬ä¸Šæ˜¯åœ¨æŠ›ç¡¬å¸ã€‚ç±»ä¼¼çš„ç»“æœé€‚ç”¨äºä¸‹é¢çš„ BAC å’Œ Cã€‚

![](img/33d3a056c6e262faec97b28e4b705f18.png)

NB é€€è´§â€” BAC

![](img/b2552621a1f96cf569c1ad4ae36659bb.png)

NB è¿”å›â€” C

**é€»è¾‘å›å½’**

é€»è¾‘å›å½’ä¸åŒäºçº¿æ€§å›å½’ï¼Œå› ä¸ºæˆ‘ä»¬ç”¨ä¸‹é¢çš„å‡½æ•°æ¥æ‹Ÿåˆæ¨¡å‹ã€‚

![](img/164d962f6c8a02f318083aa0ef3ded3a.png)![](img/890743f52630f41a06d9cd81f767d485.png)

è¿™ä½¿å¾—å€¼çš„ä¸Šéƒ¨ä¸º 0 æˆ– 1(åœ¨æ›²çº¿çš„ä¸­é—´è¢«åˆ‡å‰²)ã€‚åœ¨æˆ‘ä»¬çš„æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬è¿˜å°†åº”ç”¨ KFold æ–¹æ³•å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒå’Œæµ‹è¯•ï¼Œè°ƒæ•´æˆ‘ä»¬çš„å˜é‡ï¼Œå¹¶åº”ç”¨æ­£åˆ™åŒ–ã€‚æ­£åˆ™åŒ–æ˜¯åº”ç”¨äºæ‹Ÿåˆæ¨¡å‹çš„æƒ©ç½šï¼Œå®ƒå…·æœ‰é€šè¿‡å‡å°‘ç”±æˆ‘ä»¬çš„å›å½’ç»™å‡ºçš„å¤§ç³»æ•°æ¥å¹³è¡¡è¿‡åº¦æ‹Ÿåˆçš„æ•ˆæœã€‚æˆ‘ä»¬çš„æ¨¡å‹ä½¿ç”¨ L2 èŒƒæ•°æ¥è®¡ç®—è¿™äº›æƒ©ç½šï¼Œè¿™æ˜¯å¹³æ–¹å’Œã€‚

```
from sklearn import linear_model
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScalerlm = linear_model.LogisticRegression(C = 1e5, dual=True, solver = 'liblinear', max_iter = 1000, multi_class = 'ovr')
cols = ['Momentum', 'SMA10', 'EMA10', 'ret_1', 'ret_2', 'ret_3', 'ret_4', 'ret_5']scaler = StandardScaler()
scaler.fit(dataBACfinal)dataBACfinalScaled = pd.DataFrame(scaler.transform(dataBACfinal))
dataBACfinalScaled.columns = ['Close', 'Returns', 'ret_1', 'ret_2', 'ret_3', 'ret_4', 'ret_5', 'Momentum', 'SMA10', 'EMA10']y = dataBACfinal["Returns"].values
X = dataBACfinalScaled[cols].shift(-1).fillna(0).values
kf = KFold(n_splits=5, shuffle=True)
kf.get_n_splits(X)for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]lm.fit(pd.DataFrame(X_train), np.sign(y_train))
dfy = pd.DataFrame(y_test)
dfy.columns = ["Returns"]
dfy['SMA10'] = dataBACfinalScaled['SMA10']dfy['log_pred'] = lm.predict(pd.DataFrame(X_test))
dfy['log_p1'] = pd.DataFrame(lm.predict_proba(pd.DataFrame(X_test)))[0]
dfy['log_p2'] = pd.DataFrame(lm.predict_proba(pd.DataFrame(X_test)))[1]
dfy['log_p3'] = pd.DataFrame(lm.predict_proba(pd.DataFrame(X_test)))[2]
dfy['p'] = dfy[['log_p1', 'log_p2', 'log_p3']].max(axis=1)dfy['log_returns'] = dfy['Returns'] * dfy['log_pred']
dfy["Kelly_log_returns"] = dfy['Returns'] * dfy ['log_pred'] * (((2*(dfy['p']))-1)/2)
dfy[['Returns', 'log_returns', 'Kelly_log_returns']].cumsum().apply(np.exp).plot(figsize=(10, 6))sum(1 for x in dfy['log_returns'] if x > 0)/len(dfy['log_returns'])
```

**PNL å›æµ‹**

è¿™äº›ç»“æœå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![](img/9fead1e227f95be715e13f000e822ba8.png)

é€»è¾‘å›å½’â€” JPM

è¯¥æ¨¡å‹æ˜¾ç¤ºäº† 51.01%çš„å‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œç»“æœç»å¸¸åœ¨ 48%å’Œ 52%çš„å‡†ç¡®åº¦ä¹‹é—´å˜åŒ–ï¼Œå› æ­¤å®ƒä»ç„¶æ˜¯èµŒåšï¼Œå¹¶ä¸”æ²¡æœ‰äº§ç”Ÿä¸€è‡´çš„ alphaã€‚BAC å’Œ C çš„ç±»ä¼¼ç»“æœå¦‚ä¸‹ã€‚

![](img/4c51c4a13b39cb65cf3e9f639f959387.png)

é€»è¾‘å›å½’ BAC

![](img/ff59dc1cef4cd7a3c7a04e84f0cee4f9.png)

é€»è¾‘å›å½’â€” C

**å†³ç­–æ ‘**

å†³ç­–æ ‘æ˜¯å®¹æ˜“ç†è§£æ¨¡å‹ã€‚ä»–ä»¬çš„åˆ†ç±»è¿‡ç¨‹å¾ˆç®€å•ï¼Œå¹¶ä¸”ä¸åƒæˆ‘ä»¬çš„å…¶ä»–æ¨¡å‹é‚£æ ·å—åˆ°é»‘ç®±æ•ˆåº”çš„å½±å“ã€‚ä¸ºäº†åˆ›å»ºä¸€ä¸ªå†³ç­–æ ‘ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç†µçš„å®šä¹‰ï¼Œå®ƒæ¥è‡ªä¿¡æ¯è®ºçš„æ¦‚å¿µï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

![](img/136c27eea2b9db797e5e46ff06f0bfa1.png)

ç†µå…¬å¼

è¯¥ç­‰å¼å°†ç”¨äºå°†æ•°æ®åˆ†å‰²æˆç¢ç‰‡è¾ƒå°‘çš„å­é›†ã€‚æˆ‘ä»¬çš„æ¨¡å‹å°†ä½¿ç”¨çš„ç®—æ³•å¦‚ä¸‹:

1.  å¦‚æœæ‰€æœ‰æ•°æ®éƒ½æœ‰ç›¸åŒçš„æ ‡ç­¾ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªå¶å­å¹¶åœæ­¢ï¼›
2.  å¦‚æœæ²¡æœ‰æ›´å¤šå¯ç”¨çš„ç‰¹æ€§åˆ†è‰²ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªå…·æœ‰æœ€é«˜å¯èƒ½å€¼çš„å¶å­å¹¶åœæ­¢ï¼›
3.  å¦åˆ™ï¼Œä¸ºæ¯ä¸ªç‰¹å¾æµ‹è¯•ä¸€ä¸ªåˆ†åŒºï¼›
4.  é€‰æ‹©ç†µæœ€å°çš„ä¸€ä¸ªï¼›
5.  åŸºäºä¸Šä¸€æ¬¡å†³ç­–æ·»åŠ ä¸€ä¸ªèŠ‚ç‚¹ï¼›
6.  å¯¹æ¯ä¸ªå­é›†é‡å¤ä¸Šè¿°æ­¥éª¤ã€‚

å¦‚æœæ•°æ®æ˜¯è¿ç»­çš„ï¼Œåˆ™è®¾ç½®æ‹†åˆ†ä½ç½®çš„æ ‡å‡†åŸºäºæœ€å°åŒ–å‡æ–¹è¯¯å·®å’Œå¹³å‡ç»å¯¹è¯¯å·®ã€‚ä½¿ç”¨ Scikit å­¦ä¹ åº“ï¼Œæˆ‘ä»¬ç¼–å†™äº†ä»¥ä¸‹æ¨¡å‹ã€‚åŒæ ·ï¼Œæˆ‘ä»¬å€Ÿç”¨ KFold æ–¹æ³•æ¥åˆ†å‰²æ•°æ®ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åšæ³•ï¼Œå› ä¸ºè¿™ç§æ–¹æ³•å€¾å‘äºä¸¥é‡è¿‡åº¦æ‹Ÿåˆæµ‹è¯•æ•°æ®ã€‚è¿™ä¸€æ¬¡ï¼Œæ²¡æœ‰ç†ç”±ç¼©æ”¾æˆ‘ä»¬çš„æ•°æ®ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡æœ‰åˆ›å»ºå¯èƒ½å¯¼è‡´ä¸å¹³è¡¡ç³»æ•°çš„å•ä¸€å›å½’ã€‚åœ¨è¿™ä¸ªæ¨¡å‹ä¸­ç¼©æ”¾åªä¼šé˜»ç¢æˆ‘ä»¬å¯¹å®ƒçš„ç†è§£ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬å¹¶ä¸è¯•å›¾è¿›è¡Œå›å½’ï¼Œæˆ‘ä»¬åªæ˜¯æƒ³é¢„æµ‹å‘ä¸Šæˆ–å‘ä¸‹çš„è¿åŠ¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åˆ›å»ºäº†å¦ä¸€ä¸ªå¸¦æœ‰å›æŠ¥ç¬¦å·çš„åˆ—ï¼Œ1 è¡¨ç¤ºè´Ÿå›æŠ¥ï¼Œ0 è¡¨ç¤ºæ­£å¥½ä¸ºé›¶(å‘ç”Ÿäº†å‡ æ¬¡)ï¼Œ1 è¡¨ç¤ºæ­£å›æŠ¥ã€‚è¿™ä¸ªä¸“æ å°†ç”¨äºæ‹Ÿåˆå’Œæµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹ã€‚

```
from sklearn import tree
from sklearn.model_selection import KFold
from subprocess import call
dataBACfinal['Up_down'] = (np.sign(dataBACfinal['Returns']))
cols = ['Momentum', 'SMA10', 'EMA10', 'ret_1', 'ret_2', 'ret_3', 'ret_4', 'ret_5']kf = KFold(n_splits=5, shuffle=True)X = dataBACfinal[cols].fillna(0).values
y = dataBACfinal["Up_down"].shift(-1).fillna(0).valuesfor train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]clf = tree.DecisionTreeClassifier()clf.fit(X_train,y_train)CTreeResult = pd.DataFrame(dataBACfinal['Returns'].values[test_index])
CTreeResult.columns = ['Returns']
CTreeResult['tree_prediction'] = pd.DataFrame(clf.predict(X_test))
CTreeResult['log_p1'] = pd.DataFrame(clf.predict_proba(pd.DataFrame(X_test)))[0]
CTreeResult['log_p2'] = pd.DataFrame(clf.predict_proba(pd.DataFrame(X_test)))[1]
CTreeResult['log_p3'] = pd.DataFrame(clf.predict_proba(pd.DataFrame(X_test)))[2]
CTreeResult['p'] = CTreeResult[['log_p1', 'log_p2', 'log_p3']].max(axis=1)CTreeResult['tree_returns'] = CTreeResult['Returns'] * CTreeResult['tree_prediction']
CTreeResult["Kelly_tree_returns"] = CTreeResult['Returns'] * CTreeResult['tree_prediction'] * (((2*(CTreeResult['p']))-1)/2)CTreeResult[['Returns', 'tree_returns', 'Kelly_tree_returns']].cumsum().apply(np.exp).plot(figsize=(10, 6))sum(1 for x in CTreeResult['tree_returns'] if x > 0)/len(CTreeResult['tree_returns'])
```

**PNL å›æº¯æµ‹è¯•**

è¿™å°†äº§ç”Ÿä»¥ä¸‹ç»“æœã€‚

![](img/c4c8a20ec679c5fb97f7799c3548a116.png)

å†³ç­–æ ‘â€” JPM

è¯¥æ¨¡å‹çš„å‡†ç¡®ç‡ä¸º 46.50%ã€‚

é€šè¿‡ä½¿ç”¨ tree.export_graphviz(clf)å‘½ä»¤ï¼Œå¯ä»¥ä½¿ç”¨ Graphviz å¯è§†åŒ–è¿™ä¸ªæ¨¡å‹ã€‚è¿™äº›æ ‘å¦‚ä¸‹æ‰€ç¤ºã€‚

![](img/ef7b2a7c5615dab4b20fd7c0f511a18e.png)

JPM å†³ç­–æ ‘å¯è§†åŒ–

BAC å’Œ C çš„ç»“æœå¦‚ä¸‹ã€‚

![](img/c20a996f20d1cd11166bc4770ca57c6c.png)

å†³ç­–æ ‘â€” BAC

![](img/2157acfa1c945337c04fc1065fa5a75a.png)

BAC å†³ç­–æ ‘å¯è§†åŒ–

![](img/7bd6ff246a4f46862f2974ed27789342.png)

å†³ç­–æ ‘â€” C

![](img/d68ab4c98788acca624eaf9795af81d9.png)

c å†³ç­–æ ‘å¯è§†åŒ–

**æ”¯æŒå‘é‡æœº**

æ”¯æŒå‘é‡æœºå°è¯•ä½¿ç”¨å‘é‡æ¥çº¿æ€§åˆ†ç¦»æ•°æ®ï¼Œè¿™äº›å‘é‡åœ¨å®ƒå°è¯•åˆ†ç±»çš„æ•°æ®é›†ä¹‹é—´ä»¥æœ€é«˜çš„å¯èƒ½é—´éš”ç»˜åˆ¶ã€‚é‰´äºå®ƒé€šå¸¸æ„å»ºä¸€ä¸ªè¶…å¹³é¢æ¥ç»˜åˆ¶è¿™äº›å‘é‡ï¼Œå¯è§†åŒ–å¯èƒ½ä¼šå˜å¾—å¤æ‚ã€‚å‡è®¾æˆ‘ä»¬çš„çŸ¢é‡ä½ç½®åŸºäºè·ç¦»ï¼Œæˆ‘ä»¬å°†åœ¨æ‹Ÿåˆä¹‹å‰ç¼©æ”¾çŸ©é˜µï¼Œå¹¶ä½¿ç”¨ KFold æ¥åˆ†å‰²æ•°æ®ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Scikit å­¦ä¹ åº“æ¥è®¡ç®—æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

```
from sklearn import svm
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScalerdataBACfinal['Up_down'] = (np.sign(dataBACfinal['Returns']))
cols = ['Momentum', 'SMA10', 'EMA10', 'ret_1', 'ret_2', 'ret_3', 'ret_4', 'ret_5']scaler = StandardScaler()
scaler.fit(dataBACfinal)dataBACfinalScaled = pd.DataFrame(scaler.transform(dataBACfinal))
dataBACfinalScaled.columns = ['Close', 'Returns', 'ret_1', 'ret_2', 'ret_3', 'ret_4', 'ret_5', 'Momentum', 'SMA10', 'EMA10', 'Up_down']kf = KFold(n_splits=5, shuffle=True)X = dataBACfinalScaled[cols].fillna(0).values
y = dataBACfinal["Up_down"].shift(-1).fillna(0).valuesfor train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]svmm = svm.SVC(gamma=0.001, probability = True)
svmm.fit(X_train, y_train)CSVMResult = pd.DataFrame(dataBACfinal['Returns'].values[test_index])
CSVMResult.columns = ['Returns']
CSVMResult['log_p1'] = pd.DataFrame(svmm.predict_proba(pd.DataFrame(X_test)))[0]
CSVMResult['log_p2'] = pd.DataFrame(svmm.predict_proba(pd.DataFrame(X_test)))[1]
CSVMResult['log_p3'] = pd.DataFrame(svmm.predict_proba(pd.DataFrame(X_test)))[2]
CSVMResult['p'] = CSVMResult[['log_p1', 'log_p2', 'log_p3']].max(axis=1)
CSVMResult['SVM_prediction'] = pd.DataFrame(svmm.predict(X_test))
CSVMResult['SVM_returns'] = CSVMResult['Returns'] * CSVMResult['SVM_prediction']
CSVMResult["Kelly_SVM_returns"] = CSVMResult['Returns'] * CSVMResult['SVM_prediction'] * (((2*(CSVMResult['p']))-1)/2)
CSVMResult[['Returns', 'SVM_returns', 'Kelly_SVM_returns']].cumsum().apply(np.exp).plot(figsize=(10, 6))
```

**PNL å›æµ‹**

è¿™ä¸ºæˆ‘ä»¬æä¾›äº†ä»¥ä¸‹ç»“æœï¼Œå‡†ç¡®ç‡ä¸º 47.97%

![](img/0ae4eab33fadd5b59ecbcd2f980e2622.png)

SVM â€” JPM

å½“æˆ‘ä»¬è¯•å›¾åœ¨ 2D å›¾å½¢ä¸­å¯è§†åŒ–æˆ‘ä»¬çš„çŸ¢é‡æ—¶ï¼Œå¤§å¤šæ•°æ–¹æ³•å¾—åˆ°çš„æ˜¯ä¸€ä¸ªæ²¡æœ‰ç­‰é«˜çº¿çš„åˆ†å¸ƒã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬ä½¿ç”¨äº†å¾ˆå¤šç‰¹æ€§ï¼Œç”¨å›¾å½¢è¡¨ç¤ºå®ƒä»¬å˜å¾—éå¸¸å¤æ‚ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡é€‰æ‹© SMA å’Œ EMA ä½œä¸ºæˆ‘ä»¬è¡¨ç¤ºçš„ç‰¹å¾æ¥ç»˜åˆ¶æˆ‘ä»¬çš„å›¾å½¢ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

![](img/6b01c9ec3e0344db52bf1a143bbbe8d6.png)

æˆ‘ä»¬çš„æ•°æ®åœ¨é‚£é‡Œï¼Œä½†è½®å»“è¶…å‡ºäº†ç•Œé™ã€‚BAC å’Œ C çš„ç»“æœç›¸ä¼¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

![](img/72207696e156c4b0a514c12ddf6107e7.png)

SVM â€” BAC

![](img/71c053b8edf6a37553569830e4a588a3.png)

SVMâ€”â€”C

**æ€»ç»“**

æˆ‘ä»¬æœ‰æ—¶å¯èƒ½ä¼šè¢«è¯±æƒ‘å»æµ‹è¯•å¾ˆé…·çš„æ–° ML æ¨¡å‹æ¥é¢„æµ‹è‚¡ç¥¨å¸‚åœºçš„æœªæ¥å›æŠ¥ï¼Œä½†æ˜¯åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ‰èƒ½çœŸæ­£æ„Ÿå—åˆ°ä»·æ ¼è¡Œä¸ºçš„éšæœºæ€§ï¼Œä»¥åŠè¿™å¯¹æœ‰æ¢¦æƒ³çš„ç»Ÿè®¡å­¦å®¶æ¥è¯´æ˜¯å¤šä¹ˆä¸å¯é€¾è¶Šã€‚ç”¨å¼€ç®±å³ç”¨çš„æ¨¡å‹è¿›è¡Œç®€å•çš„é¢„æµ‹å¾ˆå¯èƒ½ä¼šè®©ä½ ä¸€æ— æ‰€è·(å°±åƒæˆ‘åœ¨è¿™é‡Œåšçš„ä¸€æ ·)ï¼Œè¿™å¤ªå¤æ‚äº†ï¼Œå¤§å¤šæ•°å¸¸å®¢çš„æ–¹æ³•ç”šè‡³ä¼šåœ¨ä½ æœ‰ä¸€ä¸ªå¥½çš„æ¼”ç¤ºæ–‡ç¨¿å‘äº¤æ˜“å°çš„åŒäº‹å±•ç¤ºå¹¶è¦æ±‚å¼€å‘é¢„ç®—ä¹‹å‰å´©æºƒã€‚

è‡ªç„¶ï¼Œè‚¯å®šä¼šæœ‰èµ¢å®¶(ä¸Šé¢çš„ä¸€äº›æ¨¡å‹åœ¨å›æº¯æµ‹è¯•ä¸­æ˜¾ç¤ºäº†è¶…è¿‡ 10%çš„ alphaï¼Œä½†è¯·è®°ä½ï¼Œ**å›æº¯æµ‹è¯•ä¸æ˜¯ç§‘å­¦[é‡å¤ 10 æ¬¡]** )ï¼Œä½†èµ¢å®¶è‡ªç„¶ä¼šåœ¨éšæœºç¯å¢ƒä¸­å‡ºç°ï¼Œå¹¸å­˜è€…åå·®ä¼šåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šè¯´æœå³ä½¿æ˜¯å¹¸è¿çš„äººï¼Œä»–ä»¬ä¹Ÿåªæ˜¯é‚£ä¹ˆå¥½ã€‚

**æœ€åï¼Œé‰´äºé‡‘èå¸‚åœºå›ºæœ‰çš„éšæœºæ€§ï¼Œå¯¹ä»»ä½•è¡¨ç°å‡ºè¿‡åº¦ç¡®å®šæ€§å¹¶å£°ç§°æ‹¥æœ‰ä¸åˆç†å®åŠ›çš„äººéƒ½è¦æŒæ€€ç–‘æ€åº¦ï¼Œå³ä½¿é‚£ä¸ªäººå°±æ˜¯ä½ è‡ªå·±ã€‚**