<html>
<head>
<title>Data Transfer Process with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python的数据传输过程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-transfer-process-with-python-999b6cbcd7ea?source=collection_archive---------5-----------------------#2021-01-19">https://medium.com/analytics-vidhya/data-transfer-process-with-python-999b6cbcd7ea?source=collection_archive---------5-----------------------#2021-01-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="967e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇文章中，我们将开发一个使用URL链接下载多个文件的过程，在一个循环中解压缩扩展名为“… tsv.gz”的文件，并将数据传输到SQL表中。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/ca6f030516183401dd42375d61b6b89d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wUT7ekI9K141c_9Z4brfGw.jpeg"/></div></div></figure><blockquote class="jp jq jr"><p id="26ca" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated">1-让我们从导入库开始。</p></blockquote><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="b9a1" class="kb kc hi jx b fi kd ke l kf kg"><strong class="jx hj"># Libraries</strong><br/>import re<br/>from urllib import request<br/>import gzip<br/>import shutil<br/>import requests<br/>import pandas as pd<br/>import pyodbc<br/>import sqlalchemy<br/>import urllib<br/>from multiprocessing.pool import ThreadPool</span></pre><blockquote class="jp jq jr"><p id="ff9b" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj"> 2 -我们定义了用URL链接下载文件然后解压的函数。gz”文件。</strong></p></blockquote><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="1379" class="kb kc hi jx b fi kd ke l kf kg">def download_url(url):<br/>    <strong class="jx hj"># Download process</strong><br/>    print("downloading: ",url)<br/>    file_title = re.split(pattern='/', string=url)[-1]<br/>    urlrtv = request.urlretrieve(url=url, filename=file_title)<br/>    <br/><strong class="jx hj">    # for ".tsv" to ".csv"</strong><br/>    title = re.split(pattern=r'\.tsv', string=file_title)[0] +".csv"<br/>    <br/>    <strong class="jx hj"># Unzip ".gz" file</strong><br/>    with gzip.open(file_title, 'rb') as f_in:<br/>        with open(title, 'wb') as f_out:<br/>            shutil.copyfileobj(f_in, f_out)</span></pre><blockquote class="jp jq jr"><p id="a8e4" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj"> 3 -首先，我们定义URL链接，我们将发送到我们已经创建的函数到一个列表中。</strong></p></blockquote><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="03ac" class="kb kc hi jx b fi kd ke l kf kg"><strong class="jx hj"># URL List</strong><br/>urls = ["<a class="ae kh" href="https://datasets.imdbws.com/title.episode.tsv.gz" rel="noopener ugc nofollow" target="_blank">https://datasets.imdbws.com/title.episode.tsv.gz</a>"<br/>        ,"<a class="ae kh" href="https://datasets.imdbws.com/title.ratings.tsv.gz" rel="noopener ugc nofollow" target="_blank">https://datasets.imdbws.com/title.ratings.tsv.gz</a>"<br/>        #,"<a class="ae kh" href="https://datasets.imdbws.com/title.akas.tsv.gz" rel="noopener ugc nofollow" target="_blank">https://datasets.imdbws.com/title.akas.tsv.gz</a>"<br/>        #,"<a class="ae kh" href="https://datasets.imdbws.com/title.basics.tsv.gz" rel="noopener ugc nofollow" target="_blank">https://datasets.imdbws.com/title.basics.tsv.gz</a>"<br/>        #,"<a class="ae kh" href="https://datasets.imdbws.com/title.crew.tsv.gz" rel="noopener ugc nofollow" target="_blank">https://datasets.imdbws.com/title.crew.tsv.gz</a>"<br/>        #,"<a class="ae kh" href="https://datasets.imdbws.com/title.principals.tsv.gz" rel="noopener ugc nofollow" target="_blank">https://datasets.imdbws.com/title.principals.tsv.gz</a>"<br/>        #,"<a class="ae kh" href="https://datasets.imdbws.com/name.basics.tsv.gz" rel="noopener ugc nofollow" target="_blank">https://datasets.imdbws.com/name.basics.tsv.gz</a>"<br/>          ]</span><span id="800c" class="kb kc hi jx b fi ki ke l kf kg"><strong class="jx hj"># Run 5 multiple threads. Each call will take the next element in urls list</strong><br/>results = ThreadPool(5).imap_unordered(download_url, urls)<br/>for r in results:<br/>    print(r)</span></pre><blockquote class="jp jq jr"><p id="6d97" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated">我们下载了文件，解压后转换成CSV格式。下一步是将数据转换成数据框，以便我们可以轻松地处理数据并将其导出到SQL。</p></blockquote><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="d96d" class="kb kc hi jx b fi kd ke l kf kg"><strong class="jx hj"># Read <em class="js">".csv"</em> file for Title Ratings</strong><br/>title_ratings_data = pd.read_csv (‘title.ratings.csv’,sep=’\\t’,engine = ‘python’,na_values=[‘\\N’])</span><span id="74ed" class="kb kc hi jx b fi ki ke l kf kg"><strong class="jx hj"># Data to DataFrame </strong><br/>title_ratings = pd.DataFrame(title_ratings_data, columns= ['tconst','averageRating','numVotes'])</span><span id="aca7" class="kb kc hi jx b fi ki ke l kf kg"><strong class="jx hj"># Read <em class="js">".csv"</em> file for Title Episode<br/></strong>title_episode_data = pd.read_csv ('title.episode.csv',sep='\\t',engine = 'python',na_values=['\\N'])</span><span id="5215" class="kb kc hi jx b fi ki ke l kf kg"><strong class="jx hj"># Data to DataFrame<br/></strong>title_episode = pd.DataFrame(title_episode_data, columns= ['tconst','parentTconst','seasonNumber','episodeNumber']</span></pre><blockquote class="jp jq jr"><p id="e749" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated">然后，我们将把数据框中的数据插入到SQL表中。在这里，数据写入可以用许多不同的方式来完成。下面的代码块显示了最佳性能。</p></blockquote><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="8abb" class="kb kc hi jx b fi kd ke l kf kg"><strong class="jx hj"># Insert DataFrame to SQL Table for Title Ratings</strong><br/>driver = ‘{ODBC Driver 17 for SQL Server}’<br/>server = ‘(local)’<br/>database = ‘MediumDS’<br/>username = ‘medium’<br/>password = ‘mediumds’<br/>tbl = ‘title_ratings’</span><span id="00be" class="kb kc hi jx b fi ki ke l kf kg"><strong class="jx hj"># Database connection<br/></strong>params = ‘DRIVER=’+driver + ‘;SERVER=’+server + ‘;PORT=1433;DATABASE=’ + database + ‘;UID=’ + username + ‘;PWD=’ + password</span><span id="884d" class="kb kc hi jx b fi ki ke l kf kg">cnxn = pyodbc.connect(params)<br/>cursor = cnxn.cursor()</span><span id="cf77" class="kb kc hi jx b fi ki ke l kf kg"><strong class="jx hj"># Create SQL Table</strong><br/>cursor.execute(‘DROP TABLE IF EXISTS dsf.title_ratings; CREATE TABLE dsf.title_ratings (tconst nvarchar(50), averageRating float, numVotes int)’)<br/>cnxn.commit()</span><span id="0126" class="kb kc hi jx b fi ki ke l kf kg">db_params = urllib.parse.quote_plus(params)<br/>engine = sqlalchemy.create_engine(“mssql+pyodbc:///?odbc_connect={}”.format(db_params))<br/>from sqlalchemy import event</span><span id="12f3" class="kb kc hi jx b fi ki ke l kf kg"><strong class="jx hj"># The code below makes the data load much much faster</strong><br/><a class="ae kh" href="http://twitter.com/event" rel="noopener ugc nofollow" target="_blank">@event</a>.listens_for(engine, “before_cursor_execute”)<br/>def receive_before_cursor_execute(<br/> cnxn, cursor, statement, params, context, executemany<br/> ):<br/> if executemany:<br/> cursor.fast_executemany = True</span><span id="7039" class="kb kc hi jx b fi ki ke l kf kg"><strong class="jx hj"># Insert Raw Data</strong><br/>title_ratings.to_sql(tbl, engine, index=False, if_exists=”append”, schema=”dsf”)</span></pre><p id="b202" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">…</p><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="c5c1" class="kb kc hi jx b fi kd ke l kf kg"><strong class="jx hj"># Insert DataFrame to SQL Table for Title Episode</strong><br/>tbl = ‘title_episode’</span><span id="2ac1" class="kb kc hi jx b fi ki ke l kf kg">cursor.execute(‘DROP TABLE IF EXISTS dsf.title_episode; CREATE TABLE dsf.title_episode (tconst nvarchar(50),parentTconst nvarchar(50),seasonNumber int,episodeNumber int)’)<br/>cnxn.commit()</span><span id="0970" class="kb kc hi jx b fi ki ke l kf kg">db_params = urllib.parse.quote_plus(params)<br/>engine = sqlalchemy.create_engine(“mssql+pyodbc:///?odbc_connect={}”.format(db_params))<br/>from sqlalchemy import event</span><span id="ff8b" class="kb kc hi jx b fi ki ke l kf kg"><a class="ae kh" href="http://twitter.com/event" rel="noopener ugc nofollow" target="_blank">@event</a>.listens_for(engine, “before_cursor_execute”)<br/>def receive_before_cursor_execute(<br/> cnxn, cursor, statement, params, context, executemany<br/> ):<br/> if executemany:<br/> cursor.fast_executemany = True</span><span id="b840" class="kb kc hi jx b fi ki ke l kf kg">title_episode.to_sql(tbl, engine, index=False, if_exists=”append”, schema=”dsf”)</span><span id="9365" class="kb kc hi jx b fi ki ke l kf kg"># Delete DF<br/># title_episode = title_episode[0:0]<br/># title_episode_data = title_episode_data[0:0]</span></pre><blockquote class="jp jq jr"><p id="7459" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj"> 6 -传送过程中可能出现问题，或者传送可能被中断。我们来测试一下。</strong></p></blockquote><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="2142" class="kb kc hi jx b fi kd ke l kf kg">rowcounts = [["title_episode",len(title_episode)],["title_ratings",len(title_ratings)]]<br/>rowcountsdf = pd.DataFrame(rowcounts,columns=['DataFrame','DFRowCount'])</span><span id="f7e0" class="kb kc hi jx b fi ki ke l kf kg">SQL_RowCount = pd.read_sql_query(<br/>                                '''SELECT [Tables].name AS   [TableName],SUM([Partitions].[rows]) AS [TableRowCount]<br/>                                FROM sys.tables AS [Tables]<br/>                                JOIN sys.partitions AS [Partitions] ON [Tables].[object_id] = [Partitions].[object_id]AND [Partitions].index_id IN ( 0, 1 )<br/>                                GROUP BY [Tables].name''', cnxn)<br/>tablesdf = pd.DataFrame(SQL_RowCount,columns=['TableName','TableRowCount'])</span><span id="d50f" class="kb kc hi jx b fi ki ke l kf kg">pd.concat([rowcountsdf, tablesdf], axis=1, join="inner")</span></pre><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kj"><img src="../Images/1fb63a4acb37f66a9e648d2d6c7c828d.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*QP7E_uWnisqWP-gXXjinRw.png"/></div></figure><blockquote class="jp jq jr"><p id="9a08" class="if ig js ih b ii ij ik il im in io ip jt ir is it ju iv iw ix jv iz ja jb jc hb bi translated"><strong class="ih hj">7——而在这篇代表我执念的一面的文章中，我们转移”。gz”和”。csv”文件复制到“备份”文件夹。</strong></p></blockquote><pre class="je jf jg jh fd jw jx jy jz aw ka bi"><span id="2f6f" class="kb kc hi jx b fi kd ke l kf kg">import shutil</span><span id="d773" class="kb kc hi jx b fi ki ke l kf kg">original_csv = r’C:\Users\busra\Documents\Python Scripts\title.ratings.csv’<br/>original_gz = r’C:\Users\busra\Documents\Python Scripts\title.ratings.tsv.gz’<br/>target_csv = r’C:\Users\busra\Documents\Python Scripts\Backups\CSVs\title.ratings.csv’<br/>target_gz = r’C:\Users\busra\Documents\Python Scripts\Backups\Gzs\title.ratings.tsv.gz’</span><span id="de1e" class="kb kc hi jx b fi ki ke l kf kg">shutil.move(original_csv,target_csv)<br/>shutil.move(original_gz,target_gz)</span></pre><p id="eb72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">仅此而已。</p><p id="0236" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">虽然您并不总是需要直接在Python上操作整个过程，但是我们已经研究了可以一部分一部分地集成到数据传输或ETL过程中的代码块。</p></div></div>    
</body>
</html>