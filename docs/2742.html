<html>
<head>
<title>Cycle GAN(Generative Adverserial Network) for MRI Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MRI图像的循环GAN(生成式广告串行网络)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cycle-gan-generative-adveserial-network-for-mri-images-349f0cb3e67e?source=collection_archive---------8-----------------------#2021-05-15">https://medium.com/analytics-vidhya/cycle-gan-generative-adveserial-network-for-mri-images-349f0cb3e67e?source=collection_archive---------8-----------------------#2021-05-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="6a3b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">涵盖的主题</h1><ul class=""><li id="cbfd" class="jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju bi translated">磁共振图像及其类型</li><li id="a52b" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">什么是氮化镓及其应用</li><li id="4019" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">循环GAN及其体系结构</li><li id="472d" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">结论</li></ul><h1 id="b683" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">磁共振图像及其类型</h1><p id="7c71" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">磁共振成像(MRI)是一种医学成像技术，用于在放射学中捕捉解剖结构的照片。MRI扫描仪使用强磁场、磁场梯度和无线电波来生成身体器官的图像。</p><p id="94e1" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">有各种类型的MRI能够捕捉不同类型的异常。因此，使用另一种类型的MRI可以提高诊断的准确性，从而可以对患者进行更好的治疗。</p><p id="59c2" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">两种类型的MRI图像是:</p><ul class=""><li id="3ed8" class="jd je hi jf b jg kp ji kq jk ku jm kv jo kw jq jr js jt ju bi translated">T1加权MRI图像(T1图像)</li><li id="693b" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">T2加权磁共振成像(T2图像)</li></ul><p id="9ec6" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">钛和T2加权磁共振成像突出不同的组成部分，如水，脂肪，肌肉和肿瘤。下表给出了比较结果</p><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lc ld l"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">T1和T2加权图像的比较</figcaption></figure><p id="2321" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">然而，创建不同类型的MRI图像既困难又昂贵。</p><p id="c14d" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">医生经常一次开出一种类型的MRI，但是如果你可以从我们已经有的一种MRI图像创建另一种类型的MRI图像，而不需要投入同样多的时间、精力和金钱，会怎么样呢？</p><p id="6d00" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">生成对抗网络(GANs)提供了从现有的MRI创建另一种类型的MRI的可能性。在这篇博客中，我们将讨论GAN的一种特殊变体，称为<strong class="jf hj">周期GAN </strong>。</p><h1 id="5b10" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">甘是什么？</h1><p id="2c54" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated"><strong class="jf hj">甘</strong>代表生成对抗网络，这是一种算法架构，使用两个神经网络相互对抗，以生成看起来像真实数据的新的合成数据实例。蒙特利尔大学的Ian Goodfellow和其他研究人员在他们的<a class="ae li" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">论文</a>中介绍了gan。这个想法是如此的受欢迎，以至于脸书的人工智能研究主任Yann LeCun称对抗性训练是“过去10年中最有趣的想法”。</p><p id="279c" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">GANs具有模仿任何数据分布的潜力，因此对善和恶都有巨大的潜力。甘人可以被教会在任何领域创造与我们相似的世界，比如图像、音乐、语音等等。</p><p id="026b" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">现在我们来了解为什么叫甘，</p><p id="2808" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">生成:</strong>在GAN中，网络学习生成模型，该模型根据概率模型描述数据是如何生成的。</p><p id="8d8f" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">对抗:</strong>使用<a class="ae li" href="https://en.wikipedia.org/wiki/Adversarial_machine_learning" rel="noopener ugc nofollow" target="_blank">高级辅助设置</a>训练模型。</p><p id="f447" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">网络:</strong>使用深度神经网络进行训练。</p><p id="865b" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">gan有两个网络<strong class="jf hj">生成器</strong>和<strong class="jf hj">鉴别器</strong>，它们以敌对关系<strong class="jf hj">耦合。</strong>生成器的任务是生成假样本数据并试图欺骗鉴别器。另一方面，鉴别器试图区分真假样品。生成器和鉴别器都是神经网络，它们在训练阶段相互竞争。更新生成器以更好地欺骗鉴别器，其中鉴别器(分类器)试图检测生成的(假的)图像，即将图像分类为假的或真实的。生成器和鉴别器互相推动，成为自己更好的版本。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lj"><img src="../Images/3f3e91b1de1658a1dd036c4d8611b01e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*nYzQvrPDmVDuxBo3QHumWg.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">GANs中发生器和鉴别器的优势关系</figcaption></figure><p id="e7bf" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">训练阿甘:</strong></p><p id="6675" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">最初，生成器和鉴别器都是新手，不熟练。因此，来自输入噪声的发生器将产生随机哑图像。那时，鉴别者(也不是那么熟练)可以很容易地将哑图像分类为假的。因此，发生器未能降低鉴别器的误差率。这是发生器更好地产生新图像的信号。随着我们继续深入训练，生成器将产生更好的新图像，与鉴别器无法区分。现在discriminator被迫学习和改进。这个过程在训练过程中继续，使得生成器和鉴别器都变得更好。</p><p id="d54d" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">甘损失:</strong></p><ul class=""><li id="104f" class="jd je hi jf b jg kp ji kq jk ku jm kv jo kw jq jr js jt ju bi translated"><strong class="jf hj"> <em class="lm">鉴别器损失(分类器损失)</em> </strong></li></ul><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/02f2f7627cd018056da5a8a2fb23a911.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-f5M4Lb9KzMOaZnC5RcXVg.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">鉴频器损耗</figcaption></figure><p id="191b" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">有两个与鉴别器相关的损失函数。鉴别器对生成器生成的真实和虚假数据进行分类。鉴别器损失惩罚将真实实例误分类为假实例或将假实例误分类为真实实例的鉴别器。鉴别器的权重通过来自鉴别器网络的反向传播来更新。</p><p id="0532" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">在训练鉴别器时，来自真实集合的数据的标签是y=1，而来自生成器的数据的标签是y=0</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es ls"><img src="../Images/4f35dcb860e9b8d3ddd62f84ff14fa94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1368/format:webp/1*iNSk9JPGqziHVKWTvVuXLA.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">真实图像的鉴频器损耗方程</figcaption></figure><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es lt"><img src="../Images/b40e1fa750dc8f207241bb149a8e2067.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qKgGkCO4OMVTnOAjONY4fQ.png"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">伪图像的鉴别器损耗方程</figcaption></figure><p id="8463" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">由于鉴别器的目标是正确地对假数据集和真数据集进行分类，因此应该最大化上述两个等式，并且鉴别器的最终损失函数如下所示:</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lu"><img src="../Images/bb0d85a3d535611d239b32c2d509d59b.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*7bN93y2dXVHw-ocsLve2nw.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">最终鉴频器损耗方程</figcaption></figure><ul class=""><li id="e68e" class="jd je hi jf b jg kp ji kq jk ku jm kv jo kw jq jr js jt ju bi translated"><strong class="jf hj"> <em class="lm">发电机损耗</em> </strong></li></ul><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lv"><img src="../Images/b9a47f99554a399829f291cb960355d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1388/format:webp/1*ae0XIwwHDFXa8bEK-CP6dQ.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">发电机损耗</figcaption></figure><p id="440f" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">发生器损耗仅取决于伪图像(由发生器网络产生)的鉴别器输出。训练发生器时，鉴别器保持固定(不训练鉴别器的权重和偏差)。这背后的原因是，鉴别器不应该变得太强，以至于将发生器的所有输出都归类为假的。从通过鉴别器和发生器的反向传播获得的梯度仅用于改变发生器的权重。</p><p id="baac" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">发生器的目的是欺骗鉴频器，使其尽量减少鉴频器的损耗。因为鉴别器在训练期间被冻结，所以发生器和y=1(真实数据)不用于损失计算。因此，发电机的最终损耗函数如下所示</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lw"><img src="../Images/7d2c6efe64d5900719f2f9d720095db3.png" data-original-src="https://miro.medium.com/v2/resize:fit:678/format:webp/1*tjIJqhCx0oB9wuNi56eyiw.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">鉴频器损耗方程</figcaption></figure><p id="90aa" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">注:<br/> </strong>鉴别器对于真假图像都会有相似的二值交叉熵损失。</p><h1 id="cdc8" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">循环GAN</h1><p id="406c" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">在GANs中，数据是从噪声中生成的，但是如果我们想要将一种类型(风格/领域)的图像转换成另一种类型(风格/领域)的图像，该怎么办呢？在这里，普通的GAN网络是没有用的。我们将不得不做类似于<strong class="jf hj">图像到图像</strong>的翻译。</p><p id="b741" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">基于所使用的数据类型，图像到图像的转换有两种类型</p><ul class=""><li id="35ee" class="jd je hi jf b jg kp ji kq jk ku jm kv jo kw jq jr js jt ju bi translated"><strong class="jf hj">成对的</strong> <br/>这里，你对每个输入图像都有精确的映射输出图像。对于这种翻译，使用了pix2pix架构</li><li id="8309" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated"><strong class="jf hj">不成对</strong> <br/>在这里，输入和输出图像之间没有唯一的关系。不成对数据也称为<strong class="jf hj">独立数据</strong>。对于不成对方法，我们可以使用<strong class="jf hj"> CycleGAN、DualGAN和DiscoGAN </strong></li></ul><p id="12a0" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">不成对方法的优点是您不需要输入图像的标签。</strong></p><p id="b67e" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">循环GAN用于从一个域生成另一个域的图像。这之所以成为可能，是因为一种叫做U-net的架构(下图)</p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lx"><img src="../Images/5e9693d797e8ca251ef81d34d3295e30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/0*e7DZTU6geJ7-MXFY"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">U-net架构</figcaption></figure><p id="8579" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">在U-net架构中，我们首先将图像压缩到低维，然后将其扩展以实现输出图像。第一个压缩步骤称为<strong class="jf hj">下采样</strong>，第二个步骤称为<strong class="jf hj">上采样</strong>。上采样层和下采样层之间也有直接连接，称为<strong class="jf hj">跳过连接</strong>。</p><h1 id="142b" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">cycle gan的架构</strong></h1><p id="83c6" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">循环GAN是GAN架构的扩展，涉及两个发生器模型和两个鉴别器模型的同时训练。一个生成器将来自第一域的图像作为输入并输出第二域的图像，另一个生成器将来自第二域的图像作为输入并生成第一域的图像。</p><p id="1bf3" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">现在考虑使用生成器将图像从第一域转换到第二域，然后使用另一个生成器将相同的第二域图像转换回第一域，这完成了一个循环，这就是为什么命名为循环GAN。</p><p id="022f" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">但是我们为什么需要鉴别器呢？就一个U网不行吗？让我们试着不带偏见地理解这个问题。在没有鉴别器的情况下，我们将不得不使用L1或L2损失进行训练，这将会失败，因为它们依赖于通过逐个像素地进行差分来对输入图像进行自然映射，这并不发展领域理解。因此，当我们使用鉴别器来计算损耗时，我们的生成器被迫学习域的特征，这导致更好的结果。</p><p id="ebf7" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">歧视者是一个新发现！！！</strong></p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es ly"><img src="../Images/29075b4dbc7b4c7f4b0ff05d713eab2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*mJkQr-eF5G0P6eus3bU0nA.png"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">具有两个发生器和两个鉴别器的循环GAN架构</figcaption></figure><p id="75ae" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">所以我们看到，循环GAN只不过是两个GAN一起工作，其中每个GAN都有自己的生成器和鉴别器。</p><p id="8298" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">甘周期亏损:</strong></p><p id="320b" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">即使在周期GAN中，我们也会有类似于GAN的损耗，即鉴别器和发生器的二进制交叉熵损耗。鉴别器将计算真实和虚假数据的损失，而生成器将只计算虚假数据的损失，如前所述。除了这些损耗，GAN循环还有额外的损耗，这些损耗仅用于发电机培训。分别是<strong class="jf hj">周期一致性丢失</strong>和<strong class="jf hj">同一性丢失。</strong>让我们详细了解一下。</p><p id="3ff4" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">周期一致性丢失:</strong></p><p id="984d" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">由于有两个生成器，因此可以在同一域中背靠背地使用它们来生成图像。假设，生成器<strong class="jf hj"> F </strong>从<strong class="jf hj">域Y </strong>转换为<strong class="jf hj">域X </strong>，生成器<strong class="jf hj"> G </strong>从<strong class="jf hj">域X </strong>转换为<strong class="jf hj">域Y</strong>，直观上，该图像应该等同于作为输入发送给生成器<strong class="jf hj"> F </strong>的原始图像。因此，可以计算两幅图像(原始图像和循环生成的图像)之间的L1(平均绝对差)损失。这种损失被认为是<strong class="jf hj">循环一致性损失。</strong></p><figure class="kx ky kz la fd lb er es paragraph-image"><div class="er es lz"><img src="../Images/5b8851e7a2902f8aa128f4edf82beaf9.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/0*EBufzJ6OWceUHTui"/></div><figcaption class="le lf et er es lg lh bd b be z dx translated">循环一致性损失</figcaption></figure><p id="f13a" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">身份丧失:</strong></p><p id="9933" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">如前所述，假设<strong class="jf hj">生成器F </strong>将图像从<strong class="jf hj">域X </strong>转换到<strong class="jf hj">域Y</strong>，现在，如果我们将<strong class="jf hj">域Y </strong>的输入给<strong class="jf hj">生成器F，</strong>预计不会改变任何东西。产生的任何差异都可以用来改进发电机。这种损耗被称为<strong class="jf hj">身份损耗</strong>，它被计算为输入和生成输出之间的L1损耗。</p><h1 id="d1b7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated"><strong class="ak">应用循环GAN在T1和T2 MRI图像之间进行转换</strong></h1><p id="cd08" class="pw-post-body-paragraph ka kb hi jf b jg jh kc kd ji jj ke kf jk kg kh ki jm kj kk kl jo km kn ko jq hb bi translated">本次活动使用的数据可以从<a class="ae li" href="https://github.com/BharathSD/CycleGAN-For-MRI/blob/main/MRI%2BT1_T2%2BDataset.RAR" rel="noopener ugc nofollow" target="_blank">这里</a>下载。</p><p id="a262" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">数据集由43幅T1加权图像和46幅T2加权图像组成，它们是不成对的。</strong></p><div class="kx ky kz la fd ab cb"><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/f2383be80a1a5f651f1938c531322aef.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*LOQAJ1LeeV-SPBLc3T2WYw.png"/></figure><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/83a257a9bfb221e234be8acb5576cce4.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*Bif_Jn8B6IEdbZOjv6h_zw.png"/></figure><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/cff9c243069ab309a2760a9b486297b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*-gbvAVmTwLhWOiSsPc9QNA.png"/></figure></div><div class="ab cb"><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/3f990f9951f4470d6f0cd28def796790.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*Nir_125fsAXJmOGNCjjEzQ.png"/></figure><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/f5d0ee74b276d2c09e9fff2f810dd82f.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*22qJITQA1BvCb1d2noVZNA.png"/></figure><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/de1ba35bab282e6c5bc74230aea44cc7.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*GPk3Kv0hCIjA1wIv5H7R7Q.png"/><figcaption class="le lf et er es lg lh bd b be z dx mg di mh mi translated">T1加权MRI图像</figcaption></figure></div><div class="ab cb"><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/607a44880a3cf86d12c27f46fa5fd7fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*ejzv-RaYIoNtIwiasAob0Q.png"/></figure><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/b2f29aed343ee3afaffb9b99af854320.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*DuHurfvk1h3uS42Lnlg2Rg.png"/></figure><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/0b2dbfdbe7c3f670c6fd10765c326edb.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*qgxhnxWAaCbGfDdzaYN8QQ.png"/></figure></div><div class="ab cb"><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/be3e27ea171f02d416dabdb64c6bcadf.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*g-5LHFORb8UmQ2LcotjDaw.png"/></figure><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/501ff294a5254d21dcb64402e0dc5b9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*HSnm5E22M2OvzEWSNelOYw.png"/></figure><figure class="ma lb mb mc md me mf paragraph-image"><img src="../Images/8914c151e6c23af332fa3c5078ff26cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:362/format:webp/1*IeIiMhHMJO5NiMzmEorf7A.png"/><figcaption class="le lf et er es lg lh bd b be z dx mg di mh mi translated">T2加权磁共振成像图像</figcaption></figure></div><p id="2133" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">该应用程序是使用Tensorflow开发的，代码可以在<a class="ae li" href="https://github.com/BharathSD/CycleGAN-For-MRI.git" rel="noopener ugc nofollow" target="_blank"> github存储库</a>中找到。这依赖于下面的python包</p><ul class=""><li id="b54b" class="jd je hi jf b jg kp ji kq jk ku jm kv jo kw jq jr js jt ju bi translated">数字-1 . 19 . 2</li><li id="986b" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">tensorflow — 2.4.1(如果您有GPU，请使用GPU版本)</li><li id="16b1" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">matplotlib — 3.3.2</li><li id="c06d" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq jr js jt ju bi translated">撇除— 0.17.2</li></ul><p id="5563" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">应用程序遵循下面提到的管道。</strong></p><ol class=""><li id="b5ba" class="jd je hi jf b jg kp ji kq jk ku jm kv jo kw jq mj js jt ju bi translated">导入库</li><li id="d755" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq mj js jt ju bi translated">数据加载和可视化</li><li id="8e48" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq mj js jt ju bi translated">数据预处理</li><li id="a688" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq mj js jt ju bi translated">模型结构</li><li id="2ba2" class="jd je hi jf b jg jv ji jw jk jx jm jy jo jz jq mj js jt ju bi translated">模特培训</li></ol><p id="a6d8" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">数据预处理</strong>步骤包括归一化-1到+1之间的像素值，必要时调整图像大小，并转换为tensorflow所需的通道最后格式。在预处理步骤之后，数据将采用(batch_size，rows，columns，channels)格式。</p><p id="9b70" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">模型构建</strong>步骤包括创建发生器和鉴别器网络。代码示例如下所示。</p><p id="56ee" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">发电机网络:</strong></p><p id="c81a" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">如前所述，发电机网络具有U-net类型的架构。为此，我们首先定义一个代码来构建一个<strong class="jf hj"> resnet </strong>块</p><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lc ld l"/></div></figure><p id="aa2d" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">该函数将过滤器的数量作为输入，并为给定的输入层创建一个resnet块。现在让我们看看利用上面定义的resnet_block创建发电机网络的函数。</p><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lc ld l"/></div></figure><p id="0b92" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">鉴别器网络:</strong></p><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lc ld l"/></div></figure><p id="cca7" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">在生成器和鉴别器网络中，我们都使用了一个<strong class="jf hj">实例规范化层</strong>，它极大地促进了GANs like架构中模块的有效学习。</p><p id="8a81" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">实例规范化:</strong></p><p id="bba4" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">实例标准化类似于对每个图像单独应用的批量标准化。假设你有一个有3个通道的图像，那么对于每个图像，你会有一个平均值和方差，正如你在下面的图片中看到的，并且你对每个图像的每个通道进行归一化。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es ln"><img src="../Images/9581ff7f40a09d23a9610449883d22c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*xgovTIBGmE5-LpTT"/></div></div><figcaption class="le lf et er es lg lh bd b be z dx translated">实例规范化。</figcaption></figure><p id="2ffc" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">要执行实例规范化，首先u必须调用axes=[1，2]的<a class="ae li" href="https://www.tensorflow.org/api_docs/python/tf/nn/moments" rel="noopener ugc nofollow" target="_blank"> tf.nn.moments </a>来计算平均值和方差。<a class="ae li" href="https://www.tensorflow.org/api_docs/python/tf/math/rsqrt" rel="noopener ugc nofollow" target="_blank"> tf.math.rsqrt </a>函数可用于求方差(inv_sqrt_var)的平方根倒数，归一化值可计算为<strong class="jf hj"><em class="lm">(x—mean)* inv _ sqrt _ var</em></strong>，与<strong class="jf hj"> <em class="lm"> 1/stddev </em> </strong>相乘相同。</p><p id="797e" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">更多信息，参见<a class="ae li" href="https://www.tensorflow.org/addons/tutorials/layers_normalizations" rel="noopener ugc nofollow" target="_blank">标准化</a>。</p><p id="e289" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">实例规范化层</strong>的代码如下所示:</p><figure class="kx ky kz la fd lb"><div class="bz dy l di"><div class="lc ld l"/></div></figure><p id="356b" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">将所有这些结合在一起，并在英伟达GTX 1080 Ti GPU上用批量大小4训练网络超过800个时期，我们在T1和T2加权图像之间的转换上获得了非常好的结果。下面的Gif展示了网络如何随着时间的推移学习生成图像。</p><figure class="kx ky kz la fd lb er es paragraph-image"><div role="button" tabindex="0" class="lo lp di lq bf lr"><div class="er es mk"><img src="../Images/824fc2b5467a7c02af0445d425d4f81b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Qi2w5O_jk2RLKJtLGHlEBA.gif"/></div></div></figure><p id="4cd2" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated">可以看出，两个生成器最初都产生垃圾结果，并且随着时间的推移(具有更多的纪元)学会在域之间转换图像。</p><p id="c12b" class="pw-post-body-paragraph ka kb hi jf b jg kp kc kd ji kq ke kf jk kr kh ki jm ks kk kl jo kt kn ko jq hb bi translated"><strong class="jf hj">所有用于训练和被训练模型的代码都可以在github</strong><a class="ae li" href="https://github.com/BharathSD/CycleGAN-For-MRI" rel="noopener ugc nofollow" target="_blank"><strong class="jf hj">cycle gan-For-MRI</strong></a><strong class="jf hj">中找到。</strong></p></div></div>    
</body>
</html>