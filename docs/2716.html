<html>
<head>
<title>Convolutional Neural Network: what it is and how it works</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">卷积神经网络:什么是卷积神经网络及其工作原理</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/convolutional-neural-network-22a9649cee8?source=collection_archive---------13-----------------------#2021-05-14">https://medium.com/analytics-vidhya/convolutional-neural-network-22a9649cee8?source=collection_archive---------13-----------------------#2021-05-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/a8c3a43c5c1373ec20f31f9ddc692aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rBLSep067nm9FQVKnf7YoA.png"/></div></div></figure><p id="3031" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在本文中，我们将讨论<strong class="ir hi">卷积神经网络(CNN) </strong>。</p><p id="e60c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">你刚刚开始你在<a class="ae jn" href="https://www.neuragate.it/intelligenza-artificiale/deep-learning-cose-e-come-funziona/" rel="noopener ugc nofollow" target="_blank">深度学习</a>的旅程吗？我推荐你阅读整篇文章，因为我将从总体上解释CNN是什么。</p><p id="ce08" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我不会在这篇文章中使用数学概念。</p><p id="43ea" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">你准备好了吗？</p><p id="abd4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们开始吧，从基础开始！</p><h1 id="4ea4" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">什么是卷积神经网络？</h1><p id="fbc3" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">卷积神经网络是一种<a class="ae jn" href="https://www.neuragate.it/intelligenza-artificiale/cosa-sono-le-reti-neurali/" rel="noopener ugc nofollow" target="_blank">人工神经网络</a>架构，用于<strong class="ir hi">检测大于64 x 64像素的图像</strong>。</p><p id="86cd" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">与普通的人工神经网络(<strong class="ir hi"> ANN </strong>)不同，CNN被用于实现更好的图像检测(我们将在后面详细介绍)。</p><p id="0955" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这种类型的神经网络也称为<strong class="ir hi"> ConvNet </strong>，常用于物体识别。事实上，它们被用于医疗领域(如<a class="ae jn" href="https://www.neuragate.it/intelligenza-artificiale/radiografia-con-lai-aiuta-a-rilevare-il-cancro-nei-polmoni/" rel="noopener ugc nofollow" target="_blank">癌症检测</a>)、自动驾驶汽车<a class="ae jn" href="https://www.neuragate.it/tech/robotaxi-il-servizio-di-taxi-autonomi-di-autox/" rel="noopener ugc nofollow" target="_blank">(如特斯拉)、农业领域的识别等等。</a></p><p id="a33e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在<a class="ae jn" href="https://www.neuragate.it/intelligenza-artificiale/che-cose-la-computer-vision/" rel="noopener ugc nofollow" target="_blank">计算机视觉</a>中使用的卷积神经网络近年来变得非常流行，因为新的和越来越强大的深度学习算法正在被发现(随着技术的进步)。</p><p id="119f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">写完序言后，我终于可以开始和你讨论普通神经网络和ConvNet之间的区别了。</p><h1 id="6bda" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">CNN和人工神经网络的区别是什么？</h1><p id="92b6" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">人工神经网络的结构与卷积神经网络的结构完全不同。</p><p id="8639" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">理论上，你可以使用人工神经网络来执行图像识别，但这会导致完全灾难性的结果。现在我将试着更好地解释我到目前为止所说的话。</p><p id="7c41" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">想象一个正常的人工神经网络，有成千上万个神经元和隐藏层相互连接:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kr"><img src="../Images/3f5401d542652f4fe1673dbdb67c9707.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/0*cSgGVB0DV4VP1q9P"/></div></div></figure><p id="a53a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于其深度和复杂性，将会出现以下问题:</p><ul class=""><li id="dbae" class="kw kx hh ir b is it iw ix ja ky je kz ji la jm lb lc ld le bi translated">高计算成本</li><li id="c704" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">梯度下降会爆炸</li></ul><p id="cdf6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了避免这种问题，使用了CNN，因为与普通的人工神经网络不同，它们适合于分析图像，这归功于放置在三维空间中的神经元，也称为通道:<strong class="ir hi">高度x宽度x深度</strong>:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es lk"><img src="../Images/71b3a4fd17ef23b310b99112ad1e0be1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/0*UVJt284XYG4iz-ue"/></div></figure><p id="4153" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">除了不费吹灰之力获得更好的结果之外，卷积神经网络还具有以下优点:</p><ul class=""><li id="43d9" class="kw kx hh ir b is it iw ix ja ky je kz ji la jm lb lc ld le bi translated"><strong class="ir hi">参数共享</strong></li><li id="b28e" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated"><strong class="ir hi">连接的稀疏性</strong>，即:在每一层中，每个输出值只取决于少量的输入。</li></ul><p id="24af" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我希望现在你已经清楚了，因为现在我已经解释了两种类型的神经网络之间的主要差异以及为什么应该使用CNN进行图像识别，让我们来看看卷积神经网络实际上是如何工作的。</p><p id="effb" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">又读</strong> : <a class="ae jn" href="https://antoniofurioso.medium.com/how-to-study-artificial-intelligence-bb7bc6640d9c" rel="noopener">如何学习人工智能</a></p><h1 id="48fe" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">卷积神经网络是如何工作的？</h1><p id="ff8b" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">神经网络的基本结构包括:</p><ol class=""><li id="6de9" class="kw kx hh ir b is it iw ix ja ky je kz ji la jm ll lc ld le bi translated"><strong class="ir hi">卷积层</strong></li><li id="0e0e" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm ll lc ld le bi translated"><strong class="ir hi">非线性激活功能</strong></li><li id="2158" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm ll lc ld le bi translated"><strong class="ir hi">联营</strong></li><li id="1396" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm ll lc ld le bi translated"><strong class="ir hi">全连接网络(即我们的NN) </strong></li></ol><p id="823c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们按顺序来看看这些特征对于构建我们的卷积神经网络是如何重要的。</p><h2 id="3bcb" class="lm jp hh bd jq ln lo lp ju lq lr ls jy ja lt lu kc je lv lw kg ji lx ly kk lz bi translated">卷积层</h2><p id="deec" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">卷积层是我们网络的初始部分，在这一层发生了所谓的“<strong class="ir hi">卷积</strong>”，CNN由此得名:</p><p id="94c4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在卷积中，我们提取图像特征。</p><p id="529b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们拿一个图像来说:它被分成正方形(以绿色正方形为例，把它做得像一个图像)。</p><p id="bff7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">执行此步骤后，将图像乘以一个矩阵(称为<strong class="ir hi">【滤波器】</strong>或<strong class="ir hi">【内核】</strong>或<strong class="ir hi">【特征检测器】</strong> —黄色方块)，从而获得卷积(或<strong class="ir hi">【特征图】</strong> —粉色方块)。</p><p id="7052" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了让你更好地理解我们将要做的事情，请看下面的图片:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es ma"><img src="../Images/45a2d9617dbfc761528e198083af9b0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:300/format:webp/0*cILscX0iq6kKGgqC.png"/></div></figure><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es mb"><img src="../Images/684c88956cc955c2165cdb34c3a4f03b.png" data-original-src="https://miro.medium.com/v2/resize:fit:148/format:webp/0*ySnDEZJMQyiWpb7r.png"/></div></figure><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es mc"><img src="../Images/729785b4d7aafce36d2eb8da39a48477.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/0*vjJfuB7ldElroLW2.gif"/></div><figcaption class="md me et er es mf mg bd b be z dx translated"><a class="ae jn" href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" rel="noopener ugc nofollow" target="_blank"> <em class="mh">图像来源</em> </a></figcaption></figure><p id="5c89" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">需要记住的一件重要事情是，这里的滤波器充当原始输入图像的特征检测器。我们有不同类型的过滤器，进而形成不同类型的<strong class="ir hi">“特征图”</strong>:</p><ul class=""><li id="e339" class="kw kx hh ir b is it iw ix ja ky je kz ji la jm lb lc ld le bi translated"><strong class="ir hi">步距</strong>:在开窗过程中，如果步距未被应用，过滤器将开始分析下一个方块(如上图所示)。另一方面，例如，如果我们应用一个<code class="du mi mj mk ml b">stride = 2</code>，过滤器将从第二个连续的方块开始，每次跳过下一个。</li><li id="1994" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated"><strong class="ir hi">填充</strong>:在图像周围添加一层0。这个<strong class="ir hi">避免了两个负面</strong>:</li><li id="06a1" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">每次应用滤镜时图像的缩小</li><li id="2283" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">和边缘处像素可用性的缺乏所导致的信息损失。</li></ul><figure class="ks kt ku kv fd ii er es paragraph-image"><div class="er es mm"><img src="../Images/6fda2833c76f3a1b461e6d0e588106de.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/0*NvOMGuU6OxWUcsb9.gif"/></div></figure><p id="e166" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">非线性激活函数被应用于该卷积层。</p><h2 id="d848" class="lm jp hh bd jq ln lo lp ju lq lr ls jy ja lt lu kc je lv lw kg ji lx ly kk lz bi translated">非线性激活的功能</h2><p id="934a" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">我们有几种类型的激活功能，但最常见的是:<strong class="ir hi"> Sigmoid、ReLu(整流线性单元)和Tanh </strong>。</p><p id="e1b7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">每次在卷积层之后应用激活函数，因为ConvNet是线性的，并且因为我们不想预测(例如)房屋的价格，所以我们必须应用非线性函数。</p><p id="7b74" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">上面提到的每个功能都适用于不同的情况。我们以ReLu函数为例，这是最常用的一个。</p><p id="1eae" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">与之前提到的其他函数不同，<strong class="ir hi"> ReLu的学习速度更快，并且当‘Z’很大或很小时，在梯度上获得更好的结果</strong>。</p><p id="5d87" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后，在应用我们的非线性函数之后，我们可以继续进行<strong class="ir hi">池化</strong>。</p><p id="afd2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">建议</strong> : <a class="ae jn" href="https://antoniofurioso.medium.com/deep-learning-specialization-review-2021-5404ba3cd9a4" rel="noopener">深度学习专业化复习</a></p><h2 id="9b0c" class="lm jp hh bd jq ln lo lp ju lq lr ls jy ja lt lu kc je lv lw kg ji lx ly kk lz bi translated">CNN中的共享</h2><p id="1696" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">Pooling没有要设置的参数，但这可以是不同的类型:<strong class="ir hi">最大值</strong>、<strong class="ir hi">总和</strong>、<strong class="ir hi">平均值</strong>等。</p><p id="1734" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这<strong class="ir hi">减小了“特征图”的大小，但同时保留了每个特征图最重要的信息</strong>。</p><p id="23b9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们以从第一步获得的特征图为例，使用MaxPooling对其应用a <code class="du mi mj mk ml b">2×2 filter</code>和<code class="du mi mj mk ml b">stride = 2</code>，我们将获得以下结果:</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mn"><img src="../Images/2b5fbe4bbf56664ea700821520dc62c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7A-h6D3GdhTGuSIg.png"/></div></div></figure><p id="a680" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">通过汇集，我们获得了以下<strong class="ir hi">好处</strong>:</p><ul class=""><li id="5d20" class="kw kx hh ir b is it iw ix ja ky je kz ji la jm lb lc ld le bi translated">使输入表示更小，更易于管理</li><li id="780b" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">减少网络中的参数和计算数量，从而控制<a class="ae jn" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">过拟合</a></li><li id="9363" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">使网络对输入图像中的小变换、扭曲和平移保持不变(输入中的小扭曲不会改变池化的输出，因为我们取最大值/平均值)。</li><li id="ba64" class="kw kx hh ir b is lf iw lg ja lh je li ji lj jm lb lc ld le bi translated">帮助我们获得图像的不变表示(称为“等变”)。这是非常强大的，因为我们可以检测图像中的物体，不管它们位于哪里。</li></ul><p id="237e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这三个步骤是每一个通信网的基础，构成了通信网的第一层。在网络中，可以添加由该基础形成的其他层，然后添加完全连接的层。</p><h2 id="7a3c" class="lm jp hh bd jq ln lo lp ju lq lr ls jy ja lt lu kc je lv lw kg ji lx ly kk lz bi translated">全连接层</h2><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kr"><img src="../Images/4631f9b4c0bbae73b586e3c094c76468.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/0*vC2ijqZoJZmX-jff"/></div></div></figure><p id="5987" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这一层意味着每个神经元都连接到上一层和下一层。</p><p id="f4e6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">完全连接的层和到目前为止描述的网络的其余部分之间的组合，设法在预测中给出更好的结果。</p><p id="cdb8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">不要忘记，线性激活函数<strong class="ir hi">‘soft max’</strong>应用于这最后一级，并将返回我们的输出。</p><p id="39ed" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Softmax是一项允许您在一幅图像中同时检测多个对象的功能。</p><h1 id="eaf9" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">这是一个ConvNet:</h1><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/8a3b77c3b2c49d0e0fe48b9eb175be69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7KDto40Ikx2MUSjG"/></div></div></figure><h1 id="d208" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">结论</h1><p id="8875" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">这篇文章旨在对CNN做一个简单的介绍，事实上，正如你所看到的，我没有详细介绍以免使你到目前为止所学的变得复杂。如果你想研究这个课题，我推荐你去参加<a class="ae jn" href="https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning" rel="noopener ugc nofollow" target="_blank">的这个免费课程</a>。</p></div></div>    
</body>
</html>