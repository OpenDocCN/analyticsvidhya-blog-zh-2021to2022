<html>
<head>
<title>Hyperparameter tuning on Kubernetes patterns</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Kubernetes模式的超参数调谐</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hyperparameter-tuning-on-kubernetes-patterns-3bcc832f3412?source=collection_archive---------2-----------------------#2021-11-18">https://medium.com/analytics-vidhya/hyperparameter-tuning-on-kubernetes-patterns-3bcc832f3412?source=collection_archive---------2-----------------------#2021-11-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="19b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文讨论Kubernetes上的超参数调优解决方案。</p><h1 id="c0e6" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">超参数调谐</h1><p id="dc68" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">如果你创建过机器学习模型，你一定遇到过超参数调优。超参数是一个模型参数，其值在学习过程开始之前就已设定。以下是一些例子:</p><ol class=""><li id="ffc1" class="kf kg hh ig b ih ii il im ip kh it ki ix kj jb kk kl km kn bi translated">KNN的k</li><li id="2a06" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">决策树中的最大深度</li><li id="c4c0" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">随机森林中的树木数量</li><li id="666e" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">神经网络中的层数、每层单元数、学习速率、批量大小</li></ol><p id="360f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">更多信息，你可以参考下面的文章</p><div class="kt ku ez fb kv kw"><a href="https://www.analyticsvidhya.com/blog/2021/04/evaluating-machine-learning-models-hyperparameter-tuning/" rel="noopener  ugc nofollow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">超参数调整|使用超参数调整评估ML模型</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">学习过程开始了。机器学习算法的关键是超参数调整。K-NN正规化中的K…</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">www.analyticsvidhya.com</p></div></div><div class="lf l"><div class="lg l lh li lj lf lk ll kw"/></div></div></a></div><div class="kt ku ez fb kv kw"><a href="https://towardsdatascience.com/beyond-grid-search-hypercharge-hyperparameter-tuning-for-xgboost-7c78f7a2929d" rel="noopener follow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">超越网格搜索:XGBoost的超荷超参数调优</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">使用Hyperopt、Optuna和Ray Tune加速机器学习超参数优化</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">towardsdatascience.com</p></div></div><div class="lf l"><div class="lm l lh li lj lf lk ll kw"/></div></div></a></div><div class="kt ku ez fb kv kw"><a href="https://towardsdatascience.com/state-of-the-art-machine-learning-hyperparameter-optimization-with-optuna-a315d8564de1" rel="noopener follow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">用Optuna优化最先进的机器学习超参数</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">Optuna是一个高级的超参数优化框架，具有可视化的可解释性</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">towardsdatascience.com</p></div></div><div class="lf l"><div class="ln l lh li lj lf lk ll kw"/></div></div></a></div><h1 id="68e3" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">超参数调整算法</h1><p id="4c4b" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">如果您的机器学习模型只有一个超参数，您可以在该超参数域中尝试不同的值。然而，在现实中，一个机器学习模型可以有多个超参数，现在超参数值组合的数量迅速变得巨大。寻找最佳超参数值组合有不同的超参数调优算法:网格搜索(强力笛卡尔组合)、随机(笛卡尔组合，但随机选择)、贝叶斯(引导、知情试验)。这里有一些好文章。</p><div class="kt ku ez fb kv kw"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/comparison-of-hyperparameter-tuning-algorithms-grid-search-random-search-bayesian-optimization-5326aaef1bd1"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">超参数调整算法的比较:网格搜索、随机搜索、贝叶斯优化</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">在模型训练阶段，模型学习其参数。但也有一些秘密旋钮，称为…</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">medium.com</p></div></div><div class="lf l"><div class="lo l lh li lj lf lk ll kw"/></div></div></a></div><div class="kt ku ez fb kv kw"><a href="https://towardsdatascience.com/intuitive-hyperparameter-optimization-grid-search-random-search-and-bayesian-search-2102dbfaf5b" rel="noopener follow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">直观的超参数优化:网格搜索，随机搜索和贝叶斯搜索！</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">机器学习算法中的超参数就像煤气炉中的旋钮。就像我们调节煤气的旋钮一样…</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">towardsdatascience.com</p></div></div><div class="lf l"><div class="lp l lh li lj lf lk ll kw"/></div></div></a></div><h1 id="dbc9" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">超参数调谐组件</h1><p id="220b" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">要将普通的机器学习训练代码转换为支持超参数调整的代码，您至少需要三样东西:</p><ol class=""><li id="290c" class="kf kg hh ig b ih ii il im ip kh it ki ix kj jb kk kl km kn bi translated">超参数调优训练调用者:负责用下一个超参数值组合调用你的训练函数，收集训练函数返回的度量</li><li id="a109" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">您的训练函数:它应该使用由超参数调整训练调用者传递的超参数值，并返回您想要优化的指标，例如精度。</li><li id="936e" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">超参数值控制器:它使用训练函数返回的超参数值和度量来确定下一个要尝试的超参数值组合。对于网格搜索，它可能只是下一个组合，对于贝叶斯，它应该使用历史值来确定最佳方向。</li></ol><p id="fb0c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">要将普通的机器学习训练代码转换为支持超参数调整的代码，您需要进行三项高级更改:</p><ol class=""><li id="1723" class="kf kg hh ig b ih ii il im ip kh it ki ix kj jb kk kl km kn bi translated">超参数的搜索域</li><li id="a479" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">一个目标函数，采用超参数值组合和回报度量进行优化。此函数需要访问训练数据来训练模型，还需要访问验证数据(可以从训练数据创建)来计算模型性能指标</li><li id="aeba" class="kf kg hh ig b ih ko il kp ip kq it kr ix ks jb kk kl km kn bi translated">一种优化算法。</li></ol><p id="9a53" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从Optuna示例中截取一些概念性代码来说明模式</p><h2 id="a32b" class="lr jd hh bd je ls lt lu ji lv lw lx jm ip ly lz jq it ma mb ju ix mc md jy me bi translated">搜索域</h2><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="9d13" class="lr jd hh mk b fi mo mp l mq mr">classifier_name = trial.suggest_categorical("classifier", ["SVC", "RandomForest"])<br/>svc_c = trial.suggest_float("svc_c", 1e-10, 1e10, log=True)<br/>rf_max_depth = trial.suggest_int("rf_max_depth", 2, 32, log=True)</span></pre><h2 id="784c" class="lr jd hh bd je ls lt lu ji lv lw lx jm ip ly lz jq it ma mb ju ix mc md jy me bi translated">目标函数</h2><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="dac0" class="lr jd hh mk b fi mo mp l mq mr">def objective(trial):<br/>    iris = sklearn.datasets.load_iris()<br/>    x, y = iris.data, iris.target</span><span id="9de7" class="lr jd hh mk b fi ms mp l mq mr">    # parameterized hyperparameter value</span><span id="6592" class="lr jd hh mk b fi ms mp l mq mr">classifier_name = trial.suggest_categorical("classifier", ["SVC", "RandomForest"])<br/>    if classifier_name == "SVC":<br/>        svc_c = trial.suggest_float("svc_c", 1e-10, 1e10, log=True)<br/>        classifier_obj = sklearn.svm.SVC(C=svc_c, gamma="auto")<br/>    else:<br/>        rf_max_depth = trial.suggest_int("rf_max_depth", 2, 32, log=True)<br/>        classifier_obj = sklearn.ensemble.RandomForestClassifier(<br/>            max_depth=rf_max_depth, n_estimators=10<br/>        )</span><span id="2fe5" class="lr jd hh mk b fi ms mp l mq mr">score = sklearn.model_selection.cross_val_score(classifier_obj, x, y, n_jobs=-1, cv=3)<br/>    accuracy = score.mean()</span><span id="4c54" class="lr jd hh mk b fi ms mp l mq mr">    <strong class="mk hi"># return metric to optimize</strong><br/>    return accuracy</span></pre><h2 id="a564" class="lr jd hh bd je ls lt lu ji lv lw lx jm ip ly lz jq it ma mb ju ix mc md jy me bi translated">最优化算法</h2><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="8146" class="lr jd hh mk b fi mo mp l mq mr"># we want to maximize accuracy value, if the metric is loss value, usually we want to minimize<br/>study = optuna.create_study(direction="maximize")<br/>study.optimize(objective, n_trials=100)<br/>print(study.best_trial)</span></pre><p id="03ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，到目前为止，代码只在单机上运行。如果我们想使用多个节点来加速训练/超参数调优，我们可以使用容器和Kubernetes进行扩展。现在让我们看看Kubernetes上流行的超参数调优框架支持。</p><h1 id="1b71" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">卡蒂卜</h1><p id="d629" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">可以作为kubeflow的一部分安装，也可以独立安装</p><div class="kt ku ez fb kv kw"><a href="https://www.kubeflow.org/docs/components/katib/hyperparameter/#installing-katib" rel="noopener  ugc nofollow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">Katib入门</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">如何设置Katib和执行超参数调整本指南显示了如何开始使用Katib和运行一些…</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">www.kubeflow.org</p></div></div><div class="lf l"><div class="mt l lh li lj lf lk ll kw"/></div></div></a></div><div class="kt ku ez fb kv kw"><a href="https://github.com/kubeflow/katib/blob/master/examples/v1beta1/kubeflow-training-operator/tfjob-mnist-with-summaries.yaml" rel="noopener  ugc nofollow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">katib/TF job-mnist-with-summarys . YAML at master kube flow/katib</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">此文件包含双向Unicode文本，其解释或编译可能与下面显示的不同…</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">github.com</p></div></div><div class="lf l"><div class="mu l lh li lj lf lk ll kw"/></div></div></a></div><p id="32ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">搜索域</p><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="e9d2" class="lr jd hh mk b fi mo mp l mq mr">parameters:<br/>    - name: learning_rate<br/>      parameterType: double<br/>      feasibleSpace:<br/>        min: "0.01"<br/>        max: "0.05"<br/>    - name: batch_size<br/>      parameterType: int<br/>      feasibleSpace:<br/>        min: "100"<br/>        max: "200"<br/>  trialTemplate:<br/>    primaryContainerName: tensorflow<br/>    trialParameters:<br/>      - name: learningRate<br/>        description: Learning rate for the training model<br/>        reference: learning_rate<br/>      - name: batchSize<br/>        description: Batch Size<br/>        reference: batch_size</span></pre><p id="6586" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">目标函数/超参数化训练函数</p><div class="kt ku ez fb kv kw"><a href="https://github.com/kubeflow/training-operator/blob/master/examples/tensorflow/mnist_with_summaries/mnist_with_summaries.py" rel="noopener  ugc nofollow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">主kubeflow/training-operator上的training-operator/mnist _ with _ summaries . py</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">此文件包含双向Unicode文本，其解释或编译可能与下面显示的不同…</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">github.com</p></div></div><div class="lf l"><div class="mv l lh li lj lf lk ll kw"/></div></div></a></div><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="c090" class="lr jd hh mk b fi mo mp l mq mr">parser.add_argument('--learning_rate', type=float, default=0.001,<br/>                      help='Initial learning rate')<br/>  parser.add_argument('--batch_size', type=int, default=100,<br/>                      help='Training batch size')</span><span id="9e7f" class="lr jd hh mk b fi ms mp l mq mr">with tf.name_scope('train'):<br/>    train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(<br/>        cross_entropy)</span><span id="ea13" class="lr jd hh mk b fi ms mp l mq mr">if train or FLAGS.fake_data:      xs, ys = mnist.train.next_batch(FLAGS.batch_size, fake_data=FLAGS.fake_data)</span></pre><p id="787b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使最优化</p><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="ec57" class="lr jd hh mk b fi mo mp l mq mr"># which metric top optimize<br/>spec:<br/>  parallelTrialCount: 3<br/>  maxTrialCount: 12<br/>  maxFailedTrialCount: 3<br/>  objective:<br/>    type: maximize<br/>    goal: 0.99<br/>    objectiveMetricName: accuracy_1<br/>  algorithm:<br/>    algorithmName: random<br/>  metricsCollectorSpec:<br/>    source:<br/>      fileSystemPath:<br/>        path: /train<br/>        kind: Directory<br/>    collector:<br/>      kind: TensorFlowEvent</span><span id="67c8" class="lr jd hh mk b fi ms mp l mq mr"># pass hyperparameter to training function<br/>trialSpec:<br/>      apiVersion: kubeflow.org/v1<br/>      kind: TFJob<br/>      spec:<br/>        tfReplicaSpecs:<br/>          Worker:<br/>            replicas: 2<br/>            restartPolicy: OnFailure<br/>            template:<br/>              spec:<br/>                containers:<br/>                  - name: tensorflow<br/>                    image: gcr.io/kubeflow-ci/tf-mnist-with-summaries:1.0<br/>                    command:<br/>                      - "python"<br/>                      - "/var/tf_mnist/mnist_with_summaries.py"<br/>                      - "--log_dir=/train/metrics"<br/>                      - "--learning_rate=${trialParameters.learningRate}"<br/>                      - "--batch_size=${trialParameters.batchSize}"</span></pre><h1 id="c728" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">远视</h1><p id="7f2c" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">没有明显的支持Kubernetes</p><h1 id="a8ef" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">奥普图纳</h1><div class="kt ku ez fb kv kw"><a href="https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/004_distributed.html" rel="noopener  ugc nofollow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">简单的并行化- Optuna 2.10.0文档</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">编辑描述</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">optuna.readthedocs.io</p></div></div></div></a></div><p id="eabf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Optuna使用共享数据库来跟踪超参数值和指标</p><p id="d500" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">创建数据库</p><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="791f" class="lr jd hh mk b fi mo mp l mq mr">$ mysql -u root -e "CREATE DATABASE IF NOT EXISTS example"<br/>$ optuna create-study --study-name "distributed-example" --storage "mysql://root@localhost/example"<br/>[I 2020-07-21 13:43:39,642] A new study created with name: distributed-example</span></pre><p id="2c7d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在训练代码中，创建研究并将存储指向数据库。Optuna使用这个数据库来跟踪不同节点上的超参数分布值。</p><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="cd2e" class="lr jd hh mk b fi mo mp l mq mr">import optuna</span><span id="659b" class="lr jd hh mk b fi ms mp l mq mr">def objective(trial):<br/>    x = trial.suggest_float("x", -10, 10)<br/>    return (x - 2) ** 2</span><span id="ed71" class="lr jd hh mk b fi ms mp l mq mr">if __name__ == "__main__":<br/>    study = optuna.load_study(<br/>        study_name="distributed-example", <strong class="mk hi">storage="mysql://root@localhost/example"</strong><br/>    )<br/>    study.optimize(objective, n_trials=100)</span></pre><p id="cf24" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">更多混凝土示例</p><div class="kt ku ez fb kv kw"><a href="https://github.com/optuna/optuna-examples/tree/main/kubernetes/simple" rel="noopener  ugc nofollow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">optuna-examples/kubernetes/simple at main optuna/optuna-examples</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">这个示例的代码与sklearn_simple.py示例基本相同，除了两件事:1 -它给出了一个名称…</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">github.com</p></div></div><div class="lf l"><div class="mw l lh li lj lf lk ll kw"/></div></div></a></div><p id="354d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Kubernetes上部署数据库</p><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="97de" class="lr jd hh mk b fi mo mp l mq mr">---<br/>apiVersion: v1<br/>kind: Secret<br/>metadata:<br/>  name: postgres-secrets<br/>type: Opaque<br/>stringData:<br/>  POSTGRES_PASSWORD: "superSecretPassword"<br/>  POSTGRES_USER: "optuna"<br/>  POSTGRES_DB: "optunaDatabase"<br/>---<br/>apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  name: postgres<br/>spec:<br/>  type: ClusterIP<br/>  selector:<br/>    app: postgres<br/>  ports:<br/>    - port: 5432<br/>---<br/>apiVersion: apps/v1<br/>kind: StatefulSet<br/>metadata:<br/>  name: postgres<br/>  labels:<br/>    app: postgres<br/>spec:<br/>  selector:<br/>    matchLabels:<br/>      app: postgres<br/>  serviceName: postgres<br/>  template:<br/>    metadata:<br/>      labels:<br/>        app: postgres<br/>    spec:<br/>      containers:<br/>        - name: postgres<br/>          image: postgres:latest<br/>          imagePullPolicy: IfNotPresent<br/>          envFrom:<br/>            - secretRef:<br/>                name: postgres-secrets<br/>          ports:<br/>            - containerPort: 5432<br/>---</span></pre><p id="d49d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">提交多节点超参数调整</p><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="645e" class="lr jd hh mk b fi mo mp l mq mr">apiVersion: batch/v1<br/>kind: Job<br/>metadata:<br/>  name: study-creator<br/>spec:<br/>  template:<br/>    spec:<br/>      restartPolicy: OnFailure<br/>      initContainers:<br/>        - name: wait-for-database<br/>          image: postgres:latest<br/>          imagePullPolicy: IfNotPresent<br/>          command:<br/>          - /bin/sh<br/>          - -c<br/>          - -e<br/>          - -x<br/>          - |<br/>            until pg_isready -U $(POSTGRES_USER) -h postgres -p 5432;<br/>            do echo "waiting for postgres"; sleep 2; done;<br/>          envFrom:<br/>            - secretRef:<br/>                name: postgres-secrets<br/>      containers:<br/>        - name: study-creator<br/>          image: optuna-kubernetes:example<br/>          imagePullPolicy: IfNotPresent<br/>          command:<br/>          # create study</span><span id="9cc2" class="lr jd hh mk b fi ms mp l mq mr"><strong class="mk hi">          - /bin/sh<br/>          - -c<br/>          - -e<br/>          - -x<br/>          - |<br/>            optuna create-study --skip-if-exists --direction maximize \<br/>            --study-name "kubernetes" --storage \<br/>            "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}</strong><a class="ae lq" href="http://twitter.com/postgres" rel="noopener ugc nofollow" target="_blank"><strong class="mk hi">@postgres</strong></a><strong class="mk hi">:5432/${POSTGRES_DB}"</strong><br/>          envFrom:<br/>            - secretRef:<br/>                name: postgres-secrets<br/>---<br/>apiVersion: batch/v1<br/>kind: Job<br/>metadata:<br/>  name: worker<br/>spec:<br/>  parallelism: 5<br/>  template:<br/>    spec:<br/>      restartPolicy: OnFailure<br/>      initContainers:<br/>        - name: wait-for-study<br/>          image: optuna-kubernetes:example<br/>          imagePullPolicy: IfNotPresent<br/>          command:<br/><strong class="mk hi">          - /bin/sh<br/>          - -c<br/>          - -e<br/>          - -x<br/>          - |<br/>            until [ `sh check_study.sh` -eq 0 ];</strong><br/>            do echo "waiting for study"; sleep 2; done;<br/>          envFrom:<br/>            - secretRef:<br/>                name: postgres-secrets<br/>      containers:<br/>        - name: worker<br/>          image: optuna-kubernetes:example<br/>          imagePullPolicy: IfNotPresent<br/>          command:<br/><strong class="mk hi">            - python<br/>            - sklearn_distributed.py</strong><br/>          envFrom:<br/>            - secretRef:<br/>                name: postgres-secrets<br/>---</span></pre><p id="2db4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">指向Postgres的存储</p><pre class="mf mg mh mi fd mj mk ml mm aw mn bi"><span id="d56d" class="lr jd hh mk b fi mo mp l mq mr">if __name__ == "__main__":<br/>    study = optuna.load_study(<br/>        study_name="kubernetes",<br/>        storage="postgresql://{}:{}<a class="ae lq" href="http://twitter.com/postgres" rel="noopener ugc nofollow" target="_blank">@postgres</a>:5432/{}".format(<br/>            os.environ["POSTGRES_USER"],<br/>            os.environ["POSTGRES_PASSWORD"],<br/>            os.environ["POSTGRES_DB"],<br/>        ),<br/>    )<br/>    study.optimize(objective, n_trials=20)<br/>    print(study.best_trial)</span></pre><h1 id="c8fd" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">射线调谐</h1><p id="6e92" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">您可以在Kubernetes上部署Ray Kubernetes operator/cluster，它包含head和worker。</p><div class="kt ku ez fb kv kw"><a href="https://docs.ray.io/en/latest/cluster/kubernetes.html" rel="noopener  ugc nofollow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">雷1.8.0版</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">您可以利用Kubernetes集群作为执行分布式Ray程序的基础。射线自动缩放器…</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">docs.ray.io</p></div></div></div></a></div><p id="82fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">光线调节支持许多超参数调节库，包括Optuna，hyperopt。</p><div class="kt ku ez fb kv kw"><a href="https://docs.ray.io/en/latest/tune/api_docs/suggestion.html" rel="noopener  ugc nofollow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">雷1.8.0版</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">Tune的搜索算法是围绕开源优化库的包装器，用于高效的超参数选择…</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">docs.ray.io</p></div></div><div class="lf l"><div class="mx l lh li lj lf lk ll kw"/></div></div></a></div><div class="kt ku ez fb kv kw"><a rel="noopener follow" target="_blank" href="/optuna/scaling-up-optuna-with-ray-tune-88f6ca87b8c7"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">使用光线调节放大Optuna</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">作者:凯·弗里克，克里斯曼·卢米斯，理查德·廖</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">medium.com</p></div></div><div class="lf l"><div class="my l lh li lj lf lk ll kw"/></div></div></a></div><h1 id="2725" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">附录</h1><div class="kt ku ez fb kv kw"><a href="https://neptune.ai/blog/optuna-vs-hyperopt" rel="noopener  ugc nofollow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">Optuna vs Hyperopt:应该选择哪个超参数优化库？- neptune.ai</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">思考应该选择哪个库进行超参数优化？使用远视有一段时间了，感觉像…</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">海王星. ai</p></div></div><div class="lf l"><div class="mz l lh li lj lf lk ll kw"/></div></div></a></div><div class="kt ku ez fb kv kw"><a href="https://towardsdatascience.com/tuning-hyperparameters-with-optuna-af342facc549" rel="noopener follow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">使用Optuna调整超参数</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">以自动和智能的方式调整机器学习模型的超参数</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">towardsdatascience.com</p></div></div><div class="lf l"><div class="na l lh li lj lf lk ll kw"/></div></div></a></div><div class="kt ku ez fb kv kw"><a href="https://towardsdatascience.com/optuna-a-flexible-efficient-and-scalable-hyperparameter-optimization-framework-d26bc7a23fff" rel="noopener follow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">OPTUNA:一个灵活、高效、可扩展的超参数优化框架</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">轻型和大型超参数优化的新选择</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">towardsdatascience.com</p></div></div><div class="lf l"><div class="nb l lh li lj lf lk ll kw"/></div></div></a></div><div class="kt ku ez fb kv kw"><a href="https://towardsdatascience.com/how-to-make-your-model-awesome-with-optuna-b56d490368af" rel="noopener follow" target="_blank"><div class="kx ab dw"><div class="ky ab kz cl cj la"><h2 class="bd hi fi z dy lb ea eb lc ed ef hg bi translated">如何用Optuna让你的模型牛逼</h2><div class="ld l"><h3 class="bd b fi z dy lb ea eb lc ed ef dx translated">轻松高效地优化模型的超参数</h3></div><div class="le l"><p class="bd b fp z dy lb ea eb lc ed ef dx translated">towardsdatascience.com</p></div></div><div class="lf l"><div class="nc l lh li lj lf lk ll kw"/></div></div></a></div></div></div>    
</body>
</html>