<html>
<head>
<title>What is Naive Bayes?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是朴素贝叶斯？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/what-is-naive-bayes-9cb4fe1ba0c3?source=collection_archive---------6-----------------------#2021-03-11">https://medium.com/analytics-vidhya/what-is-naive-bayes-9cb4fe1ba0c3?source=collection_archive---------6-----------------------#2021-03-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><h2 id="ddc0" class="hf hg hh bd b fp hi hj hk hl hm hn dx ho translated" aria-label="kicker paragraph">朴素贝叶斯指南</h2><div class=""/><div class=""><h2 id="1d72" class="pw-subtitle-paragraph in hq hh bd b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je dx translated">第1部分:定义模型</h2></div><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es jf"><img src="../Images/a8b42694325e11bad9a7cc6cc55884d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WgdhbtImr7F4cjpH_yE8wQ.png"/></div></div></figure><blockquote class="jr js jt"><p id="0ea6" class="ju jv jw jx b jy jz ir ka kb kc iu kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated"><strong class="jx hr"> <em class="hh">算法是什么？</em>T3】</strong></p></blockquote><p id="2dea" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated"><strong class="jx hr">朴素贝叶斯(NB) </strong>是一种<strong class="jx hr">监督机器学习</strong>算法。NBs的目的是通过依赖被分成类的标记输入数据来预测查询样本的分类。名称<em class="jw"> naive </em>源于算法是特征的独立性假设，而<em class="jw"> bayes </em>源于算法使用了一种称为<strong class="jx hr"> Bayes定理</strong>的统计分类技术。</p><blockquote class="jr js jt"><p id="8ee1" class="ju jv jw jx b jy jz ir ka kb kc iu kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated"><strong class="jx hr"> <em class="hh">算法是如何工作的？</em> </strong></p></blockquote><p id="a3dc" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">步骤1:计算训练数据中给定类别标签的先验概率。</p><p id="c97d" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">步骤2:获取每个类的每个特征属性的似然概率。</p><p id="7dc7" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">第三步:利用贝叶斯定理计算后验概率。</p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es ku"><img src="../Images/ec3e9c63e4f381df8b383aefb1b5c682.png" data-original-src="https://miro.medium.com/v2/resize:fit:532/format:webp/1*eOzucmgfdHupZqDmG7ZTXw.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">贝叶斯定理方程</figcaption></figure><ul class=""><li id="eb9e" class="kz la hh jx b jy jz kb kc kr lb ks lc kt ld kq le lf lg lh bi translated">P(A|B) —事件A发生的概率，假设事件B已经发生[后验概率]</li><li id="3387" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">P(B|A) —事件B发生的概率，假设事件A已经发生[似然概率]</li><li id="44e1" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">P(A) —事件A的概率[A的先验概率]</li><li id="877d" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">P(B) —事件B的概率[B的先验概率]</li></ul><p id="62c4" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">第四步:返回后验概率较高的类别标签→查询样本的预测！</p><blockquote class="jr js jt"><p id="c7ad" class="ju jv jw jx b jy jz ir ka kb kc iu kd ke kf kg kh ki kj kk kl km kn ko kp kq ha bi translated"><strong class="jx hr"> <em class="hh">算法的例子</em> </strong></p></blockquote><p id="21d7" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated"><em class="jw">让我们根据朴素贝叶斯(高斯)方程改写贝叶斯定理……</em></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div class="er es ln"><img src="../Images/b0c656af8922a9548d9d4c2e4caf2eb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*QJ1r_VI8aqSnRnAk-hoSzw.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">朴素贝叶斯(高斯)方程</figcaption></figure><ul class=""><li id="67c9" class="kz la hh jx b jy jz kb kc kr lb ks lc kt ld kq le lf lg lh bi translated">P(Class)代表<strong class="jx hr">类</strong> (y输出)的<strong class="jx hr">先验概率</strong>。</li><li id="9575" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">p(数据)代表<strong class="jx hr">预测器</strong> (X特征)<strong class="jx hr">的<strong class="jx hr">先验概率</strong>。</strong></li><li id="c70e" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">p(数据|类别)表示给定类别时<strong class="jx hr">预测器的<strong class="jx hr">似然概率</strong>。</strong></li><li id="6066" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated"><em class="jw"> P </em>(类|数据)表示给定预测值的<strong class="jx hr">类的<strong class="jx hr">后验概率</strong>。</strong></li></ul><p id="b3c7" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated"><em class="jw">让我们从一个带有… </em>的模拟数据帧开始</p><ul class=""><li id="ca2f" class="kz la hh jx b jy jz kb kc kr lb ks lc kt ld kq le lf lg lh bi translated"><em class="jw"> 4列(3个特征[X: </em> x₁、x₂、x₃ <em class="jw"> ]和1个输出[</em>y—<em class="jw">a类或b类]) </em></li><li id="a720" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated"><em class="jw"> 10行(观察值)，其中4行属于A类，6行属于B类</em></li></ul><p id="faec" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated"><em class="jw">本例的目标是预测查询样本的类别(A或B)，其中特征1、特征2和特征3的输入值分别为11、7和22。</em></p><p id="8153" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated"><em class="jw">注意:由于我们正在检查高斯朴素贝叶斯，因此使用均值(μ) </em> <strong class="jx hr"> </strong> <em class="jw">和标准差(σ)绘制每个特征的每个类的正态(或高斯)分布曲线。</em></p><figure class="jg jh ji jj fd jk er es paragraph-image"><div role="button" tabindex="0" class="jl jm di jn bf jo"><div class="er es lo"><img src="../Images/8ba7607432a6083bfbf2cd00e5625840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PD0haiwnk-kGOLZDx8nshw.png"/></div></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">朴素贝叶斯(高斯)算法</figcaption></figure><p id="84ea" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated"><em class="jw">让我们使用每个类别的计数来计算P(类别)的先验概率… </em></p><ul class=""><li id="e157" class="kz la hh jx b jy jz kb kc kr lb ks lc kt ld kq le lf lg lh bi translated">P(Class=A) → [4 /(4+6)] = 0.40</li><li id="47cc" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">P(Class=B) → [6 /(6+4)] = 0.60</li></ul><p id="53e3" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated"><em class="jw">让我们计算P(数据)的先验概率……</em></p><ul class=""><li id="2b17" class="kz la hh jx b jy jz kb kc kr lb ks lc kt ld kq le lf lg lh bi translated">在这个例子中没有计算p(数据),因为特征值是连续的而不是分类的</li></ul><p id="83f6" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated"><em class="jw">让我们使用上面的正态分布图为每个特征计算P(数据|类别)的似然概率… </em></p><ul class=""><li id="ec8a" class="kz la hh jx b jy jz kb kc kr lb ks lc kt ld kq le lf lg lh bi translated">l(特性1 = 11 |类别=A) →接近0</li><li id="6ddd" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">l(特性2 = 7 |类别=A) → 0.65</li><li id="40ae" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">l(特性3 = 22 |类别=A) → 0.05</li><li id="0d23" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">l(特性1 = 11 |类别=B) → 0.35</li><li id="a8c6" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">l(特性2 = 7 |类别=B) → 0.20</li><li id="7f2b" class="kz la hh jx b jy li kb lj kr lk ks ll kt lm kq le lf lg lh bi translated">l(特性3 = 22 |类别=B) →接近0</li></ul><p id="a8cb" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated"><em class="jw">让我们使用朴素贝叶斯方程计算P(类|数据)的后验概率… </em></p><ul class=""><li id="f82c" class="kz la hh jx b jy jz kb kc kr lb ks lc kt ld kq le lf lg lh bi translated">P(Class=A|Data)</li></ul><p id="eb66" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">= P(Class = A)x(L(Feature 1 = 11 | Class = A)x L(Feature 2 = 7 | Class = A)x L(Feature 3 = 22 | Class = A))</p><p id="152f" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">= [0.60 x((接近于0) x 0.65 x 0.05)]</p><p id="37c8" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">注意:如果概率是一个小数字(接近于0)，取计算的logₑ(以避免下溢。</p><p id="fa3a" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">logₑ(p(class=a|data)= logₑ[0.60 x((更接近于0) x 0.65 x 0.05)]</p><p id="f45e" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">= logₑ(0.60) + logₑ(closer到0) + logₑ(0.65) + logₑ(0.05)</p><p id="8fb7" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">=-0.51+-101.71+-0.43+-3.00 =<strong class="jx hr">-105.65</strong></p><ul class=""><li id="afe4" class="kz la hh jx b jy jz kb kc kr lb ks lc kt ld kq le lf lg lh bi translated">P(Class=B|Data)</li></ul><p id="57a8" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">= P(Class = B)x(L(Feature 1 = 11 | Class = B)x L(Feature 2 = 7 | Class = B)x L(Feature 3 = 22 | Class = B))</p><p id="cd32" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">= [0.40 x (0.35 x 0.20 x(更接近于0))]</p><p id="cf93" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">类似地，取计算的logₑ()以避免下溢。</p><p id="b84c" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">logₑ(p(class=b|data))= logₑ[0.40 x(0.35 x 0.20 x(更接近于0))]</p><p id="4f34" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">= logₑ(0.40)+logₑ(0.35)+logₑ(0.20)+logₑ(closer到0)</p><p id="b0b9" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">=-0.92+-1.05+-1.61+-94.84 =<strong class="jx hr">-98.42</strong></p><p id="6da6" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated">由于与类别A的后验概率对数(-105.65)相比，类别B具有更高的后验概率对数(-98.42)<strong class="jx hr"/>→查询样本将被预测为类别B！</p></div><div class="ab cl lp lq go lr" role="separator"><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu lv"/><span class="ls bw bk lt lu"/></div><div class="ha hb hc hd he"><p id="ac37" class="pw-post-body-paragraph ju jv hh jx b jy jz ir ka kb kc iu kd kr kf kg kh ks kj kk kl kt kn ko kp kq ha bi translated"><em class="jw">接下来— </em> <a class="ae lw" href="https://kopaljain95.medium.com/how-to-implement-naive-bayes-24e92f2b49f3" rel="noopener"> <em class="jw">如何实现朴素贝叶斯？第二节:用Python</em></a><em class="jw">……</em>建立模型</p></div></div>    
</body>
</html>