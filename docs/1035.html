<html>
<head>
<title>INDIAN Food Image Classification using Transfer learning…</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用转移学习的印度食物图像分类…</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/indian-food-image-classification-using-transfer-learning-b8878187ddd1?source=collection_archive---------6-----------------------#2021-02-11">https://medium.com/analytics-vidhya/indian-food-image-classification-using-transfer-learning-b8878187ddd1?source=collection_archive---------6-----------------------#2021-02-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/ed647931a7f48cb2609adb9d0dc13607.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fl00ctymp1qLNyEv"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">照片由<a class="ae it" href="https://unsplash.com/@pillepriske?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">皮勒-张力尹·普里斯克</a>在<a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</figcaption></figure><p id="c445" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">注:</strong>该岗位要求具备Python、深度学习、图像预处理、分类模型评估等知识。如果你不熟悉这些概念，请随意离开这篇文章。谢谢你…</p><p id="8522" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Namste各位…在这篇文章中，我们将对印度食物图片进行分类。印度以其多元文化而闻名。这种多元文化也影响了印度食物。我们的印度食物种类繁多。印度各邦和邦内的食物各不相同。我们将应用深度学习算法来识别这些食品。我们的目标是通过引人注目的例子让你熟悉深度分类网络。对于美食爱好者来说，这篇文章会有趣得多。此外，我们还应用迁移学习技术来提高分类性能。</p><p id="f1f3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们使用<strong class="iw hi"> Food20 </strong>数据集进行实验。数据集在Kaggle平台免费获取:<a class="ae it" href="https://www.kaggle.com/cdart99/food20 dataset" rel="noopener ugc nofollow" target="_blank">数据集链接。</a>下载zip文件并解压。保持提取的文件夹与python笔记本文件平行。该数据集包含20种不同印度食物的图像，每种食物有100个样本图像。数据已经以训练测试(训练验证)分割格式存储。火车考比是70:30。图像的分辨率在200 x 150到5760 x 3840像素的范围内变化。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es js"><img src="../Images/afa32885842c1cb2e5f2fba5290e94d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P7XQRm3JbvDgYsPDA97W3w.png"/></div></div></figure><p id="2294" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">所需库:</strong></p><p id="7da7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将使用以下python的内置库和第三方库来执行分类实验。</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="4c8b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">数据加载和预处理:</strong></p><p id="39c9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，我们从辅助存储中加载所有图像。接下来，我们将每张图片调整为256 x 256的形状。我们还执行像素值的归一化。以下代码片段与预处理部分相关。</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="dcdc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">x_train和y_train表示训练部分的图像数据和标签。x_val和y_val代表验证或测试零件的图像数据和标签。这里，我们也将验证部分用于测试。您可以创建一个单独的测试集。</p><p id="6db6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">卷积神经网络模型:</strong></p><p id="a585" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在数据预处理之后，我们创建我们的CNN模型。这里，我不打算讨论卷积神经网络的基础知识。如果你是深度学习领域的初学者，请通过以下链接了解卷积:1。<a class="ae it" href="https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning" rel="noopener ugc nofollow" target="_blank">卷积神经网络由吴恩达</a>，2。<a class="ae it" href="https://www.geeksforgeeks.org/introduction-convolution-neural-network/" rel="noopener ugc nofollow" target="_blank">CNN简介</a>，<a class="ae it" href="https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/" rel="noopener ugc nofollow" target="_blank">卷积层如何工作</a>。下面的代码块代表了我们的CNN模型。</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="f699" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们对输入图像数据应用一系列二维卷积和汇集操作。接下来，我们展平卷积和池化运算的输出，以创建一个密集网络。最后，我们添加了一个SoftMax层，用于具有20个节点的最终分类(我们有20种食物图像)。您可以试验过滤器的大小，卷积和池层的数量。下图显示了CNN模型每一层需要学习的参数数量。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es jz"><img src="../Images/f59e9752c2352aae5d099b9d2b68686d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/1*19L798LILhN5J8JLIYbPrQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">带参数计数的CNN结构。</figcaption></figure><p id="4380" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们使用Adam优化器通过反向传播来更新参数值。要详细了解Adam优化器和反向传播，请访问以下链接:<a class="ae it" href="https://www.youtube.com/watch?v=JXQT_vxqwIs" rel="noopener ugc nofollow" target="_blank"> Adam优化器</a>、<a class="ae it" href="https://www.youtube.com/watch?v=x_Eamf8MHwU" rel="noopener ugc nofollow" target="_blank">反向传播</a>。我们训练CNN模型200个纪元。你用不同的历元数重复这个实验。</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="5896" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在训练CNN模型后，我们绘制了训练和验证损失图。我们还分析了该时期的准确度分数。以下代码块绘制了分析所需的图。</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="23b9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在20个时期之后，训练损失和准确性保持恒定，只有微小的变化。另一方面，验证损失在十个时期内减少，但在十个时期后开始增加。10个时期后，验证准确度在小范围内变化。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ka"><img src="../Images/715a574a2fd6ca130d99d0955924eab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FH2z7lU8HnMCfyf2FKqQNw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">CNN模型的训练和验证性能</figcaption></figure><p id="1da0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">性能得分:</strong></p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="2486" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">上面的代码块测试经过训练的CNN模型，并以精度、召回率和F1分数的形式输出性能。有关度量的更多细节，请点击以下链接:<a class="ae it" href="https://en.wikipedia.org/wiki/Precision_and_recall" rel="noopener ugc nofollow" target="_blank">维基百科</a>，<a class="ae it" href="https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9" rel="noopener" target="_blank">Accuracy _ Precision _ Recall</a>。下表显示了CNN模型的分类性能。我们得到了平均54%的F1分数。我们的模型在<em class="kb"> butternaan </em>和<em class="kb"> dosa </em>类别中表现更差。我们可以手动分析这两个类别的图像来确定原因，这将使我们获得更有用的见解。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es kc"><img src="../Images/0de94a1eb3cc940caf8dd14b2fec7161.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*fEuWOe2le7AC7J00jd01Pg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">类别精确度、召回率和F1分数。</figcaption></figure><p id="6937" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">混淆矩阵:</strong></p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="4e15" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">混淆矩阵是分类模型性能的表格表示。请不要走上它的名字；一点也不混乱。更多详情，请点击此链接:<a class="ae it" href="https://en.wikipedia.org/wiki/Confusion_matrix" rel="noopener ugc nofollow" target="_blank">维基百科</a>。简单来说，在理想的混淆矩阵中，所有的非对角线值都必须为零。从下面的混淆矩阵，我们可以分析错误分类的图像。例如，大多数<em class="kb">巴特南</em>图像被错误分类为<em class="kb">比里亚尼、多萨、懒懒、古拉卜贾蒙</em>。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es kd"><img src="../Images/b4bdeb49f821b09937ba67f2da213998.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*VfaDeNY2l6bYwOZM1D4Vpg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">CNN预测的混乱矩阵。</figcaption></figure><p id="9947" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">使用<em class="kb">迁移学习(TL) </em>进行改进:</strong></p><p id="b6a6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们已经用简单的CNN模型获得了平均性能。让我们利用TL的力量来提高性能。在TL中，我们存储在解决一个问题时获得的知识，并将其应用于另一个不同但相关的问题。当我们只有非常少量的数据用于训练时，TL可以帮助我们。在我们的例子中，我们只有每种食物的70张图片用于训练。TL可以用于提高分类性能。这里，我们使用在ImageNet数据集上训练的模型的预训练权重。我们用我们的输入和输出层替换预训练模型的输入和输出层。</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="c639" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们不会重新训练现有的模型重量。我们只训练最后一层。您可以在下图中看到可学习和不可学习参数的数量:</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es ke"><img src="../Images/106e1c121f5a95378ca49833f7125840.png" data-original-src="https://miro.medium.com/v2/resize:fit:1108/format:webp/1*jWrACU74Hr0iCEo1c_xOBA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">具有迁移学习的模型架构。</figcaption></figure><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">用于训练基于迁移学习的模型的代码块。</figcaption></figure><p id="ad65" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在训练了基于TL的模型之后，我们比较了我们的CNN模型和基于TL的模型的训练性能。下面的代码块绘制了简单CNN和基于TL的模型相对于历元的训练精度和损失值。</p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="ec25" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">基于TL的模型在验证部分获得了更高的训练精度。与简单的CNN模型不同，对于基于TL的模型，训练精度逐渐增加。基于TL的模型的损失值持续下降。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ka"><img src="../Images/2d45d56b156ec6b9c0cdcf4d422570db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*om8w68xgrKDX255dBdzJhQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">简单CNN模型与基于迁移学习的模型的训练和验证性能比较。</figcaption></figure><p id="a790" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">性能得分:</strong></p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="d0c1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">上面的代码块测试了基于TL的模型，并打印了分类性能。基于TL的模型取得了84%的F1分数。与简单的CNN模型相比，基于TL的模型能够更有效地对<em class="kb"> butternaan </em>和<em class="kb"> dosa </em>图像进行分类。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es kf"><img src="../Images/fe573efc6741b0293cda387258c1f423.png" data-original-src="https://miro.medium.com/v2/resize:fit:980/format:webp/1*8d_UpAeS8wOQxGGlGHsOzA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">类别精确度、召回率和F1分数。</figcaption></figure><p id="84f2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">混乱矩阵:</strong></p><figure class="jt ju jv jw fd ii"><div class="bz dy l di"><div class="jx jy l"/></div></figure><p id="e3d5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果我们将这个混淆矩阵与前一个相比较，我们在对角线上有更多的值。只有<em class="kb"> bisibelebath </em>类别仍有大量误分类图像。</p><figure class="jt ju jv jw fd ii er es paragraph-image"><div class="er es kd"><img src="../Images/020865a946e492c36ef51d24f00ed90f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*zQsVL-N8rOiROyoCQGyprg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">迁移学习模型预测的混淆矩阵。</figcaption></figure><p id="6647" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后，我们成功地完成了印度食物图像的分类任务。在这个实验中，我们看到了迁移学习的力量。您可以复制这个实验，并尝试使用模型超参数。我们在这里提供了笔记本文件:<a class="ae it" href="https://github.com/sawan16/Indian_food_image_classification" rel="noopener ugc nofollow" target="_blank"> GitHub链接</a>。请在执行代码之前安装所需的库。我会建议你使用Google Collaboratory平台。在Google Collaboratory中，你不需要安装任何库，你也可以获得免费的GPU。还有另一个食物图像数据集可在:<a class="ae it" href="https://www.tensorflow.org/datasets/catalog/food101" rel="noopener ugc nofollow" target="_blank"> Tensorflow网站(<strong class="iw hi"> food101 </strong> ) </a>获得。这个数据集比<strong class="iw hi"> Food20 </strong>数据集更通用、更大。您可以使用food101数据集尝试上述实验，以获得更多有用的见解。</p><p id="eec0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">感谢你阅读这篇文章…</p></div></div>    
</body>
</html>