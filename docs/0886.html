<html>
<head>
<title>Understanding Ensemble Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解集成学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-ensemble-learning-4019bfc2e8d1?source=collection_archive---------27-----------------------#2021-02-04">https://medium.com/analytics-vidhya/understanding-ensemble-learning-4019bfc2e8d1?source=collection_archive---------27-----------------------#2021-02-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="7e67" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">成为ML专家的一步。</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/829f305231226902e6110190646f827c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BLa3h7F4rGa2EtfX_a7jrQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">大数定律。</figcaption></figure><p id="8f8d" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi ki translated">这种算法背后的直觉来自于<strong class="jo hi"> <em class="kr">群体智慧</em> </strong>也就是说，在解决问题和做出决策时，许多人的集体智慧往往超过单个专家的智慧。</p><blockquote class="ks kt ku"><p id="c622" class="jm jn kr jo b jp jq ii jr js jt il ju kv jw jx jy kw ka kb kc kx ke kf kg kh ha bi translated"><strong class="jo hi"> <em class="hh">与大多数事物一样，平庸无奇。有了决策，往往是卓越</em> </strong> <em class="hh">。詹姆斯·索罗维基</em></p></blockquote><p id="c491" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">例如:假设你决定要买一部iPhone。但是，你不确定该选择哪种模式。所以你问一群人</p><ul class=""><li id="825c" class="ky kz hh jo b jp jq js jt jv la jz lb kd lc kh ld le lf lg bi translated">一个移动店主，他对模型的看法和你有60%的相似度。</li><li id="9b1a" class="ky kz hh jo b jp lh js li jv lj jz lk kd ll kh ld le lf lg bi translated">一个YouTube技术评论者，他和你对某个模型的看法80%相似。</li><li id="9768" class="ky kz hh jo b jp lh js li jv lj jz lk kd ll kh ld le lf lg bi translated">你的一个密友，和你的观点有70%的相似度。</li></ul><p id="ecb4" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">虽然每个人单独在一起时都会有某种偏差，但他们同时出错的概率等于-<br/>P =(1–0.6)x(1–0.8)x(1–0.7)<br/>P = 0.024<br/>这意味着他们的观点有97.6%(100–2.4)的可能性是好的(假设他们的观点相互独立)。这是一个相当高的概率来决定。合奏基于相似的信念。</p><h2 id="0507" class="lm ln hh bd lo lp lq lr ls lt lu lv lw jv lx ly lz jz ma mb mc kd md me mf mg bi translated">首先，我们来了解一下<strong class="ak">为什么需要系综建模</strong>？</h2><p id="bf18" class="pw-post-body-paragraph jm jn hh jo b jp mh ii jr js mi il ju jv mj jx jy jz mk kb kc kd ml kf kg kh ha bi translated">在现实世界中，通过单个模型对数据集进行概化可能具有挑战性。一些模型将能够很好地捕捉数据的一个方面，而其他模型将在捕捉其他方面做得很好。<br/>集合建模有助于减少误差，并在最终评估指标(例如:准确度/精确度)优于每个单独模型的情况下做出预测。</p><p id="752b" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">模型的组合强度抵消了单个模型的<em class="kr">方差</em>和<em class="kr">偏差</em>。</p><blockquote class="ks kt ku"><p id="b487" class="jm jn kr jo b jp jq ii jr js jt il ju kv jw jx jy kw ka kb kc kx ke kf kg kh ha bi translated"><strong class="jo hi">一根细枝折断，但这捆细枝却很结实</strong>。</p></blockquote><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mm"><img src="../Images/4571c5c6d79f352bcce344027c719fe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uYLplxOpfjVe5lLEODQRaA.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">就这么简单。</figcaption></figure><p id="0e40" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">因此，我们可以将<strong class="jo hi">集成建模定义为一种用于组合多个机器学习模型以产生一个最佳模型的机器学习技术。</strong></p><p id="5f30" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">集合建模(方法)可分为:</p><ol class=""><li id="9a3b" class="ky kz hh jo b jp jq js jt jv la jz lb kd lc kh mn le lf lg bi translated"><strong class="jo hi">序贯集成方法</strong>。</li></ol><ul class=""><li id="e666" class="ky kz hh jo b jp jq js jt jv la jz lb kd lc kh ld le lf lg bi translated">助推。</li></ul><ol class=""><li id="0501" class="ky kz hh jo b jp jq js jt jv la jz lb kd lc kh mn le lf lg bi translated"><strong class="jo hi">并行集成方法</strong>。</li></ol><ul class=""><li id="cef9" class="ky kz hh jo b jp jq js jt jv la jz lb kd lc kh ld le lf lg bi translated">装袋粘贴。</li><li id="8b53" class="ky kz hh jo b jp lh js li jv lj jz lk kd ll kh ld le lf lg bi translated">堆叠。</li></ul><p id="5317" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在<strong class="jo hi">顺序集成方法</strong>中，连续生成基础学习器或个体模型，以提高模型性能。在<strong class="jo hi">并行集成方法</strong>中，基础学习器独立于或同时于训练数据生成。</p><h2 id="7bd1" class="lm ln hh bd lo lp lq lr ls lt lu lv lw jv lx ly lz jz ma mb mc kd md me mf mg bi translated"><strong class="ak">增压</strong>:</h2><p id="842a" class="pw-post-body-paragraph jm jn hh jo b jp mh ii jr js mi il ju jv mj jx jy jz mk kb kc kd ml kf kg kh ha bi translated">基本上就是把几个弱学习者组合成一个强学习者。它按顺序训练模型，每个模型都试图纠正其前任。</p><ol class=""><li id="49ed" class="ky kz hh jo b jp jq js jt jv la jz lb kd lc kh mn le lf lg bi translated"><strong class="jo hi"> AdaBoost — </strong>这里，新的预测器更加关注错误分类的训练实例或先前模型拟合不足的实例。</li><li id="5923" class="ky kz hh jo b jp lh js li jv lj jz lk kd ll kh mn le lf lg bi translated"><strong class="jo hi">梯度推进— </strong>这里，新的预测器由先前预测器产生的残差来拟合。梯度提升框架的好处在于，不必为可能想要使用的每个损失函数导出新的提升算法，相反，它是足够通用的框架，使得可以使用任何可微分的<strong class="jo hi">损失函数</strong>。</li></ol><h2 id="779e" class="lm ln hh bd lo lp lq lr ls lt lu lv lw jv lx ly lz jz ma mb mc kd md me mf mg bi translated"><strong class="ak">装袋粘贴</strong>:</h2><p id="7272" class="pw-post-body-paragraph jm jn hh jo b jp mh ii jr js mi il ju jv mj jx jy jz mk kb kc kd ml kf kg kh ha bi translated">Bagging通常被称为<strong class="jo hi">B</strong>ootstrap<strong class="jo hi">AGG</strong>regat<strong class="jo hi">ING</strong>是一种集成学习方法，其中给定一个训练集，通过从原始数据集中替换采样，创建多个不同的训练样本(称为bootstrap样本)。然后，为每个引导样本建立一个模型。然后将各个预测汇总，形成最终预测。</p><p id="3bda" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在没有 替换的情况下进行<strong class="jo hi"> <em class="kr">采样时，称为粘贴。</em></strong></p><p id="6cdb" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi"> RandomForest — </strong>它是<em class="kr">决策树</em>的集合，一般通过bagging方法训练。随机森林导致更大的树多样性，这以<strong class="jo hi">更高的偏差</strong>(由于特征得到子集化)换取<strong class="jo hi">更低的方差</strong>，通常产生<strong class="jo hi">整体更好的模型</strong>。</p><h2 id="296c" class="lm ln hh bd lo lp lq lr ls lt lu lv lw jv lx ly lz jz ma mb mc kd md me mf mg bi translated">堆叠:</h2><p id="8aa6" class="pw-post-body-paragraph jm jn hh jo b jp mh ii jr js mi il ju jv mj jx jy jz mk kb kc kd ml kf kg kh ha bi translated">堆叠是一种集成学习技术，通过元分类器或混合器来组合多个分类模型。它训练一个新模型来执行聚合，而不是使用任何竞争函数。</p><p id="f8dc" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">因此，集成学习通常会提高预测性能，但它也带来了<strong class="jo hi">高计算复杂性</strong>的成本，并且产生的输出也可能<strong class="jo hi">难以分析</strong>。</p><p id="4221" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">因此，我们必须尝试不同的算法，包括集成技术，以获得特定数据集的最佳预测。</p><p id="23e7" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如果你有任何建议或反馈，请通过我的电子邮件<em class="kr">mwasim.j01@gmail.com联系我。</em></p></div></div>    
</body>
</html>