<html>
<head>
<title>Machine Learning Techniques for Credit Card Fraud Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于信用卡欺诈检测的机器学习技术</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-techniques-for-credit-card-fraud-detection-609421fbcc48?source=collection_archive---------7-----------------------#2021-03-09">https://medium.com/analytics-vidhya/machine-learning-techniques-for-credit-card-fraud-detection-609421fbcc48?source=collection_archive---------7-----------------------#2021-03-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/313e3fb37f55d077c9255deb6735db67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b9PlXGgaCZ5jFqDCh8CW9w.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://unsplash.com/@rupixen?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">rupixen.com</a>在<a class="ae iu" href="https://unsplash.com/s/photos/credit?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</figcaption></figure><p id="f99f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">网上诈骗空前猖獗。在我们日益数字化的世界中，欺诈者利用互联网剥削他人从未如此容易。更糟糕的是，许多消费者的密码、信用卡号和其他敏感信息在黑暗网络上泄露。这导致账户被接管，每天都有新的欺诈性信用额度被开立。许多仍然完全不为人知。</p><p id="e499" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">信用卡诈骗是最常见的网络诈骗之一。信用卡号、pin和安全码很容易被窃取并用于欺诈交易。这会给商家和消费者带来巨大的经济损失。然而，信用卡公司最终有责任偿还客户的任何损失。因此，对于信用卡公司和其他金融机构来说，能够在欺诈发生之前检测到它是极其重要的。</p><p id="9006" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">机器学习已经成为一种越来越容易使用和可靠的方法来检测欺诈性交易。使用历史数据集，可以训练机器学习模型来学习欺诈行为背后的模式。然后可以应用一个模型来过滤掉欺诈性交易，并实时阻止它们的发生。</p><p id="8af4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这篇文章将研究4种常用的欺诈检测机器学习方法。其中包括:</p><ul class=""><li id="6802" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">随机森林</li><li id="8fb5" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">CatBoost</li><li id="7605" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">深度神经网络(DNN)</li><li id="f2f3" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">隔离森林</li></ul><p id="3313" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们将深入探讨如何用Python创建这些模型的基础知识，并比较它们彼此之间的表现。我们开始吧！</p><h1 id="cc9f" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">设置</h1><p id="61f4" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">首先，我们需要导入一些Python库，用于数据操作、建模和评估。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="ffd6" class="lt ki hi lp b fi lu lv l lw lx">import pandas as pd<br/>from sklearn.ensemble import RandomForestClassifier<br/>from keras.models import Sequential<br/>from keras.layers import Dense, Dropout, Flatten, Activation<br/>from sklearn.metrics import roc_curve<br/>from sklearn.metrics import auc<br/>import matplotlib as mpl<br/>import matplotlib.pyplot as plt</span><span id="cf27" class="lt ki hi lp b fi ly lv l lw lx">#configure plot size and colors <br/>mpl.rcParams['figure.figsize'] = (10, 10)<br/>colors = plt.rcParams['axes.prop_cycle'].by_key()['color']</span></pre><p id="8201" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">使用sklearn <em class="lz"> roc_curve </em>和<em class="lz"> auc </em>来评估模型性能。这将帮助我们了解我们的模型在预测真阳性和假阳性方面的表现。一般来说，机构希望在低的、固定的假阳性率下有高的真阳性率。因此，ROC曲线是衡量欺诈分类器性能的一种有意义的方法。</p><h1 id="7bc5" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">数据准备</h1><p id="6181" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">为了评估欺诈检测的不同机器学习方法，我们将使用在ka ggle(<a class="ae iu" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/mlg-ulb/creditcardfraud</a>)上公开提供的“信用卡欺诈检测”数据集。该数据集包含2013年欧洲持卡人的多笔信用卡交易。由于原始数据集包含敏感的个人身份信息(PII)，因此该数据集中的许多要素都使用PCA进行了转换。</p><p id="08a3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">每笔交易都在“类别”一栏中被如实标记为<em class="lz">欺诈</em>或<em class="lz">非欺诈</em>。看一下类别百分比，很明显只有极小比例的交易是欺诈性的(00.17 %)。由于大的类别不平衡，这使得训练分类器具有挑战性。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="ca9c" class="lt ki hi lp b fi lu lv l lw lx">#load data<br/>df = pd.read_csv('creditcard.csv')</span><span id="8602" class="lt ki hi lp b fi ly lv l lw lx">#drop NULL values<br/>df = df.dropna()</span><span id="b19c" class="lt ki hi lp b fi ly lv l lw lx">#drop Time column (contains limited useful information)<br/>df = df.drop('Time', axis = 1)</span><span id="29db" class="lt ki hi lp b fi ly lv l lw lx">#group data by Class<br/>groups = df.groupby('Class')<br/>fraud = (groups.get_group(1).shape[0] / df.shape[0]) * 100<br/>non_fraud = (groups.get_group(0).shape[0] / df.shape[0]) * 100</span><span id="b920" class="lt ki hi lp b fi ly lv l lw lx">#print class percentage<br/>print('Percent Fraud: ' + str(fraud) + '%')<br/>print('Percent Not Fraud ' + str(non_fraud) + '%')</span></pre><figure class="lk ll lm ln fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ma"><img src="../Images/6d3360c0af3865f224be640f78b99e80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x84ABHfa4ajk9v_ec_Kt8w.png"/></div></div></figure><p id="ac95" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们将使用我们的数据创建一个训练集和一个维持集，以便我们可以快速评估我们的模型如何处理全新的、看不见的数据。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="5234" class="lt ki hi lp b fi lu lv l lw lx">df_size = df.shape[0]<br/>test_size = int(df_size * .3)<br/>train_size = df_size - test_size</span><span id="b224" class="lt ki hi lp b fi ly lv l lw lx">train_df = df.head(train_size)<br/>test_df = df.tail(test_size)</span><span id="0a10" class="lt ki hi lp b fi ly lv l lw lx">X_train = train_df.drop('Class', axis = 1)<br/>Y_train = train_df['Class']<br/>X_test = test_df.drop('Class', axis = 1)<br/>Y_test = test_df['Class']</span></pre><p id="2ecb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，我们将对所有特征应用标准缩放器，使它们的平均值为0，标准差为1。这将有助于我们的模型更有效地学习。</p><p id="4016" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们只在训练集上拟合我们的标准标量，以防止它偏离如何转换我们的测试集。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="0a66" class="lt ki hi lp b fi lu lv l lw lx">for feat in X_train.columns.values:</span><span id="2392" class="lt ki hi lp b fi ly lv l lw lx">    ss = StandardScaler()</span><span id="d30f" class="lt ki hi lp b fi ly lv l lw lx">    X_train[feat] = ss.fit_transform(X_train[feat].values.reshape(-1,1))</span><span id="3ebc" class="lt ki hi lp b fi ly lv l lw lx">    X_test[feat] = ss.transform(X_test[feat].values.reshape(-1,1))</span></pre><p id="5573" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在我们已经准备好了数据，是时候开始构建一些模型了！</p><h1 id="6c79" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">方法1:随机森林</h1><p id="2440" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">我们将用于训练欺诈分类器的第一种方法是随机森林。随机森林是一种流行的监督机器学习算法，可用于分类和回归任务。该模型的工作方式是对训练数据集进行采样，构建多个决策树，然后让决策树的输出确定一个预测。该模型可以方便地处理高维大数据集，也可以方便地处理分类值。然而，它可能会受到我们的数据中的大类不平衡的影响。</p><p id="0071" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">首先，让我们启动一个基本的随机森林模型，并使用我们的训练数据对其进行训练。然后，我们将检索测试集中每个数据点的概率。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="6927" class="lt ki hi lp b fi lu lv l lw lx">#create Random Forest Model<br/>rf = RandomForestClassifier()</span><span id="4300" class="lt ki hi lp b fi ly lv l lw lx">#fit to training data<br/>rf.fit(X_train, Y_train)</span><span id="93d9" class="lt ki hi lp b fi ly lv l lw lx">#get class probabilities<br/>probabilities = clf.predict_proba(X_test)<br/>y_pred_rf = probabilities[:,1]</span></pre><p id="2c28" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，让我们计算一些基本的性能指标。我们将计算假阳性率(FPR)、真阳性率(TPR)和ROC曲线下的面积。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="2bfb" class="lt ki hi lp b fi lu lv l lw lx">fpr_rf, tpr_rf, thresholds_rf = roc_curve(Y_test, y_pred_rf)<br/>auc_rf = auc(fpr_rf, tpr_rf)</span></pre><p id="c3b8" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，让我们用ROC曲线(接受者操作者特征)来描绘我们模型的性能。这将帮助我们理解我们的模型在我们的测试集上产生的真阳性和假阳性之间的关系。如果我们的模型表现良好，我们应该在低假阳性率的情况下看到高真阳性率。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="fbff" class="lt ki hi lp b fi lu lv l lw lx">plt.plot(100*fpr_rf, 100*tpr_rf, label= 'Random Forest (area = {:.3f})'.format(auc_rf), linewidth=2, color = colors[0])</span><span id="6751" class="lt ki hi lp b fi ly lv l lw lx">plt.xlabel('False positives [%]')<br/>plt.ylabel('True positives [%]')<br/>plt.xlim([0,30])<br/>plt.ylim([60,100])<br/>plt.grid(True)<br/>ax = plt.gca()<br/>ax.set_aspect('equal')<br/>plt.title('Random Forest Model Performance')<br/>plt.legend(loc='best')</span></pre><figure class="lk ll lm ln fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/12ac81386c751cec287394fd3f46dc8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*Na5Eh9RsqoS-MStdJPaEag.png"/></div></figure><p id="a258" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">看起来相当不错！随机森林似乎是一种用于欺诈检测的好的机器学习方法。在不同的假阳性率(FPR)下，它有一个持续的高真阳性率(TPR)。</p><p id="dd4c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们看看更多的模型，看看他们如何比较。</p><h1 id="c005" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">方法2: CatBoost</h1><p id="4839" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">我们将尝试的下一个方法是CatBoost，这是一个用于决策树梯度提升的开源库。CatBoost算法的工作原理是连续构建决策树，并最小化每个新构建的决策树的损失。该算法因无需大量参数调整即可提供出色的结果而臭名昭著。此外，CatBoost被设计为能够很好地处理不平衡数据，这使得该算法非常适合用于欺诈检测。</p><p id="3cc5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们启动一个默认的CatBoost模型，并使其适合我们的训练数据。然后，让我们得到测试集的类概率。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="d019" class="lt ki hi lp b fi lu lv l lw lx">#create CatBoost Model<br/>clf = CatBoostClassifier()</span><span id="c585" class="lt ki hi lp b fi ly lv l lw lx">#fit to our data<br/>clf.fit(X_train, Y_train)</span><span id="4aca" class="lt ki hi lp b fi ly lv l lw lx">#generate class probabilities<br/>y_pred = clf.predict(X_test, prediction_type='RawFormulaVal')</span></pre><p id="4e0a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们做一些评估，看看我们的模型表现如何。</p><figure class="lk ll lm ln fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/2e6feff8a85b3c0247c3346574172813.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*jIfMYMCBuHy0QsHjtK2nTA.png"/></div></figure><p id="23f1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">乍一看，CatBoost似乎已经推翻了随机森林算法，提供了<strong class="ix hj"> .978 </strong>的AUC值。与我们的随机森林相比，这是一个显著的提升，随机森林的AUC值只有<strong class="ix hj"> .928 </strong>。</p><h1 id="b8a5" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">方法3:深度神经网络(DNN)</h1><p id="b8a7" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">威尔尝试的下一个方法是深度神经网络。神经网络是一种非常强大的机器学习方法，其灵感来自于神经元在大脑中的工作方式。神经网络继续应用于许多机器学习问题，如图像识别、语音检测和自动驾驶汽车。这些模型非常强大，因为它们学习了其他模型难以识别的输入和输出变量之间的复杂关系。然而，使用神经网络的一个缺点是，它们有时需要大量的微调才能产生理想的结果。</p><p id="f28f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">不幸的是，我没有时间(<em class="lz">或专业知识，坦率地说</em>)来真正深入研究如何建立和训练一个强大的神经网络。然而，我提供了一个基线神经网络，它是我在Keras中构建的，并且发现在欺诈检测中是成功的。这个神经网络包括3个密集层来从我们的数据中学习特征，以及2个下降层来防止过度拟合。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="fee7" class="lt ki hi lp b fi lu lv l lw lx">#Design and compile model<br/>DNN = Sequential()<br/>DNN.add(Input(shape=(X_train.shape[1],)))<br/>DNN.add(Dense(100, activation='relu'))<br/>DNN.add(Dropout(0.5))<br/>DNN.add(Dense(100, activation='relu'))<br/>DNN.add(Dropout(0.5))<br/>DNN.add(Dense(10, activation='relu'))<br/>DNN.add(Dense(1, activation='sigmoid'))<br/>DNN.compile(loss='binary_crossentropy', optimizer='adam', metrics = keras.metrics.AUC(name='auc'))</span><span id="5f2a" class="lt ki hi lp b fi ly lv l lw lx">#fit model<br/>DNN.fit(X_train, Y_train, epochs=10)</span><span id="b501" class="lt ki hi lp b fi ly lv l lw lx">#generate class probabilities<br/>y_pred_DNN = DNN.predict(X_test).ravel()</span></pre><p id="06df" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在拟合我们的模型并生成我们的预测概率后，让我们看看我们的DNN表现如何。</p><figure class="lk ll lm ln fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/3582551c50c181322f13772183270950.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*KS3yq-qG8thTPOqBcCPmSA.png"/></div></figure><p id="5a21" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">杰出！似乎CatBoost和我们的DNN都是迄今为止我们表现最好的车型。</p><h1 id="a6b9" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">方法4:隔离林</h1><p id="7e47" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">我们将尝试使用的最后一种方法是隔离林(或“I Forest”)；这是一种与我们以前的方法非常不同的欺诈检测方法。到目前为止，我们只看了<strong class="ix hj"> <em class="lz">监督学习</em> </strong>方法，其中模型是基于真实标记的数据来训练的。同时，隔离森林是一种<strong class="ix hj"> <em class="lz">无监督学习</em> </strong>方法，这意味着它不需要任何真值标记来进行预测，只从它在训练数据中找到的模式中学习。</p><p id="a2d0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在现实世界中，公司并不总是有真实的欺诈数据。例如，如果一个公司第一次尝试部署一个解决方案，并且它没有很多欺诈的例子可以使用，那么就不可能训练一个监督分类器。此外，出于安全原因，公司可能无法共享真实标记的欺诈数据，或者可能根本没有任何可用的欺诈示例。</p><p id="4555" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">隔离林是一种基于树的算法，用于异常检测。该算法通过使用决策树来隔离数据中的异常值。理论上，我们的欺诈群体应该主要由与我们的其余交易相比异常的数据点组成。因此，当我们没有任何标签时，这是识别欺诈的完美解决方案。</p><p id="5393" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">让我们用Python实现我们的iForest。注意我们是如何不需要“Y_train”的，因为我们的模型不需要任何真值标记来训练。</p><pre class="lk ll lm ln fd lo lp lq lr aw ls bi"><span id="7c1d" class="lt ki hi lp b fi lu lv l lw lx">#create iforest model<br/>iforest = IsolationForest()</span><span id="9d25" class="lt ki hi lp b fi ly lv l lw lx">#fit to data<br/>iforest.fit(X_train)</span><span id="2e36" class="lt ki hi lp b fi ly lv l lw lx">#generate class probabilities<br/>y_pred_iforest = - iforest.decision_function(X_test)</span></pre><p id="dfb4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">最后，让我们看看它的表现如何。</p><figure class="lk ll lm ln fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/be985c02da45a18042323edeaa5f890b.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*THgvo2ItecZWuMzT8fOXvQ.png"/></div></figure><p id="9612" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">这种方法在识别欺诈人群方面表现得非常好。然而，它比我们尝试的其他方法产生更多的假阳性。在需要的情况下，这可能非常有用。</p><h1 id="affd" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">结论</h1><p id="9ecb" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lh ji jj jk li jm jn jo lj jq jr js hb bi translated">下面是我们为信用卡欺诈检测探索的所有机器学习方法的比较。</p><figure class="lk ll lm ln fd ij er es paragraph-image"><div class="er es mb"><img src="../Images/eef350e5369d71d146dc87fafb79d930.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*BvaE_C8H3DMetTdUwlYNug.png"/></div></figure><p id="255e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在我们的测试数据集中，深度神经网络和CatBoost似乎在检测欺诈方面工作得最好。然而，根据欺诈问题的背景，多种其他方法也可能有用。随着更先进的机器学习方法的不断开发，看看哪些方法在识别欺诈方面最有效将是一件有趣的事情。</p><p id="1f4d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Github repo与所有代码/视觉效果在这里:<a class="ae iu" href="https://github.com/ryankemmer/CreditCardFraudDetection" rel="noopener ugc nofollow" target="_blank">https://github.com/ryankemmer/CreditCardFraudDetection</a></p></div></div>    
</body>
</html>