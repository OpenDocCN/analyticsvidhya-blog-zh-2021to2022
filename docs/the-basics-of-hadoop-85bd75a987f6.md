# Hadoop 的基础知识

> 原文：<https://medium.com/analytics-vidhya/the-basics-of-hadoop-85bd75a987f6?source=collection_archive---------28----------------------->

**Hadoop 的基础知识**

Hadoop 是一个用 java 编写的 Apache 开源框架，它允许使用简单的编程模型跨计算机集群分布式处理大型数据集。

首先，拥有大型数据集意味着什么？它有多大？

你可能知道，像谷歌、脸书、亚马逊等大型科技巨头每天都会产生数十亿字节的数据。

这个数据是关于什么的？毫不奇怪，你、我和许多像我们一样的人都是这些公司收集、分析和处理数据的重要贡献者。正是由于这种先进的加工工艺，我们使用他们产品的体验与日俱增。

你有没有想过，Instagram 是如何展示你最感兴趣的图片/视频的？或者，亚马逊如何能够推荐你下一次可能需要添加到购物车中的东西？

所有这些都是收集、分析和处理互联网用户产生的大量数据的结果。

我们给如此大量的数据贴上标签的一个著名的技术术语是“大数据”。

在这篇博客中，我们将探讨如何在存储方面处理“大数据”。

**为什么大数据是个问题？**

想象一下，你有 20 个客人来你家。不幸的是，你只能为其中的 5 个腾出空间。更不用说他们中的每一个对你来说都同样重要。你将如何接纳他们？

感谢上帝，你想到了一家酒店(虽然不总是五星级的)。

将这种类比扩展到数据是理解 Hadoop 技术的基础。

简而言之，当数据超出您的容量时，您会从其他计算设备中寻找资源来存储和处理数据(RAM、CPU 和硬盘)。

Apache Hadoop 是一个用于存储大量数据和执行计算的软件编程框架。

**一群商品硬件**

Hadoop 集群是一种将大数据分解成较小部分的方式，然后将这些数据存储在 Hadoop 工作节点网络中。这些工作节点可能是简单的商用硬件，不会给人留下深刻印象。

为了管理各种工作节点，有一个主节点保存所有元数据，如数据的哪一部分存储在哪里等等。主节点运行 NameNode 进程，而从节点或工作节点运行 DataNode 进程。

![](img/6421d82dadf4248d0617457e79b5eefd.png)

**引擎盖下是什么？**

**HDFS**

当你在本地机器上存储文件/文件夹时，它使用一个文件系统来跟踪你放入的所有数据。例如，维护 inode 表是文件系统的责任。

这里，我们讨论的是跨多个节点存储文件和文件夹。显然，普通的文件系统是不够的。

Hadoop 使用的分布式文件系统是 HDFS——Hadoop 分布式文件系统。这个文件系统与传统的文件系统略有不同。它有一个主/从架构。如前所述，主节点将负责所有文件系统命名空间，并将管理客户端对文件的访问，而数据节点将提供用于存储文件的实际存储。

在内部，文件被分割成一个或多个块，这些块存储在一组 DataNodes 中。NameNode 执行文件系统命名空间操作，如打开、关闭和重命名文件和目录。它还决定了块到 DataNodes 的映射。

开发 HDFS 是为了提供高可用性，因此，数据块在整个群集内复制，每个文件的副本数量是可配置的，并上传到 HDFS。

![](img/d79894ed3cdca0704599d71631b40583.png)

我们已经看到，主节点运行 NameNode 进程并执行分布式文件系统的名称空间。类似地，从节点运行 DataNode 进程。从节点是我们存储数据(输入文件的块)的地方。

当客户端有数据要上传到 HDFS 时，NameNode 将分配活动的 DataNodes 来存储数据块。

NameNode 如何知道 DataNode 是活动的？

DataNode 进程每 3 秒钟向 NameNode 连续发送一个心跳信号，这样 NameNode 就知道有一个特定的从机可以容纳数据。

回到前面关于客户端上传文件的讨论——现在 NameNode 绘制了一个 DataNodes 列表，输入文件的块将存储在这个列表中。我们已经了解到，为了提供高可用性，每个数据块都被复制(默认为 3 次)。因此，最初，从客户端机器，一个数据块将被写入其中一个从属机器。该系统依次将同一文件块复制到另一台从机中。这一直持续到创建了数据块的所需副本。

**主人是如何跟踪元数据的？**

运行在主节点上的 NameNode 创建一个本地日志文件来持久地记录文件系统中的变化。例如，每当一个新文件被上传或从文件系统中删除时，在该文件中会创建一个条目来表明这一点。我们称这个日志为**编辑日志**。

FsImage 是本地文件系统中的文件，它存储了分布式文件系统的整个名称空间。因此，每当 NameNode 启动时，它都会读取 FsImage 文件，应用编辑日志中跟踪的所有更改，然后创建 fsImage 的最终版本并用于会话。

这些信息太多了，一次阅读无法掌握。我们将在下一篇博客中探索更多。

只是，万一你想试验这些东西…

所有 HDFS 通信都通过 TCP/IP 进行。也就是说，DataNode 和 NameNode 通过 TCP/IP 协议进行通信。如果您配置了 HDFS，这非常简单—安装 2–3 个 CLI 模式虚拟机，然后在这些虚拟机上安装 java 和 Hadoop。通过编辑 hdfs-site.xml 和 core-site.xml 文件，将一个配置为主服务器，另一个配置为从服务器。然后，尝试使用 hdfs 命令在 HDFS 上上传文件。

在所有系统上，启动一个 *tcpdump* 进程，该进程将捕获网络流量。如果您擅长分析 IP 包，那么您将会在输入文件被上传的同时探索 NameNode 和 DataNode 之间以及 DataNode 之间正在进行的通信。