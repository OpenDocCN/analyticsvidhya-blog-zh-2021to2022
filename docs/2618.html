<html>
<head>
<title>Towards an Inbox Without Junk: a Machine Learning Approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">迈向没有垃圾的收件箱:一种机器学习方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/towards-an-inbox-without-junk-a-machine-learning-approach-af32a5ed3abd?source=collection_archive---------18-----------------------#2021-05-07">https://medium.com/analytics-vidhya/towards-an-inbox-without-junk-a-machine-learning-approach-af32a5ed3abd?source=collection_archive---------18-----------------------#2021-05-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="6aff" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">使用监督和深度机器学习算法从头开始设计垃圾邮件过滤系统</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/e35226cf9c1ce0be6022f06fe71e25cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NII_Oo6iCyO7WFawinaiuQ.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">来源:如何极客</figcaption></figure><p id="9a8c" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在每天发送的3000多亿封电子邮件中，至少有一半是垃圾邮件。作为一名Gmail用户，我有时会想当然地认为自己节省了多少时间，因为谷歌完成了过滤收件箱中所有垃圾邮件的巨大任务，只留下真正重要的邮件。</p><p id="96d0" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">这让我想到:<em class="ki">谷歌用什么算法来自动检测垃圾邮件？</em>从赢得国家彩票的机会，到获得当地诊所的免费面部护理，垃圾邮件的形式多种多样。这使得垃圾邮件和非垃圾邮件之间的界限变得模糊，更不用说由于不断发展的趋势，这些标准必须随着时间的推移而改变。在这一点上，说垃圾邮件检测困难是轻描淡写的。</p><p id="c90b" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">应对这一挑战的最佳方式之一是通过机器学习。我已经训练了<strong class="jo hi">八个</strong>有监督的机器学习模型，它们将在准确度、精确度、时间和误差方面进行评估和相互比较。</p><p id="d885" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">参考我用来建立我的模型的数据集<a class="ae kj" href="https://www.kaggle.com/nitishabharathi/email-spam-dataset" rel="noopener ugc nofollow" target="_blank">这里</a>。该数据集汇编了来自两个不同来源的<strong class="jo hi">垃圾邮件与“ham”</strong>(或非垃圾邮件)电子邮件:LingSpam和垃圾邮件刺客数据集。通过这种方式，我们可以接触到各种各样的例子，这些例子可以用来训练我们的模型。所有代码和数据集的副本也可以在我的<a class="ae kj" href="https://github.com/maytanti/Email-Spam-Classification" rel="noopener ugc nofollow" target="_blank"> GitHub库</a>中找到。</p><h1 id="1c75" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated"><strong class="ak">探索性数据分析</strong></h1><h2 id="e1a9" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">为了更好的理解数据，我们先来探究一下。</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es lq"><img src="../Images/cf175686d75f5aba99a25f5b14a40098.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*DmIHbeTCx0M83YyDX5_F4g.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图1: </strong>垃圾邮件和非垃圾邮件的分布</figcaption></figure><p id="c307" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">查看垃圾邮件到业余电子邮件的分布，我们发现垃圾邮件比业余电子邮件少。事实上，垃圾邮件仅占整个数据集的四分之一左右。在将数据分成训练集和测试集时，以及在评估模型时，我们必须记住这一点。</p><div class="ix iy iz ja fd ab cb"><figure class="lr jb ls lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><img src="../Images/8708f08a819e59e7bc9823347d6105e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*YyKsauc0lZwsk1A19_9MqQ.png"/></div></figure><figure class="lr jb lx lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><img src="../Images/d854e5ccb0658469ade515de9ebcd433.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*3y1JwU6pZmI5lbi73Vm1Zg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx ly di lz ma translated"><strong class="bd km">图2: </strong>非垃圾邮件中常见的停用词<strong class="bd km">(左)</strong>。<strong class="bd km">图3: </strong>垃圾邮件中常见的停用词<strong class="bd km">(右)</strong>。</figcaption></figure></div><p id="dcda" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">接下来，我们必须考虑垃圾邮件中<strong class="jo hi">停用词</strong>出现的模式，与垃圾邮件进行比较。停用词通常指的是一种语言中最常见的词，如{t <em class="ki"> he，of，</em>或<em class="ki">and【T5 }。从<em class="ki">图2 </em>和<em class="ki"> 3 </em>中，我注意到垃圾邮件和垃圾邮件都有最常见的关键词。这验证了停用词在确定电子邮件是垃圾邮件还是垃圾邮件时没有权重，因此可以被删除。</em></p><p id="393e" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">理论上，在处理数据时，应该过滤掉停用词，以便潜在地帮助提高性能，因为剩下的词越来越少，而且只有有意义的词。这有助于提高我们模型的准确性。虽然没有所有自然语言处理工具都使用的单一通用停用词列表，但有许多工具可以帮助识别常用停用词。我使用了来自<strong class="jo hi"> NLTK的<em class="ki">停用词库</em>。</strong></p><div class="ix iy iz ja fd ab cb"><figure class="lr jb ls lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><img src="../Images/6d9c694969288d4a2ebe224e4179faf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/1*ZsWXrwkKJT_9kMwe5TOleA.png"/></div></figure><figure class="lr jb lx lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><img src="../Images/6efcb602f85e2955f881ca41eebb9733.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/1*ITM7PTAHdm748BECT8gMiA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx ly di lz ma translated"><strong class="bd km">图4: </strong>非垃圾邮件中标点符号出现的频率<strong class="bd km">(左)</strong>。<strong class="bd km">图5: </strong>垃圾邮件中标点符号出现频率<strong class="bd km">(右)</strong>。</figcaption></figure></div><p id="83ff" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">标点符号表现出类似的趋势，这意味着它们也可以在数据预处理中被去除。</p><h1 id="4090" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated"><strong class="ak">数据预处理</strong></h1><p id="167a" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">为了将数据准备到训练集和测试集中，我必须:</p><ol class=""><li id="521c" class="mg mh hh jo b jp jq js jt jv mi jz mj kd mk kh ml mm mn mo bi translated">删除所有URL。</li><li id="ceed" class="mg mh hh jo b jp mp js mq jv mr jz ms kd mt kh ml mm mn mo bi translated">移除所有符号。</li><li id="ff2f" class="mg mh hh jo b jp mp js mq jv mr jz ms kd mt kh ml mm mn mo bi translated">将所有字符转换成小写。</li><li id="6113" class="mg mh hh jo b jp mp js mq jv mr jz ms kd mt kh ml mm mn mo bi translated"><strong class="jo hi">分词</strong>单词。</li><li id="3c2d" class="mg mh hh jo b jp mp js mq jv mr jz ms kd mt kh ml mm mn mo bi translated"><strong class="jo hi">将</strong>的单词进行词条整理。</li><li id="0ff9" class="mg mh hh jo b jp mp js mq jv mr jz ms kd mt kh ml mm mn mo bi translated">删除停用词。</li></ol><p id="b685" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">听起来有点奇怪的两个步骤是<strong class="jo hi">标记化</strong>和<strong class="jo hi">词汇化</strong>。</p><p id="ca03" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">单词标记化(tokenization)是将大样本文本分割成单个单词的过程。<strong class="jo hi">词汇化</strong>是利用特定语言的词典，将单词转换回其基本形式。在<strong class="jo hi"> NLTK </strong>库的帮助下，简化了术语化的实现。</p><h2 id="6fc9" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">想象我们目前所拥有的。</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mu"><img src="../Images/570cddcf55923dd21603039cf477663f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wQSzVhNOyuH5ucvshZkyOA.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图6: </strong>非垃圾邮件中最常见的单词、数字或字符序列</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mv"><img src="../Images/172ba5aaf12f00e7c3fb67d3209d4ab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o9q3Q_cY1CEyA2Yn3gRD8Q.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图7: </strong>垃圾邮件中最常见的单词、数字或字符序列</figcaption></figure><p id="2708" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">即使当我们的数据集由<strong class="jo hi"> 90，000+ </strong>个独特的单词组成时，垃圾邮件中最常见的单词通常也是垃圾邮件“触发”单词本身。这些都是像{ <em class="ki">免费</em>、<em class="ki">地址</em>、<em class="ki">金钱</em>、<em class="ki">订单</em>或者<em class="ki">点击</em>这样的话。虽然<em class="ki">图6 </em>和<em class="ki"> 7 </em>只显示了这些词的出现频率，但在对垃圾邮件检测系统进行分类时，有了这种意识可能会改善我们的决策。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mw"><img src="../Images/ff3872fa46a216a4b1a2b9bc55c265a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EugrV_z5rosNsqxW0w8eRQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图8: </strong>垃圾邮件词云</figcaption></figure><p id="7de2" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">垃圾邮件中提到的更多种类的常用词在这个词云中表示。</p><h1 id="4b36" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">列车测试分离</h1><p id="ba27" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">尽管近年来自然语言处理取得了许多进步，<strong class="jo hi">人工智能算法仍然不像我们一样理解语言。</strong>因此，在我们开发任何模型之前，我们必须将我们的数据转换为我们的机器学习算法可以理解的格式。</p><p id="e68a" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">为了将每封电子邮件组织成与建模兼容的格式，我们需要一些特征提取层来将单词转换成整数或浮点数。这可以通过矢量化来实现，也就是将一组文本转化为数字特征向量的过程。我使用<strong class="jo hi">计数矢量器</strong>将每个条目表示为一个向量，该向量基于在数据集中找到的<strong class="jo hi"> 20，000个最常见单词</strong>的词频(忽略单词的相对位置信息)形成。</p><p id="064b" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">为了公平地评估我们的模型，我们必须分离一部分数据，以便可以根据我们训练的模型对其进行测试。我已经将<strong class="jo hi"> 80% </strong>的数据分配到<strong class="jo hi">训练</strong>数据集，剩下<strong class="jo hi"> 20% </strong>给<strong class="jo hi">测试</strong>数据集。我还使用了<strong class="jo hi">随机状态</strong>的<strong class="jo hi"> 42 </strong>来确保我生成的分割是可重复的。</p><p id="2a7d" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">正如之前在讨论图1 时所述，确保训练集和测试集之间的数据分布相似非常重要，尤其是当数据集只有四分之一是垃圾邮件时。这可以通过使用我已经实现的<strong class="jo hi">分层参数</strong>来实现。</p><h2 id="0c2a" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">现在，让我们训练一系列模型来找到最有效的垃圾邮件与火腿分类器。</h2><h1 id="065b" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated"><strong class="ak">一、虚拟分类器……又名基准。</strong></h1><h2 id="943b" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">让我们从基线模型开始。</h2><p id="4827" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">我使用<strong class="jo hi">最频繁</strong>策略构建了虚拟分类器，其中模型每次都采用最频繁出现的事件(即ham)并预测结果。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mx"><img src="../Images/758afa1ea57d85942c2afb1b73e68430.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*RNrD2bZ1uC-UrH4oA2NdcQ.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图9: </strong>虚拟分类器的混淆矩阵</figcaption></figure><p id="bb2a" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">请注意，测试准确率约为73%,这一数据与垃圾邮件占电子邮件总数的比例非常接近。</p><h2 id="bfb1" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">关键数据。</h2><p id="3674" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated"><strong class="jo hi">测试精度:73.06 </strong></p><h1 id="6295" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">二。朴素贝叶斯</h1><p id="502c" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">朴素贝叶斯分类器是一个简单的“概率分类器”家族，基于应用贝叶斯定理，具有特征之间的强独立性假设。有关该理论的更清晰的解释，请参考本文。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es my"><img src="../Images/0d04b82487993828c40d35bf7bc64fbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*eDsYgtQCwlQh6cory6enbg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图10: </strong>朴素贝叶斯模型分类报告</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mz"><img src="../Images/234945f31af04b8b89ac48a5f409cabc.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*oPREB8Xzd5-d2Mvn5plmSA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图11: </strong>朴素贝叶斯模型的混淆矩阵</figcaption></figure><p id="47ae" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">关于该模型的一些关键见解是，它的运行速度非常快，只有1.9秒。然而，该模型的准确性仍有待提高。我们看到，该模型有255个误报预测(预测为垃圾邮件，但实际上是垃圾邮件)，这不应该被轻视，因为如果分类不正确，用户可能会完全错过一封重要的电子邮件，并将其发送到很少检查的垃圾邮件文件夹。</p><h2 id="3466" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">关键数据。</h2><p id="f3e6" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated"><strong class="jo hi">生成模型所用时间:</strong> 1.9秒</p><p id="f982" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试精度:</strong> 82.49%</p><p id="3a9a" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">精度得分:</strong> 0.62</p><p id="5e76" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试RMSE: </strong> 0.4185</p><h1 id="60c3" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">三。逻辑回归</h1><p id="9a54" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">逻辑回归是二元分类问题的首选方法。它使用sigmoid函数，这是一条S形曲线，其值介于0和1之间。这对我们的数据来说是完美的，因为这个范围之间的数字反映了数据点被分类为垃圾邮件的概率。点击了解更多信息<a class="ae kj" href="https://machinelearningmastery.com/logistic-regression-for-machine-learning/#:~:text=Logistic%20regression%20is%20another%20technique,problems%20with%20two%20class%20values).&amp;text=The%20many%20names%20and%20terms,like%20log%20odds%20and%20logit)." rel="noopener ugc nofollow" target="_blank">。</a></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es na"><img src="../Images/f71fa50bb3f7c85ec7f3633e75703667.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*Uu01dzpdoIEa3FJED-vMrA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图12: </strong>逻辑回归模型分类报告</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mx"><img src="../Images/844e371643b1c634c0367211f44b83c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*hlO9FtH3WViVE2AHl9EGlA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图13: </strong>逻辑回归模型的混淆矩阵</figcaption></figure><p id="945b" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">逻辑回归似乎是最适合我们数据集的模型之一。该模型的测试准确率为96.13%，生成时间仅为15秒左右。我们的精度分数0.90似乎也比朴素贝叶斯高得多。</p><h2 id="e6e0" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">关键数据。</h2><p id="68dd" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated"><strong class="jo hi">生成模型所用时间:</strong> 15.07秒</p><p id="911f" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">检测准确率:</strong> 96.13%</p><p id="8b40" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">精度得分:</strong> 0.90</p><p id="447a" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试RMSE: </strong> 0.1968</p><h1 id="c758" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">四。决策图表</h1><p id="3057" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">决策树以树结构的形式建立分类或回归模型。它将一个数据集分解成越来越小的子集，与此同时，一个相关的决策树被增量开发。更多信息请参考本文。</p><h2 id="9753" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">基本估计量。</h2><p id="22ee" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">首先，我使用默认参数构建模型。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nb"><img src="../Images/9b0c77edc694d14961621ec69fc7b4e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*QMod1xscUf-6cou66zBMfQ.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图14: </strong>决策树(基础估计器)模型分类报告</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mz"><img src="../Images/22f637ef166b30c99e7a0569f34aa8df.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*Z7xjAgMwkxMq7DzQfA9o0w.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图15: </strong>决策树(基础估计器)模型的混淆矩阵</figcaption></figure><h2 id="a722" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">修剪过的树:通过阿尔法正则化。</h2><p id="5b57" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">Alpha是一种用于修剪决策树的机制。为了降低树的复杂性并避免过度拟合，我通过减少节点层来正则化基本估计器模型，这由Alpha控制。</p><div class="ix iy iz ja fd ab cb"><figure class="lr jb nc lt lu lv lw paragraph-image"><img src="../Images/07de7bb41ade499058874fa1d9e568cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:790/format:webp/1*ivv2uRJuqzfd9eoh0TDE1w.png"/></figure><figure class="lr jb nd lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><img src="../Images/3903f92b7cb563092b048f3c77a78099.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*r-5NDjKVqj-XyMFXDP9e5Q.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx ne di nf ma translated"><strong class="bd km">图16: </strong>训练集和测试集的精度与Alpha的关系<strong class="bd km">(左)</strong>。放大版确定峰值测试精度<strong class="bd km">(右)</strong>。</figcaption></figure></div><p id="0dca" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">为了确定树的精度峰值在哪里，我绘制了一个阶跃函数，表示基于给定Alpha的精度变化，范围从<em class="ki"> 1e-6 </em>到<em class="ki"> 2e-2 </em>，包括0。从图16<em class="ki">，</em>中可以明显看出，测试精度有了初步提高。放大那个区域后，我确定理想的Alpha值应该是<strong class="jo hi"> <em class="ki"> 9.04e-4 </em> </strong>。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ng"><img src="../Images/e8c23c5cd1aec330026c456525452454.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*26TyNAf5rbp7Xo2PkYYbbg.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图17: </strong>细化<strong class="bd km"> </strong>决策树模型分类报告</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mz"><img src="../Images/60274d198307199e1c6f03a921b0cbc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:744/format:webp/1*GaEj9OKP93Y6FGx2hgJ6xw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图18: </strong>细化决策树模型的混淆矩阵</figcaption></figure><p id="5ae4" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">尽管生成模型所需的时间保持不变，但改进后的模型似乎比其基本估计值更精确一些。我发现值得注意的是，由于减少了10个以上的假阳性预测，精确度分数增加了2%，这是一个非常重要的指标。无论如何，模型的准确度和精确度分数都没有打败逻辑回归。</p><h2 id="c03e" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">关键数据。</h2><p id="2c27" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated"><strong class="jo hi">生成模型所用时间:</strong> 18.25秒</p><p id="fbf4" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试准确率:</strong> 92.43%</p><p id="d5ff" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">精度得分:</strong> 0.82</p><p id="553a" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">测试RMSE:  0.2752</p><h1 id="2ecc" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">动词 （verb的缩写）随机森林</h1><p id="cc16" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">随机森林是一种用于分类的集成学习方法，它通过在训练期间构建许多决策树并输出各个树的模式类或平均预测来进行操作。除了对来自引导的数据进行采样，随机森林还对用于构建每棵树的特征进行采样。点击了解更多信息<a class="ae kj" href="https://towardsdatascience.com/understanding-random-forest-58381e0602d2" rel="noopener" target="_blank">。</a></p><h2 id="ddd8" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">基线模型。</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nh"><img src="../Images/00d64c7c534ca587ebcfc3c9bec7c7c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*4wc1uwy8sbhTTDgApt82JQ.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图19: </strong>基线随机森林模型分类报告</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mx"><img src="../Images/f16404cf75ded1c87ba13448eb74d7e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*00r-Y7NmQoSi_pZLDVgLyQ.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图20: </strong>基线随机森林模型的混淆矩阵</figcaption></figure><h2 id="68e1" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">改进的模型:用外袋评分来调整。</h2><p id="ddcb" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">为了测量我们的基线模型的预测误差，并使其规则化，我使用了<strong class="jo hi">出袋(OOB)误差</strong>。Bagging使用带替换的子采样来创建模型学习的训练样本。简单地说，OOB是在任何二次抽样中都没有选择的数据点。</p><div class="ix iy iz ja fd ab cb"><figure class="lr jb ni lt lu lv lw paragraph-image"><img src="../Images/bde8c1119f70abe8006b2e8eda56827c.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*fqwvMi3EHstBS8Dkrz5eUg.png"/></figure><figure class="lr jb nj lt lu lv lw paragraph-image"><img src="../Images/eaedc9d89e933f8af77f7d3905ee7dfa.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*wAxgcgS1FvhfUr1fLj3r8Q.png"/><figcaption class="ji jj et er es jk jl bd b be z dx nk di nl ma translated"><strong class="bd km">图21: </strong>不同取样数量的随机森林出袋误差最大特征<strong class="bd km">(左)。图22: </strong>基于树木数量的增加而变化的出袋误差率:n_estimators ϵ [10，600] <strong class="bd km">(右)</strong>。</figcaption></figure></div><p id="4a3e" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">从<em class="ki">图21 </em>，将<strong class="jo hi"> max_features </strong>设置为<strong class="jo hi">‘sqrt’</strong>选项(特征总数的平方根)将产生最低的OOB错误率。我们还可以从图22 中看到,‘sqrt’max _ features的OOB错误率在大约250 n_estimators 处开始达到平稳状态。当在进一步训练模型时考虑收益递减时，这将是一个合理的停止点。这些关键特征将用于改进我们的模型。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nh"><img src="../Images/97f27db9425c4a449908052cca78a744.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*3Rz2PYoBcvEjGYDDKig-Mw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图23: </strong>细化随机森林模型分类报告</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mx"><img src="../Images/8a254848c0c81c401138f5e22843dbf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*-yq1eHM2pU1E9EX9ZCuzng.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图24: </strong>细化随机森林模型的混淆矩阵</figcaption></figure><p id="b01d" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在优化模型后，我注意到在准确率和精度得分上有微小的改进，这两者最终都无法击败逻辑回归。除此之外，该模型的训练时间几乎增加了3倍，从仅35秒跃升至99秒。</p><h2 id="44eb" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">关键数据。</h2><p id="21c2" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated"><strong class="jo hi">生成模型所用时间:</strong> 99.62秒</p><p id="217d" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试准确率:</strong> 95.43%</p><p id="15a7" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">精度得分:</strong> 0.89</p><p id="94b6" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">测试RMSE:  0.2164</p><h1 id="2f2f" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">不及物动词XGBoost</h1><p id="35f0" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">XGBoost，极限梯度提升，在梯度提升框架下实现机器学习算法。参考<a class="ae kj" href="https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>获得完整的解释。</p><p id="ca3b" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">为了识别一封电子邮件是否是垃圾邮件，我决定使用带有逻辑回归目标<strong class="jo hi">的<strong class="jo hi"> XGB分类器</strong>作为最佳匹配。通过一系列试验，我确定理想的参数集是:最大特征的30%，学习率为0.1，Alpha为10，最大深度为10，以及159次迭代的<strong class="jo hi">n _ estimators</strong>。</strong></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ng"><img src="../Images/4936c2c6172c5ad501c5ec67d4718447.png" data-original-src="https://miro.medium.com/v2/resize:fit:936/format:webp/1*yVaoqqMjcB5GA4YvO4smkA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图25: </strong> XGBoost模型分类报告</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mx"><img src="../Images/10b39563a2590948d960966cb94b4c9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*MJLomcbf0TG91G6ZCS7Drw.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图26:</strong>XGBoost模型的混淆矩阵</figcaption></figure><h2 id="8889" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">通过K-fold交叉验证来验证模型。</h2><p id="96f4" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">XGBoost模型使用内置的<a class="ae kj" href="https://machinelearningmastery.com/k-fold-cross-validation/" rel="noopener ugc nofollow" target="_blank"> K倍交叉验证</a>进行评估，并启用早期停止。通过早期停止，XGBoost模型被正则化为159次迭代。<em class="ki">图27 </em>通过证明RMSE的训练和测试已经达到平稳状态，进一步证实了这一点。通过外推法，很明显，进一步的迭代对整体性能的改善可以忽略不计。</p><div class="ix iy iz ja fd ab cb"><figure class="lr jb nm lt lu lv lw paragraph-image"><img src="../Images/7984261f47ec231c2cf9864b840bd1e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*yVN5zUfTxgIUAL4RI31rcw.png"/></figure><figure class="lr jb nn lt lu lv lw paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><img src="../Images/9b93481a77163e9b3fbf4a7da50fe008.png" data-original-src="https://miro.medium.com/v2/resize:fit:1008/format:webp/1*_eItelvdT8sbgA9LhjH8lA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx ne di nf ma translated"><strong class="bd km">图27: </strong>随着模型迭代次数增加，变化的训练和测试意味着RMSE。</figcaption></figure></div><p id="2c47" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">令我惊讶的是，这个模型运行了相当长的时间，总计大约8分半钟。虽然它的测试准确度和精度分数超过了决策树和随机森林模型，但它仍然无法击败逻辑回归。更不用说光是训练XGBoost模型就要花费<strong class="jo hi"> 33倍的时间</strong>！</p><h2 id="7a8c" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">关键数据。</h2><p id="334d" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated"><strong class="jo hi">生成模型所用时间:</strong> 505.92秒</p><p id="c812" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试准确率:</strong> 96.07%</p><p id="44f6" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">精度得分:</strong> 0.89</p><p id="75c2" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试RMSE: </strong> 0.1983</p><h1 id="6c75" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">七。基本序列神经网络模型</h1><p id="986e" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">序列是神经网络模型的较简单形式之一。它允许我们一层一层地建立模型。每一层都有与其下一层相对应的权重。参见<a class="ae kj" href="https://towardsdatascience.com/sequence-models-and-recurrent-neural-networks-rnns-62cadeb4f1e1#:~:text=Recurrent%20Neural%20Network%20(RNN)%20is%20a%20Deep%20learning%20algorithm%20and,Natural%20Language%20Processing%20(NLP).&amp;text=In%20RNN%20loss%20function%20is,loss%20at%20each%20time%20step." rel="noopener" target="_blank">本文</a>进一步了解。</p><p id="4a06" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">我实现了一个由五层组成的序列神经网络模型。最后一层保存sigmoid激活函数，该函数在逻辑回归后建模。</p><pre class="ix iy iz ja fd no np nq nr aw ns bi"><span id="23c4" class="lc kl hh np b fi nt nu l nv nw">model = Sequential()</span><span id="8f31" class="lc kl hh np b fi nx nu l nv nw">model.add(Dense(units=20000,activation='relu'))</span><span id="fa8c" class="lc kl hh np b fi nx nu l nv nw">model.add(Dropout(0.5))</span><span id="8722" class="lc kl hh np b fi nx nu l nv nw">model.add(Dense(units=10000,activation='relu'))</span><span id="51c1" class="lc kl hh np b fi nx nu l nv nw">model.add(Dropout(0.5))</span><span id="fdbd" class="lc kl hh np b fi nx nu l nv nw">model.add(Dense(units=2500,activation='relu'))</span><span id="f4a2" class="lc kl hh np b fi nx nu l nv nw">model.add(Dropout(0.5))</span><span id="2888" class="lc kl hh np b fi nx nu l nv nw">model.add(Dense(units=1000,activation='relu'))</span><span id="a108" class="lc kl hh np b fi nx nu l nv nw">model.add(Dropout(0.5))</span><span id="7f64" class="lc kl hh np b fi nx nu l nv nw">model.add(Dense(units=1,activation='sigmoid'))</span><span id="1de6" class="lc kl hh np b fi nx nu l nv nw">model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])</span><span id="8538" class="lc kl hh np b fi nx nu l nv nw">K.set_value(model.optimizer.learning_rate, 0.0001)</span><span id="94db" class="lc kl hh np b fi nx nu l nv nw">early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)</span><span id="f020" class="lc kl hh np b fi nx nu l nv nw">history = model.fit(x=X_train,y=y_train,epochs=11,validation_data=(X_test, y_test), verbose=1,callbacks=[early_stop])</span></pre><p id="f610" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">需要注意的一些重要特性是:</p><ul class=""><li id="71df" class="mg mh hh jo b jp jq js jt jv mi jz mj kd mk kh ny mm mn mo bi translated">每层的Drop out = 0.5(防止依赖任何单个节点)</li><li id="6b2c" class="mg mh hh jo b jp mp js mq jv mr jz ms kd mt kh ny mm mn mo bi translated">损失=二元交叉熵(分类问题的理想损失函数)</li><li id="3f1a" class="mg mh hh jo b jp mp js mq jv mr jz ms kd mt kh ny mm mn mo bi translated">优化器= Adam</li><li id="b083" class="mg mh hh jo b jp mp js mq jv mr jz ms kd mt kh ny mm mn mo bi translated">学习率= 0.0001(默认学习率为训练和验证提供了相当低的准确度)</li><li id="ac2a" class="mg mh hh jo b jp mp js mq jv mr jz ms kd mt kh ny mm mn mo bi translated">纪元= 11</li><li id="282a" class="mg mh hh jo b jp mp js mq jv mr jz ms kd mt kh ny mm mn mo bi translated">启用提前停止</li></ul><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es nz"><img src="../Images/75a4d28526fed0da44b388682f8398bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/format:webp/1*LcfJPKAejSfQaDD0o_vZKA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图28: </strong>基本序贯神经网络模型分类报告</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mx"><img src="../Images/7b831eb134b13d8b1869b47592b48df7.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*tUHc98r0TbKkEfyDSzfkCQ.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图29: </strong>基本序列神经网络模型的混淆矩阵</figcaption></figure><p id="c404" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">到目前为止，这个模型在准确性方面表现最好，比逻辑回归模型高出不到一个百分点。然而，它的精度分数仍然低0.01。考虑到生成这个模型花费了多长时间(将近<strong class="jo hi">两个小时</strong>相比之下仅仅<strong class="jo hi">十五秒</strong>，用神经网络模型处理这个问题可能是不可行的。</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es oa"><img src="../Images/ee54b061cda3f60196767c1b330c9f1c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FivQ-g59IbZzmUNNrGnIjw.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图30: </strong>模型迭代的精度和损失图(对于基本的顺序神经网络)</figcaption></figure><p id="bdb5" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">迭代过程中模型的训练和验证性能图描绘了验证准确性和损失的显著波动。这说明我们模型的训练过程还是有些不稳定。</p><h2 id="ed8f" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">关键数据。</h2><p id="be6e" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated"><strong class="jo hi">生成模型所用时间:</strong> 5602.89秒</p><p id="4374" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试准确率:</strong> 96.18%</p><p id="f311" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">精度得分:</strong> 0.89</p><p id="2558" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试RMSE: </strong> 0.1953</p><h2 id="6fb6" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">既然神经网络表现最好，我们再进一步如何？</h2><h1 id="3cd7" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">八。<strong class="ak">递归神经网络(LSTM) </strong></h1><h2 id="9e3a" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">或许，单词的顺序很重要。</h2><p id="1a1d" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">所有先前模型的限制之一是单词的顺序如何不传播到训练过程。相反，每个模型完全依赖于每个单词的出现。</p><p id="fe44" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">为了解决这个问题，我引入了一种新的数据结构化方法:<strong class="jo hi">带预填充的单热点向量</strong>。</p><p id="d001" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在自然语言处理中，一个热点向量是一个1 × N矩阵，用于将词汇表中的每个单词与词汇表中的每个其他单词区分开。每个单词被分配一个特定的整数，整个邮件由一系列数字表示。</p><h2 id="9e26" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">长短期记忆(LSTM)</h2><p id="7d52" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">长短期记忆(LSTM)是一种用于深度学习领域的人工<strong class="jo hi">递归神经网络(RNN) </strong>架构。与标准的前馈神经网络不同，LSTM有反馈连接。</p><p id="8b65" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">一个普通的LSTM单元由一个<strong class="jo hi">单元</strong>、一个<strong class="jo hi">输入门</strong>、一个<strong class="jo hi">输出门</strong>和一个<strong class="jo hi">遗忘门</strong>组成。该单元记忆任意时间间隔内的值，三个<em class="ki">门</em>调节进出该单元的信息流。</p><p id="5acc" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">与传统的分类器不同，LSTM有能力学习手工制作的抽象特征，这使它们非常适合基于时间序列排序数据(如一次性向量)对预测进行分类。点击了解更多关于LSTM <a class="ae kj" href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21" rel="noopener" target="_blank">的信息。</a></p><p id="e4a8" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">下面是我实现的模型(使用与前面的神经网络模型相同的评估指标)。请注意，我指定了100个隐藏节点，以及层间0.3的丢失率。该模型的学习率比前一个模型(0.001)高一个数量级。指定了十五个纪元。</p><pre class="ix iy iz ja fd no np nq nr aw ns bi"><span id="8a0a" class="lc kl hh np b fi nt nu l nv nw">embedding_feature_vector = 40<br/>model = Sequential()<br/>model.add(Embedding(vocab_size,embedding_feature_vector,input_length=sent_length))<br/>model.add(Dropout(0.3))<br/>model.add(LSTM(100))<br/>model.add(Dropout(0.3))<br/>model.add(Dense(1,activation=’sigmoid’))</span><span id="81c1" class="lc kl hh np b fi nx nu l nv nw">model.compile(loss=’binary_crossentropy’,optimizer=’adam’,metrics=[‘accuracy’])</span><span id="41b7" class="lc kl hh np b fi nx nu l nv nw">history = model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=15, batch_size=64)</span></pre><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ob"><img src="../Images/f2707d9c30c7e11220e11f2b85883f76.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*Thq8ydb6jpZCFH1-O4CYpA.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图31: </strong> LSTM神经网络模型分类报告</figcaption></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mx"><img src="../Images/a53dd21a54939c80ea6de3ff7ce0349d.png" data-original-src="https://miro.medium.com/v2/resize:fit:746/format:webp/1*pgyeQV6lmqyIZXKerQU5rQ.png"/></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图32:</strong>LSTM神经网络模型的混淆矩阵</figcaption></figure><p id="13d2" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">令人惊讶的是，LSTM模型产生了与先前的神经网络模型相当的结果。但是，精确度分数有所提高。这是值得注意的，因为将非垃圾邮件归类为垃圾邮件的错误代价非常高。随着假阳性病例的减少，这种模式盛行。这种模式的一个局限是训练时间:七个半小时，这个数字惊人<strong class="jo hi">。</strong>(对，你没看错。<em class="ki">小时</em>！)</p><h2 id="ee60" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">从长远来看，这比逻辑回归模型长1745倍。</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es oa"><img src="../Images/abbc9cfe0ec8ca1f9040b5d77ea5b62e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qYV4ITFj-5-uUA2F2i8zYQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图33: </strong>模型迭代的精度和损失图(针对LSTM神经网络)</figcaption></figure><p id="52e1" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">将<em class="ki">图33 </em>与之前模型的<em class="ki">图30 </em>进行比较，验证损失函数大幅平滑，波动范围仅为0.1-0.15，而之前为0.1-0.35。这是支持更成功的神经网络训练程序的证据。</p><h2 id="d421" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">关键数据。</h2><p id="514a" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated"><strong class="jo hi">生成模型所用时间:</strong> 26309.92秒</p><p id="cd43" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试准确率:</strong> 96.18%</p><p id="b061" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">精度得分:</strong> 0.90</p><p id="f256" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><strong class="jo hi">测试RMSE: </strong> 0.1953</p><h1 id="1071" class="kk kl hh bd km kn ko kp kq kr ks kt ku in kv io kw iq kx ir ky it kz iu la lb bi translated">把这些放在一起。</h1><h2 id="3067" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">那么，我们如何决定哪种模式效果最好呢？</h2><p id="4b9b" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">毫无疑问，准确性是一个需要考虑的重要指标，但是它并不总是给出全部情况。</p><p id="7046" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">除了准确性之外，评估每个分类模型的一些最重要的指标是生成模型所花费的<strong class="jo hi">时间</strong>、<strong class="jo hi">测试均方根误差(RMSE) </strong>和<strong class="jo hi">精度分数</strong>。</p><p id="2f1f" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">精确度分数使用以下公式计算:</p><p id="b1e2" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated"><em class="ki">精度= TP / (TP + FP) </em></p><p id="fe31" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">对于这个特定的模型，我们希望最大化精度分数，因为将非垃圾邮件发送到垃圾邮箱对用户来说是非常昂贵的。就我个人而言，我很少检查我的垃圾邮件信箱——可能一个月最多一两次。如果一封非垃圾邮件被错误分类，普通用户可能看不到它。反过来，如果偶尔有一两封垃圾邮件出现在我们的收件箱里，成本也不会那么高。</p><p id="c4ca" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">正因为如此，我们必须更加重视降低假阳性率，因此强调精确评分。</p><h2 id="64ed" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">每个模型的摘要和关键指标。</h2><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es oc"><img src="../Images/3c564d6dcfaa7d2254b9114302b2715d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W0mHGhIhTHCM_TeG-C7Jrw.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated"><strong class="bd km">图34: </strong>带有关键指标的每个模型的摘要</figcaption></figure><p id="0070" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">最终，<strong class="jo hi">的</strong>在<strong class="jo hi">精度、</strong>和<strong class="jo hi">精度</strong>方面表现最好。但是，<strong class="jo hi">它的致命缺陷是生成模型</strong>的时间。神经网络模型有许多参数需要修改。也许，如果我们花更多的时间来微调这些参数，我们可能会得到一个更快、更准确、性能更好的模型。</p><p id="63cd" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">除了虚拟分类器和朴素贝叶斯模型，RMSE相对较低，具有可比性。我们看到，平均而言，我们预测的偏差在15–30%之内。即使两个神经网络模型在RMSE方面表现最佳，这些数字也仅略低于其他模型，这表明这一指标的改善更难实现。</p><p id="f3ce" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在构建机器学习模型时，定义一个明确的目标很重要。如果目标是实现最大潜力，那么LSTM可能是最好的解决方案。相比之下，<strong class="jo hi">逻辑回归模型可能是一个更可行的选择</strong>对于那些只是想复制一个垃圾邮件分类模型，以便在闲暇时构建的人来说。在精确度和RMSE只有轻微下降的情况下，该模型产生了相同的精确度分数，并且训练速度快得多。</p><h2 id="3a13" class="lc kl hh bd km ld le lf kq lg lh li ku jv lj lk kw jz ll lm ky kd ln lo la lp bi translated">最后一点。</h2><p id="97cb" class="pw-post-body-paragraph jm jn hh jo b jp mb ii jr js mc il ju jv md jx jy jz me kb kc kd mf kf kg kh ha bi translated">通过比较每个模型的混淆矩阵，我得出了一个有趣的观察结果，当比较假阳性和假阴性时，这个比例高得令人不安。平均而言，每个模型预测三个假阳性到一个假阴性。</p><p id="4e1f" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如前所述，我们都不介意收件箱中偶尔出现垃圾邮件，但不能冒险将重要的邮件放入我们很少查看的垃圾文件夹中。这将是有趣的看到这个项目的扩展，其中可以引入一个评分系统，给每个假阳性比假阴性更大的负权重。这将允许我们创建一个更实际的模型，更好地符合我们在现实中的偏好。</p></div></div>    
</body>
</html>