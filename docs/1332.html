<html>
<head>
<title>YOLOv4 vs YOLOv4-tiny</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLOv4 vs YOLOv4-tiny</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/yolov4-vs-yolov4-tiny-97932b6ec8ec?source=collection_archive---------1-----------------------#2021-02-24">https://medium.com/analytics-vidhya/yolov4-vs-yolov4-tiny-97932b6ec8ec?source=collection_archive---------1-----------------------#2021-02-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><figure class="hh hi ez fb hj hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es hg"><img src="../Images/7e82ccefa4125015c6780cf7cabb3290.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v_cPG9Gyy08h6sqsuqjQHw.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated"><strong class="bd hv">照片由</strong> <a class="ae hw" href="https://unsplash.com/@mitchel3uo?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> <strong class="bd hv">米切尔罗</strong> </a> <strong class="bd hv">上</strong> <a class="ae hw" href="https://unsplash.com/photos/J0p6uULLZsQ?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> <strong class="bd hv">下</strong> </a></figcaption></figure><div class=""/><div class=""><h2 id="cc29" class="pw-subtitle-paragraph iw hy hz bd b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn dx translated">用于目标检测的训练YOLO</h2></div><h1 id="b911" class="jo jp hz bd hv jq jr js jt ju jv jw jx jf jy jg jz ji ka jj kb jl kc jm kd ke bi translated">什么是YOLO？</h1><p id="6284" class="pw-post-body-paragraph kf kg hz kh b ki kj ja kk kl km jd kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi lb translated"><span class="l lc ld le bm lf lg lh li lj di">Y</span>T14代表<strong class="kh ia">Y</strong>ou<strong class="kh ia">O</strong>only<strong class="kh ia">L</strong>ook<strong class="kh ia">O</strong>nce。YOLO是一个最先进的实时物体探测系统。它是由约瑟夫·雷德蒙开发的。这是一个实时对象识别系统，可以在单个帧中识别多个对象。随着时间的推移，YOLO已经发展成更新的版本，即。、YOLOv2、YOLOv3和YOLOv4。</p><p id="0bbe" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">YOLO使用了一种完全不同于以往其他探测系统的方法。它将单个神经网络应用于整个图像。该网络将图像分成多个区域，并预测每个区域的边界框和概率。这些边界框由预测概率加权。</p><p id="248d" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">下图展示了YOLO的基本思想。YOLO将输入图像分成一个S × S网格，每个网格单元负责预测位于该网格单元中心的物体。</p><figure class="lq lr ls lt fd hk er es paragraph-image"><div class="er es lp"><img src="../Images/9a94f2d71b64f53f5e7394cdcb80d2e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*Okuwq93g3v13CShN"/></div></figure><p id="fc92" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">每个网格单元预测B边界框和这些框的置信度得分。这些置信度得分反映了模型对盒子包含对象的置信度，以及它认为盒子预测的准确性。</p><figure class="lq lr ls lt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es lu"><img src="../Images/50d16621ea7f80b81f8ca88d82afde18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IhbtJNWpPG1PgTRk"/></div></div></figure><p id="be9a" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">与基于分类器的系统相比，YOLO模型有几个优点。它可以在单个帧中识别多个对象。它在测试时查看整个图像，因此它的预测是由图像中的全局上下文提供的。它还可以通过单个网络评估进行预测，不像R-CNN这样的系统需要成千上万的单个图像。这使得它非常快，比R-CNN快1000多倍，比快速R-CNN快100倍。YOLO设计支持端到端训练和实时速度，同时保持较高的平均精度。</p><p id="98cb" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">有关完整YOLO系统的更多详细信息，请参见以下文章。</p><ul class=""><li id="9c72" class="lv lw hz kh b ki lk kl ll ko lx ks ly kw lz la ma mb mc md bi translated"><a class="ae hw" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.02640</a></li><li id="45d2" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://arxiv.org/abs/1804.02767" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1804.02767</a></li><li id="a0a5" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://arxiv.org/abs/1807.05511" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1807.05511</a></li><li id="d488" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://arxiv.org/abs/1907.09408" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1907.09408</a></li></ul></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="50e4" class="jo jp hz bd hv jq mq js jt ju mr jw jx jf ms jg jz ji mt jj kb jl mu jm kd ke bi translated">YOLOv4是什么？</h1><p id="4b12" class="pw-post-body-paragraph kf kg hz kh b ki kj ja kk kl km jd kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated"><strong class="kh ia"> YOLOv4 </strong>是一种对象检测算法，它是由<strong class="kh ia"> YOLOv3 </strong>模型演化而来。<strong class="kh ia"> YOLOv4 </strong>方法是由<strong class="kh ia"> Alexey Bochkovskiy </strong>、<strong class="kh ia">钱-王尧</strong>和<strong class="kh ia">洪元标廖</strong>创造的。在性能相当的情况下，它的速度是EfficientDet的两倍。此外，<strong class="kh ia"> YOLOv4 </strong>中的<strong class="kh ia"> AP </strong>(平均精度)和<strong class="kh ia"> FPS </strong>(每秒帧数)比<strong class="kh ia"> YOLOv3 </strong>分别增加了<strong class="kh ia"> 10% </strong>和<strong class="kh ia"> 12% </strong>。<strong class="kh ia"> YOLOv4 </strong>的架构由CSPDarknet53作为主干，空间金字塔池附加模块，PANet路径聚合颈，和<strong class="kh ia"> YOLOv3 </strong>头组成。</p><p id="fa41" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated"><strong class="kh ia"> YOLOv4 </strong>使用了许多新功能，并结合了其中的一些功能来实现最先进的结果:<strong class="kh ia">43.5% AP</strong>(<strong class="kh ia">65.7% AP50</strong>)对于<strong class="kh ia"> MS COCO </strong>数据集，在<strong class="kh ia"> Tesla V100 </strong>上的实时速度为<strong class="kh ia"> ~65 FPS </strong>。以下是<strong class="kh ia"> YOLOv4 </strong>使用的新功能:</p><ul class=""><li id="a6ca" class="lv lw hz kh b ki lk kl ll ko lx ks ly kw lz la ma mb mc md bi translated"><strong class="kh ia"><em class="mv">【WRC】</em></strong></li><li id="099a" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><strong class="kh ia"> <em class="mv">【跨阶段部分连接】</em> </strong></li><li id="97f1" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><strong class="kh ia"> <em class="mv">交叉小批量标准化</em> </strong></li><li id="c856" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><strong class="kh ia"><em class="mv">【SAT】</em></strong></li><li id="307a" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><strong class="kh ia"> <em class="mv"> Mish激活</em> </strong></li><li id="eff6" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><strong class="kh ia"> <em class="mv">镶嵌数据增强</em> </strong></li><li id="78af" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><strong class="kh ia"> <em class="mv"> DropBlock正则化</em> </strong></li><li id="7983" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><strong class="kh ia"> <em class="mv">完全交集超过并集损失(CIoU loss) </em> </strong></li></ul><figure class="lq lr ls lt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mw"><img src="../Images/4a3fb91f1a6c2463ca8edbbbb6f0df49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m2N0pah1h1fYKlkAYGlsLQ.png"/></div></div></figure></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="8a03" class="jo jp hz bd hv jq mq js jt ju mr jw jx jf ms jg jz ji mt jj kb jl mu jm kd ke bi translated">什么是YOLOv4-tiny？</h1><p id="39bd" class="pw-post-body-paragraph kf kg hz kh b ki kj ja kk kl km jd kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated"><strong class="kh ia"> YOLOv4-tiny </strong>是<strong class="kh ia"> YOLOv4的压缩版。</strong><strong class="kh ia"/>是在YOLOv4的基础上提出的，目的是使网络结构更简单，参数更少，使其在移动和嵌入式设备上开发变得可行。</p><p id="816f" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">我们可以使用YOLOv4-tiny进行更快的训练和更快的检测。它只有两个YOLO头，而不是YOLOv4中的三个，并且它已经从29个预训练的卷积层中<strong class="kh ia"/><strong class="kh ia"/>训练，而不是YOLOv4已经从137个预训练的卷积层中训练。</p><p id="8445" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">YOLOv4-tiny中的<strong class="kh ia"> FPS </strong>(每秒帧数)大约是YOLOv4的八倍。然而，在MS COCO数据集上测试时，YOLOv4-tiny的<strong class="kh ia">精度</strong>是YOLOv4的2/3。</p><p id="fcd5" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">YOLOv4-tiny模型在RTX 2080Ti上以443 FPS的速度实现了<strong class="kh ia"> 22.0% AP (42.0% AP50) </strong>，而通过使用TensorRT，batch size = 4和FP16-precision，YOLOv4-tiny实现了1774 FPS。</p><p id="dac6" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">对于<strong class="kh ia">实时对象检测</strong>，<strong class="kh ia"> YOLOv4-tiny </strong>与<strong class="kh ia"> YOLOv4 </strong>相比是更好的选择，因为在使用实时对象检测环境时，更快的推理时间比精度或准确度更重要。</p><figure class="lq lr ls lt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es mx"><img src="../Images/844570ccc0137b790623c14747fcf9df.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h3TR3znA4zQST8wOy1PFEw.png"/></div></div></figure></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="28a1" class="jo jp hz bd hv jq mq js jt ju mr jw jx jf ms jg jz ji mt jj kb jl mu jm kd ke bi translated"><strong class="ak"> YOLOv4定制物体检测器vs yolov 4-微型定制物体检测器</strong></h1><h2 id="007e" class="my jp hz bd hv mz na nb jt nc nd ne jx ko nf ng jz ks nh ni kb kw nj nk kd nl bi translated">面罩检测</h2><figure class="lq lr ls lt fd hk er es paragraph-image"><div class="er es lp"><img src="../Images/3720218957609fd98aa448a11873eeef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*t3yKIfrDfd7AsYE4qDBx8w.gif"/></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">来自<a class="ae hw" href="https://www.pexels.com/photo/a-teacher-and-his-students-wearing-a-face-mask-while-looking-at-the-camera-5199637/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae hw" href="https://www.pexels.com/@max-fischer?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Max Fischer </a>的原始视频</figcaption></figure><p id="f0f9" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">我在相同的1500图像掩模数据集上训练了<strong class="kh ia"> YOLOv4 </strong>和<strong class="kh ia"> YOLOv4-tiny </strong>检测器，其中<strong class="kh ia"> YOLOv4 </strong>平均损耗在6000次迭代后达到约0.68，而<strong class="kh ia"> YOLOv4-tiny </strong>平均损耗在6000次迭代后达到约0.15。</p><blockquote class="nm nn no"><p id="22cc" class="kf kg mv kh b ki lk ja kk kl ll jd kn np lm kq kr nq ln ku kv nr lo ky kz la hb bi translated">对于一个好的探测器模型，平均损耗应该在0.05到0.3之间。</p></blockquote><figure class="lq lr ls lt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es ns"><img src="../Images/e9cb7cc24278de8d34187fd41c2a39a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nBRbhW-Q9_LCbRfFTSyIag.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">约洛夫4号..……………………………………………..<strong class="bd hv"> YOLOv4-tiny </strong></figcaption></figure></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="83fa" class="jo jp hz bd hv jq mq js jt ju mr jw jx jf ms jg jz ji mt jj kb jl mu jm kd ke bi translated">测试经过培训的定制检测器</h1><p id="8059" class="pw-post-body-paragraph kf kg hz kh b ki kj ja kk kl km jd kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">当使用网络摄像头进行实时对象检测测试时，YOLOv4-tiny比YOLOv4更好，因为它的推理时间快得多。然而，当在图像和视频上测试时，YOLOv4比YOLOv4-tiny更有效。</p><h1 id="680c" class="jo jp hz bd hv jq jr js jt ju jv jw jx jf jy jg jz ji ka jj kb jl kc jm kd ke bi translated">在图像上测试探测器</h1><p id="e762" class="pw-post-body-paragraph kf kg hz kh b ki kj ja kk kl km jd kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">我在相同的图像上运行了两个训练过的探测器。在下面并排看到它们的输出，左边是<strong class="kh ia">yolov 4-tiny</strong>T32】预测图像，右边是<strong class="kh ia">yolov 4</strong>T36】预测图像。</p><h2 id="a4d8" class="my jp hz bd hv mz na nb jt nc nd ne jx ko nf ng jz ks nh ni kb kw nj nk kd nl bi translated">yolov 4-tiny ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ yolov 4</h2><figure class="lq lr ls lt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nt"><img src="../Images/ac5caa84b7068f218506a08dc99e550a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JPRCahpezpJzxBU9P-1SZA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">原始照片由<a class="ae hw" href="https://www.pexels.com/@life-matters-3043471?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">生活要紧</a>发自<a class="ae hw" href="https://www.pexels.com/photo/crowd-of-protesters-holding-signs-4614165/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a></figcaption></figure><figure class="lq lr ls lt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nu"><img src="../Images/d2dc33802a8909711af9b2320237f8a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KjeljdXp4_qxtl9VmWMGZA.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">由<a class="ae hw" href="https://www.pexels.com/@life-matters-3043471?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank">拍摄的原始照片</a>来自<a class="ae hw" href="https://www.pexels.com/photo/women-holding-signs-in-protest-4613917/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a></figcaption></figure><figure class="lq lr ls lt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nv"><img src="../Images/1957710b45e03c620dc63d3bd708537f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*F8mqoyxyH-LsbFzx7IgDHg.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">来自<a class="ae hw" href="https://www.pexels.com/photo/women-holding-signs-in-protest-4613917/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae hw" href="https://www.pexels.com/@life-matters-3043471?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Life Matters </a>原图</figcaption></figure><figure class="lq lr ls lt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nw"><img src="../Images/57915ae1c5e5e8dfccbca788d3d0cbc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2XBFSlnYRmIUYBm0UwiE6Q.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">来自<a class="ae hw" href="https://www.pexels.com/photo/group-of-people-with-masks-protesting-on-street-5382987/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae hw" href="https://www.pexels.com/@brett-sayles?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Brett Sayles </a>的原始照片</figcaption></figure><figure class="lq lr ls lt fd hk er es paragraph-image"><div role="button" tabindex="0" class="hl hm di hn bf ho"><div class="er es nx"><img src="../Images/51fe11b80ef20bad74266ea7308e9cd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m4E2QfUD64Bnk5jGdu9X4A.png"/></div></div><figcaption class="hr hs et er es ht hu bd b be z dx translated">来自<a class="ae hw" href="https://www.pexels.com/photo/group-of-protesting-people-standing-on-street-5408003/?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Pexels </a>的<a class="ae hw" href="https://www.pexels.com/@brett-sayles?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels" rel="noopener ugc nofollow" target="_blank"> Brett Sayles </a>的原始照片</figcaption></figure><h1 id="21d3" class="jo jp hz bd hv jq jr js jt ju jv jw jx jf jy jg jz ji ka jj kb jl kc jm kd ke bi translated">在视频上测试探测器</h1><p id="6d75" class="pw-post-body-paragraph kf kg hz kh b ki kj ja kk kl km jd kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">我还在相同的视频上运行了两个探测器。你可以在下面看到他们的视频对比。</p><figure class="lq lr ls lt fd hk"><div class="bz dy l di"><div class="ny nz l"/></div></figure></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="b323" class="jo jp hz bd hv jq mq js jt ju mr jw jx jf ms jg jz ji mt jj kb jl mu jm kd ke bi translated">我的自定义掩膜数据集</h1><p id="77ad" class="pw-post-body-paragraph kf kg hz kh b ki kj ja kk kl km jd kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">我在下面的链接中分享了我的标注掩膜数据集。这是一个相对较小的数据集，但它将为您如何使用YOLO训练您自己的自定义检测器模型提供一个良好的开端。您可以找到具有更高质量图像的更大数据集，并在以后自己标记它们。</p><p id="5951" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated"><a class="ae hw" href="https://www.kaggle.com/techzizou/labeled-mask-dataset-yolo-darknet" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/techzizou/labelled-mask-dataset-yolo-darknet</a></p><p id="e73c" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated"><strong class="kh ia"> <em class="mv"> obj.zip </em> </strong>文件包含1510张图像以及它们的YOLO格式标签文本文件。我已经标记了大约1350张，并从Roboflow下载了149张带标签的图片。</p><p id="8016" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated"><strong class="kh ia">注意:</strong>这个数据集大部分是特写图像(1300左右)，很少是远景图像(200左右)。如果你想下载更多的长镜头图像，你可以在网上搜索数据集。有很多网站可以找到更多的数据集。我在底部的<a class="ae hw" href="https://medium.com/p/97932b6ec8ec/edit#e5ee" rel="noopener">数据集来源</a>下给出了几个链接。您还可以将自己的图像及其YOLO格式的标签文本文件添加到数据集中。</p><p id="ec84" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">由于我的数据集大部分都是特写图像，所以对图像和视频中特写的检测非常好。另一方面，只有200个远景图像给了我们远景检测的平均性能。</p><p id="14f9" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">这表明收集数据集并正确标记它们的过程是多么重要。永远记住这条规则:- <strong class="kh ia">垃圾入=垃圾出</strong>。选择和标记图像是最重要的部分。尽量找质量好的图片。数据的质量在很大程度上决定了结果的质量。</p></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="9507" class="jo jp hz bd hv jq mq js jt ju mr jw jx jf ms jg jz ji mt jj kb jl mu jm kd ke bi translated">查看以下媒体文章，了解如何使用<strong class="ak">yolov 4</strong>T28】Y<strong class="ak">olo v4-tiny</strong>训练您的自定义对象检测器</h1><h2 id="371a" class="my jp hz bd hv mz na nb jt nc nd ne jx ko nf ng jz ks nh ni kb kw nj nk kd nl bi translated">自定义YOLOv4培训教程</h2><div class="hh hi ez fb hj oa"><a rel="noopener follow" target="_blank" href="/@techzizou007/training-a-custom-detector-for-mask-detection-using-yolov4-darknet-using-google-colab-61a659d4868"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ia fi z dy of ea eb og ed ef hy bi translated">中等</h2><div class="oh l"><p class="bd b fp z dy of ea eb og ed ef dx translated">训练YOLOv4自定义对象检测器(使用Google Colab)</p></div></div></div></a></div><p id="5d2c" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated"><strong class="kh ia">定制YOLOv4-tiny训练教程</strong></p><div class="hh hi ez fb hj oa"><a rel="noopener follow" target="_blank" href="/@techzizou007/training-a-custom-detector-for-mask-detection-using-yolov4-tiny-darknet-using-google-colab-b58be08c9593"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ia fi z dy of ea eb og ed ef hy bi translated">中等</h2><div class="oh l"><p class="bd b fp z dy of ea eb og ed ef dx translated">训练一个yolov 4-微型自定义对象检测器(使用Google Colab)</p></div></div></div></a></div></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="870b" class="jo jp hz bd hv jq mq js jt ju mr jw jx jf ms jg jz ji mt jj kb jl mu jm kd ke bi translated">如果你觉得这篇文章有帮助，请订阅我的YouTube频道或考虑在帕特里翁/ BuyMeACoffee🖖上支持我</h1><div class="hh hi ez fb hj oa"><a href="https://www.buymeacoffee.com/techzizou" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ia fi z dy of ea eb og ed ef hy bi translated">给我买杯咖啡！</h2><div class="oi l"><h3 class="bd b fi z dy of ea eb og ed ef dx translated">嘿，👋我正在创建技术博客和视频。你现在可以给我买杯咖啡来支持我的频道了！</h3></div><div class="oh l"><p class="bd b fp z dy of ea eb og ed ef dx translated">www.buymeacoffee.com/techzizou</p></div></div></div></a></div><div class="hh hi ez fb hj oa"><a href="https://www.patreon.com/techzizou" rel="noopener  ugc nofollow" target="_blank"><div class="ob ab dw"><div class="oc ab od cl cj oe"><h2 class="bd ia fi z dy of ea eb og ed ef hy bi translated">订阅模式</h2><div class="oi l"><h3 class="bd b fi z dy of ea eb og ed ef dx translated">Patreon正在为新一代创作者赋能。支持和参与艺术家和创作者，因为他们活出自己的…</h3></div><div class="oh l"><p class="bd b fp z dy of ea eb og ed ef dx translated">www.patreon.com/techzizou</p></div></div></div></a></div></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h1 id="1d2f" class="jo jp hz bd hv jq mq js jt ju mr jw jx jf ms jg jz ji mt jj kb jl mu jm kd ke bi translated">信用</h1><h2 id="46cc" class="my jp hz bd hv mz na nb jt nc nd ne jx ko nf ng jz ks nh ni kb kw nj nk kd nl bi translated">参考</h2><ul class=""><li id="d2c4" class="lv lw hz kh b ki kj kl km ko oj ks ok kw ol la ma mb mc md bi translated"><a class="ae hw" href="https://github.com/pjreddie/darknet" rel="noopener ugc nofollow" target="_blank"> pjreddie Github </a></li><li id="037f" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://pjreddie.com/darknet/yolo/" rel="noopener ugc nofollow" target="_blank"> pjreddie站点</a></li><li id="0455" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">阿列克谢·阿布·吉图布</li><li id="4026" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.02640</a></li><li id="68e8" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://arxiv.org/abs/1804.02767" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1804.02767</a></li><li id="d349" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://arxiv.org/abs/1807.05511" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1807.05511</a></li><li id="cbfb" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://arxiv.org/abs/1907.09408" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1907.09408</a></li><li id="f55b" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">https://arxiv.org/abs/2004.10934<a class="ae hw" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank"/></li><li id="311e" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">【https://arxiv.org/abs/2011.08036 T4】</li></ul><h2 id="e5ee" class="my jp hz bd hv mz na nb jt nc nd ne jx ko nf ng jz ks nh ni kb kw nj nk kd nl bi translated">数据集源</h2><p id="a144" class="pw-post-body-paragraph kf kg hz kh b ki kj ja kk kl km jd kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">您可以从下面提到的网站下载许多对象的数据集。这些网站还包含许多种类的对象的图像以及它们的多种格式的注释/标签，例如YOLO _黑暗网文本文件和帕斯卡_VOC xml文件。</p><ul class=""><li id="acf6" class="lv lw hz kh b ki lk kl ll ko lx ks ly kw lz la ma mb mc md bi translated"><a class="ae hw" href="https://storage.googleapis.com/openimages/web/index.html\" rel="noopener ugc nofollow" target="_blank">通过谷歌打开图像数据集</a></li><li id="3fb3" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://www.kaggle.com/datasets" rel="noopener ugc nofollow" target="_blank"> Kaggle数据集</a></li><li id="f511" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://public.roboflow.com/" rel="noopener ugc nofollow" target="_blank"> Roboflow公共数据集</a></li><li id="0d23" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://www.visualdata.io/discovery" rel="noopener ugc nofollow" target="_blank">可视化数据数据集</a></li></ul><h2 id="9c7e" class="my jp hz bd hv mz na nb jt nc nd ne jx ko nf ng jz ks nh ni kb kw nj nk kd nl bi translated">屏蔽数据集源</h2><p id="3d2e" class="pw-post-body-paragraph kf kg hz kh b ki kj ja kk kl km jd kn ko kp kq kr ks kt ku kv kw kx ky kz la hb bi translated">我将这3个数据集用于我的标记数据集:</p><ul class=""><li id="af9e" class="lv lw hz kh b ki lk kl ll ko lx ks ly kw lz la ma mb mc md bi translated"><a class="ae hw" href="https://github.com/prajnasb/observations" rel="noopener ugc nofollow" target="_blank">般若Github </a></li><li id="dbe0" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated">约瑟夫·纳尔逊·罗博弗洛</li><li id="3102" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset" rel="noopener ugc nofollow" target="_blank">X-张洋Github </a></li></ul><p id="36bf" class="pw-post-body-paragraph kf kg hz kh b ki lk ja kk kl ll jd kn ko lm kq kr ks ln ku kv kw lo ky kz la hb bi translated">更多掩膜数据集</p><ul class=""><li id="892d" class="lv lw hz kh b ki lk kl ll ko lx ks ly kw lz la ma mb mc md bi translated">Prasoonkottarathil ka ggle(20000张图片)</li><li id="358d" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://www.kaggle.com/ashishjangra27/face-mask-12k-images-dataset?select=Face+Mask+Dataset" rel="noopener ugc nofollow" target="_blank">ashishjangra 27 ka ggle</a>(12000张图片)</li><li id="431c" class="lv lw hz kh b ki me kl mf ko mg ks mh kw mi la ma mb mc md bi translated"><a class="ae hw" href="https://www.kaggle.com/andrewmvd/face-mask-detection" rel="noopener ugc nofollow" target="_blank">安德鲁·默德·卡格尔</a></li></ul><h2 id="066d" class="my jp hz bd hv mz na nb jt nc nd ne jx ko nf ng jz ks nh ni kb kw nj nk kd nl bi translated">视频源</h2><ul class=""><li id="e7e3" class="lv lw hz kh b ki kj kl km ko oj ks ok kw ol la ma mb mc md bi translated"><a class="ae hw" href="https://www.pexels.com/" rel="noopener ugc nofollow" target="_blank">https://www.pexels.com/</a></li></ul></div><div class="ab cl mj mk gp ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hb hc hd he hf"><h2 id="011a" class="my jp hz bd hv mz na nb jt nc nd ne jx ko nf ng jz ks nh ni kb kw nj nk kd nl bi translated">别忘了留下👏</h2><h2 id="0d55" class="my jp hz bd hv mz na nb jt nc nd ne jx ko nf ng jz ks nh ni kb kw nj nk kd nl bi translated">祝您愉快！！！✌</h2><h2 id="96f4" class="my jp hz bd hv mz na nb jt nc nd ne jx ko nf ng jz ks nh ni kb kw nj nk kd nl bi translated">♕·特奇佐·♕</h2></div></div>    
</body>
</html>