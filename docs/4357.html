<html>
<head>
<title>Simple Concept of Apache Kafka</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">阿帕奇卡夫卡的简单概念</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-apache-kafka-841c1238d5b6?source=collection_archive---------1-----------------------#2021-09-28">https://medium.com/analytics-vidhya/introduction-to-apache-kafka-841c1238d5b6?source=collection_archive---------1-----------------------#2021-09-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es hf"><img src="../Images/6e66a806b8aa7f7cfcc210c66e2d1b08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aE3FWQSpipw-L7jkK9oW0Q.jpeg"/></div></div></figure><div class=""/><h1 id="7cc6" class="ip iq hs bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">介绍</h1><p id="5277" class="pw-post-body-paragraph jn jo hs jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">Apache Kafka是一个开源的分布式<strong class="jp ht">事件流</strong>平台，被数千家公司用于高性能数据管道、流分析、数据集成和关键任务应用。<strong class="jp ht">事件流</strong>是从数据库、传感器、移动设备、云服务和软件应用程序等事件源实时捕获数据的实践</p><p id="b94a" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp ht">卡夫卡的特点</strong>是:<br/>它是一个分布式、分区的消息传递系统。<br/>·高度容错。<br/>高度可扩展。它可以每秒钟处理和发送数百万条信息给几个接收者。</p><p id="e231" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">Kafka可用于<strong class="jp ht">组织中的各种用途</strong>，例如:<br/><strong class="jp ht">消息服务，</strong> Kafka可用于实时发送和接收数百万条消息。<br/><strong class="jp ht">实时流处理</strong>，Kafka可用于实时处理连续的信息流，并将其传递给Storm等流处理系统。<br/><strong class="jp ht"/>日志聚合，Kafka可以用来从多个系统收集物理日志文件，并将它们存储在一个中心位置，比如HDFS。<br/><strong class="jp ht">提交日志服务</strong>，Kafka可以作为分布式系统的外部提交日志。<br/><strong class="jp ht">事件源</strong>，Kafka可以用来维护事件的时间顺序。<br/><strong class="jp ht">网站活动跟踪</strong>，Kafka可用于处理实时网站活动，如页面浏览、搜索或用户可能采取的其他行动。</p><h1 id="bad1" class="ip iq hs bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">使用阿帕奇卡夫卡前后的区别</h1><p id="fc6a" class="pw-post-body-paragraph jn jo hs jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">我们为什么不用通常的方法呢？现在我们将模拟我们的应用程序如何不使用Apache Kafka。</p><p id="d77b" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp ht">在</strong>之前</p><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kq"><img src="../Images/aaeb7d41b285c33376f86ae4c36fa819.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0JCaHKHv6amcjqsQnpeomA.png"/></div></div></figure><p id="8823" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">例如，我们有几个类似上面的应用程序，如果我们在ERP应用程序需要订单数据时不使用发布-订阅，那么我们必须将数据发送到ERP，然后应用程序成员将数据发送到ERP，每个处理的数据都需要一个请求。用这种方法，当你的app比较多的时候，比如100个app，效率不高，数据事务图会比较复杂，一个app崩溃，另一个app也会崩溃。因此，需要另一种方法。</p><p id="9cf5" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp ht">在</strong>之后</p><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kq"><img src="../Images/4e8b9f71f34c364b4d5aa8c795ce4d13.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-Mkp9WadEj_4ZPdSqli8nw.png"/></div></div></figure><p id="3d90" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">使用Apache Kafka后，通过按摩经纪人发送和接收数据的过程，如果其中一个app出现错误，也不会破坏现有的流量。上述过程将使用<strong class="jp ht">发布</strong>和<strong class="jp ht">订阅</strong>，发布/订阅通过消息代理实时自动传输数据。通过使用这种方法，我们不需要从特定的应用程序请求所需的数据，该过程将自动完成。Apache Kafka也是一个<strong class="jp ht">消息代理</strong>应用程序。还有其他几个按摩经纪人应用程序，但最流行的按摩经纪人应用程序是Apache Kafka。</p><h1 id="b26f" class="ip iq hs bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">发布者和订阅者</h1><p id="6194" class="pw-post-body-paragraph jn jo hs jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">Apache Kafka是一个可以用来处理发布和订阅的应用程序。Apache Kafka也是一个消息代理应用程序。</p><p id="0ba8" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp ht">发布</strong> =发送数据<br/> <strong class="jp ht">订阅</strong> =接收数据</p><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kv"><img src="../Images/f3e043bad58f9b44a1c906941cb8b1fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2JH3YLomHXep6FlU5MSysg.png"/></div></div></figure><p id="7ed3" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">通过使用发布/订阅，所有发布者应用程序将向主题发送数据(<strong class="jp ht">主题</strong>是一个<strong class="jp ht">表</strong>，如果它在数据库中被类推的话)，然后所有订阅者将听到数据(数据检索的术语是<strong class="jp ht">侦听，</strong>因此每个传入的数据将被所有订阅者立即接收)。这个过程将由message broker应用程序维护。</p><p id="6769" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">一个<strong class="jp ht"> <em class="kw">主题</em> </strong>是卡夫卡中的一个信息范畴。Kafka中的数据将存储在一个主题中。</p><p id="deb8" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp ht">卡夫卡:主题—数据库:表格</strong></p><p id="f174" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">apache Kafka上的数据无法更改。在Kafka中，主题数据不能处理更新，概念上Kafka发送事件或日志。</p><h1 id="14cb" class="ip iq hs bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">卡夫卡建筑</h1><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kv"><img src="../Images/9666acd2434c8189460a3ea1e1071489.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*10FxhE7k7B4J-wagGsRybQ.png"/></div></div></figure><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kx"><img src="../Images/d08b8fdbd58e67b24b3eba8472f9e7ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WzHWHmnEMjaqa-rrP9XU7A.png"/></div></div></figure><ul class=""><li id="d1e5" class="ky kz hs jp b jq kl ju km jy la kc lb kg lc kk ld le lf lg bi translated"><strong class="jp ht"/><strong class="jp ht">Streams API</strong>允许将数据流从输入主题转换为输出主题。</li><li id="e6ff" class="ky kz hs jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><strong class="jp ht">Connect API</strong>允许将数据从某个源系统摄取到Kafka，或者从Kafka推入某个接收系统。</li><li id="30f8" class="ky kz hs jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><strong class="jp ht"/><strong class="jp ht">生产者API </strong>允许应用程序向Kafka集群中的主题发送数据流。</li><li id="d400" class="ky kz hs jp b jq lh ju li jy lj kc lk kg ll kk ld le lf lg bi translated"><strong class="jp ht"/><strong class="jp ht">消费者API </strong>允许应用程序从Kafka集群中的主题读取数据流。</li></ul><p id="fc12" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">应用程序可以同时充当生产者和消费者。</p><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kv"><img src="../Images/b6b7ac99f4b3831aaa61c4d66f7e3f2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*geoJBq8HwuBO9yoBlLVxUw.png"/></div></div></figure><p id="1e22" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">卡夫卡不能处理自己的集群，因此需要一个动物园管理员来管理卡夫卡。Kafka上的所有管理都将在zookeeper中完成，但数据将存储在apache Kafka中。</p><h1 id="f593" class="ip iq hs bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">划分</h1><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kv"><img src="../Images/2f43273f0b6ab53e99d8c52e99e54fab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3-XSweUVobS5d7pjtr4TGw.png"/></div></div></figure><p id="c25f" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">主题分为分区，分区是卡夫卡中的排比单位。分区可以分布在Kafka集群中。<br/>在创建一个我们可以确定的主题时，我们可以确定我们想要多少个分区。为什么要使用分区？这是因为一个分区只能被一个应用程序订阅</p><p id="5bc6" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp ht"> 1个分区— 1个应用</strong></p><p id="234f" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">当使用apache Kafka时，建议分区数量大于创建的应用程序数量。</p><p id="8ba3" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">每个Kafka服务器可以处理一个或多个分区。<br/>一个分区可以跨多个服务器复制，以实现容错。<br/>一台服务器被标记为分区的领导者，其他服务器被标记为追随者。<br/>领导者控制分区的读写，而从者复制数据。<br/>如果一个领导者失败，其中一个追随者会自动成为领导者。<br/>·ZooKeeper用于首领选择。</p><figure class="kr ks kt ku fd hj er es paragraph-image"><div class="er es lm"><img src="../Images/89aedf8911962df2813ed4525314589a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*f1Jf0aQhvB3WmAiYtLE9wA.png"/></div></figure><p id="b85c" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">0到12称为日志，数据会不断增加，会形成历史，比如我们把数据加到log 0上，值为“1”，然后在log 1上，值为“1”。复制对该方法没有影响。</p><figure class="kr ks kt ku fd hj er es paragraph-image"><div class="er es ln"><img src="../Images/29b2ccc43eb500bdb415335f57996617.png" data-original-src="https://miro.medium.com/v2/resize:fit:916/format:webp/1*vJxy4lOpRh-PvldN0TTPAQ.png"/></div></figure><p id="9c68" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">上面是一个例子，我们有2个消费者，在消费者A中，消费的数据是第9个字(偏移量9)，对于消费者B，消费的是第11个数据(偏移量11)。偏移函数是数据分布的标志。比如消费者A消费数据1，2，3然后app死亡，那么当app重启时app就不需要再从头消费数据了，可以立即继续消费4，5，6等。分区和偏移量是由Kafka自动设置的，所以不需要担心这个问题。</p><h1 id="edba" class="ip iq hs bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">复制</h1><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kx"><img src="../Images/f438ce9fb93f32caf1bbdffcabafc6b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PnByc6-sEp3q9iOXxClUeA.png"/></div></div></figure><p id="4976" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在上面的示例中，有3个Kafka服务器，复制用R表示，分区用p表示。对于分区创建和复制，将由apache Kafka管理。在分区放置和复制中，1个服务器不能有相同的1个分区和1个复制。<br/>所以不可能<br/> S = P &lt; A &gt;，R&lt;A&gt;T9】举个例子:<br/>服务器1 = P1 <br/>服务器2 = P2，R1 <br/>服务器3 = R2</p><h1 id="7f5f" class="ip iq hs bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">消费者群体</h1><p id="fb2f" class="pw-post-body-paragraph jn jo hs jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">在Apache Kafka中，有一个所谓的消费者组，消费者组是应用程序的集合，其中一个消费者组只能访问一个分区。</p><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kx"><img src="../Images/9ac4fd731193b7f82c489b0e4a235faf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UMBhFh8Wh5c5u6_52zqFSQ.png"/></div></div></figure><p id="e33d" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在上图中，当有2个类似的应用程序时，应用程序上会有重复的数据，因为每个应用程序都消耗2个分区的数据。因此，我们使用客户群来解决这个问题。</p><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es kv"><img src="../Images/9fcd1db372416ddcbf5208dde3ec5962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hsW4tvdS-0QQGBh9SNWkMg.png"/></div></div></figure><p id="7110" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在上面的例子中，一个用户组只能访问一个分区。不能再多了，因此当你创建一个分区时，分区必须大于一个消费者组中的应用数量。</p><p id="b525" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp ht">分区数量&gt; =应用数量</strong></p><figure class="kr ks kt ku fd hj er es paragraph-image"><div role="button" tabindex="0" class="hk hl di hm bf hn"><div class="er es lo"><img src="../Images/7186604e86509cd1cd8aee6bb46b28b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ntl9le11Dcr8fZz9C5l19g.png"/></div></div></figure><p id="8c39" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">上面的例子是一个错误的例子，因为app的数量大于分区的数量。</p><h1 id="bb29" class="ip iq hs bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">自留责任保险</h1><p id="04b8" class="pw-post-body-paragraph jn jo hs jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">我们知道，在Kafka中，数据是不可更改的，因此它需要自动删除不时持续增长的数据。在apache Kafka中有两种方法可以擦除数据:</p><ol class=""><li id="b246" class="ky kz hs jp b jq kl ju km jy la kc lb kg lc kk lp le lf lg bi translated"><strong class="jp ht">日志保留时间<br/> </strong>日志保留时间是基于时间的数据删除，例如当数据是7天前的数据时，该数据将被自动删除(在Kafka中，默认的日志保留时间是7天)。</li><li id="009f" class="ky kz hs jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated"><strong class="jp ht">日志保留字节<br/> </strong>日志保留字节是基于数据量的数据删除。例如，当我们有1千兆字节，旧的数据将被删除。</li><li id="a55b" class="ky kz hs jp b jq lh ju li jy lj kc lk kg ll kk lp le lf lg bi translated"><strong class="jp ht">偏移保留时间<br/> </strong>偏移保留时间是偏移数据在Kafka中存储的时间。偏移数据是apache Kafka在应该使用Kafka数据的应用程序不活动时存储的数据。举个例子:当有1个不活跃的app时，那么数据会存储在apache Kafka中。如果应用程序长时间不活动，存储在apache Kafka中的数据会增加。因此，需要偏移保留时间来删除数据。(默认偏移保留时间为7天)</li></ol><p id="96e0" class="pw-post-body-paragraph jn jo hs jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">感谢您阅读这篇文章。希望这篇文章能对数据开发有所帮助。别忘了跟着并给予很多掌声。下次见</p><h2 id="1f65" class="lq iq hs bd ir lr ls lt iv lu lv lw iz jy lx ly jd kc lz ma jh kg mb mc jl md bi translated">来源:</h2><p id="db37" class="pw-post-body-paragraph jn jo hs jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated"><a class="ae me" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank">https://kafka.apache.org/</a><br/><a class="ae me" href="https://www.youtube.com/watch?v=SArQUV0CE2I&amp;list=PL-CtdCApEFH8dJMuQGojbjUdLEty8mqYF" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=SArQUV0CE2I&amp;list = PL-ctdcapefh 8 djmuqgojbjudlety 8 mqyf</a><br/><a class="ae me" href="https://lms.simplilearn.com/courses/2810/Big-Data-Hadoop-and-Spark-Developer/syllabus" rel="noopener ugc nofollow" target="_blank">https://LMS . simpli learn . com/courses/2810/Big-Data-Hadoop-and-Spark-Developer/Sylvia</a></p></div></div>    
</body>
</html>