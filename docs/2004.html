<html>
<head>
<title>From Keras to PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从喀拉斯到皮托尔彻</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/from-keras-to-pytorch-722fa3b65cce?source=collection_archive---------6-----------------------#2021-03-31">https://medium.com/analytics-vidhya/from-keras-to-pytorch-722fa3b65cce?source=collection_archive---------6-----------------------#2021-03-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="c04b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以。出于某种原因，您必须将您的完美的Keras模型转换为PyTorch。也许你想尝试一个新的框架，也许这是一份工作的要求(因为Keras在大多数招聘信息中已经失宠)，也许这实际上是你现在的工作任务。</p><p id="5ad6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当我有同样的目标时，我读过几本PyTorch指南，但它们看起来都有点复杂，我看不出PyTorch和Keras代码之间有什么相似之处:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/0520897f7c034ae0efd0f6e9c4b851fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Q1KEvdS4ZVyBwAPO41EaXw.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">两个框架中的简单CNN。</figcaption></figure><p id="26d0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里没有简单的一行程序和常见的<code class="du jt ju jv jw b">.fit</code>和<code class="du jt ju jv jw b">.predict</code>方法，而是有几个非常冗长的循环。同样，在PyTorch中，你<em class="jx">继承自类</em>。如果你主要在Jupyter笔记本上工作，你很可能不知道那是什么意思，因为通常它不是必要的。</p><p id="9fc0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我花了相当多的时间试图破译PyTorch发生了什么，通过这篇文章，我想帮助其他人跳过这一阶段。请注意，我不会深究<em class="jx">为什么</em>有些事情是这样做的，而另一些不是。相反，我专注于用最少的努力编写工作代码的过程。记住这一点，我将向您展示如何用PyTorch重写Keras代码。一旦你有了一个非常基本的工作模型，你就可以堆叠更多的层，添加扩展等等。但是现在，让我们让它工作。</p></div><div class="ab cl jy jz gp ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="hb hc hd he hf"><p id="0b9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于这项任务，我们将使用MNIST数据集和来自<a class="ae kf" href="https://keras.io/examples/vision/mnist_convnet/" rel="noopener ugc nofollow" target="_blank"> Keras MNIST示例</a>的代码。就像那个例子一样，我们将经历编写ML代码的一般步骤:</p><ul class=""><li id="acfe" class="kg kh hi ih b ii ij im in iq ki iu kj iy kk jc kl km kn ko bi translated">进口</li><li id="0f93" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">数据加载和准备</li><li id="e167" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">模型描述</li><li id="6aec" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated">模型训练和评估</li></ul><p id="0735" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于每一步，我将向您展示相应的PyTorch代码，并解释其中一些复杂的部分。</p><h1 id="4bed" class="ku kv hi bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">进口</h1><p id="f4ec" class="pw-post-body-paragraph if ig hi ih b ii ls ik il im lt io ip iq lu is it iu lv iw ix iy lw ja jb jc hb bi translated">Keras:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="a2ce" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PyTorch:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="7f3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止没什么令人惊讶的。</p><h1 id="7d5d" class="ku kv hi bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">数据加载和准备</h1><p id="9722" class="pw-post-body-paragraph if ig hi ih b ii ls ik il im lt io ip iq lu is it iu lv iw ix iy lw ja jb jc hb bi translated">Keras:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="84ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PyTorch:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="080b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们已经从Keras加载了相同的MNIST数据集，然后将其转换为张量。张量是PyTorch数据结构，你可以把它们想象成稍微复杂一点的n数组。然后我们将它们转换成TensorDataset，并定义了一个数据加载器。Dataloader是一个特殊的对象，它帮助将数据以块的形式输入到模型中。实际上，当整个数据集不适合我们的RAM时，这是很有用的。</p><p id="0197" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du jt ju jv jw b">.type(torch.LongTensor)</code>将我们的地面真实答案转换为浮点型，因为默认情况下，Torch在看到整数类型时会惊慌失措。</p><p id="615e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过<code class="du jt ju jv jw b">example_data.unsqueeze(1)</code>，我们为数据增加了一个额外的维度。之前，我们有一个28x28图像的数组([128，28，28])，现在我们有一个<em class="jx">单通道</em>图像的数组([128，1，28，28])。</p><h1 id="208e" class="ku kv hi bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">模型描述</h1><p id="29f0" class="pw-post-body-paragraph if ig hi ih b ii ls ik il im lt io ip iq lu is it iu lv iw ix iy lw ja jb jc hb bi translated">Keras:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="3322" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">PyTorch:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="4575" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是两个框架之间的第一个大区别——模型架构被分成两部分。首先，我们定义了层，然后定义了路径，我们的数据必须在训练过程中进行。这背后的逻辑是<a class="ae kf" href="https://stackoverflow.com/questions/59642925/pytorch-can-we-use-nn-module-layers-directly-in-forward-function" rel="noopener ugc nofollow" target="_blank">一些层是可训练的(它们存储权重)，而forward方法中的层只是修改张量</a>。</p><p id="088f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">您也可以在这里使用<code class="du jt ju jv jw b">nn.Sequential</code>，并以Keras方式定义您的模型(conv2d和relu都作为层)，但是您会更经常地遇到用<code class="du jt ju jv jw b">nn.Module</code>定义的网络。<a class="ae kf" href="https://discuss.pytorch.org/t/when-should-i-use-nn-modulelist-and-when-should-i-use-nn-sequential/5463/2" rel="noopener ugc nofollow" target="_blank">更多关于那个</a>。</p><p id="6f36" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">另一件事是PyTorch更希望你计算张量维度，这些维度有很多不匹配的方式。我使用这些工具来帮助我:</p><p id="8433" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du jt ju jv jw b">print(network)</code> —将非常基本的内容打印到about in_channels中。</p><pre class="je jf jg jh fd lz jw ma mb aw mc bi"><span id="a062" class="md kv hi jw b fi me mf l mg mh">network = Net()<br/>print(network)<br/>&gt;&gt;&gt;<br/>Net(<br/>  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))<br/>  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br/>  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))<br/>  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)<br/>  (flatten): Flatten(start_dim=1, end_dim=-1)<br/>  (conv2_drop): Dropout(p=0.5, inplace=False)<br/>  (fc1): Linear(in_features=1600, out_features=10, bias=True)<br/>)</span></pre><p id="efec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du jt ju jv jw b">torchsummaty.summary(network)</code> —打印更详细的描述，类似于Keras的<code class="du jt ju jv jw b">model.summary()</code>命令。</p><pre class="je jf jg jh fd lz jw ma mb aw mc bi"><span id="9475" class="md kv hi jw b fi me mf l mg mh">from torchsummary import summary<br/>...<br/>network = Net()<br/>summary(network, (1, 28, 28))<br/>&gt;&gt;&gt;<br/>----------------------------------------------------------------<br/>        Layer (type)               Output Shape         Param #<br/>================================================================<br/>            Conv2d-1           [-1, 32, 26, 26]             320<br/>         MaxPool2d-2           [-1, 32, 13, 13]               0<br/>            Conv2d-3           [-1, 64, 11, 11]          18,496<br/>         MaxPool2d-4             [-1, 64, 5, 5]               0<br/>           Flatten-5                 [-1, 1600]               0<br/>           Dropout-6                 [-1, 1600]               0<br/>            Linear-7                   [-1, 10]          16,010<br/>================================================================</span></pre><p id="0cf0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><code class="du jt ju jv jw b">print(x.shape)</code> —追踪张量形状的最简单工具。</p><pre class="je jf jg jh fd lz jw ma mb aw mc bi"><span id="0261" class="md kv hi jw b fi me mf l mg mh">def forward(self, x):<br/>    x = self.conv1(x)<br/>    print(x.shape)<br/>&gt;&gt;&gt;<br/>torch.Size([2, 32, 26, 26])</span></pre><h1 id="6e1f" class="ku kv hi bd kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq lr bi translated">模型训练和评估</h1><p id="e1b0" class="pw-post-body-paragraph if ig hi ih b ii ls ik il im lt io ip iq lu is it iu lv iw ix iy lw ja jb jc hb bi translated">在Keras中，整个训练过程只需调用一个<code class="du jt ju jv jw b">.fit</code>方法即可完成:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="c5a9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然而，在PyTorch中，您需要手动编写整个训练和测试循环。无需深究太多理论，伪代码中的神经网络训练循环如下所示:</p><pre class="je jf jg jh fd lz jw ma mb aw mc bi"><span id="2d2b" class="md kv hi jw b fi me mf l mg mh">for every epoch:<br/>    for every batch:<br/>        load data;<br/>        pass data through network;<br/>        calculate losses;<br/>        calculate gradients;<br/>        adjust network weights through backpropagation.</span></pre><p id="ce6e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此时，您可能想知道:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mi"><img src="../Images/eff2e5fc3b84b073018bd213e4734f67.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*FfcIBw5aKsgydEOUKaY7Kg.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">不幸的是，是的。</figcaption></figure><p id="79e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在PyTorch中是这样的:</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="lx ly l"/></div></figure><p id="1cf9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个过程非常简单，虽然有些冗长，但是有两点我想详细说明一下:</p><ul class=""><li id="1df8" class="kg kh hi ih b ii ij im in iq ki iu kj iy kk jc kl km kn ko bi translated"><code class="du jt ju jv jw b">network.train()</code>和<code class="du jt ju jv jw b">network.eval()</code>就是这样做的——它们为我们的模型打开训练或评估模式。例如，丢弃层在评估期间没有意义，因此在评估模式中关闭<a class="ae kf" href="https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615" rel="noopener ugc nofollow" target="_blank">。</a></li><li id="3b76" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated"><code class="du jt ju jv jw b">optimizer.zero_grad()</code>在开始反向传播之前，将梯度设置为零。我们需要这样做，因为PyTorch在随后的反向过程中累积梯度，当您开始训练循环时，您应该将梯度归零，以便您<a class="ae kf" href="https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch" rel="noopener ugc nofollow" target="_blank">正确地进行参数更新</a>。</li></ul></div><div class="ab cl jy jz gp ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="hb hc hd he hf"><p id="0adf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的PyTorch之旅到此结束。现在我们有了一个可以工作的MNIST模型，从这里开始，你有希望为你的特定任务修改这个代码时会有更少的问题。</p><p id="ae47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你有额外的问题，评论，或者只是想分享一些东西——请在这里随意评论，或者在<a class="ae kf" href="https://twitter.com/soo_underground" rel="noopener ugc nofollow" target="_blank"> twitter </a>或<a class="ae kf" href="https://t.me/soo_underground" rel="noopener ugc nofollow" target="_blank"> telegram </a>上给我发消息。</p></div><div class="ab cl jy jz gp ka" role="separator"><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd ke"/><span class="kb bw bk kc kd"/></div><div class="hb hc hd he hf"><p id="e734" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有用的链接:</p><ul class=""><li id="e8b8" class="kg kh hi ih b ii ij im in iq ki iu kj iy kk jc kl km kn ko bi translated"><a class="ae kf" href="https://keras.io/examples/vision/mnist_convnet/" rel="noopener ugc nofollow" target="_blank">喀拉斯MNIST的例子</a>。</li><li id="ac56" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated"><a class="ae kf" href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" rel="noopener ugc nofollow" target="_blank"> PyTorch CIFAR-10示例</a>。</li><li id="21f6" class="kg kh hi ih b ii kp im kq iq kr iu ks iy kt jc kl km kn ko bi translated"><a class="ae kf" href="https://towardsdatascience.com/converting-from-keras-to-pytorch-lightning-be40326d7b7d" rel="noopener" target="_blank">类似PyTorch的闪电文章</a>。</li></ul></div></div>    
</body>
</html>