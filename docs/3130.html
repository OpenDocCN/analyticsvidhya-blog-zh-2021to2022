<html>
<head>
<title>Tech Is Biased, Because Humans Are.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">技术是有偏见的，因为人类是。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tech-is-biased-because-humans-are-dc811114af94?source=collection_archive---------9-----------------------#2021-06-09">https://medium.com/analytics-vidhya/tech-is-biased-because-humans-are-dc811114af94?source=collection_archive---------9-----------------------#2021-06-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="3425" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">坏消息:偏见减缓了社会创新。好消息是:我们可以修复它。</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/6df1f5b77b20040a1a0d25be55c23fe0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_sydRtY-DM559T3L5cpyKg.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">照片由Michael Dziedzic在Unsplash上拍摄</figcaption></figure><p id="c97a" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi ki translated"><span class="l kj kk kl bm km kn ko kp kq di"> P </span> <strong class="jo hi"> ART 1 — </strong>不久前，在女性历史月期间，在Aticco Coworking主办的“<em class="kr">增强职场女性权能”</em>活动之际，我饶有兴趣地听取了各种关于女性在科技领域的地位的演讲。</p><p id="2ab3" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">all women的首席执行官兼联合创始人Laura Ferná ndez做了一个引人入胜的演讲，题为“T10科技女性运动是社会变革的加速器T11”，我有机会总结了一些想法，并与她就此话题进行了交谈。在这篇由两部分组成的文章中，你会发现一些对这次演讲的印象，以及当前的技术状态(<em class="kr">第一部分</em>)和即将发布的对劳拉的特别采访(<em class="kr">第二部分</em>)。敬请期待！</p><h1 id="f606" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">反思技术多样性的现状</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ll"><img src="../Images/785da458a6543d5f7e9a67a4635e34f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Zx3FA4QU5ngmtRnO71TkSQ.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">戴安娜·沃克尔在1984年写的《史蒂夫·乔布斯和麦金塔电脑》</figcaption></figure><p id="b51d" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">让我们做一个小练习。闭上眼睛，想象一个在科技领域工作的人。你想到了什么？很有可能是你的大脑让你想到了一个白人中年男人。我说的对吗？</p><p id="1d52" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">AllWomen的首席执行官劳拉费尔南德斯认为，这种行为有一个简单的解释:我们生活的世界完全是有偏见的。</p><blockquote class="lm ln lo"><p id="6c36" class="jm jn kr jo b jp jq ii jr js jt il ju lp jw jx jy lq ka kb kc lr ke kf kg kh ha bi translated">偏见是支持或反对一个想法或事物的不相称的力量，通常是以一种封闭的、偏见的或不公平的方式。—维基百科</p></blockquote><p id="c9ba" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">我们生活的现实充满了刻板印象，以至于我们甚至没有意识到我们已经被它们完全包围了——在某些情况下，是无意的。</p><h1 id="26d5" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">性别偏见始于游戏时间</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ls"><img src="../Images/f1a7a81dbd66542e81fde7dabcef5159.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ibgZBqc9FnZIwgzyML5_6w.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">Raj Rana在Unsplash上拍摄的照片</figcaption></figure><p id="8e79" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">刻板印象是人们经常错误地认为的“标准”。这种消极行为的一个影响是，通过这样做，我们无意中强化了它们，助长了现状。一个例子？<strong class="jo hi">有些工作是“<em class="kr">男</em>”，有些是“<em class="kr">女</em>”。</strong></p><p id="00a6" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">这助长了一种心态，即职业选择应该以你的性别为条件。这些限制和标准化的倾向早已被社会接受，不管它们有多肤浅——如果你认为自己是女性，这对你来说可能不是什么新闻。</p><p id="3db7" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">男性职业和所谓的性别化工作不仅对当代人是危险的，对未来的人也是危险的。</p><p id="2e0e" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">儿童可能从很小的时候就错误地认识到，金融专业人员是男性，而保健专业人员是女性。</p><p id="c987" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">工程师是男性，而教师是女性。警察是男性，而人力资源专业人员是女性，等等。此外，根据<a class="ae ks" href="https://science.sciencemag.org/content/355/6323/389" rel="noopener ugc nofollow" target="_blank">美国的一项研究</a>，到6岁时，女孩认为男孩比同性别的孩子聪明。</p><p id="0b1e" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">这项研究认为，这种定型观念在很小的时候就被吸收了，最终阻碍了成年女性进入需要特殊智力的职业。因此，女性在物理、科学或哲学等领域的代表性不足。</p><p id="2a84" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如果我们考虑STEM领域，那么很少有知名的女性榜样。这样的结果就是，女生成长过程中没有一个灵感可以跟随，无疑很难变成你没见过的样子。</p><p id="ed62" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">让我们谈谈数字:</p><ul class=""><li id="0af1" class="lt lu hh jo b jp jq js jt jv lv jz lw kd lx kh ly lz ma mb bi translated">不到25%的全球STEM毕业生是女性。</li><li id="94fd" class="lt lu hh jo b jp mc js md jv me jz mf kd mg kh ly lz ma mb bi translated">女性只占所有技术工作的1/4。</li><li id="4cbe" class="lt lu hh jo b jp mc js md jv me jz mf kd mg kh ly lz ma mb bi translated">女性拥有的科技初创企业占5%。</li><li id="5409" class="lt lu hh jo b jp mc js md jv me jz mf kd mg kh ly lz ma mb bi translated">硅谷公司中只有11%的高管职位由女性担任。</li><li id="5f71" class="lt lu hh jo b jp mc js md jv me jz mf kd mg kh ly lz ma mb bi translated">在科技行业工作中，女性的离职率是男性的两倍多，分别为41%和17%。科技行业56%的女性会在职业生涯中期离开她们的雇主。</li><li id="b239" class="lt lu hh jo b jp mc js md jv me jz mf kd mg kh ly lz ma mb bi translated">男性薪酬中位数比女性薪酬中位数高出61%。</li></ul><p id="36fc" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">统计数据令人震惊，清楚地表明我们还没有达到这一步。</p><h1 id="d0d6" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">人工智能反映了我们生活的不公平世界</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mh"><img src="../Images/8af3fde126458ac394139a420c3a7d36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pmOqOZnGP8m2MWJJexQt0A.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">Unsplash机器人中的人工智能</figcaption></figure><p id="4fad" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在技术领域，焦点通常是创造能够解决问题并满足最终消费者需求的产品。然而，没有合适的环境，没有多样性，没有包容性，就很难创造出大规模有效的解决方案。结果，<strong class="jo hi">产品无法满足用户的需求</strong>，我们强化了一个没有包容性替代方案的不适当环境。</p><p id="a64e" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">甚至像谷歌这样的科技巨头也面临一些批评。有几个众所周知的带有偏见和歧视性的谷歌图片搜索结果的例子:当搜索一个医生的照片时，几乎所有的白人男性都出现了。用“<em class="kr"> CEO </em>”这个词，结果是一样的——大多是男性和白人——而如果我们键入“<em class="kr">秘书</em>”，算法主要返回白人女性的图像。这反映了以前说过的话:男人是领导者、企业家。女人是助手，照顾者。这只是反映我们时代的社会问题的一面镜子。</p><p id="fd27" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">让我们尝试一个不同的查询— <a class="ae ks" href="https://www.wired.co.uk/article/google-image-search-sexist-suggestions" rel="noopener ugc nofollow" target="_blank">好莱坞演员</a>。事情并没有变好，相反，谷歌的算法变得更加偏颇。如果我们搜索一个男演员，算法将主要关注他的职业生涯。如果我们搜索一名女演员，谷歌的算法将关注她的身体——从而强化性别歧视的陈词滥调。</p><p id="8f8f" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">谷歌声称自己不偏不倚。但是如果没有人监督它的算法是如何工作的，<strong class="jo hi">这种公正性是很难把握的</strong>。</p><h1 id="6f44" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">种族主义被编码到科技产品中</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mi"><img src="../Images/156ae3617d52ca363e8ec164a74a52d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PcEM-seQpr-mXKl8zL-kYQ.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">照片由Rolande PG在Unsplash上拍摄</figcaption></figure><p id="7697" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">当我们谈论多样性时，我们不仅仅指性别问题。对非白人和BIPOC社区的种族歧视和偏见在技术领域非常普遍。</p><p id="af10" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">一个简单而可悲的众所周知的例子，也是劳拉在她的演讲中提到的，就是自动<a class="ae ks" href="https://www.mic.com/articles/124899/the-reason-this-racist-soap-dispenser-doesn-t-work-on-black-skin" rel="noopener ugc nofollow" target="_blank">皂液机</a>无法检测到黑人顾客的手。乍一看，这似乎很滑稽，但它清楚地证明了许多科技公司存在的一个重大而普遍的问题:<strong class="jo hi">缺乏多样性</strong>。</p><p id="acec" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如果一家公司的大多数人是白人，那么这家公司开发的产品很可能会呈现出某种固有的歧视。工作环境呈现的多样性越少，设计缺陷就越有可能对少数族裔不利。</p><p id="0602" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">另一个常见的例子是<a class="ae ks" href="https://www.theatlantic.com/technology/archive/2016/04/the-underlying-bias-of-facial-recognition-systems/476991/" rel="noopener ugc nofollow" target="_blank">面部识别</a> <a class="ae ks" href="https://www.theatlantic.com/technology/archive/2016/04/the-underlying-bias-of-facial-recognition-systems/476991/" rel="noopener ugc nofollow" target="_blank">系统</a>，在美国，这些系统比白人更有可能错误识别或无法识别非裔美国人。</p><p id="344e" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">这表明创建算法的条件会强烈影响其结果的准确性。</p><h1 id="1d32" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">如果是中性的，那就不是技术</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mj"><img src="../Images/2711b17efa18f51517433f91256d2bc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BGwG5AJ4P88K2bNO_upjOQ.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">卢卡·布拉沃在Unsplash上的照片</figcaption></figure><p id="7a39" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">总而言之，值得记住的是，技术本身既不是性别歧视，也不是种族歧视。技术只是一种工具，因此它没有自己的意志。</p><p id="292a" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">然而，不可能认为技术是中性的东西。任何技术都是由个人设计的:生活在社会中的人类，以及他们所有的文化框架、现实和观点。和偏见。</p><p id="be7d" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">技术发展离不开背景——由个人和他们的<em class="kr">环境构成——它产生于其中。因此，当创造者团队中没有多样化的声音和观点时，技术就变得具有歧视性。</em></p><p id="0ff1" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">解决办法？我们需要为我们的偏见负责，并采取相应的行动。</p><h1 id="1090" class="kt ku hh bd kv kw kx ky kz la lb lc ld in le io lf iq lg ir lh it li iu lj lk bi translated">教育有助于创造更美好的未来</h1><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mk"><img src="../Images/0373482f51bfe471e6521d72b5a277c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5Hr1TE3yzf2rJ0rsiEzOWw.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">Christina Morillo在Unsplash上拍摄的照片</figcaption></figure><p id="3f29" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在她演讲的最后，劳拉告诉我们<a class="ae ks" href="https://www.allwomen.tech/" rel="noopener ugc nofollow" target="_blank"> AllWomen </a> academy背后的使命:改善当前的技术状态，并最终为所有认为自己是女性并在技术相关领域工作(或渴望这样做)的人提供一个更好、更平衡和公平的未来。</p><p id="06bc" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">AllWomen的使命是改变现实，因为事情可以变得不同，变得更好，科技的未来也可以是女性的。引用劳拉的话来说，这个学院是一个学生可以实现和发展他们潜力的地方，总是具有全球性和包容性的观点。</p><p id="0124" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">社会变革包括社会秩序的改变。令人鼓舞的是，AllWomen的愿景是创建一个能够设计包容性技术的社区——并且<strong class="jo hi">解决社会问题，而不是加剧这些问题</strong>。</p></div><div class="ab cl ml mm go mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="ha hb hc hd he"><p id="aa15" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">在演讲结束时，合上笔记本电脑几秒钟后，我被沮丧、愤怒和希望的复杂感觉淹没了。不过，有一件事是肯定的。</p><p id="9c2b" class="pw-post-body-paragraph jm jn hh jo b jp jq ii jr js jt il ju jv jw jx jy jz ka kb kc kd ke kf kg kh ha bi translated">如果我闭上眼睛，想象一个在科技领域工作的人，那个人是一个强大、聪明、有才华的女人。</p></div></div>    
</body>
</html>