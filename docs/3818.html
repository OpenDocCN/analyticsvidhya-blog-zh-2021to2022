<html>
<head>
<title>Demystifying Delta Lake</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">揭开三角洲湖的神秘面纱</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/demystifying-delta-lake-d15869fd3470?source=collection_archive---------0-----------------------#2021-07-29">https://medium.com/analytics-vidhya/demystifying-delta-lake-d15869fd3470?source=collection_archive---------0-----------------------#2021-07-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/1ddb3a2c1bab909bf93f7100fd218768.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*t-ByO3x24Ho9RuTZ"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@wynand_uys?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Wynand Uys </a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="65c6" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在真实的数据世界中，大多数业务问题都可以通过无处不在的关系数据库来解决，这显然是一个有效的选择，原因有几个。但随着社交媒体、机器数据(物联网设备、PoS机)和交易数据公司的出现，它们开始生成和消费大型数据集。<strong class="ix hj"/><strong class="ix hj">大数据</strong>一词被创造出来，用来表示这种不受管理的海量数据集。使用传统的商业智能工具解决业务问题，尤其是数据库的使用开始成为瓶颈，因为存储、管理和计算如此庞大的数据集需要经济高效且快速的处理解决方案。为了解决这些问题，雅虎参考了谷歌白皮书MapReduce的概念，创建了Hadoop。然而，MapReduce的传统算法有其自身的局限性，它不是围绕内存独立性设计的(它使用中间磁盘存储进行操作)。除此之外，MapReduce及其相关工具主要是解决批量数据处理的问题，不支持任何属性、真正的流数据以及数据科学获得大数据洞察力的良好框架。</p><p id="7695" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，为了解决MapReduce的问题，Apache spark被引入作为大数据和机器学习的统一分析引擎。Apache Spark的基本计算原理是内存处理。然而，除了Spark最初的进步之外，仍然存在一些根本差距，这些差距不能完全支持现代数据架构来存储、管理和处理大数据。例如，如果我们谈论被定义为</p><ul class=""><li id="cb5d" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">存储应该是廉价的，并且可以包含各种原始格式的数据(XML、JSON、CSV、ORC、PARQUET等)</li><li id="d26c" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">可以维护这些不同格式的历史转储。</li><li id="ba6f" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">历史数据可能需要不同类型的数据更改，这进一步要求对数据进行事务性操作。</li></ul><p id="1bf2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">以上定义为数据湖<strong class="ix hj"> <em class="kh">灵活性的属性，如果组织和管理不当，会使其成为数据沼泽</em> </strong>。所有基于文件的体系结构也是如此，在这些体系结构中，数据是从数据湖中提取的。数据湖也带来了需要解决的挑战。</p><ul class=""><li id="6534" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">元数据的频繁刷新</li><li id="7fea" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">处理模式更改并实施模式。</li><li id="0254" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">处理小文件(在接收和处理流数据的情况下)</li><li id="961f" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">修改现有数据。</li><li id="0f01" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">优化性能</li><li id="af4c" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">如果数据分布在许多文件中，并由一些列进行分区，则通过索引对数据进行管理和重新排序。</li></ul><p id="fd87" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了牢记上述挑战，并且不将宝贵的数据湖转化为数据沼泽，Databricks推出了一款名为Delta Lake的产品。它是开源的，在这篇博客中，我们将看到它是如何有用的，以及我们可以在不同的数据应用中利用它。</p><h1 id="4c51" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">三角洲湖</h1><p id="7282" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">Delta Lake是一种基于文件的开源存储格式，使组织能够构建现代化的数据产品，将数据的治理和结构集中到一个地方，最重要的是提供数据的可靠性，以确保组织生成的洞察力是可信的。</p><p id="f8b0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">它通过采用以下方式解决了上述主要挑战</p><ul class=""><li id="5aaa" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">开源文件格式(拼花地板)</li><li id="940f" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">对商业智能、机器学习和数据科学的一流支持。</li><li id="80f9" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">解决数据仓库的主要挑战，包括</li></ul><p id="6642" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> a .可靠性</strong> —保持数据湖和数据仓库的一致性</p><p id="6424" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> b .数据陈旧</strong> —与数据湖相比，仓库中的数据是陈旧的，因为它得到的更新越来越少。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es ll"><img src="../Images/3d0b2b6ee34e1d267a072756dfb2cd38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*g5w6PUead03K0tJJd62LdA.png"/></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:https://databricks.com/product/data-lakehouse<a class="ae iu" href="https://databricks.com/product/data-lakehouse" rel="noopener ugc nofollow" target="_blank"/></figcaption></figure><p id="1a60" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，在阅读了Delta Lake的定义后，可能会出现一个天真的问题……很明显，这是一个存储系统，可以智能地管理以前无法填补的空白，但是<strong class="ix hj">Delta Lake究竟是如何组织和传输数据的？</strong></p><p id="3de9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kh">这是通过遵循从数据接收到数据消费的数据质量模式来实现的。随着我们从摄取转向消费，数据的质量不断提高，越来越好。为了体现这一理念，Delta Lake将这一数据质量流程定义为不同的层，分别称为青铜层、白银层和黄金层。</em></p><p id="de92" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">铜牌:</strong>保持数据的原样(原始形式，如JSON、Parquet、IOT数据、XML等)</p><p id="e385" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">白银:</strong>更精细的组织数据视图。它可以被直接查询，且数据是干净、标准化的，并且可以被认为是真实的单一来源。</p><p id="89f7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> Gold: </strong>这是为不同业务用例保留的聚合数据层。</p><p id="e476" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从<strong class="ix hj">黄金</strong>层，可以构建报告、分析，因为这是根据业务用例聚合数据的地方。</p><p id="12c0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">事实上，以上是一些花哨的名字，但这是实至名归的，因为<strong class="ix hj">在每一层中，数据质量都得到了提高</strong>，在最后阶段，我们获得了可用于分析的数据。</p><p id="994a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">要了解三角洲湖如何应对上述挑战，我们需要深入了解其关键要素和特征。</p></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><h1 id="127a" class="ki kj hi bd kk kl lx kn ko kp ly kr ks kt lz kv kw kx ma kz la lb mb ld le lf bi translated">三角洲湖泊元素</h1><p id="775e" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">三角洲湖有<strong class="ix hj"> 4个主要元素</strong>，作为构建三角洲湖特征的基础(特征将在下一节描述)。</p><ol class=""><li id="0a22" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js mc jz ka kb bi translated"><strong class="ix hj"> Delta文件— </strong>它使用了<strong class="ix hj"> <em class="kh"> Parquet文件</em> </strong>，这是一个为存储表格数据而优化的柱状文件系统。</li></ol><p id="c129" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="kh">问题:</em> </strong>如果使用<strong class="ix hj"/>拼花文件，那么<strong class="ix hj"><em class="kh"/></strong>有何不同？</p><p id="9ebd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="kh">答:</em> </strong> <em class="kh"> </em>的确，delta使用parquet文件进行存储，但是Parquet表和Delta表之间的唯一区别是<strong class="ix hj"> _delta_log </strong>文件夹，它存储Delta事务日志并帮助实现不同的Delta特性(将在下一节中讨论)。</p><p id="d874" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 2。增量表— </strong>它是一个由三个部分组成的数据集合</p><p id="81dd" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">a)包含数据的数据文件</p><p id="a41e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">b)在跟踪元数据的Metastore中注册的增量表。</p><p id="e7b9" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">c)具有增量文件的事务日志，用于跟踪所有事务。</p><p id="1721" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 3。Delta优化引擎— </strong> Delta引擎可加速数据湖操作，并支持从大规模ETL处理到即席交互式查询的各种工作负载。许多优化会自动应用。</p><p id="c067" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> 4。Delta Lake存储层— </strong>组织以低廉的成本将其数据保存在对象存储中的位置，以后可以使用Delta来访问这些文件。</p><h1 id="f373" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">三角洲湖泊特征</h1><h2 id="a0d3" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak">兼容Apache Spark API </strong></h2><p id="0a2f" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">这是将底层存储和应用平稳切换到Delta Lake的一个重要功能。与Apache Spark兼容使得利用新特性变得容易。这个特性对于在Spark上开发但需要迁移到Delta的项目非常有用。</p><p id="9ea0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">格式要求此流进入增量</strong></p><p id="708a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">在文件级</strong></p><p id="6f15" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kh">任意文件格式- &gt;拼花- &gt;增量</em></p><p id="1b42" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">代码级</strong></p><p id="884d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kh">与德尔塔基于相同的火花发动机的小调整。</em></p><p id="b78e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">看看下面的片段-</p><pre class="lm ln lo lp fd mr ms mt mu aw mv bi"><span id="6342" class="md kj hi ms b fi mw mx l my mz">from delta.tables import DeltaTable <br/>parquet_table = "some_parquet_table"<br/>partitioning_scheme = "some_id int"<br/>DeltaTable.convertToDelta(spark, parquet_table, partitioning_scheme)</span></pre><p id="73e3" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">上面的片段是不是看着很眼熟像Spark代码？</p><h2 id="8c25" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak">酸性交易</strong></h2><p id="7d99" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">写入增量存储的所有数据更改都是为了持久性而提交的，并保证不再有部分或损坏的文件。这意味着读取器可以读取一致的数据。</p><p id="3a0e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了理解ACID行为，我们需要解包由Delta lake维护的事务文件，以促进这一属性。</p><p id="f910" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为了检查事务日志，我们可以列出<strong class="ix hj"> _delta_log </strong>文件夹，所有与事务相关的数据都在这些文件夹中被捕获。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es na"><img src="../Images/e0fc64d58f83d59322f4ebebd8f613ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*Xv-kGLwhCW8kdhd5ysklxg.png"/></div></figure><p id="954f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在folder _delta_log中，我们可以看到两个文件被创建为<strong class="ix hj">。crc </strong>和<strong class="ix hj">。json </strong>带一个零的大序列。如果数据上发生任何操作，那么<strong class="ix hj">另一个。json和。生成带有增量序列的crc </strong>文件。了解这些文件捕获的内容以及它们对多种用途的益处非常重要。</p><p id="fd7c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> CRC </strong>(循环冗余校验)文件帮助spark优化其查询，因为它提供了数据的关键统计信息。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es na"><img src="../Images/60a7ce945e3448a26512ff102f14a7a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*rVVyyjcJHjGQM5DvF9yhkA.png"/></div></figure><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es na"><img src="../Images/a6fd72431f4daff6d2454ebb7f8dafcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*Vc9yfrGs8kU_221Cg-M35w.png"/></div></figure><p id="2c6a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">另一方面，<strong class="ix hj"> JSON </strong>文件捕获了很多信息。让我们读取JSON文件并列出info列，然后我们看到有4列名为<strong class="ix hj"> add、commitInfo、metaData、</strong>和<strong class="ix hj"> protocol </strong>。</p><p id="c626" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">如果进一步展开<strong class="ix hj">添加栏</strong>，我们得到确认<strong class="ix hj">数据变更</strong>、<strong class="ix hj">修改时间、路径、大小、</strong>和数据基本统计的内容。</p><p id="7544" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">扩大加列</strong></p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es na"><img src="../Images/07384941466edb4440e1bd6a53904003.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*5sIoUqdGP3vjn36TD2Q4zA.png"/></div></figure><p id="465e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">扩展元数据列</strong></p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es na"><img src="../Images/fd41a3587b9ea66c828482f87a611a7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*lgirs6P-I2bAsht_vgoMQQ.png"/></div></figure><p id="367a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">提交信息— </strong>关于提交的信息。</p><p id="3a7f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">协议— </strong>通过将Delta Lake事务日志切换到最新的软件协议(读写器版本)来启用新功能</p><p id="c293" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，让我们尝试从写入的路径创建一个表，并尝试从表中更新记录。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es na"><img src="../Images/e280373f88ed76260468c71d89d9ebea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*OixjH2OdOWlYQvhPxJ7Qtg.png"/></div></figure><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es na"><img src="../Images/ff27ed3321b766dbc9856cc02819bd94.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*-9aaRyYQWVE_81crrxmuCA.png"/></div></figure><p id="0c6f" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">为新的id值更新数据。所以从内部来说。json和。crc文件也进行了更改，以捕捉这一新的数据变化。让我们重新读取<strong class="ix hj"> _delta_log </strong>文件夹及其文件</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es na"><img src="../Images/737555ba0a1d9155a28353dccaf57f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*uzdlNH8jon9y3L0MchrgLw.png"/></div></figure><p id="adec" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们现在看到了什么变化？</p><p id="8940" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以看到，随着表的更新，另一个<strong class="ix hj"> JSON &amp; CRC </strong>文件被创建。如果我们打开0000000000000000001.json文件并查看其中的列(您注意到这里有什么吗？在文件00000000000000000000.json中，列<strong class="ix hj"> add存在于</strong>中，因为我们添加了记录，现在添加了一个额外的列作为<strong class="ix hj"> remove </strong>以显示更新的数据)和内容，然后我们可以找到数据集已发生的事务的所有信息。</p><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es na"><img src="../Images/8ee9d02e224fa1e3a64ad0bb0c879e60.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*1l4-BKpTEWTIKzX-i4xvog.png"/></div></figure><figure class="lm ln lo lp fd ij er es paragraph-image"><div class="er es na"><img src="../Images/c3f84a3b43492c7728342a95ed35a575.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*_xQX2-RT6Txq1nkfRtbqJw.png"/></div></figure><p id="9c67" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">因此，对于每个操作，Delta在内部维护文件以捕获其相关信息，这是维护大量额外信息的地方，以便做出处理不同操作的决定，并启用数据的所有良好功能，这在以前对于其他文件格式是不可能的。</p><p id="ef36" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">外卖—</strong></p><p id="38a5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><em class="kh">三角洲湖泊</em> <strong class="ix hj"> <em class="kh">交易日志</em> </strong> <em class="kh">是一个</em> <strong class="ix hj"> <em class="kh">单一来源的真实数据</em> </strong> <em class="kh">。ACID还使Delta能够支持</em><strong class="ix hj"><em class="kh">upsert</em></strong><em class="kh">和</em><a class="ae iu" href="https://docs.databricks.com/spark/latest/spark-sql/language-manual/delta-merge-into.html" rel="noopener ugc nofollow" target="_blank"><strong class="ix hj"><em class="kh">merge</em></strong></a><em class="kh">。</em></p><h2 id="c672" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak">读取模式</strong></h2><p id="0aac" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">这是一个概念，当数据从存储位置取出时，它被应用于计划或模式。</p><p id="5026" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在Delta之前，在Spark或Hadoop传统架构中，每当添加一个带有附加数据集的表时，每次读取所有新添加的带有旧记录的数据集时，我们都需要使用<strong class="ix hj"> MSCK修复表</strong>命令来刷新备份文件系统的<strong class="ix hj"> metastore </strong>。但是，在delta中，这个问题得到了解决，无论用户何时查询数据，都可以确保获得最新的数据集。</p><h2 id="7241" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak">数据版本化又名时间旅行</strong></h2><p id="4aac" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">数据版本化是一个类似的概念，我们遵循代码版本化(git或任何其他代码管理软件)。我们可以根据时间或具体数字(版本)切换到数据集的不同版本。这个特性简化了为不断变化的数据集构建管道的过程。不断变化的数据带来了审计挑战、重现实验、修复数据错误以及回滚以切换所需状态(如果需要)。</p><p id="e15a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">怎么用？</strong></p><p id="97cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从<strong class="ix hj">增量表中选择特定版本或时间戳的数据很容易。</strong></p><pre class="lm ln lo lp fd mr ms mt mu aw mv bi"><span id="52c5" class="md kj hi ms b fi mw mx l my mz">.option("timestampAsOf", timestamp_expr) =&gt; <strong class="ms hj">to get specific timestamp e.g. option("timestampAsOf", "2018–10–18T22:15:12.013Z")</strong><br/>.option("versionAsOf", version) =&gt;<strong class="ms hj"> to get specific version e.g. option("versionAsOf", 9)</strong></span></pre><p id="197c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">也可以回滚到不同的版本</p><h2 id="d3b5" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak">模式实施或模式验证</strong></h2><p id="fd1f" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">检查 <em class="kh">写</em>  <em class="kh"> </em>上<strong class="ix hj"> <em class="kh">数据的模式验证，帮助确保数据的正确性。拒绝写入与定义的模式不匹配的表是一项强制检查。</em></strong></p><p id="7ac1" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">遵循这些规则来确定是否允许对表进行写操作</p><ul class=""><li id="ae9c" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">不能包含目标表的架构中不存在的任何附加列</li><li id="e95a" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">列数据类型不能与目标表中的列数据类型不同。</li><li id="f5d2" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">不能包含仅大小写不同的列名(<strong class="ix hj"> Delta区分大小写— <em class="kh"> Delta </em> </strong> <em class="kh">和</em><strong class="ix hj"><em class="kh">Delta</em></strong><em class="kh"/>不相同)</li></ul><p id="81a2" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">注意</strong> —这个特性有助于验证很多东西，我们通常在实际项目中为这些东西创建定制的数据验证器。仅仅有一个标准的<strong class="ix hj"> delta </strong>格式就可以避免很多数据问题。</p><h2 id="8245" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak">图式进化</strong></h2><p id="9857" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">它帮助用户轻松地修改表的当前模式，以适应随时间变化的新数据。该特性的一般用途是在<strong class="ix hj">追加</strong>和<strong class="ix hj">覆盖</strong>操作期间自动调整模式以包含一个或多个新列。</p><p id="4606" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">怎么用？</strong></p><p id="77ad" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在将数据帧写入增量文件的过程中，我们需要将<strong class="ix hj"> mergeSchema </strong>属性设置为true。</p><pre class="lm ln lo lp fd mr ms mt mu aw mv bi"><span id="8493" class="md kj hi ms b fi mw mx l my mz">df.write.format("delta")\<br/>.mode("overwrite")\<br/>.option("path", "file_path")\<br/>.option("<strong class="ms hj">mergeSchema</strong>", "<strong class="ms hj">true</strong>")\<br/>.partitionBy("partition_col")\<br/>.saveAsTable("table_name")</span></pre><p id="e2ef" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">还可以检索增量表历史</p><pre class="lm ln lo lp fd mr ms mt mu aw mv bi"><span id="226a" class="md kj hi ms b fi mw mx l my mz">DESCRIBE HISTORY &lt;table_name&gt;-- get the full history of the table<br/>DESCRIBE HISTORY delta.&lt;delta_file_path&gt;</span></pre><h1 id="2391" class="ki kj hi bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf bi translated">最佳化</h1><p id="e4c6" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">到目前为止，我们已经看到增量文件捕获了操作文件的一些统计数据。这些统计数据是由Delta lake的创建者出于某种目的编写的，其中一个明显的目的是利用优化并增强Delta Lake的性能。</p><p id="27af" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在这最后一节中，我们将学习一些优化技术，这些技术可以用来(如果需要的话)提高增量文件/表的性能。</p><h2 id="cbc9" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak"> a. </strong> <strong class="ak">通过压缩优化</strong></h2><p id="dac1" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">优化操作执行文件压缩，即将小文件压缩成较大的文件(最大1 GB)。</p><p id="edb7" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">Delta <strong class="ix hj">不支持</strong>优化<strong class="ix hj">作为自动过程</strong>，但是期望用户根据需要来执行。</p><p id="2cf4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">怎么用？</strong></p><pre class="lm ln lo lp fd mr ms mt mu aw mv bi"><span id="0b17" class="md kj hi ms b fi mw mx l my mz">Optimize &lt;table_name&gt;<strong class="ms hj"> OR </strong>delta.`delta file location`</span></pre><h2 id="c034" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak">b .</strong>T26】Z顺序</h2><p id="c214" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">这是一种通过保持数据点的局部性来将多维数据并置到一维的技术。简而言之，这是一种将相关信息保存在同一组文件中的方法。在内部，它创建更少的文件来保存数据，当搜索或查询启动时，它扫描更少的文件来获得结果。</p><p id="e963" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">一旦我们在某些列上应用ZORDER(不能在分区列上应用), Delta在幕后执行以下活动</p><ul class=""><li id="83c6" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">获取分区中现有的拼花文件。</li><li id="05b1" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">根据为<a class="ae iu" href="https://en.wikipedia.org/wiki/Z-order_curve" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj"> ZORDER </strong> </a> <strong class="ix hj">选择的列映射拼花文件中的行。</strong></li><li id="c081" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">在只有一列的情况下，上面的映射变成了线性排序。</li><li id="1a73" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">将排序后的数据重新写入新的拼花文件。</li></ul><p id="c770" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="kh">问题:</em> </strong> <em class="kh">如何选择ZORDER列？</em></p><p id="f54b" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj"> <em class="kh">答案:</em> </strong>经验法则是选择那些筛选数据集合最大的列(低基数列但不选择分区列)。也可以选择多个列，但这会降低局部性的有效性。</p><p id="11cb" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">怎么用？</strong></p><pre class="lm ln lo lp fd mr ms mt mu aw mv bi"><span id="6098" class="md kj hi ms b fi mw mx l my mz"><em class="kh">OPTIMIZE table_identifier [WHERE clause]</em></span><span id="7f40" class="md kj hi ms b fi nb mx l my mz"><em class="kh">[ZORDER BY (col_name1, col_name2, ...)]  -- </em><strong class="ms hj"><em class="kh">be mindful not to use partition column.</em></strong></span></pre><h2 id="2cdf" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak">c .</strong>T8】分区修剪</h2><p id="dac9" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">它用于加速查询，以最小化读取的数据量。简单的意思是总是在where子句中放置分区列来过滤数据。</p><h2 id="0da1" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak">d .</strong>T12】数据跳过</h2><p id="7f49" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">应用where子句在查询中添加更多列来过滤记录，并提示增量文件(保存统计信息的文件)跳过不必要的信息。</p><h2 id="04c6" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated"><strong class="ak">e .</strong>T16】真空</h2><p id="2069" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">方便的命令，只保留相关文件，节省存储成本。</p><p id="7185" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><strong class="ix hj">怎么用？</strong></p><pre class="lm ln lo lp fd mr ms mt mu aw mv bi"><span id="1e26" class="md kj hi ms b fi mw mx l my mz">VACUUM &lt;name-of-table&gt; RETAIN &lt;number-of-hours&gt;</span></pre></div><div class="ab cl lq lr gp ls" role="separator"><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv lw"/><span class="lt bw bk lu lv"/></div><div class="hb hc hd he hf"><p id="55e5" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我试图捕捉我对delta的理解，我发现理解它的功能是很重要的，这样就可以在不同的用例中充分利用它。如果我们致力于构建或设计任何分析解决方案(数据湖、数据仓库、机器学习、处理流数据等。)可以安全地选择增量作为数据处理的标准存储。</p><p id="e08a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">感谢您的阅读💕</p><h2 id="761b" class="md kj hi bd kk me mf mg ko mh mi mj ks jg mk ml kw jk mm mn la jo mo mp le mq bi translated">参考</h2><p id="bfa2" class="pw-post-body-paragraph iv iw hi ix b iy lg ja jb jc lh je jf jg li ji jj jk lj jm jn jo lk jq jr js hb bi translated">如果你想更深入地了解它，这是一本由三角洲湖创造者写的极好的<a class="ae iu" href="https://databricks.com/blog/2021/06/22/get-your-free-copy-of-delta-lake-the-definitive-guide-early-release.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ix hj">书</strong> </a>。</p><p id="af48" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://databricks.com/wp-content/uploads/2020/08/p975-armbrust.pdf" rel="noopener ugc nofollow" target="_blank">https://databricks . com/WP-content/uploads/2020/08/p975-armbrust . pdf</a></p><p id="0a41" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf" rel="noopener ugc nofollow" target="_blank">http://cidrdb.org/cidr2021/papers/cidr2021_paper17.pdf</a></p><p id="54df" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://databricks.com/product/delta-lake-on-databricks" rel="noopener ugc nofollow" target="_blank">https://databricks.com/product/delta-lake-on-databricks</a></p><p id="63c0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated"><a class="ae iu" href="https://docs.databricks.com/delta/optimizations/file-mgmt.html" rel="noopener ugc nofollow" target="_blank">https://docs . databricks . com/delta/optimizations/file-mgmt . html</a></p></div></div>    
</body>
</html>