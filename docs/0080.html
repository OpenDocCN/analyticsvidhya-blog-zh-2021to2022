<html>
<head>
<title>Getting Started with PySpark UDF(User Defined Function)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PySpark UDF入门(用户定义函数)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/user-defined-functions-udf-in-pyspark-928ab1202d1c?source=collection_archive---------1-----------------------#2021-01-04">https://medium.com/analytics-vidhya/user-defined-functions-udf-in-pyspark-928ab1202d1c?source=collection_archive---------1-----------------------#2021-01-04</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/261c18e60a975cd31a3991466934b521.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*56guEA0xDY09_Qvq6sJJOg.png"/></div></div></figure><h1 id="a114" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">什么是UDF？</h1><p id="6560" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">用户定义函数是一个自定义函数，用于对Pyspark数据帧执行转换操作。一旦定义，它就可以在多个数据帧中重复使用。它也可以用作循环的替代<strong class="jq hj">，以获得更快的性能。</strong></p><h1 id="e29b" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">为什么需要UDF？</h1><p id="5791" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated"><em class="km"> UDF可用于执行Pyspark内置功能</em>中没有的数据转换操作。例如，我们有一个包含字符串值的列，我们需要创建一个包含反转字符串值的新列。没有内置函数来执行这个操作，我们需要编写一个自定义函数。<br/> <em class="km"> UDF可用作for循环的替代，因为它们的并行处理速度更快，而不像for循环那样执行逐步迭代</em>。例如，假设您有一个dataframe列，其中有100行由字符串值组成。现在，您需要在新列中存储反向字符串值。没有内置的函数来执行这个操作，所以让我们看看如何处理这个问题。<br/> 1。<strong class="jq hj"> For循环</strong> :-逐一迭代每100行，并执行所需的操作。由于迭代将一步一步地执行，所以执行起来需要很多时间。<br/> 2。<strong class="jq hj"> UDF:- </strong>定义一个自定义函数(UDF)来执行操作。因为这100行中的每一行的操作都是相互独立的，所以UDF可以并行执行该操作，并且执行速度比for循环快得多。</p><h1 id="48d7" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">在派斯帕克创造UDF</h1><p id="9caf" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">让我们考虑一个包含客户的名和姓的dataframe列。我们需要创建一个新列，将两个单词的首字母转换为大写字母。让我们了解如何使用UDF创建一个具有所需转换的新列。</p><h2 id="87d5" class="kn ir hi bd is ko kp kq iw kr ks kt ja jz ku kv je kd kw kx ji kh ky kz jm la bi translated"><strong class="ak">创建一个PySpark数据帧</strong></h2><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lb"><img src="../Images/dec3cfa9c25c7ddc340ad252eba87296.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CuaesdXmK1j8dAwU6y5T2w.png"/></div></div></figure><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lg"><img src="../Images/a63b1775f67a621ba7ff52eabf3daea7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JY1o028iC9nRljrq35Zprg.png"/></div></div></figure><h2 id="d8b4" class="kn ir hi bd is ko kp kq iw kr ks kt ja jz ku kv je kd kw kx ji kh ky kz jm la bi translated"><strong class="ak">创建自定义功能</strong></h2><p id="1f56" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">让我们创建一个自定义函数，它接受客户姓名并返回转换为大写的第一个字母。</p><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lh"><img src="../Images/4e9e3be3b21feea3c9cd3701391e7dd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l1-LuYb6PxZUZPLhvvfuJA.png"/></div></div></figure><h2 id="bdf5" class="kn ir hi bd is ko kp kq iw kr ks kt ja jz ku kv je kd kw kx ji kh ky kz jm la bi translated"><strong class="ak">注册一辆PySpark UDF </strong></h2><p id="6eb7" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">使用<em class="km">PySpark</em><strong class="jq hj"><em class="km">UDF()</em></strong><em class="km">函数创建一个PySpark UDF。它有两个参数，自定义函数和返回数据类型(自定义函数返回值的数据类型)。默认情况下是StringType()。</em></p><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es li"><img src="../Images/7e7cdd47684bcb2612bf49167b2cd826.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*49vklTEsLVGK7R-hdZCGgw.png"/></div></div></figure><h2 id="a65e" class="kn ir hi bd is ko kp kq iw kr ks kt ja jz ku kv je kd kw kx ji kh ky kz jm la bi translated">称PySpark为UDF</h2><p id="1f13" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">最后创建一个新列，并通过调用UDF来执行所需的转换(<em class="km"/><strong class="jq hj"><em class="km">)with column()</em></strong><em class="km">函数用于创建一个新列或转换现有的列值</em>)。</p><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lj"><img src="../Images/49a8354322ff90447c37148e321a8991.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hVlqiUprKudmgaU9we1aPw.png"/></div></div></figure><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lk"><img src="../Images/2269c39eda83d9e1fb72181818e1c327.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ELLI1vVQxOscbC5e9F_D7A.png"/></div></div></figure><p id="bae1" class="pw-post-body-paragraph jo jp hi jq b jr ll jt ju jv lm jx jy jz ln kb kc kd lo kf kg kh lp kj kk kl hb bi translated">最后，我们有了一个具有预期结果的新列。这样，您可以通过定义UDF来执行任何自定义操作。让我们看一些更有趣的用例。</p><h1 id="631f" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">PySpark UDF的更多使用案例</h1><p id="6a38" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">让我们再看几个UDF非常有用的例子。</p><h2 id="b3c1" class="kn ir hi bd is ko kp kq iw kr ks kt ja jz ku kv je kd kw kx ji kh ky kz jm la bi translated">时区转换</h2><p id="21a1" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">考虑一个场景，其中一个数据帧有两列，一列包含本地时间戳，另一列包含本地时区。</p><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lq"><img src="../Images/af52077d2fdc3f59edd78be5a1a558ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HccpiR6n1ZOzfghaJqSnuA.png"/></div></div></figure><p id="9e15" class="pw-post-body-paragraph jo jp hi jq b jr ll jt ju jv lm jx jy jz ln kb kc kd lo kf kg kh lp kj kk kl hb bi translated">让我们创建一个自定义函数，根据时区将时间戳转换为UTC。</p><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lr"><img src="../Images/813e9178b43107c996cd642a6eb3a051.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4SMTcklkZRsUiZ8d8sh-Pw.png"/></div></div></figure><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ls"><img src="../Images/9a8e577cc6db9d87a4e70d4ecd880dbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ucItPh0CbxZCUzpDaGJ93w.png"/></div></div></figure><p id="7742" class="pw-post-body-paragraph jo jp hi jq b jr ll jt ju jv lm jx jy jz ln kb kc kd lo kf kg kh lp kj kk kl hb bi translated"><em class="km">注意，在上面的例子中，我们将不止1列作为参数传递给了UDF。这样，我们可以通过使用多个列来创建一个新列。</em></p><h2 id="af62" class="kn ir hi bd is ko kp kq iw kr ks kt ja jz ku kv je kd kw kx ji kh ky kz jm la bi translated">用平均值输入缺失值</h2><p id="c1a7" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">考虑一个列中有一些缺失值的数据帧。我们需要用各列的平均值来估算缺失值。</p><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lt"><img src="../Images/1972e3c4efd2fb48135253ea91a3e140.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EBcNpZBhU0uM_YKBAK0osw.png"/></div></div></figure><p id="c322" class="pw-post-body-paragraph jo jp hi jq b jr ll jt ju jv lm jx jy jz ln kb kc kd lo kf kg kh lp kj kk kl hb bi translated">在到目前为止的例子中，我们已经看到我们使用UDF一次创建/更新一列。现在，由于我们需要用每一列的平均值来估算空值，我们将创建一个UDF并在数据帧的每一列上运行它。</p><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lu"><img src="../Images/308bc7563ae1db6c478b1d11bbec1ec2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yZUGH42eh1l_klUiK4thHw.png"/></div></div></figure><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es lv"><img src="../Images/73d66d8d8c9d2a4d43537858c3a07c25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jKw8a_yDHTGaoDRXJxNf3w.png"/></div></div></figure><p id="a0eb" class="pw-post-body-paragraph jo jp hi jq b jr ll jt ju jv lm jx jy jz ln kb kc kd lo kf kg kh lp kj kk kl hb bi translated">每一列的空值用该列的平均值进行估算。</p><h1 id="9074" class="iq ir hi bd is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn bi translated">结论</h1><p id="b0fc" class="pw-post-body-paragraph jo jp hi jq b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl hb bi translated">在这篇文章中，我们了解了以下<br/> 1。当我们需要在PySpark数据帧上执行转换时，UDF非常方便。<br/> 2。一旦定义，就可以在多个数据帧中重复使用。<br/> 3。比for循环在数据帧上执行迭代更快。</p></div></div>    
</body>
</html>