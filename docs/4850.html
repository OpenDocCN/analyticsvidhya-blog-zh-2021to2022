<html>
<head>
<title>Cross-Validation with Code in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python中的代码进行交叉验证</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cross-validation-with-code-in-python-55b342840089?source=collection_archive---------0-----------------------#2022-04-09">https://medium.com/analytics-vidhya/cross-validation-with-code-in-python-55b342840089?source=collection_archive---------0-----------------------#2022-04-09</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="3dc6" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">是的，我们将在这里编写5种不同的技术！</h2></div></div><div class="ab cl iw ix go iy" role="separator"><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb"/></div><div class="ha hb hc hd he"><p id="b7d0" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">交叉验证是解释模型性能的最有效的方法之一。它确保模型准确地符合数据，并检查任何过度拟合。它是评估统计分析结果如何推广到独立数据集的过程。</p><p id="c66d" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">当模型完全适合训练集，而在测试集中表现不佳时，就会发生过度拟合。这意味着模型将很好地学习训练数据，但不会对看不见的样本进行归纳。</p><p id="1a95" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">有不同的交叉验证技术，例如，</p><ol class=""><li id="92e8" class="jz ka hh jf b jg jh jj jk jm kb jq kc ju kd jy ke kf kg kh bi translated"><strong class="jf hi"> K倍交叉验证</strong></li><li id="a4f9" class="jz ka hh jf b jg ki jj kj jm kk jq kl ju km jy ke kf kg kh bi translated"><strong class="jf hi">分层K倍交叉验证</strong></li><li id="0187" class="jz ka hh jf b jg ki jj kj jm kk jq kl ju km jy ke kf kg kh bi translated"><strong class="jf hi">基于坚持的验证</strong></li><li id="d518" class="jz ka hh jf b jg ki jj kj jm kk jq kl ju km jy ke kf kg kh bi translated"><strong class="jf hi">留一交叉验证</strong></li><li id="f7d7" class="jz ka hh jf b jg ki jj kj jm kk jq kl ju km jy ke kf kg kh bi translated"><strong class="jf hi">K倍组交叉验证</strong></li></ol><p id="ee83" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">交叉验证背后的一般思想是，我们将训练数据分成几个部分。我们选择其中的一些部分进行训练，其余的部分用于测试模型。不同的交叉验证技术基于我们如何划分数据。</p></div><div class="ab cl iw ix go iy" role="separator"><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb"/></div><div class="ha hb hc hd he"><ol class=""><li id="4b8b" class="jz ka hh jf b jg jh jj jk jm kb jq kc ju kd jy ke kf kg kh bi translated"><strong class="jf hi"> K倍交叉验证</strong></li></ol><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es kn"><img src="../Images/c5da10c66632bdbda3602c69ed36fd14.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/1*p7Nx7am64glZ_kZi9-4USA.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">k倍简历(来源-互联网)</figcaption></figure><p id="afc9" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">我们将数据分割成k个相等的部分，在每次分割时，使用一部分作为测试集，其他部分作为训练集，我们对多次分割一直这样做。这种方法最大限度地减少了数据的浪费，因此在样本数量较少的情况下证明是有益的。</p><p id="10e1" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">启动K重交叉验证的代码片段，</p><pre class="ko kp kq kr fd kz la lb lc aw ld bi"><span id="d94b" class="le lf hh la b fi lg lh l li lj"><em class="lk"># import model_selection module of scikit-learn</em></span><span id="dbc6" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">from sklearn import model_selection</strong></span><span id="cb12" class="le lf hh la b fi ll lh l li lj"><em class="lk"># initiate the k-fold class from model_selection module</em></span><span id="c6fc" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">kf = model_selection.KFold(n_splits=5)</strong></span><span id="01bf" class="le lf hh la b fi ll lh l li lj"><em class="lk"># fill the new kfold column</em></span><span id="8809" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">for fold, (trn_, val_) in enumerate(kf.split(X=df)):</strong></span><span id="fa67" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">df.loc[val_, 'kfold'] = fold</strong></span></pre></div><div class="ab cl iw ix go iy" role="separator"><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb"/></div><div class="ha hb hc hd he"><p id="22ca" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">2.<strong class="jf hi">分层K倍交叉验证</strong></p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es lm"><img src="../Images/eaab2f45c823d2acd5da5d98adbff366.png" data-original-src="https://miro.medium.com/v2/resize:fit:862/format:webp/1*XzCUFVbd2ZczwxR1wzJ5Sw.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">分层K倍(来源-互联网)</figcaption></figure><p id="6b6f" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">分层K-Fold用于从数据中创建K个Fold，以保持每个类别的样本百分比。</p><p id="02e7" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">例如，在二进制分类问题中，类的偏斜比例为90:10，分层K-Fold将创建保持该比例的折叠，这与K-Fold验证不同。</p><p id="32d2" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">这种交叉验证技术是用于分类问题的，然而，对于回归，我们必须在一定范围内将数据绑定在一起，然后对其应用分层K-Fold。</p><p id="1266" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">为了找到适当数量的箱子，我们遵循<strong class="jf hi">斯特奇法则</strong>，</p><p id="0021" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">箱数= <strong class="jf hi"> 1 + log2(N) </strong></p><p id="a9ea" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">其中N是数据集中的样本数。</p><p id="b025" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">分层K-Fold的代码是类似的，只是我们提供了目标变量，我们希望保留样本的百分比，</p><pre class="ko kp kq kr fd kz la lb lc aw ld bi"><span id="69dc" class="le lf hh la b fi lg lh l li lj"><strong class="la hi"># import model_selection module of scikit-learn</strong></span><span id="78cb" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">from sklearn import model_selection</strong></span><span id="e1ed" class="le lf hh la b fi ll lh l li lj"><strong class="la hi"># fetch targets</strong></span><span id="2cf5" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">y = df.target.values</strong></span><span id="fc03" class="le lf hh la b fi ll lh l li lj"><strong class="la hi"># initiate the kfold class from model_selection module</strong></span><span id="1980" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">kf = model_selection.StratifiedKFold(n_splits=5)</strong></span><span id="30f8" class="le lf hh la b fi ll lh l li lj"><strong class="la hi"># fill the new kfold column</strong></span><span id="6ee7" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">for f, (t_, v_) in enumerate(kf.split(X=df, y=y)):</strong></span><span id="03af" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">df.loc[v_, 'kfold'] = f</strong></span></pre></div><div class="ab cl iw ix go iy" role="separator"><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb"/></div><div class="ha hb hc hd he"><p id="9973" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">3.<strong class="jf hi">基于持有的验证</strong></p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es ln"><img src="../Images/172aaf8eafee6d33575b298cc2f8c951.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*XuQ1HNDoTUbzBlZsW1_3vQ.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">基于简历(来源-互联网)</figcaption></figure><p id="3a73" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">这是最常见的交叉验证。这里，我们将数据集分为训练集和测试集，通常比例为70:30或80:20。根据训练数据训练模型，并根据测试数据进行性能评估。因为我们知道模型看到的数据越多，它就越好，这种方法在这方面有所欠缺，因为它在训练时从模型中分离出大量数据。</p><p id="8d41" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">保留交叉验证也用于时间序列模型，其中最近的数据用作验证集。例如，我们有2005-2010年的数据，所以我们将2010年的数据用于验证，而将2005-2009年的数据用于训练。</p><p id="25d2" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">我们可以使用scikit-learn函数来拆分数据，或者针对上面讨论的问题进行手动拆分。</p><pre class="ko kp kq kr fd kz la lb lc aw ld bi"><span id="8ea4" class="le lf hh la b fi lg lh l li lj"><strong class="la hi"># import model_selection module of scikit-learn</strong></span><span id="0315" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">from sklearn import model_selection</strong></span><span id="f04f" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">#holding out 40% of the data for testing (evaluating)</strong></span><span id="8323" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">X_train, X_test, y_train, y_test = model_selection.train_test_split (X, y, test_size=0.4, random_state=0)</strong></span></pre></div><div class="ab cl iw ix go iy" role="separator"><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb"/></div><div class="ha hb hc hd he"><p id="70c5" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">4.<strong class="jf hi">留一交叉验证</strong></p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es lo"><img src="../Images/f93ec7835e0f499c45f9a6df5d2a3c59.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*78byIZ0WCM7eummJvRRc4g.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">LOOCV(来源-互联网)</figcaption></figure><p id="0512" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">留一交叉验证是K重交叉验证的极端情况，其中K是数据中的样本数。这种技术在计算上非常昂贵，应该只用于小型数据集。由于这种技术适合许多模型，它在评估估计方面是稳健的。</p><p id="e470" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">我们可以使用K-Fold验证代码来创建n-Fold，其中n是数据中的样本数。或者，我们也可以利用scikit-learn的LeaveOneOut()方法，</p><pre class="ko kp kq kr fd kz la lb lc aw ld bi"><span id="642e" class="le lf hh la b fi lg lh l li lj"><strong class="la hi"># import model_selection module of scikit-learn</strong></span><span id="2837" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">from sklearn.model_selection import LeaveOneOut</strong></span><span id="53ce" class="le lf hh la b fi ll lh l li lj"><strong class="la hi"># Instantiate the LeaveOneOut() object</strong></span><span id="b971" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">loo = LeaveOneOut()</strong></span><span id="3887" class="le lf hh la b fi ll lh l li lj"><strong class="la hi"># Run the function through the dataset (here, X)</strong></span><span id="1e05" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">loo.get_n_splits(X)</strong></span><span id="ac1b" class="le lf hh la b fi ll lh l li lj"><strong class="la hi"># Get the list of Train-Test sets</strong></span><span id="9cdf" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">for train_index, test_index in loo.split(X):</strong></span><span id="eecf" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">X_train, X_test = X[train_index], X[test_index]</strong></span><span id="92df" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">y_train, y_test = y[train_index], y[test_index]</strong></span></pre></div><div class="ab cl iw ix go iy" role="separator"><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb"/></div><div class="ha hb hc hd he"><p id="1c25" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">5.<strong class="jf hi">K倍组交叉验证</strong></p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es lp"><img src="../Images/0237141c10761a1b1581d1d2142885da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*cppER9qxep6bP1GB8RVYJw.png"/></div><figcaption class="kv kw et er es kx ky bd b be z dx translated">K-Fold组(来源-互联网)</figcaption></figure><p id="ba56" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">GroupKFold是k-fold的变体，它确保同一组不会同时出现在测试/验证和训练集中。</p><p id="f279" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">例如，如果您的数据包括每个客户的多行(但对单个事务/行进行训练仍然有意义)，并且您的生产用例涉及对新客户进行预测，那么对来自客户的行进行测试(这些行在您的训练集中也有行)可能会有乐观偏差。</p><p id="72a4" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">GroupKFold使检测这种过拟合情况成为可能。</p><p id="a2c9" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">用于相同应用的片段，</p><pre class="ko kp kq kr fd kz la lb lc aw ld bi"><span id="704c" class="le lf hh la b fi lg lh l li lj"><strong class="la hi"># import model_selection module of scikit-learn</strong></span><span id="ea7d" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">from sklearn.model_selection import LeaveOneOut</strong></span><span id="44f8" class="le lf hh la b fi ll lh l li lj"><strong class="la hi"># Creating GroupKFold Object</strong></span><span id="8bf1" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">n_splits = 5</strong></span><span id="a837" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">gkf = GroupKFold(n_splits = 5)</strong></span><span id="a741" class="le lf hh la b fi ll lh l li lj"><strong class="la hi"># Creating Group Folds</strong></span><span id="2c36" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">result = []</strong></span><span id="8798" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">for train_idx, val_idx in gkf.split(train_df, y_labels, groups =groups_by_patient_id_list):</strong></span><span id="4d9c" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">train_fold = train_df.iloc[train_idx]</strong></span><span id="49b6" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">val_fold = train_df.iloc[val_idx]</strong></span><span id="a06e" class="le lf hh la b fi ll lh l li lj"><strong class="la hi">result.append((train_fold, val_fold))</strong></span></pre><p id="5e28" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">交叉验证是对我们的模型进行统计评估时的一项重要技术。确保正确的技术可以提高模型的准确性和稳健性。使用这些技术推断性能指标有助于创建在看不见的数据上表现更好的模型。</p><p id="1d65" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">还有更多这样的交叉验证技术，但是我们留给你去探索和发现！</p></div><div class="ab cl iw ix go iy" role="separator"><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb jc"/><span class="iz bw bk ja jb"/></div><div class="ha hb hc hd he"><p id="6757" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">如果你已经走了这么远，请鼓掌并跟随我了解更多！</p><p id="543f" class="pw-post-body-paragraph jd je hh jf b jg jh ii ji jj jk il jl jm jn jo jp jq jr js jt ju jv jw jx jy ha bi translated">此外，为Abhishek Thakur令人惊叹的著作《接近(几乎)任何机器学习问题<strong class="jf hi"> </strong>详细介绍了交叉验证，以及scikit-learn网站提出了令人惊叹的交叉验证可视化，干杯。</p></div></div>    
</body>
</html>