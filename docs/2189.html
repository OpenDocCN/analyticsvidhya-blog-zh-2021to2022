<html>
<head>
<title>Introduction To Ensemble Learning | Optimal Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">集成学习介绍|最佳机器学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ensemble-modeling-in-machine-learning-7b74a2286f94?source=collection_archive---------9-----------------------#2021-04-11">https://medium.com/analytics-vidhya/ensemble-modeling-in-machine-learning-7b74a2286f94?source=collection_archive---------9-----------------------#2021-04-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/2c846a97de391a1349d70f4963214789.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oETUVgD2SC9Pl7y7VQg5AA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">由ashwinhprasad和canva一起创建</figcaption></figure><p id="bfec" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">当谈到预测建模时，单一的算法模型可能不足以做出最佳预测。机器学习中最有效的方法之一是<strong class="iv hi">集成建模</strong>或<strong class="iv hi">集成</strong>。</p><p id="40c1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">集成建模是遵循相同或不同算法的多个机器学习模型的组合，以做出更好的整体预测。<br/>通常是这些类型的模型赢得了由<em class="jr">网飞</em>或<em class="jr">卡格尔</em>举办的机器学习比赛。</p><h1 id="5a84" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">种类</h1><p id="ade1" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">集成建模方法可以分为不同的类别。<br/>他们是:</p><ol class=""><li id="5a15" class="kv kw hh iv b iw ix ja jb je kx ji ky jm kz jq la lb lc ld bi translated"><strong class="iv hi">顺序</strong></li></ol><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es le"><img src="../Images/a7213d798715b468cf76dfa4d04286f2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_W0QyzVLx0PDCuzQwTgmdQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">图片来自kdnuggets</figcaption></figure><p id="717e" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">您可能已经猜到了，该模型包含一系列步骤。<br/>在每一步，通过考虑模型在前一步产生的预测中的误差，通过对前一步的错误分类增加一些权重，来提高模型的性能。例子:<strong class="iv hi"> Adaboost。</strong></p><blockquote class="lj lk ll"><p id="91f5" class="it iu jr iv b iw ix iy iz ja jb jc jd lm jf jg jh ln jj jk jl lo jn jo jp jq ha bi translated">M <!-- -->模型犯错误→模型更加关注错误→模型改进</p></blockquote><p id="7932" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">上述语句被重复多次，直到模型做出准确的预测</p><p id="c775" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi"> 2。平行</strong></p><p id="e33c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">与顺序方法相反，并行方法同时在数据集上拟合(训练)多个模型。在这里，模型是相互独立的。<br/>对数据集进行独立训练后，所有模型进行预测，最终的最优预测将基于分类问题的投票原则或回归问题的平均原则。<br/> <strong class="iv hi">示例:</strong>多个决策树一起工作以形成对相同数据的多个预测，最终结果将是所有决策树预测的平均值(在回归问题的情况下为<em class="jr"/>)</p><p id="79e8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">并行建模可以进一步分为两类:<strong class="iv hi">同构和异构建模</strong>。</p><ul class=""><li id="647c" class="kv kw hh iv b iw ix ja jb je kx ji ky jm kz jq lp lb lc ld bi translated"><em class="jr">同质建模:</em> <strong class="iv hi"> </strong>在数据集上训练的多个模型是相同类型的，只有一些最小的变化。<br/>示例:随机森林算法(多决策树)</li><li id="b6f1" class="kv kw hh iv b iw lq ja lr je ls ji lt jm lu jq lp lb lc ld bi translated"><em class="jr">异构建模:</em>模型类型不同。<br/>示例:一个人工神经网络和一个k-最近邻模型一起工作以做出最佳预测</li></ul><h1 id="9b92" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">集成建模的四个主要子类</h1><p id="4eff" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">整体建模有4个主要的子类，分别是<em class="jr">装袋、推进、模型桶和堆叠</em></p><p id="1167" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">装袋或自举聚集</strong></p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lv"><img src="../Images/3a38c869de164bc8c908ce13822703f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MkeRi6EMvvZvUpHmQU0dWg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">来自Analytics Vidhya的随机森林图像</figcaption></figure><p id="2a6a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这是同质系综的一个例子。在这种方法中，数据集的随机样本被挑选<strong class="iv hi"> n </strong>次，并且同类型的<strong class="iv hi"> n </strong>个模型在这些<strong class="iv hi"> n </strong>个样本上训练(<em class="jr">每个模型在单个样本上训练</em>)。然后使用投票系统从所有<strong class="iv hi"> n </strong>模型的预测中做出预测，或者在回归的情况下平均所有模型的预测</p><p id="9fc2" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">提升<br/> </strong>在提升中，权重被添加到来自前一次迭代的误分类数据，从而在下一次迭代中进行改进。这个过程一直持续到模型能够做出好的预测。这是顺序建模的一个例子。</p><p id="b646" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这可以与下面的场景相比较:<br/>老师在学校上化学课，在进行测试时，她知道一些学生在测试中表现不好。因此，她为上次考试分数低的学生开设补习班来提高他们的成绩，同时让分数高的学生自学。<br/>这就是boosting的基本功能。</p><p id="c6d8" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">模型桶<br/> </strong>在这种技术中，在给定的训练数据集上训练不同的模型，并且在所有超参数调整之后，最终选择在测试集上表现最好的模型供将来使用。</p><p id="de0c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated"><strong class="iv hi">堆叠</strong></p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lw"><img src="../Images/30d0a166146c31280bb02b08b4239898.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TcGmOuMTARvshOY5bDN81Q.png"/></div></div></figure><p id="fe5c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">Stacking根据数据训练多个不同的模型，并进行新的预测，它使用所有这些模型进行组合预测。<br/>示例:将神经网络与K个最近邻居相结合</p><h1 id="3ab5" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">结论</h1><p id="469f" class="pw-post-body-paragraph it iu hh iv b iw kq iy iz ja kr jc jd je ks jg jh ji kt jk jl jm ku jo jp jq ha bi translated">因此，一个不可否认的事实是，集成建模可能会提高准确性，并给我们一个整体更好的预测。这些多个模型的组合可以补充和补偿每个mdoel的弱点，从而导致更好的预测。但是，也有理由说，这样做，我们牺牲了模型的简单性和透明性，这可能导致一个解决方案是一个统计黑箱。</p></div></div>    
</body>
</html>