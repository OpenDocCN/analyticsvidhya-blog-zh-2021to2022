<html>
<head>
<title>Training a model with Tensorflow — Sequential API and Sub-classing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Tensorflow训练模型—顺序API和子分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/training-a-model-with-tensorflow-sequential-api-and-sub-classing-de986b11288f?source=collection_archive---------15-----------------------#2021-05-27">https://medium.com/analytics-vidhya/training-a-model-with-tensorflow-sequential-api-and-sub-classing-de986b11288f?source=collection_archive---------15-----------------------#2021-05-27</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/d311c9bd129170e049a6cbcda2d719e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*P1x3QEIj6rrXvaAEst86iw.jpeg"/></div></div></figure><p id="d88b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">本博客是使用Tensorflow 2.0训练模型的代码演练，以及使用Keras训练模型的两种不同技术的演练。</p><h1 id="cf4b" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">顺序API</h1><p id="049c" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">Keras中的<a class="ae kq" href="https://keras.io/api/models/sequential/" rel="noopener ugc nofollow" target="_blank">序列类</a>可以帮助你快速原型化和训练模型。顾名思义，顺序模型只是不同的<a class="ae kq" href="https://keras.io/api/layers/" rel="noopener ugc nofollow" target="_blank"> Keras层</a>的集合。顺序类将一系列线性层组合成一个<a class="ae kq" href="https://keras.io/api/models/model/" rel="noopener ugc nofollow" target="_blank"> Keras模型</a>。</p><h1 id="08a8" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">子分类</h1><p id="4ec4" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated"><a class="ae kq" href="https://www.tensorflow.org/guide/keras/custom_layers_and_models" rel="noopener ugc nofollow" target="_blank">子分类</a>方法让您可以自由定制<a class="ae kq" href="https://keras.io/api/layers/" rel="noopener ugc nofollow" target="_blank"> Keras层</a>和<a class="ae kq" href="https://keras.io/api/models/model/" rel="noopener ugc nofollow" target="_blank">模型</a>。您可以创建自己的图层或使用现有图层，只需创建一个继承Keras图层类的自定义图层，还可以创建一个继承Keras模型类的自定义模型。</p><p id="2d4a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae kq" href="https://www.tensorflow.org/guide/keras/custom_layers_and_models" rel="noopener ugc nofollow" target="_blank">子类</a>方法更多用于研究工作，也用于构建复杂模型，因为它有助于轻松定制神经网络的不同组件。</p><h1 id="2342" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">1.代码-顺序API</h1><p id="7f68" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">在本演练中，我们将考虑Cifar-10数据集。要了解更多关于数据集的信息，请点击<a class="ae kq" href="https://keras.io/api/datasets/cifar10/" rel="noopener ugc nofollow" target="_blank">此处</a>。</p><p id="e9c6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">导入所有库</strong></p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="3a03" class="la jo hh kw b fi lb lc l ld le">import warnings<br/>warnings.filterwarnings(‘ignore’)</span><span id="a88c" class="la jo hh kw b fi lf lc l ld le">import numpy as np<br/>import pandas as pd</span><span id="01be" class="la jo hh kw b fi lf lc l ld le">import time</span><span id="d80a" class="la jo hh kw b fi lf lc l ld le">import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="0f25" class="la jo hh kw b fi lf lc l ld le">import tensorflow as tf<br/>from tensorflow.keras.datasets import cifar10 <br/>from tensorflow.keras.preprocessing.image import ImageDataGenerator<br/>from tensorflow.keras.models import Sequential, Model, load_model<br/>from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Layer, InputLayer<br/>from tensorflow.keras.optimizers import Adam<br/>from tensorflow.keras.losses import SparseCategoricalCrossentropy<br/>from tensorflow.keras.callbacks import ReduceLROnPlateau</span></pre><p id="5f62" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">加载数据集</strong></p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="8962" class="la jo hh kw b fi lb lc l ld le">(X_train, y_train), (X_test, y_test) = cifar10.load_data()<br/>NUM_OUTPUTS = len(np.unique(y_train))</span></pre><p id="cbfa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于我们希望模型在数据批次中进行训练，因此我们定义了批次大小。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="9d6b" class="la jo hh kw b fi lb lc l ld le">BATCH_SIZE = 128</span></pre><p id="5498" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">创建一个数据生成器</strong></p><p id="7bef" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们需要一个数据生成器来根据批量大小提供数据。这里，我们将<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank"> ImageDataGenerator </a>来准备训练和测试数据集。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="17ef" class="la jo hh kw b fi lb lc l ld le">train_dataset = ImageDataGenerator(rescale=1/255).flow(X_train, y_train, batch_size=BATCH_SIZE, shuffle=True)<br/>test_dataset = ImageDataGenerator(rescale=1/255).flow(X_test, y_test, batch_size=BATCH_SIZE)</span></pre><p id="d7c8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于X_train和X_test都包含像素值范围从0到255的图像，我们使用1/255的重新缩放因子将像素从0缩放到1。</p><p id="bb12" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">使用顺序API定义模型</strong></p><p id="8251" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们将使用3个卷积块，每个卷积块由一个具有64个过滤器和3x3内核大小的<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D" rel="noopener ugc nofollow" target="_blank">卷积层</a>和一个<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D" rel="noopener ugc nofollow" target="_blank">最大池</a>层组成。</p><p id="14db" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后一个卷积与一个<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten" rel="noopener ugc nofollow" target="_blank">展平</a>层连接，该层进一步与一个具有128个节点的<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense" rel="noopener ugc nofollow" target="_blank">密集</a>层连接，其后是一个具有10个节点的输出<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense" rel="noopener ugc nofollow" target="_blank">密集</a>层(因为我们的数据中有10个类，所以NUM_OUTPUTS=10)和一个<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax" rel="noopener ugc nofollow" target="_blank"> softmax </a>激活层。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="df14" class="la jo hh kw b fi lb lc l ld le">cifar_model = Sequential()<br/>cifar_model.add(Input(shape=(32,32,3)))<br/># CONV-LAYER1<br/>cifar_model.add(Conv2D(64, kernel_size=(3,3)))<br/>cifar_model.add(MaxPooling2D())<br/># CONV-LAYER2<br/>cifar_model.add(Conv2D(64, kernel_size=(3,3)))<br/>cifar_model.add(MaxPooling2D())<br/># CONV-LAYER3<br/>cifar_model.add(Conv2D(64, kernel_size=(3,3)))<br/>cifar_model.add(MaxPooling2D())</span><span id="a718" class="la jo hh kw b fi lf lc l ld le">cifar_model.add(Flatten())<br/>cifar_model.add(Dense(128, activation=’relu’))<br/>cifar_model.add(Dense(NUM_OUTPUTS, activation=’softmax’))</span><span id="c9d0" class="la jo hh kw b fi lf lc l ld le">cifar_model.compile(optimizer=Adam(lr=1e-3), metrics=[‘accuracy’], loss=[‘sparse_categorical_crossentropy’])<br/>cifar_model.summary()</span></pre><p id="4544" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">训练序列模型</strong></p><p id="3ea5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后，我们定义模型将训练的时期的数量和每个时期的步骤。我们调用fit_generator函数并提供训练和测试数据。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="c308" class="la jo hh kw b fi lb lc l ld le">EPOCHS = 10<br/>STEPS_PER_EPOCHS = (X_train.shape[0] // BATCH_SIZE)</span><span id="ce07" class="la jo hh kw b fi lf lc l ld le">cifar_model.fit_generator(train_dataset, steps_per_epoch=STEPS_PER_EPOCHS, epochs=EPOCHS, validation_data=test_dataset)</span></pre><p id="36a9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">一旦模型训练完毕，我们就可以保存模型了。这就完成了我们使用顺序API的模型训练。</p><h1 id="4d16" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak"> 2。代码-子类方法</strong></h1><p id="b738" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">对于顺序模型，我们创建了一个训练和测试数据集，它是ImageDataGenerator的对象。这里，我们将使用一个<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank"> tensorflow数据集</a>对象来创建训练/测试数据集。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="b9ff" class="la jo hh kw b fi lb lc l ld le">def parse_data(img, label):<br/> img = tf.cast(img, tf.float32)<br/> img = img/255.0<br/> return img,label</span><span id="3a8e" class="la jo hh kw b fi lf lc l ld le">train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).map(parse_data).batch(BATCH_SIZE)<br/>test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).map(parse_data).batch(BATCH_SIZE)</span></pre><p id="9312" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">卷积块</strong></p><p id="464a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在顺序API中，我们重复了Conv2D和MaxPooling2D层三次。这里，我们创建一个卷积模块，它由Conv2D层和MaxPooling2D层组成。然后我们将在模型类中使用这个块三次，就像我们之前做的那样。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="df7a" class="la jo hh kw b fi lb lc l ld le">class ConvolutionLayer(Layer):<br/> <br/> def __init__(self, filters, kernel_size):<br/>     super(ConvolutionLayer, self).__init__()<br/>     self.__conv = Conv2D(filters, kernel_size, activation=’relu’)<br/>     self.__max_pool = MaxPooling2D()<br/> <br/> def call(self, x):<br/>     x = self.__conv(x)<br/>     return self.__max_pool(x)</span></pre><p id="23f4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ConvolutionLayer类继承了Keras层类，在它的构造函数中我们初始化了父类和其他将要使用的层类。根据从单个卷积层到最大池层的数据流来覆盖调用方法。</p><p id="9bf6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">预测块</strong></p><p id="a366" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果您与顺序模型进行比较，数据将从最后一个最大池层到扁平化层，然后是两个密集层。这里，我们创建一个类似的系统来制作最终的预测块。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="8233" class="la jo hh kw b fi lb lc l ld le">class HeadLayer(Layer):</span><span id="7eec" class="la jo hh kw b fi lf lc l ld le"> def __init__(self, num_outputs):<br/>     super(HeadLayer, self).__init__()<br/>     self.__flatten = Flatten()<br/>     self.__dense1 = Dense(128, activation=’relu’)<br/>     self.__classifier = Dense(num_outputs, activation=’softmax’)<br/> <br/> def call(self, x):<br/>     x = self.__flatten(x)<br/>     x = self.__dense1(x)<br/>     return self.__classifier(x)</span></pre><p id="1881" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">自定义模型类</strong></p><p id="ff8e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，我们把所有东西都放在一个地方，然后把每一层都连在一起。首先，我们创建一个输入层并定义input_shape参数。然后是3个卷积模块，最后是预测模块。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="dbfb" class="la jo hh kw b fi lb lc l ld le">class CifarModel(Model):<br/> <br/> def __init__(self, input_shape, filters, kernel_size, num_outputs):<br/>     super(CifarModel, self).__init__()<br/>     self.__input = InputLayer(input_shape=input_shape)<br/>     self.__conv_layer_1 = ConvolutionLayer(filters, kernel_size)<br/>     self.__conv_layer_2 = ConvolutionLayer(filters, kernel_size)<br/>     self.__conv_layer_3 = ConvolutionLayer(filters, kernel_size)<br/>     self.__classifier = HeadLayer(num_outputs)<br/> <br/> def call(self, x):<br/>     x = self.__input(x)<br/>     x = self.__conv_layer_1(x)<br/>     x = self.__conv_layer_2(x)<br/>     x = self.__conv_layer_3(x)<br/>     return self.__classifier(x)</span></pre><p id="256c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">初始化模型</strong></p><p id="fabe" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下一步，我们初始化CifarModel类，并将必要的参数传递给模型。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="482c" class="la jo hh kw b fi lb lc l ld le">cifar_model = CifarModel(input_shape=(32,32,3), filters=64, kernel_size=(3,3), num_outputs=NUM_OUTPUTS)</span></pre><h1 id="6c16" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">3.代码—构建定制培训渠道</h1><p id="bbe2" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">因为CifarModel类继承了Keras模型类，所以我们可以直接调用fit方法来训练我们的模型。但是，为了以不同的方式做事，我们将建立一个定制的培训渠道。</p><p id="5509" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">预设训练参数</strong></p><p id="c302" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们希望模型被训练10个时期，我们也提到了训练/测试步骤的数量。我们选择优化器为<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam" rel="noopener ugc nofollow" target="_blank">亚当</a>，损失对象为<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy" rel="noopener ugc nofollow" target="_blank">稀疏分类交叉熵</a>。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="9591" class="la jo hh kw b fi lb lc l ld le">EPOCHS = 10<br/>TRAIN_STEPS_PER_EPOCHS = (X_train.shape[0] // BATCH_SIZE)<br/>TEST_STEPS_PER_EPOCHS = (X_test.shape[0] // BATCH_SIZE)</span><span id="d887" class="la jo hh kw b fi lf lc l ld le">adam = Adam(learning_rate=1e-3)<br/>loss_object = SparseCategoricalCrossentropy(from_logits=False)</span></pre><p id="4f08" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">设置检查点管理器</strong></p><p id="0526" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/train/CheckpointManager" rel="noopener ugc nofollow" target="_blank">tensor flow check point manager</a>帮助您在每个训练时期跟踪您的最佳模型。即使您的训练由于某种原因失败，您也可以从最后一个检查点恢复，并从该特定点开始训练。</p><p id="73cf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，您提到tensorflow将保存模型的路径，并且在checkpoint类中，您提到在检查点期间需要存储哪个对象状态。我们将保存模型和优化器对象。</p><p id="fcba" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后，我们将检查点对象和checkpoint_path一起传递给<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/train/CheckpointManager" rel="noopener ugc nofollow" target="_blank"> CheckpointManager </a>，我们提到max_to_keep = 1。因此，检查点管理器将在整个训练迭代中只存储一个最佳模型。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="eb75" class="la jo hh kw b fi lb lc l ld le">checkpoint_path = “../models/ckpts/cifar_10/”<br/>ckpt = tf.train.Checkpoint(cifar_model=cifar_model, optimizer=adam)<br/>ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)</span></pre><p id="0e2a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">定义训练/测试步骤</strong></p><p id="36e0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">train_step函数将一批图像作为输入。这些图像批次被传递到cifar_model对象，该对象返回一个大小为(BATCH_SIZE，NUM_OUTPUTS)的预测数组。</p><p id="e549" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">然后，我们借助损失函数计算损失，并使用损失来计算梯度。</p><p id="3545" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">损耗的梯度由<a class="ae kq" href="https://www.tensorflow.org/api_docs/python/tf/GradientTape" rel="noopener ugc nofollow" target="_blank"> tf计算。GradientTape() </a>记录自动微分操作的函数。</p><p id="66fa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们在adam优化器的帮助下更新参数(权重和偏差), Adam优化器将梯度和可训练变量作为输入。</p><p id="5ee6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后，我们返回总批量损失和单个训练步骤的平均损失。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="f2a2" class="la jo hh kw b fi lb lc l ld le"><a class="ae kq" href="http://twitter.com/tf" rel="noopener ugc nofollow" target="_blank">@tf</a>.function<br/>def train_step(img, label):<br/>    train_loss = 0<br/>    with tf.GradientTape() as tape:<br/>        pred = cifar_model(img)<br/>        train_loss = loss_object(label, pred)<br/>    avg_loss = (train_loss / int(label.shape[1]))<br/>    trainable_variables = cifar_model.trainable_variables<br/>    gradients = tape.gradient(train_loss, trainable_variables)<br/>    adam.apply_gradients(zip(gradients, trainable_variables))<br/>    return train_loss, avg_loss</span></pre><p id="2103" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">测试或val步骤类似于训练步骤。唯一的区别是，我们没有为测试步骤实现梯度更新和优化器功能。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="58ba" class="la jo hh kw b fi lb lc l ld le"><a class="ae kq" href="http://twitter.com/tf" rel="noopener ugc nofollow" target="_blank">@tf</a>.function<br/>def val_step(img, label):<br/>    val_loss = 0<br/>    pred = cifar_model(img)<br/>    val_loss = loss_object(label, pred)<br/>    avg_loss = (val_loss / int(label.shape[1]))<br/>    return val_loss, avg_loss</span><span id="daf5" class="la jo hh kw b fi lf lc l ld le">def validation_loss(test_dataset):<br/>    total_loss = 0<br/>    for idx, (img, label) in enumerate(test_dataset):<br/>        batch_loss, t_loss = val_step(img, label)<br/>        total_loss += t_loss<br/>    avg_test_loss = total_loss/TEST_STEPS_PER_EPOCHS<br/>    return avg_test_loss</span></pre><p id="7743" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">火车环线</strong></p><p id="17d0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">为了训练，我们循环通过每个时期，并且在每个时期内，我们分批循环通过完整的数据集。每批图像被传递给训练步骤函数，该函数返回训练损失。类似地，将测试数据集传递给validation_loss函数，该函数将在每个训练时期后给出验证损失。</p><p id="ed35" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果一个时期之后的验证损失小于前一个时期，我们使用我们的检查点管理器对象来保存模型。</p><p id="49e1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">最后，我们绘制损失图，培训结束。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="1812" class="la jo hh kw b fi lb lc l ld le">loss_plot = []<br/>test_loss_plot = []</span><span id="7d2d" class="la jo hh kw b fi lf lc l ld le">best_test_loss=100</span><span id="6259" class="la jo hh kw b fi lf lc l ld le">for epoch in range(0, EPOCHS):<br/>    start = time.time()<br/>    total_loss = 0<br/>    for (batch, (img_tensor, target)) in enumerate(train_dataset):<br/>        batch_loss, t_loss = train_step(img_tensor, target)<br/>        total_loss += t_loss<br/> <br/>    avg_train_loss = total_loss / TRAIN_STEPS_PER_EPOCHS<br/>    loss_plot.append(avg_train_loss.numpy()) <br/>    test_loss = validation_loss(test_dataset)<br/>    test_loss_plot.append(test_loss.numpy())<br/> <br/>    print (‘For epoch: {}, the train loss is {:.3f}, &amp; test loss is {:.3f}’.format(epoch+1,avg_train_loss,test_loss))<br/>    print (‘Time taken for 1 epoch {} sec\n’.format(time.time() — start))<br/> <br/>    if test_loss &lt; best_test_loss:<br/>        print(‘Val loss has been reduced from %.3f to %.3f’ % (best_test_loss, test_loss))<br/>        best_test_loss = test_loss<br/>        ckpt_manager.save()<br/> <br/>plt.plot(loss_plot)<br/>plt.plot(test_loss_plot)<br/>plt.xlabel(‘Epochs’)<br/>plt.ylabel(‘Loss’)<br/>plt.title(‘Loss Plot’)<br/>plt.show()</span></pre><h1 id="6e54" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">结论</h1><p id="cf06" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">这就完成了我们如何使用顺序和子类方法来训练Tensorflow模型的完整演练。此外，我们还看到了定制模型培训渠道。实际上，我们用子类方法建立的模型非常简单，但是在像<a class="ae kq" href="https://www.tensorflow.org/tutorials/text/image_captioning" rel="noopener ugc nofollow" target="_blank">图像字幕</a>这样的真实用例中，你必须小心使用编码器-解码器模型，子类方法将是唯一的选择。</p><p id="6233" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">请在这里浏览这个博客<a class="ae kq" href="https://nbviewer.jupyter.org/github/iamrajatroy/Data-Science-Lab/blob/main/notebook/Tensorflow%20Sequential%20API%20and%20Subclassing.ipynb" rel="noopener ugc nofollow" target="_blank">的python笔记本。</a></p></div></div>    
</body>
</html>