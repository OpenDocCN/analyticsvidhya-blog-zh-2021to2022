# 随机森林:简化

> 原文：<https://medium.com/analytics-vidhya/random-forest-simplified-98da251c7522?source=collection_archive---------22----------------------->

***随机森林*** *是一种主流的人工智能算法，在规则学习策略中占有一席之地。它可以用于 ML 中的分类和回归问题。让我们在接下来的几分钟内了解这一点！*

> 它依赖于**集成学习**的思想，这是一个连接众多分类器的循环，以解决一个复杂的问题并改善模型的呈现。

![](img/c6f79fdaa4f3bc0bbfff488710301e25.png)

图片来源:Tellius

***顾名思义—***

*“随机森林是一种分类器，它在给定数据集的各个子集上包含不同的决策树，并采用典型来提高该数据集的感知精度。”—来源:*[***daily hunt***](https://m.dailyhunt.in/news/india/english/upgrad+english-epaper-upgrad/introduction+to+random+forest+algorithm+functions+applications+benefits-newsid-n237260050)

随机森林不是依靠 ***一棵决策树*** ，而是从每棵树上取数字，让它服从欲望的大部分投票，它预测最后的产量。森林中的树木数量越多，精确度越高，并且可以防止过度拟合的问题。

> 关于决策树算法的更多内容，请参考我之前的博客— **这里**

## 随机森林的假设

由于随机森林合并了各种树来预测数据集的类别，因此可以想象一些选择树可能会预测正确的产量，而其他树可能不会。

> 然而，所有的树一起预期正确的产量。

*这样，下面是对高级随机森林分类器的两个假设:*

*   数据集的组成变量中应该有一些真实的质量，目标是分类器可以预见精确的结果，而不是推测的结果。
*   来自每棵树的预测必须具有低连接。

## 为什么利用随机森林？

*以下几个重点阐明了为什么我们应该使用随机森林算法:*

*   与不同的算法相比，它需要一些投资。
*   在任何情况下，对于它高效运行的庞大数据集，它都可以高精度地预测产量。
*   同样，当大量信息缺失时，它也能保持准确性。

## 分类器与回归器

随机森林分类器处理具有*离散标记或也称为类别的信息。*

> **例如:**患者是否正在经历恶性生长，个人是否有资格获得信贷，等等。

一个随机森林回归器处理具有*数字或不断产出*的信息，并且类不能描述它们的特征。

> 例如:房屋成本、奶牛产奶量、组织的总工资等等。

# 随机森林算法

*随机森林分两个阶段*——最初，目的是通过加入 N 棵精选树来创建随机森林，其次是对主阶段创建的每棵树进行期望。

***工作循环可以在下面的步骤和图表中明确:***

***Step-1:*** 选择 ***随机 K*** 信息侧重于编制设置。

***第二步:*** 建立与所选信息焦点相关的选择树*(子集)*。

***第三步:*** 选择 ***号 N*** 选择你需要制作的树。

***步骤-4:*** 重复*步骤 1 和 2。*

***Step-5:*** 对于新的信息焦点，发现每个选择树的预测，并将新的信息焦点分配到大部分投票成功的类上。

> **例子:**假设有一个数据集，包含了无数的有机产品图片。按照这些思路，这个数据集被提供给随机森林分类器。数据集被划分为子集，并分配给每个选择树。

在准备阶段，每个选择树都会创建一个预测结果。当另一个信息点发生时，在该点上，根据大多数结果，随机森林分类器预测官方结论。

## 随机森林的用例

*通常使用随机森林的主要有四个地区:*

*   ***银行:*** 银行领域一般利用该算法进行信用风险的判别证明。
*   ***用药:*** 在这种算法的辅助下，可以识别疾病模式和疾病的危险性。
*   ***土地利用:*** 我们可以通过这个算法识别出比较土地利用的区域。
*   ***推广:*** 利用该算法可以识别营销模式。

## 随机森林的优势

*   它通过平均或加入各种选择树的结果来解决 ***过拟合*** 的问题。
*   随机森林比单独的选择树能更好地处理大范围的信息。
*   随机森林在这一点上的变化比单一选择树少。
*   随机森林是 ***真正适应性强的*** 和精度高的 ***。***
*   信息的缩放不需要随机森林算法。即使在没有缩放的情况下给出信息 ***后，它也能保持很高的精度。***
*   随机森林算法保持着令人难以置信的精确度，甚至有大量的数据丢失。

## 随机森林的缺点

*   随机森林被配备用于执行分类和回归任务。
*   它被配备用于处理具有 ***高维度的巨大数据集。***
*   它提高了模型的准确性，并且*防止了过拟合问题。*
*   多面性是随机森林算法的主要危害。
*   开发随机森林比选择树要困难和乏味得多。
*   需要更多的 ***计算资源*** 来实现随机森林算法。
*   当我们有一个*巨大的选择树*的分类时，这就不那么本能了。
*   利用随机森林的*期望周期*在不同算法的检验中非常繁琐。

## 随机森林的弱点

尽管随机森林可以用于表征和复发任务，但它并不更适合回归任务。

## 结尾注释

> 它依靠调查者来改变边界以提高精确度。由于它使用了基于标准的方法，因此过度拟合的可能性通常较小。

当我们试图避免构建选择树的过度拟合时，随机森林的功能令人钦佩。同样，当信息包含明确的因素时，它也能很好地工作。

就数字因素而言，不同的算法(如战略复发)可能会胜出，但当涉及到根据条件做出选择时，随机森林是理想的决定。

> 然而，再一次，它依赖于信息和审查员来选择最好的算法。

***要从头实现，请访问我的 GitHub 库—***

[](https://github.com/tanvipenumudy/Winter-Internship-Internity/blob/main/Day%209%20-%20Decision%20Tree%20%26%20Random%20Forest/Day-9%20Notebook-2%20%28Random%20Forest%29.ipynb) [## tanvipenumudy/Winter-实习-实习

### 存储库跟踪每天分配的工作-tanvipenumudy/Winter-实习-实习

github.com](https://github.com/tanvipenumudy/Winter-Internship-Internity/blob/main/Day%209%20-%20Decision%20Tree%20%26%20Random%20Forest/Day-9%20Notebook-2%20%28Random%20Forest%29.ipynb)