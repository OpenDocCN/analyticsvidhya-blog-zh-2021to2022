<html>
<head>
<title>LOGISTIC REGRESSION FOR CLASSIFYING CANCER BEHAVIORAL RISK</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">癌症行为风险分类的逻辑回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/logistic-regression-for-classifying-cancer-behavioral-risk-c9cfdadc800e?source=collection_archive---------17-----------------------#2021-01-26">https://medium.com/analytics-vidhya/logistic-regression-for-classifying-cancer-behavioral-risk-c9cfdadc800e?source=collection_archive---------17-----------------------#2021-01-26</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="0ca1" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="6528" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">线性模型是在实践中广泛使用的一类模型，在过去的几十年里得到了广泛的研究，其根源可以追溯到一百多年前。线性模型使用输入要素的线性函数进行预测。</p><p id="6945" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">线性模型也广泛用于分类。最常用的一种线性分类模型是逻辑回归。</p><p id="6e33" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">逻辑回归是机器学习从统计学领域借用的另一种技术。这是二元分类问题(具有两个类值的问题)的常用方法。</p><p id="2a5e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在本文中，我们将尝试使用逻辑回归对宫颈癌行为风险进行分类，这是一个二元分类问题(具有两个类值的问题)</p><p id="4d5a" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated"><strong class="je hi">免责声明</strong></p><p id="4889" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">作者不是卫生部门的专家，所以本文不应作为主要参考资料。</p><h1 id="a529" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">导入所需的库</h1><p id="0f79" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">首先，我们首先导入我们需要的库</p><blockquote class="kf kg kh"><p id="af0c" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated"><em class="hh">从matplotlib导入熊猫作为pd <br/>导入pyplot作为plt <br/> %matplotlib inline <br/>导入seaborn作为sns </em></p><p id="8c3c" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated"><em class="hh">从sklearn.model_selection导入train_test_split <br/>从sklearn.model_selection导入GridSearchCV <br/>从sklearn.linear_model导入LogisticRegression </em></p></blockquote><h1 id="23c3" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">关于数据集</h1><p id="46e0" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我们下载数据集，获取数据信息</p><blockquote class="kf kg kh"><p id="1a82" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">URL = '<a class="ae km" href="https://archive.ics.uci.edu/ml/machine-learning-databases/00537/sobar-72.csv'" rel="noopener ugc nofollow" target="_blank">https://archive . ics . UCI . edu/ml/machine-learning-databases/00537/sobar-72 . CSV '</a></p><p id="0619" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">data = pd.read_csv(url)</p><p id="b773" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">数据.形状</p><p id="9931" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">data.info()</p><p id="32f3" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">data . is null()values . any()</p><p id="b3e6" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">SNS . Count Plot(x = data . ca _子宫颈)<br/> plt.title('标签的计数图')<br/> plt.show()</p><p id="019a" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">label _ 0 = len(data[data . ca _宫颈= = 0])<br/>label _ 1 = len(data[data . ca _宫颈== 1])</p><p id="88cf" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">总计=标签_1 +标签_0</p><p id="1f7d" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">PC _ of _ 0 = label _ 0 * 100/total<br/>PC _ of _ 1 = label _ 1 * 100/total</p><p id="70c4" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">打印('无癌百分比:{:.0f} '。format(pc_of_0)) <br/>打印('无癌百分比:{:.0f} '。格式(第1页，共1页)</p></blockquote><p id="f82b" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">根据上面的信息，我们知道数据集有72个样本，包含20个特征。</p><p id="6ba2" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">一个特征(ca _子宫颈)是一个值为1的标签，表示样本有宫颈癌，值为0表示样本没有宫颈癌。从数据来看，大约71%的样本没有患宫颈癌，而大约29%的样本患有宫颈癌</p><p id="36e5" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">同样基于上述信息，数据集没有空值，因此我们可以继续下一步</p><h1 id="18b3" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">分割数据集</h1><p id="e9ed" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">将数据分为训练集和测试集的目的是为了使以后获得的模型在分类数据时具有良好的泛化能力。分类模型在训练集中很好地执行数据分类，但在分类新的和不存在的数据时表现很差，这种情况并不罕见。</p><blockquote class="kf kg kh"><p id="b974" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">数据集=数据.值</p><p id="16f0" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">X =数据集[:，:-1] <br/> y =数据集[:，-1]</p><p id="c863" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">X_train，X_test，y_train，y_test = train_test_split(X，y，random_state=42)</p><p id="2465" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">print('训练集的形状是'，(X_train.shape，y_train.shape)) <br/> print('测试集的形状是'，(X_test.shape，y_test.shape))</p></blockquote><h1 id="75b3" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">使用逻辑回归分类</h1><p id="da5c" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">逻辑回归是统计学中的一种数据分析技术，旨在确定几个变量之间的关系，其中响应变量是分类的，包括名义变量和顺序变量，解释变量是分类的或连续的。二元逻辑回归是一种数学模型方法，用于分析几个因素和二元变量之间的关系。在逻辑回归中，如果响应变量包含两个类别，例如Y = 1表示获得的结果“成功”, Y = 0表示获得的结果“失败”,则逻辑回归使用二元逻辑回归。</p><p id="bbba" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在本文中，我们将使用默认参数值和使用网格搜索指定的参数值进行逻辑回归。然而，具体到规划求解，我们将使用liblinear。这是因为我们将使用的分类是二元分类，数据集属于小数据集类别</p><p id="cca2" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">逻辑回归的主要参数是正则化，称为C。C的小值表示简单模型。因此，调整这些参数尤其重要。</p><p id="0f80" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">你要做的另一个决定是你想使用L1正则化还是L2正则化。如果你假设你的特性中只有少数是真正重要的，你应该使用L1。否则，您应该默认为L2。如果模型的可解释性很重要，L1也是有用的。由于L1将只使用少数几个特征，这就更容易解释哪些特征对模型是重要的，以及这些特征的作用是什么。</p><p id="0af9" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">所以，我们将只在第二种方法中设置2个参数，即C和penalty</p><p id="db79" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们可以用一个新的缺省的线性和参数解算器进行逻辑回归。</p><blockquote class="kf kg kh"><p id="1488" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">log reg = LogisticRegression(solver = ' liblinear ')</p><p id="1c88" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">logreg.fit(X_train，y_train)</p><p id="2fd2" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">打印('分数训练集:{:.3f} '。格式(logreg.score(X_train，y _ train))<br/>打印('分数测试集:{:.3f} '。格式(logreg.score(X_test，y_test)))</p></blockquote><p id="5e13" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在默认值下，逻辑回归在训练集上提供100%的准确度，在测试集上提供83.3%的准确度。这说明我们过度拟合了。</p><p id="3522" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">接下来，我们设置C和惩罚参数。我们使用交叉验证值为5的网格搜索来确定C参数和最佳惩罚</p><blockquote class="kf kg kh"><p id="7930" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">param_grid = {'C':[0.001，0.01，0.1，1，10，100]，' penalty':['l1 '，' l2']}</p><p id="1479" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">grid _ search = GridSearchCV(log reg，param_grid，cv=5)</p><p id="f913" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">grid_search.fit(X_train，y_train)</p><p id="445f" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">打印('最佳参数:{} '。format(grid _ search . Best _ params _)<br/>print('最佳交叉验证分数:{:.3f} '。格式(grid _ search . best _ score _)<br/>打印('测试集分数:{:.3f} '。格式(grid_search.score(X_test，y_test)))</p></blockquote><p id="ff4d" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">验证集上最好的分数是91%，比以前低，可能是因为我们使用了更少的数据来训练模型(X_train现在变小了，因为我们对数据集进行了两次拆分)。然而，测试集上的分数——实际上告诉我们概括得有多好的分数——变成了89%,比以前更好。</p><h1 id="ad9b" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">结论</h1><p id="3409" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">逻辑回归可用于估计上述数据集中的癌症风险。</p><p id="2614" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">使用默认值(使用liblinear解算器)我们得到83.3%的分数准确度。同时，如果我们使用交叉验证值为5的网格搜索找到的参数(使用liblinear求解器)，我们会得到88.9%的准确率。</p><h1 id="42e5" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">参考</h1><ol class=""><li id="1236" class="kn ko hh je b jf jg jj jk jn kp jr kq jv kr jz ks kt ku kv bi translated"><a class="ae km" href="https://archive.ics.uci.edu/ml/datasets/Cervical+Cancer+Behavior+Risk" rel="noopener ugc nofollow" target="_blank">https://archive . ics . UCI . edu/ml/datasets/宫颈癌+癌症+行为+风险</a></li><li id="a1a7" class="kn ko hh je b jf kw jj kx jn ky jr kz jv la jz ks kt ku kv bi translated">安德烈亚斯·穆勒和萨拉·圭多。Python机器学习简介</li><li id="d28a" class="kn ko hh je b jf kw jj kx jn ky jr kz jv la jz ks kt ku kv bi translated"><a class="ae km" href="https://machinelearningmastery.com/logistic-regression-for-machine-learning/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/logistic-regression-for-machine-learning/</a></li></ol><p id="fc7f" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">完整的代码你可以访问<a class="ae km" href="https://github.com/dhiboen/Project/blob/main/Untitled3.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a></p></div></div>    
</body>
</html>