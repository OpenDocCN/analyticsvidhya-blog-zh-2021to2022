<html>
<head>
<title>Neural Networks In a Nutshell.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简而言之就是神经网络。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/neural-networks-in-a-nutshell-bb013f40197d?source=collection_archive---------8-----------------------#2021-02-14">https://medium.com/analytics-vidhya/neural-networks-in-a-nutshell-bb013f40197d?source=collection_archive---------8-----------------------#2021-02-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/1f6c3d9026cc07a3b69be30a9da66b8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*FaI8y0j15hB70kbj"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">艾莉娜·格鲁布尼亚克在<a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="bd0f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我将尽我最大的努力呈现一个关于神经网络如何工作的透明视图，这样到本文结束时，你可能会对这个主题有一个扎实的了解。</p><blockquote class="js jt ju"><p id="53c4" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">关注神经网络的理由</p></blockquote><p id="8a71" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因为机器学习算法现在被递归地用于预测各种情况，如癌症、股票等。神经网络项目的数量正以指数速度增长。我们也可以说，神经网络位于革命性机器学习项目的核心。</p><p id="ffdb" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="jv">让我们了解一下他们</em></p><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es jz"><img src="../Images/359d519b218d7aa972bff09adcef71e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*ouEpYDyi7QfYOcUz-ihWnA.png"/></div></figure><p id="458b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">人工神经网络受到生物神经网络的启发。</p><p id="f829" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">就像生物神经网络一样，人工神经网络也在不断地学习和更新它的知识，以及基于它所遇到的经验对环境的理解。</p><p id="6eb2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">人工神经网络只是一组数学算法，它们一起工作以对输入执行操作。这些操作然后产生一个输出。</p><p id="9f5a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，这些数学上相互关联的公式被称为人工神经网络(ANN)。</p><p id="2bd1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">神经网络可以帮助我们理解复杂数据结构之间的关系。神经网络可以使用经过训练的知识对复杂结构的行为进行预测。他们可以处理图像，甚至做出复杂的决定，比如如何驾驶汽车，或者下一步进行哪项金融交易。</p><p id="e4ef" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">虽然神经网络可能很复杂，可以解决复杂的问题，但它们比大多数机器算法都要慢。他们也可能最终过度拟合训练数据。</p><blockquote class="js jt ju"><p id="b807" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">它是如何工作的？</p></blockquote><figure class="ka kb kc kd fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ke"><img src="../Images/6f7fa6af1ae2b22aa12fbf9a4a5710e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ub-ifcgdi9xgryqvo0_GRA.png"/></div></div></figure><p id="158a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们回顾一下这个神经网络</p><p id="5229" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">神经网络可以包含多个层。上面所示的人工神经网络有5层:</p><ol class=""><li id="c2ce" class="kf kg hh iw b ix iy jb jc jf kh jj ki jn kj jr kk kl km kn bi translated">一个输入层</li><li id="7a58" class="kf kg hh iw b ix ko jb kp jf kq jj kr jn ks jr kk kl km kn bi translated">一个输出层</li><li id="a2a5" class="kf kg hh iw b ix ko jb kp jf kq jj kr jn ks jr kk kl km kn bi translated">三个隐藏层</li></ol><p id="bef2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">忽略第n个输入，总共有12个神经元:</p><ol class=""><li id="7770" class="kf kg hh iw b ix iy jb jc jf kh jj ki jn kj jr kk kl km kn bi translated">2个输入神经元</li><li id="ca32" class="kf kg hh iw b ix ko jb kp jf kq jj kr jn ks jr kk kl km kn bi translated">9个隐藏神经元—每个隐藏层中有3个神经元</li><li id="1629" class="kf kg hh iw b ix ko jb kp jf kq jj kr jn ks jr kk kl km kn bi translated">2个输出神经元</li></ol><p id="7512" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是一个前馈神经网络，因为数据只在一个方向上流动，从输入层到输出层。</p><ul class=""><li id="4c89" class="kf kg hh iw b ix iy jb jc jf kh jj ki jn kj jr kt kl km kn bi translated">每个神经元通过突触与另一个神经元相连。</li><li id="04d8" class="kf kg hh iw b ix ko jb kp jf kq jj kr jn ks jr kt kl km kn bi translated">每个神经元从一个或多个神经元接收输入，以及权重和偏差，我稍后会详细解释。</li></ul><blockquote class="js jt ju"><p id="e07e" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">什么是神经元？</p></blockquote><figure class="ka kb kc kd fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ku"><img src="../Images/82c59add0e43ed046e4abad8e42e6bd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RwLOqQj__8I6C9yyYTXr6w.png"/></div></div></figure><p id="f263" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">神经元是一个容器，它包含一个被称为<strong class="iw hi">激活函数的数学函数、</strong>输入(x1和x2)、一个权重向量(w1，w2)和一个偏差(b)。</p><p id="3700" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">神经元首先计算输入的加权和。</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es kv"><img src="../Images/76dc542e21a2d7e2bf598a581535379c.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*V1mNUbnpA7thNIUCHJNpuA.png"/></div></figure><p id="01f2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">将激活函数视为一种数学运算，它将输入归一化并产生一个输出。然后输出被向前传递到下一层的神经元上。</p><blockquote class="js jt ju"><p id="59b7" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">了解神经网络层</p></blockquote><p id="c8c0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">总会有一个输入和输出层。在一个神经网络中，我们可以有零个或多个隐藏层。<em class="jv">神经网络的学习过程是用层来执行的。</em>需要注意的关键是，神经元是分层放置的，每层都有其用途。在神经网络的每一层中，神经元执行相同的功能。它们只是计算输入和权重的加权和，加上偏差并执行一个激活函数。</p><blockquote class="kw"><p id="6c04" class="kx ky hh bd kz la lb lc ld le lf jr dx translated">让我们分别理解每一层</p></blockquote><blockquote class="js jt ju"><p id="be06" class="iu iv jv iw b ix lg iz ja jb lh jd je jw li jh ji jx lj jl jm jy lk jp jq jr ha bi translated"><strong class="iw hi">输入图层</strong></p></blockquote><p id="2bf9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">输入层负责接收输入。神经网络中必须始终有一个输入层。</p><p id="f8b8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">输入层接收输入，通过其神经元执行计算，然后将输出传输到后续层。输入层接受输入。输出层产生最终结果。</p><blockquote class="js jt ju"><p id="d478" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated"><strong class="iw hi">输出层</strong></p></blockquote><p id="a80c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">输出层负责产生最终结果。神经网络中必须始终有一个输出层。</p><p id="0a40" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">输出层接收从它之前的层传入的输入，通过它的神经元执行计算，然后计算输出。</p><p id="acc3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在具有多个隐藏层的复杂神经网络中，输出层接收来自前一个隐藏层的输入。</p><blockquote class="js jt ju"><p id="1b73" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated"><strong class="iw hi">隐藏层</strong></p></blockquote><p id="1c7a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">隐含层的引入使得神经网络优于大多数机器学习算法。隐藏层位于输入和输出层之间，这是它们被称为<em class="jv">隐藏</em>的主要原因。“隐藏”一词意味着它们对外部系统不可见，对神经网络是“私有的”。</p><p id="7979" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在一个神经网络中可以有零个或多个隐藏层。</p><p id="3594" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">神经网络中的隐藏层数越多，神经网络产生输出所需的时间就越长，并且神经网络可以解决的问题就越复杂。</p><p id="c282" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">神经元简单地计算输入和权重的加权和，加上偏差并执行激活函数。</p><blockquote class="js jt ju"><p id="20f8" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated"><strong class="iw hi">激活功能</strong></p></blockquote><p id="51f3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">激活函数只不过是一个接受输入并产生输出的数学函数。当计算结果达到指定阈值时，该功能被激活。这种情况下的输入是加权和加偏差:</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ll"><img src="../Images/c68b87e8fe53b02150ede331cd472ec5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*CA3YaYR6qiA0sUBveckNyQ.png"/></div></div></figure><p id="78c3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">并且阈值在函数中预定义。激活函数的这一本质会给输出增加非线性。随后，激活函数的这一特性使得神经网络能够解决非线性问题。非线性问题是那些输入和输出之间没有直接线性关系的问题。</p><p id="6d8d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了处理这些复杂的情况，引入了许多可以在输入端配置的激活功能。</p><p id="f7de" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们回顾一些常见的激活功能。在我们深入研究每个激活函数之前，请看一下这个表。我正在演示五个最著名的激活函数的值是如何不同的，我将详细解释。</p><p id="3790" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="jv">每个激活功能都有自己的公式，用于转换输入。</em></p><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es lm"><img src="../Images/5e243a3881d26501d39c4ada9e11cc8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*mIzcD05pLDhqsEHPEotpxA.png"/></div></figure><blockquote class="js jt ju"><p id="05d0" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">线性激活函数:</p></blockquote><p id="fef3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">激活函数只是用一个因子来缩放输入，这意味着输入和输出之间存在线性关系。</p><p id="d8b7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是数学公式:</p><p id="a94e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">产量= Y*X </strong></p><figure class="ka kb kc kd fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ln"><img src="../Images/84038f3511d2825a8e248edf4afcc9f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-nXC4OGbNHs2gbKdWDzCjg.png"/></div></div></figure><blockquote class="js jt ju"><p id="8760" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">乙状结肠激活功能:</p></blockquote><p id="a988" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">乙状结肠激活函数是“S”形的。它可以向输出添加非线性，并返回二进制值0或1。</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es lo"><img src="../Images/d7025d160f64e8637f516c7cb6687423.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/1*BwZmaMBaVW8f8lBAQUoytw.png"/></div></figure><blockquote class="js jt ju"><p id="6aed" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">Tanh激活功能:</p></blockquote><p id="0727" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Tanh是sigmoid激活函数的扩展。因此，Tanh可以用来增加输出的非线性。输出在-1到1的范围内。双曲正切函数移动sigmoid激活函数的结果:</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lp"><img src="../Images/cd8193999a374337ab8bc1e97befdd88.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*XN9vplm0XpPn9sTcRG71Yw.png"/></div></div></figure><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/826661c40fd596264fe2716dfee14064.png" data-original-src="https://miro.medium.com/v2/resize:fit:646/format:webp/1*jN8wevzcbhZmOXm_ElTUng.png"/></div></figure><blockquote class="js jt ju"><p id="6b49" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">校正线性单位激活函数(RELU)</p></blockquote><p id="dfc9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">RELU是最常用的激活函数之一。在隐藏层中最好使用RELU。这个概念非常简单。它还会增加输出的非线性。但是，结果的范围可以从0到无穷大。</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/882c3411dc8c93b69aa0da41e1fc2ea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/format:webp/1*AzbcenVIbcrXWv8Vey-Qtw.png"/></div></figure><blockquote class="js jt ju"><p id="be27" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">Softmax激活功能:</p></blockquote><p id="588e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Softmax是Sigmoid激活函数的扩展。Softmax函数增加了输出的非线性，但是，它主要用于可以计算多类结果的分类示例。</p><figure class="ka kb kc kd fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ke"><img src="../Images/2b7bc1de7720d9bf4c3aaf9e7843834d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iRG_C_FWeJItR8PYckk9nA.png"/></div></div></figure><p id="63cd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">激活函数将输入标准化，并产生从0到1的值范围。</p><p id="2c8f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="jv">权重和偏差可以改变神经网络的运行方式。</em></p><blockquote class="js jt ju"><p id="65d4" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">什么是偏见？</p></blockquote><p id="cd6e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">偏差只是一个常量值(或常量向量),加到输入和权重的乘积上。利用偏差来抵消结果。</p><p id="2fba" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">该偏置用于将激活函数的结果向正侧或负侧移动。</p><blockquote class="js jt ju"><p id="e4e8" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">什么是重量？</p></blockquote><p id="3038" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">权重可能是神经网络最重要的概念。当输入在神经元之间传输时，权重被应用于输入，并与偏差一起传递到激活函数中。权重本质上反映了输入的重要性。</p><p id="a6d2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当在训练集上训练神经网络时，它用一组权重进行初始化。然后在训练期间优化这些权重，并产生最佳权重。</p><p id="7457" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">权重是你试图求解的方程的系数。负权重会降低产出的价值。</p><blockquote class="js jt ju"><p id="de5e" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">学习率:</p></blockquote><p id="4d55" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">学习率决定了我们想要更新权重的速度。学习率越低，优化算法达到局部极小点和收敛的时间越长。另一方面，如果学习率很大，那么它可能永远不会收敛并达到局部最小点。因此，需要正确的平衡。</p><p id="cee8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在优化算法中使用学习率来更新权重。</p><blockquote class="js jt ju"><p id="0d0f" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">纪元:</p></blockquote><p id="a6de" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">历元是学习算法的输入参数之一。认为epoch有一个循环。它决定了学习算法更新权重的次数。</p><p id="cac7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果epoch的值为1，则意味着训练集中的每个数据集将被送入神经网络以更新权重。</p><p id="0f9e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果时期是5，则意味着将有5个循环。</p><blockquote class="js jt ju"><p id="1923" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">损失和准确性:</p></blockquote><p id="9cba" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">损失函数也称为成本函数。他们计算误差值。</p><p id="2ff1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">准确地说，成本函数是损失函数的平均值。这是优化算法试图最小化的函数。有大量的损失函数可用，如均方误差，二元交叉熵等。</p><p id="08ff" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">损失函数本质上告诉神经网络它需要执行什么动作来提高精度。优化器利用这些信息来产生准确的权重。</p><p id="2b58" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">神经网络然后可以向前传播输入数据。</p><blockquote class="js jt ju"><p id="504c" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">正向传播:</p></blockquote><p id="8b25" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">正向传播过程也称为推理。这是最简单的神经网络形式，它接受输入，处理它们，并把它们传递给随后的层；一直到输出层的神经元。</p><p id="9fa9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">每个神经元将权重与偏差一起应用于输入，并计算适当的激活函数。</p><blockquote class="js jt ju"><p id="e518" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">反向传播:</p></blockquote><p id="3ffc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">反向传播采用预测值和实际值之间的差异来进一步增强权重。</p><p id="0ee7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，计算误差值相对于每个重量的偏导数。导数是指斜率的梯度，从最后一层开始计算。然后，导数用于计算前一层的<em class="jv">梯度</em>，然后重复该过程。对每一层中的每个重量重复该过程。</p><p id="f8d5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从<em class="jv">误差值中减去<em class="jv">权重值</em>的值，以确保精度得到提高。注:误差值是预测值和实际值之间的差值。</em></p><p id="0a29" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当我们从最后一层向后移动到第一层时，这个过程被称为反向传播。它还可以将漏失应用到权重。</p><blockquote class="js jt ju"><p id="931e" class="iu iv jv iw b ix iy iz ja jb jc jd je jw jg jh ji jx jk jl jm jy jo jp jq jr ha bi translated">辍学:</p></blockquote><p id="4f71" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">Dropout用于将权重设置为零。这个过程将权重随机设置为0，从而增强了网络的预测。</p><p id="2d2b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">希望这篇文章有所帮助。</strong></p></div></div>    
</body>
</html>