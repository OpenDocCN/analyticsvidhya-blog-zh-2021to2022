<html>
<head>
<title>The Story of DCGANs, WGAN and CGANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">DCGANs、WGAN和cgan的故事</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/the-story-of-dcgans-wgan-and-cgans-c0182ad014bd?source=collection_archive---------7-----------------------#2021-08-13">https://medium.com/analytics-vidhya/the-story-of-dcgans-wgan-and-cgans-c0182ad014bd?source=collection_archive---------7-----------------------#2021-08-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="b1cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对GANs的选定变体及其定义概念的介绍。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/933ba0556da28a78f59d8eb74a98b3ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WPdc8xZbKclXS19OY6yeZQ.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jt" href="https://www.pexels.com/@suzyhazelwood" rel="noopener ugc nofollow" target="_blank">苏西·黑兹尔伍德</a></figcaption></figure></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="f3fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">嗖！我终于让自己写下我的想法。这篇文章将带你了解我对某些gan变体的发现，以及它们之间的区别。如果你像我一样是一个数据科学爱好者，我敢肯定你已经发现了GANs的概念及其巨大的可能性。</em></p><p id="b1c3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">我们将在本文中讨论的重点:</strong></p><ul class=""><li id="3993" class="kb kc hh ig b ih ii il im ip kd it ke ix kf jb kg kh ki kj bi translated">GANs的简要概述</li><li id="eb27" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">深度卷积生成对抗网络</li><li id="1c85" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">沃瑟斯坦生成对抗网络</li><li id="7c16" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">条件生成广告串行网络</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kp"><img src="../Images/f8ab21af468f18a270e89dde77dff89d.png" data-original-src="https://miro.medium.com/v2/resize:fit:490/1*O6ZlCS4r_7Ck4taQEmfJeQ.gif"/></div></figure><h1 id="45c2" class="kq kr hh bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated"><strong class="ak"> <em class="lo">甘斯</em> </strong>概述</h1><p id="efbf" class="pw-post-body-paragraph ie if hh ig b ih lp ij ik il lq in io ip lr ir is it ls iv iw ix lt iz ja jb ha bi translated"><strong class="ig hi">生成对抗网络(GANs) </strong>由<strong class="ig hi"> Ian </strong> <strong class="ig hi"> Goodfellow等人</strong>提出。在最初的设置中，GANs由一个发生器和一个鉴别器组成，它们被训练成具有竞争目标。该发生器被训练以产生朝向真实数据分布的样本来欺骗鉴别器，而鉴别器被优化以区分来自真实数据分布的真实样本和由发生器产生的假样本。</p><p id="c538" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">用图形术语来说，生成者是艺术伪造者，鉴别者是艺术专家或艺术评论机构请来辨别真艺术和假艺术的人。这比这复杂得多，但它解释了他们的基本作用。这是神经网络的一个有趣的应用。随着我们的深入，我们将看到它是如何在不同的变化中成为可能的。最近，GANs在模拟复杂的数据分布方面显示出巨大的潜力，例如文本、图像和视频。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lu"><img src="../Images/a9c89bd36e5a45f03f9caec4bbad0813.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/1*GeFQ-j0EkP0ViN83rW0--g.gif"/></div></figure><h1 id="cf2d" class="kq kr hh bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">DCGANs</h1><p id="ce29" class="pw-post-body-paragraph ie if hh ig b ih lp ij ik il lq in io ip lr ir is it ls iv iw ix lt iz ja jb ha bi translated"><strong class="ig hi">深度卷积GANs </strong>是一种不太复杂且易于实现的变异GANs，由<a class="ae jt" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Radford%2C+A" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="jc">亚历克</em> <em class="jc">拉德福德</em></strong></a><em class="jc"/><strong class="ig hi"><em class="jc"/></strong><a class="ae jt" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Metz%2C+L" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi"><em class="jc">卢克·梅斯</em> </strong> </a>和<a class="ae jt" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chintala%2C+S" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi"> <em class="jc">苏密特·钦塔拉</em> </strong> </a>在一篇论文中称之为<a class="ae jt" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank"/></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/c306653f6ae51c7e027acb559cbf902d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QX2UOM40ShuP9FTCCeMefw.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">DCGAN发生器架构</figcaption></figure><p id="5c88" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是用于LSUN场景建模论文的DCGANs生成器的图示，它采用形状为100x1x1的随机噪声向量，表示为Z，并被传递到生成器网络，该网络将其映射到形状为64x64x3的G(Z)输出。该网络包含转置的CNN层，其对输入张量进行上采样，应用批量归一化，并且除了包含在[-1，1]范围内缩放图像的Tanh激活的最后一层之外，每一层都具有Relu激活。</p><p id="38b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如图所示的第一层将输入从100x1x1扩展到1024x4x4，这一层称为<strong class="ig hi"> <em class="jc">项目和整形</em> </strong>。在这一层之后，应用经典的卷积层，这利用与卷积层相关联的<em class="jc">(N+P-F)/S+1</em>等式来重塑网络。我们可以看到<em class="jc"> N参数(身高，体重)</em>从4到8到16到32，内核过滤器<em class="jc"> F </em>是5x5，步幅<em class="jc"> S </em>是2，似乎没有填充。</p><p id="cd31" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">网络从100 x1x 1→1024 x4x 4→512 x8x 8→256 x16x 16→128 x32x 32→64 x64x 3。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/53b575a8c411747e9d5c0769cc42d057.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fjZcXfvlSQiQeYt3fHA9rw.png"/></div></figure><p id="c867" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的图像是生成器经过5个时期的训练后产生的令人印象深刻的输出。</p><h2 id="1dae" class="lw kr hh bd ks lx ly lz kw ma mb mc la ip md me le it mf mg li ix mh mi lm mj bi translated">DCGANs的关键概念</h2><ul class=""><li id="85fa" class="kb kc hh ig b ih lp il lq ip mk it ml ix mm jb kg kh ki kj bi translated">它由像其他GAN一样的神经网络组成，即<strong class="ig hi">发生器</strong>和<strong class="ig hi">鉴别器</strong>。</li><li id="a48e" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated"><strong class="ig hi">鉴别器</strong>将生成的图像和真实图像作为输入，并输出一个介于0和1之间的值，即图像是真实还是虚假的置信度。</li><li id="477e" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated"><strong class="ig hi">发生器</strong>看不到真实图像，它通过<strong class="ig hi">鉴频器</strong>的反馈进行学习。</li><li id="c935" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">在<strong class="ig hi">鉴别器</strong>和<strong class="ig hi">发生器</strong>中，分别用步长卷积和分数步长卷积代替池层。</li><li id="59ab" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">在<strong class="ig hi">发生器</strong>和<strong class="ig hi">鉴别器</strong>中都使用了批量归一化。</li><li id="106e" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">使用更深的架构，而不是完全连接的隐藏层。</li><li id="00d2" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">ReLu激活在<strong class="ig hi">发生器</strong>中用于所有层，除了使用Tanh激活的输出层。</li><li id="468b" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">LeakyReLu激活用于<strong class="ig hi">鉴别器</strong>中的所有层。</li><li id="4ed2" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">使用小批量随机梯度下降(SGD)训练模型，小批量大小为128。</li><li id="8dc5" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">二元交叉熵损失(BCE)函数用于<strong class="ig hi">发生器</strong>。</li></ul><h2 id="5c27" class="lw kr hh bd ks lx ly lz kw ma mb mc la ip md me le it mf mg li ix mh mi lm mj bi translated">DCGANs的约束</h2><p id="ac9e" class="pw-post-body-paragraph ie if hh ig b ih lp ij ik il lq in io ip lr ir is it ls iv iw ix lt iz ja jb ha bi translated">DCGANs的一些局限性是由BCE损失函数造成的，即:</p><ul class=""><li id="29c9" class="kb kc hh ig b ih ii il im ip kd it ke ix kf jb kg kh ki kj bi translated"><strong class="ig hi"> <em class="jc">模式崩溃:</em> </strong>这用于描述GANs网络无法生成分布的不同类别，例如MNIST，GANs可能只能从10个可能的类别中生成一个类别，在Dog实施中，模型可能只能在许多可能的可用种类中生成一个种类的狗。</li><li id="a0c7" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated"><strong class="ig hi"> <em class="jc">消失梯度:</em></strong><strong class="ig hi">鉴别器</strong>的置信水平是一个只能在0和1之间的单一值，目标是使该值尽可能接近1，因此当计算出的梯度接近0时，<strong class="ig hi">发生器</strong>无法获得太多信息，使其无法学习，这留给我们一个强<strong class="ig hi">鉴别器</strong>和一个弱<strong class="ig hi">发生器</strong>。</li></ul><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mn"><img src="../Images/95b32ace2312bf960e952e5acfc3e3f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:996/1*4iPZY3lvSA3wCj7pQ1y8fA.gif"/></div></figure><h1 id="b4e7" class="kq kr hh bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">WGAN</h1><p id="1030" class="pw-post-body-paragraph ie if hh ig b ih lp ij ik il lq in io ip lr ir is it ls iv iw ix lt iz ja jb ha bi translated"><strong class="ig hi">瓦瑟斯坦·甘</strong>是由<a class="ae jt" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Arjovsky%2C+M" rel="noopener ugc nofollow" target="_blank"> <em class="jc">马丁·阿约夫斯基</em></a><em class="jc"/><a class="ae jt" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Chintala%2C+S" rel="noopener ugc nofollow" target="_blank"><em class="jc">苏密特·钦塔拉</em></a><em class="jc"/><a class="ae jt" href="https://arxiv.org/search/stat?searchtype=author&amp;query=Bottou%2C+L" rel="noopener ugc nofollow" target="_blank"><em class="jc">莱昂·博托</em> </a>在一篇论文中提出的，命名为<a class="ae jt" href="https://arxiv.org/abs/1701.07875" rel="noopener ugc nofollow" target="_blank"> <em class="jc">瓦瑟斯坦·甘</em> </a> <em class="jc">。</em>该算法被引入作为传统GANs训练的替代方案，在该模型中，学习的稳定性被提高，并且模式崩溃等问题被处理。</p><p id="5a8a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与DCGANs不同，在本文中，<strong class="ig hi"> <em class="jc"> EM距离</em> </strong>也被称为<strong class="ig hi"> <em class="jc"> wasserstein距离</em> </strong>被引入作为度量，EM距离是将一个分布移动到另一个分布的努力量，即你应该花费多少工作来将该分布运输到另一个分布。值为正，形状对称。EM距离有两个属性:</p><ol class=""><li id="7806" class="kb kc hh ig b ih ii il im ip kd it ke ix kf jb mo kh ki kj bi translated"><strong class="ig hi">该功能在任何地方都是连续的</strong></li><li id="4a94" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb mo kh ki kj bi translated"><strong class="ig hi">函数的梯度几乎无处不在</strong></li></ol><p id="8b80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">利用这两个性质，我们能够避免消失梯度的问题，并且能够继续训练和更新我们的模型，直到它收敛。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mp"><img src="../Images/670e49ea03f4c50c292b8e6c71a7de1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_Uu1zHKlMasujh1iGQt6pg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">EM-距离的对偶关系</figcaption></figure><p id="55f5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，在寻找下确界时，很难穷尽联合分布中所有可能的样本。使用<em class="jc"> Kantorovich-Rubinstein对偶方法</em>，该问题可以近似为其对偶格式，我们继续寻找其上确界。这两种形式之间的关系如上所示。<strong class="ig hi"> <em class="jc">唯一的约束条件是函数应该是Lipschitz-1连续函数</em> <em class="jc">，即梯度的范数在每一点上必须最大为1</em>。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mq"><img src="../Images/0b684e4f4d905c5cffa6fb24eed48167.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*xqbtEDSsMYNJFvwTe_JzrA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">WGAN的目标。</figcaption></figure><p id="7e5b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在<strong class="ig hi"> DCGANs </strong>中，我们总是以最大化分类得分为目标。如果图像是假的，<strong class="ig hi">鉴别器</strong>给它一个分值0，如果图像是真的，<strong class="ig hi">鉴别器</strong>给它一个分值1。在<strong class="ig hi"> WGAN </strong>中，鉴别器的任务变成了更多的回归问题，马丁将其重命名为<strong class="ig hi">批评家</strong>。评论家应该测量EM-distance <em class="jc">，即应该花费多少工作</em>，并找到上图所示的最大值。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mr"><img src="../Images/c760679d6869a1de837010880560bafc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d8lO5nQcbE9FKLBmvlCbVg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">WGAN算法</figcaption></figure><p id="f459" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上图所示为<strong class="ig hi"> WGAN </strong>的训练过程，与普通GAN相似，主要区别在于:</p><ul class=""><li id="712c" class="kb kc hh ig b ih ii il im ip kd it ke ix kf jb kg kh ki kj bi translated">评论家多次更新。</li><li id="5c38" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">我们在计算损失时不使用交叉熵，即我们不需要取对数。</li><li id="2efb" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">应进行权重裁剪，以满足<strong class="ig hi"> <em class="jc"> Lipschitz连续性</em> </strong>的约束。</li><li id="7a2e" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">不要使用像Adam optimizer这样的基于动量的优化器。</li></ul><p id="4f0f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了加强<strong class="ig hi"> <em class="jc"> Lipschitz连续性</em> </strong>，进行了权重裁剪。减肥有它自己的缺点，在这篇<a class="ae jt" rel="noopener" href="/@sunnerli/the-story-about-wgan-784be5acd84c">文章</a>中有详细的讨论。提出了另一种达到<strong class="ig hi"> <em class="jc"> Lipschitz连续性</em> </strong>极限的方法:将极限项合并到损失函数中。这种变化的思想类似于在SVM机制中加入约束项。唯一的区别是拉格朗日乘数，这是应该通过二次规划找到的最佳参数，但我们只需要在<strong class="ig hi"> WGAN </strong>中将它设置为常数。这一项叫做<strong class="ig hi">梯度惩罚</strong>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ms"><img src="../Images/555f05a9759e55c6a6411a71ceb7542f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1102/format:webp/1*93jkRJeg4Dj_OUfofq35AQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">WGAN-GP中的修订目标</figcaption></figure><p id="053e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上图显示了修改后的损失函数。然而，在<strong class="ig hi"> <em class="jc"> Lipschitz连续性</em> </strong>的定义中，我们要穷尽联合分布中所有可能的样本。作者声称我们根本不需要考虑整个样本。事实上，有人建议我们只需要生成两个分布之间的组合，并且<strong class="ig hi">只对这些中间样本</strong>进行惩罚。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/95275afbd94e5751691e49b934a8e402.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*beBPhmaVZ3ZV2XVGKNWUKQ.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">WGAN-GP算法。</figcaption></figure><p id="4cd8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上图是修改后的训练流程，它被赋予了另外一个名字:<strong class="ig hi"> WGAN-GP </strong>。在这个版本中，可以使用基于动量的优化器来更新模型，并且不会导致损失爆炸错误。在更新批评时，损失函数中应加入梯度惩罚项。</p><p id="6d1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有一点你要记住:B <strong class="ig hi">不应该使用补丁规范化</strong>！在Kantorovich-Rubinstein的对偶理论中，每一对的梯度都是唯一的。然而，批量规范化会打乱这种情况，并使映射受到干扰。因此，建议在结构中使用层标准化(或其他方法)。这篇<a class="ae jt" rel="noopener" href="/@sunnerli/the-story-about-wgan-784be5acd84c"> <em class="jc">文章</em> </a>对于详细阐述<strong class="ig hi"> WGAN </strong>和<strong class="ig hi"> WGAN-GP </strong>的概念确实很有帮助。</p><h1 id="e694" class="kq kr hh bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">CGANs</h1><p id="fab1" class="pw-post-body-paragraph ie if hh ig b ih lp ij ik il lq in io ip lr ir is it ls iv iw ix lt iz ja jb ha bi translated"><strong class="ig hi">条件甘(cgan)</strong>是甘的一个更加平和的变体。顾名思义，CGANs可以生成具有特定条件或特征的图像。</p><p id="1c02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">像前面讨论的GANs的两种变体一样，<strong class="ig hi"> CGANs </strong>有两个组件一个<strong class="ig hi">发生器</strong>和一个<strong class="ig hi">鉴别器</strong>。<strong class="ig hi"> CGANs </strong>与之前讨论的变体的不同之处在于<strong class="ig hi">发生器</strong>和<strong class="ig hi">鉴别器</strong>接收额外的调节输入信息，该信息可以是一类当前图像或一些其他优先级。这是它比<strong class="ig hi"> DCGANs </strong>更酷的地方，我们无法控制它生成什么类。在<strong class="ig hi"> CGANs </strong>中解决了<strong class="ig hi"> DCGANs </strong>的特定问题，我们添加了一个额外的输入层，其中包含一个热编码图像标签的值。</p><h2 id="ad25" class="lw kr hh bd ks lx ly lz kw ma mb mc la ip md me le it mf mg li ix mh mi lm mj bi translated">CGANs的优先级</h2><ul class=""><li id="63f5" class="kb kc hh ig b ih lp il lq ip mk it ml ix mm jb kg kh ki kj bi translated">添加一个特征向量来引导和控制生成器的输出，它帮助生成器弄清楚该做什么。</li><li id="87a7" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">向量特征应该对我们想要生成的图像的类别或者我们期望图像拥有的一组特定特征进行编码。</li><li id="9fa1" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">我们将信息整合到将要学习的图像中，也整合到Z输入中，这不再是随机的。</li><li id="e810" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated"><strong class="ig hi">鉴别器的</strong>评估不仅针对伪数据和原始数据之间的相似性，还针对伪图像与其输入标签(或特征)之间的对应性。</li><li id="e5d4" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated">我们可以像对<strong class="ig hi"> DCGANs </strong>那样做，但是必须在<strong class="ig hi">发生器</strong>和<strong class="ig hi">鉴别器</strong>上施加一个独热向量形式的条件。</li></ul><p id="5a2d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">注:cgan</em></strong><em class="jc">并不是严格意义上的无人监管，它们需要某种标签才能工作。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mt"><img src="../Images/7b792b1c547172c4bb9eea1c72794f6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*tEWmyCbbaUxmgwxog5XL9g.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">CGANs示意图</figcaption></figure><p id="29ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> CGANs </strong>的<strong class="ig hi">鉴别器</strong>和<strong class="ig hi">发生器</strong>模型与<strong class="ig hi"> DCGANs </strong>相似，不同之处在于用于调节<strong class="ig hi">鉴别器</strong>和<strong class="ig hi">发生器</strong>的独热向量。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/14c3c99cf750f93198ef5dbf19219f99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kYMbk-D1aLoWLwn06GBz9g.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">CGANs架构</figcaption></figure><p id="2fcf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">鉴别器有两个任务</strong></p><ol class=""><li id="a742" class="kb kc hh ig b ih ii il im ip kd it ke ix kf jb mo kh ki kj bi translated">将从训练数据集中采样的真实图像正确标记为<em class="jc">【真实】</em></li><li id="5776" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb mo kh ki kj bi translated">将来自<strong class="ig hi">发生器</strong>的图像正确标记为“<em class="jc">假</em>”。</li></ol><p id="7148" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们计算了<strong class="ig hi">鉴别器</strong>的两个损耗，假图像和真实图像损耗之和就是<strong class="ig hi">鉴别器</strong>的总损耗。损失函数旨在最小化预测来自训练集的真实图像和来自生成器的假图像的误差，给定它们的一个热标签。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/4e8dab5053ea30332d2645835ac1c8cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3mZWBtho9f9vV8HKgDZ4AQ.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">鉴别器的损失函数</figcaption></figure><p id="5624" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">发生器</strong>只有一个责任，那就是生成一个看起来足够真实的图像来骗过<strong class="ig hi">鉴别器</strong>。其损失函数旨在最小化<strong class="ig hi">鉴别器</strong>的正确预测。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/a52ac9174dd1c5b6a26df33594892a51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-qB5MXj3LoZU_c92igVThg.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">发电机的损耗函数。</figcaption></figure><p id="b44c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">鉴别器的训练流程</em> </strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/ce72f7f08d81ee572d90905f31098d69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dtdBgkQK9YSQv2s3dqVLKQ.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">鉴频器的训练过程</figcaption></figure><p id="4015" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="jc">发电机的培训流程</em> </strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lv"><img src="../Images/f22fa92790da951db31f752537ee53b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KO2T-VNsQwlmy0iKmLy9JQ.jpeg"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">发电机的培训过程</figcaption></figure><p id="6edd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">我发现这篇</em> <a class="ae jt" href="https://medium.datadriveninvestor.com/an-introduction-to-conditional-gans-cgans-727d1f5bb011" rel="noopener ugc nofollow" target="_blank"> <em class="jc">文章</em> </a> <em class="jc">在我对</em><strong class="ig hi"><em class="jc">CGANs</em></strong><em class="jc">的解释中非常有用，很有帮助。</em></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mu"><img src="../Images/5f120588ec1eaad1644afb7d2a807936.png" data-original-src="https://miro.medium.com/v2/resize:fit:400/format:webp/1*Gtz4DAziWTjl7N4GPiYR5Q.jpeg"/></div></figure><h1 id="40c0" class="kq kr hh bd ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln bi translated">结论</h1><p id="d370" class="pw-post-body-paragraph ie if hh ig b ih lp ij ik il lq in io ip lr ir is it ls iv iw ix lt iz ja jb ha bi translated">我希望这篇文章无论如何是有用的，而不是令人厌烦的。<strong class="ig hi"><em class="jc">DC GANs</em></strong><em class="jc">，</em><strong class="ig hi"><em class="jc">WGAN</em></strong><em class="jc">和</em><strong class="ig hi"><em class="jc">cgan</em></strong><em class="jc">都是</em><strong class="ig hi"><em class="jc">GANs</em></strong><em class="jc">的有趣变种。他们都有长处和短处。我试图记录我所知道的关于每个变体的所有信息，并且我期待着就每个变体写一篇更加以代码为中心的文章，展示如何用python实现它们。所有这一切都在不久的将来。</em></p><h2 id="8f6f" class="lw kr hh bd ks lx ly lz kw ma mb mc la ip md me le it mf mg li ix mh mi lm mj bi translated">参考</h2><ul class=""><li id="f0ed" class="kb kc hh ig b ih lp il lq ip mk it ml ix mm jb kg kh ki kj bi translated"><a class="ae jt" href="https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8" rel="noopener" target="_blank">https://towards data science . com/DC gans-deep-convolutional-generative-adversarial-networks-c7f 392 C2 c8 f 8</a></li><li id="cc30" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated"><a class="ae jt" href="https://medium.datadriveninvestor.com/an-introduction-to-conditional-gans-cgans-727d1f5bb011" rel="noopener ugc nofollow" target="_blank">https://medium . datadriveninvestor . com/an-introduction-to-conditional-gans-cgans-727 D1 F5 bb 011</a></li><li id="b978" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated"><a class="ae jt" rel="noopener" href="/@sunnerli/the-story-about-wgan-784be5acd84c">https://medium . com/@ sunner Li/the-story-about-wgan-784 be 5 ACD 84 c</a></li><li id="542b" class="kb kc hh ig b ih kk il kl ip km it kn ix ko jb kg kh ki kj bi translated"><a class="ae jt" href="https://towardsdatascience.com/deep-convolutional-vs-wasserstein-generative-adversarial-network-183fbcfdce1f" rel="noopener" target="_blank">https://towards data science . com/deep-convolutional-vs-wasser stein-generative-adversarial-network-183 fbcfdce1 f</a></li></ul><p id="d616" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jc">这是我的第一份媒体出版物，我非常感谢对所讨论主题的反馈和建议，以及任何有助于我成为更好的</em> <strong class="ig hi"> <em class="jc">数据科学家</em> </strong> <em class="jc">和</em> <strong class="ig hi"> <em class="jc">作家</em> </strong> <em class="jc">。随时和我联系</em><a class="ae jt" href="https://www.linkedin.com/in/busayo-awobade-107a94175/" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi"><em class="jc">LinkedIn</em></strong></a><em class="jc">。</em> <strong class="ig hi"> <em class="jc">我很乐意回答您的任何问题或数据科学自由职业者的任务:)</em></strong></p></div></div>    
</body>
</html>