<html>
<head>
<title>Deep Learning Specialization Course</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习专业化课程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-learning-specialization-course-fd18ee60394?source=collection_archive---------9-----------------------#2021-04-07">https://medium.com/analytics-vidhya/deep-learning-specialization-course-fd18ee60394?source=collection_archive---------9-----------------------#2021-04-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="51d9" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated"><strong class="ak">课程2: </strong>改进深度神经网络:超参数调整、正则化和优化(第3周笔记)</h2></div><p id="b706" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我的课程笔记收到了很好的回应。它激励我做好每一篇文章。如果你还没有读过我第一周和第二周的笔记，请看看<a class="ae js" rel="noopener" href="/analytics-vidhya/deep-learning-specialization-course-20c115b77d0e">这篇</a>文章。</p><p id="568e" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">不再拖延，让我们开始本周的学习吧。</p><h2 id="1e87" class="jt ju hh bd jv jw jx jy jz ka kb kc kd jf ke kf kg jj kh ki kj jn kk kl km kn bi translated">超参数调谐</h2><p id="61e0" class="pw-post-body-paragraph iw ix hh iy b iz ko ii jb jc kp il je jf kq jh ji jj kr jl jm jn ks jp jq jr ha bi translated">训练神经网络包括设置几个超参数。在这一周，我们将学习为他们找到一个好的环境。</p><ol class=""><li id="ef7c" class="kt ku hh iy b iz ja jc jd jf kv jj kw jn kx jr ky kz la lb bi translated"><strong class="iy hi">调谐过程</strong></li></ol><p id="8bb2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">优化超参数时出现的问题是，如何选择要研究的值集？在早期，通常的做法是在网格上绘制超参数，并系统地探索它们的值。网格的最佳选择是五乘五。但是当参数数量相对较少时，这种方法效果最好。推荐的做法是随机选择点，然后在随机选择的这组点上尝试超参数。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es lc"><img src="../Images/7d5ba417388bf760ffdbcd2bfd6dde50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*VQUcdshzeDmcMHGVJqUPaQ.png"/></div></figure><p id="3e7a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">上图只考虑了两个超参数。如果我们有三个参数，那么我们可以使用第三维的立方体。通过在三维立方体中采样，我们可以为每个超参数尝试更多的值。</p><p id="ed1c" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> 2。使用合适的标尺选择超参数</strong></p><p id="3014" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们看到，在超参数范围内随机采样可以更有效地搜索超参数空间。选择一个合适的尺度来研究超参数是很重要的。</p><p id="d75d" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了理解这一点，考虑隐藏单元的数量超参数。我们感兴趣的范围是从50到100。我们可以使用包含50到100之间的值的网格来找到最佳值:</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es lk"><img src="../Images/7bf10ecc6372f9a1a6b25e684a757885.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/0*oojwjUJ9SHG1NORM.png"/></div></figure><p id="fc58" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在考虑范围在0.0001和1之间的学习率。如果我们用这些极值画一条数线，并随机均匀地采样这些值，大约90%的值将落在0.1到1之间。换句话说，我们使用90%的资源来搜索0.1到1之间的值，仅使用10%的资源来搜索0.0001到0.1之间的值。这看起来不正确！相反，我们可以使用对数标度来选择值:</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es ll"><img src="../Images/3007b70a47172068bd08f9caf8dfd961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/0*DbhqIirSR5vVAm_S.png"/></div></figure><h2 id="288b" class="jt ju hh bd jv jw jx jy jz ka kb kc kd jf ke kf kg jj kh ki kj jn kk kl km kn bi translated">批量标准化</h2><p id="a512" class="pw-post-body-paragraph iw ix hh iy b iz ko ii jb jc kp il je jf kq jh ji jj kr jl jm jn ks jp jq jr ha bi translated">深度学习中的一个重要思想是一种叫做批量归一化的算法，它有助于更快地训练一种算法。</p><p id="f966" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">回想一下，在逻辑回归中，标准化输入可以加速学习。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lm"><img src="../Images/5fef32b9f4f640cb473bc909caf13533.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cnz6R_AbQv9eq9v8fBNzSA.png"/></div></div></figure><p id="5d05" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在更深的模型中，除了输入特性，我们在所有层中都有激活。如果我们能归一化激活的均值和方差，使W和b的训练更有效，这不是很好吗？比如我们想在下面的网络中更快的训练W3和b3。由于a2是下一层的输入，所以会影响W3和b3的训练。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es lr"><img src="../Images/2667b85ca4b2e1d6f4990719fd578e8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*lclleiyVjMNlsuMFDZAsCg.png"/></div></figure><p id="0464" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下面是我们如何在单个训练层中实现批量标准化:</p><p id="753a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">给定神经网络z到Z^m中的一些中间值，归一化可以计算如下:</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es ls"><img src="../Images/7d279ed14a0a9ac054a08faea68e8e47.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*Jg3gDG06jblc3Yk21zliZQ.png"/></div></figure><p id="37e2" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里，为了数值稳定性，增加了ε。Z的每个分量的平均值为0，方差为1。对于隐藏单元，如果我们对每个组件都有相同的均值和方差，那就没有意义了。因此，对隐藏单元进行不同的分配会更有意义。我们可以利用下面的公式来计算Z tilda。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es lt"><img src="../Images/88ea47da1a4db085d5a8936b182bf82a.png" data-original-src="https://miro.medium.com/v2/resize:fit:604/format:webp/1*Bboi9C5S9nJInVrgIiSVPA.png"/></div></figure><p id="8f54" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其中γ和β是可学习的参数。Batch norm将规范化过程应用于输入图层和深层图层。训练输入层和隐藏层之间的唯一区别是，我们不希望对隐藏层的所有值应用零均值和方差1，因为我们希望利用非线性函数。隐藏层具有标准化的均值和方差，其中两者都由显式参数γ和β控制。</p><p id="8cb9" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">向网络添加批量定额</strong></p><figure class="ld le lf lg fd lh er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lu"><img src="../Images/b34867853b00199d178ef27b1bad599a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IibF8-IH7kLAY2nRvjxGFA.png"/></div></div></figure><p id="4ba7" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">批量定额为什么真的管用？</strong></p><ol class=""><li id="b926" class="kt ku hh iy b iz ja jc jd jf kv jj kw jn kx jr ky kz la lb bi translated">将输入要素归一化为均值为0且方差为1可提高速度，类似于批量归一化对隐藏图层的处理。</li><li id="46a3" class="kt ku hh iy b iz lv jc lw jf lx jj ly jn lz jr ky kz la lb bi translated">考虑<a class="ae js" rel="noopener" href="/@izadi/what-is-covariate-shift-d7a7af541e6">协变量移位</a>的场景，其中分布随着另一个数据集而改变，并且算法无法在该数据集上进行归纳。同样，在神经网络中，如果我们考虑任何隐藏层，输入值会不断变化，导致协变量移位。批量定额减少了这些隐藏单位值分布的移动量。</li></ol><p id="6377" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi">一次测试时批量定额</strong></p><p id="0fbc" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当我们对训练数据应用batch norm时，它与小批量一起工作，步骤如下所示。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es ma"><img src="../Images/afaa545d032c0461e31e2dfaf180267e.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*dq5gAqJc-o0zuMomqa-hDQ.png"/></div></figure><p id="12d8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">但是在测试期间，我们希望一次处理一个例子。因此，我们将使用指数加权平均值来计算Z范数的值。</p><h2 id="8371" class="jt ju hh bd jv jw jx jy jz ka kb kc kd jf ke kf kg jj kh ki kj jn kk kl km kn bi translated">多类分类</h2><p id="e3bc" class="pw-post-body-paragraph iw ix hh iy b iz ko ii jb jc kp il je jf kq jh ji jj kr jl jm jn ks jp jq jr ha bi translated">逻辑回归的推广被称为softmax回归，它可以让我们进行预测以识别两个以上的类。在下图中，外层将有四个输出单元，我们将尝试确定这四个类别的概率。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es mb"><img src="../Images/9037e2bbd171b041dc56db129bd9fd43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1166/format:webp/1*Gu1nXY5AM3qNODxBCwUGcA.png"/></div></figure><p id="3c40" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">为了计算每个类的概率，我们将使用softmax激活函数，它不同于其他激活函数，如relu。在softmax激活函数中，我们将获取一个临时变量t，并通过对每个输出单元进行元素求和来计算其值，如下所示。这里，我们考虑将4作为输出参数。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es mc"><img src="../Images/9c6fd3b2083b8e6ca6d4cad23abf8f33.png" data-original-src="https://miro.medium.com/v2/resize:fit:796/format:webp/1*Xp1Ayv56UTarPL62Y_nxFg.png"/></div></figure><p id="cb37" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">那么输出a1将是归一化为sum 1的向量t，如下例所示。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div class="er es md"><img src="../Images/78049ee3435130c69620dcad5e2225e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*JsMJYwxAc0ExpW8NDcbF-Q.png"/></div></figure><p id="30b8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">以下是使用softmax分类创建的决策界限的几个示例。</p><figure class="ld le lf lg fd lh er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es me"><img src="../Images/40ef0a416008c8757207620e869f06e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XjPwwEt0mk-HgAWZg323TQ.png"/></div></div></figure><p id="b278" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这样，我们完成了深度学习专业化的第二个课程。</p><p id="9634" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">请关注我，获取更多关于机器学习的有用文章。</p><p id="298a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iy hi"> <em class="mf">做一个终身学习者！！快乐学习！！</em>T3】</strong></p></div></div>    
</body>
</html>