<html>
<head>
<title>Web Scraping with Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python进行Web抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-with-python-91d2e955a363?source=collection_archive---------7-----------------------#2021-04-14">https://medium.com/analytics-vidhya/web-scraping-with-python-91d2e955a363?source=collection_archive---------7-----------------------#2021-04-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="9656" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">如何从网站上抓取数据并将其转储到CSV中</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/21e1a48f06cce1f6cec8c910e16dfc36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nMsg5fH66TlqNGpl"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">马库斯·斯皮斯克在<a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="a5f2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><a class="ae jm" href="https://realpython.com/beautiful-soup-web-scraper-python/" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">网络搜集</strong> </a> <strong class="jp hi"> </strong>是从互联网上搜集信息的过程。</p><p id="dc8d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">注意:</strong>如果你只是出于教育目的抓取万维网上的一个页面，那似乎没什么问题。但是，你仍然应该考虑检查他们的<em class="kj">服务条款</em>，因为很少有网站不喜欢自动抓取器收集他们的数据，而其他人并不介意。</p><p id="7f4d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">让我给你一个简单的例子来说明它的用途。比如你想从一个网站上买一个受欢迎的产品，这个产品一上来就没货了。一种方法是访问网站，做一些过滤，每天检查你的产品的可用性。</p><p id="1e49" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">为此，你必须每天花几分钟时间，以便下次它出现在网站上时你可以抓住它。另一种方法是，你可以用python web scraping 来自动化它，而不是每天查找。</p><p id="34f4" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">它非常有助于你在网上自动搜索，将你的搜索范围扩大到你想要的任何网页，等等。</p></div><div class="ab cl kk kl go km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="ha hb hc hd he"><h2 id="7649" class="kr ks hh bd kt ku kv kw kx ky kz la lb jw lc ld le ka lf lg lh ke li lj lk ll bi translated">抓取测试页面</h2><p id="ce03" class="pw-post-body-paragraph jn jo hh jp b jq lm ii js jt ln il jv jw lo jy jz ka lp kc kd ke lq kg kh ki ha bi translated"><a class="ae jm" href="https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/" rel="noopener ugc nofollow" target="_blank">链接</a></p><p id="7ebe" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">请求</strong>模块允许您使用Python发送HTTP请求。</p><p id="bf0a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">HTTP请求返回一个包含所有响应数据(内容、编码、状态等)的响应对象。</p><pre class="ix iy iz ja fd lr ls lt lu aw lv bi"><span id="8ed1" class="kr ks hh ls b fi lw lx l ly lz">import requests<br/><br/>res = requests.get('link to your web page')</span></pre><p id="a205" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在我们将使用Python中一个名为<a class="ae jm" href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#:~:text=Beautiful%20Soup%20is%20a%20Python,hours%20or%20days%20of%20work." rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi">的库BeautifulSoup </strong> </a>来做网页抓取。</p><blockquote class="ma mb mc"><p id="c5b8" class="jn jo kj jp b jq jr ii js jt ju il jv md jx jy jz me kb kc kd mf kf kg kh ki ha bi translated">Beautiful Soup是一个Python库，用于从HTML和XML文件中提取数据。它与您喜欢的解析器一起工作，提供导航、搜索和修改解析树的惯用方式。它通常为程序员节省数小时或数天的工作。</p></blockquote><p id="9c54" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">要了解更多关于它的特性，你可以查看:<a class="ae jm" href="https://www.crummy.com/software/BeautifulSoup/" rel="noopener ugc nofollow" target="_blank">链接</a></p><p id="74eb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果你没有太多的时间去查阅它的文档和特性，你只需要弄清楚一件事:<strong class="jp hi"> <em class="kj"> BeautifulSoup可以解析你在网上给它的任何东西。</em>T29】</strong></p><p id="6e7b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">从测试页面抓取标题的简单例子。</p><pre class="ix iy iz ja fd lr ls lt lu aw lv bi"><span id="4337" class="kr ks hh ls b fi lw lx l ly lz">from bs4 import BeautifulSoup<br/><br/>page = requests.get("<!-- -->https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/<!-- -->")</span><span id="2c40" class="kr ks hh ls b fi mg lx l ly lz">soup = BeautifulSoup(page.content, 'html.parser')</span><span id="3de2" class="kr ks hh ls b fi mg lx l ly lz">title = soup.title.text # gets you the text of the &lt;title&gt;(...)&lt;/title&gt;</span></pre><p id="f35a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">没错，就是这么简单。</strong></p><p id="86d8" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在可以试试刮头、刮身、刮标题等。在我们深入研究收集产品并将其存储到CSV中之前，您需要自己动手。</p><p id="8113" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><a class="ae jm" href="https://github.com/rahulkapoor253/WebScraping" rel="noopener ugc nofollow" target="_blank"> <strong class="jp hi"> Github链接到资源库</strong> </a> <strong class="jp hi">。</strong></p><pre class="ix iy iz ja fd lr ls lt lu aw lv bi"><span id="d96a" class="kr ks hh ls b fi lw lx l ly lz">import requests<br/>from bs4 import BeautifulSoup<br/>import csv<br/><br/>res = requests.get('https://codedamn-classrooms.github.io/webscraper-python-codedamn-classroom-website/')<br/><br/>soup = BeautifulSoup(res.content, 'html.parser')</span></pre><p id="2a35" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在我们可以使用soup变量属性开始收集数据。</p><pre class="ix iy iz ja fd lr ls lt lu aw lv bi"><span id="ca64" class="kr ks hh ls b fi lw lx l ly lz">all_products = []<br/><br/>products = soup.select("div.thumbnail")</span><span id="0e8d" class="kr ks hh ls b fi mg lx l ly lz">for product in products:<br/>    name = product.select("h4 &gt; a")[0].text.strip()<br/>    price = product.select("h4.price")[0].text.strip()<br/>    description = product.select("p.description")[0].text.strip()<br/>    reviews = product.select('div.ratings')[0].text.strip()<br/>    image = product.select("img")[0].get("src")<br/><br/>    all_products.append({<br/>        "product_name": name,<br/>        "price": price,<br/>        "description": description,<br/>        "reviews": reviews,<br/>        "image": image<br/>    })<br/><br/>columns = all_products[0].keys()<br/>with open("my_data.csv", "w", newline="") as file:<br/>    dict_writer = csv.DictWriter(file, columns)<br/>    dict_writer.writeheader()<br/>    dict_writer.writerows(all_products)</span></pre><p id="759e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我来解释一下上面刚刚发生的事情。</p><p id="1d92" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我们可以看到，所有产品的详细信息都显示在一个div中，类名为thumbnail。下面提到的是代表每个产品的HTML。</p><p id="29c8" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><code class="du mh mi mj ls b">&lt;div class=”thumbnail”&gt;<br/>&lt;img alt=”item” class=”img-responsive” src=”/webscraper-python-codedamn-classroom-website/cart2.png”/&gt;<br/>&lt;div class=”caption”&gt;<br/>&lt;h4 class=”pull-right price”&gt;$1139.54&lt;/h4&gt;<br/>&lt;h4&gt;<br/>&lt;a class=”title” href=”/webscraper-python-codedamn-classroom-website/test-sites/e-commerce/allinone/product/593" title=”Asus AsusPro Advanced BU401LA-FA271G Dark Grey”&gt;Asus AsusPro Adv…&lt;/a&gt;<br/>&lt;/h4&gt;<br/>&lt;p class=”description”&gt;<br/> Asus AsusPro Advanced BU401LA-FA271G Dark Grey,<br/> 14", Core i5–4210U, 4GB, 128GB SSD, Win7 Pro 64bit,<br/> ENG<br/> &lt;/p&gt;<br/>&lt;/div&gt;<br/>&lt;div class=”ratings”&gt;<br/>&lt;p class=”pull-right”&gt;7 reviews&lt;/p&gt;<br/>&lt;p data-rating=”3"&gt;<br/>&lt;span class=”glyphicon glyphicon-star”&gt;&lt;/span&gt;<br/>&lt;span class=”glyphicon glyphicon-star”&gt;&lt;/span&gt;<br/>&lt;span class=”glyphicon glyphicon-star”&gt;&lt;/span&gt;<br/>&lt;/p&gt;<br/>&lt;/div&gt;</code></p><p id="6c64" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">名称</strong>:在&lt; h4 &gt;后面跟一个&lt;标签。所以我们使用了product . select(" H4&gt;a ")[0]. text . strip()</p><p id="7d47" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">价格</strong>:内&lt; h4 &gt;同档次价格</p><p id="d3e8" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">描述</strong>:带类描述的&lt; p &gt;内</p><p id="1516" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">评论</strong>:内部&lt;部门&gt;有等级评定</p><p id="b80d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">图像</strong>:在属性为src的&lt; img &gt;内</p><p id="ebc1" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">然后有代码将追加到<strong class="jp hi"> all_products </strong>列表中的数据写入CSV。这是在python中的<a class="ae jm" href="https://docs.python.org/3/library/csv.html" rel="noopener ugc nofollow" target="_blank"> csv模块</a>的帮助下完成的。</p><p id="c7d2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">如果你在评论中遇到任何困难，请告诉我。</p></div></div>    
</body>
</html>