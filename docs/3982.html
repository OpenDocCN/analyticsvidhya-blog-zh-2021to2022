<html>
<head>
<title>Torch Text :Not so Popular Library</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">火炬文:不那么受欢迎的图书馆</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/torch-text-not-so-popular-library-8cf2dbaba956?source=collection_archive---------4-----------------------#2021-08-15">https://medium.com/analytics-vidhya/torch-text-not-so-popular-library-8cf2dbaba956?source=collection_archive---------4-----------------------#2021-08-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/f3eab22f7e0c9aa5ea2aaca0beb836e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oUlC0vnbFSkLft2W.jpg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">基本介绍</figcaption></figure><blockquote class="it iu iv"><p id="037e" class="iw ix iy iz b ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju ha bi translated"><strong class="iz hi">什么是火炬文字？</strong></p></blockquote><p id="ee4b" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">如果你已经在NLP中完成了一些基本的预处理任务，那么你可能知道NLTK，Spacy，Textblob，Stanford NLP，这些都是强大的文本预处理库。但是在pytorch的情况下，我们有专门的库来处理从加载数据到嵌入文本的所有文本预处理步骤。</p><figure class="jz ka kb kc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jy"><img src="../Images/b76923238107f3cd9746638eedf4e720.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uApjOSx7QFstTxClRD_4Zg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">图:火炬文本使用的步骤</figcaption></figure><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="42b7" class="ki kj hh ke b fi kk kl l km kn">from torchtext.legacy.data import Field , TabularDataset<br/>from torchtext.legacy.data import BucketIterator</span></pre><p id="5160" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated"><code class="du ko kp kq ke b">Field</code>将指定如何进行准备。<code class="du ko kp kq ke b">TabularDataset</code>用于从不同的文件格式如<code class="du ko kp kq ke b">json,csv,tsv,text</code>等加载数据集，<code class="du ko kp kq ke b"> BucketIterator</code>帮助在给定的数据集中进行批处理和填充。让我们举个例子来理解给定的库。让我们开始吧……</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="5e7c" class="ki kj hh ke b fi kk kl l km kn">#overview of data<br/>import pandas as pd<br/>data=pd.read_csv('train.csv')<br/>data.head()</span></pre><figure class="jz ka kb kc fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kr"><img src="../Images/c089d5116519f60fbe18fb4a1cd1d3b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tTxChz4fqqtf-17llu6OWg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">图1</figcaption></figure><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="1480" class="ki kj hh ke b fi kk kl l km kn">tokens=lambda x:x.split()<br/>comment=Field(sequential=True,use_vocab=True,tokenize=tokens,  <br/>                                              lower=True)<br/>score=Field(sequential=False,use_vocab=False)<br/>fields={'comments':('c',comment),'score':('s',score)}</span></pre><p id="1e95" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated"><code class="du ko kp kq ke b">Sequential</code>如果这为真，那么它将对文本进行分词，否则不会执行分词。变量<code class="du ko kp kq ke b">fields</code>中的列将采用与数据集中相同的格式。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="63db" class="ki kj hh ke b fi kk kl l km kn">train_set,test_set=TabularDataset.splits(path='/content',<br/>                                          format='csv',<br/>                                          train='train.csv',<br/>                                          test='test.csv',<br/>                                          fields=fields)</span></pre><p id="f414" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">在<code class="du ko kp kq ke b">TabularDataset</code>的帮助下，我加载了数据集，并分成训练集和测试集。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="9445" class="ki kj hh ke b fi kk kl l km kn">comment.build_vocab(train_set,<br/>                    max_size=100,<br/>                    min_frequency=1)</span></pre><p id="93e5" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">这里<code class="du ko kp kq ke b">max_size</code>允许我们选择有限的词汇量。意味着我们将只为前100个出现的单词构建词汇表，而<code class="du ko kp kq ke b">min_freq=2</code>提供了只为那些在给定数据集中至少出现两次的单词构建词汇表的灵活性。</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="e513" class="ki kj hh ke b fi kk kl l km kn">train_iter,test_iter=BucketIterator.splits((train_set,test_set),<br/>                                            batch_size=2)<br/>for i in train_iter:<br/>    print(i.c,i.s)</span></pre><figure class="jz ka kb kc fd ii er es paragraph-image"><div class="er es ks"><img src="../Images/04d763b6461ad74b451a10010452bcad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1188/format:webp/1*PRp7uejL6QdfOPncnKsITA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">结果</figcaption></figure><p id="987a" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">结论:-</p><p id="e88e" class="pw-post-body-paragraph iw ix hh iz b ja jb jc jd je jf jg jh jv jj jk jl jw jn jo jp jx jr js jt ju ha bi translated">这都是我这边的。请在评论框中给你宝贵的建议。这个博客的全部功劳归于<strong class="iz hi">阿拉丁·佩尔森。</strong></p></div></div>    
</body>
</html>