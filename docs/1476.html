<html>
<head>
<title>Our Journey Towards Event Based Analytics Platform</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">我们迈向基于事件的分析平台的旅程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/our-journey-towards-streaming-analytics-8324042c6b74?source=collection_archive---------13-----------------------#2021-03-03">https://medium.com/analytics-vidhya/our-journey-towards-streaming-analytics-8324042c6b74?source=collection_archive---------13-----------------------#2021-03-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/3ad596accca118f495f3b68a29d51b84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oelf9EJY9jcLCBSdEIAQ4w.png"/></div></div></figure><p id="6d7b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们是一家数据驱动的科技公司，数据是我们工作的核心。作为一家互联网公司，我们从各种内部和外部来源获取并分析数Pb的数据。随着组织的有机和无机快速增长，在过去几年中，我们一直在实现数据环境的现代化，并大幅扩展我们的数据平台基础架构。随着组织的不断发展和技术的快速变化，数据工程师的生活中似乎没有沾沾自喜的时刻——在这里，变化是唯一不变的！我们最近做了这样的改变，我们进一步增强了我们的能力，使近实时的基于事件的数据处理成为现实。</p><h1 id="f854" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">传统流程:</h1><p id="7186" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">我们使用具有28个集群和800多个节点的开源Cassandra (C*)发行版作为我们的生产OLTP数据库。C*作为一个分布式的键-值对数据库，它在不可变的二进制数据库文件中的许多不同节点中存储表的数据片段，这些文件被称为SSTables，我们在S3增量地和/或完整地备份这些<a class="ae kq" href="https://github.com/fullcontact/hadoop-sstable" rel="noopener ugc nofollow" target="_blank"> SSTables </a>用于数据库恢复目的。网飞开发并开源了一个名为<a class="ae kq" href="https://github.com/Netflix/aegisthus/," rel="noopener ugc nofollow" target="_blank"> Aegisthus </a>的工具，可以将这些二进制db文件翻译成JSON。使用Aegisthus和自主开发的流程，我们可以批量供应数据平台的源层。以下是工艺流程的简化图示-</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kr"><img src="../Images/284001d6ecf3a3ed823e278328c76c18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4tJ0TmIhTE9X0BZcTIvhmQ.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">遗留流程</figcaption></figure><p id="a5c2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这在相当一段时间内为我们完成了工作，但存在以下固有问题:</p><ol class=""><li id="0e42" class="la lb hh ir b is it iw ix ja lc je ld ji le jm lf lg lh li bi translated"><a class="ae kq" href="https://github.com/Netflix/aegisthus/," rel="noopener ugc nofollow" target="_blank"> Aegisthus </a>项目现已存档，该插件没有主动维护或支持，当前版本不支持升级后的C*版本。因此，我们有点被旧版本的Cassandra锁定，从业务和运营的角度来看，这是一个风险。</li><li id="74f7" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated">Cassandra很好地实现了存储和检索键值对数据的目的，但是当所有分布的数据都需要从表中进行整理以生成表的当前快照/CDC时，这个过程变得非常耗费资源和时间。</li><li id="17c0" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated">由于我们直接从Cassandra生产数据库备份中提取数据，分析团队(即数据的消费者)无法控制所读取数据的结构或数据类型。因此，生产数据库中的任何此类更改通常会使我们的管道失败，需要进行中断修复。</li><li id="415c" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated">没有地方来处理源模式的演变。作为一个充满活力的组织，我们经常推出新功能。为了将新的数据带到数据仓库，我们被迫在增量ETL管道中运行回填。</li><li id="dc82" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated">这是一个批处理过程，有很长的等待时间。</li></ol><p id="a992" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这些是我们需要立即解决的一些问题，这是我们转向基于事件的平台的绝佳机会-</p><h1 id="c2d6" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">现代化流程:</h1><h1 id="5536" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated"><strong class="ak">源层:</strong></h1><p id="9829" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">我们近80%的数据适合流式传输，其余20%的数据需要高精度，查找或维度数据很少改变，或者数据对象较大(&gt; 1MB)，需要批处理。现代化后，我们通过以下方式从生产C*数据库获取数据-</p><h2 id="5ed7" class="lo jo hh bd jp lp lq lr jt ls lt lu jx ja lv lw kb je lx ly kf ji lz ma kj mb bi translated">1.流式摄取:</h2><p id="ae62" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">微服务应用程序捕获事务日志并传输这些日志条目。我们使用<em class="mc"> Fluentd </em>作为日志聚合器，它定期从fluentd-agents(以TCP模式从服务中收集日志流)收集分布式日志，在一个时间范围内进行聚合和重复数据删除，并发送到AWS Firehose，在一定次数的重试后故障切换到S3路径。将数据分块(大约5mb/文件)、分批(YYYY-MM-DD-HH)发送，然后写入S3。</p><figure class="ks kt ku kv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es md"><img src="../Images/d2a1bbead3939a2d7fc4de64419e036e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Adab69z4hGKQ7WVEaaxqwQ.png"/></div></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">现代化流程</figcaption></figure><p id="738f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们从微服务中标准化和抽象出事件发布流程，我们将其命名为<em class="mc"> Eventhub。</em>每次服务团队想要发布数据时，他们都需要在Java代码中调用该功能，并按照数据生产者和消费者之间约定的模式传递事件POJO。这样，数据生产者就必须严格按照约定的模式发送数据，任何偏差都会导致事件发布失败，从而强制执行<a class="ae kq" href="https://docs.microsoft.com/en-us/dotnet/framework/wcf/feature-details/using-data-contracts" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi"> <em class="mc">数据约定</em> </strong> </a> <strong class="ir hi"> <em class="mc">。</em> </strong> <em class="mc"> Eventhub </em>也<em class="mc"> </em>下面做附加作品——</p><ul class=""><li id="f698" class="la lb hh ir b is it iw ix ja lc je ld ji le jm me lg lh li bi translated">向JSON注入元数据并序列化事件POJOs</li><li id="1135" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm me lg lh li bi translated">将事件类型、唯一事件id、事件时间戳添加到JSON中</li><li id="a9f9" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm me lg lh li bi translated">向<em class="mc">数据狗</em>发出不同的度量，用于监控和调试。</li></ul><p id="86d3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">该模式在生产者和消费者团队之间的开发阶段最终确定，任何更改都需要消费者团队的PR批准。这个收缩的模式定义也是我们实现<a class="ae kq" href="https://docs.oracle.com/database/nosql-11.2.2.0/GettingStartedGuide/schemaevolution.html" rel="noopener ugc nofollow" target="_blank"> <strong class="ir hi"> <em class="mc">模式进化</em></strong></a><strong class="ir hi"><em class="mc"/></strong>的地方，为了<strong class="ir hi">向前兼容</strong>(新版本的编写器模式—例如，添加新列)，需要在模式中提到新添加列的默认值。Avro是面向行的数据格式，能够读取新数据和旧数据。<strong class="ir hi">还支持向后兼容性(</strong>读者模式的新版本—例如，取消列)。</p><p id="9adf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">Kinesis写入S3的文件是二进制JSON (Avro)格式，看起来像:<em class="mc">S3://event-name/yyyymmdd hh/XXX . Avro .</em>该路径链接到外部配置单元表，该表也链接到相同的数据契约模式。这样数据在产生后一分钟左右就可供查询，从而使<strong class="ir hi"><em class="mc"/><em class="mc">接近实时</em> </strong> <em class="mc">分析</em>。</p><p id="8322" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这对于我们需要接收的大部分数据来说都非常好，但这仍然有某些缺点，我们需要替代的并行解决方案-</p><ol class=""><li id="c04b" class="la lb hh ir b is it iw ix ja lc je ld ji le jm lf lg lh li bi translated">当前的流处理非常稳定，但由于“至少一次”语义，当这些事件超出在<em class="mc"> Fluentd </em>配置的重复数据删除窗口时，我们仍有可能出现重复事件，或者由于系统中的不同故障点，很少会出现缺失事件。对于关键的财务指标或对账，这可能会导致问题。</li><li id="8466" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated">对频率极低的事件进行流式传输是没有意义的，例如一些很少更改的查找类型的数据。</li><li id="7a65" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated">Kinesis Firehose允许记录大小达到1000 KB，我们发现这在某些情况下是有限制的，因为数据生产者不能在数据中发送大的JSON blobs。</li></ol><p id="2c88" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们以两种不同的方式解决了这一挑战，这两种方式都来自不同的用例。</p><h2 id="2a25" class="lo jo hh bd jp lp lq lr jt ls lt lu jx ja lv lw kb je lx ly kf ji lz ma kj mb bi translated">2.批量摄入:</h2><p id="9f22" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">这里的数据发布与eventhub streaming中的相同，即它通过数据契约和Eventhub功能进行，但fluentd代理没有配置为读取这些数据，而是从Cassandra产品中批量提取数据，并通过Eventhub写入指定的S3路径。这适用于关键的小批量数据。</p><h2 id="d6c0" class="lo jo hh bd jp lp lq lr jt ls lt lu jx ja lv lw kb je lx ly kf ji lz ma kj mb bi translated">3.C*火花摄入:</h2><p id="009a" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">Cassandra (C*)的DataStax Enterprise (DSE)发行版附带了Spark connector，很容易建立一个db api连接，并将所需数据从DSE Cassandra提取到parquet文件。我们的生产C*是开源版本和800多个节点的集群，因此更容易将所需C*密钥空间/表的子集从生产集群转移到单独的小型DSE Cassandra集群，并从那里提取数据到分析平台的源区域。生产中的增量/快照稳定备份被复制到GDP S3存储桶，然后加载到GDP C*集群。从这里，使用Spark connector以parquet格式提取数据，这很容易用于分析。该流程用于一些包含大量数据的表格，与GreenTea流程相比，该流程消耗的资源和时间较少，并且不依赖于<a class="ae kq" href="https://github.com/Netflix/aegisthus/," rel="noopener ugc nofollow" target="_blank"> Aegisthus </a>插件。这是GreenTea过程的中间替代，没有数据契约和模式演化。</p><h1 id="d821" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">ODS层:</h1><p id="e638" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">原始区或着陆区中的数据有利于进行近实时数据分析，但这带来了某些功能，需要下游层(ODS)来运行大型分析工作负载-</p><ol class=""><li id="8af8" class="la lb hh ir b is it iw ix ja lc je ld ji le jm lf lg lh li bi translated">源层是面向行的Avro格式。这对于大型分析工作负载来说性能不是很好，因为它们通常需要面向列的结构。</li><li id="ed0a" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated">来自数据生产者的数据的源层或着陆区本质上是短暂的，并且具有有限的保留期(我们将其设置为30天)。这也部分是因为消费者的隐私法(如CCPA ),该法要求在收到消费者的“忘记我”通知后的几天内从系统中删除消费者的数据。从ODS到报告层，我们使用一个模糊处理过程，该过程定期(我们将转到令牌化过程，以更好的方式处理这一点)为希望被遗忘的客户模糊PII数据。</li><li id="788b" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated">在许多情况下，数据生产者可能更倾向于发送来自服务的复杂或嵌套的JSON，而没有责任或能力以更相关和易于消费的形式提供数据。ODS是一个层，在这个层中，使用定制流程的不太熟悉的用户可以更方便地进行分析。话虽如此，但强烈建议不要在模式契约中接受复杂的数据类型。来自服务的数据应该是具有最低复杂性的格式良好且完整的业务事件。</li><li id="b1fc" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm lf lg lh li bi translated">某些其他基于规则的数据验证、重复数据删除、合并源中的小文件等。以使其成为数据仓库中的第一个净化的用户可消费层。</li></ol><p id="9fd7" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们已经创建了高度可配置的工厂(流和批处理),用于从服务到ODS层接收数据。如果数据从源实时输入ODS，ODS的一些好处就会丧失，但用户仍然可以通过合并ODS的批量数据和源层的流数据(大多数情况下不到一分钟的延迟)来获得接近实时的数据。</p><h1 id="d948" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">ODS快照层:</h1><p id="a95e" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">ODS(前一层)存放不可变的事件日志数据，这些数据是不压缩的。因此，同一个主键可能有许多行，它们是在不同的时间点生成的。“ODS快照”包含数据的快照视图，该视图由给定的主键压缩。我们构建了高度可配置的声明性工厂来完成这种压缩。</p><h1 id="d971" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">集成层:</h1><p id="4087" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">ODS为用户提供了查询操作数据的能力，操作数据是不可变的事件日志数据。它仍然不是运行真正的报告查询或方便地将它与仓库中的其他数据结合起来进行决策的地方。这些不可变的事件日志仍然需要经历来自最新状态的转换逻辑，以描绘人们关心的数据的当前视图，这是在集成层中完成的。该过程改变了数据的现有状态，并且由于S3(我们使用的文件存储)不支持改变，该层不能是流层，也不需要成为流层。我们使用Spark批处理ETL定期刷新我们的集成层。集成层支持快照或增量摄取。</p><h1 id="9053" class="jn jo hh bd jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk bi translated">展望未来:</h1><p id="a4cd" class="pw-post-body-paragraph ip iq hh ir b is kl iu iv iw km iy iz ja kn jc jd je ko jg jh ji kp jk jl jm ha bi translated">使用我们当前的框架，我们可以进行非常低的延迟近实时分析，但我们仍然无法执行流或真正的实时分析。我们正在使用Kafka进行POC和流分析的实施，并计划在我们的数据平台中添加以下功能—</p><ul class=""><li id="b628" class="la lb hh ir b is it iw ix ja lc je ld ji le jm me lg lh li bi translated">复杂的事件处理能力，这将帮助我们在管道中插入事件处理例程，利用来自多个主题的流连接。目前，我们无法将来自不同事件管道的飞行数据结合起来。</li><li id="86ff" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm me lg lh li bi translated">这将为我们的交易系统提供一个反馈回路。</li><li id="3310" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm me lg lh li bi translated">除了充当消息队列，Kafka还可以作为我们的源层，具有数据保留、自动日志压缩和事件重复数据删除功能，因此可以替代源、<em class="mc"> ODS </em>和<em class="mc"> ODS快照</em>层。</li><li id="0feb" class="la lb hh ir b is lj iw lk ja ll je lm ji ln jm me lg lh li bi translated">有了Kafka，我们可以在更高的抽象层次上处理数据流。</li></ul></div></div>    
</body>
</html>