<html>
<head>
<title>Ridge and Lasso Regression In Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的脊和套索回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ridge-and-lasso-regression-in-python-60cf1af69cfe?source=collection_archive---------5-----------------------#2021-03-28">https://medium.com/analytics-vidhya/ridge-and-lasso-regression-in-python-60cf1af69cfe?source=collection_archive---------5-----------------------#2021-03-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/88229a6da2ec9dd018092e81d76c9fc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TsDEpAI4SdpGal4K"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">尼古拉斯·洛沃斯在<a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="9f7d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在我以前的帖子中，我谈到了与脊和套索回归相关的理论以及它们背后的数学方程。</p><p id="4134" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在本文中，让我们用python实现脊和套索回归。</p><p id="7520" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">注</strong>:如果你不知道山脊和拉索背后的数学和理论概念，我强烈推荐你点击这个链接:<a class="ae it" href="https://manojgadde.medium.com/ridge-and-lasso-regression-made-easy-343df45a90b9#4be1-463c284cfb2d" rel="noopener">https://manojgadde . medium . com/ridge-and-lasso-regression-made-easy-343 df45 a90 b 9 # 4be 1-463 c284 CFB 2d</a></p><h2 id="2f9b" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak">简介:</strong></h2><p id="9610" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">幸运的是，实现任何机器学习算法并不困难，Scikit-learn库提供了许多机器学习算法。让我们使用scikit-learn库实现脊和套索回归。</p><p id="cfed" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这种情况下，我们使用的是令人惊讶的住房数据集，我们需要使用正则化建立一个回归模型，以预测未来房产的实际价值，并决定是否投资。</p><p id="98e3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">你可以在这里找到数据集:<a class="ae it" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/c/house-prices-advanced-regression-techniques/data</a></p><p id="13d1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">注意</strong>:我不会经历所有的预处理步骤，我会直接跳转到脊和套索实现。</p><p id="2cdd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将数据集分为70%的训练规模和30%的测试规模，并使用minmaxscaler缩放训练和测试数据。</p><h2 id="a871" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak"> 1。岭回归:</strong></h2><p id="be89" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">这里，我们从sklearn库导入了ridge，并使用X_train和y_train拟合模型，其中y_train包含目标变量，即“销售价格”, X_train包含所有独立变量。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ks"><img src="../Images/5a08920255f23b68efacea4fb3a42e10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_lHIYlEl62aNzUYSEm_yPw.jpeg"/></div></div></figure><p id="8d50" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里需要注意的一点是，我们向岭传递了一个名为“alpha”的附加参数，这个alpha只是岭回归数学方程中的λ值，这个alpha也是一个要调整的超参数，我们需要找出最佳的alpha值。</p><p id="650b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们只取一个0.01的随机alpha值，看看我们的岭回归模型在训练数据上表现如何。这里，我们在训练数据上得到91%的r2分数。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kx"><img src="../Images/7e22281a0e952bd355248776ea3d7d03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E_ER23sW3K-w8keHdCl08w.jpeg"/></div></div></figure><p id="fde8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们对测试数据进行预测，以检查我们的模型在看不见的数据上表现如何。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ky"><img src="../Images/7a1bb14914341ec7e6ade29d473e51bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ka4iNDnZ4zBtss3gDUz8Jw.jpeg"/></div></div></figure><p id="9809" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们得到了89%的r2分数，这相当不错，但我们不能说这个alpha(0.01)值是唯一的最佳alpha值，我们需要使用gridsearchcv找到最佳alpha值，让我们这样做吧</p><h2 id="7b08" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak">超参数调谐:</strong></h2><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kz"><img src="../Images/5ca5889240dc39a58941ef96cb8e38ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*012R9FNBOiSUUXTEWdQCWA.jpeg"/></div></div></figure><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es la"><img src="../Images/28d2a7cfbbe7c8840986eaae28f33f1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1118/format:webp/1*8n_tIH8LajCWMod4LJXBUQ.jpeg"/></div></figure><p id="a8ee" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里，我们已经定义了kfold(5倍)交叉验证和阿尔法值范围，即超参数值，并选择评估指标作为r2得分，我们得到了1.0的最佳阿尔法值，并使用该阿尔法值再次训练我们的模型。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lb"><img src="../Images/9404e49ae90b22c692d16016b60b84e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E8xJVq8Zeo3eulkG0Jv2bg.jpeg"/></div></div></figure><p id="b61e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，最终使用最佳alpha值1.0给出了岭回归的最佳训练(91%)和测试(90%)结果。</p><p id="35a3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">注</strong>:岭回归也降低了系数的大小。</p><h2 id="807b" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated">2.<strong class="ak">拉索回归:</strong></h2><p id="d4b0" class="pw-post-body-paragraph iu iv hh iw b ix kn iz ja jb ko jd je jf kp jh ji jj kq jl jm jn kr jp jq jr ha bi translated">这里，我们从sklearn库中导入lasso，并使用X_train和y_train拟合模型，其中y_train包含目标变量，即“销售价格”, X_train包含所有独立变量。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es lc"><img src="../Images/6669882e2216e281090796a9687d9a29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*-zD9ReXjr5ikVchnb1g-Pw.jpeg"/></div></figure><h2 id="36e6" class="js jt hh bd ju jv jw jx jy jz ka kb kc jf kd ke kf jj kg kh ki jn kj kk kl km bi translated"><strong class="ak">超参数调谐:</strong></h2><figure class="kt ku kv kw fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ld"><img src="../Images/7a6ce71e2657a9c71b59007948e8966e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AVRER4QsIbF1rKoiTeSxbA.jpeg"/></div></div></figure><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es le"><img src="../Images/8387cf299e330b56182576420c00f52b.png" data-original-src="https://miro.medium.com/v2/resize:fit:710/format:webp/1*NF9djLhNwDIErl---9wZFA.jpeg"/></div></figure><p id="5de3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里，我们使用了5重交叉验证，定义了alpha值的范围，并选择评估指标为r2分数，得到了最佳alpha值0.001。让我们使用这个alpha值再次训练我们的模型，我们得到的训练和测试分数几乎相似。</p><figure class="kt ku kv kw fd ii er es paragraph-image"><div class="er es lf"><img src="../Images/8d0c80e78e3fc479222eda6acebecaa3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*CuV_7lvQ98rV94Bd8y-fSg.jpeg"/></div></figure><p id="55e0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">注意:</strong> lasso回归也使冗余变量系数为零，这意味着它将有助于特征选择。</p></div><div class="ab cl lg lh go li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ha hb hc hd he"><p id="fdec" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们关于山脊和套索回归的python实现的文章到此结束。我希望这篇文章能帮助你理解python的实现。</p></div><div class="ab cl lg lh go li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ha hb hc hd he"><p id="66e3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这是我的第二篇媒体文章，如果你喜欢这篇文章，请在下面为这篇文章鼓掌以示支持，这真的激励我写更多有趣的文章，如果你有任何问题，请在下面留下评论，我很乐意收到你的来信。</p></div><div class="ab cl lg lh go li" role="separator"><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll lm"/><span class="lj bw bk lk ll"/></div><div class="ha hb hc hd he"><p id="78a3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我是一个数据科学爱好者，目前正在班加罗尔国际信息技术学院攻读机器学习和人工智能的pg文凭。</p><p id="10f3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">你也可以在<a class="ae it" href="http://www.linkedin.com/in/manoj-gadde" rel="noopener ugc nofollow" target="_blank">www.linkedin.com/in/manoj-gadde</a>找到我</p></div></div>    
</body>
</html>