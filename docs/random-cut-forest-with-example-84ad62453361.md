# éšæœºé‡‡ä¼æ£®æ—ç¤ºä¾‹

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/random-cut-forest-with-example-84ad62453361?source=collection_archive---------5----------------------->

[ä»£ç ä¸º](https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_amazon_algorithms/random_cut_forest/random_cut_forest.html)çš„ä¹±ç æ£®æ—ï¼Œä½ è¦æé˜²ä»€ä¹ˆã€‚

è¿™æ˜¯æˆ‘ä¹‹å‰çš„æ•…äº‹çš„å»¶ç»­ï¼Œåœ¨é‚£é‡Œæˆ‘å¿…é¡»è§£é‡Šéšæœºé‡‡ä¼æ£®æ—çš„ç†è®ºã€‚

![](img/1664db728ccaba75838503dce2ce6dd0.png)

ç…§ç‰‡ç”±[è©¹å§†æ–¯Â·å“ˆé‡Œé€Š](https://unsplash.com/@jstrippa?utm_source=medium&utm_medium=referral)åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„

å˜¿ï¼Œä¼™è®¡ä»¬ï¼Œæˆ‘ä»¬å·²ç»çŸ¥é“ RCF æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œè®©æˆ‘ä»¬ç›´æ¥è¿›å…¥ç¼–ç ã€‚æˆ‘å¯ä»¥ä¿è¯è¿™å°†æ˜¯è¿„ä»Šä¸ºæ­¢ä½ é¢å¯¹ä»»ä½•å¼‚å¸¸æ£€æµ‹ä»£ç æ—¶æœ€ç®€å•çš„æ–¹æ³•ã€‚

ç®€å•åœ°è¯´ï¼ŒåŸºäºæˆ‘ä»¬çš„æ•°æ®ç‚¹ï¼ŒRCF æ¨¡å‹ä¼šåˆ†é…åˆ†æ•°ï¼Œå¹¶åŸºäºè¯¥åˆ†æ•°æ¥å†³å®šå¼‚å¸¸æƒ…å†µã€‚

é¦–å…ˆï¼Œæˆ‘ä¸ä¼šç›´æ¥ä¸¾ AWS æä¾›çº½çº¦å‡ºç§Ÿè½¦æ•°æ®çš„ä¾‹å­ï¼Œè€Œæ˜¯ä½¿ç”¨[è¿™é‡Œ](https://github.com/numenta/NAB/blob/master/data/realKnownCause/ambient_temperature_system_failure.csv)çš„æœºå™¨æ•…éšœæ•°æ®ã€‚

## å¯†ç 

è®©æˆ‘ä»¬å¯¼å…¥æ‰€æœ‰å¿…éœ€çš„åº“

```
## Importing all necessary Libs that will be required
import pandas as pd
import numpy as np
import os
import warnings
import pickle
import matplotlib.pyplot as plt
import boto3
# import sagemaker
import sys
import seaborn as sns
import holoviews as hv
from holoviews import opts
hv.extension('bokeh')
```

ä¹Ÿå°†å¢åŠ ä¸€äº›æ›´å¥½çš„è§†å›¾é€‰é¡¹

```
warnings.simplefilter('ignore')
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)sns.set_style('white')
sns.set_palette('pastel',8)seed=345
np.random.seed(seed)
```

åŠ è½½æ•°æ®:

```
## Loading Data
df = pd.read_csv("./data/nab_machine_failure.csv")
print("")
# print("Data columns ---> {}".format(list(fulldata.columns)))
# fulldata = df
print("Total Number of records ---> {}".format(df.shape[0]))
print("Total Number of features ---> {}".format(df.shape[1]))
print("")
df.head()
```

![](img/5326e2c175105eaab3c8a28cd9a39d83.png)

```
anomaly_points = [
        ["2013-12-10 06:25:00.000000","2013-12-12 05:35:00.000000"],
        ["2013-12-15 17:50:00.000000","2013-12-17 17:00:00.000000"],
        ["2014-01-27 14:20:00.000000","2014-01-29 13:30:00.000000"],
        ["2014-02-07 14:55:00.000000","2014-02-09 14:05:00.000000"]
]df['timestamp'] = pd.to_datetime(df['timestamp'])
#is anomaly? : True => 1, False => 0
df['anomaly'] = 0
for start, end in anomaly_points:
    df.loc[((df['timestamp'] >= start) & (df['timestamp'] <= end)), 'anomaly'] = 1df['year'] = df['timestamp'].apply(lambda x : x.year)
df['month'] = df['timestamp'].apply(lambda x : x.month)
df['day'] = df['timestamp'].apply(lambda x : x.day)
df['hour'] = df['timestamp'].apply(lambda x : x.hour)
df['minute'] = df['timestamp'].apply(lambda x : x.minute)
```

ä¿®æ”¹äº†æ•°æ®æ¡†ï¼Œå¢åŠ äº†ä¸€äº›åŠŸèƒ½ï¼Œå°†å®Œæ•´çš„æ—¥æœŸæ—¶é—´æˆ³è½¬æ¢ä¸ºå•ç‹¬çš„åŠŸèƒ½ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å®ƒä»¬æ˜¯å¦‚ä½•å½¢æˆçš„ã€‚

```
df.index = df['timestamp']
df.drop(['timestamp'], axis=1, inplace=True)
df.head(3)
```

![](img/9443f083aa6d7ff49535a03161405bd4.png)

æˆ‘ä»¬å°†çœ‹åˆ°ä¸€ä¸ªå¼‚å¸¸ç‚¹çš„ä¾‹å­ã€‚å› ä¸ºæˆ‘ä»¬å·²ç»æ˜ç¡®ç»™å‡ºäº†åŸºäº anomly _ point çš„å¼‚å¸¸ç‚¹ã€‚æ‰€ä»¥ä¸ºäº†å½¢è±¡åŒ–ï¼Œæˆ‘ä½¿ç”¨äº†å­”è§†å›¾ï¼Œå®ƒä»¬å¾ˆæ£’ï¼Œæœ‰æ—¶ä¼šåœ¨ä¸Šé¢å†™ä¸€ä¸ªæ•…äº‹ã€‚

```
anomalies = [[ind, value] for ind, value in zip(df[df['anomaly']==1].index, df.loc[df['anomaly']==1,'value'])]
(hv.Curve(df['value'], label="Temperature") * hv.Points(anomalies, label="Anomaly Points").opts(color='red', legend_position='bottom', size=2, title="Temperature & Given Anomaly Points"))\
    .opts(opts.Curve(xlabel="Time", ylabel="Temperature", width=700, height=400,tools=['hover'],show_grid=True))
```

![](img/8e4a12fba76e79df010ed915109ec57e.png)

ç°åœ¨å¯¹äºä¸»äº‹ä»¶ï¼Œå¦‚ä½•å°† RCF åº”ç”¨äºæ­¤ï¼Œå¹¶å°†å¾—åˆ°æˆ‘ä»¬æ‰€æœ‰çš„å¼‚å¸¸ã€‚è®©æˆ‘ä»¬ä»å†æ¬¡å¯¼å…¥ä¸€äº› imp åº“å¼€å§‹ï¼Œä»¥ä¾¿ä½¿ç”¨éšæœºåˆ‡å‰²æ£®æ—ã€‚ç”±äº RCF æ˜¯ AWS åˆ›å»ºçš„æ¨¡å‹ï¼Œæˆ‘ä»¬å¿…é¡»åŠ è½½ Sagemakerã€boto3 ç­‰ã€‚

```
from sagemaker import RandomCutForest
import boto3
import botocare
import sagemaker
import sys
```

å®šä¹‰è§’è‰²:

```
iam = boto3.client('iam')
role = iam.get_role(RoleName='NAB_machine_failure_analytics')['Role']['Arn']
print(role)
```

![](img/3093fe813f7a2d735b61da37bdab056c.png)

å‡†å¤‡å¥½åŸ¹è®­è¯„ä¼°å‘˜è§’è‰²:

```
# Training
rcf = RandomCutForest(
    role=role,
    instance_count=1,
    instance_type='ml.m4.xlarge'
    output_path='s3://data/output_rcf',
    num_sample_per_tree=512,
    num_trees=50
)# automatically upload the training data to s3 and run the training job
rcf.fit(rcf.record_set(data['value'].to_numpy().reshape(-1,1)))
```

![](img/9e0d6b56e8e30d844a77481a836b3686.png)

å¦‚æœä½ çœ‹åˆ°è¿™æ ·çš„ä¸œè¥¿ï¼Œè¿™æ„å‘³ç€ä½ çš„è®­ç»ƒå¼€å§‹äº†ã€‚ç¡®ä¿æ‚¨åœ¨åŸ¹è®­ç»“æŸæ—¶ä¹Ÿèƒ½æ”¶åˆ°åŸ¹è®­å®Œæˆçš„æ¶ˆæ¯ã€‚

ä¸ºäº†é¢„æµ‹æ•°æ®ï¼Œæˆ‘ä»¬å¿…é¡»æ¨æ–­å®ƒï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å¿…é¡»éƒ¨ç½²å®ƒã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªéƒ¨ç½²å¥½çš„æ–¹æ³•æ¥åˆ›å»ºæ¨è®ºã€‚

```
rcf_interference = rcf.deploy(initial_instance_count=1, ins)
```

ç„¶åï¼Œæˆ‘ä»¬å¿…é¡»å¯¹å…¶è¿›è¡Œåºåˆ—åŒ–ï¼Œä»¥ä¾¿å°†åˆ†æ•°æ·»åŠ åˆ°ä¸»æ•°æ®æ¡†ä¸­ã€‚ç„¶åä½ ä¼šå¾—åˆ°ä¸€ä¸ªè¿™æ ·çš„æ•°æ®å¸§ã€‚

```
from sagemaker.serializers import CSVSerializer
from sagemaker.deserializers import JSONDeserializerrcf_inference.serializer = CSVSerializer()
rcf_inference.deserializer = JSONDeserializer()machine_data_numpy = data.value.to_numpy().reshape(-1, 1)
print(machine_data_numpy[:6])
results = rcf_inference.predict(
    machine_data_numpy[:6], initial_args={"ContentType": "text/csv", "Accept": "application/json"}
)results = rcf_inference.predict(machine_data_numpy)
scores = [datum["score"] for datum in results["scores"]]# add scores to taxi data frame and print first few values
data["score"] = pd.Series(scores, index=data.index)
data.head()
```

![](img/0ec18c7c2f6d864dfa4efd8fc8840823.png)

è®©æˆ‘ä»¬çœ‹çœ‹åˆ†æ•°å‘æˆ‘ä»¬å±•ç¤ºäº†ä»€ä¹ˆå¼‚å¸¸ã€‚

![](img/f267710fc261b0950b0c842d1dc74637.png)

å¦‚æ‚¨æ‰€è§ï¼Œè¿™æ˜¯ä¸€ç§éå¸¸ç®€å•çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚

è°¢è°¢ä½ ä»¬é˜…è¯»è¿™ç¯‡æ–‡ç« ã€‚å¦‚æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·å‘è¡¨è¯„è®ºã€‚

# ç°åœ¨æ€ä¹ˆåŠï¼Ÿ

è¿™è¾¹è¯·..ä½ ç°åœ¨ç¼–ç éšæœºç ä¼æ£®æ—ã€‚ä¸‹ä¸€ç¯‡åšå®¢å°†æ¢è®¨å…¶ä»– AWS æ¨¡å‹ã€‚ç„¶åæˆ‘ä»¬ä¼šä»”ç»†è§‚å¯Ÿå…¨æ¯è§†å›¾ã€‚

æ„Ÿè°¢é˜…è¯»ã€‚

![](img/cc966bebf9823e73df076f70acb94af2.png)

å¦‚æœä½ å–œæ¬¢è¿™ç¯‡æ–‡ç« ï¼Œè¯·ä¸€å®šè¦é¼“æŒã€‚è¯·å…³æ³¨æˆ‘çš„ Github å’Œæˆ‘çš„ medium ä¸ªäººèµ„æ–™ä¸Šçš„æ›´å¤šé¡¹ç›®å’Œæ–‡ç« ã€‚

[](https://github.com/tapanKumarPatro) [## tapanKumarPatro -æ¦‚è¿°

### Arctic Code Vault è´¡çŒ®è€…æ¥è‡ª greensdata/æˆä¸ºæ•°æ®ç§‘å­¦å®¶çš„ 10 ä¸ªæ­¥éª¤ğŸ“¢å‡†å¤‡å­¦ä¹ æˆ–å¤ä¹ â€¦

github.com](https://github.com/tapanKumarPatro) [](https://tapanpatro.medium.com/) [## Tapan Kumar Patro -ä¸­ç­‰

### å…³äºè¿™ä¸ªæ— ç›‘ç£çš„æœºå™¨å­¦ä¹ ç®—æ³•ä½ åº”è¯¥çŸ¥é“çš„äº‹æƒ…ã€‚æˆ‘çŒœå¦‚æœä½ åœ¨æ‰¾è¿™ä¸ªâ€¦

tapanpatro.medium.com](https://tapanpatro.medium.com/) 

ä¸è¦å¿˜äº†ç”¨ Android åº”ç”¨ç¨‹åºå¼€å‘æ¥æ£€æŸ¥æ·±åº¦å­¦ä¹ é¡¹ç›®çš„ç«¯åˆ°ç«¯éƒ¨ç½²ã€‚

[](/analytics-vidhya/end-to-end-deep-learning-based-app-af67d4008550) [## åŸºäºæ·±åº¦å­¦ä¹ çš„ç«¯åˆ°ç«¯ appã€‚

### èªæ˜çƒ¹é¥ª

medium.com](/analytics-vidhya/end-to-end-deep-learning-based-app-af67d4008550) 

è°¢äº†ã€‚å¦‚æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·ç•™è¨€ã€‚