<html>
<head>
<title>Predict Stock Prices using LSTMs (PyTorch edition)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用LSTMs预测股票价格(PyTorch版)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/predict-stock-prices-using-lstms-pytorch-edition-aa9b3875f131?source=collection_archive---------7-----------------------#2021-01-12">https://medium.com/analytics-vidhya/predict-stock-prices-using-lstms-pytorch-edition-aa9b3875f131?source=collection_archive---------7-----------------------#2021-01-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="194b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果Medium在订阅等问题上困扰你，你可以使用这个链接:<a class="ae jc" href="https://gitlab.com/-/snippets/2059718" rel="noopener ugc nofollow" target="_blank">https://gitlab.com/-/snippets/2059718</a>。</p><p id="22e4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们将使用LSTMs编写一个简单的股票预测器。神经网络使用过去半年左右的股票数据，并使用LSTMs来预测未来股票价格的值。<br/>你可能已经从这篇文章的标题猜到了，这篇文章的TensorFlow版本即将问世。为什么要同时使用TensorFlow和PyTorch编写一个类似的程序？我对神经网络和深度学习真的很陌生，在看到一堆关于Keras和PyTorch如何优于另一个的资源后，我决定测试一下这两个，看看哪个更容易使用。</p><p id="f70c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Jupyter笔记本在<a class="ae jc" href="https://gitlab.com/-/snippets/2059712" rel="noopener ugc nofollow" target="_blank">这里</a>有售。</p><h1 id="d51d" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">LSTMs</h1><p id="e412" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">什么是LSTMs？LSTMs是类似于RNNs的神经网络，它们获取一些输出并将它们“循环回”网络。这使得他们可以学习一些东西，比如部分或完全依赖于之前股票价格的股票价格。例如，如果一只股票的价格正在上涨，它可能在下一分钟也会上涨。</p><p id="4b42" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">写有<code class="du kg kh ki kj b"># elided</code>的行被省略了，因为我觉得它们对于理解程序是不必要的。您仍然可以在笔记本上查看完整的源代码。</p><p id="fe9e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将从导入我们的库开始。</p><pre class="kk kl km kn fd ko kj kp kq aw kr bi"><span id="a9a2" class="ks je hh kj b fi kt ku l kv kw">#@title Install/Import Libraries { vertical-output: true }</span><span id="dbe7" class="ks je hh kj b fi kx ku l kv kw">def import_install(id: str):<br/>  # elided defining import_install, which installs the module is not available and imports it.</span><span id="6d90" class="ks je hh kj b fi kx ku l kv kw">!python3 -m pip install --quiet --upgrade pip</span><span id="d756" class="ks je hh kj b fi kx ku l kv kw">import os<br/>import time<br/>import datetime<br/>import pathlib</span><span id="0f20" class="ks je hh kj b fi kx ku l kv kw">sns = import_install('seaborn')<br/>!python3 -m pip install --quiet --upgrade matplotlib<br/>mpl = import_install('matplotlib')<br/>plt = mpl.pyplot<br/>torch = import_install('torch')<br/>nn = torch.nn<br/>np = import_install('numpy')<br/>pd = import_install('pandas')<br/>yf = import_install('yfinance')</span><span id="c36e" class="ks je hh kj b fi kx ku l kv kw"># elided configuring matplotlib</span><span id="2e70" class="ks je hh kj b fi kx ku l kv kw">import seaborn<br/>import matplotlib<br/>import torch<br/>import numpy<br/>import pandas<br/>import yfinance</span></pre><p id="a021" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们可以使用Yahoo！使用<code class="du kg kh ki kj b"><a class="ae jc" href="https://github.com/ranaroussi/yfinancehttps://github.com/ranaroussi/yfinance" rel="noopener ugc nofollow" target="_blank">yfinance</a></code> Python模块进行财务。我们将从获取<code class="du kg kh ki kj b">TSLA</code>特斯拉的股票价格开始。</p><pre class="kk kl km kn fd ko kj kp kq aw kr bi"><span id="5052" class="ks je hh kj b fi kt ku l kv kw">#@title Get Stock Data { vertical-output: true }<br/>run = True #@param {type:"boolean"}<br/>cache_path = "./data.csv" #@param {type:"string"}<br/>ticker = "TSLA" #@param {type:"string"}<br/>period = "1y" #@param {type:"string"}<br/>interval = "1h" #@param {type:"string"}<br/>auto_adjust = True #@param {type:"boolean"}<br/>prepost = True #@param {type:"boolean"}<br/>threads = 0 #@param {type:"integer"}<br/>if threads == 0:<br/>  threads = False<br/>proxy = "" #@param {type:"string"}<br/>if proxy == "":<br/>  proxy = None</span><span id="dc8b" class="ks je hh kj b fi kx ku l kv kw">if run:<br/>  df = yf.download(<br/>      # elided yfinance configuration<br/>      )<br/>  df.to_csv(cache_path)<br/>  df = pd.read_csv(cache_path)<br/>  # ensure consistency beyween run = True and False<br/>  print('successfully fetched data from yfinance &amp; saved to cache')<br/>else:<br/>  df = pd.read_csv(cache_path)<br/>  print('successfully fetched data from cache')</span><span id="958c" class="ks je hh kj b fi kx ku l kv kw">df = df.dropna()<br/>df['Average'] = df[['High', 'Low']].mean(axis=1)<br/>df['Date'] = pd.to_datetime(df['Date'])<br/>df['DateNum'] = df['Date'].values.astype(np.int64) // 10 ** 9<br/>print('successfully added columns: Average, DateNum')</span><span id="9eed" class="ks je hh kj b fi kx ku l kv kw">[*********************100%***********************]  1 of 1 completed<br/>successfully fetched data from yfinance &amp; saved to cache<br/>successfully added columns: Average, DateNum</span></pre><p id="dc9b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们已经下载了我们的股票数据，我们可以看看它是什么样子的。我们首先从列表中获取每20个价格，然后绘制平均价格(从高到低)。</p><pre class="kk kl km kn fd ko kj kp kq aw kr bi"><span id="9272" class="ks je hh kj b fi kt ku l kv kw">#@title Graph Data { run: "auto", vertical-output: true }</span><span id="6368" class="ks je hh kj b fi kx ku l kv kw">dep_cols = ['Average'] #@param {type:"raw"}<br/>indep_col = 'Date' #@param {type:"string"}</span><span id="dfba" class="ks je hh kj b fi kx ku l kv kw">start = 0 #@param {type:"integer"}<br/>stop =  -1#@param {type:"integer"}<br/>step =  20#@param {type:"integer"}</span><span id="a5fd" class="ks je hh kj b fi kx ku l kv kw">plot_features = df[dep_cols]</span><span id="0446" class="ks je hh kj b fi kx ku l kv kw">plot_features.index = df[indep_col]<br/>_ = plot_features.plot(subplots=True)</span><span id="7ed5" class="ks je hh kj b fi kx ku l kv kw">plot_features = df[dep_cols][start:stop:step]<br/>plot_features.index = df[indep_col][start:stop:step]<br/>_ = plot_features.plot(subplots=True)</span></pre><p id="0c19" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在将分割和标准化数据。由于神经网络只能预测从<code class="du kg kh ki kj b">-1</code>到<code class="du kg kh ki kj b">+1</code>的值，我们必须确保数据被标准化以适应这些值。我们还将把数据分成训练、验证和测试数据。由于模型可能会记住训练数据，我们需要模型不知道的数据来准确地测试它。</p><pre class="kk kl km kn fd ko kj kp kq aw kr bi"><span id="9140" class="ks je hh kj b fi kt ku l kv kw">#@title Split &amp; Normalize Data</span><span id="5416" class="ks je hh kj b fi kx ku l kv kw">train = 0.7 #@param {type:"number"}<br/>val = 0.2 #@param {type:"number"}<br/>test = 0.1 #@param {type:"number"}</span><span id="89f1" class="ks je hh kj b fi kx ku l kv kw">normalize = True #@param {type:"boolean"}</span><span id="b497" class="ks je hh kj b fi kx ku l kv kw">dep_cols =  ['Average'] #@param {type:"raw"}<br/>indep_cols = ['DateNum'] #@param {type:"raw"}</span><span id="e0c5" class="ks je hh kj b fi kx ku l kv kw">def without(d, *keys):<br/>  # elided defining without which removes *keys from dict d.</span><span id="235a" class="ks je hh kj b fi kx ku l kv kw">del_cols = list(df.columns) # columns to be removed<br/>for dep_col in dep_cols:<br/>  del_cols.pop(del_cols.index(dep_col))<br/>for indep_col in indep_cols:<br/>  del_cols.pop(del_cols.index(indep_col))<br/>df_only = without(df, *del_cols)<br/>avg_data = df_only['Average'].values.astype(float)</span><span id="031b" class="ks je hh kj b fi kx ku l kv kw">l = len(avg_data)<br/>train_data = avg_data[0:int(l*train)]<br/>val_data = avg_data[int(l*train):int(l*(train+val))]<br/>test_data = avg_data[int(l*(train+val)):]</span><span id="8efd" class="ks je hh kj b fi kx ku l kv kw">mean = avg_data.mean()<br/>std = avg_data.std()</span><span id="4dd3" class="ks je hh kj b fi kx ku l kv kw">if normalize:<br/>  train_data = (train_data - mean) / std<br/>  val_data = (val_data - mean) / std<br/>  test_data = (test_data - mean) / std</span><span id="2673" class="ks je hh kj b fi kx ku l kv kw">print(f'train:\t{len(train_data)}')<br/>print(f'val:\t{len(val_data)}')<br/>print(f'test:\t{len(test_data)}')</span><span id="e960" class="ks je hh kj b fi kx ku l kv kw">train:	2911<br/>val:	832<br/>test:	416</span></pre><p id="27ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们可以把数据转换成张量，这样我们就可以在上面训练了。</p><pre class="kk kl km kn fd ko kj kp kq aw kr bi"><span id="3d91" class="ks je hh kj b fi kt ku l kv kw">#@title Convert Data to Tensors</span><span id="5959" class="ks je hh kj b fi kx ku l kv kw">def create_inout_sequences(input_data, tw):<br/>  inout_seq = []<br/>  for i in range(len(input_data)-tw):<br/>    train_seq = input_data[i:i+tw]<br/>    train_label = input_data[i+tw:i+tw+1]<br/>    inout_seq.append((train_seq ,train_label))<br/>  return inout_seq</span><span id="57dc" class="ks je hh kj b fi kx ku l kv kw">raw_train_data = train_data<br/>train_data = torch.FloatTensor(train_data).view(-1)<br/>train_window = 12</span><span id="63c1" class="ks je hh kj b fi kx ku l kv kw">raw_val_data = val_data<br/>val_data = torch.FloatTensor(val_data).view(-1)</span><span id="a626" class="ks je hh kj b fi kx ku l kv kw">raw_test_data = test_data<br/>test_data = torch.FloatTensor(test_data).view(-1)</span><span id="9ca6" class="ks je hh kj b fi kx ku l kv kw">train_inout_seq = create_inout_sequences(train_data, train_window)</span><span id="39ee" class="ks je hh kj b fi kx ku l kv kw">print(train_inout_seq[:5])</span><span id="19ce" class="ks je hh kj b fi kx ku l kv kw">[(tensor([-1.1586, -1.1591, -1.1572, -1.1543, -1.1551, -1.1513, -1.1431, -1.1360,<br/>        -1.1270, -1.1221, -1.1230, -1.1218]), tensor([-1.1165])), (tensor([-1.1591, -1.1572, -1.1543, -1.1551, -1.1513, -1.1431, -1.1360, -1.1270,<br/>        -1.1221, -1.1230, -1.1218, -1.1165]), tensor([-1.1186])), (tensor([-1.1572, -1.1543, -1.1551, -1.1513, -1.1431, -1.1360, -1.1270, -1.1221,<br/>        -1.1230, -1.1218, -1.1165, -1.1186]), tensor([-1.1109])), (tensor([-1.1543, -1.1551, -1.1513, -1.1431, -1.1360, -1.1270, -1.1221, -1.1230,<br/>        -1.1218, -1.1165, -1.1186, -1.1109]), tensor([-1.1101])), (tensor([-1.1551, -1.1513, -1.1431, -1.1360, -1.1270, -1.1221, -1.1230, -1.1218,<br/>        -1.1165, -1.1186, -1.1109, -1.1101]), tensor([-1.1067]))]</span></pre><p id="c723" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">1</p><p id="2d7b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">100</p><p id="34dd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi">1</p><p id="49f2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">投入</p><p id="d6f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">LSTM</p><p id="aff6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">线性的</p><p id="f4dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出</p><p id="587b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们可以制作模型了，它是<code class="du kg kh ki kj b">torch.nn.Module</code>的子类。</p><pre class="kk kl km kn fd ko kj kp kq aw kr bi"><span id="cb21" class="ks je hh kj b fi kt ku l kv kw">#@title Make Model { vertical-output: true } #@markdown Model: #@markdown ``` #@markdown LSTM( #@markdown (lstm): LSTM(1, 100) #@markdown (linear): Linear(in_features=100, out_features=1, bias=True) #@markdown ) #@markdown ``` class LSTM(nn.Module): def __init__(self, input_size=1, hidden_layer_size=100, output_size=1): super().__init__() self.hidden_layer_size = hidden_layer_size self.lstm = nn.LSTM(input_size, hidden_layer_size) self.linear = nn.Linear(hidden_layer_size, output_size) self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size), torch.zeros(1,1,self.hidden_layer_size)) def forward(self, input_seq): lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell) predictions = self.linear(lstm_out.view(len(input_seq), -1)) return predictions[-1]</span></pre><p id="017d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">建立模型后，我们现在将使用训练数据训练网络。</p><pre class="kk kl km kn fd ko kj kp kq aw kr bi"><span id="7b25" class="ks je hh kj b fi kt ku l kv kw">#@title Train or Load Model { vertical-output: true }<br/>#@markdown Check `load_model` to load the model. Uncheck to train the model.<br/>load_model = True #@param {type:"boolean"}<br/>load_model_from = './models/epoch-190.pt' #@param {type:"string"}<br/>epochs = 200 #@param {type:"integer"}<br/>save_model_to = './models-{datetime}' #@param {type:"string"}<br/>show_status_every = 5 #@param {type:"integer"}</span><span id="fe09" class="ks je hh kj b fi kx ku l kv kw"># Make model<br/>model = LSTM()<br/>loss_function = nn.MSELoss()<br/>optimizer = torch.optim.Adam(model.parameters(), lr=0.001)<br/># elided<br/>if load_model:<br/>  # elided<br/>  model.load_state_dict(torch.load(load_model_from))<br/>else:<br/>  # elided</span><span id="22e5" class="ks je hh kj b fi kx ku l kv kw">  for epoch in range(epochs):<br/>    # elided<br/>    for seq, labels in train_inout_seq: # Train for an epoch<br/>      optimizer.zero_grad()<br/>      model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),<br/>                      torch.zeros(1, 1, model.hidden_layer_size))<br/>      y_pred = model(seq)<br/>      single_loss = loss_function(y_pred, labels)<br/>      single_loss.backward()<br/>      optimizer.step()</span><span id="a676" class="ks je hh kj b fi kx ku l kv kw">    # Save model<br/>    torch.save(<br/>      model.state_dict(), <br/>      os.path.join(save_model_to, f'epoch-{epoch}-state.pt'),<br/>    )<br/>    # elided</span></pre><p id="55cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们的模型已经训练好了。我们可以看到它在测试数据中的表现。<code class="du kg kh ki kj b">x</code>变量是<code class="du kg kh ki kj b">train_window</code>训练窗口中值的索引范围。通过这种方式，我们可以将这些值与真实数据对齐。</p><pre class="kk kl km kn fd ko kj kp kq aw kr bi"><span id="74ae" class="ks je hh kj b fi kt ku l kv kw">#@title Predict &amp; Plot Predicted Data { vertical-output: true }<br/>test_inputs = test_data[-train_window:].tolist()</span><span id="deb1" class="ks je hh kj b fi kx ku l kv kw">model.eval()</span><span id="4771" class="ks je hh kj b fi kx ku l kv kw">for i in range(train_window):<br/>    seq = torch.FloatTensor(test_inputs[-train_window:])<br/>    with torch.no_grad():<br/>        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),<br/>                        torch.zeros(1, 1, model.hidden_layer_size))<br/>        test_inputs.append(model(seq).item())</span><span id="d698" class="ks je hh kj b fi kx ku l kv kw">actual_predictions = (np.array(test_inputs[train_window:]).reshape(-1, 1)) * std + mean</span><span id="8b52" class="ks je hh kj b fi kx ku l kv kw">plt.title('Predicted Data: Time v Price (all)')<br/>plt.xlabel('Time')<br/>plt.ylabel('Price')<br/>plt.grid(True)<br/>plt.autoscale(axis='x', tight=True)<br/>plt.plot(test_data * std + mean)<br/>x = np.arange(len(test_data)-train_window-1, len(test_data)-1, 1)<br/>plt.plot(x,actual_predictions)<br/>plt.show()</span><span id="0cdb" class="ks je hh kj b fi kx ku l kv kw"># elided as it almost the same as above</span></pre><p id="1f75" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型的预测是图中的橙色线。如您所见，我们的模型能够捕捉价格趋势，并根据之前的价格做出合理的预测。</p><h1 id="04b4" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">结论</h1><p id="edb5" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">LSTMs广泛用于解决序列问题，例如预测股票。在本文中，我们介绍了如何实现LSTM网络并使用它来预测股票价格，并将其与实际价格进行比较的步骤。</p></div></div>    
</body>
</html>