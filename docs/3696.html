<html>
<head>
<title>Udacity Capstone-Identifying Dog Breeds Using Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用卷积神经网络识别狗的品种</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/identifying-dog-breeds-using-convolutional-neural-networks-e1a039db87e4?source=collection_archive---------12-----------------------#2021-07-18">https://medium.com/analytics-vidhya/identifying-dog-breeds-using-convolutional-neural-networks-e1a039db87e4?source=collection_archive---------12-----------------------#2021-07-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/b0791cb54d415cc85f240b6df78515bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0_XqS9Coorib-FGGwNziuQ.jpeg"/></div></div></figure><h1 id="8c7d" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">项目概述</h1><p id="b32d" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">在这个项目中，我训练了卷积神经网络(CNN)来对图像中的狗的品种进行分类！CNN是一类深度神经网络，在分析和学习视觉数据模式方面非常强大。然而，CNN可能需要大量数据集和大量计算时间来训练。为了在有限的训练数据量下达到可接受的分类精度水平，在训练期间应用迁移学习可能非常有用。</p><p id="5e0c" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">迁移学习是一个过程，在这个过程中，您将从以前解决的问题中学到的许多特征提取器作为训练模型的起点。通过这种方法，我们可以利用这样一个事实，即一些模型已经使用数百万张训练图像训练了数千个GPU小时。使用这种方法，可以用较少的训练数据和训练时间获得较高的精度。</p></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><h1 id="715e" class="ip iq hh bd ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji lb jk jl jm bi translated">项目目标</h1><p id="1240" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">目标是创建一个犬种分类器算法，该算法能够正确分类测试数据集中至少60%的犬种。</p><p id="2c6e" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">该算法接受图像作为输入，并完成以下任务。</p><ul class=""><li id="1c29" class="lc ld hh jp b jq kl ju km jy le kc lf kg lg kk lh li lj lk bi translated">如果在图像中检测到一只<strong class="jp hi">狗</strong>，返回预测的品种。</li><li id="0f59" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">如果在图像中检测到一个<strong class="jp hi">人</strong>，返回相似的狗品种。</li><li id="6cdd" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">如果图像中未检测到<strong class="jp hi">或</strong>，则提供指示错误的输出。</li></ul><p id="5a5c" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">达到这个测试精度后，我们将测试从互联网上收集的一些图像，看看结果。</p></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><h1 id="3a80" class="ip iq hh bd ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji lb jk jl jm bi translated">实现目标的策略</h1><p id="c0a0" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">为实现这一目标而制定的战略如下:</p><ul class=""><li id="ca9b" class="lc ld hh jp b jq kl ju km jy le kc lf kg lg kk lh li lj lk bi translated">步骤0:导入数据集</li><li id="1ab7" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">第一步:探测人类</li><li id="76d9" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">第二步:探测狗</li><li id="b957" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">第三步:创建一个CNN来分类狗的品种(从头开始)</li><li id="09f9" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">第四步:创建一个CNN对狗的品种进行分类(使用迁移学习)</li><li id="9e08" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">第五步:写一个算法</li><li id="bce3" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">步骤6:测试算法</li></ul></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><h1 id="8d93" class="ip iq hh bd ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji lb jk jl jm bi translated">韵律学</h1><p id="0d1e" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">我将用来评估每个模型的分类标准是准确性标准。为了测量模型的准确性，我将使用模型来预测测试集中所有图像的狗的品种，然后计算模型正确预测的图像的比例。</p><p id="143b" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">尽管数据集的类并不是完全平衡的，但由于类的数量，在这种情况下精确度是一个很好的衡量标准。如果模型只是猜测和预测每个图像都是训练集中最常见的狗品种，那么模型将准确预测不到百分之一的测试图像。</p></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><h1 id="35f3" class="ip iq hh bd ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji lb jk jl jm bi translated">探索性数据分析</h1><p id="137f" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">为了训练和测试我们的狗品种分类器，Udacity非常好心地给我提供了许多狗的标签图像。通过探索数据，我们看到有8300个标记的狗图像，其中标签是133个狗品种中的一个。为了训练一个bog品种分类器，我把数据分成训练、验证和测试数据集。</p><p id="bbec" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">训练前，了解数据中犬种的分布很重要。我们可以在下面看到，不同品种之间的数据并不完全平衡，但最低代表品种仍然有超过25个训练样本图像。</p><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lq"><img src="../Images/188d017c720b29191899bf21020fd374.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VBqvaSqiLDa7QW-8gzauXw.png"/></div></div></figure></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><h1 id="43fc" class="ip iq hh bd ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji lb jk jl jm bi translated">数据可视化</h1><p id="a791" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">同样在训练之前，重要的是要想象一些图像，以确定狗是在什么样的环境中被拍摄的。如果所有的狗都是在室内拍摄的，那么这个模型在室外拍摄的图像上可能就不那么适用了。</p><p id="d05a" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">下面我们可以看到两个例子，它们很好地展示了整个数据集的样子。这个数据集中的狗是在各种各样的环境中拍摄的，这可能会使我们的模型更难训练，但当它被训练时，它应该可以在许多环境中工作。</p><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es lv"><img src="../Images/91a6cb10130897ea63b605dc8b07afaa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*4CgC-YaHuxJJ_OhyofD5rg.jpeg"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">达尔马提亚狗</figcaption></figure><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ma"><img src="../Images/712a5f87170e3a37f85c33fd24cc9466.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rpurYy7PJqtHMq2DrIGEnA.jpeg"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">英国史宾格猎犬</figcaption></figure></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><h1 id="a8f1" class="ip iq hh bd ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji lb jk jl jm bi translated">履行</h1><p id="698a" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated"><strong class="jp hi">步骤0:导入数据集和必要的库</strong></p><p id="24df" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">以下2个数据集由Udacity提供</p><ol class=""><li id="afe0" class="lc ld hh jp b jq kl ju km jy le kc lf kg lg kk mb li lj lk bi translated"><a class="ae mc" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip" rel="noopener ugc nofollow" target="_blank">训练模型的狗图片</a> s</li><li id="7a65" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk mb li lj lk bi translated"><a class="ae mc" href="https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/lfw.zip" rel="noopener ugc nofollow" target="_blank">人脸检测器</a></li></ol><p id="323a" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">笔记本中使用的库如下</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="c3ef" class="mi iq hh me b fi mj mk l ml mm">from sklearn.datasets import load_files <br/>from keras.utils import np_utils<br/>import numpy as np<br/>from glob import glob<br/>from keras.applications.resnet50 import ResNet50<br/>from keras.preprocessing import image<br/>from tqdm import tqdm</span><span id="4e8f" class="mi iq hh me b fi mn mk l ml mm">from keras.applications.resnet50 import preprocess_input, decode_predictions</span><span id="9c55" class="mi iq hh me b fi mn mk l ml mm">from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D</span><span id="989f" class="mi iq hh me b fi mn mk l ml mm">from PIL import ImageFile<br/>from keras.layers import Dropout, Flatten, Dense<br/>from keras.models import Sequential<br/>from keras.callbacks import ModelCheckpoint<br/>from extract_bottleneck_features import *</span><span id="4484" class="mi iq hh me b fi mn mk l ml mm">import random<br/>import cv2                <br/>import matplotlib.pyplot as plt</span></pre><p id="98d3" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">步骤1:检测图像中的人</strong></p><p id="95d0" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">OpenCV实现的<a class="ae mc" href="http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html" rel="noopener ugc nofollow" target="_blank">基于Haar特征的级联分类器</a>在这个项目中用于检测人脸。OpenCV提供了许多预先训练好的人脸检测器，作为XML文件存储在<a class="ae mc" href="https://github.com/opencv/opencv/tree/master/data/haarcascades" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上。我们已经下载了这些检测器中的一个，并将其存储在<code class="du mo mp mq me b">haarcascades</code>目录中。</p><p id="53db" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">下面提供的代码单元演示了如何使用该检测器在样本图像中查找人脸。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="3ef0" class="mi iq hh me b fi mj mk l ml mm"># extract pre-trained face detector<br/>face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')</span><span id="6b67" class="mi iq hh me b fi mn mk l ml mm">def face_detector(img_path):<br/>    img = cv2.imread(img_path)<br/>    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br/>    faces = face_cascade.detectMultiScale(gray)<br/>    return len(faces) &gt; 0</span><span id="5d12" class="mi iq hh me b fi mn mk l ml mm">human_files_short = human_files[:100]<br/>dog_files_short = train_files[:100]<br/># Do NOT modify the code above this line.<br/>face_dec = np.vectorize(face_detector)<br/>human_face_detected =face_dec(human_files_short)<br/>dog_detected = face_dec(dog_files_short)</span><span id="cf34" class="mi iq hh me b fi mn mk l ml mm">print(" Human Face Detected with {:.1f}%accuracy".format(sum(human_face_detected)))<br/>print("Dog detected with  {:.1f}% error".format(sum(dog_detected)))<br/></span></pre><ul class=""><li id="9420" class="lc ld hh jp b jq kl ju km jy le kc lf kg lg kk lh li lj lk bi translated">正确识别的人数:100</li><li id="918c" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">被认为有人类的狗的数量:11</li></ul><p id="496b" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">结果并不完美，但还可以接受。</p><p id="b056" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">步骤2:检测图像中的狗</strong></p><p id="a2c3" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在本节中，我们使用预训练的<a class="ae mc" href="http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006" rel="noopener ugc nofollow" target="_blank"> ResNet-50 </a>模型来检测图像中的狗。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="9aee" class="mi iq hh me b fi mj mk l ml mm">from keras.applications.resnet50 import ResNet50# define ResNet50 model<br/>ResNet50_model = ResNet50(weights='imagenet')</span></pre><p id="33db" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在输入图像中检测狗的过程包括两个步骤。第一步是处理输入的图像数据，第二步是根据处理后的图像进行预测。</p><p id="01e5" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi"> <em class="mr">预处理</em> </strong></p><p id="ac51" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在将数据传递到Resnet 50模型进行预测之前，我们需要对图像数据进行一些预处理。我们这样做是因为使用TensorFlow作为后端的Keras CNNs要求输入是4D数组。输入数组的形式如下:</p><p id="fc62" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">(样本数、行数、列数、通道数)</p><p id="b593" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">为了实现以下功能，定义了:</p><p id="2330" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi"> Path_to_tensor </strong>:这个函数接受一个彩色图像的字符串值文件路径作为输入，并返回一个适合提供给Keras CNN的4D张量。该函数首先加载图像，并将其调整为224×224像素的正方形图像。然后，图像被转换成一个数组，数组的大小被调整为4D张量。在这种情况下，由于我们正在处理彩色图像，每个图像有三个通道。</p><p id="ea8a" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi"> Paths_to_tensor: </strong>该函数将字符串值图像路径的NumPy数组作为输入，并返回具有所需形状的4D张量。在我们的数据为模型做好准备之前，要采取的最后一步包括额外的归一化步骤，即获取ImageNet中所有图像的所有像素的平均像素值(用RGB表示为[103.939，116.779，123.68])，并从每个图像的每个像素中减去它。这是在导入函数<code class="du mo mp mq me b">preprocess_input</code>中实现的，可以在<a class="ae mc" href="https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py" rel="noopener ugc nofollow" target="_blank">这里找到</a>。</p><p id="bfdd" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">这两个函数的代码如下所示。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="c7fd" class="mi iq hh me b fi mj mk l ml mm">from keras.preprocessing import image                  <br/>from tqdm import tqdm</span><span id="f5b6" class="mi iq hh me b fi mn mk l ml mm">def path_to_tensor(img_path):<br/>    # loads RGB image as PIL.Image.Image type<br/>    img = image.load_img(img_path, target_size=(224, 224))<br/>    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)<br/>    x = image.img_to_array(img)<br/>    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor<br/>    return np.expand_dims(x, axis=0)</span><span id="4a2f" class="mi iq hh me b fi mn mk l ml mm">def paths_to_tensor(img_paths):<br/>    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]<br/>    return np.vstack(list_of_tensors)</span></pre><p id="d851" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi"> <em class="mr">做出预测</em> </strong></p><p id="cd20" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">下面显示的函数是用于进行预测的函数，它使用predict函数来获得ImageNet的1000个类的数组。然后，我们使用NumPy的argmax函数来隔离概率最高的类。</p><p id="9ead" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在ImageNet类的输出字典中(在这里找到<a class="ae mc" href="https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a" rel="noopener ugc nofollow" target="_blank"/>)，条目151到269表示狗，因此我们编写了第二个函数，使用这个字典来确定图像中的任何已识别对象是否属于这个字典范围。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="1050" class="mi iq hh me b fi mj mk l ml mm">from keras.applications.resnet50 import preprocess_input, decode_predictions</span><span id="57cd" class="mi iq hh me b fi mn mk l ml mm">def ResNet50_predict_labels(img_path):<br/>    # returns prediction vector for image located at img_path<br/>    img = preprocess_input(path_to_tensor(img_path))<br/>    return np.argmax(ResNet50_model.predict(img))</span><span id="2ca8" class="mi iq hh me b fi mn mk l ml mm">def dog_detector(img_path):<br/>    prediction = ResNet50_predict_labels(img_path)<br/>    return ((prediction &lt;= 268) &amp; (prediction &gt;= 151))</span></pre><p id="1749" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">下面的代码用于测试狗检测器的准确性，结果是0%的人图像和100%的狗图像检测到人脸</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="bd39" class="mi iq hh me b fi mj mk l ml mm">human_files_short = human_files[:100]<br/>dog_files_short = train_files[:100]<br/><br/>dog_dec = np.vectorize(dog_detector)<br/><br/>human_face_detected =dog_dec(human_files_short)<br/>dog_detected = dog_dec(dog_files_short)</span><span id="39cd" class="mi iq hh me b fi mn mk l ml mm">print("{:.1f}% of Humans are detected as dogs".format(sum(human_face_detected)))<br/>print("{:.1f}% of Dogs detected in the first 100 files".format(sum(dog_detected)))<br/></span></pre><p id="a872" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">第三步:创建一个CNN对狗的品种进行分类(从头开始)</strong></p><p id="2a03" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">尽管该项目的目标是使用迁移学习建立一个狗品种分类器，但该项目的这一部分对于理解CNN的基本原理及其工作方式是有用的。</p><p id="58c1" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们首先通过将每个图像中的每个像素除以255来重新缩放图像。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="da09" class="mi iq hh me b fi mj mk l ml mm">from PIL import ImageFile <br/>ImageFile.LOAD_TRUNCATED_IMAGES = True</span><span id="0be3" class="mi iq hh me b fi mn mk l ml mm"># pre-process the data for Keras<br/>train_tensors = paths_to_tensor(train_files).astype(‘float32’)/255<br/>valid_tensors = paths_to_tensor(valid_files).astype(‘float32’)/255<br/>test_tensors = paths_to_tensor(test_files).astype(‘float32’)/255</span></pre><p id="838b" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们用下面的代码创建了一个CNN来分类狗的品种</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="3d15" class="mi iq hh me b fi mj mk l ml mm">from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D<br/>from keras.layers import Dropout, Flatten, Dense<br/>from keras.models import Sequential<br/><br/>model = Sequential()<br/>model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', input_shape=(224, 224, 3)))<br/>model.add(MaxPooling2D(pool_size=2))</span><span id="531e" class="mi iq hh me b fi mn mk l ml mm">model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))<br/>model.add(MaxPooling2D(pool_size=2))</span><span id="f4e8" class="mi iq hh me b fi mn mk l ml mm">model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))<br/>model.add(MaxPooling2D(pool_size=2))<br/>model.add(GlobalAveragePooling2D())<br/>model.add(Dense(133, activation='relu'))</span><span id="c151" class="mi iq hh me b fi mn mk l ml mm">model.summary()</span></pre><p id="f35a" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">大纲:</p><ol class=""><li id="f5f8" class="lc ld hh jp b jq kl ju km jy le kc lf kg lg kk mb li lj lk bi translated">我们创建了3个卷积层，中间有3个最大池层，以了解高级功能的层次结构。添加最大池层以减少维度。</li><li id="4236" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk mb li lj lk bi translated">我们在3个卷积层中使用了3个滤波器' 16，32，64 '。</li><li id="63dd" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk mb li lj lk bi translated">整流线性激活函数或简称ReLU是一个分段线性函数，如果它是正的，它将直接输出输入，否则，它将输出零。所以，我们对所有的层都使用了ReLu激活函数。</li><li id="f8bc" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk mb li lj lk bi translated">GlobalAveragePooling2D做了一些不同的事情。它在空间维度上应用平均池，直到每个空间维度都是一个，而其他维度保持不变。</li><li id="42e5" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk mb li lj lk bi translated">最后一个全连接层中的节点数设置为133，并使用ReLu激活函数来获得预测的概率。</li></ol><p id="1b81" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">获得的输出:</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="ef81" class="mi iq hh me b fi mj mk l ml mm">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d_25 (Conv2D)           (None, 224, 224, 16)      208       <br/>_________________________________________________________________<br/>max_pooling2d_26 (MaxPooling (None, 112, 112, 16)      0         <br/>_________________________________________________________________<br/>conv2d_26 (Conv2D)           (None, 112, 112, 32)      2080      <br/>_________________________________________________________________<br/>max_pooling2d_27 (MaxPooling (None, 56, 56, 32)        0         <br/>_________________________________________________________________<br/>conv2d_27 (Conv2D)           (None, 56, 56, 64)        8256      <br/>_________________________________________________________________<br/>max_pooling2d_28 (MaxPooling (None, 28, 28, 64)        0         <br/>_________________________________________________________________<br/>global_average_pooling2d_2 ( (None, 64)                0         <br/>_________________________________________________________________<br/>dense_10 (Dense)             (None, 133)               8645      <br/>=================================================================<br/>Total params: 19,189<br/>Trainable params: 19,189<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="cb70" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在编译了上述模型，并使用训练和验证数据对其进行拟合之后，我接着在我们的测试图像上测试了该模型，并看到该模型对1.0766%的测试图像正确地预测了狗的品种。</p><p id="13d4" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">为了获得更好的准确性，我们将使用迁移学习，看看我们能获得多大的改进。</p><p id="f514" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">步骤4:使用CNN对狗的品种进行分类(使用迁移学习)</strong></p><p id="fad1" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">为了在不牺牲准确性的情况下减少训练时间，我们可以使用迁移学习来训练CNN。在接下来的步骤中，我们使用迁移学习在我们自己的CNN上进行训练。为了提高精确度，我首先尝试使用VGG-16模型作为起点。通过在我们的训练和验证数据上训练该模型，该模型能够在42.7033%的测试图像上正确预测狗的品种。以下是模型总结:</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="c2d3" class="mi iq hh me b fi mj mk l ml mm">VGG16_model = Sequential()<br/>VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))<br/>VGG16_model.add(Dense(133, activation=’softmax’))</span><span id="f2cb" class="mi iq hh me b fi mn mk l ml mm">VGG16_model.summary()<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>global_average_pooling2d_3 ( (None, 512)               0         <br/>_________________________________________________________________<br/>dense_11 (Dense)             (None, 133)               68229     <br/>=================================================================<br/>Total params: 68,229<br/>Trainable params: 68,229<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="0ae9" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">精确度的提高是一个巨大的进步，但是离我们想要的还很远。接下来，我选择利用在ImageNet数据库上训练的Resnet 50 CNN来构建我的CNN。Resnet 50模型的瓶颈特性是存在的，我只需要下载我们的Resnet 50 CNN的文件，然后用下面的代码导入它。</p><p id="47f8" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">通过运行以下命令提取与训练集、测试集和验证集对应的瓶颈特征:</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="39bc" class="mi iq hh me b fi mj mk l ml mm">bottleneck_features = np.load(‘bottleneck_features/DogResnet50Data.npz’)<br/>train_Resnet50 = bottleneck_features[‘train’]<br/>valid_Resnet50 = bottleneck_features[‘valid’]<br/>test_Resnet50 = bottleneck_features[‘test’]</span></pre><p id="52f1" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">新数据集很小，并且与原始训练数据相似，因此网络的末端被切掉，并且添加了与新数据集中的类的数量相匹配的完全连接的层。接下来，新的全连接层的权重被随机化；来自预训练网络的所有权重都被冻结。最后，训练网络来更新新的全连接层的权重。</p><p id="d2d7" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">应用Resnet50模型后，准确率达到75%以上。我还添加了一个具有500个节点的全连接层和一个ReLu激活函数来检测更多的模式和一个Dropout以避免过度拟合。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="a06c" class="mi iq hh me b fi mj mk l ml mm">from keras.layers import Dropout</span><span id="79b9" class="mi iq hh me b fi mn mk l ml mm">Resnet50_model = Sequential()<br/>Resnet50_model.add(GlobalAveragePooling2D(input_shape=train_Resnet50.shape[1:]))<br/>Resnet50_model.add(Dense(133, activation='softmax'))</span><span id="2ae2" class="mi iq hh me b fi mn mk l ml mm">Resnet50_model.summary()</span><span id="c04d" class="mi iq hh me b fi mn mk l ml mm">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>global_average_pooling2d_6 ( (None, 2048)              0         <br/>_________________________________________________________________<br/>dense_16 (Dense)             (None, 133)               272517    <br/>=================================================================<br/>Total params: 272,517<br/>Trainable params: 272,517<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="14a3" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">定义架构后，使用下面的代码对其进行编译和训练。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="2acb" class="mi iq hh me b fi mj mk l ml mm">Resnet50_model.compile(loss=’categorical_crossentropy’, optimizer=’rmsprop’, metrics=[‘accuracy’])</span></pre><p id="3664" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们跟踪所有时期并加载最佳参数，以确保我们的CNN在训练过程中具有最高精度的权重。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="7e1f" class="mi iq hh me b fi mj mk l ml mm">from keras.callbacks import ModelCheckpoint</span><span id="00c1" class="mi iq hh me b fi mn mk l ml mm">checkpointer = ModelCheckpoint(filepath=’saved_models/weights.best.Resnet50.hdf5', <br/> verbose=1, save_best_only=True)</span><span id="8b0f" class="mi iq hh me b fi mn mk l ml mm">Resnet50_model.fit(train_Resnet50, train_targets, <br/> validation_data=(valid_Resnet50, valid_targets),<br/> epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)</span></pre><p id="e296" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">现在，我们已经使用下面的代码加载了具有最佳验证损失的模型</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="2300" class="mi iq hh me b fi mj mk l ml mm">Resnet50_model.load_weights(‘saved_models/weights.best.Resnet50.hdf5’)</span></pre><p id="ef7d" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我们测试了用下面的代码实现的模型的准确性，得到了80.7416%的准确性。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="af4e" class="mi iq hh me b fi mj mk l ml mm"># get index of predicted dog breed for each image in test set<br/>Resnet50_predictions = [np.argmax(Resnet50_model.predict(np.expand_dims(feature, axis=0))) for feature in test_Resnet50]</span><span id="5be3" class="mi iq hh me b fi mn mk l ml mm"># report test accuracy<br/>test_accuracy = 100*np.sum(np.array(Resnet50_predictions)==np.argmax(test_targets, axis=1))/len(Resnet50_predictions)<br/>print(‘Test accuracy: %.4f%%’ % test_accuracy)</span></pre><p id="f17c" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">下一步是将它放入一个函数中，该函数将接收图像路径并预测图像中的狗的品种。为此任务定义的函数如下所示。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="75ea" class="mi iq hh me b fi mj mk l ml mm">from extract_bottleneck_features import *</span><span id="6c4d" class="mi iq hh me b fi mn mk l ml mm">def Resnet50_predict_breed(img_path):<br/> # extract bottleneck features<br/> bottleneck_feature = extract_Resnet50(path_to_tensor(img_path))<br/> # obtain predicted vector<br/> predicted_vector = Resnet50_model.predict(bottleneck_feature)<br/> # return dog breed that is predicted by the model<br/> return dog_names[np.argmax(predicted_vector)]</span></pre><p id="0bd9" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">第五步:编写算法</strong></p><p id="5fbf" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">在这里，我们创建我们的算法来分析任何图像。该算法接受文件路径，并且:</p><ul class=""><li id="1838" class="lc ld hh jp b jq kl ju km jy le kc lf kg lg kk lh li lj lk bi translated">如果在图像中检测到一只<strong class="jp hi">狗</strong>，返回预测的品种。</li><li id="d296" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">如果在图像中检测到一个<strong class="jp hi">人</strong>，返回相似的狗品种。</li><li id="ede6" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">如果在图像中没有检测到<strong class="jp hi">或</strong>，则提供指示错误的输出。</li></ul><p id="3515" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">该算法收集我们之前使用的所有函数来创建最终输出并显示图像。</p><pre class="lr ls lt lu fd md me mf mg aw mh bi"><span id="f2c6" class="mi iq hh me b fi mj mk l ml mm">def display_img(img_path):<br/> img = cv2.imread(img_path)<br/> cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)<br/> imgplot = plt.imshow(cv_rgb)<br/> return imgplot</span><span id="88a1" class="mi iq hh me b fi mn mk l ml mm">def predict_breed(img_path):<br/> display_img(img_path)<br/> if dog_detector(img_path):<br/> return print(“It’s a Dog and the breed is {}”.format(Resnet50_predict_breed(img_path)))<br/> <br/> if face_detector(img_path):<br/> <br/> return print(“if you were a dog you’ll be a {}!!”.format(Resnet50_predict_breed(img_path)))<br/> <br/> else:<br/> return print(“Definitely not a Human or a Dog”)</span></pre><p id="5808" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">第六步:测试算法</strong></p><p id="7c10" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">我用从互联网上随机获取的图片测试了该算法，结果如下:</p><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/e7cc87200ad5129e87d8e0291d2200c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:774/format:webp/1*PSoJQ2i-_Yb6BVSpu9us9A.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd ir">是狗，品种是ages/train/071。德国_牧羊犬_狗</strong></figcaption></figure><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/bbd691fd18f3973641f8a9212c301d5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*p-kn4i4oSenmlACeLFJXfQ.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd ir">是一只狗，品种是ages/train/133。约克夏_梗</strong></figcaption></figure><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/0f34368ffa166e8fe5db558eda4b212e.png" data-original-src="https://miro.medium.com/v2/resize:fit:412/format:webp/1*AU5Q_pLU-qVSui4iK7dPfg.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">如果你是一只狗，你将会是一只狗。丝滑_梗！！</figcaption></figure><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/c4afb91e88a5bc998f2682bd1567d005.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*ndtACU0uu9P3NKh5gE8_Ig.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd ir">是狗，品种是ages/train/076。金毛寻回犬</strong></figcaption></figure><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es mv"><img src="../Images/3750746e326e4452c2c1fa94f1c4898d.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*bsyKVFvBZFAAqSq5xqrjlw.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd ir">是狗，品种是ages/train/041。斗牛犬</strong></figcaption></figure><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/a7b3734b7386ea97434b1a4b1262e541.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*3nMa14m4cWLrsEfLHN5EYw.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">是一只狗，品种是ages/train/034。拳击手</figcaption></figure><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es mw"><img src="../Images/13986045473f023792b12a3306f61fbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:474/format:webp/1*hJLkVf6SpZLZX6NY1Kjk0g.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated"><strong class="bd ir">肯定不是人也不是狗</strong></figcaption></figure></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><h1 id="be3d" class="ip iq hh bd ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji lb jk jl jm bi translated">结果</h1><p id="82f5" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">以下是每个模型在测试集上获得的准确度。</p><ul class=""><li id="2ec8" class="lc ld hh jp b jq kl ju km jy le kc lf kg lg kk lh li lj lk bi translated">CNN从零开始:1.0766%</li><li id="4a7e" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">来自VGG16的CNN:42.7033%</li><li id="54c7" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">来自Resnet50的CNN:80.7416%</li></ul><p id="33f1" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">模型评估和验证</strong></p><p id="41f7" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">用Resnet50训练的CNN在测试集上达到了可接受的80.7416%的准确率。我相信这个精度是可以接受的，因为应用程序的目的。使用这个程序是为了乐趣，所以它应该相当准确，但是一点点的不准确实际上可以增加乐趣！</p><p id="706a" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated"><strong class="jp hi">理由</strong></p><p id="9289" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">模型之间精度差异的一个原因是每个模型中使用的参数数量。CNN从头开始使用了19，189个参数，VGG-16模型使用了68，229个参数，Resnet50模型使用了272，517个参数。更多的参数可能导致过度拟合，并学习训练集的过于具体的细节。然而，上面的精度是在测试集上用训练中没有使用的数据计算的。因此，我们可以看到，由于测试精度提高，过拟合不是问题。</p></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><h1 id="b060" class="ip iq hh bd ir is kx iu iv iw ky iy iz ja kz jc jd je la jg jh ji lb jk jl jm bi translated"><strong class="ak">倒影</strong></h1><p id="e365" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">产量比我预期的要好。即使图片中有人脸，算法也匹配得很好。然而，对于看起来非常接近的赛狗来说，要把它弄对似乎仍然很棘手。</p><p id="f536" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">使用Keras从零开始构建CNN可能很简单，但它显然不是有效的，只能正确分类百分之一的测试图像。幸运的是，迁移学习有助于解决这个问题。在以两个不同的预训练模型作为起点进行实验后，我偶然发现了Resnet50模型，它帮助我在测试集上达到了80.7416%的准确率，我认为这是可以接受的。</p><h1 id="54f8" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">丰富</h1><p id="aded" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">我想尝试以下实验，看看它们是否能进一步提高精确度:</p><ul class=""><li id="c869" class="lc ld hh jp b jq kl ju km jy le kc lf kg lg kk lh li lj lk bi translated">图像增强</li><li id="f202" class="lc ld hh jp b jq ll ju lm jy ln kc lo kg lp kk lh li lj lk bi translated">通过增加神经网络的深度</li></ul></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><p id="7d33" class="pw-post-body-paragraph jn jo hh jp b jq kl js jt ju km jw jx jy kn ka kb kc ko ke kf kg kp ki kj kk ha bi translated">链接到GitHub:<a class="ae mc" href="https://github.com/lakshman533/Dog-Breed-Identifier" rel="noopener ugc nofollow" target="_blank">https://github.com/lakshman533/Dog-Breed-Identifier</a></p></div></div>    
</body>
</html>