<html>
<head>
<title>Demystifying Hidden Units in Neural Networks through Network Dissection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过网络剖析揭示神经网络中的隐藏单元</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/demystifying-hidden-units-in-neural-networks-through-network-dissection-7d3ac657c428?source=collection_archive---------14-----------------------#2021-05-16">https://medium.com/analytics-vidhya/demystifying-hidden-units-in-neural-networks-through-network-dissection-7d3ac657c428?source=collection_archive---------14-----------------------#2021-05-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="9414" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">麻省理工学院CSAIL的研究人员通过他们引人入胜的论文“<a class="ae iw" href="http://netdissect.csail.mit.edu/" rel="noopener ugc nofollow" target="_blank">网络剖析:量化深度视觉表征的可解释性</a>”阐述了神经网络预测背后的思维过程。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es ix"><img src="../Images/c91b16ffd0fa4e24eece31fa952c19ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*X0IyRVsBsqkr_u_9QCMhHQ.jpeg"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">由<a class="ae iw" href="https://unsplash.com/@alinnnaaaa" rel="noopener ugc nofollow" target="_blank">阿丽娜·格鲁布尼亚</a>在Unsplash上拍摄的照片</figcaption></figure><p id="12ee" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">你有没有想过神经网络(NN)一旦被训练后是如何进行预测的？解剖NN，找出隐藏单元都学了什么，岂不是很有意思？你认为隐藏单元对训练后的神经网络预测有什么贡献？嗯，当一个人的模型继续训练时，他有足够的时间来思考这种复杂的深层网络。唉，一个深度学习的新手怎么可能把探头放在隐藏的单元上，解读出来。所以，我很自然地抛弃了这些想法，直到我偶然发现了论文“<a class="ae iw" href="http://netdissect.csail.mit.edu/final-network-dissection.pdf" rel="noopener ugc nofollow" target="_blank">网络剖析:量化深度视觉表征的可解释性</a>”。</p><h1 id="cd72" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">关于论文:</h1><p id="6541" class="pw-post-body-paragraph jj jk hh jl b jm kx ii jo jp ky il jr js kz ju jv jw la jy jz ka lb kc kd ke ha bi translated">来自麻省理工学院CSAIL的研究人员提出了一种称为“<a class="ae iw" href="http://netdissect.csail.mit.edu/" rel="noopener ugc nofollow" target="_blank">网络剖析</a>的技术，他们在二进制分割任务中评估CNN中的每个单独的卷积单元，以表征一个单元的行为。换句话说，这种方法通过向网络的隐藏单元提供有意义的标签来解释网络。他们已经表明，解释单元可以用来为分类器给出的单个图像预测提供解释。</p><p id="4dae" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">过去，对隐藏单元的观察表明，人类可以解释的概念有时会出现在网络中的单个单元中。例如，在场景分类网络 中已经观察到<a class="ae iw" href="https://arxiv.org/pdf/1412.6856.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">对象检测器单元，并且在视觉识别任务</strong> </a> <strong class="jl hi">中已经出现<a class="ae iw" href="https://arxiv.org/pdf/1607.03738.pdf" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">部分检测器。</strong></a></strong></p><p id="285a" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">使用<strong class="jl hi"> </strong>“网络剖析”，作者评估了这种概念检测器在深度网络中的出现，量化了CNN中单个单元的可解释性，并试图回答问题-“<em class="lc">CNN是否学习了被解开的特征？”。<br/>注意:解开的特征是狭义定义的隐藏单元，编码特定的现实世界概念。</em></p><h1 id="6080" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">网络剖析法:</h1><p id="3c2b" class="pw-post-body-paragraph jj jk hh jl b jm kx ii jo jp ky il jr js kz ju jv jw la jy jz ka lb kc kd ke ha bi translated">单个单元的可解释性通过测量隐藏单元的响应和一组视觉概念之间的一致性来量化。人类可以理解的概念包括像颜色这样的低级概念和像物体这样的高级概念。通过测量与每个单元最匹配的概念，网络剖析可以分解层中表示的概念类型。</p><p id="6ada" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">使用网络剖析量化单个单元的可解释性分三步进行:</p><h2 id="0da2" class="ld kg hh bd kh le lf lg kl lh li lj kp js lk ll kr jw lm ln kt ka lo lp kv lq bi translated"><strong class="ak"> 1:用人类标注的视觉概念采集图像。</strong></h2><p id="c061" class="pw-post-body-paragraph jj jk hh jl b jm kx ii jo jp ky il jr js kz ju jv jw la jy jz ka lb kc kd ke ha bi translated">为了识别一组广泛的视觉概念的基础事实样本，作者组装了一个新的异构数据集，称为<strong class="jl hi"><em class="lc"/>。</strong></p><blockquote class="lr ls lt"><p id="ccae" class="jj jk lc jl b jm jn ii jo jp jq il jr lu jt ju jv lv jx jy jz lw kb kc kd ke ha bi translated"><strong class="jl hi"> <em class="hh">广泛且密集标记的数据集</em></strong><em class="hh">(</em><strong class="jl hi"><em class="hh">Broden</em></strong><em class="hh">)</em>统一了几个密集标记的图像数据集:<a class="ae iw" href="https://people.csail.mit.edu/bzhou/publication/scene-parse-camera-ready.pdf" rel="noopener ugc nofollow" target="_blank"> ADE </a>、<a class="ae iw" href="https://www.cs.cornell.edu/~sbell/pdf/siggraph2014-intrinsic.pdf" rel="noopener ugc nofollow" target="_blank">开放曲面</a>、<a class="ae iw" href="https://www.cs.toronto.edu/~urtasun/publications/mottaghi_et_al_cvpr14.pdf" rel="noopener ugc nofollow" target="_blank"> Pascal-Context </a>、<a class="ae iw" href="https://arxiv.org/pdf/1406.2031.pdf" rel="noopener ugc nofollow" target="_blank"> Pascal-Part </a>和<a class="ae iw" href="https://www.robots.ox.ac.uk/~vgg/publications/2014/Cimpoi14/cimpoi14.pdf" rel="noopener ugc nofollow" target="_blank">可描述纹理数据集</a>。这些数据集包含各种上下文中的各种对象、场景、对象部分、纹理和材质的示例。</p></blockquote><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es lx"><img src="../Images/338841b16e0b81622380e030b9443a2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*88B8BCGDHvmLINYhb1lvFw.png"/></div></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">图:Broden数据集中的标签类型示例。(图来自<a class="ae iw" href="http://netdissect.csail.mit.edu/final-network-dissection.pdf" rel="noopener ugc nofollow" target="_blank"> Bau &amp;周等人。铝(2017) </a>)</figcaption></figure><p id="1d1b" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">在Broden数据集中有大约60，000幅图像和跨越1197个视觉概念的注释。对于大多数视觉概念来说，图像是按像素标记的，除了纹理和场景，它们为整个图像给出了单独的标记。此外，每个图像像素都标有11种常见颜色名称中的一种。这样，每个图像都将获得一个注释遮罩，每个视觉概念都有<strong class="jl hi"> L </strong> _c，<strong class="jl hi"> c </strong>。</p><h2 id="be59" class="ld kg hh bd kh le lf lg kl lh li lj kp js lk ll kr jw lm ln kt ka lo lp kv lq bi translated">2:检索单个单元的激活<strong class="ak">。</strong></h2><p id="15bd" class="pw-post-body-paragraph jj jk hh jl b jm kx ii jo jp ky il jr js kz ju jv jw la jy jz ka lb kc kd ke ha bi translated">为了收集单个单元对概念的反应，来自Broden数据集的图像被输入到CNN，并向前传递。</p><ol class=""><li id="98e1" class="mc md hh jl b jm jn jp jq js me jw mf ka mg ke mh mi mj mk bi translated">对于每个卷积单元(<strong class="jl hi"> k </strong>)，将每个输入图像(<strong class="jl hi"> x </strong>)从Broden数据集馈入CNN，计算激活图，<strong class="jl hi"> A_ </strong> k( <strong class="jl hi"> x </strong>)。<br/> <em class="lc">激活图是卷积运算后单元的输出。<br/> </em> <strong class="jl hi"> <em class="lc">注:</em> </strong> <em class="lc">在一个单元中，一个核或滤波器与图像体进行卷积。</em></li><li id="cad0" class="mc md hh jl b jm ml jp mm js mn jw mo ka mp ke mh mi mj mk bi translated">计算所有图像上的激活分布，<strong class="jl hi"> a_ </strong> k。a_  k是一个实值映射。</li><li id="6ebe" class="mc md hh jl b jm ml jp mm js mn jw mo ka mp ke mh mi mj mk bi translated">要将其转换为二进制图，请计算一个顶分位数阈值<strong class="jl hi"> T_ </strong> k，使得P(<strong class="jl hi">a _</strong>k&gt;<strong class="jl hi">T _</strong>k)= 0.005。这意味着图像<strong class="jl hi"> x </strong>的单元“<strong class="jl hi"> k </strong>的所有激活的0.5%大于<strong class="jl hi"> T_ </strong> k。</li><li id="5f2e" class="mc md hh jl b jm ml jp mm js mn jw mo ka mp ke mh mi mj mk bi translated">通常，神经网络越深入，激活图的尺寸越小。为了获得二进制分割图，使用双线性插值将较低分辨率的激活图<strong class="jl hi"> A </strong> _k( <strong class="jl hi"> x </strong>)缩放到图像分辨率，得到<strong class="jl hi"> S </strong> _k( <strong class="jl hi"> x </strong>)。</li><li id="0fae" class="mc md hh jl b jm ml jp mm js mn jw mo ka mp ke mh mi mj mk bi translated">将激活图二值化:获得一个新的掩膜，<strong class="jl hi">M</strong>_ k(<strong class="jl hi">x</strong>)=<strong class="jl hi">S</strong>_ k(<strong class="jl hi">x</strong>)≥<strong class="jl hi">T</strong>_ k(<strong class="jl hi">x</strong>)，使得一个像素根据是否超过激活阈值<strong class="jl hi"> T </strong> _k. <br/> <em class="lc">来开启或关闭。注意:这些激活掩膜标记高度激活的区域。</em></li></ol><h2 id="04ce" class="ld kg hh bd kh le lf lg kl lh li lj kp js lk ll kr jw lm ln kt ka lo lp kv lq bi translated"><strong class="ak"> 3:量化激活——概念比对。</strong></h2><p id="435f" class="pw-post-body-paragraph jj jk hh jl b jm kx ii jo jp ky il jr js kz ju jv jw la jy jz ka lb kc kd ke ha bi translated">现在我们有了人类标记的概念面具，<strong class="jl hi"> L </strong> _c(来自步骤1)和激活面具，<strong class="jl hi"> M </strong> _k(来自步骤2)。接下来，我们需要确定激活特定节点的视觉概念。换句话说，我们试图确定每个节点“寻找”的是哪个概念。</p><p id="ffcd" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">这是通过将激活掩码与所有标记的概念进行比较来完成的。我们量化激活掩码，<strong class="jl hi"> M </strong> _k和概念掩码，<strong class="jl hi"> L </strong> _c之间的比对，并使用<strong class="jl hi">交集除以并集(IoU) </strong>得分。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mq"><img src="../Images/16ac9018be24fdcf797893dadab97670.png" data-original-src="https://miro.medium.com/v2/resize:fit:904/format:webp/1*T6z5XXMbq5xK31X-iePwdA.jpeg"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">图:<strong class="bd kh">交集超过并集(IoU) </strong>得分公式。</figcaption></figure><p id="8d68" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated"><strong class="jl hi"> IoU得分</strong> =(被两个遮罩识别为概念<strong class="jl hi"> c </strong>的像素数量)<strong class="jl hi"> / </strong> <br/>(被识别为概念<strong class="jl hi"> c </strong>的唯一像素的总数)</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es mr"><img src="../Images/0082b4dee7f45ee2bc2a9cd654ea73ad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vvSJZHqX1iU1g88Maiyx8A.jpeg"/></div></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">图:如何计算IoU分数的示例。(来源:<a class="ae iw" href="https://christophm.github.io/interpretable-ml-book/cnn-features.html#network-dissection" rel="noopener ugc nofollow" target="_blank">可解释机器学习</a>)</figcaption></figure><blockquote class="lr ls lt"><p id="32d8" class="jj jk lc jl b jm jn ii jo jp jq il jr lu jt ju jv lv jx jy jz lw kb kc kd ke ha bi translated"><strong class="jl hi"> IoU </strong> _(k，c)的值是单元<strong class="jl hi"> k </strong>在检测概念<strong class="jl hi"> c时的精度</strong>如果<strong class="jl hi"> IoU得分超过阈值，我们认为<strong class="jl hi"> k </strong>是概念<strong class="jl hi"> c </strong>的检测器。</strong></p></blockquote><p id="99a9" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">作者选择0.04作为将一个单元分类为特定概念检测器的阈值。一个单元可以检测多个概念，并选择排名最高的标签进行分析。</p><p id="eb1a" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">为了量化层的可解释性，在层中识别的唯一概念的数量记为<strong class="jl hi">唯一检测器的数量</strong>。</p><h1 id="2063" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">实验:</h1><p id="1a95" class="pw-post-body-paragraph jj jk hh jl b jm kx ii jo jp ky il jr js kz ju jv jw la jy jz ka lb kc kd ke ha bi translated">随着框架的建立，作者在不同的网络架构(AlexNet，GoogLeNet，VGG，ResNet)上测试了网络解剖，这些网络架构是在不同的数据集(ImageNet，Places205，Places365)上从头开始训练的。对于自我监督的训练任务，AlexNet接受了解谜和跟踪等任务的训练。</p><p id="b06a" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated"><strong class="jl hi"><em class="lc">ImageNet</em></strong><em class="lc"/>是一个<em class="lc">以对象为中心的</em>数据集，拥有来自1000个类的120万张图片。<em class="lc"> </em> <strong class="jl hi"> <em class="lc">地点205 </em> </strong>和<strong class="jl hi"> <em class="lc">地点365 </em> </strong>是一个以<em class="lc">场景为中心的</em>数据集，分别有205和365个类别。Places205包含240万张图片，Places365包含160万张来自厨房和客厅等类别的图片。</p><h2 id="e8e5" class="ld kg hh bd kh le lf lg kl lh li lj kp js lk ll kr jw lm ln kt ka lo lp kv lq bi translated">以下是他们的一些发现:</h2><ol class=""><li id="dd07" class="mc md hh jl b jm kx jp ky js ms jw mt ka mu ke mh mi mj mk bi translated">作者在较高层发现了高级概念的检测器，在较低层发现了低级概念(即低级概念如<em class="lc">颜色</em>和<em class="lc">纹理</em>在<em class="lc"> conv1 </em>和<em class="lc"> conv2、</em>中占主导地位，而更多的<em class="lc">对象</em>和<em class="lc">部分</em>检测器出现在<em class="lc"> conv5中)。</em></li><li id="c1c9" class="mc md hh jl b jm ml jp mm js mn jw mo ka mp ke mh mi mj mk bi translated">接受监督任务训练的网络比接受自我监督任务训练的网络拥有更多独特的检测器。</li><li id="cbf1" class="mc md hh jl b jm ml jp mm js mn jw mo ka mp ke mh mi mj mk bi translated">独特概念检测器的数量随着训练迭代次数的增加而增加。</li><li id="8588" class="mc md hh jl b jm ml jp mm js mn jw mo ka mp ke mh mi mj mk bi translated">批量标准化减少了唯一概念检测器的数量，而增加层中单元的数量会增加可解释单元的数量。</li><li id="97aa" class="mc md hh jl b jm ml jp mm js mn jw mo ka mp ke mh mi mj mk bi translated">ResNet &gt; VGG &gt; GoogLeNet &gt; AlexNet的可解释性。在Places &gt; ImageNet上训练的模型的可解释性。</li></ol><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mv"><img src="../Images/cd7925fd656ab1420c7568918e337aab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1324/format:webp/1*FDdf-c1R3FbZAbcEHL4rZA.jpeg"/></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">图来自<a class="ae iw" href="http://netdissect.csail.mit.edu/final-network-dissection.pdf" rel="noopener ugc nofollow" target="_blank"> Bau &amp;周等人2017 </a>。</figcaption></figure><h1 id="a93f" class="kf kg hh bd kh ki kj kk kl km kn ko kp in kq io kr iq ks ir kt it ku iu kv kw bi translated">结论:</h1><p id="8e67" class="pw-post-body-paragraph jj jk hh jl b jm kx ii jo jp ky il jr js kz ju jv jw la jy jz ka lb kc kd ke ha bi translated">网络剖析帮助我们理解在神经网络中出现了什么涌现的概念，允许我们量化它的可解释性。虽然概念检测器出现在网络中，但并不是神经网络中的所有单元都是可解释的，这证明了网络中的部分非纠缠表示。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es mw"><img src="../Images/76b4779650a5cc7154b8001404e05c64.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d4PzplTiAINM8sUP9-L7Cg.jpeg"/></div></div><figcaption class="jf jg et er es jh ji bd b be z dx translated">图:图层中可解释单元的总数。(图来自<a class="ae iw" href="http://netdissect.csail.mit.edu/final-network-dissection.pdf" rel="noopener ugc nofollow" target="_blank"> Bau &amp;周等。铝(2017) </a></figcaption></figure><blockquote class="lr ls lt"><p id="e660" class="jj jk lc jl b jm jn ii jo jp jq il jr lu jt ju jv lv jx jy jz lw kb kc kd ke ha bi translated">作者还使用网络剖析生成性对抗网络(GANs)。你可以在这里找到项目<a class="ae iw" href="https://gandissect.csail.mit.edu/" rel="noopener ugc nofollow" target="_blank">。</a></p></blockquote><p id="82b0" class="pw-post-body-paragraph jj jk hh jl b jm jn ii jo jp jq il jr js jt ju jv jw jx jy jz ka kb kc kd ke ha bi translated">希望这篇文章对你有所帮助。感谢您的阅读！</p></div></div>    
</body>
</html>