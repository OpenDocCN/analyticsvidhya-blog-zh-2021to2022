<html>
<head>
<title>YOLO for Object Detection, Architecture Explained!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO为对象检测，架构解释！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-yolo-and-implementing-yolov3-for-object-detection-5f1f748cc63a?source=collection_archive---------0-----------------------#2021-08-29">https://medium.com/analytics-vidhya/understanding-yolo-and-implementing-yolov3-for-object-detection-5f1f748cc63a?source=collection_archive---------0-----------------------#2021-08-29</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/19c264cd1ad33d747f5da5b486bb4f83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*PnxWlqMTCeMW_C_nQllsEw.gif"/></div><figcaption class="im in et er es io ip bd b be z dx translated">使用YOLOv3进行检测</figcaption></figure><p id="60b0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在上一篇文章<a class="ae jo" rel="noopener" href="/@sairajneelam/introduction-to-object-detection-with-rcnn-family-models-310558ce2033"> <strong class="is hj">介绍RCNN系列模型的对象检测</strong> </a> <strong class="is hj"> </strong>中，我们看到了RCNN系列模型，它为我们提供了单级对象检测器的方法。</p><ol class=""><li id="4de9" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn ju jv jw jx bi translated">YOLO(你只看一眼)</li><li id="22c2" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn ju jv jw jx bi translated">单发多盒探测器</li></ol><p id="1880" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">读完这篇文章你会知道:</p><ul class=""><li id="5523" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn kd jv jw jx bi translated">YOLO是如何运作的</li><li id="5cbd" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">YOLO的挑战</li><li id="b85a" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">YOLO的局限性</li><li id="24d2" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">YOLOv3架构</li><li id="c135" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">如何在python中使用OpenCV实现YOLOv3</li></ul><p id="c273" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们开始吧。</p><h1 id="7c19" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated"><strong class="ak"> <em class="lc">你只看一次(YOLO): </em> </strong></h1><p id="caf9" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated"><strong class="is hj"><em class="li">(</em></strong><a class="ae jo" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank"><strong class="is hj"><em class="li">你只看一次:统一的、实时的物体检测</em> </strong> </a> <strong class="is hj"> <em class="li">)由</em> </strong> <a class="ae jo" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Redmon%2C+J" rel="noopener ugc nofollow" target="_blank">约瑟夫·雷德蒙</a>、<a class="ae jo" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Divvala%2C+S" rel="noopener ugc nofollow" target="_blank">桑托什·迪瓦拉</a>、<a class="ae jo" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Girshick%2C+R" rel="noopener ugc nofollow" target="_blank">罗斯·吉尔希克</a>、<a class="ae jo" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Farhadi%2C+A" rel="noopener ugc nofollow" target="_blank">阿里·法尔哈迪</a>于2016年。</p><p id="9ff5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">以前的对象检测方法，如R-CNN及其变体，使用流水线在多个步骤中执行这项任务。这可能运行缓慢，也很难优化，因为每个单独的组件必须单独训练。</p><p id="0d57" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">就YOLO而言，它的名字本身就说明了很多，它只在整个图像中出现一次。因此，我们将探索YOLO是如何工作的。</p><h2 id="87f8" class="lj kf hi bd kg lk ll lm kk ln lo lp ko jb lq lr ks jf ls lt kw jj lu lv la lw bi translated">让我们首先了解YOLO是如何对其输出进行编码的，</h2><p id="1661" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">1.输入图像被分成n×n个网格单元。对于图像上出现的每个对象，一个网格单元负责预测对象。</p><p id="48cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.每个网格预测“B”边界框和“C”类概率。边界框由5个部分组成(x，y，w，h，置信度)</p><p id="9fa1" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">(x，y) =代表盒子中心的坐标</p><p id="5b77" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">(w，h) =盒子的宽度和高度</p><p id="f272" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">置信度=表示任何对象的存在/不存在</p><p id="f796" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="li">让我们用一个例子来看看这些，</em></p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es lx"><img src="../Images/392b0267d33ec39b92993c7a3d5a054e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D-gLFHZPIvEyDsn807HXtw.png"/></div></div></figure><p id="44e5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">具有对象中心的单元，该单元确定或负责检测对象。</p><h2 id="1155" class="lj kf hi bd kg lk ll lm kk ln lo lp ko jb lq lr ks jf ls lt kw jj lu lv la lw bi translated"><strong class="ak">YOLO的挑战:</strong></h2><blockquote class="mg mh mi"><p id="2f7c" class="iq ir li is b it iu iv iw ix iy iz ja mj jc jd je mk jg jh ji ml jk jl jm jn hb bi translated"><strong class="is hj"> <em class="hi">问题1。我们如何判断对象检测算法是否运行良好？</em> </strong></p></blockquote><p id="7834" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">解决方案:我们已经在以前的文章中看到了这一点，在那里我们讨论了R-CNN家族模型，我们如何评估对象定位，这是通过称为交集并集(IOU)的度量</p><p id="986b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">IOU =相交面积/并集面积</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mm"><img src="../Images/43d1b0d7820e04ecb0a96946b0343958.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8PzGCuR37gT1oknFQUeWuw.png"/></div></div></figure><blockquote class="mg mh mi"><p id="96a4" class="iq ir li is b it iu iv iw ix iy iz ja mj jc jd je mk jg jh ji ml jk jl jm jn hb bi translated"><strong class="is hj"> <em class="hi">问题2。一个图像中每个物体可以有多个包围盒，那么如何处理呢？</em>T3】</strong></p></blockquote><p id="780b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">解决方案:我们使用非最大抑制(NMS)，这是确保你的算法只检测你的对象一次的方法。</p><p id="8c4f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们将看到这是如何工作的，</p><p id="461c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因为，你在每个网格单元上运行图像分类和定位算法，可能许多单元说它们的“Pc”类概率或在该单元中有物体的机会是最高的。</p><p id="33e3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，当我们运行算法时，我们可能会对同一对象进行多次检测。</p><p id="3ecc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，NMS所做的是，它清除其他不需要的检测，所以我们最终只检测到一个特定的对象。</p><p id="2d48" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><em class="li">这个NMS是怎么运作的？</em></p><p id="146b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.首先，它寻找与特定对象的每个检测相关联的概率(Pc)</p><p id="49d5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.它采用最大的“Pc ”,这是对物体最有把握的检测</p><p id="1f80" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.完成后，NMS部分寻找所有剩余的边界框，并选择所有那些与最高“Pc”的边界框具有高交集(IOU)的边界框，并抑制它们。</p><p id="fa3a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.然后，我们寻找剩余的边界框，并找到最高的“Pc ”, NMS再次寻找具有高IOU的剩余边界框，其中边界框具有高“Pc ”,然后它们将被抑制。</p><p id="45f8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">通过对每个对象这样做，我们只为每个对象得到一个边界框。</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mn"><img src="../Images/c0b441eb5b454becb6fe22ddc94673b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rnIxE9wXcny6prBbiHfaOA.png"/></div></div></figure><p id="fd9b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于这个例子:</p><p id="1a7b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">1.它需要最大的Pc，在这种情况下是0.9</p><p id="6a06" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">2.它检查所有剩余边界框的IOU(即汽车1的0.6，0.7和汽车2的0.8，0.7)</p><p id="9e4c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">3.现在，NMS将取消汽车1的0.6和0.7，因为它们相对于Pc=0.9的边界框具有较高的IOU，所以像这样，我们只获得汽车1的一个边界框，它在图像中高亮显示。</p><p id="72b0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">4.接下来，对于剩余的边界框，car2的Pc最高=0.8，我们再次检查剩余框的IOU(即car1的0.9和car2的0.7)</p><p id="a55b" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">5.现在，NMS将抑制0.7，因为它相对于Pc=0.8的边界框具有高IOU。汽车2也只有一个包围盒。</p><blockquote class="mg mh mi"><p id="cbdc" class="iq ir li is b it iu iv iw ix iy iz ja mj jc jd je mk jg jh ji ml jk jl jm jn hb bi translated"><strong class="is hj"> <em class="hi">问题3。如果我们在一个单元格中有多个对象呢？也就是说，如果我们有重叠的对象，并且两个对象的中点都在单个网格单元中，该怎么办？</em>T9】</strong></p></blockquote><p id="bca0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">解决方案:我们使用多个锚盒来解决这个问题，</p><p id="5490" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每个单元表示这个输出(Pc，x，y，h，w，c1，c2，c3 ),它是形状(8，1)的向量，即8行1列。c1，c2，c3是不同的类别，比如人，汽车，自行车。</p><p id="d981" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，边界框的形状可以根据类的数量而改变。</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mo"><img src="../Images/4901cdc4ebc69a40be7717fbe8c52c89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ax3OJ3Qq0YASci8BnDPzSw.png"/></div></div></figure><p id="21ee" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，每个单元将不能输出2个检测，因此必须选择两个检测中的任何一个来输出。</p><p id="c7f9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">有了锚框的概念，你要做的是预定义两个不同的形状，分别叫做锚框1和锚框2。这样我们可以用两个锚盒做两个预测。</p><p id="2a7c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">一般来说，我们可以使用更多的定位框来捕捉物体的各种形状。</p><p id="ea13" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，对于两个锚盒，我们的输出在3个类的情况下是怎样的，</p><p id="02e4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输出将是大小为(16，1)的向量，该向量包含(Pc1，x1，y1，h1，w1，c1，c2，c3，Pc2，x2，y2，h2，w2，c1，c2，c3)</p><p id="bef8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">假设c1 =人，c2 =汽车，c3 =自行车</p><p id="5190" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在我们的例子中，因为我们有人员和汽车，所以输出将是，</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/f5dca3ba110cb6833d28631cffef2115.png" data-original-src="https://miro.medium.com/v2/resize:fit:954/format:webp/1*fVyDmmfuLuCobEkPqTw4RA.png"/></div></figure><p id="4d31" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">结合所有这些步骤，我们得到了我们的YOLO算法:</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mq"><img src="../Images/c123b82dab0a0b06e759a92f2921f4d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HOE9YPC9U7USEx91EdNP-A.png"/></div></div></figure><p id="8f04" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">YOLO的局限性:</strong></p><p id="255a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">在最初的研究论文中，YOLO只能预测每个网格单元的有限数量的边界框，2个。虽然该数量可以增加，但是每个单元只能进行一个类别预测，这限制了当多个对象出现在单个网格单元中时的检测。因此，它与小对象的边界组进行斗争，例如一群鸟，或者不同类别的多个小对象。</p><h1 id="875b" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated"><strong class="ak">约洛夫3的建筑:</strong></h1><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mr"><img src="../Images/8e1fa824da2b78f982cc8acd24f39c6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ro3fspog1fXfs5SGJwGaTw.png"/></div></div></figure><p id="315f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">YOLO v3使用了Darknet的一个变种，它原本有在ImageNet 上训练的<strong class="is hj"> 53层网络。对于检测任务，其上堆叠了53层，为我们提供了106层的YOLO v3完全卷积底层架构。</strong></p><p id="0fd3" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">检测分三层进行<strong class="is hj">第82层、第94层、第106层。</strong></p><h2 id="c1e8" class="lj kf hi bd kg lk ll lm kk ln lo lp ko jb lq lr ks jf ls lt kw jj lu lv la lw bi translated">YOLOv3中的卷积层</h2><ul class=""><li id="e706" class="jp jq hi is b it ld ix le jb ms jf mt jj mu jn kd jv jw jx bi translated">它包含53个卷积层，每个卷积层之后是批量归一化层和泄漏ReLU激活。</li><li id="b231" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">卷积层用于卷积图像上的多个滤波器，并产生多个特征图</li><li id="32f7" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">不使用任何形式的汇集，并且使用步长为2的卷积层来对特征图进行下采样。</li><li id="fb6f" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">它有助于防止通常归因于池化的低级特性的丢失。</li></ul><p id="7409" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们看看输入，它看起来怎么样，</p><p id="70dd" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输入是一批形状为(n，416，416，3)的图像，其中，</p><p id="3eb9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">n =图像数量，(416，416) =(宽度，高度)和3个通道(RGB)。</p><p id="fe0e" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">宽度和高度可以被32整除。这些数字(宽度、高度)也称为输入网络大小。</p><p id="9e74" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">为什么能被32整除？</strong></p><p id="943d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们一会儿就会看到这一点。</p><p id="14d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">输入分辨率的提高可能会提高训练后的准确性。输入图像可以是任何大小，我们不需要在将它们输入网络之前调整它们的大小，它们都将根据输入网络的大小调整大小。</p><p id="48c9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">网络如何检测物体？</strong></p><p id="e7f8" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">YOLOv3在网络中的3个不同位置进行检测。这些是第82层，第94层和第106层。网络通过在第82层、第94层、第106层的以下因子<strong class="is hj"> 32、16和8对输入图像进行下采样。相应地，这些数字被称为网络步长，它们显示了网络中3个位置的输出如何小于网络输入。</strong></p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mv"><img src="../Images/07ec9ab74ccd0ed403daa15305dc2404.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ykd_U_iqTxE-B0o0xZEAGg.png"/></div></div></figure><p id="c1ad" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于网络输入(416，416)，</p><p id="9e17" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于第82层，步距为32，输出大小为13×13，负责<strong class="is hj">检测大物体</strong></p><p id="f904" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于第94层，步幅为16，输出大小为26×26，负责<strong class="is hj">检测中等物体</strong></p><p id="83e4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于第106层，步幅为8，输出大小为52×52，它负责<strong class="is hj">检测小物体</strong></p><p id="0852" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">这就是网络输入必须能被32整除的原因，因为如果它能被32整除，那么它也能被16和8整除。</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es mw"><img src="../Images/8975a08ef51d89ac92ae748d77dd7187.png" data-original-src="https://miro.medium.com/v2/resize:fit:892/format:webp/1*h0lA6qEbtq-kikyHAJFvbA.png"/></div><figcaption class="im in et er es io ip bd b be z dx translated">这里我们可以看到，为什么13x13，26x26，52x52检测大中小物体</figcaption></figure><p id="36bc" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们看看，什么是检测内核，</p><p id="f042" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，为了产生输出，YOLOv3在网络的三个输出层应用1x1内核(滤波器)。1x1内核被应用于下采样图像，因此我们的输出具有相同的空间维度13x13、26x26和52x52</p><p id="87be" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">检测核的形状也具有其深度，其通过以下公式计算，</p><p id="22c5" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj"> (b*(5+c)) </strong>其中，b =包围盒的数量，c =类的数量，80(对于COCO数据集)</p><p id="e180" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">每个边界框有(5+c个属性)</p><p id="554a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于<strong class="is hj"> YOLOv3，它为这3个特征图的每一个的每个单元</strong>预测3个边界框(即，对于13x13、26x26、52x52特征图)</p><p id="63df" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">由于，b = 3，c = 80，我们得到(3*(5+80)) = 255个属性。</p><p id="0c8c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在，我们可以说由检测核在网络中的3个独立位置(输出层)产生的每个特征图具有一个以上的维度深度，其结合了COCO数据集的边界框的255个属性，并且这些特征图的形状如下，(13×13×255)，(26×26×255)，(52×52×255)。</p><p id="833d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">现在让我们看看，网格细胞，简单地说，它们是检测细胞。</p><p id="03af" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">我们已经知道YOLOv3为特征图的每个单元预测了3个边界框。因此YOLOv3的任务是识别包含对象中心的单元。</p><p id="7a3d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">训练YOLOv3，</p><p id="8275" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">当它训练时，它有一个地面真实包围盒，负责检测一个对象。因此，我们需要知道这些边界框属于哪个单元。</p><p id="bba9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于这个YOLOv3，以3种比例对步幅32、16和8进行预测。</p><p id="5566" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，以该物体为中心的细胞负责检测该物体。</p><p id="d92c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated"><strong class="is hj">锚框</strong>用于预测边界框，YOLOv3使用预定义的边界框，称为锚/先验，这些锚/先验<strong class="is hj">也用于计算预测边界框的实际宽度和实际高度。</strong></p><p id="4513" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">总共使用9个锚盒，每个音阶使用3个锚盒，第一个音阶使用3个最大的锚，第二个音阶使用接下来的3个，第三个音阶使用最后的3个。这意味着在每个输出图层，要素地图的每个格网比例都可以使用3个定位框预测3个边界框。</p><p id="f5d7" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了计算这些锚点，在YOLOv3中应用了K-Means聚类。</p><p id="7a9d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">锚的宽度和高度，</p><p id="c637" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">对于，比例1: (116x90)，(156x198)，(373x326)</p><p id="f288" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">比例2: (30x61)，(62x45)，(59x119)</p><p id="4086" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">比例3: (10x13)，(16x30)，(33x23)</p><p id="2348" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，对于比例1:我们有13x13x3 = <strong class="is hj"> 507个边界框</strong></p><p id="3663" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">比例尺2:我们有，26x26x3 = <strong class="is hj"> 2028包围盒</strong></p><p id="3537" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">比例尺3:我们有，52x52x3 = <strong class="is hj"> 8112边框</strong></p><p id="964a" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">总共，<strong class="is hj"> YOLOv3预测10，847箱。</strong></p><p id="5bff" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">为了预测边界框的实际高度和宽度，YOLOv3计算偏移量，也称为对数空间变换。现在让我们看看，</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mv"><img src="../Images/4726aaf510a39c02ebc68208b25d0cb6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*r0IMDcK3-iio8wB_HKhCMQ.png"/></div></div></figure><p id="6501" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，为了预测边界框的中心坐标(bx，by ), yolo v3通过sigmoid函数传递输出(tx，ty)。</p><p id="853c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">因此，基于图中给出的上述等式，我们得到了边界框的中心坐标、宽度和高度。</p><p id="5bcb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">并且使用NMS抑制来自10，847个框的所有冗余边界框。</p><h1 id="1d1a" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">实现YOLOv3进行对象检测</h1><p id="d9eb" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">我们将使用开源计算机视觉库(OpenCV)</p><p id="bbbe" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#我们将首先导入所需的库</p><p id="0be0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第06行)我们将使用此函数<strong class="is hj"> "cv.dnn.readNet()" </strong>来读取我们的权重文件和配置文件(权重文件包含已在<a class="ae jo" href="https://cocodataset.org/#home" rel="noopener ugc nofollow" target="_blank"> coco数据集</a>上训练的预训练权重，以及被称为配置文件的cfg文件，该配置文件具有YOLOv3网络架构)</p><p id="2255" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第08，09行)我们将置信度阈值和非最大抑制阈值存储为常量，并(第11–13行)读取coco.names文件以提取对象名称并将其放入列表中，我们总共有80个类</p><p id="d2cb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第16行)使用<strong class="is hj"> "cv。VideoCapture()" </strong>我们阅读我们的视频</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mx"><img src="../Images/39bb7be83e8b2963004ccdb6d332216b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w5Goz2HJpwECEXmrjcbC9Q.png"/></div></div></figure><p id="c69f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第18行)现在我们将循环读取捕获的视频并执行对象检测任务</p><p id="aadb" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第19行)现在“cap.read()”正在读取视频，它将被读取为帧，该函数基本上返回两个输出，首先是基于“视频读取/未读取”的布尔值“真/假”,第二个是帧</p><p id="90d0" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第23行)我们不能将帧直接传递到我们的网络，我们需要标准化帧，我们还需要将帧的大小调整为<strong class="is hj"> (416，416) </strong>，因为YOLOv3采用这个输入大小，OpenCV读取的图像是<strong class="is hj">“BGR”格式</strong>，所以我们也需要交换蓝色和红色通道，然后将帧传递到网络</p><p id="c9f6" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第26–27行)我们还需要获取输出层名称，并在正向传递中传递这些名称</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es my"><img src="../Images/23845e9123f60b02fdf6b11b5cd79f0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MgYqQqQENnlfhFR3Sr1V-g.png"/></div></div></figure><p id="c41d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#但是我们在这里还没有完成，因为我们需要可视化结果，为此我们需要提取边界框，我们以什么样的置信度预测对象以及对象是什么类</p><p id="fdf4" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第34 -35行)我们使用两个for循环来提取边界框、置信度和类id。(第35-37行)因此，对于每个检测到的对象，检测包含85个参数，其中前5个参数是边界框和置信度，之后我们有80类预测的概率</p><p id="f545" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#第一个循环从总共3个输出层中提取每个输出层，在第二个循环中，我们将在每个输出层中找到检测到的对象</p><p id="1522" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第38–49行)基于置信度阈值，我们提取边界框的中心及其宽度和高度，并将它们添加到我们创建的空列表中</p><p id="f56f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#在第44–45行，我们提取边界框的左上角坐标</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es mz"><img src="../Images/6827e0e2006a984cd8e29e032c6f51b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OnzDYCnm6_gmeTwUQpGpwQ.png"/></div></div></figure><p id="19e9" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#现在我们已经得到了所有的边界框，但是我们只需要每个对象一个边界框，所以我们把边界框从OpenCV传递给NMS函数</p><p id="6827" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第51行)基于置信度阈值和nms阈值，框将被抑制，并且我们将得到正确检测对象的框</p><p id="9d9d" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第52–58行)我们只是获取边界框及其置信度和标签所需的坐标，并为其分配颜色</p><p id="1a08" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#(第60–61行)我们正在为检测到的对象绘制矩形边界框，并在边界框上方放置文本</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div role="button" tabindex="0" class="mc md di me bf mf"><div class="er es na"><img src="../Images/24a7900f1d6ffafc98a8f62c65ea294c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*appCgI_WVYooey98n81BIw.png"/></div></div></figure><p id="0d6f" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">#这里我们使用cv.imshow()显示检测到的对象</p><figure class="ly lz ma mb fd ij er es paragraph-image"><div class="er es nb"><img src="../Images/3f04b558e2911fe1343062a72b9bb863.png" data-original-src="https://miro.medium.com/v2/resize:fit:974/format:webp/1*CbTDxZtNgeND_n3zg4EGqw.png"/></div></figure><h1 id="8b0b" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">摘要</h1><p id="325d" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated">在这篇文章中，你发现了一个关于YOLO的简单介绍，以及我们如何实现YOLOv3来检测物体。</p><p id="50ae" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">具体来说，您学到了:</p><ul class=""><li id="1b7f" class="jp jq hi is b it iu ix iy jb jr jf js jj jt jn kd jv jw jx bi translated">你学习了YOLO如何运作，如何应对YOLO的挑战及其局限性。</li><li id="81c8" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">还有YOLOv3的架构。</li><li id="22b4" class="jp jq hi is b it jy ix jz jb ka jf kb jj kc jn kd jv jw jx bi translated">和使用OpenCV库的对象检测任务的代码。</li></ul><h1 id="d236" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">参考</h1><p id="6007" class="pw-post-body-paragraph iq ir hi is b it ld iv iw ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn hb bi translated"><a class="ae jo" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1506.02640</a>————&gt;给YOLO的纸</p><p id="bc4c" class="pw-post-body-paragraph iq ir hi is b it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn hb bi translated">Andrew NG的YOLO物体探测YouTube视频</p></div></div>    
</body>
</html>