<html>
<head>
<title>Sign Language Detection Using OpenPose in Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Colab中的OpenPose进行手语检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sign-language-detection-using-openpose-in-colab-a2f364e3fcd2?source=collection_archive---------3-----------------------#2021-06-23">https://medium.com/analytics-vidhya/sign-language-detection-using-openpose-in-colab-a2f364e3fcd2?source=collection_archive---------3-----------------------#2021-06-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="a98c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如何使用Google <a class="ae jc" href="https://research.google.com/colaboratory/" rel="noopener ugc nofollow" target="_blank"> Colab </a>中的OpenPose检测手语</p><p id="b473" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="#595d" rel="noopener ugc nofollow">在Colab中设置</a> <br/> <a class="ae jc" href="#43ac" rel="noopener ugc nofollow"> TensorFlow姿态</a> <br/> <a class="ae jc" href="#07e2" rel="noopener ugc nofollow">从网络直播图像推断</a> <br/> <a class="ae jc" href="#0c41" rel="noopener ugc nofollow">结论</a> <br/> <a class="ae jc" href="#08c7" rel="noopener ugc nofollow">参考</a></p><p id="b7f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有听力障碍的人用手语交流。<a class="ae jc" href="https://github.com/CMU-Perceptual-Computing-Lab/openpose" rel="noopener ugc nofollow" target="_blank"> OpenPose </a>是一个由CMU开发的开源库，可以检测包括面部和手部动作在内的人体姿态。很酷的应用程序是用OpenPose开发的。在本文中，我想展示如何在Google Colab环境中使用<a class="ae jc" href="https://github.com/CMU-Perceptual-Computing-Lab/openpose" rel="noopener ugc nofollow" target="_blank"> OpenPose </a>进行实验和原型制作。</p><h1 id="595d" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">Colab中的设置</h1><p id="c661" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">为什么是Colab？在本地机器上运行实验的设置需要处理一些虚拟环境和依赖关系。另一方面，Colab总是干净的，像TensorFlow这样受欢迎的库已经安装了。最重要的是，它带有一个免费的GPU，这是一个巨大的优势。</p><p id="926d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">整个代码样本在这里<a class="ae jc" href="https://github.com/changsin/DL/blob/main/notebooks/openpose_sign_language.ipynb" rel="noopener ugc nofollow" target="_blank">分享。</a></p><ol class=""><li id="907c" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated"><strong class="ig hi">安装和构建OpenPose: </strong>安装和构建OpenPose及其依赖项的步骤摘自<a class="ae jc" href="https://github.com/tugstugi/dl-colab-notebooks/blob/master/notebooks/OpenPose.ipynb" rel="noopener ugc nofollow" target="_blank"> Tugstugi </a>的笔记本。</li></ol><ul class=""><li id="602f" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kp km kn ko bi translated">git克隆CMU开放姿态</li></ul><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="d4de" class="kz je hh kv b fi la lb l lc ld">!git clone https://github.com/CMU-Perceptual-Computing-Lab/openpose.git'</span></pre><ul class=""><li id="3be4" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kp km kn ko bi translated">安装依赖项</li></ul><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="51a3" class="kz je hh kv b fi la lb l lc ld">!apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev</span></pre><ul class=""><li id="b266" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kp km kn ko bi translated">构建:这将需要几分钟时间。</li></ul><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="ddd4" class="kz je hh kv b fi la lb l lc ld">!mkdir build &amp;&amp; cd build &amp;&amp; cmake .. &amp;&amp; make -j`nproc`</span></pre><p id="0a5c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。下载youtube视频或上传自己的视频:</strong>您可以使用<a class="ae jc" href="https://youtube-dl.org/" rel="noopener ugc nofollow" target="_blank"> youtube-dl </a>下载youtube视频，如示例命令所示。用实际的youtube id替换$youtube_id。例如，对于youtube链接:<a class="ae jc" href="https://youtu.be/VjainPzPo2k" rel="noopener ugc nofollow" target="_blank">https://youtu.be/VjainPzPo2k</a>，youtube id是<a class="ae jc" href="https://youtu.be/VjainPzPo2k" rel="noopener ugc nofollow" target="_blank">vjainzpo 2k</a>。</p><figure class="kq kr ks kt fd le"><div class="bz dy l di"><div class="lf lg l"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">手语演示服务</figcaption></figure><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="3bb8" class="kz je hh kv b fi la lb l lc ld">!youtube-dl -f 'bestvideo[ext=mp4]' --output "youtube.%(ext)s" <a class="ae jc" href="https://www.youtube.com/watch?v=$youtube_id" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=$youtube_id</a></span></pre><p id="bfa4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.<strong class="ig hi">使用OpenPose进行姿态估计:</strong>视频下载后，通过OpenPose进行处理，得到关键点。最多可检测135个关键点。然而，默认情况下，CMU OpenPose不会注释手语检测所需的面部和手部姿势。要将它们包括在关键点检测中，请添加“手”和“脸”参数，如下所示:</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="56f4" class="kz je hh kv b fi la lb l lc ld">.<a class="ae jc" href="https://colab.research.google.com/github/changsin/DL/blob/main/notebooks/openpose_sign_language.ipynb#" rel="noopener ugc nofollow" target="_blank">/build/examples/openpose/openpose.bin</a> --face --hand --video ../video.mp4 --write_json ./output_json/ --display 0 --write_video ../openpose.avi</span></pre><p id="1cc2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">指定了两个输出。</p><ul class=""><li id="7c71" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kp km kn ko bi translated">write_json:将自动注释结果写入一个json文件。对于视频的每一帧，都会生成一个JSON文件。</li><li id="e0c4" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kp km kn ko bi translated">write_video:编写包含姿势注释的视频</li></ul><p id="206c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出单位为*。avi格式，因此使用<a class="ae jc" href="https://www.ffmpeg.org/" rel="noopener ugc nofollow" target="_blank"> FFmpeg </a>将其转换为*.mp4以便于处理。转换命令是:</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="1b83" class="kz je hh kv b fi la lb l lc ld">!ffmpeg -y -loglevel info -i openpose.avi output.mp4</span></pre><p id="8878" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出视频包含重叠在原始图像中的关键点标签。</p><figure class="kq kr ks kt fd le er es paragraph-image"><div class="er es lq"><img src="../Images/49117467e38aeede5b2060ad1f83d91a.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*VyLNVPeLo_XbGNw0YU2f9Q.png"/></div></figure><p id="c4db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.<strong class="ig hi">解析重点:</strong>改装后的mp4可以放在Jupyter笔记本里面玩。如果你想看到图像中的点，你必须将视频转换成图像。您可以使用<a class="ae jc" href="https://www.ffmpeg.org/" rel="noopener ugc nofollow" target="_blank"> FFmpeg </a>将视频分割成帧。只需添加一个额外的参数来指定fps(每秒帧数):</p><p id="b9d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lt lu lv kv b">-vf fps=30</code></p><p id="26c9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了使输出文件名易于跟踪，让我们通过用五个零填充输出文件名来格式化编号的输出文件名。<code class="du lt lu lv kv b">.<a class="ae jc" href="https://colab.research.google.com/github/changsin/DL/blob/main/notebooks/openpose_sign_language.ipynb#" rel="noopener ugc nofollow" target="_blank">/images/out</a>%05.png</code></p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="ebde" class="kz je hh kv b fi la lb l lc ld">!cd openpose &amp;&amp; ffmpeg -ss 10 -t 5 -i ../youtube.mp4 ./output_images/out%05d.png -vf fps=30</span></pre><p id="dcac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出图像文件现在按顺序显示:</p><figure class="kq kr ks kt fd le er es paragraph-image"><div class="er es lw"><img src="../Images/9514584bddf6a858662373df83ce7daf.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*f0CXnBn3GrLPhSSQJVEA2w.png"/></div></figure><p id="7fab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，让我们处理包含关键点的json文件。每个json文件对应一个帧，并包含以下部分:</p><ul class=""><li id="8ebe" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kp km kn ko bi translated">姿势_关键点_2d</li><li id="6328" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kp km kn ko bi translated">面_关键点_二维</li><li id="150d" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kp km kn ko bi translated">手_左_关键点_二维</li><li id="4872" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kp km kn ko bi translated">手_右_关键点_二维</li><li id="c1a8" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kp km kn ko bi translated">姿势_关键点_3d</li><li id="f9f1" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kp km kn ko bi translated">面_关键点_3d</li><li id="c015" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kp km kn ko bi translated">手_左_关键点_3d</li><li id="72ec" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kp km kn ko bi translated">手_右_关键点_3d</li></ul><p id="b233" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因为输入的是2D图像，所以只有2D关键点被填充。</p><figure class="kq kr ks kt fd le"><div class="bz dy l di"><div class="lx lg l"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">OpenPose的示例注释文件</figcaption></figure><p id="2e7c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每个关键点由(x坐标，y坐标，置信度值)组成。您可以使用这些信息快速解析JSON文件，并在相应的图像上标出关键点:</p><figure class="kq kr ks kt fd le er es paragraph-image"><div class="er es ly"><img src="../Images/7405249c6b3cb0146f3714fd00fdde34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*H2Igq8vLTfBKH7eodAgDLg.png"/></div></figure><h1 id="43ac" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">张量流姿态</h1><p id="79ae" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">tf_pose是OpenPose的TensorFlow库，它是可视化关键点的好方法。它支持身体姿势，但不支持手或脸。让我们安装tf_pose，估计身体姿势。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="f119" class="kz je hh kv b fi la lb l lc ld">!pip install tf_pose</span></pre><figure class="kq kr ks kt fd le"><div class="bz dy l di"><div class="lx lg l"/></div></figure><p id="4f01" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">变量“人类”包含图像中识别的身体部位的关键点。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="194c" class="kz je hh kv b fi la lb l lc ld">[BodyPart:0-(0.49, 0.42) score=0.73 BodyPart:1-(0.50, 0.63) score=0.52 BodyPart:2-(0.38, 0.61) score=0.56 BodyPart:5-(0.62, 0.62) score=0.60 BodyPart:6-(0.67, 0.78) score=0.10 BodyPart:14-(0.46, 0.39) score=0.39 BodyPart:15-(0.52, 0.39) score=0.68 BodyPart:17-(0.56, 0.43) score=0.48]</span></pre><p id="b852" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">变量“图像”现在可以使用标准绘图功能可视化。</p><pre class="kq kr ks kt fd ku kv kw kx aw ky bi"><span id="4af1" class="kz je hh kv b fi la lb l lc ld">plt.imshow(image)</span></pre><figure class="kq kr ks kt fd le er es paragraph-image"><div class="er es lz"><img src="../Images/260a410535417931c0cc1e9b3cd86914.png" data-original-src="https://miro.medium.com/v2/resize:fit:462/format:webp/1*QRzH-okp7wZZ3C7DTalcKw.png"/></div></figure><h1 id="07e2" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">从实时网络摄像头图像推断</h1><p id="6f5b" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">现在，通过TensorFlow Pose，OpenPose的设置已经就绪，您甚至可以提供实时网络摄像头图像。要采取的步骤是:</p><ol class=""><li id="0274" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated">在字节数组中拍摄实时图像</li><li id="1741" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kl km kn ko bi translated">将其转换为png格式</li><li id="a178" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kl km kn ko bi translated">将png图像传递给TfPoseEstimator</li><li id="fabc" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kl km kn ko bi translated">将带注释的OpenPose图像转换为字节数组</li><li id="64c7" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kl km kn ko bi translated">通过javascript在浏览器中显示字节数组。</li></ol><p id="9cf2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">附带的Colab <a class="ae jc" href="https://github.com/changsin/DL/blob/main/notebooks/openpose_sign_language.ipynb" rel="noopener ugc nofollow" target="_blank">笔记本</a>包含最终看到OpenPose处理的实时图像提要的必要代码。</p><figure class="kq kr ks kt fd le er es paragraph-image"><div class="er es ma"><img src="../Images/8a550009f6dff164f7e194714146a62c.png" data-original-src="https://miro.medium.com/v2/resize:fit:698/format:webp/1*7hWbp46uvF400yWhS-4TIg.png"/></div></figure><p id="3a84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当前示例代码只能显示姿态关键点。要真正注释关键点，你需要一个像<a class="ae jc" href="https://testworks.co.kr/contents/blackolive.html" rel="noopener ugc nofollow" target="_blank"> blackolive </a>这样的专业工具。</p><h1 id="0c41" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">结论</h1><p id="beee" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">本文展示了如何在Colab环境中使用OpenPose库进行原型设计和实验来检测手语。整个代码样本在这里<a class="ae jc" href="https://github.com/changsin/DL/blob/main/notebooks/openpose_sign_language.ipynb" rel="noopener ugc nofollow" target="_blank">分享。就是这样。</a></p><h1 id="08c7" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">参考</h1><ul class=""><li id="17eb" class="kg kh hh ig b ih kb il kc ip mb it mc ix md jb kp km kn ko bi translated">OpenPose的初始设置借用了<a class="ae jc" href="https://github.com/tugstugi/dl-colab-notebooks/blob/master/notebooks/OpenPose.ipynb" rel="noopener ugc nofollow" target="_blank"> Tugstugi的OpenPose笔记本</a>。</li><li id="042e" class="kg kh hh ig b ih ll il lm ip ln it lo ix lp jb kp km kn ko bi translated">启用网络摄像头馈送修改自<a class="ae jc" href="https://colab.research.google.com/github/vindruid/yolov3-in-colab/blob/master/yolov3_streaming_webcam.ipynb#scrollTo=7OYmjeF-edKE" rel="noopener ugc nofollow" target="_blank"> Vindruid的yolov3笔记本</a>。</li></ul></div></div>    
</body>
</html>