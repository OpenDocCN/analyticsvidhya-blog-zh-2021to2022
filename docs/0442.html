<html>
<head>
<title>Deep Learning — Classification Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习—分类示例</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-learning-classification-example-c7d5bc74b35e?source=collection_archive---------23-----------------------#2021-01-16">https://medium.com/analytics-vidhya/deep-learning-classification-example-c7d5bc74b35e?source=collection_archive---------23-----------------------#2021-01-16</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ae3a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">大家好！！！今天写这篇文章是一种巨大的快乐，因为这是我在2021年能够写的第一篇文章。新年快乐！！🥳 🎂 🎉</p><p id="c02b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇文章中，我们将看到深度学习技术的延续。我们将看到一个带有分类示例的深度学习模型。</p><p id="d42d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们上一篇文章中，我们学习了使用一个简单的神经网络来解决回归问题——<a class="ae jc" href="https://devskrol.com/index.php/2020/11/22/388/" rel="noopener ugc nofollow" target="_blank">人工神经网络用一个回归例子</a>来解释。</p><p id="9973" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你错过了前传，请查看以下内容:</p><p id="2f74" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://devskrol.com/index.php/2020/11/07/artificial-intelligence-a-brief-introduction-and-history-of-deep-learning/" rel="noopener ugc nofollow" target="_blank">人工智能——深度学习简介和历史</a></p><p id="246f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://devskrol.com/index.php/2020/11/08/how-neurons-work-and-how-artificial-neuron-mimics-neurons-in-human-brain/" rel="noopener ugc nofollow" target="_blank">神经元如何工作？以及人工神经元是如何模仿人脑神经元的？</a></p><p id="9c73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jc" href="https://devskrol.com/index.php/2020/11/22/388/" rel="noopener ugc nofollow" target="_blank">人工神经网络用回归实例说明</a></p><h1 id="60c3" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">分类示例数据集:</h1><p id="6ef1" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">为了便于使用和下载，我们采用了来自sklearn.datasets的乳腺癌数据集。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="cf1e" class="kp je hh kl b fi kq kr l ks kt">from sklearn.datasets import load_breast_cancer<br/>from sklearn.model_selection import train_test_split</span><span id="fd45" class="kp je hh kl b fi ku kr l ks kt">whole_data = load_breast_cancer()</span><span id="975a" class="kp je hh kl b fi ku kr l ks kt">X_data = whole_data.data<br/>y_data = whole_data.target</span><span id="5458" class="kp je hh kl b fi ku kr l ks kt">X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 7)</span></pre><p id="fb28" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我们有398个记录的数据集用于训练，171个记录用于30个特征的测试。尽管这对于深度学习来说是一个非常少的数据，但我们将它用于实验目的。</p><p id="0700" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">数据集文档:</strong><a class="ae jc" href="http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer" rel="noopener ugc nofollow" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . datasets . load _ breast _ cancer . html # sk learn . datasets . load _ breast _ cancer</a></p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="8015" class="kp je hh kl b fi kq kr l ks kt">X_train.shape, X_test.shape, y_train.shape, y_test.shape</span><span id="cc9a" class="kp je hh kl b fi ku kr l ks kt">Output:<br/>((398, 30), (171, 30), (398,), (171,))</span></pre><h1 id="5937" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">模型创建:</h1><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="1517" class="kp je hh kl b fi kq kr l ks kt">from keras.models import Sequential</span><span id="aa10" class="kp je hh kl b fi ku kr l ks kt">model = Sequential()</span></pre><p id="1dff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">创建一个顺序模型。让我们给它添加深度学习层。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="372d" class="kp je hh kl b fi kq kr l ks kt"># Keras model with two hidden layer with 10 neurons each <br/>model.add(Dense(10, input_shape = (30,)))    <br/># Input layer<br/>model.add(Activation('sigmoid'))<br/>model.add(Dense(10))                         <br/># Hidden layer <br/>model.add(Activation('sigmoid'))<br/>model.add(Dense(10))                         <br/># Hidden layer <br/>model.add(Activation('sigmoid'))<br/>model.add(Dense(1))                          <br/># Output layer =&gt; output dimension = 1 since it is regression problem<br/>model.add(Activation('sigmoid'))</span></pre><p id="aece" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里可以注意到输入层具有30°的输入形状。第一行也提到了10。</p><p id="fe4f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们大多数人可能会有一个问题，确切的输入形状是什么？30还是10？</p><p id="0f97" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">得到输入的第一层是输入层，这里有30个神经元。每1个输入节点对应一个要素。下一层是第一个隐藏层，有10个神经元。</p><figure class="kg kh ki kj fd kw er es paragraph-image"><div class="er es kv"><img src="../Images/423ac6824d7504fa0c45b2a66fd4ad80.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*YAmG2JJV2rtWR7lEYfxaqg.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">按作者分类的图像-输入图层和第一个隐藏图层</figcaption></figure><p id="108f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还可以看到，输出层只有1个神经元。为什么没有2个神经元作为目标变量是一个二元类(1-恶性，0-良性)？</p><p id="ba94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这一个神经元输出值将是0和1之间的概率值，因为我们在输出层中使用sigmoid激活。基于阈值0.5，可以将概率值确定为0或1n。</p><figure class="kg kh ki kj fd kw er es paragraph-image"><div class="er es ld"><img src="../Images/acf657caca08c394be2920466f737c51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/1*KfBHpwxPSK3PoVuONwLtfw.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">按作者分类的图像-最后一个隐藏层和输出层</figcaption></figure><p id="3499" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们已经构建了神经网络。让我们用优化器和损失函数来编译它。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="225b" class="kp je hh kl b fi kq kr l ks kt">from keras import optimizers</span><span id="fa5d" class="kp je hh kl b fi ku kr l ks kt">sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer</span><span id="39f9" class="kp je hh kl b fi ku kr l ks kt">model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])</span></pre><p id="8e28" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">随机梯度下降用作优化器，当反向传播和“二元交叉熵”损失函数用于评估时，将使用该优化器。</p><p id="8ecb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了得到整个结构的摘要，我们可以使用summary()函数对模型进行处理。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="534c" class="kp je hh kl b fi kq kr l ks kt">model.summary()</span><span id="3dbd" class="kp je hh kl b fi ku kr l ks kt">Output:<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>dense_9 (Dense)              (None, 10)                310       <br/>_________________________________________________________________<br/>activation_4 (Activation)    (None, 10)                0         <br/>_________________________________________________________________<br/>dense_10 (Dense)             (None, 10)                110       <br/>_________________________________________________________________<br/>activation_5 (Activation)    (None, 10)                0         <br/>_________________________________________________________________<br/>dense_11 (Dense)             (None, 10)                110       <br/>_________________________________________________________________<br/>activation_6 (Activation)    (None, 10)                0         <br/>_________________________________________________________________<br/>dense_12 (Dense)             (None, 1)                 11        <br/>_________________________________________________________________<br/>activation_7 (Activation)    (None, 1)                 0         <br/>_________________________________________________________________<br/>dense_13 (Dense)             (None, 10)                20        <br/>_________________________________________________________________<br/>dense_14 (Dense)             (None, 10)                110       <br/>_________________________________________________________________<br/>dense_15 (Dense)             (None, 10)                110       <br/>_________________________________________________________________<br/>dense_16 (Dense)             (None, 1)                 11        <br/>=================================================================<br/>Total params: 792.0<br/>Trainable params: 792.0<br/>Non-trainable params: 0.0<br/>_________________________________________________________________</span></pre><p id="672f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个总结有助于我们理解权重和偏差的总数。总参数:792.0</p><h1 id="1da8" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">训练模型:</h1><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="ba0b" class="kp je hh kl b fi kq kr l ks kt">history = model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)</span></pre><p id="0dcd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上面的代码将在50个批次和100个时期中训练模型。</p><p id="4ae9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1次迭代-发送到神经网络一次的一个数据点或一组数据点。</p><p id="9742" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">批处理大小= 50。这意味着整个训练数据点将被划分，并且对于每次迭代，将批量给出50个数据点。</p><p id="0593" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">纪元= 100。一个时期提到整个数据集被发送到训练1次。即神经网络将用398个数据点训练100次。每次都将使用反向传播来更新权重。</p><p id="eb31" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从而最终的权重将被近似优化。基于数据集、学习速率、激活函数等，增加历元的数量可能会也可能不会优化它。</p><p id="0c7c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于我们将verbose设为1，我们将能够看到每个历元中的精度和损失。</p><figure class="kg kh ki kj fd kw er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es le"><img src="../Images/9f476f422342ae101df82b0453e93ad6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6POkvaEMoEJ3iL9xGmWg5w.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">作者图片-模型训练日志</figcaption></figure><p id="fe06" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里你可以看到我们的损耗更高，精度更低。</p><h1 id="79b6" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">评估:</h1><p id="c89e" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">模型的评估函数。文档可以在这里找到<a class="ae jc" href="https://keras.io/metrics/" rel="noopener ugc nofollow" target="_blank">https://keras.io/metrics/</a>。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="3971" class="kp je hh kl b fi kq kr l ks kt">results = model.evaluate(X_test, y_test)</span><span id="ece8" class="kp je hh kl b fi ku kr l ks kt">Output:<br/>32/171 [====&gt;.........................] - ETA: 0s</span></pre><p id="0fc7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们有了结果。该对象将有两个指标损失和准确性。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="92c4" class="kp je hh kl b fi kq kr l ks kt">print(model.metrics_names)     # list of metric names the model is employing<br/>print(results)                 # actual figure of metrics computed<br/>print('loss: ', results[0])<br/>print('accuracy: ', results[1])</span><span id="099d" class="kp je hh kl b fi ku kr l ks kt">Output:<br/>['loss', 'acc']<br/>[0.6395693376050358, 0.6783625724022848]<br/>loss:  0.6395693376050358<br/>accuracy:  0.6783625724022848</span></pre><p id="9d59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了清楚地了解整个训练过程中发生了什么，我们可以使用从model.fit语句接收的对象。我们把它命名为历史。</p><figure class="kg kh ki kj fd kw er es paragraph-image"><div class="er es lj"><img src="../Images/3c277f27d5ef7f074ceb67d35c732b05.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/1*ZKxkvpiG-JhwHUYQ0sno9A.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">作者图片-培训过程的历史</figcaption></figure><p id="2c13" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以使用matplotlib进行可视化:</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="feb5" class="kp je hh kl b fi kq kr l ks kt">from matplotlib import pyplot as plt</span><span id="9767" class="kp je hh kl b fi ku kr l ks kt">plt.plot(history.history['accuracy'])<br/>plt.plot(history.history['loss'])<br/>plt.legend(['Accuracy', 'Loss'], loc = 'upper left')<br/>plt.show()</span></pre><figure class="kg kh ki kj fd kw er es paragraph-image"><div class="er es lk"><img src="../Images/deb3b18b0816d892d2bbd660e29061f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*nlh5kuxWsu2IEa4FCtrWtA.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">输出</figcaption></figure><p id="731e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们在拟合函数中添加了验证分割，我们将同时获得训练和验证结果。</p><pre class="kg kh ki kj fd kk kl km kn aw ko bi"><span id="03a5" class="kp je hh kl b fi kq kr l ks kt">history = model.fit(X_train, y_train, validation_split = 0.3, epochs = 100, verbose = 0)<br/>plt.plot(history.history['accuracy'])<br/>plt.plot(history.history['val_accuracy'])<br/>plt.legend(['training', 'validation'], loc = 'upper left')<br/>plt.show()</span></pre><figure class="kg kh ki kj fd kw er es paragraph-image"><div class="er es ll"><img src="../Images/b9960081d270721346b0e081ab6aa260.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/format:webp/1*lLI5jZ4WmpQ1mJiq4udpuw.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">输出</figcaption></figure><p id="d081" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">您可以看到，在这个新模型中，验证和训练的准确性没有提高。我们也使用相同的训练数据进行验证分割。所以训练数据是不够的。</p><h1 id="e066" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">结论:</h1><p id="6a8d" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">现在你可能会认为，所有的CPU时间和GPU时间都浪费在不太准确的地方了？甚至ML模型给出了更好的结果！！！</p><p id="f358" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">是的，当我第一次看到这种准确性时，我也有同样的想法。</p><p id="24f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们还没有做一件事情，这是模型创建的有趣部分。是啊！调音！</p><p id="d9fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一个基本模型。我们仍然可以用不同数量的神经元、层、时期、不同的激活函数、优化器和损失函数来调整这个模型。</p><p id="fad2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们也可以增加数据集来获得更好的结果。</p><p id="fa68" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我打算发表一篇文章来调整这个模型。下期文章再见。</p><p id="5680" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">感谢您阅读我们的文章，希望您喜欢。😊</p><p id="db7a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">喜欢支持？只要按一下拍手按钮❤️.</p><p id="cb59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">快乐学习！👩‍💻</p></div></div>    
</body>
</html>