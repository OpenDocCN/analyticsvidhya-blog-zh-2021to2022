<html>
<head>
<title>Introduction to Apache Hudi with PySpark</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PySpark介绍Apache胡迪</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/introduction-to-apache-hudi-with-pyspark-62915e1a6c5c?source=collection_archive---------4-----------------------#2021-03-23">https://medium.com/analytics-vidhya/introduction-to-apache-hudi-with-pyspark-62915e1a6c5c?source=collection_archive---------4-----------------------#2021-03-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/bdc79ebe28c9c2a6b174b4361de958ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*wcFr3hFmmn2AXQsiisWtVQ.jpeg"/></div></figure><p id="0f75" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在当今世界，与以前相比，我们更加关注个人数据隐私。在未来，肯定需要制定关于数据隐私的法律，个人数据的存储也将成为发展中国家的问题。</p><p id="0c38" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">因为许多欧盟国家已经制定了管理个人数据使用的通用数据保护条例(GDPR)。因此，如果用户请求组织从数据湖中选择退出或删除他/她的个人数据。从1pb的数据中删除一条记录变得非常棘手。</p><p id="df2d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了克服从大数据系统中删除单个行的问题，市场上有许多可用的解决方案，即从Hive事务属性到数据块Delta功能。今天我们将学习Apache胡迪，并做一些从数据集中删除记录的实践。</p><h1 id="6ab9" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">环境:AWS EMR 5.32(包括Spark 2.4.3)</h1><p id="cd96" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">在AWS EMR 5.32中，我们默认使用apache胡迪jar，要使用它们，我们只需提供一些参数:</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es km"><img src="../Images/c8c3f65cf71e4fac382083a91b5fef25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EW3DnLexVFbVdmOO"/></div></div></figure><p id="0d3d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们深入了解一下，在使用Apache Spark ( pyspark)时，插入/更新和删除是如何与胡迪一起工作的</p><h1 id="8846" class="jj jk hh bd jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg bi translated">数据集:</h1><p id="305e" class="pw-post-body-paragraph il im hh in b io kh iq ir is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji ha bi translated">在演示中，我们使用了一个用户及其恢复密码的样本数据</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es kv"><img src="../Images/1508fb90f2ae35cc5a1aa36cbf70125e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bSm1K_JPPKGTOjki"/></div></div></figure><p id="be2d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在我们继续接收这些数据之前，让我们首先在spark/hive中创建一个表</p><pre class="kn ko kp kq fd kw kx ky kz aw la bi"><span id="ba14" class="lb jk hh kx b fi lc ld l le lf">CREATE TABLE `user_password_info`(<br/>  `timestamp` STRING,<br/>  `username` STRING,<br/>  `identifier` STRING,<br/>  `otp` STRING,<br/>  `code` STRING,<br/>  `first_name` STRING,<br/>  `last_name` STRING,<br/>  `department` STRING,<br/>  `location` STRING)<br/>STORED AS<br/>INPUTFORMAT 'org.apache.hudi.hadoop.HoodieParquetInputFormat'<br/>OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat';</span></pre><p id="41c9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">一旦创建了表，我们将读取数据集，并尝试将它们插入到上面的胡迪表中</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es km"><img src="../Images/4de628c78902c7d3ff2bc02d0c8a6015.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*gOjhFUap9qwY4r6R"/></div></div></figure><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es km"><img src="../Images/1c7da033d5784b775de5d0ed67eb941f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*9vF-u13sMh6wY7u_"/></div></div></figure><p id="62d6" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们现在已经完成了数据的写入，将选择一个用户并尝试更新与其对应的值。</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es km"><img src="../Images/dfe64deef867a7fa02f694673675083c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*KG2iEBLHCo4u20pE"/></div></div></figure><p id="3059" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在上面的单元格中，我们可以看到一些额外的列，这些是胡迪的元数据列，如果我们直接读取表，并且我们没有在模式中保留这些列，那么我们在查询时就不会拥有它们。</p><p id="acc3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">让我们以用户"<strong class="in hi"> Rachel </strong>"为例，我们将尝试更新Rachel的用户名</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es lg"><img src="../Images/13232c722263de6f0deade3b7efbc85f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*of78Af_tQwz412nm"/></div></div></figure><p id="4e13" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们想从“Booker 12”-&gt;“Rachel 12”中更新Rachel的用户名</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es km"><img src="../Images/9306c0cb166edf3044f74a3283e7f9ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AJspbDcVG00ikJko"/></div></div></figure><p id="04a0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">所以我们可以看到“Rachel”对应的用户名被更新了。现在，让我们从表中删除用户本身。</p><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="kr ks di kt bf ku"><div class="er es km"><img src="../Images/b8b3881fad11f12ccaa389ad01061431.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_VvJzqDsK8KpinGb"/></div></div></figure><p id="9110" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们可以看到用户“Rachel”不再存在于表中。</p><p id="a9c0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">实际上，Apache Spark通过将胡迪库放在Spark类路径中来支持胡迪，这肯定会对管理用户隐私合规性或不断变化的维度有很大帮助。</p><p id="1e7a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">以后我会尽量详细报道更精彩的话题。</p><p id="f60b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这只是一个开始。感谢阅读！！</p><p id="2796" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">迪彭德拉·辛格</p></div></div>    
</body>
</html>