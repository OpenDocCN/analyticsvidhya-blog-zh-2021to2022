<html>
<head>
<title>CNN, Transfer Learning with VGG-16 and ResNet-50, Feature Extraction for Image Retrieval with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">CNN，用VGG-16和ResNet-50进行迁移学习，用Keras进行图像检索的特征提取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cnn-transfer-learning-with-vgg-16-and-resnet-50-feature-extraction-for-image-retrieval-with-keras-53320c580853?source=collection_archive---------1-----------------------#2021-01-09">https://medium.com/analytics-vidhya/cnn-transfer-learning-with-vgg-16-and-resnet-50-feature-extraction-for-image-retrieval-with-keras-53320c580853?source=collection_archive---------1-----------------------#2021-01-09</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="85d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本文中，我们将首先讨论如何实现一个简单的卷积神经网络模型。然后我们要用VGG-16和ResNet-50实现迁移学习模型。最后，我们将从这些用于图像检索的迁移学习模型中提取特征。我们将使用 <a class="ae je" href="https://www.kaggle.com/mengcius/cinic10" rel="noopener ugc nofollow" target="_blank"> <em class="jd"> CINIC-10 </em> </a> <em class="jd">数据集训练模型，并使用Keras库实现和训练每个模型。</em></p><h1 id="a158" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated">导入必要的库并<strong class="ak">使用ImageDataGenerator </strong>获取数据集</h1><p id="22e7" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">首先，我们应该导入必要的库，并用如下代码所示的ImageDataGenerator获取数据集。在使用ImageDataGenerator时，我们应该给出训练、验证和测试数据集目录作为参数。我们在每个数据集中有90000幅图像，在CINIC-10数据集中有10个类。所以我们选择<em class="jd">分类</em>作为class_mode <em class="jd">。</em>对于训练模型，我们的批次大小为64，时期数为10。所有图像的输入形状是(224，224，3)，我们用<em class="jd"> rescale=1来归一化所有图像。/255作为ImageDataGenerator的</em>参数。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="kn ko l"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">使用ImageDataGenerator获取数据集</figcaption></figure></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="d2a9" class="jf jg hi bd jh ji la jk jl jm lb jo jp jq lc js jt ju ld jw jx jy le ka kb kc bi translated"><strong class="ak">用Keras实现CNN模型</strong></h1><p id="47da" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">我们可以简单地用下面的函数实现一个卷积神经网络模型。该函数有一些参数:</p><ul class=""><li id="6a7e" class="lf lg hi ih b ii ij im in iq lh iu li iy lj jc lk ll lm ln bi translated"><strong class="ih hj">层数:</strong>模型中Conv2d的层数</li><li id="bbd6" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated"><strong class="ih hj">过滤器数量:</strong>Conv2d层数</li><li id="7ed1" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated"><strong class="ih hj">filter _ size:</strong>Conv2d图层的滤镜大小</li><li id="1b6d" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated"><strong class="ih hj">初始化器:</strong>内核_层的初始化器</li><li id="c44e" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated"><strong class="ih hj">激活_功能:</strong>层的激活功能</li><li id="dedd" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated"><strong class="ih hj">脱层:</strong>脱层</li><li id="efb1" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated"><strong class="ih hj"> opt: </strong>层的优化器</li></ul><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="kn ko l"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">实现一个简单的CNN模型</figcaption></figure><p id="9a9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用上述函数创建CNN模型，在训练模型之后，对于一些超参数组合，有<em class="jd">测试准确度</em>结果。我们可以在下面的柱状图中看到10个时期的结果。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lt"><img src="../Images/9a41d9bc6d1128cab6e25bfc7946a405.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*KxdGGq-b4xgsV2HgCVqW-w.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">不同CNN模型的测试精度</figcaption></figure><p id="0faa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">通过上面的柱状图，我们可以对超参数进行一些概括</p><ul class=""><li id="9639" class="lf lg hi ih b ii ij im in iq lh iu li iy lj jc lk ll lm ln bi translated">我们可以说，如果我们选择(3，3)滤波器大小而不是(5，5)滤波器大小，我们可以获得更好的结果。因为如果我们使用(3，3)滤波器大小，我们需要做更多的卷积计算。</li><li id="ee38" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated">我们还可以看到，辍学效应可以根据其价值变化。因此，我们应该尝试我们的模型的压差值，并选择最好的一个。</li><li id="4c43" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated">我们可以说，如果我们的模型中有3个卷积层，我们可以获得比有2个卷积层的模型更好的结果。</li></ul></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="db9c" class="jf jg hi bd jh ji la jk jl jm lb jo jp jq lc js jt ju ld jw jx jy le ka kb kc bi translated"><strong class="ak">用VGG-16和ResNet-50转移学习</strong></h1><p id="5616" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">对于VGG-16和ResNet-50的迁移学习，我们可以使用以下函数。在这个函数中，我们将创建没有最后分类层的模型，并添加我们的具有1024个神经元的全连接层。</p><p id="73fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个函数中有一个参数是<em class="jd">lastfourtrainiable</em>。如果函数的这个参数为<em class="jd">假</em>；那么只有最后一层完全连接的模型是可训练的。但是如果这个参数<em class="jd">为真</em>；然后有参数的最后四层模型将是可训练的。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="kn ko l"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">用VGG-16和ResNet-50迁移学习</figcaption></figure><p id="ec15" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">利用上述函数建立VGG-16和雷斯网-50的迁移学习模型，对这些模型的4个组合有<em class="jd">测试精度</em>结果。我们可以在下面的柱状图中看到10个时期的结果。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lt"><img src="../Images/67513434f25db69bd26a58c35dce9192.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*9jrkadp_4zUcWQKq25GfiQ.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">不同迁移学习模型的测试准确性</figcaption></figure><p id="6be5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，与其他迁移学习模型相比，使用<em class="jd">lastfourtrainiable = True</em>的VGG-16迁移学习模型给我们带来了最好的结果。我们也可以说，如果我们增加可训练层的数量，我们可以在所有模型中获得更好的结果。</p><p id="92aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们也可以在下面看到我们的最佳迁移学习模型的混淆矩阵。</p><figure class="ki kj kk kl fd km er es paragraph-image"><div class="er es lt"><img src="../Images/dd35e2f6f38c64740023c5bf904fae9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*qz-UP1AV3ntSHomykhoglQ.png"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">VGG-16迁移学习模型的混淆矩阵(最后四层是可训练的)</figcaption></figure></div><div class="ab cl kt ku gp kv" role="separator"><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky kz"/><span class="kw bw bk kx ky"/></div><div class="hb hc hd he hf"><h1 id="8fdf" class="jf jg hi bd jh ji la jk jl jm lb jo jp jq lc js jt ju ld jw jx jy le ka kb kc bi translated"><strong class="ak">使用迁移学习模型进行特征提取的图像检索</strong></h1><p id="94d0" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">深度学习模型中的特征提取可用于图像检索。我们将从我们在上一节中训练的VGG-16和ResNet-50迁移学习模型中提取特征。因此，我们现在有4个模型权重，我们将使用它们进行特征提取。</p><p id="4766" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了提取特征，我们将在模型的分类层之前使用输出。例如VGG-16型；</p><ul class=""><li id="8a80" class="lf lg hi ih b ii ij im in iq lh iu li iy lj jc lk ll lm ln bi translated">我们将首先从保存的文件中获取模型的权重。</li><li id="2351" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated">然后得到该模型分类层前的输出权重。</li><li id="0c56" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated">模型准备就绪后，我们将获取训练和验证数据集的特征向量作为数据帧，并将其保存为pickle文件。</li><li id="3c43" class="lf lg hi ih b ii lo im lp iq lq iu lr iy ls jc lk ll lm ln bi translated">现在，我们为图像检索做好了准备。在本节中，我们将给出一个图像，并将其特征向量与所有特征向量进行比较。然后，我们将得到这个图像的前5个相似的图像。</li></ul><p id="1e56" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以在下面的中看到特征提取的代码。</p><figure class="ki kj kk kl fd km"><div class="bz dy l di"><div class="kn ko l"/></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">基于特征提取的图像检索</figcaption></figure><p id="7728" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的代码中有一些函数:</p><p id="edfb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> getFeatureVector(model，img_path): </strong>该函数将使用给定的模型找到给定img_path的特征向量，并返回该特征向量。</p><p id="4d9e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> getCosineSimilarity(model，img_path): </strong>该函数将找到给定的A和B特征向量之间的余弦相似度。</p><p id="e0b1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">getFeatureDataFrame(model):</strong>该函数首先用Pandas库创建一个数据帧，该数据帧有“文件”和“特征”两列。然后，我们将找到训练和验证数据集的所有特征向量，并将这些特征向量作为数据帧返回。</p><p id="c579" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> getSimilarImages(img_file，features_df，model，model_name): </strong>该函数将获取给定图像的特征向量，并将该特征向量与DataFrame中的所有特征向量进行比较，并绘制前5幅相似图像。</p><p id="1407" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，是时候看看使用特征提取进行图像检索的结果了！</p><figure class="ki kj kk kl fd km er es paragraph-image"><div role="button" tabindex="0" class="lx ly di lz bf ma"><div class="er es lw"><img src="../Images/bdd3789adccb456d7bacc559302abdf2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3o0jCqAIf1CPLzfYs5GAiQ.png"/></div></div><figcaption class="kp kq et er es kr ks bd b be z dx translated">图像检索结果为给定的飞机图像与4个不同的模型</figcaption></figure><p id="5110" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上表可以看出，VGG-16模型比ResNet-50模型更适合图像检索。此外，我们可以说，如果我们在每个模型中增加可训练层，我们可以获得更好的结果。</p><h1 id="20a6" class="jf jg hi bd jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="ak">总结</strong></h1><p id="6f21" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kf is it iu kg iw ix iy kh ja jb jc hb bi translated">在本文中，我们首先学习了如何实现一个简单的CNN模型，以及超参数如何改变CNN模型的精度。</p><p id="f8b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二部分，我们得到了VGG-16迁移学习模型和ResNet模型的测试精度结果。根据这些结果，我们可以说VGG-16模型可以胜过雷斯网-50模型。</p><p id="6532" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们看到，VGG-16模型可以优于ResNet-50模型的图像检索。</p><p id="6510" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以在<a class="ae je" href="https://github.com/frhtas/cnn-imageretrieval" rel="noopener ugc nofollow" target="_blank"> GitHub </a>库中看到所有代码。</p></div></div>    
</body>
</html>