<html>
<head>
<title>Decision Tree - For Beginners</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">决策树-适合初学者</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/decision-tree-for-beginners-dd966beb0a8b?source=collection_archive---------12-----------------------#2021-01-27">https://medium.com/analytics-vidhya/decision-tree-for-beginners-dd966beb0a8b?source=collection_archive---------12-----------------------#2021-01-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="0835" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树是基于特定条件的决策的所有可能解决方案的图形表示。</p><p id="9e5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树是通用的机器学习算法，可以执行分类和回归任务，甚至多输出任务。它们最广泛地用于监督学习。</p><p id="2308" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">它们是强大的算法，能够拟合复杂的数据集。</p><p id="c22d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树基于CART(分类和回归树)算法</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es jd"><img src="../Images/e6f8aab97c94d13f091be81b6eb423c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*M4RhGdLXyZGZ00yh6340KQ.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated"><strong class="bd jp">这是一个简单的决策树</strong></figcaption></figure><h1 id="6a6f" class="jq jr hi bd jp js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">决策树术语</strong></h1><p id="95fe" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">在我们进入决策树如何工作之前，我们需要理解决策树的一些术语。</p><p id="85c9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">根节点:这是构建决策树的最顶层节点。它代表整个群体/样本，并进一步分为两个或多个节点(上图中紫色的根节点)。</p><p id="db65" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">父/子节点:根节点是父节点，从父/根节点分支的所有其他节点称为子节点。</p><p id="c4d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">分支/子树:通过拆分树/节点形成。</p><p id="f333" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">分裂:根据某种条件将根/子节点分成不同的部分</p><p id="1db6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">叶节点:无法进一步划分/分离的节点，例如上图中的橙色节点(最下面)。</p><p id="95d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">修剪:除去树上不需要的树枝。</p><h1 id="5985" class="jq jr hi bd jp js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">购物车算法</strong></h1><p id="75e0" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">CART(分类和回归树)算法由一系列问题构成，这些问题的答案决定了下一个问题(如果有的话)应该是什么。这些问题的结果是一个树状结构，其末端是叶子/终端节点，这里不再有问题。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ks"><img src="../Images/2f86e9665d969fc8b215fc9acb6a816e.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*BhdZ97cS8x4otNb1J7hr6g.png"/></div><figcaption class="jl jm et er es jn jo bd b be z dx translated"><strong class="bd jp">如何提问</strong></figcaption></figure><p id="ed5b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">决策树的构建依赖于以下几点。</strong></p><p id="d58e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">熵</strong>:这是数据中随机性的度量。</p><p id="636a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">公式:熵(s) = -P(是)log2P(是)-P(否)log2P(否)</strong></p><p id="5ce9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">s是总样本空间</p><p id="d0cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">P(是)是肯定的概率，P(否)是否定的概率</p><p id="1c96" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果<strong class="ih hj">是数=否数</strong>，则P(s) = 0.5，则熵(s) = 1</p><p id="9c7f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果数据仅包含<strong class="ih hj">是或不包含</strong>，即P(s) = 1或0，则熵(s) = 0</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es kt"><img src="../Images/edae869664fd4a5f0d18821d1e9e8fad.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*JFlHPoggihIATJLngyzexA.png"/></div></figure><p id="9532" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">信息增益:</strong>信息增益测量熵的减少。这决定了在从根节点开始构建决策树的每一步中应该选择哪个属性进行拆分。</p><p id="0875" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">公式:信息增益=熵(s) — [(加权平均值)*熵(每个特征)] </strong></p><p id="a5fe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中<strong class="ih hj">(加权平均值)*熵(每个特征)</strong>为每个特征的<strong class="ih hj">信息</strong>。</p><p id="541b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">树必须简单易懂，为此我们需要选择一个纯粹的分裂。一个常用的纯度衡量标准是信息。信息值告诉我们一个特性给了我们多少信息。具有最高信息增益的分割被选为第一分割，并且该过程继续。</p><p id="1e72" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">基尼不纯:</strong>首先让我们了解什么是纯和不纯，纯是指所选样本的数据属于同一类。不纯意味着数据包含不同类别的混合。</p><p id="3548" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">基尼系数衡量的是不正确分类的可能性。如果数据集是纯的，那么不正确分类的可能性是0，否则它将是高的。</p><h1 id="4d20" class="jq jr hi bd jp js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">如何构建决策树</strong></h1><p id="8dcd" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">用因变量求出整个数据集的熵。</p><p id="4782" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">找出每个特征(自变量)的信息增益，选择信息增益最高的特征作为根节点。</p><p id="0240" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">形成树，并重复这些步骤，以获得整个决策树。</p><p id="424b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在你已经建立了树，是时候在测试数据上测试它了，你发现树实际上过度拟合了数据，这是决策树的主要缺点之一。为了避免过度拟合，我们去除了利用低重要性特征的分支。这种方法被称为<strong class="ih hj">剪枝</strong>或<strong class="ih hj">后剪枝</strong>，这降低了树的复杂度，提高了测试精度。另一种方法叫做<strong class="ih hj">提前停止</strong>或<strong class="ih hj">预修剪</strong>在这里，我们试图在树生成叶子之前提前停止树构建过程。预修剪的一个问题是，如果我们停止得太早，我们可能会对数据进行欠填充。</p><h1 id="512c" class="jq jr hi bd jp js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">决策树的优势</strong></h1><p id="679e" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">容易理解</p><p id="a3e1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以处理分类数据和数字数据</p><p id="ab27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对异常值稳健</p><h1 id="51de" class="jq jr hi bd jp js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">决策树的缺点</strong></h1><p id="f033" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">倾向于过度拟合</p><p id="70b9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">需要小心调整参数</p><p id="c9cd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果某些职业占优势，可能会创建有偏见的学习树</p><h1 id="2f14" class="jq jr hi bd jp js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">决策树上的面试问题</strong></h1><p id="7c76" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">什么是决策树，它是如何工作的？</p><p id="5110" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">离群值对决策树有什么影响？</p><p id="ba9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树如何避免过拟合？</p><p id="f04b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">决策树如何处理单个数据集中的分类和数字特征？</p><p id="aca8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">用于构建决策树的库有哪些？</p></div></div>    
</body>
</html>