<html>
<head>
<title>Intel OpenVINO on Google Colab</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google Colabä¸Šçš„è‹±ç‰¹å°”OpenVINO</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/analytics-vidhya/intel-openvino-on-google-colab-20ac8d2eede6?source=collection_archive---------6-----------------------#2021-07-15">https://medium.com/analytics-vidhya/intel-openvino-on-google-colab-20ac8d2eede6?source=collection_archive---------6-----------------------#2021-07-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="7565" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">è‹±ç‰¹å°”çš„OpenVINOå‘è¡Œç‰ˆä½¿<strong class="ih hj"> <em class="jd">äººå·¥æ™ºèƒ½æ¨ç†</em> </strong>å˜å¾—å¿«é€Ÿè€Œç®€å•ã€‚æ¨ç†åŸºæœ¬ä¸Šæ˜¯æ¨¡å‹è·å¾—äº†æ‰€æœ‰æ•™è‚²(è®­ç»ƒ)å¹¶éœ€è¦é€šè¿‡åŸºäºå…¶èƒ½åŠ›æ¨æ–­æ–°ä¿¡æ¯æ¥ç‚«è€€çš„é˜¶æ®µã€‚</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es je"><img src="../Images/0971412ac4a65d113bd7b1a81cad10ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Kp1rC8GLbFk-Zltb.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">æ¥æº:<a class="ae ju" href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html" rel="noopener ugc nofollow" target="_blank">https://software . Intel . com/content/www/us/en/develop/tools/open vino-toolkit . html</a></figcaption></figure><p id="7b9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">OpenVINOæ¡†æ¶ä½¿å¾—è·¨å„ç§æ¶æ„çš„æ¨æ–­å’Œéƒ¨ç½²å˜å¾—éå¸¸å®¹æ˜“ã€‚æ›´å¤šå…³äºæ¡†æ¶çš„<a class="ae ju" href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html" rel="noopener ugc nofollow" target="_blank">åœ¨è¿™é‡Œ</a>ã€‚</p><p id="30f8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">æœ¬æ•™ç¨‹å°†æ•™ä½ å¦‚ä½•åœ¨Google Colabä¸Šæµ‹è¯•OpenVINOçš„èƒ½åŠ›ã€‚</p><h1 id="7c13" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">ä¸€èˆ¬æ¥è¯´ï¼Œä½¿ç”¨OpenVINOçš„æ­¥éª¤æ˜¯:</h1><p id="7db9" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">â€”ä½¿ç”¨æ¥è‡ª<a class="ae ju" href="https://github.com/IntelAI/models" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">è‹±ç‰¹å°”æ¨¡å‹åŠ¨ç‰©å›­</strong> </a> <strong class="ih hj"> </strong>çš„<strong class="ih hj"> <em class="jd">é¢„è®­ç»ƒæ¨¡å‹</em> </strong>æˆ–ä½¿ç”¨æ‚¨è‡ªå·±çš„<strong class="ih hj"> <em class="jd">æ¨¡å‹(æ„å»º)</em> </strong></p><p id="bea8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">â€”ä½¿ç”¨æ¨ç†å¼•æ“ç”Ÿæˆxmlå’Œbinæ–‡ä»¶(ä¼˜åŒ–)</p><p id="53bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">â€”ä½¿ç”¨æ‚¨é¦–é€‰çš„ç¯å¢ƒè¿›è¡Œéƒ¨ç½²</p><h1 id="ede9" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">ä½¿ç”¨Google Colabéƒ¨ç½²</h1><p id="4f68" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">é¦–å…ˆï¼Œæˆ‘ä»¬å°†å…³æ³¨ç¬¬ä¸‰æ­¥ã€‚è¿™é‡Œï¼Œ<strong class="ih hj">å‡è®¾</strong>æ‚¨å·²ç»æœ‰äº†xmlå’Œbinæ–‡ä»¶ã€‚æˆ‘åœ¨æˆ‘çš„å­˜å‚¨åº“ä¸­æ·»åŠ äº†ä¸€äº›ç”¨äºè‹±ç‰¹å°”é¢„è®­ç»ƒæ¨¡å‹çš„xmlå’Œbinæ–‡ä»¶ã€‚è¯·éšæ„ä½¿ç”¨:<a class="ae ju" href="https://github.com/jojo96/intel-openvino-colab/tree/main/models" rel="noopener ugc nofollow" target="_blank">https://github . com/jojo 96/Intel-open vino-colab/tree/main/models</a></p><p id="3a41" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">å®‰è£…åº“:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es ky"><img src="../Images/2a75e67747b40e9f6c2d5132d86a882c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NvJ6iPhWGJTxBwp06jxbzA.png"/></div></div></figure><p id="3c53" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">è¿›è¡Œå¿…è¦çš„å¯¼å…¥:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es kz"><img src="../Images/a199783d254a0cab2381f1f49545e0b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9E8VsFVJNAazOgT9SRFHng.png"/></div></div></figure><p id="85f6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">è·å–å¯æ‰§è¡Œç½‘ç»œ:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es la"><img src="../Images/aa41d2928099e245a5e2dd9fd8067190.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qxDL4UCJcruq07PjbcHwPQ.png"/></div></div></figure><p id="1251" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">æ¨æ–­æ—¶é—´:</strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lb"><img src="../Images/2f367159ff0a32225e7857c073cda99b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qt_e39jLWhkCHXLpDcFX2A.png"/></div></div></figure><p id="0d83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> TLDR </strong> &gt; &gt;ä½¿ç”¨æœ¬ç¬”è®°æœ¬:<a class="ae ju" href="https://github.com/jojo96/intel-openvino-colab/blob/main/notebooks/AllModels.ipynb" rel="noopener ugc nofollow" target="_blank"><strong class="ih hj">https://github . com/jojo 96/Intel-open vino-colab/blob/main/notebooks/all models . ipynb</strong></a></p><h1 id="8529" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">ä¸€äº›ä½¿ç”¨æ¡ˆä¾‹:</h1><p id="613a" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">è¿™é‡Œç”¨åˆ°çš„æ‰€æœ‰xmlå’Œbinæ–‡ä»¶éƒ½å¯ä»¥åœ¨æˆ‘çš„repo:<a class="ae ju" href="https://github.com/jojo96/intel-openvino-colab/tree/main/models" rel="noopener ugc nofollow" target="_blank">https://github . com/jojo 96/Intel-open vino-colab/tree/main/models</a></p><p id="9311" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">å¹´é¾„æ£€æµ‹ç¤ºä¾‹:</strong></p><p id="7b90" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">å¹´é¾„-æ€§åˆ«-è¯†åˆ«-é›¶å”®-0013 </strong>:è¿™ç§ç»è¿‡é¢„å…ˆè®­ç»ƒçš„è‹±ç‰¹å°”æ¨¡å‹èƒ½å¤Ÿæ£€æµ‹å‡º[18â€“75]å¹´é¾„ç»„çš„äººã€‚ä¸‹é¢çš„ä»£ç ç‰‡æ®µå†³å®šäº†<em class="jd">ä¸€ä¸ªäººçš„å¹´é¾„ã€‚</em></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lc"><img src="../Images/f61ddf0a955d19c3a7e464da391d9331.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5m9rphOANGXcTN6AItUM_Q.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">æ¥æº:<a class="ae ju" href="https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/age-gender-recognition-retail-0013" rel="noopener ugc nofollow" target="_blank">https://github . com/openvinotoolkit/open _ model _ zoo/tree/master/models/Intel/age-gender-recognition-retail-0013</a></figcaption></figure><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="1e62" class="li jw hi le b fi lj lk l ll lm">#age detection age-gender-recognition-retail-0013</span><span id="6034" class="li jw hi le b fi ln lk l ll lm">en = load_IR_to_IE('age.xml')</span><span id="a62b" class="li jw hi le b fi ln lk l ll lm">import cv2<br/>image = cv2.imread('age1.png')<strong class="le hj">#input image for age prediction</strong><br/>resized = cv2.resize(image, (62,62), interpolation = cv2.INTER_AREA)</span><span id="19c7" class="li jw hi le b fi ln lk l ll lm">from torchvision import transforms<br/>tran = transforms.ToTensor()  # Convert the numpy array or PIL.Image #read image to (C, H, W) Tensor format and /255 normalize to [0, #1.0]<br/>img_tensor = tran(resized)<br/>img_tensor = img_tensor.unsqueeze_(0)</span><span id="5bd9" class="li jw hi le b fi ln lk l ll lm">res = synchronous_inference(en, img_tensor)<br/>cv2_imshow(cv2.imread('age1.png'))<strong class="le hj">#input image for age prediction</strong><br/>print("age is:"+str(round(res['age_conv3'][0][0][0][0]*100)))</span></pre><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lo"><img src="../Images/353ed6b0e244f5961f7a5f1d19d20ea8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DimvRcf9rxYAtessj2vyw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">è¾“å‡º</figcaption></figure><p id="ea19" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">æƒ…æ„Ÿæ£€æµ‹ç¤ºä¾‹(å‹å·:</strong> <a class="ae ju" href="https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/emotions-recognition-retail-0003" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">æƒ…æ„Ÿ-è¯†åˆ«-é›¶å”®-0003 </strong> </a> <strong class="ih hj"> ): </strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lp"><img src="../Images/e228694d52dbcde071a0f81dbfa022cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kBuKJRRVVFtoQsgrDjAQGA.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">æ¥æº:<a class="ae ju" href="https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/emotions-recognition-retail-0003" rel="noopener ugc nofollow" target="_blank">https://github . com/openvinotoolkit/open _ model _ zoo/tree/master/models/Intel/emotions-recognition-retail-0003</a></figcaption></figure><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="45cc" class="li jw hi le b fi lj lk l ll lm">#emotion detection emotions-recognition-retail-0003</span><span id="fad6" class="li jw hi le b fi ln lk l ll lm">en = load_IR_to_IE('<strong class="le hj">emo.xml</strong>')</span><span id="91bc" class="li jw hi le b fi ln lk l ll lm">import cv2<br/>image = cv2.imread('angry.jpg')<strong class="le hj">#input image for emotion prediction</strong><br/>resized = cv2.resize(image, (64,64), interpolation = cv2.INTER_AREA)</span><span id="396e" class="li jw hi le b fi ln lk l ll lm">from torchvision import transforms<br/>tran = transforms.ToTensor()  # Convert the numpy array or PIL.Image #read image to (C, H, W) Tensor format and /255 normalize to [0, #1.0]<br/>img_tensor = tran(resized)<br/>img_tensor = img_tensor.unsqueeze_(0)</span><span id="a030" class="li jw hi le b fi ln lk l ll lm">res = synchronous_inference(en, img_tensor)<br/>cv2_imshow(cv2.imread('angry.jpg'))<strong class="le hj">#input image for emotion #prediction</strong></span><span id="545b" class="li jw hi le b fi ln lk l ll lm">print(res)</span></pre><p id="2331" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ç»“æœ:åŒ…å«5ä¸ªæƒ…æ„Ÿæ¦‚ç‡æµ®ç‚¹æ•°çš„æ•°ç»„ï¼Œé¡ºåºä¸º:(<strong class="ih hj"> 0:ä¸­æ€§ï¼Œ1:å¿«ä¹ï¼Œ2:æ‚²ä¼¤ï¼Œ3:æƒŠè®¶ï¼Œ4:æ„¤æ€’</strong>)</p><p id="0d5d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">è½¦è¾†æ£€æµ‹ç¤ºä¾‹(å‹å·:</strong> <a class="ae ju" href="https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/vehicle-attributes-recognition-barrier-0039" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">è½¦è¾†-å±æ€§-è¯†åˆ«-æŠ¤æ -0039 </strong> </a> <strong class="ih hj"> ): </strong></p><figure class="jf jg jh ji fd jj er es paragraph-image"><div role="button" tabindex="0" class="jk jl di jm bf jn"><div class="er es lq"><img src="../Images/360677ed9c987c65a40d2ffdc4b83f08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3MF1uTjMVEuMiCNfHgzRIw.png"/></div></div><figcaption class="jq jr et er es js jt bd b be z dx translated">æ¥æº:<a class="ae ju" href="https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/vehicle-attributes-recognition-barrier-0039" rel="noopener ugc nofollow" target="_blank">https://github . com/openvinotoolkit/open _ model _ zoo/tree/master/models/Intel/vehicle-attributes-recognition-barrier-0039</a></figcaption></figure><pre class="jf jg jh ji fd ld le lf lg aw lh bi"><span id="c53a" class="li jw hi le b fi lj lk l ll lm">#vehicle detection</span><span id="2db7" class="li jw hi le b fi ln lk l ll lm">en = load_IR_to_IE('vehicle.xml')</span><span id="18a4" class="li jw hi le b fi ln lk l ll lm">import cv2<br/>image = cv2.imread('truck.jpg')<strong class="le hj">#input image for vehicle prediction</strong><br/>resized = cv2.resize(image, (72,72), interpolation = cv2.INTER_AREA)</span><span id="0740" class="li jw hi le b fi ln lk l ll lm">from torchvision import transforms</span><span id="7e81" class="li jw hi le b fi ln lk l ll lm">tran = transforms.ToTensor() <br/>img_tensor = tran(resized)<br/>img_tensor = img_tensor.unsqueeze_(0)</span><span id="ba6c" class="li jw hi le b fi ln lk l ll lm">res = synchronous_inference(en, img_tensor)cv2_imshow(cv2.imread('truck.jpg'))<strong class="le hj">#input image for #vehicle prediction</strong></span><span id="c6bb" class="li jw hi le b fi ln lk l ll lm">print(res)</span></pre><p id="b4fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">ç‚¹å‡»æ­¤å¤„æŸ¥çœ‹æ•´ä¸ªç¬”è®°æœ¬:</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lr ls l"/></div></figure><h1 id="60c1" class="jv jw hi bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">å¥–é‡‘</h1><p id="f006" class="pw-post-body-paragraph if ig hi ih b ii kt ik il im ku io ip iq kv is it iu kw iw ix iy kx ja jb jc hb bi translated">è€¶ï¼ä½ å·²ç»èµ°åˆ°è¿™ä¸€æ­¥äº†ã€‚ä¸€ä»½å°ç¤¼ç‰©ğŸ€</p><p id="05a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">å› æ­¤ï¼Œä¸‹é¢çš„ç¬”è®°æœ¬å¯ä»¥ç”¨äºä»<a class="ae ju" href="https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel" rel="noopener ugc nofollow" target="_blank">è‹±ç‰¹å°”æ¨¡å‹åŠ¨ç‰©å›­</a>çš„æ¨¡å‹ç”Ÿæˆxmlå’Œbinæ–‡ä»¶ã€‚æœ‰ä¸€ä¸ªå®Œæ•´çš„ä¾‹å­å±•ç¤ºäº†xmlå’Œbijnæ–‡ä»¶çš„ç”Ÿæˆå’Œé¢„æµ‹ã€‚</p><figure class="jf jg jh ji fd jj"><div class="bz dy l di"><div class="lr ls l"/></div></figure><p id="2ae3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="jd">å‚è€ƒèµ„æ–™:è¿™é‡Œå¾ˆå¤šä»£ç éƒ½æ˜¯ç”±</em><a class="ae ju" href="https://github.com/alihussainia/openvino-colab" rel="noopener ugc nofollow" target="_blank"><em class="jd">https://github.com/alihussainia/openvino-colab</em></a>ä¿®æ”¹æ”¹ç¼–è€Œæ¥</p></div></div>    
</body>
</html>