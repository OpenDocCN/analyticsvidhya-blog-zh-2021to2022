<html>
<head>
<title>Azure Databricks MLFlow CI/CD with Azure DevOps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带有Azure DevOps的Azure data brick ml flow CI/CD</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/azure-databricks-mlflow-ci-cd-with-azure-devops-d02973ba28e3?source=collection_archive---------7-----------------------#2021-06-10">https://medium.com/analytics-vidhya/azure-databricks-mlflow-ci-cd-with-azure-devops-d02973ba28e3?source=collection_archive---------7-----------------------#2021-06-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="9ece" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">使用mlflow和批量推理进行机器学习模型训练的CI/CD</h1><h1 id="d25f" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">先决条件</h1><ul class=""><li id="9409" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">Azure帐户</li><li id="4b6a" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure存储帐户</li><li id="058c" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure DevOps</li><li id="9fba" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure数据块</li><li id="fedd" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">azure devo PS—data brick市场安装</li><li id="7ab3" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Github存储代码</li></ul><h1 id="7898" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">数据</h1><ul class=""><li id="ae2b" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">导航到<a class="ae jz" href="https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/" rel="noopener ugc nofollow" target="_blank">https://archive . ics . UCI . edu/ml/machine-learning-databases/wine-quality/</a>并将winequality-red.csv和winequality-white.csv下载到您的本地机器。</li><li id="48d0" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">下载到本地计算机并上传到文件夹中的Azure数据块</li></ul><h1 id="a1b6" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">步伐</h1><ul class=""><li id="585f" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">首先用python创建一个笔记本</li><li id="2b3b" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">创建一个运行时为8.2毫升的集群</li><li id="2744" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">这是训练</li><li id="edda" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">注册模型</li><li id="d426" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">使用模型进行批量评分</li><li id="41c0" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">将其作为增量存储回存储器</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="652e" class="kj if hh kf b fi kk kl l km kn">import pandas as pd<br/><br/># In the following lines, replace &lt;username&gt; with your username.<br/>white_wine = pd.read_csv("/dbfs/FileStore/shared_uploads/username/winequality_white.csv", sep=';')<br/>red_wine = pd.read_csv("/dbfs/FileStore/shared_uploads/username/winequality_red.csv", sep=';')</span><span id="30d2" class="kj if hh kf b fi ko kl l km kn">red_wine['is_red'] = 1<br/>white_wine['is_red'] = 0<br/><br/>data = pd.concat([red_wine, white_wine], axis=0)<br/><br/># Remove spaces from column names<br/>data.rename(columns=lambda x: x.replace(' ', '_'), inplace=True)</span><span id="f263" class="kj if hh kf b fi ko kl l km kn">data.head()</span></pre><ul class=""><li id="d897" class="jc jd hh je b jf kp jh kq jj kr jl ks jn kt jp jq jr js jt bi translated">显示图表</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="8e13" class="kj if hh kf b fi kk kl l km kn">import seaborn as sns<br/>sns.distplot(data.quality, kde=False)</span><span id="ecbc" class="kj if hh kf b fi ko kl l km kn">high_quality = (data.quality &gt;= 7).astype(int)<br/>data.quality = high_quality</span><span id="26f6" class="kj if hh kf b fi ko kl l km kn">import matplotlib.pyplot as plt<br/><br/>dims = (3, 4)<br/><br/>f, axes = plt.subplots(dims[0], dims[1], figsize=(25, 15))<br/>axis_i, axis_j = 0, 0<br/>for col in data.columns:<br/>  if col == 'is_red' or col == 'quality':<br/>    continue # Box plots cannot be used on indicator variables<br/>  sns.boxplot(x=high_quality, y=data[col], ax=axes[axis_i, axis_j])<br/>  axis_j += 1<br/>  if axis_j == dims[1]:<br/>    axis_i += 1<br/>    axis_j = 0</span><span id="339c" class="kj if hh kf b fi ko kl l km kn">data.isna().any()</span><span id="fcfd" class="kj if hh kf b fi ko kl l km kn">from sklearn.model_selection import train_test_split<br/><br/>train, test = train_test_split(data, random_state=123)<br/>X_train = train.drop(["quality"], axis=1)<br/>X_test = test.drop(["quality"], axis=1)<br/>y_train = train.quality<br/>y_test = test.quality</span><span id="ba26" class="kj if hh kf b fi ko kl l km kn">import mlflow<br/>import mlflow.pyfunc<br/>import mlflow.sklearn<br/>import numpy as np<br/>import sklearn<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn.metrics import roc_auc_score<br/>from mlflow.models.signature import infer_signature<br/>from mlflow.utils.environment import _mlflow_conda_env<br/><br/># The predict method of sklearn's RandomForestClassifier returns a binary classification (0 or 1). <br/># The following code creates a wrapper function, SklearnModelWrapper, that uses <br/># the predict_proba method to return the probability that the observation belongs to each class. <br/><br/>class SklearnModelWrapper(mlflow.pyfunc.PythonModel):<br/>  def __init__(self, model):<br/>    self.model = model<br/>    <br/>  def predict(self, context, model_input):<br/>    return self.model.predict_proba(model_input)[:,1]<br/><br/>experiment_name = "/Shared/wine_experiment/"<br/>mlflow.set_experiment(experiment_name)<br/># mlflow.start_run creates a new MLflow run to track the performance of this model. <br/># Within the context, you call mlflow.log_param to keep track of the parameters used, and<br/># mlflow.log_metric to record metrics like accuracy.<br/>with mlflow.start_run(run_name='untuned_random_forest'):<br/>  n_estimators = 10<br/>  model = RandomForestClassifier(n_estimators=n_estimators, random_state=np.random.RandomState(123))<br/>  model.fit(X_train, y_train)<br/><br/>  # predict_proba returns [prob_negative, prob_positive], so slice the output with [:, 1]<br/>  predictions_test = model.predict_proba(X_test)[:,1]<br/>  auc_score = roc_auc_score(y_test, predictions_test)<br/>  mlflow.log_param('n_estimators', n_estimators)<br/>  # Use the area under the ROC curve as a metric.<br/>  mlflow.log_metric('auc', auc_score)<br/>  wrappedModel = SklearnModelWrapper(model)<br/>  # Log the model with a signature that defines the schema of the model's inputs and outputs. <br/>  # When the model is deployed, this signature will be used to validate inputs.<br/>  signature = infer_signature(X_train, wrappedModel.predict(None, X_train))<br/>  <br/>  # MLflow contains utilities to create a conda environment used to serve models.<br/>  # The necessary dependencies are added to a conda.yaml file which is logged along with the model.<br/>  conda_env =  _mlflow_conda_env(<br/>        additional_conda_deps=None,<br/>        additional_pip_deps=["cloudpickle=={}".format(cloudpickle.__version__), "scikit-learn=={}".format(sklearn.__version__)],<br/>        additional_conda_channels=None,<br/>    )<br/>  mlflow.pyfunc.log_model("random_forest_model", python_model=wrappedModel, conda_env=conda_env, signature=signature)</span><span id="b9d9" class="kj if hh kf b fi ko kl l km kn">feature_importances = pd.DataFrame(model.feature_importances_, index=X_train.columns.tolist(), columns=['importance'])<br/>feature_importances.sort_values('importance', ascending=False)</span><span id="432c" class="kj if hh kf b fi ko kl l km kn">run_id = mlflow.search_runs(filter_string='tags.mlflow.runName = "untuned_random_forest"').iloc[0].run_id</span><span id="4bcb" class="kj if hh kf b fi ko kl l km kn"># If you see the error "PERMISSION_DENIED: User does not have any permission level assigned to the registered model", <br/># the cause may be that a model already exists with the name "wine_quality". Try using a different name.<br/>model_name = "wine_quality"<br/>model_version = mlflow.register_model(f"runs:/{run_id}/random_forest_model", model_name)</span><span id="1ef1" class="kj if hh kf b fi ko kl l km kn">from mlflow.tracking import MlflowClient<br/><br/>client = MlflowClient()<br/>client.transition_model_version_stage(<br/>  name=model_name,<br/>  version=model_version.version,<br/>  stage="Production",<br/>)</span><span id="656a" class="kj if hh kf b fi ko kl l km kn">model = mlflow.pyfunc.load_model(f"models:/{model_name}/production")<br/><br/># Sanity-check: This should match the AUC logged by MLflow<br/>print(f'AUC: {roc_auc_score(y_test, model.predict(X_test))}')</span><span id="d4b6" class="kj if hh kf b fi ko kl l km kn">from hyperopt import fmin, tpe, hp, SparkTrials, Trials, STATUS_OK<br/>from hyperopt.pyll import scope<br/>from math import exp<br/>import mlflow.xgboost<br/>import numpy as np<br/>import xgboost as xgb</span><span id="9094" class="kj if hh kf b fi ko kl l km kn">params = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}<br/>mlflow.xgboost.autolog()<br/>with mlflow.start_run(nested=True):<br/>  train = xgb.DMatrix(data=X_train, label=y_train)<br/>  test = xgb.DMatrix(data=X_test, label=y_test)<br/>  # Pass in the test set so xgb can track an evaluation metric. XGBoost terminates training when the evaluation metric<br/>  # is no longer improving.<br/>  booster = xgb.train(params=params, dtrain=train, num_boost_round=1000,\<br/>                      evals=[(test, "test")], early_stopping_rounds=50)<br/>  predictions_test = booster.predict(test)<br/>  auc_score = roc_auc_score(y_test, predictions_test)<br/>  mlflow.log_metric('auc', auc_score)<br/><br/>  signature = infer_signature(X_train, booster.predict(train))<br/>  mlflow.xgboost.log_model(booster, "model", signature=signature)</span><span id="0c96" class="kj if hh kf b fi ko kl l km kn">mlflow.end_run()</span><span id="602a" class="kj if hh kf b fi ko kl l km kn">model = mlflow.pyfunc.load_model(f"models:/{model_name}/production")<br/>print(f'AUC: {roc_auc_score(y_test, model.predict(X_test))}')</span><span id="b4bd" class="kj if hh kf b fi ko kl l km kn"># To simulate a new corpus of data, save the existing X_train data to a Delta table. <br/># In the real world, this would be a new batch of data.<br/>spark_df = spark.createDataFrame(X_train)<br/># Replace &lt;username&gt; with your username before running this cell.<br/>table_path = "dbfs:/mlflowdata/delta/wine_data"<br/># Delete the contents of this path in case this cell has already been run<br/>dbutils.fs.rm(table_path, True)<br/>spark_df.write.format("delta").save(table_path)</span><span id="919a" class="kj if hh kf b fi ko kl l km kn">import mlflow.pyfunc<br/><br/>apply_model_udf = mlflow.pyfunc.spark_udf(spark, f"models:/{model_name}/production")</span><span id="877c" class="kj if hh kf b fi ko kl l km kn"># Read the "new data" from Delta<br/>new_data = spark.read.format("delta").load(table_path)<br/>display(new_data)</span><span id="6932" class="kj if hh kf b fi ko kl l km kn">from pyspark.sql.functions import struct<br/><br/># Apply the model to the new data<br/>udf_inputs = struct(*(X_train.columns.tolist()))<br/><br/>new_data = new_data.withColumn(<br/>  "prediction",<br/>  apply_model_udf(udf_inputs)<br/>)<br/>display(new_data)</span><span id="65c3" class="kj if hh kf b fi ko kl l km kn">new_data.write.format("delta").mode("overwrite").save("/mnt/mlflow/wineoutput")<br/>df1 = spark.read.format("delta").load("/mnt/mlflow/wineoutput")<br/>display(df1)</span></pre><h1 id="6e20" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">Azure DevOps</h1><ul class=""><li id="57d9" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">去DevOps</li><li id="ef8e" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">创建项目</li><li id="03b1" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">创建新版本</li><li id="8a2b" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">连接到回购</li><li id="c1b5" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">创建一个新管道作为azure-pipelines.yml</li><li id="8ef9" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">此回购中可用的示例代码—【https://github.com/balakreshnan/sparkops T2】</li><li id="52c8" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">首先创建变量</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="3e45" class="kj if hh kf b fi kk kl l km kn">clusterid <br/>databricks_token</span></pre><ul class=""><li id="116e" class="jc jd hh je b jf kp jh kq jj kr jl ks jn kt jp jq jr js jt bi translated">使用JSON输出从Azure databricks workspace获取集群</li><li id="9101" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">databricks_token是个人访问令牌</li><li id="8e44" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">DevOps构建管道代码</li></ul><pre class="ka kb kc kd fd ke kf kg kh aw ki bi"><span id="d7a5" class="kj if hh kf b fi kk kl l km kn">trigger:<br/>- main<br/><br/>pool:<br/>  vmImage: ubuntu-latest<br/><br/>steps:<br/>- script: echo Hello, world!<br/>  displayName: 'Run a one-line script'<br/><br/>- script: |<br/>    echo Add other tasks to build, test, and deploy your project.<br/>    echo See https://aka.ms/yaml<br/>  displayName: 'Run a multi-line script'<br/><br/>- task: UsePythonVersion@0<br/>  inputs:<br/>    versionSpec: '3.7'<br/>    addToPath: true<br/>    architecture: 'x64'<br/><br/>- task: CopyFiles@2<br/>  inputs:<br/>    SourceFolder: 'notebooks'<br/>    Contents: '**'<br/>    TargetFolder: '$(Build.SourcesDirectory)'<br/><br/>- task: DownloadGitHubRelease@0<br/>  inputs:<br/>    connection: 'balakreshnan'<br/>    userRepository: 'balakreshnan/sparkops'<br/>    defaultVersionType: 'latest'<br/>    downloadPath: '$(System.ArtifactsDirectory)'<br/><br/>- task: Bash@3<br/>  inputs:<br/>    targetType: 'inline'<br/>    script: |<br/>      # Write your commands here<br/>      <br/>      ls -l $(System.ArtifactsDirectory)<br/><br/>- task: configuredatabricks@0<br/>  inputs:<br/>    url: 'https://adb-xxxxxxxxxxx.x.azuredatabricks.net'<br/>    token: '$(databricks_token)'<br/><br/>- task: startcluster@0<br/>  inputs:<br/>    clusterid: '$(clusterid)'<br/><br/>- task: executenotebook@0<br/>  inputs:<br/>    notebookPath: '/Users/babal@microsoft.com/ML/xgboost-python'<br/>    existingClusterId: '$(clusterid)'<br/><br/>- task: executenotebook@0<br/>  inputs:<br/>    notebookPath: '/Users/babal@microsoft.com/ML/pytorch-single-node'<br/>    existingClusterId: '$(clusterid)'<br/><br/><br/>- task: executenotebook@0<br/>  inputs:<br/>    notebookPath: '/Users/babal@microsoft.com/ML/mlflowexp'<br/>    existingClusterId: '$(clusterid)'</span></pre><figure class="ka kb kc kd fd kv er es paragraph-image"><div class="er es ku"><img src="../Images/de4e3ed727e82ca65cd0f3928d00342c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/0*8vIhMG2e8P7u9DMK.jpg"/></div></figure><figure class="ka kb kc kd fd kv er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ky"><img src="../Images/0b87cd3738e1d0067ed44e5b46e547da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rGXna3ghYg2VgtXZ.jpg"/></div></div></figure><figure class="ka kb kc kd fd kv er es paragraph-image"><div class="er es ld"><img src="../Images/7452e187492260432de8da5e2c9f0cff.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/0*yLSOwcxVOuIpwb4M.jpg"/></div></figure><figure class="ka kb kc kd fd kv er es paragraph-image"><div class="er es le"><img src="../Images/de619618018a685a4a2c86725f25ecdb.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/0*WIXVIKPxM_OAYloS.jpg"/></div></figure></div><div class="ab cl lf lg go lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ha hb hc hd he"><ul class=""><li id="6f0d" class="jc jd hh je b jf kp jh kq jj kr jl ks jn kt jp jq jr js jt bi translated">检查Azure数据块以查看笔记本是否成功</li><li id="fe73" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">我们可以使用Azure Data Factory或Azure Synapse Integrate来重新训练模型和批量评分或推理自动化</li></ul><p id="f2bc" class="pw-post-body-paragraph lm ln hh je b jf kp lo lp jh kq lq lr jj ls lt lu jl lv lw lx jn ly lz ma jp ha bi translated">【https://github.com】最初发表于<a class="ae jz" href="https://github.com/balakreshnan/Samples2021/blob/main/adb/sparkmlflowops.md" rel="noopener ugc nofollow" target="_blank"><em class="mb"/></a><em class="mb">。</em></p></div></div>    
</body>
</html>