<html>
<head>
<title>(Part-III)EyeAttend — Facial Recognition based Attendance System from scratch. — A complete approach.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">(第三部分)eye attend——从零开始的基于面部识别的考勤系统。—完整的方法。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/eyeattend-facial-recognition-based-attendance-system-from-scratch-4c07ce9da319?source=collection_archive---------17-----------------------#2021-03-21">https://medium.com/analytics-vidhya/eyeattend-facial-recognition-based-attendance-system-from-scratch-4c07ce9da319?source=collection_archive---------17-----------------------#2021-03-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h1 id="ab82" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">介绍</h1><p id="1271" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">欢迎来到我们博客系列的第三部分。最后，在2个关于我们的愿景和项目概述的故事之后，我们将在这个故事中开始我们的编码。不浪费你太多时间，让我们开始吧。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h1 id="d149" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">概述</h1><p id="1e75" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">在开始之前，让我们复习一下上一个故事的内容。因此，我们讨论了深度学习模型的概述，并简要介绍了我们项目中的以下模型:</p><ol class=""><li id="42b9" class="kh ki hh jl b jm kj jq kk ju kl jy km kc kn kg ko kp kq kr bi translated"><strong class="jl hi"> keras-facenet </strong>(迁移学习)</li><li id="6fcb" class="kh ki hh jl b jm ks jq kt ju ku jy kv kc kw kg ko kp kq kr bi translated"><strong class="jl hi">面具探测器</strong></li><li id="4e2e" class="kh ki hh jl b jm ks jq kt ju ku jy kv kc kw kg ko kp kq kr bi translated"><strong class="jl hi">真假探测器</strong></li></ol><p id="92bc" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">您可以通过快速浏览本系列的第一部分和第二部分来熟悉这个项目。</p><p id="32ba" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">数据是训练深度学习模型的主要资源。在我们的项目中，需要的第一类数据是课堂数据。为了执行面部匹配，我们实际上需要一个数据库，从中我们将绘制我们的图像比较。首先，我们将生成课堂数据。为此，我们的要求是学生的面部图像。由于在这个项目的开发过程中，我们地区的学校和大学因新冠肺炎疫情而关闭，我们必须想出一种方法来生成数据。</p><h1 id="8f4d" class="il im hh bd in io la iq ir is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji bi translated">数据生成</h1><h2 id="c840" class="lf im hh bd in lg lh li ir lj lk ll iv ju lm ln iz jy lo lp jd kc lq lr jh ls bi translated">1.收藏品</h2><p id="a822" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">我们回忆起我们的集体照片、当地旅行和其他照片。接下来，我们将它们放在一个文件夹中以供考虑。这些图像确实包含重复的人脸，但是我们需要收集最大数量的人脸，以便生成我们的教室批次。我们的试验是获得最多人脸的图像，以减少收集工作。将它存储在一个目录中标志着这个阶段的完成。参见下面的附图，以供参考。</p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lt"><img src="../Images/baa150e102342d005a795ef12985ff11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NhCEMLLj6bPk9fiKrxyoTQ.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">原始数据:用于提取人脸的群组照片</figcaption></figure><h2 id="2e4e" class="lf im hh bd in lg lh li ir lj lk ll iv ju lm ln iz jy lo lp jd kc lq lr jh ls bi translated">2.提取，血统</h2><p id="30e7" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">接下来，我们需要从这些图像中提取人脸。一些图像在肖像模式下显示，而一些图像在某个角度被点击。手动提取人脸是一项繁琐的任务。如前所述，我们将使用迁移学习进行人脸提取和人脸识别，我们将使用MTCNN(多任务级联神经网络)模型进行人脸提取。MTCNN模块可以从PyPI安装在[1]。您可以通过终端执行以下命令将其安装在您的机器上:</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="1c47" class="lf im hh mk b fi mo mp l mq mr">pip3 install mtcnn</span></pre><p id="1dda" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">请注意，在安装之前，您的机器上已经安装了pip3。</p><p id="bcaf" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">安装MTCNN后，我们将导入人脸提取所需的库</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="4f22" class="lf im hh mk b fi mo mp l mq mr">import os<br/>import numpy as np<br/>from PIL import Image<br/>from mtcnn import MTCNN</span></pre><p id="938f" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">导入库之后，我们将把源和目标路径存储在一个变量中，并初始化mtcnn对象。你也可以使用参数解析器直接在终端中输入这些文件夹和输出路径。</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="b78a" class="lf im hh mk b fi mo mp l mq mr">detector = MTCNN()<br/>folder_path = '/home/username/Eye_Attend/Eye_Attend/images'<br/>output_path = '/home/username/Eye_Attend/Eye_Attend/FACES_224'</span></pre><p id="f1f8" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">为了理解MTCNN是如何工作的，考虑下面的例子:</p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es ms"><img src="../Images/dd2939f2452c553d86d5d71123f477d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hG8hNRx3B2bPdqeqPqV2uw.jpeg"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">示例图像</figcaption></figure><p id="af97" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">如果我们对这个图像运行MTCNN检测器(通过下面的代码)，我们会得到下面的输出:</p><p id="2ecf" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated"><strong class="jl hi">代码:</strong></p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="676b" class="lf im hh mk b fi mo mp l mq mr">img = Image.open(folder_path+os.sep+"IMG_20171130_105137.jpg")<br/>pixels = np.asarray(img)<br/>results = detector.detect_faces(pixels)<br/>print(len(results))<br/>print(results)</span></pre><p id="0c65" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated"><strong class="jl hi">输出:</strong></p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="2061" class="lf im hh mk b fi mo mp l mq mr">6<br/>[</span><span id="ce90" class="lf im hh mk b fi mt mp l mq mr">{'box': [602, 470, 358, 454], 'confidence': 1.0, <br/>'keypoints': {'left_eye': (724, 643), 'right_eye': (888, 662), 'nose': (816, 743), 'mouth_left': (718, 807), 'mouth_right': (863, 825)}}, </span><span id="83b2" class="lf im hh mk b fi mt mp l mq mr">{'box': [1066, 401, 228, 305], 'confidence': 0.9999994039535522, 'keypoints': {'left_eye': (1136, 518), 'right_eye': (1244, 523), 'nose': (1196, 571), 'mouth_left': (1137, 624), 'mouth_right': (1235, 632)}}, </span><span id="10c3" class="lf im hh mk b fi mt mp l mq mr">{'box': [1542, 538, 226, 283], 'confidence': 0.9999988079071045, 'keypoints': {'left_eye': (1591, 645), 'right_eye': (1692, 646), 'nose': (1625, 692), 'mouth_left': (1596, 755), 'mouth_right': (1671, 758)}}, </span><span id="b047" class="lf im hh mk b fi mt mp l mq mr">{'box': [1764, 844, 477, 588], 'confidence': 0.9999927282333374, 'keypoints': {'left_eye': (1873, 1078), 'right_eye': (2096, 1067), 'nose': (1968, 1204), 'mouth_left': (1898, 1299), 'mouth_right': (2088, 1294)}}, </span><span id="273a" class="lf im hh mk b fi mt mp l mq mr">{'box': [1038, 951, 453, 523], 'confidence': 0.9999831914901733, 'keypoints': {'left_eye': (1162, 1174), 'right_eye': (1351, 1109), 'nose': (1289, 1293), 'mouth_left': (1244, 1375), 'mouth_right': (1410, 1313)}}, </span><span id="b6fc" class="lf im hh mk b fi mt mp l mq mr">{'box': [-92, 769, 623, 850], 'confidence': 0.9803318977355957, 'keypoints': {'left_eye': (86, 1089), 'right_eye': (375, 1070), 'nose': (268, 1253), 'mouth_left': (84, 1357), 'mouth_right': (392, 1330)}}</span><span id="c3f5" class="lf im hh mk b fi mt mp l mq mr">]</span></pre><p id="cd78" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">输出是一个字典列表，每个字典都有“box”、“confidence”和“keypoints”作为关键字。键“关键点”是另一个字典，带有“左眼”、“右眼”、“鼻子”、“口左”和“口右”键。方框键列表由x1、y1、宽度和高度组成。这指的是人脸的边界框，我们可以用它从图像中提取人脸。</p><p id="8146" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">以与上述类似的方式，我们将逐一迭代源文件夹中的图像，并从当前图像中检测所有人脸，提取它们的边界框坐标，然后将人脸图像存储在output_folder中。下面的代码帮助我们从输入目录路径中提取人脸，并将图像保存在输出路径中。</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="0c9e" class="lf im hh mk b fi mo mp l mq mr">for image in os.listdir(folder_path):<br/>    img = Image.open(folder_path+os.sep+image)<br/>    pixels = np.asarray(img)<br/>    filename , extension = image.split(".")<br/>    results = detector.detect_faces(pixels)<br/>    for i in range(len(results)):<br/>        x1, y1, width, height = results[i]['box']<br/>        x1, y1 = abs(x1), abs(y1)<br/>        x2, y2 = x1 + width, y1 + height<br/>        face = pixels[y1:y2, x1:x2]<br/>        face_image = Image.fromarray(face)<br/>        face_image = face_image.resize((224, 224))<br/>        face_image.save(<br/>            output_path+os.sep+filename+"_"+str(i)+"."+extension<br/>        )</span></pre><p id="6fe6" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">在每次迭代时，image变量被转换为numpy数组，该数组作为参数传递给detector.detect()以提取面部细节，如前面的示例所述。我们还存储图像的文件名和扩展名，以相同的前缀保存人脸图像。我们迭代每一个检测到的人脸，通过包围盒坐标从图像的numpy数组中提取人脸。将其大小调整为224，244维，因为我们将在稍后阶段需要一个预训练的模型，其权重在imagenet数据集上，该数据集接受224x224图像。最后，我们将把生成的面保存在输出目录中。下面是我们的源文件夹的结果。</p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mu"><img src="../Images/af217cb969e8a9be41d80e853e71866b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OSq33f0JG5HyHYpKYR4WNQ.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">教室批次的输出面</figcaption></figure><h2 id="4120" class="lf im hh bd in lg lh li ir lj lk ll iv ju lm ln iz jy lo lp jd kc lq lr jh ls bi translated">3.隔离:</h2><p id="eefa" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">在从组图像中提取可能检测到的人脸之后，我们有一些不想要的、扭曲的、模糊的和重复的人脸(由于图像中的重复个体)。下一步是从这个数据集中取出高质量的图像。这将是我们的隔离阶段。我们将挑选出高质量的图像，这些图像是可见的、可区分的，并且像素化程度较低。在新的目录中，这些图像将被粘贴，文件名将被更改为个人的卷号。这样做的原因将在后面解释。结果如下所示:</p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mv"><img src="../Images/565baf21ba557a66fc771c5923db13b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SlIC4a-GtaTPSQBTAosQ3A.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">学生们被隔离的面孔</figcaption></figure><p id="c52f" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">你可能会发现一些名单号码不见了，那是因为我们在gallary中找不到少数人的照片。我们的下一个目标是通过数据库导出这些数据，以便在需要时可以根据我们的应用程序流使用这些数据。</p><p id="3c47" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">想到的一个问题是，我们真的需要图像数据来进行面部识别吗？如果你想一想，你就会明白我们需要人脸数据只是为了比较前端发送的人脸数据，如果你想得更深，那么我们实际上是在比较从前端获得的图像嵌入和从后端数据库获得的特定批次的人脸嵌入。因此，不是存储60-80幅图像，然后检索每一幅图像，从而计算它们的嵌入是一项计算量很大的任务。</p><p id="3218" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">因此，一个更好的方法是通过MySQL数据库上传每张脸的嵌入和其他学生的详细信息。</p><h2 id="f173" class="lf im hh bd in lg lh li ir lj lk ll iv ju lm ln iz jy lo lp jd kc lq lr jh ls bi translated">4.存储在数据库中:</h2><p id="01c7" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">我们在这个项目中使用MySQL数据库，现在下一步是上传数据库上的学生数据。随着面部嵌入，我们也将上传其他细节，即姓名，电子邮件，大学电子邮件，批次，分支机构等。需要明确的是，以上教室数据是针对分公司‘CSE’和批次2017–21的。</p><p id="54f5" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">我们的下一个挑战是在MySQL中存储numpy数组。这个挑战是通过将numpy数组转换成字节并存储在LONGBLOB类型的列中解决的。这一部分比较棘手，但这一切都会过去的，而且确实过去了。让我们看看在MySQL表上上传数据的代码。</p><p id="dfa6" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated"><strong class="jl hi">学生详细信息:</strong>每个教室的详细信息，如点名号、电子邮件id等，由CR和班级负责人保存为Excel记录。做了两年的前科犯，我也有学生记录表。我们使用excel表格中的详细信息和面部图像(按照卷号的升序排列),并将两者结合起来，自动完成将数据上传到数据库的任务。</p><p id="2512" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">在导入库之前，我们必须安装用于迁移学习的预训练的keras facenet模型。</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="c4b0" class="lf im hh mk b fi mo mp l mq mr">pip3 install keras-facenet</span></pre><p id="f87e" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">成功安装后，导入基本库并从keras-facenet [2]创建一个Facenet实例:</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="db59" class="lf im hh mk b fi mo mp l mq mr">import os<br/>import pickle<br/>import numpy as np<br/>import pandas as pd<br/>from PIL import Image<br/>import mysql.connector<br/>from keras_facenet import FaceNet<br/>from tensorflow.keras.preprocessing.image import img_to_array,array_to_img</span><span id="b193" class="lf im hh mk b fi mt mp l mq mr">embedder = FaceNet() </span></pre><p id="88b0" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">一旦导入所有内容，我们将打开包含学生详细信息的excel文件。出于隐私考虑，电子邮件和个人信息被从图片中删除。我们使用熊猫图书馆来读取数据。</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="987b" class="lf im hh mk b fi mo mp l mq mr">df = pd.read_excel(“StudentListEmail_ccet_gmail.xlsx”)<br/>       .fillna(“example@domain.com”)</span><span id="28b5" class="lf im hh mk b fi mt mp l mq mr">df.head(5)</span></pre><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mw"><img src="../Images/77908f4e0235c26d9634c87874813425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M0YFrPGjBVAOQsvrUIK7jA@2x.jpeg"/></div></div></figure><p id="aee2" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">上图显示了班级学生详细信息的输出。使用这个和学生的脸的图像，我们将在MySQL数据库上传相同的。</p><p id="9367" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">我们的下一个任务是计算每个人脸的嵌入，并把它存储在一个列表中。</p><p id="c01f" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">注:excel文件中的辊号和各面的文件名相同，数量相等，按升序排列。我们的教室文件夹中不存在excel中的额外条目，反之亦然。</p><p id="6d30" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">请参见下面计算嵌入的代码片段。</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="1da3" class="lf im hh mk b fi mo mp l mq mr">name = list(df['First Name '])<br/>email = list(df['Email [Secondary]'])<br/>ccet_email = list(df['Email Address [CCET]'])<br/>roll= list(df['Roll Number'])</span><span id="3219" class="lf im hh mk b fi mt mp l mq mr">class_temp_path ="/home/username/Eye_Attend/Eye_Attend_Final/classroom_224"</span><span id="8493" class="lf im hh mk b fi mt mp l mq mr">temp_totalEmbeddings = []<br/>for faces in os.listdir(class_temp_path):<br/>    face = Image.open(class_temp_path+os.sep+faces)<br/>    face = img_to_array(face)<br/>    face = np.expand_dims(face, axis=0)<br/>    embedding = embedder.embeddings(face)<br/>    temp_totalEmbeddings.append(embedding)</span></pre><p id="6287" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">temp_totalEmbeddings列表保存了我们教室中每个人脸的嵌入。每个嵌入都是一个512维向量，如下所示:</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="f61e" class="lf im hh mk b fi mo mp l mq mr">print(temp_totalEmbeddings[0].shape)<br/>print(len(temp_totalEmbeddings))<br/>print(len(roll))</span><span id="9872" class="lf im hh mk b fi mt mp l mq mr">#Output <br/>(1, 512)<br/>40<br/>40</span></pre><p id="a0d1" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">这表明我们的excel中有40名学生，教室文件夹中有40张与他们对应的图像(按卷号asc排序)。</p><p id="9afe" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">由于每个嵌入是512维向量，因此我们的最终矩阵将是40×512维的。</p><p id="bee7" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">接下来，我们将看到在MySQL数据库中上传所有这些数据的上传代码。</p><pre class="lu lv lw lx fd mj mk ml mm aw mn bi"><span id="1d1f" class="lf im hh mk b fi mo mp l mq mr">branch_ = 'cse'<br/>batch_ = '2017'<br/>conn = mysql.connector.connect(<br/>    host="localhost",<br/>    user="root",<br/>    password="",<br/>    database="eyeattend"<br/>    )<br/>if conn.is_connected():<br/>    print("Successfully connected")<br/>    mycursor = conn.cursor()<br/>    create_tab = "CREATE TABLE IF NOT EXISTS `batch_2017` ( `roll_no` varchar(10) NOT NULL, \<br/>                 `name` varchar(50) NOT NULL,\<br/>                 `branch` text NOT NULL,\<br/>                 `batch` text NOT NULL,\<br/>                 `email` varchar(50) NOT NULL,\<br/>                 `ccet_email` varchar(50) NOT NULL,\<br/>                 `photo_embedd` longblob NOT NULL,\<br/>                 PRIMARY KEY (`roll_no`) ) "<br/>    <br/>    mycursor.execute(create_tab)<br/>    conn.commit()<br/>    <br/>    for i in range(len(roll)):<br/>        r = str(roll[i])<br/>        naam = str(name[i])<br/>        ema = str(email[i])<br/>        ccet = str(ccet_email[i])<br/>        embed = temp_totalEmbeddings[i]<br/>        pickemb = embed.dumps()<br/>        mycursor.execute("INSERT INTO batch_2017 VALUES (%s,%s,%s,%s,%s,%s,%s)",(r,naam,branch_,batch_,ema,ccet,pickemb))<br/>        conn.commit()<br/>        # Closing the connection<br/>    conn.close()<br/>    <br/>else:<br/>    print('Error in connecting with database')</span></pre><p id="4300" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">这里我们使用mysql.connector包。branch和batch是变量，可用于判断哪个分支和批次的学生数据将被上传到DB中。</p><p id="200b" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">首先，我们尝试与后端数据库建立连接。如果连接成功，我们打印出一条成功消息并创建一个光标对象。接下来，我们将运行CREATE TABLE查询来为特定的批处理创建表(如果它不存在的话)。此外，我们逐一迭代学生的详细信息及其面部图像嵌入，并将它们插入到数据库中。如前所述，为了上传嵌入，我们必须将它们编码成字节形式，因为我们的<code class="du mx my mz mk b">image_embed</code>属性接受<code class="du mx my mz mk b">longblob</code>。为此，我们使用dumps()函数并通过DB上传数据。下面显示了该代码以DB为单位的输出:</p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es na"><img src="../Images/982f9a2c1d34e5eb9d7a549f7bbffc34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kVOA745ryc2wIcm66Vu8Fg.png"/></div></div><figcaption class="mf mg et er es mh mi bd b be z dx translated">DB输出</figcaption></figure><p id="ab12" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">这样，同一批次的其他流(如ECE、CIVIL、MECH、BIOTECH、EE等)的数据可以以相同的方式上传。这就是我们如何为这个项目建立数据库的。在未来的博客中，你会看到我们将如何只获取coma监狱的点名号码和嵌入信息，以及我们将如何通过面部识别来标记出席人数。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h1 id="8e0f" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">结论</h1><p id="e4ce" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">所以这标志着博客的结束。在这篇博客中，你看到了我们如何使用预训练的keras-facenet模型来生成人脸图像的矢量嵌入，以及我们如何在MySQL上创建我们的教室数据库。在下一篇博客中，我们将建立面具检测器模型。敬请关注，我们希望你喜欢这个博客。一定要喜欢并分享给你的圈子。</p><h1 id="b11a" class="il im hh bd in io la iq ir is lb iu iv iw lc iy iz ja ld jc jd je le jg jh ji bi translated">参考</h1><p id="99e4" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">[1]https://pypi.org/project/mtcnn/<a class="ae nb" href="https://pypi.org/project/mtcnn/" rel="noopener ugc nofollow" target="_blank"/></p><p id="a27a" class="pw-post-body-paragraph jj jk hh jl b jm kj jo jp jq kk js jt ju kx jw jx jy ky ka kb kc kz ke kf kg ha bi translated">[2]https://pypi.org/project/keras-facenet/<a class="ae nb" href="https://pypi.org/project/keras-facenet/" rel="noopener ugc nofollow" target="_blank"/></p></div></div>    
</body>
</html>