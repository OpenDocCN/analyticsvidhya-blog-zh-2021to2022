<html>
<head>
<title>Predicting the future using Machine Learning part VI</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用机器学习预测未来第六部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/predicting-the-future-using-machine-learning-part-vi-ab2d1a4f9c3d?source=collection_archive---------21-----------------------#2021-01-13">https://medium.com/analytics-vidhya/predicting-the-future-using-machine-learning-part-vi-ab2d1a4f9c3d?source=collection_archive---------21-----------------------#2021-01-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="f1dc" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">K-means和肘方法+在Python中的实现</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/76ead3863f4516c2cc1b4e2bc886f223.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HmSQuT6OjB1KZOUh"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">奥斯卡·伊尔迪兹在<a class="ae jm" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="102e" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在完成了监督机器学习算法的主要类型之后，是时候讨论一种无监督机器学习算法了。无监督学习的一个经典例子是K-means算法，我将在本系列的最后一篇文章中讨论它以及Elbow方法。</p><h2 id="94f2" class="kj kk hh bd kl km kn ko kp kq kr ks kt jw ku kv kw ka kx ky kz ke la lb lc ld bi translated">k均值</h2><p id="387f" class="pw-post-body-paragraph jn jo hh jp b jq le ii js jt lf il jv jw lg jy jz ka lh kc kd ke li kg kh ki ha bi translated">对于K-means算法，我们没有试图建模的目标输出，而是试图从整个数据集中提取一个模式。K-means算法的目标是找到数据集中的<em class="lj"> k </em>个聚类，这些聚类由它们的中心表示。这种聚类方法试图找到实例和组实例之间的相似性，与维数减少方法相反，维数减少方法试图找到特征和组特征之间的相关性(<a class="ae jm" rel="noopener" href="/analytics-vidhya/predicting-the-future-using-machine-learning-part-iv-8747b319be5c">第四部分</a>和<a class="ae jm" href="https://minasuntea.medium.com/predicting-the-future-using-machine-learning-part-v-d8e9c54ef415" rel="noopener">第五部分</a>)。</p><p id="8bb0" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我通过创建7个函数来实现这个算法，为了说明和测试我的最终K-means算法，我使用了<em class="lj"> Iris </em>数据集的最后2个变量，就像在<a class="ae jm" rel="noopener" href="/analytics-vidhya/predicting-the-future-using-machine-learning-part-v-d8e9c54ef415">第五部分</a>中一样。</p><p id="83d6" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lj"> init_clusters </em>:从数据中随机初始化均值</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lk"><img src="../Images/7aca06872a6e175780c534fb8cf60410.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6ANWDe0bwPNx8Gu0ypdPtg.png"/></div></div></figure><p id="c2e2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lj">距离</em>:计算两点之间的距离</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ll"><img src="../Images/631629cd497526963c7eacfa61038919.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D4aiF-l-beSGMy69s0Udcw.png"/></div></div></figure><p id="122a" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lj"> cluster_assignment </em>:根据当前平均值计算矩阵<strong class="jp hi"> b，</strong>，其中包含点对聚类的分配</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lm"><img src="../Images/f69158205d6861b5476ef89d29259970.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wUhd3qeVETj96VK2hQreYA.png"/></div></div></figure><p id="d8dc" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lj"> compute_means </em>:根据当前的聚类分配，计算包含计算出的平均向量的矩阵<strong class="jp hi"> m </strong></p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ln"><img src="../Images/9d633391c16f289a8200e81bdd1986b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1I_OF8JyTwddVbRtcN5jXg.png"/></div></div></figure><p id="b5ab" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lj"> plot_clusters </em>:用不同的颜色绘制每个聚类的平均值及其指定点</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lo"><img src="../Images/9f95c125b0e52ea30a9b46a128dfaae3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TP_YKh7J1bUZ-u_1yovAqw.png"/></div></div></figure><p id="5bcb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lj"> is_converged </em>:使用阈值确定算法是否已基于当前和新均值集合收敛(已达到最小误差值)</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lp"><img src="../Images/29783105d6956f5de3cb2d1a9fdcb593.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WohGHcBXYLtrZ9LQvdFm_Q.png"/></div></div></figure><p id="0e51" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><em class="lj"> k_means </em>:结合以上所有函数，创建k-means函数</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lq"><img src="../Images/9ff1d18127c514525dbc86d873addcc3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BrQDXEkn6cb9gIRjBVrG3w.png"/></div></div></figure><p id="7ceb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">用<em class="lj"> Iris </em>数据集测试<em class="lj"> k_means </em>算法；</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lr"><img src="../Images/703305910003b504074bfa2440cf157f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*50NhEUT9BrocZ_E20SRNew.png"/></div></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es ls"><img src="../Images/b49410af86776c00d3e6ef72eb5f3a81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*JypyZxBlYJovsN-eJNbmpw.png"/></div></figure><p id="2cee" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">在上面显示的图表中，我选择k的值为1，并绘制了算法的1个步骤。其中前一步骤和后一步骤的手段被可视化。在这种情况下，这是手段趋同的最后一步。这样你可以看到均值在迭代时是如何移动的。当为k_means算法的3ʳᵈ自变量选择更高的值时，可以看到更多的迭代。</p><h2 id="d5b1" class="kj kk hh bd kl km kn ko kp kq kr ks kt jw ku kv kw ka kx ky kz ke la lb lc ld bi translated"><strong class="ak">肘法</strong></h2><p id="3112" class="pw-post-body-paragraph jn jo hh jp b jq le ii js jt lf il jv jw lg jy jz ka lh kc kd ke li kg kh ki ha bi translated">通过使用<em class="lj"> Iris </em>数据集，我们拥有了预先知道有多少个集群的优势。但是，即使不知道数据集中的聚类数，仍然有办法解决聚类问题。一种可能的方法是肘法。</p><p id="85e2" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">对于该方法，只需构建2个额外的函数，即最小化的合理的<em class="lj">成本</em>函数和<em class="lj">平均成本</em>函数，该函数计算<em class="lj"> k </em>值1到确定数的平均成本，并将它们组合在一个图中:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lt"><img src="../Images/4be11a1d67efdb8b8f90d945bfe83406.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aMM6cgCDFe-gQYLPBk67bg.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">计算20次成本以确定平均成本</figcaption></figure><p id="c2b9" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在唯一要做的事情是绘制每k值的平均成本:</p><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lu"><img src="../Images/7dcdeff85d4d434845e63c3cbd690229.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AMYt2bqPmMfE4oTzPzclXg.png"/></div></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es lv"><img src="../Images/3c821d267e0495f9c862cf0e8f325311.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D_jJckovW7gSTnewQWmznQ.png"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">看起来像个手肘！因此得名</figcaption></figure><p id="56dd" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">通过这篇文章，我已经达到了这个系列的结尾！我已经展示并讨论了机器学习算法的主要类型，有监督的和无监督的。有了这些算法，你已经在尝试使用机器学习进行准确预测方面取得了很大进展。我希望你喜欢这个系列，并继续关注我的页面，寻找更多像这样的(即将到来的)系列！</p></div></div>    
</body>
</html>