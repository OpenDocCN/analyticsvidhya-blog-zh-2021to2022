<html>
<head>
<title>Paper Explained- MLP Mixer: An MLP Architecture for Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">论文解释- MLP混合器:MLP建筑的视觉</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/paper-explained-mlp-mixer-an-mlp-architecture-for-vision-5e217ea8d287?source=collection_archive---------5-----------------------#2021-05-15">https://medium.com/analytics-vidhya/paper-explained-mlp-mixer-an-mlp-architecture-for-vision-5e217ea8d287?source=collection_archive---------5-----------------------#2021-05-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/6a264ab788d55fc11d831f5566634b34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yjJiNUqv2NOEPWFDJEaHaQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">MLP混合器由每个面片的线性嵌入、混合器层和分类器头组成。混合器层包含一个令牌混合MLP和一个通道混合MLP，每个都由两个全连接层和一个GELU非线性组成。其他组件包括:跳过连接、丢失、通道上的层规范和线性分类器头。图片取自<a class="ae it" href="https://arxiv.org/pdf/2105.01601.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>的第2页。</figcaption></figure><h1 id="39f3" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">简介和概述</h1><p id="d8a0" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">本文介绍了一个神经网络，它只是一个前馈多层感知器(MLP)，这意味着没有卷积，没有注意机制，没有λ层，什么都没有。只是矩阵乘法、非线性、归一化和跳过连接(改编自ResNets’)。这篇论文类似于最近SOTA论文中阐述的抽象概念，被称为“<a class="ae it" href="https://openreview.net/pdf?id=YicbFdNTTy" rel="noopener ugc nofollow" target="_blank">视觉变形金刚</a>”。我写了一个博客，详细地解释了视觉变形金刚，你可以在这里查看<a class="ae it" rel="noopener" href="/analytics-vidhya/vision-transformers-bye-bye-convolutions-e929d022e4ab">。😌</a></p><h1 id="2aaa" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">MLP混频器架构</h1><p id="9a7b" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">作者提出了一个分类体系结构。像在视觉变形器中一样，我们将输入图像分成小的小片(最好是16✕16).大小的)图像尺寸必须能被碎片尺寸整除。现在，当我们在网络中传播时，我们只是对这些迷你补丁进行操作，不像在卷积神经网络中，我们通过制作特征图来缩小分辨率但增加通道，在这里，我们将有一个又一个层，所有层都具有相同的大小，并且<strong class="ju hi">栈栈</strong>直到结束。<strong class="ju hi"> </strong>所以它很像一个变形金刚，当然这和变形金刚的区别在于各个层的外观。因此，就像在《变形金刚》中一样，首先，每个补丁都被馈送到一个完全连接的层，使其成为一个潜在的表示，也称为<strong class="ju hi">潜在嵌入</strong>。图像中的每个小块对应一个向量。使用相同的函数将每个面片投影到潜在空间中。</p><p id="169d" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">让我们试着理解什么是<strong class="ju hi">混合器层</strong>，这就是这个架构的核心。馈送到MLP架构的每个补丁被展开成一个向量，然后这些向量中的每一个被彼此堆叠，并且可以被解释为一个表。该表中的每一行代表一个具有512个通道的向量。有两种类型的MLP混合器层:<strong class="ju hi">令牌混合MLPs和信道混合MLPs。</strong></p><h1 id="993b" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">混合器层-解释</h1><p id="99cb" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">在令牌混合中，我们执行以下操作，我们以这样的方式转置表格，使得每一行都具有来自所有补丁的相同通道。因此，第一行表示，通道1的所有补丁在图像中，我们要饲料每一行相同的完全连接层(简单的MLP层)。事实上，您可以看到完全连接的层中的所有权重都是共享权重，这表示不同面片的相同通道之间的权重共享。令牌混合MLP允许不同空间位置(令牌)之间的通信；它们在每个通道上独立操作，并将表中的各个列作为输入。这有助于我们在逐个特征的基础上进行计算(512个通道只不过是特征图)。该架构使用单通道深度卷积进行令牌混合。这也称为跨位置操作。</p><p id="d427" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">在通道混合中，因为权重是共享的，所以在元级别上，这意味着现在我们可以再次执行相反的操作，将表翻转回面片，然后对所有面片执行相同的共享计算。信道混合MLP允许不同信道之间的通信；它们独立地对每个令牌进行操作，并将表中的各个行作为输入。该架构使用1✕1卷积进行声道混合。这也称为每个位置的操作。<strong class="ju hi">这两种类型的层是交错的，以实现两个输入维度的交互</strong>。</p><p id="9eb8" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">最终，每个混合器层具有两个权重矩阵，一个矩阵是我们以相同的方式单独前向传播所有通道的矩阵。第二个矩阵是以相同的方式单独向前传播所有补丁的矩阵。</p><p id="9b89" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">Mixer的架构完全基于多层感知器(MLP ),这些感知器在空间位置或特征通道上重复应用。混频器架构仅依赖于基本的矩阵乘法例程、数据布局的改变(整形和转置)以及标量非线性。</p><h1 id="14bc" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">混频器架构的规格</h1><p id="8817" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">如果您看过《愿景转变》或《大转移》一书，所有这些在架构方面都非常相似。他们所做的是用不同的补丁分辨率建立一堆不同大小的模型。因此，分辨率始终是斜杠(/)后的数字。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kv"><img src="../Images/ad437e0a4fdb8cd73fb770745ad783ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FJbGZyKRZrVm7C9pvpv4sQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">表1。图片取自<a class="ae it" href="https://arxiv.org/pdf/2105.01601.pdf" rel="noopener ugc nofollow" target="_blank">报纸</a>的第4页。</figcaption></figure><p id="ec66" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">与视觉转换器相比，由于注意力机制，当它们增加序列长度时(即，当它们降低分辨率时)，它们具有二次计算存储器需求。最终，图像中的碎片数量增加，因此，它们受到二次影响，而混合器仅受到线性影响。</p><h1 id="60f9" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">规模效应</h1><p id="b153" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">让我们在论文中提到的一个任务上对此进行分析。它们是许多提到的任务。我们将看看线性5镜头图像网络分类。</p><figure class="kw kx ky kz fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es la"><img src="../Images/b8cc3ae8a3a3d0948da83a8ee193f3e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RcTPWITnriFJ7NEw7ODErQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">图片摘自<a class="ae it" href="https://arxiv.org/pdf/2105.01601.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>的第6页。</figcaption></figure><p id="b773" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">让我们看看5镜头线性影像网络分类的最高精度。以下是他们对5镜头分类器的定义:“我们报告了通过解决图像和标签的冻结学习表示之间的L2正则化线性回归问题而获得的少镜头精度。这是它如何工作的，你训练一个线性分类器在模型给你的冻结的表示上，你以最高的准确度评估它。这是一项非常特殊的任务。我们可以清楚地看到，在这个框架中，这个模型比其他模型更容易扩展。因此，BiT-R152擅长小数据集，但随着训练规模的增加，它会停滞不前，不会有太大改善。然而，混音器模型的伸缩性非常好。</p><h1 id="d7ec" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">结论</h1><p id="2e33" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">这种模式受益于更大的规模，它是一种更简单的体系结构，具有更高的吞吐量(每秒每核的图像数量)，并且计算效率更高。这篇论文并不复杂，其简单的结构是它的卖点。准确性和计算之间权衡是公平的。从研究的角度来看，它提出了许多关于归纳偏差的问题，规模如何表现，以及是否可以在只有SDG和大量TPU的情况下让一切都工作。😶‍🌫️</p><p id="5bd2" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated"><strong class="ju hi">如果你喜欢这篇文章并获得了真知灼见，可以考虑</strong> <a class="ae it" href="https://www.buymeacoffee.com/nakshatrasinghh" rel="noopener ugc nofollow" target="_blank"> <strong class="ju hi">给我买杯咖啡</strong> ☕️ <strong class="ju hi">点击这里</strong> </a> <strong class="ju hi">。🤤</strong></p><h1 id="4650" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">参考</h1><ol class=""><li id="5c5c" class="lb lc hh ju b jv jw jz ka kd ld kh le kl lf kp lg lh li lj bi translated"><a class="ae it" href="https://arxiv.org/pdf/2105.01601.pdf" rel="noopener ugc nofollow" target="_blank"> MLP混合器:一个全MLP架构的愿景</a>。</li></ol><p id="c8e7" class="pw-post-body-paragraph js jt hh ju b jv kq jx jy jz kr kb kc kd ks kf kg kh kt kj kk kl ku kn ko kp ha bi translated">如果你喜欢这个帖子，请一定要鼓掌👏。💬连接？让我们来看看社会:<a class="ae it" href="https://myurls.co/nakshatrasinghh" rel="noopener ugc nofollow" target="_blank"><strong class="ju hi">http://myurls.co/nakshatrasinghh</strong></a><strong class="ju hi">。</strong></p></div></div>    
</body>
</html>