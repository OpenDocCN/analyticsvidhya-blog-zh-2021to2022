<html>
<head>
<title>Loss Functions Part-1</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">损失函数第一部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/loss-functions-part-1-17b2601031c1?source=collection_archive---------6-----------------------#2021-05-10">https://medium.com/analytics-vidhya/loss-functions-part-1-17b2601031c1?source=collection_archive---------6-----------------------#2021-05-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="e4f5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jc translated">首先让我们理解，机器是如何从给定的数据中学习的。其实就是学习数据内部的关系。有3个步骤，机器首先学习，然后预测输出。主要是第一次预测大多是随机的。然后它计算误差，然后学习，然后这个过程发生多次。错误继续减少成本函数也称为损失函数。如果代价函数是凸的，那么就更容易计算误差并将其作为全局和局部极小值来最小化。但并不是所有的成本函数本质上都是凸的。我们会通过观察它们的图形来看例子，慢慢理解误差函数。</p><h1 id="1b12" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">损失函数</h1><blockquote class="kj kk kl"><p id="7b2e" class="ie if km ig b ih ii ij ik il im in io kn iq ir is ko iu iv iw kp iy iz ja jb ha bi translated"><strong class="ig hi">为什么我们需要损失函数？</strong></p></blockquote><p id="7729" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">损失函数实际上衡量的是模型的预测结果有多好，这是衡量模型有多好的标准。</p><blockquote class="kj kk kl"><p id="5ab3" class="ie if km ig b ih ii ij ik il im in io kn iq ir is ko iu iv iw kp iy iz ja jb ha bi translated"><strong class="ig hi">成本函数和损失函数是一样的吗？</strong></p></blockquote><p id="2cb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们的日常生活中，我们通常会看到成本函数和损失函数这两个术语互换使用，但实际上，这两个术语并不相同。损失函数针对单个训练示例(条目)。成本函数是整个训练数据集的平均损失。</p><blockquote class="kj kk kl"><p id="9f55" class="ie if km ig b ih ii ij ik il im in io kn iq ir is ko iu iv iw kp iy iz ja jb ha bi translated">我们是否对所有数据集使用相同的损失函数？</p></blockquote><p id="9287" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们考虑损失函数之前，我们需要确定问题是什么，我们正在解决的是回归还是分类。在分类中，我们可以使用损失函数，如交叉熵、铰链损失。在回归中，我们使用SME、MAE和Huber。</p><blockquote class="kj kk kl"><p id="61d9" class="ie if km ig b ih ii ij ik il im in io kn iq ir is ko iu iv iw kp iy iz ja jb ha bi translated"><strong class="ig hi">损失函数都是凸的吗？</strong></p></blockquote><p id="0ddb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">没有。请看下图。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es kq"><img src="../Images/02efb352637e74f23f07fcb24d562cb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/0*8A2CHmSV_niVKljT"/></div><figcaption class="ky kz et er es la lb bd b be z dx translated">凸的、非凸的成本函数</figcaption></figure><blockquote class="kj kk kl"><p id="0a08" class="ie if km ig b ih ii ij ik il im in io kn iq ir is ko iu iv iw kp iy iz ja jb ha bi translated"><strong class="ig hi">为什么不使用相同的损失函数进行回归&amp;分类？</strong></p></blockquote><p id="6fde" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在对惩罚进行分类时，我们需要知道模型预测的置信度。这意味着，如果模型以高置信度预测了错误的结果，那么它应该受到更多的惩罚。在回归中，我们只看到预测值和实际值之间的差异。</p><h1 id="0ccc" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">回归损失平方的推导</h1><p id="a91e" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">回归问题中损失函数的一个常见选择是平方损失。现在，该过程正在为每个输入x选择t值的特定估计值y(x)，假设这样做，我们招致损失L(t，y(x))。平均或预期损失由E[L]给出。我们的目标是找到E[L]。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es lh"><img src="../Images/c815639c59a659380ec0447a59b489ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/0*Ft3y8w2XzesqzIAm.jpg"/></div></figure><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es li"><img src="../Images/b0c9c612700adb8e7b49111ff38aaa73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1016/format:webp/0*2J9-AUC8f37i8d6k.jpg"/></div></figure><p id="2d1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最佳最小二乘预测值由条件均值给出，另一项是目标数据的固有可变性。现在让我们看看回归问题的一些损失函数。</p><h2 id="2fed" class="lj jm hh bd jn lk ll lm jr ln lo lp jv ip lq lr jz it ls lt kd ix lu lv kh lw bi translated">均方误差</h2><p id="81a2" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">均方差是最常用的回归损失函数。MSE是我们的实际目标值和预测值之间距离的平方和。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es lx"><img src="../Images/3bbd5638409b1ede28aa26f66a52857d.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/0*3jvxSA4pudTXQZ4Z"/></div></figure><p id="7a47" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它克服了轴上和轴下距离相减的问题，因为现在所有值都是正的。它不考虑方向，只关注平均震级。至于平方的原因，与偏差较小的预测值相比，远离实际值的预测值受到严重惩罚。这一特性使得MSE对异常值的鲁棒性较差。因此，它不应该用于我们的数据容易出现许多异常值。观察下图中MSE的形状。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es ly"><img src="../Images/5d6001840d55813dc73330015db5c086.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/format:webp/0*JPDBjDWtZQ8iN8NJ.png"/></div></figure><p id="1af7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">二次函数只有全局最小值。因为没有局部极小值，我们永远不会陷入其中。因此，总是保证梯度下降将收敛到全局最小值(如果它收敛的话)。MSE等于方差和偏差平方之和。下面就是证明。通过最小化MSE，我们可以估计最佳拟合直线方程。首先来看推导。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es lz"><img src="../Images/dc3c36701fb0476f26d029daa3ab83f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/0*v_PDDzIBI1aY5rig.png"/></div></figure><p id="1c79" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过最小化MSE，我们可以估计最佳拟合直线方程。首先来看推导。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es ma"><img src="../Images/ca28a64ac7baf32835f12a4b2663ddd3.png" data-original-src="https://miro.medium.com/v2/resize:fit:902/format:webp/0*F63BXOJVq1RQtEdn.png"/></div></figure><p id="4f3e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我们已经看到的从MSE最小化得到线方程的推导。下面这个题目的数值问题。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es mb"><img src="../Images/1bdabce8100bb77a141cff6e83f6099b.png" data-original-src="https://miro.medium.com/v2/resize:fit:928/format:webp/0*FCvAUGE8qOujwxen.jpg"/></div></figure><h1 id="074d" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">平均绝对误差</h1><p id="0f63" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">平均绝对误差是用于回归问题的另一个损失函数。MAE是我们的目标值和模块函数预测值之差的总和。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es mc"><img src="../Images/f39748f08d7a1d2f22518c68c7a8d585.png" data-original-src="https://miro.medium.com/v2/resize:fit:514/format:webp/0*fG16FGEX4QoB8jLa.png"/></div></figure><p id="eca4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以它不考虑误差的方向。由于差不是平方的，所以它比MSE对异常值更稳健。但是当我们最小化MAE时，预测将是训练数据集的中间值。</p><h1 id="c0ea" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">MAE Vs MSE</h1><p id="8967" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">具有MAE损失的模型的预测受异常值和噪声的影响较小，而具有MSE损失函数的预测由于平方误差而略有偏差。所以人们想到了RMSE，它就是MSE的平方根。但是具有RMSE的模型针对少量的异常值进行了调整，这再次降低了性能。但我们不能得出一个结论，我们总是会使用MAE，因为它的导数不是连续的，所以效率很低，而使用MSE时，我们可以找到它的导数，等于0，以找到最优解。因此，如果数据有许多异常值，那么使用MAE，因为对于异常值，它比MSE更稳健。</p><h1 id="f69c" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">胡伯损失</h1><p id="c899" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">Huber损失是MSE和MAE中较好点的组合。Huber损失在0处是可微的，并且比MSE对异常值更不敏感。基本上是绝对误差，误差小了就变成二次误差了。当δ ~ 0时，Huber损耗接近MSE，当δ ~ ∞时，接近MAE。但是Huber损失也有一个问题，就是我们需要迭代地训练超参数delta。</p><h1 id="ec52" class="jl jm hh bd jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">回归损失函数的比较</h1><p id="8dfb" class="pw-post-body-paragraph ie if hh ig b ih lc ij ik il ld in io ip le ir is it lf iv iw ix lg iz ja jb ha bi translated">经验是，当没有很多异常值时，我们使用MSE作为误差函数。下图显示了上述所有误差函数。</p><figure class="kr ks kt ku fd kv er es paragraph-image"><div class="er es md"><img src="../Images/ef43886b25d72f36b2956ab5eaadff6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/0*pdhI8z-RD3ZBWbaF.png"/></div></figure></div></div>    
</body>
</html>