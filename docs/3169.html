<html>
<head>
<title>Deep Learning — A brief Introduction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">深度学习——简介</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/deep-learning-a-brief-introduction-86c92c6dd555?source=collection_archive---------8-----------------------#2021-06-14">https://medium.com/analytics-vidhya/deep-learning-a-brief-introduction-86c92c6dd555?source=collection_archive---------8-----------------------#2021-06-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="d644" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">深度学习也称为神经网络，是机器学习的一个子集，模仿人脑处理数据和创建决策模式的工作。</p><p id="6621" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">1967年，Alexey Ivakhnenko发表了有监督的、深度的、前馈多层感知器的第一个工作模型，</p><p id="0c71" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">那么，为什么深度学习不出名，然后突然之间深度学习行业蓬勃发展…？</p><p id="1d94" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">即使神经网络很久以前就被开发出来了，公司也没有足够的基础设施来投资研究。</p><p id="4d3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">举个例子，</p><p id="2f2f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5 MB硬盘在1956年重1吨。</p><p id="4b6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">10兆硬盘在20世纪80年代的价格是3495美元。</p><p id="6753" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">转向云服务的行业为许多研究人员打开了一扇大门，他们可以探索具有高GPU和TPU处理数百万数据的最佳配置的神经网络。</p><p id="b570" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据类型:</p><p id="1d3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结构化数据——结构化数据是定义明确且可搜索的数据类型，类似于表格格式的数据。</p><p id="fb45" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">非结构化数据——非结构化数据没有任何数据模型，以图像、音频等原始格式存储。</p><p id="aaf6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">神经元:</p><p id="eb50" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">神经元是大脑中的基本单位，它接收来自外部世界的感觉输入，并将这些输入转化为对自主和非自主行动有用的电信号。类似地，数百万个神经元会相互作用，产生有用信息电脉冲。</p><p id="62a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">人类大脑对图像/音频的反应比表格结构更快，我们正试图在神经网络中模仿同样的情况。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/4375286ba28758da2d28c0ed7be7b626.png" data-original-src="https://miro.medium.com/v2/resize:fit:1106/format:webp/1*ZK9XCXkktrBy8b-y0zW25A.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">神经元</figcaption></figure><p id="6aa4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">激活功能:</strong></p><p id="7cb3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">激活函数在计算加权和的基础上决定是否激活隐层中的一个神经元，并用于在神经元的输出中引入非线性。</p><p id="a21b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，在下面的等式中，每个神经元的输出将总是线性的，并且多个神经元的组合将总是提供相同的线性输出。神经元不能用线性函数学习，所以有必要添加一个激活函数来转换为非线性函数。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jo"><img src="../Images/0ad7265e60e5fc954453fc17523a42ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*k3lo9VkKbbGifd0Joj1k4Q.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">输出层的加权和</figcaption></figure><p id="30ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">激活功能类型:</strong></p><p id="2bbd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">乙状结肠功能:</strong></p><p id="b3a6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该图绘制成S形，数值范围在0和1之间。图形是非线性的，当斜率更陡时，X的小变化会导致Y值的大变化。如果该值大于0.5，则将该值预测为1，如果该值小于0.5，则将该值预测为0。这仅在二进制分类的情况下有用。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jp"><img src="../Images/d90b6fb6618b73f95bd9e1a3d427f747.png" data-original-src="https://miro.medium.com/v2/resize:fit:732/format:webp/1*IyvKUCkH4AKQqj4OUSkd5A.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">Sigmoid函数</figcaption></figure><p id="d325" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">双曲正切函数:</strong></p><p id="2c45" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是sigmoid函数的数学修改版本。值的范围在-1到1之间，本质上是非线性的。随着输入值范围的增加，曲线饱和，这意味着斜率将等于零。所以优化是不可能的。为了克服这种情况，开发了另一种激活功能，称为RELU。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jq"><img src="../Images/c88c9b750890753d6d7609e0f7b451af.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*K4gw8cAJNKXBrw6eTMuUEw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">Tan h函数</figcaption></figure><p id="1dd7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> RELU(整流线性单位):</strong></p><p id="371d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是非线性的，通常值的范围在0和无穷大之间，斜率永远不会达到0，除非值为负。RELU在计算上比Sigmoid和Tan h更便宜</p><p id="efd3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"><em class="jr">【A(x)= max(0，x) </em> </strong>。如果x是正数，它给出一个输出x，否则给出0</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es js"><img src="../Images/d34619683accc8bc8c6c2aa89c723f77.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*O_ASNaDyha1qzEFuLFDGTA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">RELU函数</figcaption></figure><p id="7cb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">漏Relu: </strong></p><p id="67d4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于负值，RELU函数将总是导致斜率为0，因此为了克服这种情况，引入了在负方向具有窄斜率的泄漏Relu。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jt"><img src="../Images/516df4f7b463e4c41dc9194e844c9064.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*PLQV4aUtmiA_nBeU3zST4Q.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">泄漏Relu</figcaption></figure><p id="4082" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">机器学习中梯度下降法介绍:</strong></p><p id="93a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">梯度下降是线性回归中的一种迭代优化算法，用于寻找微分函数的局部最小值。梯度下降算法将在斜率开始时选择随机初始化，并截取和计算误差项。在每次迭代中，它将反向检查误差项，并反向传播和更新斜率和截距值，直到误差最小。</p><p id="631b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">学习率代表步长，偏导数代表它应该移动的方向。总是建议选择较小的学习率，这样就不会错过局部最小值。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ju"><img src="../Images/b7ad4a186f509b340525a4616edeb315.png" data-original-src="https://miro.medium.com/v2/resize:fit:994/format:webp/1*unqdmYtSncQU5kubdl3puw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">梯度下降图</figcaption></figure><p id="f660" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">保持斜率和截距不变推导梯度下降方程:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jv"><img src="../Images/4626875dce0512833ad06167b5a3d247.png" data-original-src="https://miro.medium.com/v2/resize:fit:1286/format:webp/1*eKRFNdMYzmkiNT5cvvkjPw.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">梯度下降的偏导数</figcaption></figure><p id="7aae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用导出的公式对样本数据集进行梯度下降。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jw"><img src="../Images/32c1907012dd108a3d883e57ae828739.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*9H07vJOxVOCLdFt1Edzw5A.png"/></div></figure><p id="eb97" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">简单的神经网络架构。</strong></p><p id="8289" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在下图中，X1、X2和X3是表示数据集中的列的输入要素，隐藏图层不对外公开，所有计算都在隐藏图层中完成，并将数据传输到输出图层。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jx"><img src="../Images/14702123402ddf66e422491afa18d9ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:794/format:webp/1*5LEWMp1DxpVAQPeKxuSbeg.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">神经网络</figcaption></figure><p id="4308" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果输出应该是二进制分类，则在输出图层的末尾添加一个sigmoid函数，将其转换为0和1。默认情况下，输出是线性的。</p><p id="863e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一旦正向计算完成，基于成本函数，它将反向传播并更新隐藏层中的权重和偏差，并重新计算，直到成本函数最小化，类似于上述情况中看到的梯度下降示例。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jy"><img src="../Images/fd8fe713f61ac9b2fa554cf2b7d844b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*ewaed0YChbVWImGwf6P5KA.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">向前和向后计算</figcaption></figure><p id="b9f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">损失函数:</strong></p><p id="cec2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">它只是真实值与预测值的偏差，现在可以是平方差或绝对差的形式。</p><p id="8229" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">成本函数:</strong></p><p id="d878" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">损失函数仅针对一个训练示例，而成本函数考虑了作为损失函数的平均值简单计算的整个数据集。</p><p id="db30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">用Python构建单层神经网络:</strong></p><p id="82df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae jz" href="https://raw.githubusercontent.com/Jayachandran9283/Dataset/main/pima-indians-diabetes-data.csv" rel="noopener ugc nofollow" target="_blank">数据集</a></p><p id="c06e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在Google Colab中安装驱动器。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es ka"><img src="../Images/88dd5fcf4b7559f6e5d03ba19a595d92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BkMVCbNne_i0ZzA__OvrAA.png"/></div></div></figure><p id="a7cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">加载所需的库:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kf"><img src="../Images/384f55dac9228e015a37d5a2dcaa4cc4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LnPc1rnJQFFK0EwzVgxbZQ.png"/></div></div></figure><p id="236c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">神经网络是顺序的，我们在输入数据集中总共有8列作为独立变量和1个隐藏层来转换为非线性，并且由于输出是二进制分类器，所以添加了Sigmoid激活函数。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kg"><img src="../Images/e32a8fc03dd82d3753241d9d264c9961.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lmJWf8Zlo1en6-SCOXYpSw.png"/></div></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kh"><img src="../Images/ef34717f345f4a558329085ff73f0bf4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6YpO-UfPjXnEA_HT87WtUQ.png"/></div></div></figure><p id="79a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">增加历元大小/批次大小，并重复迭代以获得更好的精度。</p></div></div>    
</body>
</html>