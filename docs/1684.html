<html>
<head>
<title>Quantisation of Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">模型的量化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/quantisation-of-models-8f609987a1f5?source=collection_archive---------27-----------------------#2021-03-12">https://medium.com/analytics-vidhya/quantisation-of-models-8f609987a1f5?source=collection_archive---------27-----------------------#2021-03-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/34e24fd1e48aa153eda37914dbbae799.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-sw6x19DcL3nrwViN2i9iA.jpeg"/></div></div></figure><p id="3483" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在<a class="ae jn" rel="noopener" href="/analytics-vidhya/introduction-to-tf-lite-3a02d753939">之前的文章</a>中，我们已经讨论了以TF-Lite格式保存Tensorflow模型。现在让我们来理解为什么优化模型很重要。</p><ol class=""><li id="cecd" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated">尺寸减小导致手机、raspberry pi等边缘设备的存储尺寸更小。即使是一个小尺寸的模型消耗更少的内存，这给了我们更好的性能和稳定性。</li><li id="8aac" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">延迟也将减少。(模型在边缘设备中获得单个推断所花费的时间量称为延迟。)延迟还降低了边缘设备的功耗。</li><li id="2bd8" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated">对于一些硬件加速设备，如Edge GPU，如果模型优化正确，模型会给出更快的推断。</li></ol><p id="d295" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">量化可以解决这些问题。现在，让我们理解什么是量化。</p><h1 id="17fe" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated"><strong class="ak">什么是量化？</strong></h1><p id="e6fb" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated">量化是一个过程，其中用于表示模型参数的数字的精度(默认情况下，它们是float32)减少到float 16或int8。</p><p id="da4b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在让我们用更简单的术语来理解这个东西。</p><p id="2c66" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在前向和后向传播过程中，权重以float32的形式进行调整，以获得更好的推断，但在量化过程中，权重会根据您使用的量化方法转换为int8格式或float16。这导致减少模型大小和模型的等待时间，从而通过使模型精确来增加模型的加速。</p><h1 id="67c5" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">量化的类型</h1><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lf"><img src="../Images/d01b8e025e9366620c7c33786e251280.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bMaoOtniySalnBlCF6ZvyA.png"/></div></div></figure><p id="a031" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">现在让我们了解哪种量化对我们有利:</strong></p><figure class="lg lh li lj fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lk"><img src="../Images/8c7a622fe5e79d8b94f94fcc316a6d09.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AHPmJ0qKsJyaBVj0nMf1Bw.jpeg"/></div></div><figcaption class="ll lm et er es ln lo bd b be z dx translated">参考:<a class="ae jn" href="https://www.tensorflow.org/lite/performance/post_training_quantization" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/lite/performance/post _ training _ quantization</a></figcaption></figure><p id="92cc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">让我们来理解这个决策树，如果你已经保存了你的模型，那么如果你不想进一步优化它，你就把它转换成一个TF-Lite文件。如果你想进一步优化它，那么你有两个选择，你可以量化它:</p><p id="2b86" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">空间</strong></p><pre class="lg lh li lj fd lp lq lr ls aw lt bi"><span id="e159" class="lu kd hh lq b fi lv lw l lx ly">import tensorflow as tf</span><span id="52d3" class="lu kd hh lq b fi lz lw l lx ly">converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)</span><span id="d9f2" class="lu kd hh lq b fi lz lw l lx ly">tf_lite_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]</span><span id="0f08" class="lu kd hh lq b fi lz lw l lx ly">tflite_model = tf_lite_converter.convert()</span></pre><p id="fb55" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">浮动16 </strong></p><pre class="lg lh li lj fd lp lq lr ls aw lt bi"><span id="c4b3" class="lu kd hh lq b fi lv lw l lx ly">import tensorflow as tf<br/>converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)<br/>tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]<br/>tf_lite_converter.target_spec.supported_types = [tf.float16]<br/>tflite_model = tf_lite_converter.convert()</span></pre><p id="2049" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果您有一个代表性数据集，您可以将其量化为int8或uint8。可用于评估转换器优化的代表性数据集。这有助于通过校准模型的输入来估计最大和最小范围。因此，它有助于量化转换后的浮点模型。</p><pre class="lg lh li lj fd lp lq lr ls aw lt bi"><span id="f490" class="lu kd hh lq b fi lv lw l lx ly">def representative_data_gen():<br/>  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):<br/>    yield [input_value]</span></pre><p id="b1d1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这就是我们如何为我们的模型制作一个代表性的数据集。</p><p id="541f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi"> uint8 </strong></p><pre class="lg lh li lj fd lp lq lr ls aw lt bi"><span id="1784" class="lu kd hh lq b fi lv lw l lx ly">import tensorflow as tf</span><span id="e4fe" class="lu kd hh lq b fi lz lw l lx ly">converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)</span><span id="75e5" class="lu kd hh lq b fi lz lw l lx ly">converter.optimizations = [tf.lite.Optimize.DEFAULT]</span><span id="e223" class="lu kd hh lq b fi lz lw l lx ly">converter.representative_dataset = representative_data_gen</span><span id="3bbf" class="lu kd hh lq b fi lz lw l lx ly">converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]</span><span id="7d87" class="lu kd hh lq b fi lz lw l lx ly">converter.inference_input_type = tf.uint8 # or tf.int8</span><span id="290a" class="lu kd hh lq b fi lz lw l lx ly">converter.inference_output_type = tf.uint8 # or tf.int8</span><span id="77d3" class="lu kd hh lq b fi lz lw l lx ly">tflite_quant_model = converter.convert()</span></pre><p id="3038" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这就是我们如何量化我们的模型，以在我们的边缘设备中获得推论。在我接下来的博客中，我将通过制作深度学习模型向你展示，并向你解释量化是如何工作的。</p><p id="2b99" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在Github上关注我</p><div class="ma mb ez fb mc md"><a href="https://github.com/sayannath" rel="noopener  ugc nofollow" target="_blank"><div class="me ab dw"><div class="mf ab mg cl cj mh"><h2 class="bd hi fi z dy mi ea eb mj ed ef hg bi translated">sayannath -概述</h2><div class="mk l"><h3 class="bd b fi z dy mi ea eb mj ed ef dx translated">我是萨彦纳特。我是KIIT大学本科二年级的学生。我是……的主要贡献者之一</h3></div><div class="ml l"><p class="bd b fp z dy mi ea eb mj ed ef dx translated">github.com</p></div></div><div class="mm l"><div class="mn l mo mp mq mm mr in md"/></div></div></a></div><h1 id="577f" class="kc kd hh bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz bi translated">社交把手</h1><p id="d21c" class="pw-post-body-paragraph ip iq hh ir b is la iu iv iw lb iy iz ja lc jc jd je ld jg jh ji le jk jl jm ha bi translated"><em class="ms">insta gram:</em><a class="ae jn" href="https://www.instagram.com/sayannath235/" rel="noopener ugc nofollow" target="_blank"><em class="ms">https://www.instagram.com/sayannath235</em></a><em class="ms">/</em></p><p id="25b3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ms">领英:</em><a class="ae jn" href="https://www.linkedin.com/in/sayannath235/" rel="noopener ugc nofollow" target="_blank"><em class="ms">https://www.linkedin.com/in/sayannath235</em></a><em class="ms">/</em></p><p id="4a6b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><em class="ms">邮件:sayannath235@gmail.com</em></p></div></div>    
</body>
</html>