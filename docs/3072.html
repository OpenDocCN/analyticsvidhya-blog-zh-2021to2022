<html>
<head>
<title>Do You Visualize DataLoaders for Deep Neural Networks?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你能想象深度神经网络的数据加载器吗？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/do-you-visualize-dataloaders-for-deep-neural-networks-7840ae58fee7?source=collection_archive---------1-----------------------#2021-06-03">https://medium.com/analytics-vidhya/do-you-visualize-dataloaders-for-deep-neural-networks-7840ae58fee7?source=collection_archive---------1-----------------------#2021-06-03</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="9d2f" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">许多因素会影响深度神经网络的性能。让我们看看如何设置PyTorch管道进行图像增强(借助Albumentations Python库)，并使用可视化来发现任何潜在的问题，以免耗费您的时间和金钱。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/eb1ef6e79cdedf92311854f85ab5dc88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NdxIFtI2AeW3WkTaFePRjA.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">照片由Pexels的<a class="ae jn" href="https://www.pexels.com/photo/man-wearing-black-and-white-stripe-shirt-looking-at-white-printer-papers-on-the-wall-212286/" rel="noopener ugc nofollow" target="_blank">初创公司股票照片</a>提供</figcaption></figure><p id="180b" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">在软件开发中，当出现问题时，通常我们会得到一个错误，但是在数据科学中却不是这样。如果模型表现不佳，那么一般的方法是改变模型架构或调整超参数并进行更多的训练。是的，这些都是很好的选择，但是确保数据的正确性应该是首要的。</p><p id="2276" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">出自电视剧<a class="ae jn" href="https://www.imdb.com/title/tt1870479/" rel="noopener ugc nofollow" target="_blank"> <em class="kk">编辑室</em> </a> <em class="kk"> </em>:</p><blockquote class="kl"><p id="3fb2" class="km kn hi bd ko kp kq kr ks kt ku kj dx translated">解决问题的第一步是认识到它确实存在。</p></blockquote><p id="dc3b" class="pw-post-body-paragraph jo jp hi jq b jr kw ij jt ju kx im jw jx ky jz ka kb kz kd ke kf la kh ki kj hb bi translated">训练与测试数据的差异是低性能模型的最大原因。图像增强有助于通过人工添加更多数据来对抗过度拟合，并提高深度神经网络在计算机视觉任务中的性能。在本帖中，我们将涵盖以下内容:</p><ol class=""><li id="623c" class="lb lc hi jq b jr js ju jv jx ld kb le kf lf kj lg lh li lj bi translated">计算机视觉任务概述</li><li id="ee98" class="lb lc hi jq b jr lk ju ll jx lm kb ln kf lo kj lg lh li lj bi translated">计算机视觉管道</li><li id="fb1a" class="lb lc hi jq b jr lk ju ll jx lm kb ln kf lo kj lg lh li lj bi translated">使用白蛋白的图像增强</li><li id="46dc" class="lb lc hi jq b jr lk ju ll jx lm kb ln kf lo kj lg lh li lj bi translated">可视化数据加载器</li></ol><p id="1503" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你熟悉计算机视觉任务和PyTorch，那么可以跳过前两个。</p><h1 id="30f6" class="lp lq hi bd lr ls lt lu lv lw lx ly lz io ma ip mb ir mc is md iu me iv mf mg bi translated">计算机视觉任务概述</h1><p id="891f" class="pw-post-body-paragraph jo jp hi jq b jr mh ij jt ju mi im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated">计算机视觉(CV)任务的常见类型有:</p><ul class=""><li id="60e7" class="lb lc hi jq b jr js ju jv jx ld kb le kf lf kj mm lh li lj bi translated">图像分类</li><li id="0318" class="lb lc hi jq b jr lk ju ll jx lm kb ln kf lo kj mm lh li lj bi translated">图象分割法</li><li id="7f79" class="lb lc hi jq b jr lk ju ll jx lm kb ln kf lo kj mm lh li lj bi translated">目标检测</li></ul><p id="5d16" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">如果你不熟悉这些计算机视觉任务，那么看看post — <a class="ae jn" rel="noopener" href="/analytics-vidhya/image-classification-vs-object-detection-vs-image-segmentation-f36db85fe81">图像分类vs .对象检测vs .图像分割</a>。图像增强有助于使模型更好地概括所有3种类型的CV任务。</p></div><div class="ab cl mn mo gp mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="hb hc hd he hf"><h1 id="d2cf" class="lp lq hi bd lr ls mu lu lv lw mv ly lz io mw ip mb ir mx is md iu my iv mf mg bi translated">计算机视觉管道</h1><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mz"><img src="../Images/2a78dec4c84466a5bc555354bd81805d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hY7TSHLuP-fJBhdi29obVg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">PyTorch数据管道</figcaption></figure><p id="8f8d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">输入数据和目标数据都必须经过数据集和数据加载器，然后才能传递给模型进行训练。最好将数据加载器的输出可视化。通过这种方式，我们还可以识别数据集定义何时出现问题。相对于上面的数据管道图，只有目标数据和应用的转换基于CV任务类型而不同。</p><h2 id="679e" class="na lq hi bd lr nb nc nd lv ne nf ng lz jx nh ni mb kb nj nk md kf nl nm mf nn bi translated">使用白蛋白的图像增强</h2><p id="0fa2" class="pw-post-body-paragraph jo jp hi jq b jr mh ij jt ju mi im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated"><a class="ae jn" href="https://albumentations.ai/docs/" rel="noopener ugc nofollow" target="_blank">albumations</a>是一个快速灵活的图像增强库。它支持PyTorch和Keras。<a class="ae jn" href="https://pytorch.org/vision/stable/index.html" rel="noopener ugc nofollow" target="_blank"> Torchvision </a> library很好，但在图像分割或物体检测方面，它需要很大的努力才能做好。对输入数据和目标标注应用变换的方式因增强类型而异:像素级或空间级。</p><h2 id="cbc7" class="na lq hi bd lr nb nc nd lv ne nf ng lz jx nh ni mb kb nj nk md kf nl nm mf nn bi translated"><strong class="ak">像素级增强:</strong></h2><p id="6df9" class="pw-post-body-paragraph jo jp hi jq b jr mh ij jt ju mi im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated">更改原始图像的像素值，但不会更改输出遮罩。图像变换，如改变亮度或调整图像RGB调色板值的对比度，是像素级的增强。我们通过调整亮度来修改输入图像，但是我们保持输出遮罩不变。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es no"><img src="../Images/07e90c144c082e9c99e6568f5535273f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6VHqHzdQrt3qT5LY.jpg"/></div></div></figure><h2 id="4894" class="na lq hi bd lr nb nc nd lv ne nf ng lz jx nh ni mb kb nj nk md kf nl nm mf nn bi translated"><strong class="ak">空间级扩充:</strong></h2><p id="7479" class="pw-post-body-paragraph jo jp hi jq b jr mh ij jt ju mi im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated">更改图像和遮罩。当您应用图像变换(如镜像、旋转或裁剪输入图像的一部分)时，您还需要对输出标签应用相同的变换以保持其正确性。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es np"><img src="../Images/2da6237d00190ea11c2d364273e54303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*NiWZ6s-G48p0pUqe.jpg"/></div></div></figure><h2 id="717c" class="na lq hi bd lr nb nc nd lv ne nf ng lz jx nh ni mb kb nj nk md kf nl nm mf nn bi translated"><strong class="ak">白蛋白的印象分:</strong></h2><ul class=""><li id="4bf3" class="lb lc hi jq b jr mh ju mi jx nq kb nr kf ns kj mm lh li lj bi translated">能够毫不费力地将图像增强添加到任何计算机视觉管道中。</li><li id="9f42" class="lb lc hi jq b jr lk ju ll jx lm kb ln kf lo kj mm lh li lj bi translated">转换声明的语法非常类似于Torchvision。</li><li id="cf32" class="lb lc hi jq b jr lk ju ll jx lm kb ln kf lo kj mm lh li lj bi translated">允许您为每个变换设置所需的概率和值的大小。</li></ul><p id="4730" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">增强管道的示例定义如下:</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="nt nu l"/></div></figure><p id="a7fe" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">还不服气？然后查看文章— <a class="ae jn" href="https://albumentations.ai/docs/introduction/why_you_need_a_dedicated_library_for_image_augmentation/" rel="noopener ugc nofollow" target="_blank">为什么您需要一个图像增强专用库</a>。</p></div><div class="ab cl mn mo gp mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="hb hc hd he hf"><h1 id="c482" class="lp lq hi bd lr ls mu lu lv lw mv ly lz io mw ip mb ir mx is md iu my iv mf mg bi translated">可视化数据加载器</h1><h2 id="d055" class="na lq hi bd lr nb nc nd lv ne nf ng lz jx nh ni mb kb nj nk md kf nl nm mf nn bi translated">为什么？</h2><p id="3c0c" class="pw-post-body-paragraph jo jp hi jq b jr mh ij jt ju mi im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated">现在，您可能会想，如果Albumentations这么好，那么我们为什么需要可视化数据加载器。我很高兴你问了，蛋白沉淀仍然需要用户输入，我们在提供正确的值方面不是很好。任何理性的人都应该考虑增强的类型以及它是否适用于特定的数据集，但通常情况并非如此。</p><blockquote class="kl"><p id="4ad2" class="km kn hi bd ko kp kq kr ks kt ku kj dx translated">为了避免任何意外，最好是观想。</p></blockquote><p id="84ba" class="pw-post-body-paragraph jo jp hi jq b jr kw ij jt ju kx im jw jx ky jz ka kb kz kd ke kf la kh ki kj hb bi translated">当对MNIST数据集中的数字9应用旋转变换时，它可以被变换为6，但标注仍为9。看到搞砸数据增强有多容易了吧？</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nv"><img src="../Images/9f32e4ffcd807ba66e0027fd2b4db7e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2zx0vNjpuSeyBxdZrokX9g.png"/></div></div></figure><h2 id="9899" class="na lq hi bd lr nb nc nd lv ne nf ng lz jx nh ni mb kb nj nk md kf nl nm mf nn bi translated">怎么会？</h2><p id="2b4a" class="pw-post-body-paragraph jo jp hi jq b jr mh ij jt ju mi im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated">像<a class="ae jn" href="https://pytorch.org/vision/stable/utils.html#torchvision.utils.make_grid" rel="noopener ugc nofollow" target="_blank"> <em class="kk"> make_grid </em> </a>和<a class="ae jn" href="https://pytorch.org/vision/stable/utils.html#torchvision.utils.draw_bounding_boxes" rel="noopener ugc nofollow" target="_blank"><em class="kk">draw _ bounding _ box</em></a>这样的Torchvision函数相当好用，但是并不是端到端的。因此，我们将编写某种包装器，接受数据加载器的<code class="du nw nx ny nz b">iter</code>对象，并绘制输入和目标数据值。</p><p id="65a0" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">关于以下代码的注释:</p><ul class=""><li id="aa25" class="lb lc hi jq b jr js ju jv jx ld kb le kf lf kj mm lh li lj bi translated">PyTorch张量需要形状(C x H x W)的图像，它与NumPy数组形状(H x W x C)相反。</li><li id="9032" class="lb lc hi jq b jr lk ju ll jx lm kb ln kf lo kj mm lh li lj bi translated">图像数据必须是数据类型为<code class="du nw nx ny nz b">float</code>的火炬张量，以训练模型，而对于绘图，其类型应为<code class="du nw nx ny nz b">uint8</code>。</li><li id="a0b3" class="lb lc hi jq b jr lk ju ll jx lm kb ln kf lo kj mm lh li lj bi translated">最佳实践是尽可能避免对数据加载器的<code class="du nw nx ny nz b">iter</code>对象进行多次初始化，因为这非常耗时。这就是为什么要把<code class="du nw nx ny nz b">iter</code>对象作为函数参数，而不是数据加载器本身。</li></ul><p id="4591" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">同样，这篇文章的重点是数据加载器的输出，如果你对整个数据管道感兴趣，那么看看这个<a class="ae jn" href="https://colab.research.google.com/drive/1xnYAmyWqMKMaYDY4J6yty_hQEIPrLMcK?usp=sharing" rel="noopener ugc nofollow" target="_blank"> Colab笔记本</a></p><p id="3759" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">图像分类</strong></p><p id="f89d" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">资料组👉<a class="ae jn" href="https://www.cs.toronto.edu/%7Ekriz/cifar.html" rel="noopener ugc nofollow" target="_blank"> CIFAR10 </a></p><p id="3af8" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">转换👉调整➡️大小旋转➡️水平翻转</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="nt nu l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es oa"><img src="../Images/5eeea2ae371b9277843135d2192978db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*73sPfLxYlYtBF5FQN6rYLg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图像分类数据加载器的可视化</figcaption></figure><p id="dfa9" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">图像分割</strong></p><p id="3537" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">资料组👉<a class="ae jn" href="http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamSeq01/" rel="noopener ugc nofollow" target="_blank">坎维德</a></p><p id="cbfe" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">转换👉调整➡️大小旋转➡️水平翻转</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="nt nu l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ob"><img src="../Images/19431835570ce7ec41e4881e1fdf71d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JBsOYAQdrT2TsYojdTHogw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">图像分割数据加载器的可视化</figcaption></figure><p id="f9f6" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated"><strong class="jq hj">物体检测</strong></p><p id="cacb" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">资料组👉<a class="ae jn" href="https://www.cis.upenn.edu/%7Ejshi/ped_html/" rel="noopener ugc nofollow" target="_blank">宾夕法尼亚-复旦行人检测数据库</a></p><p id="a6d3" class="pw-post-body-paragraph jo jp hi jq b jr js ij jt ju jv im jw jx jy jz ka kb kc kd ke kf kg kh ki kj hb bi translated">转换👉调整➡️水平翻转➡️亮度和对比度➡️移动，缩放和旋转</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="nt nu l"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es oc"><img src="../Images/2cfe282a6e09db50e5a84ac4701249d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GJSO4i3Gh9x-6qV6UV4Fdw.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">对象检测数据加载器的可视化</figcaption></figure></div><div class="ab cl mn mo gp mp" role="separator"><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms mt"/><span class="mq bw bk mr ms"/></div><div class="hb hc hd he hf"><h1 id="abab" class="lp lq hi bd lr ls mu lu lv lw mv ly lz io mw ip mb ir mx is md iu my iv mf mg bi translated">结论</h1><p id="f923" class="pw-post-body-paragraph jo jp hi jq b jr mh ij jt ju mi im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated">在计算机视觉中，相对更容易把握模型在做什么。它是如何工作的是一个不同的故事，但是通过足够多的实验，我们可以猜测什么是有效的，什么是无效的。关键是要用最少的实验来解决这个问题。我们对数据管道设置越有信心，就越有时间进行各种实验来提高模型性能。</p><h1 id="e42c" class="lp lq hi bd lr ls lt lu lv lw lx ly lz io ma ip mb ir mc is md iu me iv mf mg bi translated">旁注</h1><p id="fb87" class="pw-post-body-paragraph jo jp hi jq b jr mh ij jt ju mi im jw jx mj jz ka kb mk kd ke kf ml kh ki kj hb bi translated">[1]我相信来自<em class="kk">新闻编辑室</em>的引语是取自下面<a class="ae jn" href="https://en.wikipedia.org/wiki/Zig_Ziglar" rel="noopener ugc nofollow" target="_blank">金克拉</a>的引语，但我不太确定。</p><blockquote class="kl"><p id="e5aa" class="km kn hi bd ko kp kq kr ks kt ku kj dx translated"><em class="kv">除非你承认自己有问题，并承担解决问题的责任，否则你无法解决问题。</em></p></blockquote><p id="b690" class="pw-post-body-paragraph jo jp hi jq b jr kw ij jt ju kx im jw jx ky jz ka kb kz kd ke kf la kh ki kj hb bi translated">[2]我从白蛋白中听说过AutoAlbument，但还没有尝试过。</p></div></div>    
</body>
</html>