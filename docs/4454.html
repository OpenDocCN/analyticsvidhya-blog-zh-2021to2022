<html>
<head>
<title>Hack a Neural Network in just 10 Lines of Code!!!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">只用10行代码就能黑进一个神经网络！！！</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/hack-a-neural-network-in-just-10-lines-of-code-ecd2192930a1?source=collection_archive---------4-----------------------#2021-10-17">https://medium.com/analytics-vidhya/hack-a-neural-network-in-just-10-lines-of-code-ecd2192930a1?source=collection_archive---------4-----------------------#2021-10-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/6e6b76b6e9f8228ee755f48629792ebd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EVbKTcwZcAyfXSxl"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">杰佛森·桑多斯在<a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><p id="adcc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">大家好！希望你一切都好。让我们开始吧。</p><h1 id="162d" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">什么是入侵神经网络？</h1><blockquote class="kq kr ks"><p id="26fa" class="iu iv kt iw b ix iy iz ja jb jc jd je ku jg jh ji kv jk jl jm kw jo jp jq jr ha bi translated">黑掉一个神经网络就是简单的愚弄一个神经网络。神经网络越来越多地用于不同领域的各种安全和调节系统。在不同类型的攻击中保持完整性是非常重要的。在这篇文章中，我将解释我们如何修改一幅图像(而不改变太多)来迫使神经网络对它进行错误分类(这也有很高的确定性)。</p><p id="7461" class="iu iv kt iw b ix iy iz ja jb jc jd je ku jg jh ji kv jk jl jm kw jo jp jq jr ha bi translated">下面是伊恩·古德菲勒论文的摘录，<a class="ae it" href="https://arxiv.org/pdf/1412.6572.pdf" rel="noopener ugc nofollow" target="_blank">解释和利用对立的例子</a>。</p></blockquote><figure class="ky kz la lb fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kx"><img src="../Images/09f0f5282feea3678e0a57352bd15492.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NAtY_3O5gnpY9tsTGer7NA.png"/></div></div></figure><p id="b71d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在上面的例子中，我们可以看到，在图像中添加精心设计和数学设计的噪声可以极大地扰乱神经网络的预测，同时设法保持图像在视觉上不变。</p><p id="f046" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这篇文章中，我将黑客MNIST数字分类器神经网络。让我们拍摄一个数字为0的图像(如下所示)。由于我建立的模型有大约96%的准确率，它将正确地将这张图像分类为0。现在，我想通过添加一些策略噪声(这是通过简单的梯度下降实现的)来修改0的图像，以便MNIST模型将其分类为图像8 <strong class="iw hi">和</strong>，图像没有被修改太多。因此，对我们人类来说，我们仍然可以清楚地看到图像是数字0，但模型认为图像很有可能由数字8组成。</p><p id="f7a5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">结果如下所示:</p><figure class="ky kz la lb fd ii er es paragraph-image"><div class="er es lc"><img src="../Images/b0ac03a69e824106d1db205ef3a01b4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*rHfi3js7IEqLG_icOPmCtw.png"/></div></figure><p id="def8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">上面的图像被MNIST分类器识别为0号，有99%的把握。下面给出的是被NN以99.6%的确定性识别为8号的修改图像。</p><figure class="ky kz la lb fd ii er es paragraph-image"><div class="er es lc"><img src="../Images/c4c28e24800cece4b5a6621916618774.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*fVwxjbg59g8nirkLqacMHQ.png"/></div></figure><p id="359f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这篇文章中，我将解释我如何能够将第一幅图像修改为第二幅图像，即，我如何欺骗神经网络将一幅明显为0的图像分类为8(具有非常高的可信度)。</p><h1 id="8dc7" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated"><strong class="ak"> <em class="ld">破解MNIST分类器的步骤:</em> </strong></h1><p id="b892" class="pw-post-body-paragraph iu iv hh iw b ix le iz ja jb lf jd je jf lg jh ji jj lh jl jm jn li jp jq jr ha bi translated">基于在这篇<a class="ae it" href="https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627" rel="noopener" target="_blank">文章</a>中找到的MNIST分类器来训练要被攻击的模型。既然我们已经有了准备好接受黑客攻击的训练模型，让我们开始黑客攻击吧。</p><p id="f794" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将使用简单的梯度下降来计算必须添加到原始图像中的精确噪声，以便摆脱神经网络。首先，我要为梯度下降做一个损失函数。损失函数是任何涉及梯度下降系统的最重要部分之一。梯度下降只是最小化损失函数的一种方式。因此，我们需要建立一个反映我们目标的损失函数，即，使图像的预测概率为8最大，并保持原始图像和修改图像之间的差异最小。这是损失函数的样子。</p><pre class="ky kz la lb fd lj lk ll lm aw ln bi"><span id="1885" class="lo jt hh lk b fi lp lq l lr ls"><strong class="lk hi">def</strong> findloss(diff,pred):</span><span id="6e3c" class="lo jt hh lk b fi lt lq l lr ls">    l1=torch.mean(torch.square(diff))<br/>    l2=pred**(-1)<br/>    <br/>    fl=(l1+l2)**0.5<br/>    <br/>    <strong class="lk hi">return</strong> fl</span></pre><p id="f21e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">l1表示修改后的图像和原始图像之间的偏差(差异或噪声)。l2表示概率的倒数，NN将修改的图像分类为数字8。因此，最小化l1和l2之和的平方根，导致最小化l1和l2，从而最小化噪声并最大化修改图像同时被NN分类为8的概率。</p><p id="176f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，让我们使用梯度下降来修改噪声，以便最小化上面定义的损失函数(这自动实现了我们设置的攻击神经网络的目标)。下面是代码。</p><pre class="ky kz la lb fd lj lk ll lm aw ln bi"><span id="ab33" class="lo jt hh lk b fi lp lq l lr ls">learning_rate=0.0005<br/>num_descents=2000000 <br/><em class="kt">#number of times gradient descent is employed</em><br/><br/>img=img.cuda()<br/>#generate random noise to finetune using gradient descent<br/>diff=torch.rand(784).cuda().requires_grad_()</span><span id="9ed3" class="lo jt hh lk b fi lt lq l lr ls"><strong class="lk hi">for</strong> i <strong class="lk hi">in</strong> range(num_descents):<br/>    <br/>    #get the modified image<br/>    imagef=img+diff</span><span id="b3e3" class="lo jt hh lk b fi lt lq l lr ls">    pred=torch.exp(model(imagef.reshape([1,784])))[0][8]<br/>    <br/>    totalloss=findloss(diff,pred)<br/>    <strong class="lk hi">if</strong> i%10000 ==0:<br/>        print('Loss and prediction by the model after '+str(i)+' steps of gradient descent are '+str(totalloss.item()),str(pred.item()))<br/>     <br/>        <br/>    <em class="kt">#find gradients of totalt wrt yarray.</em><br/>    totalloss.backward()<br/><br/>    gradients=diff.grad<br/>    <em class="kt">#torch.clip(gradients,max=100.0)</em><br/>    <strong class="lk hi">with</strong> torch.no_grad():<br/>        diff[1:]=diff[1:]-learning_rate*gradients[1:]<br/>    diff.grad.data.zero_()</span></pre><p id="dcaa" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">完整的代码可以在我的<a class="ae it" href="https://github.com/mohammadaaftabv/HackNN/blob/master/SimpeGradientDescentToHackNN.ipynb" rel="noopener ugc nofollow" target="_blank"> repo </a>中找到。通过这种方法获得的结果已经在上面写了。</p><p id="a7a5" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">所以，这就是简单梯度下降是如何骗过MNIST分类器的。</p><p id="9d56" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">感谢您通读这篇文章。这里有另一篇文章展示了简单梯度下降是多么强大。</p><div class="lu lv ez fb lw lx"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/neural-networks-vs-simple-gradient-descent-the-age-old-brachistochrone-problem-7503be69d611"><div class="ly ab dw"><div class="lz ab ma cl cj mb"><h2 class="bd hi fi z dy mc ea eb md ed ef hg bi translated">神经网络与简单梯度下降:古老的最速降问题。</h2><div class="me l"><h3 class="bd b fi z dy mc ea eb md ed ef dx translated">简介:</h3></div><div class="mf l"><p class="bd b fp z dy mc ea eb md ed ef dx translated">medium.com</p></div></div><div class="mg l"><div class="mh l mi mj mk mg ml in lx"/></div></div></a></div><p id="44c3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果你喜欢这篇文章，让我们联系。</p><p id="b9aa" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae it" href="https://www.linkedin.com/in/mohammadaaftabv/" rel="noopener ugc nofollow" target="_blank"> Linkedin </a>，<a class="ae it" href="https://twitter.com/Aaftab08924859" rel="noopener ugc nofollow" target="_blank"> Twitter </a>，<a class="ae it" href="https://github.com/mohammadaaftabv" rel="noopener ugc nofollow" target="_blank"> Github </a></p></div></div>    
</body>
</html>