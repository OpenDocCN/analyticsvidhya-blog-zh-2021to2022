<html>
<head>
<title>Train a custom object detection model in less than 5 min</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在不到5分钟的时间内训练一个自定义对象检测模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/train-a-custom-object-detection-model-in-less-than-5-min-96ceff8f567a?source=collection_archive---------15-----------------------#2021-04-03">https://medium.com/analytics-vidhya/train-a-custom-object-detection-model-in-less-than-5-min-96ceff8f567a?source=collection_archive---------15-----------------------#2021-04-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="97a3" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">使用微型YOLO v4的Grapes检测</h2></div><h2 id="73a1" class="iw ix hh bd iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">2022年11月11日更新:我们刚刚发布了我们的开源Python API，你现在可以用几行代码做同样的事情！关于我们的Github的更多信息。</h2><p id="c716" class="pw-post-body-paragraph jv jw hh jx b jy jz ii ka kb kc il kd jh ke kf kg jl kh ki kj jp kk kl km kn ha bi translated">虽然从预训练的模型启动对象检测非常简单，但当训练您的自定义对象检测模型时，事情可能会变得更难。这篇文章描述了这个任务是如何通过<a class="ae ju" href="https://ikomia.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="jx hi"> Ikomia平台</strong> </a>在几次点击中被有效解决的。</p><figure class="ko kp kq kr fd ks"><div class="bz dy l di"><div class="kt ku l"/></div></figure><h1 id="101b" class="kv ix hh bd iy kw kx ky jc kz la lb jg in lc io jk iq ld ir jo it le iu js lf bi translated">自动葡萄检测</h1><p id="7f66" class="pw-post-body-paragraph jv jw hh jx b jy jz ii ka kb kc il kd jh ke kf kg jl kh ki kj jp kk kl km kn ha bi translated">我们今天的用例旨在葡萄栽培中基于图像的监控和田间机器人的背景下检测葡萄。</p><p id="e652" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">首先，我们需要一个合适的数据集来训练我们的自定义对象检测模型。我们在这里选择Embrapa WGISD数据集<a class="ae ju" href="https://github.com/thsant/wgisd" rel="noopener ugc nofollow" target="_blank"/>。这是Santos等人[1]利用深度神经网络和三维关联  <em class="ll"> </em>进行<a class="ae ju" href="https://arxiv.org/abs/1907.11819v3" rel="noopener ugc nofollow" target="_blank"> <em class="ll">葡萄检测、分割和跟踪研究工作的一部分。</em></a></p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lm"><img src="../Images/1efab943ff8efb1c5322b92db1bf8198.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RXANSnks6tLXSaiD.jpg"/></div></div></figure><p id="f0bc" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">当搜索对象检测算法时，YOLO系列是最受欢迎的算法之一。以下是主要优势的非详尽列表:</p><ul class=""><li id="e638" class="lt lu hh jx b jy lg kb lh jh lv jl lw jp lx kn ly lz ma mb bi translated"><strong class="jx hi">快速</strong>:在支持GPU的设备上进行实时检测</li><li id="b9ab" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated"><strong class="jx hi">高效</strong> : YOLOv3和最近的YOLOv4 [2]实现了最先进的性能</li><li id="ae8b" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated"><strong class="jx hi">完整性</strong>:不同的架构可供选择，从采用微型YOLO的边缘计算到采用YOLOv4的高效率</li><li id="33fa" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">经济实惠:训练可以在只有一个传统图形处理器的标准计算机上执行</li><li id="0678" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">开源框架:由充满活力的社区支持</li></ul><p id="719c" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">点击<a class="ae ju" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">这里</a>看一下YOLO框架。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es mh"><img src="../Images/1de489b34ebbd83942cfb72794c06f89.png" data-original-src="https://miro.medium.com/v2/resize:fit:256/format:webp/0*fL4vKPP4G2iM6QCI.png"/></div></figure><h1 id="278d" class="kv ix hh bd iy kw kx ky jc kz la lb jg in lc io jk iq ld ir jo it le iu js lf bi translated">让我们在Ikomia工作室训练吧</h1><p id="85e1" class="pw-post-body-paragraph jv jw hh jx b jy jz ii ka kb kc il kd jh ke kf kg jl kh ki kj jp kk kl km kn ha bi translated">训练一个定制的物体检测器从未如此简单。Ikomia HUB为我们的培训渠道提供了所有的构件。一切都是现成的，没有代码。当然，您将能够在不到5分钟的时间内开始您的训练。只要按照这四个步骤。</p><h1 id="0077" class="kv ix hh bd iy kw kx ky jc kz la lb jg in lc io jk iq ld ir jo it le iu js lf bi translated">1-从中心安装算法</h1><p id="99a7" class="pw-post-body-paragraph jv jw hh jx b jy jz ii ka kb kc il kd jh ke kf kg jl kh ki kj jp kk kl km kn ha bi translated">为了构建我们的定制训练工作流，我们只需要两个算法。</p><p id="9775" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">第一个将数据集转换为Ikomia格式，以确保与任何训练算法兼容。WGISD数据集的注记以YOLO格式存储。每个图像都有一个描述对象类别和框坐标的文本文件。集线器中已经存在一个专用加载器。</p><p id="2ee8" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">第二个有效地训练了我们的基于<em class="ll">暗网</em>框架的目标检测模型。而且，这个插件提供了不同的模型架构。所以你可以选择一个最符合你需要的。在本教程中，我们使用微型YoloV4网络。</p><p id="80be" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">以下是在Ikomia STUDIO中安装它们的步骤:</p><ul class=""><li id="eccb" class="lt lu hh jx b jy lg kb lh jh lv jl lw jp lx kn ly lz ma mb bi translated">从Ikomia STUDIO打开中枢</li><li id="cb92" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">搜索<strong class="jx hi"> <em class="ll"> dataset_yolo </em> </strong>和<strong class="jx hi"> <em class="ll"> train_yolo_v4 </em> </strong>插件(在搜索栏中使用‘yolo’关键字)</li><li id="6f8d" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">按顺序安装它们</li></ul><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mi"><img src="../Images/d68ee5d0ccab27f3c3b75ac982f8ec4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*rKG9JKQS_ufY9pfc.gif"/></div></div><figcaption class="mj mk et er es ml mm bd b be z dx translated">YOLO算法的安装</figcaption></figure><h1 id="ff79" class="kv ix hh bd iy kw kx ky jc kz la lb jg in lc io jk iq ld ir jo it le iu js lf bi translated">2-加载数据集</h1><p id="cc47" class="pw-post-body-paragraph jv jw hh jx b jy jz ii ka kb kc il kd jh ke kf kg jl kh ki kj jp kk kl km kn ha bi translated">首先，从Github存储库中获取数据集:</p><pre class="ko kp kq kr fd mn mo mp mq aw mr bi"><span id="e608" class="iw ix hh mo b fi ms mt l mu mv">cd your-favorite-dataset-folder<br/>git clone <a class="ae ju" href="https://github.com/thsant/wgisd.git" rel="noopener ugc nofollow" target="_blank">https://github.com/thsant/wgisd.git</a></span></pre><p id="b961" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">其次，在<em class="ll"> wgisd </em>文件夹中创建一个文件<em class="ll"> classes.txt </em>来存储类标签。数据集包含在一个表示grapes的类中，所以只需在文件中放一行“<em class="ll"> grapes </em>”。</p><p id="b8c9" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">然后，用<strong class="jx hi"> <em class="ll"> dataset_yolo </em> </strong>插件在Ikomia STUDIO中加载数据集:</p><ol class=""><li id="e5de" class="lt lu hh jx b jy lg kb lh jh lv jl lw jp lx kn mw lz ma mb bi translated">在过程库中搜索新安装的插件(左窗格)</li><li id="22e9" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn mw lz ma mb bi translated">填充参数</li></ol><ul class=""><li id="aa47" class="lt lu hh jx b jy lg kb lh jh lv jl lw jp lx kn ly lz ma mb bi translated">数据文件夹(应为<em class="ll"> path-to-wgisd/data </em></li><li id="ddb8" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">类文件(应为<em class="ll">path-to-wgisd/classes . txt</em>)</li></ul><p id="2a1a" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">3.点击<em class="ll">应用</em></p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mi"><img src="../Images/dec083ae43ef38e11105fefa6c283b86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*i8Bbcoz-g0-8eP4f.gif"/></div></div><figcaption class="mj mk et er es ml mm bd b be z dx translated">YOLO数据集加载和可视化</figcaption></figure><h1 id="6c56" class="kv ix hh bd iy kw kx ky jc kz la lb jg in lc io jk iq ld ir jo it le iu js lf bi translated">3-设置YOLO火车插件</h1><p id="8783" class="pw-post-body-paragraph jv jw hh jx b jy jz ii ka kb kc il kd jh ke kf kg jl kh ki kj jp kk kl km kn ha bi translated">此时，我们已经准备好将YOLO培训作业添加到工作流中:所以在过程库中搜索新安装的插件(左窗格)。</p><p id="0dce" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">在开始我们的培训之前，我们需要挖掘可用的参数。</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div class="er es mx"><img src="../Images/fd02be03afde4c28a7d607d2fd9610cc.png" data-original-src="https://miro.medium.com/v2/resize:fit:592/format:webp/0*HxY8f3_SBebcDcl_.jpg"/></div></figure><p id="aa43" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated"><strong class="jx hi">模型选择</strong> : <em class="ll"> darknet </em> <em class="ll">框架</em>提供不同的深度学习架构。因此，我们必须选择模型来训练我们的葡萄检测。由于我们想进行快速有效的训练，我们选择了微型YOLOv4。显然，您可以自由选择列表中的任何一个。</p><p id="8eca" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated"><strong class="jx hi">输入尺寸</strong>:必须是32的倍数。更高的输入分辨率意味着更高的精度，但会占用更多内存。您必须根据您的GPU内存能力来设置输入大小。</p><p id="7762" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated"><strong class="jx hi">训练/评估分割比</strong>:插件自动将数据集分为训练和评估子集。值0.9表示90%的数据用于训练，10%用于评估。</p><p id="8710" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated"><strong class="jx hi">超参数</strong>:驱动优化过程的公共参数。更多信息请咨询<a class="ae ju" href="https://github.com/AlexeyAB/darknet" rel="noopener ugc nofollow" target="_blank">官方知识库</a>。</p><p id="d370" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated"><strong class="jx hi">自动配置</strong>:在<em class="ll">暗网</em> <em class="ll">框架</em>中的培训工作基于配置文件。因此，该功能会根据最佳实践自动生成配置文件。此外，对于想要完全控制的专家，可以禁用自动配置。然后是有效的配置文件(。cfg)必须设置。</p><p id="ffd5" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated"><strong class="jx hi">输出文件夹</strong>:包含训练作业中生成的所有文件以及推理时需要的所有文件。</p><h1 id="aeec" class="kv ix hh bd iy kw kx ky jc kz la lb jg in lc io jk iq ld ir jo it le iu js lf bi translated">4-开始训练</h1><p id="5f40" class="pw-post-body-paragraph jv jw hh jx b jy jz ii ka kb kc il kd jh ke kf kg jl kh ki kj jp kk kl km kn ha bi translated">现在，按下<em class="ll">应用</em>按钮，将"<em class="ll"> train_yolo" </em>任务添加到当前工作流程中。</p><p id="5e27" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">培训过程立即开始。得益于MLflow的无缝集成，您可以实时监控训练进度。平均精度和损失值等参数和指标会自动报告，并可通过MLflow仪表盘查看。</p><p id="7279" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">请查看以下结果，这些结果是在输入尺寸为608像素且所有其他参数设置为默认值的小型YOLOv4模型上运行时获得的:</p><ul class=""><li id="a5ac" class="lt lu hh jx b jy lg kb lh jh lv jl lw jp lx kn ly lz ma mb bi translated">平均精度(mAP@0.5): 85.9%</li><li id="2d3d" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">最小损失值:2.99</li><li id="4aeb" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">时代数:2000</li><li id="34ed" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">培训时间:30分钟(单个GPU —英伟达GTX 1060)</li><li id="2f62" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">模型大小:22.4兆字节</li></ul><p id="346a" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">最后，Ikomia STUDIO给你几个选择:</p><ul class=""><li id="2c0e" class="lt lu hh jx b jy lg kb lh jh lv jl lw jp lx kn ly lz ma mb bi translated">修改训练参数以开始新的跑步和比较</li><li id="b340" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">保存当前工作流以备将来培训</li></ul><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es mi"><img src="../Images/d927a2034b7b911d70fd231c62160c20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1c8aqMF9Rl8qQh8b.gif"/></div></div><figcaption class="mj mk et er es ml mm bd b be z dx translated">YOLO模型的训练过程</figcaption></figure><h1 id="0814" class="kv ix hh bd iy kw kx ky jc kz la lb jg in lc io jk iq ld ir jo it le iu js lf bi translated">测试您的定制训练模型</h1><p id="8202" class="pw-post-body-paragraph jv jw hh jx b jy jz ii ka kb kc il kd jh ke kf kg jl kh ki kj jp kk kl km kn ha bi translated">一旦您的定制模型被训练，您可以很容易地在Ikomia STUDIO中测试它。关闭之前的培训工作流程，并遵循以下步骤:</p><ol class=""><li id="51e6" class="lt lu hh jx b jy lg kb lh jh lv jl lw jp lx kn mw lz ma mb bi translated">从Ikomia STUDIO打开中枢</li><li id="5214" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn mw lz ma mb bi translated">搜索"<strong class="jx hi"><em class="ll">infer _ yolo _ v4 "</em></strong>插件并安装</li><li id="9adb" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn mw lz ma mb bi translated">打开grapes图像</li><li id="4b1f" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn mw lz ma mb bi translated">在工艺库中选择新安装的"<strong class="jx hi"><em class="ll">【infer _ yolo _ v4】</em></strong>(左窗格)</li><li id="4825" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn mw lz ma mb bi translated">填充参数:</li></ol><ul class=""><li id="f51b" class="lt lu hh jx b jy lg kb lh jh lv jl lw jp lx kn ly lz ma mb bi translated">输入大小:必须是32的倍数(可以不同于训练输入分辨率)</li><li id="6c2d" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">型号:和训练用的一样(我们用的是小YOLOv4)</li><li id="35c8" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">培训内容:定制</li><li id="9c4e" class="lt lu hh jx b jy mc kb md jh me jl mf jp mg kn ly lz ma mb bi translated">训练过程中生成的配置、权重和标签文件(默认文件夹:<em class="ll">user-folder/Ikomia/Plugins/c++/infer _ yolo _ v4/data/models/</em>)</li></ul><p id="63c8" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">6.按下<em class="ll">应用</em></p><p id="e9ca" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">7.尽情享受吧！</p><figure class="ko kp kq kr fd ks er es paragraph-image"><div role="button" tabindex="0" class="ln lo di lp bf lq"><div class="er es lm"><img src="../Images/858a500cd8ea46e166d022ca104d02fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*TIHa0d3lMz7f6Yu0.jpg"/></div></div><figcaption class="mj mk et er es ml mm bd b be z dx translated">用TinyYOLOv4检测葡萄</figcaption></figure><h1 id="ea51" class="kv ix hh bd iy kw kx ky jc kz la lb jg in lc io jk iq ld ir jo it le iu js lf bi translated">结论</h1><p id="79dc" class="pw-post-body-paragraph jv jw hh jx b jy jz ii ka kb kc il kd jh ke kf kg jl kh ki kj jp kk kl km kn ha bi translated">我希望你会喜欢Ikomia工作室的简单。没有更多的时间浪费在训练自定义对象检测模型，如YOLO。你可能会在<a class="ae ju" href="https://github.com/Ikomia-hub" rel="noopener ugc nofollow" target="_blank"> Ikomia HUB </a>中找到其他有趣的算法。因此，请随意查看并发现它们。</p><p id="fd2c" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">[1] T. T. Santos，L. L. de Souza，A. A. dos Santos，S. Avila，<a class="ae ju" href="https://arxiv.org/abs/1907.11819v3" rel="noopener ugc nofollow" target="_blank"> <em class="ll">利用深度神经网络和三维关联进行葡萄检测、分割和跟踪</em> </a> (2020)，计算机和电子在农业中的应用</p><p id="c201" class="pw-post-body-paragraph jv jw hh jx b jy lg ii ka kb lh il kd jh li kf kg jl lj ki kj jp lk kl km kn ha bi translated">[2] A. Bochkovskiy，C-y .-y . m .廖，<a class="ae ju" href="https://arxiv.org/abs/2004.10934" rel="noopener ugc nofollow" target="_blank"> YOLOv4:物体探测的最佳速度和精度</a> (2020)</p></div></div>    
</body>
</html>