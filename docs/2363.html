<html>
<head>
<title>Lane detection for a self-driving car using OpenCV</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于OpenCV的自动驾驶汽车车道检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/lane-detection-for-a-self-driving-car-using-opencv-e2aa95105b89?source=collection_archive---------4-----------------------#2021-04-20">https://medium.com/analytics-vidhya/lane-detection-for-a-self-driving-car-using-opencv-e2aa95105b89?source=collection_archive---------4-----------------------#2021-04-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="8a0a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于那些想知道如何在一篇文章中涵盖这一概念的人，我要说，事情听起来很复杂，直到你探索了它的深度。我不会说这篇文章会非常容易，但的确，它将建立在非常基本的计算机视觉概念之上。请不要假设这正是特斯拉将在他们的汽车上使用，但它可能是类似的东西。</p><p id="bf1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">先决条件是什么？</strong>了解一些OpenCV的基础知识会比较好。如果没有，不要担心，我会试着解释我将使用的OpenCV函数，并提供参考资料让你更详细地检查它们。</p><p id="a930" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">本文的每一节都将涵盖一个最终将在程序的主要部分使用的函数。此外，在本文中，我将使用图像演示一切。您可以在视频中重用相同的代码(因为视频只是图像的集合)。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/2f3bbac81475d365cb2415e8637b94d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E3BuOdElSbg4nIb09P_CTA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">我将在本文中使用的图像</figcaption></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="9c28" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">步骤1:边缘检测</h1><p id="05b1" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">我们将使用精明的边缘检测。如果你不确定这是什么，看看我的<a class="ae lc" rel="noopener" href="/analytics-vidhya/image-simplification-through-binarization-in-opencv-1292d91cae12">以前的文章</a>，它以一种实用的方式解释了这一点。</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="af19" class="li ka hh le b fi lj lk l ll lm">def canyEdgeDetector(image):<br/>    edged = cv2.Canny(image, 50, 150)<br/>    return edged</span></pre><p id="455a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是我们应用canny边缘检测后的输出</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ln"><img src="../Images/947e8d915b9af696d17668b21b993fd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2YGV_7Ov8a9JeolJnUA0rA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">Canny边缘检测后的输出</figcaption></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="4c9d" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">步骤2:定义ROI(感兴趣的区域)</h1><p id="9f4a" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">开车时，为了让车保持在车道上，你只需关注当前道路的下一个100米。还有，你根本不关心分割线另一边的路。这就是我们感兴趣的<em class="lo">地区</em>。我们隐藏了图像中不必要的细节，只显示有助于我们找到车道的区域。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lp"><img src="../Images/176330a66ccd0aa674203ba527d357e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uffjcrzYap__4dd7M6oVAg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">红色三角形表示我们感兴趣的区域</figcaption></figure><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="5ff5" class="li ka hh le b fi lj lk l ll lm">def getROI(image):<br/>    height = image.shape[0]<br/>    width = image.shape[1]<br/>    # Defining Triangular ROI: The values will change as per your camera mounts<br/>    triangle = np.array([[(100, height), (width, height), (width-500, int(height/1.9))]])<br/>    # creating black image same as that of input image<br/>    black_image = np.zeros_like(image)<br/>    # Put the Triangular shape on top of our Black image to create a mask<br/>    mask = cv2.fillPoly(black_image, triangle, 255)<br/>    # applying mask on original image<br/>    masked_image = cv2.bitwise_and(image, mask)<br/>    return masked_image</span></pre><ol class=""><li id="6efa" class="lq lr hh ig b ih ii il im ip ls it lt ix lu jb lv lw lx ly bi translated">我们已经定义了三角形ROI，其坐标将根据您在汽车上安装摄像机的位置而变化(尽量只保留图像中实际有助于车道检测的部分)。</li><li id="7152" class="lq lr hh ig b ih lz il ma ip mb it mc ix md jb lv lw lx ly bi translated">我们创建了一个与原始图像形状相同的黑色图像:</li></ol><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es me"><img src="../Images/c0cda82fbe75787904d55b6ac83f0147.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1E4GQp1tOdfqfoifDnyQtw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">创建与原始图像形状相同的黑色图像</figcaption></figure><p id="9633" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.<strong class="ig hi">创建一个蒙版:</strong>然后我们使用<em class="lo"> cv2.fillPoly() </em>将我们的三角形(带有白色线条)放在我们的黑色图像上来创建一个蒙版。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mf"><img src="../Images/837f8d2bfd839a34bc49f95e8212f479.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*bDFHGLoRrswBkRrvAIfSIQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">创建一个遮罩</figcaption></figure><p id="8c63" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.在我们的原始图像上应用蒙版，得到只包含我们感兴趣区域的裁剪图像。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mg"><img src="../Images/5373890ac851d9bdb623b350db9d3604.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eejLU4rD-LU7RGdhXwZy7Q.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">原始图像+蒙版=带ROI的最终图像</figcaption></figure><p id="e110" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这一步的输出类似于:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lp"><img src="../Images/843635e7b4aa12164c98a1acdc18e30f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nXxjhojr01VdNRpxoy61Xw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">getROI()后的输出</figcaption></figure><blockquote class="mh mi mj"><p id="ad8c" class="ie if lo ig b ih ii ij ik il im in io mk iq ir is ml iu iv iw mm iy iz ja jb ha bi translated">在获得ROI之前应用边缘检测是很重要的，否则边缘检测也会检测我们的ROI的边界。</p></blockquote></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="1a6f" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">第三步:排队</h1><p id="97ae" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">下一步将是通过ROI获得图像中的所有直线。<em class="lo"> cv2。HoughLinesP() </em>帮助你实现这一点。这个函数返回它能在输入图像中找到的所有直线的列表。每条线由[x1，y1，x2，y2]表示。</p><p id="7dab" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，这可能看起来非常简单，但霍夫线检测的基本工作原理需要一点时间来解释。所以我不会在这篇文章中涉及它。相反，我建议你看一下<a class="ae lc" href="https://www.youtube.com/watch?v=7m-RVJ6ABsY" rel="noopener ugc nofollow" target="_blank">这个教程</a>(28、#29、#30应该足以理解霍夫线条原理)。</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="6cff" class="li ka hh le b fi lj lk l ll lm">def getLines(image):<br/>    lines = cv2.HoughLinesP(image, 0.3, np.pi/180, 100, np.array([]), minLineLength=70, maxLineGap=20)<br/>    return lines</span></pre><p id="53a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">cv2的参数。HoughLinesP()必须根据您的需求进行调整(尝试更改和调试最适合您的方法)。但是我认为上面的那些应该在大多数情况下都管用。这一步的输出如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mg"><img src="../Images/cb15b1209693bc01f9c82d715c2bb2a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zelUwhKEkek6LONCMigPRw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">在图像中检测到3条线。在您的图像中可能会检测到数百条线。因此，调整您的参数以获得尽可能少的行数</figcaption></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="a6c5" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">步骤4:一些实用函数</h1><p id="4883" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">下面的实用函数获取图像和线条列表，并在图像上绘制线条。(此步骤不接受来自步骤3的任何输入。相反，这只是一个从步骤5调用的实用程序步骤，因此您可以先查看步骤5，并在需要时访问该步骤。</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="b1bc" class="li ka hh le b fi lj lk l ll lm">def displayLines(image, lines):<br/>    if lines is not None:<br/>        for line in lines:<br/>            x1, y1, x2, y2 = line.reshape(4) #converting to 1d array<br/>            cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 10)<br/>    return image</span></pre><p id="fd44" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们定义了另一个效用函数来从它的参数(斜率和截距)中获取线坐标。请记住，直线由<em class="lo"> y=mx+c </em>表示，其中m是斜率，c是截距。</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="c221" class="li ka hh le b fi lj lk l ll lm">def getLineCoordinatesFromParameters(image, line_parameters):<br/>    slope = line_parameters[0]<br/>    intercept = line_parameters[1]<br/>    y1 = image.shape[0]  # since line will always start from bottom of image<br/>    y2 = int(y1 * (3.4 / 5))  # some random point at 3/5<br/>    x1 = int((y1 - intercept) / slope)<br/>    x2 = int((y2 - intercept) / slope)<br/>    return np.array([x1, y1, x2, y2])</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mn"><img src="../Images/e4e1bf72baabf4f0e8da6c00cb4e328e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TlowOsXP_8K2TLDFe3AFcg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">注意我们是如何选择y1和y2的值的</figcaption></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="f565" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated"><strong class="ak">第五步:获得平滑线</strong></h1><p id="494f" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">一旦我们从步骤3中获得了线条，在这一步中，我们将这些线条分成2组(左和右)。如果您注意到步骤3的输出图像，该步骤会将Line1和Line 2放入<em class="lo">左组</em>中，将Line3放入<em class="lo">右组</em>中。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mo"><img src="../Images/5e699797c8b8985b5a8e92a1d0b9b6bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:754/format:webp/1*FaBe4GOSyIyoLc48XZ55_Q.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">如何获得车道左右侧的公共线</figcaption></figure><p id="5dfc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">分组后，我们找到该组的平均斜率(m)和截距(c ),并尝试通过调用getLineCoordinatesFromParameters()并传递average m和average c为每个组创建一条线。</p><p id="b3a0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是完成所有这些工作的函数:</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="9326" class="li ka hh le b fi lj lk l ll lm">def getSmoothLines(image, lines):<br/>    left_fit = []  # will hold m,c parameters for left side lines<br/>    right_fit = []  # will hold m,c parameters for right side lines<br/><br/>    for line in lines:<br/>        x1, y1, x2, y2 = line.reshape(4)<br/>        parameters = np.polyfit((x1, x2), (y1, y2), 1)<br/>        slope = parameters[0]<br/>        intercept = parameters[1]<br/><br/>        if slope &lt; 0:<br/>            left_fit.append((slope, intercept))<br/>        else:<br/>            right_fit.append((slope, intercept))<br/><br/>    left_fit_average = np.average(left_fit, axis=0)<br/>    right_fit_average = np.average(right_fit, axis=0)<br/><br/>    # now we have got m,c parameters for left and right line, we need to know x1,y1 x2,y2 parameters<br/>    left_line = getLineCoordinatesFromParameters(image, left_fit_average)<br/>    right_line = getLineCoordinatesFromParameters(image, right_fit_average)<br/>    return np.array([left_line, right_line])</span></pre><p id="4b6d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是线条分组后的图像外观:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lp"><img src="../Images/dc6b85423e4df0c5743ebd479e854b00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VT72TaYU7cuEI7o5Nn8ujQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">行分组后的输出</figcaption></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="3e9a" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">主代码(逐个调用上面的步骤)</h1><p id="20b3" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">一旦我们准备好了单独的函数，我们只需要在我们的主代码中调用它们，你就会在你的图像中检测到车道。</p><pre class="jd je jf jg fd ld le lf lg aw lh bi"><span id="8d00" class="li ka hh le b fi lj lk l ll lm">image = cv2.imread("3.jpg") #Load Image<br/><br/>edged_image = canyEdgeDetector(image)   # Step 1<br/>roi_image = getROI(edged_image)         # Step 2<br/><br/>lines = getLines(roi_image)             # Step 3<br/><br/>smooth_lines = getSmoothLines(image, lines)    # Step 5<br/>image_with_smooth_lines = displayLines(image, smooth_lines) # Step 4<br/><br/>cv2.imshow("Output", image_with_smooth_lines)<br/>cv2.waitKey(0)</span></pre><p id="b3cb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出将如下所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mp"><img src="../Images/9078d10f2690bff9b0ec3745eaf3a626.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*56_Mzzdq-wNkaPsIp0IUjg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">确定车道的最终输出</figcaption></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="ffb0" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">最后的话</h1><p id="6889" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">你坚持到了文章的结尾。一旦事情被分类并且对图像工作良好，你知道如何让它在视频上工作。你可能已经意识到如何巧妙地使用非常基本的计算机视觉操作来实现如此有用的东西。我还是要说，不要试图将这项工作与特斯拉等更大的公司所做的工作进行比较(他们的基础也是类似的)。相反，用这个作为动力，也许在某个时候，你能够实现类似的事情。</p><p id="b4fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在此之前，请继续探索:)您可以在这里查看本文的Github源代码的链接。</p><p id="2735" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="lo">在视频上检测车道后的样本输出(由于视频记录器的原因，帧很慢):</em></p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mq mr l"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">检测视频中的车道</figcaption></figure></div></div>    
</body>
</html>