<html>
<head>
<title>A primer of Entropy, Information and KL Divergence</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">熵、信息和KL散度入门</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-primer-of-entropy-information-and-kl-divergence-42290791398f?source=collection_archive---------19-----------------------#2021-01-10">https://medium.com/analytics-vidhya/a-primer-of-entropy-information-and-kl-divergence-42290791398f?source=collection_archive---------19-----------------------#2021-01-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="5ab9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">直观地了解机器学习的三个重要的相关概念:信息、熵和Kullback-Leibler散度。</p><h1 id="4459" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">简介:如何测量分布？</h1><p id="91f1" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">在我们深入探讨什么是熵、信息和KL散度之前，我们必须首先理解这些术语的必要性以及它们解决了什么问题。</p><p id="ba40" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我们的基础统计/数学课程中，我们遇到了许多不同的分布。其中一些是:高斯，伯努利，贝塔等。概率密度函数(p.d.f .)或概率质量函数(p.m.f .)因分布而异。我们说两种分布相等当且仅当。两者都具有完全相同的概率密度函数或概率平均函数。现在问题来了，如果两个概率分布不同，如何测量两者之间的差异？考虑下面的例子:</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kf"><img src="../Images/a015c74b498c463308c6c9061a351db2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eKhDl6FJcXyNHq_9o-j4cQ.png"/></div></div></figure><p id="6306" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们有3个发行版。我们可以定性地说，分布2比分布3更类似于分布1。这只是一个定性的估计，我们仍然无法回答“一个分布与另一个分布有多相似/不同？”。我们在这里寻找的是一个数字量，它可以定义一个分布与另一个分布有多大的不同。</p><p id="5fb7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">事实证明，有很多方法可以发现一个发行版与另一个发行版的不同之处。一些读者可能会想“衡量差异的最佳方式是什么”？事实证明，没有既定的“最佳”方法，最终都归结于它所应用的问题。在这篇文章中，我们探索了其中的一种方式:Kullback -Leiblier分歧。在我们继续讨论这个听起来奇怪的术语是什么之前，我们需要理解两个基本术语:<strong class="ig hi">熵</strong>和<strong class="ig hi">信息</strong>。</p><h1 id="83f5" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">分布的熵</h1><p id="404d" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">早在香农将熵这个术语用于压缩之前，它就已经被用于物理科学了。物理系统中熵的定义如下:</p><blockquote class="kr ks kt"><p id="4887" class="ie if ku ig b ih ii ij ik il im in io kv iq ir is kw iu iv iw kx iy iz ja jb ha bi translated">熵是系统随机性的一种度量。系统越随机，系统的熵就越大。</p></blockquote><p id="cad2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">与概率相似，分布的熵随着随机性的增加而增加。为了更好地理解它，让我们举一个例子:</p><p id="dbbe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有两种硬币:</p><p id="cc5d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">硬币1:正面概率= 0.9的偏向硬币</p><p id="1f00" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">硬币2:无偏硬币(正面概率= 0.5)</p><p id="f2e8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">投掷硬币1的结果比投掷硬币2的结果更容易预测。换一种说法:<strong class="ig hi">抛硬币2的结果不如抛硬币1的结果随机。因为投掷硬币2给出更随机的结果，所以与投掷硬币2相关联的分布具有更大的熵。</strong></p><p id="e8d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了更好地理解熵，我们需要理解信息内容。</p><h1 id="c111" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated"><strong class="ak">事件的信息内容</strong></h1><p id="54fb" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">信息可以被认为是事件的惊奇程度。如果我们被告知一个极不可能(更有趣)的事件刚刚发生，我们会比被告知某个非常可能的事件刚刚发生时收到更多的信息，而如果我们知道该事件肯定会发生，我们就不会收到任何信息。</p><p id="b7f5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">事件的信息取决于事件的概率。如果事件发生的概率较大，即发生的几率较高，则传达的信息会较低。将信息与随机性联系起来似乎有点荒谬，因此让我们举一个简单的例子来帮助我们更好地理解:</p><p id="5a0c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有两个事件:</p><p id="1c1f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">事件一:“太阳从东方升起。”</p><p id="e689" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">事件2:“XYZ公司的股票价值急剧上升。”</p><p id="a524" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">事件1是普遍真理。读者非常确定事件将会发生，告诉读者他已经预期/知道的事情是没有意义的。所以事件1据说具有非常低/零的信息。另一方面，事件2不是很可能发生的事件，它的发生可能会让一些人感到惊讶(尤其是那些预期价格会下跌的人)。所以这个事件有更高的信息含量。</p><p id="ecc3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ku">注:</em> </strong>信息是为一个事件定义的。熵是为分布定义的。</p><h1 id="3a50" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">信息的熵</h1><p id="8d8d" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">我们已经为分布中的特定事件定义了信息。由于信息是对事件随机性的一种度量，关于分布中所有事件的知识给了我们一个分布随机性的概念。因此，熵也可以定义为分布的预期信息内容。</p><p id="7c80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">现在我们来看信息的数学表达:</strong></p><p id="9e7f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们考虑一个离散变量x，它可以取n个不同的值。</p><p id="e2a0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这些值的概率由p(x)定义。</p><p id="e1aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">观察一个事件所提供的信息由h(x)给出。</p><p id="104c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">h()的形式可以通过注意到如果我们有两个不相关的事件x和y，那么从观察这两个事件得到的信息增益应该是分别从它们中的每一个得到的信息之和，所以h(x，y) = h(x) + h(y)。两个不相关的事件在统计上是独立的，所以p(x，y) = p(x)p(y)。根据这两个关系，很容易证明h(x)必须由p(x)的对数给出</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ky"><img src="../Images/b1a5017ca8230f857ad2ed4c58c9ac0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1254/format:webp/1*e5qI3QE3XXDnzqr1gzzmlQ.png"/></div></figure><p id="f02f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">分布的熵可以写成:</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es kz"><img src="../Images/7a2f77e26340bf66c188ce83dfa4050e.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/format:webp/1*BRBQr9SB-XJUvsSMPu0lSA.png"/></div></figure><p id="dd35" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们以骰子为例，</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es la"><img src="../Images/640256bdc26043fbd74e089cce557fb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*bMSIT3mVjlhUKnDFbJuy9w.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">掷骰子的熵</figcaption></figure><p id="7701" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个结果可以推广到连续分布:</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lf"><img src="../Images/d0eb3b43332c4f7f17abd31319e1bfc1.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/format:webp/1*TyKCKJ0zRD85nrRsx8mDJg.png"/></div><figcaption class="lb lc et er es ld le bd b be z dx translated">p(x)的自熵</figcaption></figure><h1 id="9041" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">库尔贝克-莱布利尔散度</h1><p id="7524" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">在机器学习中，我们会遇到许多问题，其中给定了具有特定目标分布的数据，我们必须训练模型，以使我们的模型接近给定数据的相似分布。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lg"><img src="../Images/df454a9c5ce57bd574942200bb289c3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FDK2YwJU51VlEA6zI7K2Vg.jpeg"/></div></div><figcaption class="lb lc et er es ld le bd b be z dx translated">以下是来自MNIST数据集的示例，显示了数据和目标标签分布。</figcaption></figure><p id="80e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">目标/实际分布的概率:p(x)和模拟分布的概率:q(x)。我们注意到，尽管预测的分布是q(x ),但原始分布仍然是p(x)。因此，q(x)相对于p(x)的熵由下式给出:</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lh"><img src="../Images/ce96e69a064c7d1f287e7ba085736a8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:722/format:webp/1*YADUTW9WkRCGVc-HIOh5Fw.png"/></div></figure><p id="a2ac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这也称为q(x)相对于p(x)的相对熵。现在要找出相对熵和实际熵的区别:</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es li"><img src="../Images/6e61e8367e98c8256e7754b3403d792f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*rJl8VzeMB8SPYpua1gcArQ.png"/></div></figure><p id="9c86" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这叫做q(x)相对于p(x)的KL散度。我们可以看到，这是一个量化术语，用来回答支持度相同的分布与支持度不同的分布有多大。</p><p id="db2c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">注意:Kullback-Leiblier散度是不对称的，即一般情况下<strong class="ig hi"> KL </strong> (p(x)||q(x))不等于<strong class="ig hi"> KL </strong> (q(x)||p(x))。</p></div></div>    
</body>
</html>