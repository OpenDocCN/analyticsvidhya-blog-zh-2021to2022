<html>
<head>
<title>How to scrape all types of websites with python — part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用python抓取所有类型的网站—第2部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-scrape-all-types-of-websites-with-python-part-2-7014c614f8d?source=collection_archive---------1-----------------------#2021-08-10">https://medium.com/analytics-vidhya/how-to-scrape-all-types-of-websites-with-python-part-2-7014c614f8d?source=collection_archive---------1-----------------------#2021-08-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="e9e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">关于我如何用scrappy和splash刮了19000个中等帖子的综合指南。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/a885244df198d32746b04cb84cab36fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*PmHwN5WovermAzxf"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">照片由<a class="ae js" href="https://unsplash.com/@nate_dumlao?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">内森·杜姆劳</a>在<a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="ef78" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><a class="ae js" href="https://kuleafenu.medium.com/how-to-scrape-all-types-of-websites-with-python-part-1-552aafd93884" rel="noopener"> <strong class="ig hi">在上一篇文章(本教程的第1部分)</strong> </a>中，我们学习了如何为这个项目设置环境。我们下载并安装了Anaconda navigator、Scrapy、Docker和Splash。</p><p id="f796" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你已经安装了这些设置，瞧！否则，请花几分钟时间浏览一下<a class="ae js" href="https://kuleafenu.medium.com/how-to-scrape-all-types-of-websites-with-python-part-1-552aafd93884" rel="noopener"> <strong class="ig hi">之前关于环境设置的帖子</strong> </a>。</p><p id="2448" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们开始吧！！</p><p id="675b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">项目目标:</strong>从《走向数据科学》刮出数千篇中型文章</p><p id="412b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">要学的东西</strong></p><ol class=""><li id="eca3" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb jy jz ka kb bi translated">学习如何用VS代码编程</li><li id="6ad2" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">编写Splash脚本</li><li id="80d6" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">用Scrapy提取图案</li><li id="18f9" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">以CSV、JSON和XML格式存储数据</li></ol></div><div class="ab cl kh ki go kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="ha hb hc hd he"><h1 id="bb09" class="ko kp hh bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated"><strong class="ak">创建新项目</strong></h1><p id="a89b" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">a.启动anaconda navigator并点击<code class="du lr ls lt lu b">environment</code></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lv"><img src="../Images/bc4999b181c3c34fcfdfa3c84e5aea38.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eJ7H-2upWTWjqJNc-_3nrQ.png"/></div></div></figure><p id="2aec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">b.点击我们在上一个教程中创建的右边环境的play按钮，在我的例子中是<code class="du lr ls lt lu b">web_scraping_project</code>并运行终端</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lw"><img src="../Images/a8ec7bde76c0052d217f27d53684b2f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AjD1wsbDuiJGk57oEeJ76w.png"/></div></div></figure><p id="3e6f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">c.用<code class="du lr ls lt lu b">mkdir</code>创建一个新目录，然后将该目录更改为用<code class="du lr ls lt lu b">cd</code>【目录名】创建的新目录。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lx"><img src="../Images/ede5d8c09f528c1a37b0049955eb3962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ln9_rmx79s1rjxNm8XgxLw.png"/></div></div></figure><p id="78c3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">d.用Scrapy命令<code class="du lr ls lt lu b"> scrapy</code>创建一个新项目<code class="du lr ls lt lu b">startproject [project_name].</code></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ly"><img src="../Images/19f44c2fb9ad097bf63e84bfb96ed6f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K_uP0q90yMETox554EL91w.png"/></div></div></figure><p id="2b21" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">e.在你的桌面上打开文件夹<code class="du lr ls lt lu b">medium_splash </code>，你会看到以下文件和子文件夹。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lz"><img src="../Images/08dc2eca33981d926eed6b40fb5609ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KYPluLdQhZYxQP1B10NRHg.png"/></div></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ma"><img src="../Images/d1258a24d2dd8e200b5fd334e535a37a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2DUr2zhTGXrXqQYcECzMSg.png"/></div></div></figure><p id="9eb1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">让我们了解一些关于各种文件的事情</strong></p><p id="60f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这有助于我们部署蜘蛛。</p><p id="5976" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个文件夹是我们编写蜘蛛脚本的地方。</p><p id="abd2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lu b">items.py</code>用于存储我们将要创建的一些字段中的抓取数据。</p><p id="d4db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lu b">middlewares.py</code>这是负责请求和响应的对象。别担心，我们会一路了解这两个物体。</p><p id="4a57" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lu b">pipelines.py</code>我们用它来存储我们在数据库中抓取的项目。</p><p id="451b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以在这里配置我们的项目设置。</p><p id="4724" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">f.将目录切换到项目文件夹，用<br/> <code class="du lr ls lt lu b">scrapy genspider [spider_name] [page_link]</code> <br/> <code class="du lr ls lt lu b">spider_name</code>生成我们的蜘蛛，蜘蛛名称是我的案例<code class="du lr ls lt lu b">md</code>。<br/> <code class="du lr ls lt lu b">page_link</code>是对页面的链接进行抓取。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ly"><img src="../Images/45f4a28b4a32e3a9710eb4ecbc389457.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E9TtAc_T8ilbxgBkomrs8g.png"/></div></div></figure><p id="6d17" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">g.安装scrapy-splash软件包。这使我们能够从Scrapy脚本发送splash请求。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mc"><img src="../Images/a195795b586f5662c4017c9ce226a61d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KXF065oQeUe-bNH7UUhS6Q.png"/></div></div></figure><p id="58ea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">h.启动anaconda navigator并运行VS代码。如果你启动anaconda navigator，而不是你看到install的<em class="mb"> launch </em>按钮，点击它来<em class="mb"> install </em>它，然后你启动它。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es md"><img src="../Images/1f4ced994c5a2bee7a1020e9a9fb85db.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ys3g6U9pnqybzAhVXk4ZCQ.png"/></div></div></figure><p id="f9a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一、点击<em class="mb">打开文件夹</em>，导航到您的项目目录，选择我们创建的文件夹，如果您继续操作，那么您必须选择名为<code class="du lr ls lt lu b"><em class="mb">medium_splash</em></code> <em class="mb">的文件夹。</em></p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es me"><img src="../Images/13f126b1f0358369a447777732dac3e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*znBc9WPXvVpA_WxKzT5CXg.png"/></div></div></figure><p id="1890" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">j.该项目应该打开如下，我们目前在<em class="mb">蜘蛛&gt; md.py </em>文件。这是我们写所有代码的地方。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mf"><img src="../Images/a9ec19bb8e604f2a465f6391b2a7230b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_RJmblcdZg3YEwhBWrkrAQ.png"/></div></div></figure><p id="124b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们已经成功地创建了一个新项目，并在VS代码中启动了它。</p></div><div class="ab cl kh ki go kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="ha hb hc hd he"><p id="6a0b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本节中，我们将学习:</p><ul class=""><li id="eeba" class="jt ju hh ig b ih ii il im ip jv it jw ix jx jb mg jz ka kb bi translated">如何配置我们的项目设置？</li><li id="5884" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb mg jz ka kb bi translated">编写我们的报废脚本</li><li id="899f" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb mg jz ka kb bi translated">运行它来提取我们的数据集。</li></ul><p id="b6be" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">a.打开<em class="mb"> settings.py </em>文件</p><p id="3808" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是一个被许多网站用来拒绝访问Scrapy的文件。</p><p id="4646" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">改变:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="cc14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">收件人:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="0639" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">b.如果检测到Scrapy的默认用户代理，一些网站会迅速阻止你访问他们的网站。所以改成你的浏览器用户代理。</p><p id="bc44" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你只要在谷歌搜索<code class="du lr ls lt lu b"><em class="mb">my user agent</em></code>就可以知道你的用户代理。<br/> <em class="mb">记得换成自己的用户代理</em></p><p id="2d39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">改变:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="2c82" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">收件人:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="6a43" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">c.这些改动可以在<a class="ae js" href="https://github.com/scrapy-plugins/scrapy-splash" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">官方Scrapy-splash GitHub资源库</strong> </a> <strong class="ig hi">中找到。我鼓励你去看看。</strong></p><p id="f8d2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">改变:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="3f0a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">收件人:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="3ec3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">改变:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="e71f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">收件人:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="4902" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">d.在<em class="mb"> setting.py </em>文件的基础上添加以下脚本，最后保存。</p><pre class="jd je jf jg fd mj lu mk ml aw mm bi"><span id="a759" class="mn kp hh lu b fi mo mp l mq mr">SPLASH_URL = 'http://localhost:8050'</span></pre><p id="3a39" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是URL，端口splash将在浏览器中打开。</p></div><div class="ab cl kh ki go kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="ha hb hc hd he"><h1 id="80e6" class="ko kp hh bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">编写我们的代码</h1><p id="7e19" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">a.在蜘蛛文件夹内打开蜘蛛文件，在我们的<code class="du lr ls lt lu b"> md.py</code></p><p id="1124" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">默认情况下，我们已经有:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="596e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将导入scrapy_splash库</p><pre class="jd je jf jg fd mj lu mk ml aw mm bi"><span id="6716" class="mn kp hh lu b fi mo mp l mq mr">from scrapy_splash import SplashRequest</span></pre><p id="524b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当你查看“朝向数据科学”的主要档案时</p><pre class="jd je jf jg fd mj lu mk ml aw mm bi"><span id="cfc9" class="mn kp hh lu b fi mo mp l mq mr"><a class="ae js" href="https://towardsdatascience.com/archive" rel="noopener" target="_blank">https://towardsdatascience.com/archive</a></span></pre><p id="1369" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以看到每一页都包含一个文章列表，也可以通过添加年、月、日作为<code class="du lr ls lt lu b"><a class="ae js" href="https://towardsdatascience.com/archive" rel="noopener" target="_blank">https://towardsdatascience.com/archive</a>/2020/01/01</code>来访问</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es ms"><img src="../Images/01fafee3ec47a3f1bc8c231bea07013a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0lqDKyfnhLgzlwoRkNtYxA.png"/></div></div></figure><p id="c0f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">b.因此，让我们生成所有的主页链接，如下所示</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="c6d1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">c.当你运行一个蜘蛛时，Scrapy会搜索两个函数，<code class="du lr ls lt lu b">start_requests</code>和<code class="du lr ls lt lu b">parse</code>函数。</p><p id="cccb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们来创造它们</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="dd27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="mb">第1–26行是splash代码。对此的解释已经作为评论注入其中。</em></p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="c4f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lu b"><a class="ae js" href="https://www.w3.org/TR/xpath/all/" rel="noopener ugc nofollow" target="_blank">XPath</a></code>是一种在XML文档中选择节点的语言，也可以和HTML一起使用。</p><p id="d2f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模式<code class="du lr ls lt lu b"> .//div[@class=’postArticle-readMore’]/a/@href</code>基本上是页面上列出的每篇文章的链接路径。这个路径可以通过使用开发者工具<em class="mb"> ( ctrl +shift +i) </em>命令得知。</p><p id="7c62" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我强烈推荐你在这里做一个关于如何使用XPath和CSS选择器的快速参考。T15】</p><p id="aa37" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">d.我们将创建一个函数，从splash脚本返回的HTML响应中提取我们的项目。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure><p id="3b81" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">把所有东西放在一起；脚本应该是这样的。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="mh mi l"/></div></figure></div><div class="ab cl kh ki go kj" role="separator"><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km kn"/><span class="kk bw bk kl km"/></div><div class="ha hb hc hd he"><h1 id="9f92" class="ko kp hh bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll bi translated">运行我们的蜘蛛</h1><p id="ddc2" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">a.启动docker桌面</p><p id="f1dc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">b.打开命令提示符发出以下命令来运行docker服务器:</p><pre class="jd je jf jg fd mj lu mk ml aw mm bi"><span id="1219" class="mn kp hh lu b fi mo mp l mq mr">docker run -p 8050:8050 scrapinghub/splash --max-timeout 3600</span></pre><p id="122e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">c.在VS代码内的选项卡上，点击<em class="mb">视图</em>，然后点击<em class="mb">终端、</em>打开VS代码内的终端。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mt"><img src="../Images/61a5ea32abc213e323f5ad538f35461c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hskOZc3t_l3beLQbduwXlg.png"/></div></div></figure><p id="d9d3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">d.在终端内运行脚本<code class="du lr ls lt lu b">scrapy crawl md</code></p><p id="51bf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">e.要在文件中存储报废的项目，只需</p><p id="7698" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lu b">scrapy crawl md -o [filename].[json or csv or XML]</code></p><p id="6601" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们以JSON格式存储数据</p><p id="6d18" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lu b">scrapy crawl md -o mydata.json</code></p><p id="a946" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们的蜘蛛应该运行良好。</p><h1 id="c8f8" class="ko kp hh bd kq kr mu kt ku kv mv kx ky kz mw lb lc ld mx lf lg lh my lj lk ll bi translated">结论</h1><ol class=""><li id="9fff" class="jt ju hh ig b ih lm il ln ip mz it na ix nb jb jy jz ka kb bi translated">在本教程中，我们学习了如何用Scrapy和Splash编写和运行简单的spider</li><li id="59ec" class="jt ju hh ig b ih kc il kd ip ke it kf ix kg jb jy jz ka kb bi translated">将数据存储在CSV、JSON或XML中</li></ol><p id="745a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.抓取的项目有标题、副标题、文章内容、点击次数和标签。</p><p id="7407" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你可以在<a class="ae js" href="https://github.com/kuleafenu/web_scraping" rel="noopener ugc nofollow" target="_blank"> <strong class="ig hi">我的Github库</strong> </a> <strong class="ig hi">上获取完整代码。</strong></p></div></div>    
</body>
</html>