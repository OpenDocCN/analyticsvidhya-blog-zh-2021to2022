<html>
<head>
<title>UNET Implementation in TensorFlow using Keras API — Idiot Developer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras API(白痴开发者)在TensorFlow中实现UNET</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/unet-implementation-in-tensorflow-using-keras-api-idiot-developer-bc3504e9ca69?source=collection_archive---------8-----------------------#2021-02-15">https://medium.com/analytics-vidhya/unet-implementation-in-tensorflow-using-keras-api-idiot-developer-bc3504e9ca69?source=collection_archive---------8-----------------------#2021-02-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="08b8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本帖中，您将学习如何使用Keras API在TensorFlow中实现UNET架构。这篇文章帮助你了解UNET，以及如何在你的研究中使用它。</p><p id="a166" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">UNET是最流行的语义分割架构之一。Olaf Ronneberger等人在2015年开发了这个用于生物医学图像分割的网络。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/6cc97b3b312fcea02cb3ed2d1d54ffb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RhC320AkobcipG5g.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">原始UNET建筑的方块图</figcaption></figure><p id="6cc8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">要了解更多，请阅读文章:<a class="ae jt" href="https://idiotdeveloper.com/what-is-unet/" rel="noopener ugc nofollow" target="_blank">什么是UNET？</a></p><h1 id="e568" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">导入</h1><p id="a087" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">在本文的第一部分，您需要导入实现UNET架构所需的所有类。</p><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="7ae3" class="lc jv hi ky b fi ld le l lf lg">from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input<br/>from tensorflow.keras.models import Model</span></pre><p id="4665" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们已经从TensorFlow导入了所有需要的图层类。这些层类包括<em class="lh"> Conv2D </em>、<em class="lh">批处理规范化</em>、<em class="lh"> ReLU </em>等等。</p><p id="03ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了连接UNET架构的输入和输出层，我们引入了<em class="lh">模型</em>类。</p><h1 id="c4db" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">卷积块</h1><p id="2d32" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">整个UNET体系结构由两个3×3卷积的重复使用组成，每个卷积之后是一个ReLU激活。</p><p id="e1d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，我们编写构建卷积模块的代码。</p><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="e3ee" class="lc jv hi ky b fi ld le l lf lg">def conv_block(input, num_filters):<br/>    x = Conv2D(num_filters, 3, padding="same")(input)<br/>    x = BatchNormalization()(x)<br/>    x = Activation("relu")(x)<br/><br/>    x = Conv2D(num_filters, 3, padding="same")(x)<br/>    x = BatchNormalization()(x)<br/>    x = Activation("relu")(x)<br/><br/>    return x</span></pre><p id="5fe5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷积块或<em class="lh">conv _块</em>函数有两个参数:</p><ol class=""><li id="48e4" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc ln lo lp lq bi translated"><strong class="ih hj">输入:</strong><em class="lh">输入</em>表示来自前一块的特征图。</li><li id="6e8f" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><strong class="ih hj">num _ filters:</strong><em class="lh">num _ filters</em>指的是<em class="lh">conv _布洛克</em>函数中出现的卷积层的输出特征通道的数量。</li></ol><p id="4212" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在最初的UNET架构中，两个3×3卷积之后是一个ReLU激活函数。这里，我们在卷积层和ReLU层之间引入了批量归一化。</p><p id="6834" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">批量归一化通过归一化输入层，有助于使深度神经网络更快、更稳定。</p><h1 id="38e5" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">编码器模块</h1><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="d86b" class="lc jv hi ky b fi ld le l lf lg">def encoder_block(input, num_filters):<br/>    x = conv_block(input, num_filters)<br/>    p = MaxPool2D((2, 2))(x)<br/>    return x, p</span></pre><p id="1702" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">编码器_模块</em>函数有两个参数:</p><ol class=""><li id="ada7" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc ln lo lp lq bi translated"><strong class="ih hj">输入:</strong><em class="lh">输入</em>表示来自前一块的特征图。</li><li id="3a70" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><strong class="ih hj">num _ filters:</strong><em class="lh">num _ filters</em>表示输出特征通道的数量。</li></ol><p id="2666" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">编码器_块</em>由一个conv _块和一个2×2最大池层组成。<em class="lh"> encoder_block </em>返回两个特征图:</p><ol class=""><li id="901c" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc ln lo lp lq bi translated"><strong class="ih hj"> x: </strong>表示conv _块的输出。它充当相应解码器块的跳过连接。</li><li id="4f35" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><strong class="ih hj"> p: </strong>表示传递给下一个块作为输入的缩减特征图。</li></ol><p id="e2de" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh"> encoder_block </em>获取num_filters = 64的大小为(128 x 128 x 32)的输入，然后返回输出x = (128 x 128 x 64)和p = (64 x 64 x 64)</p><h1 id="d1c0" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">解码器块</h1><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="42b2" class="lc jv hi ky b fi ld le l lf lg">def decoder_block(input, skip_features, num_filters):<br/>    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding="same")(input)<br/>    x = Concatenate()([x, skip_features])<br/>    x = conv_block(x, num_filters)<br/>    return x</span></pre><p id="416e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">解码器_模块</em>采用三个参数:</p><ol class=""><li id="47a9" class="li lj hi ih b ii ij im in iq lk iu ll iy lm jc ln lo lp lq bi translated"><strong class="ih hj">输入:</strong><em class="lh">输入</em>表示来自前一块的特征地图。</li><li id="0bb5" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><strong class="ih hj">skip _ features:</strong>skip _ features表示通过skip连接从编码器模块获取的特征映射。</li><li id="286e" class="li lj hi ih b ii lr im ls iq lt iu lu iy lv jc ln lo lp lq bi translated"><strong class="ih hj">num _ filters:</strong>num _ filters表示输出特征通道的数量。</li></ol><p id="7146" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh"> decoder_block </em>函数开始一个2×2转置卷积，该卷积将输入特征图的空间维度(高度和宽度)加倍。</p><p id="a0e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果输入大小是(16 x 16 x 32)并且num_filters是64，则转置卷积的输出是(32 x 32 x 64)。</p><p id="0165" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们将二次抽样特征映射与跳过连接特征映射连接起来。这些跳跃连接带来了早期层的特征图，帮助网络生成更好的语义特征图。</p><p id="e388" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在连接之后，使用conv块。</p><p id="22ba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我们已经研究了UNET结构的编码器和解码器模块。现在，我们开始建造完整的UNET建筑。</p><h1 id="c7a4" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">UNET建筑</h1><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="6a98" class="lc jv hi ky b fi ld le l lf lg">def build_unet(input_shape):<br/>    inputs = Input(input_shape)<br/><br/>    s1, p1 = encoder_block(inputs, 64)<br/>    s2, p2 = encoder_block(p1, 128)<br/>    s3, p3 = encoder_block(p2, 256)<br/>    s4, p4 = encoder_block(p3, 512)<br/><br/>    b1 = conv_block(p4, 1024)<br/><br/>    d1 = decoder_block(b1, s4, 512)<br/>    d2 = decoder_block(d1, s3, 256)<br/>    d3 = decoder_block(d2, s2, 128)<br/>    d4 = decoder_block(d3, s1, 64)<br/><br/>    outputs = Conv2D(1, 1, padding="same", activation="sigmoid")(d4)<br/><br/>    model = Model(inputs, outputs, name="U-Net")<br/>    return model</span></pre><p id="9363" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">build_unet函数接受一个参数:</p><p id="cfb2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh"> build_unet </em>函数返回包含所有层的<em class="lh">模型</em>对象。</p><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="f3bc" class="lc jv hi ky b fi ld le l lf lg">inputs = Input(input_shape)</span></pre><p id="6c86" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh"> build_unet </em>函数从一个输入层开始，该输入层具有作为函数参数提供的指定输入形状。</p><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="7a37" class="lc jv hi ky b fi ld le l lf lg">s1, p1 = encoder_block(inputs, 64) <br/>s2, p2 = encoder_block(p1, 128) <br/>s3, p3 = encoder_block(p2, 256) <br/>s4, p4 = encoder_block(p3, 512)</span></pre><p id="0177" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来是四个编码器模块，这里每个编码器模块使用前一层作为输入。除了输入，它还接受输出特征通道的数量。滤波器的数量从64开始，随后对于编码器模块加倍。</p><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="0782" class="lc jv hi ky b fi ld le l lf lg">b1 = conv_block(p4, 1024)</span></pre><p id="45e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第4个编码器模块的输出充当电桥的输入。该桥是一个简单的conv模块，具有1024个输出特征通道。</p><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="43d3" class="lc jv hi ky b fi ld le l lf lg">d1 = decoder_block(b1, s4, 512) <br/>d2 = decoder_block(d1, s3, 256) <br/>d3 = decoder_block(d2, s2, 128) <br/>d4 = decoder_block(d3, s1, 64)</span></pre><p id="63a2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来是解码器，由四个解码器模块组成。每个解码器模块使用先前的特征映射作为输入和输出声道的数量。首先使用转置卷积对输入进行上采样。这些上采样的特征映射与来自编码器块的适当的跳过连接连接在一起。之后，紧接着是一个<em class="lh">conv _区块</em>。</p><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="3b24" class="lc jv hi ky b fi ld le l lf lg">outputs = Conv2D(1, 1, padding="same", activation="sigmoid")(d4)</span></pre><p id="f20e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第4个解码器模块的输出通过具有sigmoid激活函数的1×1卷积层。</p><p id="7f6d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于二进制分割，我们使用1个具有sigmoid激活的输出特征通道。在多类分割中，我们使用softmax激活函数将类的数量作为输出特征通道。</p><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="0085" class="lc jv hi ky b fi ld le l lf lg">model = Model(inputs, outputs, name="U-Net") <br/>return model</span></pre><p id="d6a3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们将UNET架构的输入和输出都交给了<em class="lh">模型</em>类。现在我们有了一个包含所有层的模型对象。</p><h1 id="3e5f" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">跑UNET</h1><pre class="je jf jg jh fd kx ky kz la aw lb bi"><span id="9405" class="lc jv hi ky b fi ld le l lf lg">if __name__ == "__main__":<br/>    input_shape = (512, 512, 3)<br/>    model = build_unet(input_shape)<br/>    model.summary()</span></pre><p id="ff89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们已经使用Keras API在TensorFlow中实现了UNET架构。我们用(512 x 512 x 3)的<em class="lh">输入形状</em>调用<em class="lh">构建_unet </em>函数</p><p id="0563" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是UNET建筑的概要。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lw"><img src="../Images/e240a574534ce9690c0d9720b3a695bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1366/format:webp/0*yYWvksf48Te_uPbi.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">UNET建筑概述</figcaption></figure></div><div class="ab cl lx ly gp lz" role="separator"><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc md"/><span class="ma bw bk mb mc"/></div><div class="hb hc hd he hf"><p id="c864" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="lh">原载于2021年2月15日</em><a class="ae jt" href="https://idiotdeveloper.com/unet-implementation-in-tensorflow-using-keras-api/" rel="noopener ugc nofollow" target="_blank"><em class="lh">【https://idiotdeveloper.com】</em></a><em class="lh">。</em></p></div></div>    
</body>
</html>