<html>
<head>
<title>Know about Quantization in TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解张量流中的量子化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/know-about-quantization-in-tensorflow-7f111eedd2a6?source=collection_archive---------2-----------------------#2021-09-15">https://medium.com/analytics-vidhya/know-about-quantization-in-tensorflow-7f111eedd2a6?source=collection_archive---------2-----------------------#2021-09-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="9765" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">细说量子化的奇迹</p><h1 id="cb65" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">动机</h1><p id="1669" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">每当我从事深度学习项目来训练一个模型，并通过保存模型为生产做好准备时，它都会给我带来巨大的记忆。然后我开始研究减少节省的模型内存，在这里我发现了一个名字叫做“量化”。我想用一些代码样本和背后的理论来解释更多关于这个量化的内容。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es kf"><img src="../Images/3a351b761d92185892e0cc9235671afd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SRx7cM-gvhOJtCVc"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">乌萨马·阿扎姆在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><p id="868c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">有两种量化形式:</p><ol class=""><li id="4bd1" class="kw kx hh ig b ih ii il im ip ky it kz ix la jb lb lc ld le bi translated">训练后量化。</li><li id="c021" class="kw kx hh ig b ih lf il lg ip lh it li ix lj jb lb lc ld le bi translated">量化感知训练。</li></ol><p id="73fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从训练后量化开始，因为它更容易使用，尽管量化感知训练通常对模型准确性更好。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lk"><img src="../Images/acb0a08d4e7a5597f702006508478874.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jS52twEr4MbI0p9YJzn3BA.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">来源:“作者图片”</figcaption></figure><p id="e1f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">通过上面的图像，我们可以说，通过量化，我们可以将模型的权重从浮点数减少到整数，甚至可以减少模型的大小来释放内存。</p><h1 id="6870" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">训练后量化概述</h1><p id="e096" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">训练后量化包括减少CPU和硬件加速器延迟、处理和模型大小的一般技术，而模型精度几乎没有下降。这些技术可以在已经训练好的float TensorFlow模型上执行，并在TensorFlow Lite转换期间应用。这些技术在TensorFlow Lite转换器中作为选项启用。</p><p id="c497" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">权重可以转换为精度降低的类型，如16位浮点数或8位整数。我们通常建议GPU加速使用16位浮点，CPU执行使用8位整数。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es ll"><img src="../Images/32cd947295042e1a2a01bce076749e10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/format:webp/1*RTsSsBgNulyWc7uMZ_5tHA.png"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">来源:“作者图片”</figcaption></figure><figure class="kg kh ki kj fd kk"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="17f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，使用上面的代码行，我们可以减少保存的模型的大小并开始生产。但是当我们使用训练后量化时，精度可能随着先前训练的模型而变化。所以，使用量化感知训练。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lo"><img src="../Images/907766a907f6ac0fd3317b6b278ae6d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FszB0pmLBmzQaDBAblrAsg.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">来源:“作者图片”</figcaption></figure><h1 id="9785" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">量化感知培训概述</h1><p id="6eaa" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">量化感知训练模拟推理时量化，创建一个模型，下游工具将使用它来产生实际的量化模型。量化模型使用较低的精度(例如，8位而不是32位浮点)，从而在部署期间带来好处。</p><p id="5250" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">量化通过模型压缩和延迟减少带来改进。使用API默认值，模型大小缩小了4倍，我们通常会看到测试后端的CPU延迟提高了1.5到4倍。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div class="er es lp"><img src="../Images/eda82eeec0514fbf87276efe7679220a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1356/format:webp/1*5F0bcVXH4JnNSiOJdtFGgQ.png"/></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">来源:“作者图片”</figcaption></figure><figure class="kg kh ki kj fd kk"><div class="bz dy l di"><div class="lm ln l"/></div></figure><p id="01e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了进行这种量化感知训练，我们需要开始量化保存的模型TF模型。然后通过编译来拟合量化模型，用一些历元来拟合。随后，微调量化的拟合模型，并通过使用tf lite转换器提取Tf lite模型，以获得良好的部署精度。</p><figure class="kg kh ki kj fd kk er es paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="er es lq"><img src="../Images/c3fd35fa767ec985e2153eebe2e3cdd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Qzre-EnDOt0iWbsXReUnIA.png"/></div></div><figcaption class="kr ks et er es kt ku bd b be z dx translated">来源:“作者图片”</figcaption></figure><h1 id="2251" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">结论</h1><p id="e478" class="pw-post-body-paragraph ie if hh ig b ih ka ij ik il kb in io ip kc ir is it kd iv iw ix ke iz ja jb ha bi translated">通过这种量化，我们可以减少所保存的TF模型的大小，并为其生产获得良好的精度。此外，它易于实现，重量轻，最重要的是在构建大型神经网络时没有内存。</p><p id="dfbc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">希望你喜欢，感谢阅读！！</p></div></div>    
</body>
</html>