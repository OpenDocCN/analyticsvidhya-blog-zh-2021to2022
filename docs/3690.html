<html>
<head>
<title>Sign Language Gesture Detection Using Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习的手语手势检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sign-language-gesture-detection-using-deep-learning-ffb17d5c4015?source=collection_archive---------6-----------------------#2021-07-18">https://medium.com/analytics-vidhya/sign-language-gesture-detection-using-deep-learning-ffb17d5c4015?source=collection_archive---------6-----------------------#2021-07-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="1fe8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">端到端机器学习项目</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/2fc9669c61e4937742cfd4b300b366e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZTd273ugvifyxK9-"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">照片由<a class="ae js" href="https://unsplash.com/@codypboard?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">科迪板</a>在<a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><p id="9666" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jt translated"><span class="l ju jv jw bm jx jy jz ka kb di">在着手解决问题之前，了解问题陈述的原因和内容非常重要。那我们开始吧..</span></p><p id="1a88" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">手语是一种交流语言，就像聋人社会中使用的任何其他语言一样。这个数据集是手语中使用的一套完整的手势，可以被其他正常人用来更好地理解手语手势。数据集收集自Kaggle网站。该数据总共包括37个类，它们具有英语字母表的所有字符，也全部是10个数字和一个低分数(对于空格)。细节将在后面的章节中解释。该模型是在Python语言下构建的，这是ML和DL任务的流行选择。</p><p id="1b55" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Pytorch是一个灵活的库和特性，它被用于这个项目。关于模型和其他的进一步细节在下面提到。该模型在可通过Kaggle内核获得的GPU下训练。</p><p id="0711" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ML生命周期有4个主要部分</p><ul class=""><li id="a6d7" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">数据采集</li><li id="6135" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">从数据中预处理和提取特征</li><li id="af03" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">模型准备</li><li id="0d35" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">模型的部署</li></ul></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><blockquote class="kx ky kz"><p id="489d" class="ie if la ig b ih ii ij ik il im in io lb iq ir is lc iu iv iw ld iy iz ja jb ha bi translated"><strong class="ig hi">数据集</strong>的采集 <strong class="ig hi"/></p></blockquote><p id="5d18" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该数据集由37种不同的<strong class="ig hi">手势组成，其中包括<strong class="ig hi"> A-Z字母</strong>手势、<strong class="ig hi">0–9</strong>数字手势以及一种表示空间的手势，这意味着聋哑人在交流时如何表示两个字母或两个单词之间的空间。数据集有两个部分，即</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es le"><img src="../Images/b5843f06e9d863b6772a356651d47f2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:100/0*qFuwrQxS3R8vDTj1"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">手势符号“H”</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es le"><img src="../Images/fd69637c90abd76ccdafc994fa160884.png" data-original-src="https://miro.medium.com/v2/resize:fit:100/0*KDQ29Y4CZnL6VzSN"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">手势符号“0”</figcaption></figure><p id="8cd5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">文件夹(1)-手势图像数据-由不同手势的手的彩色图像组成。每个手势图像的大小为<strong class="ig hi"> 50 x 50 </strong>，并且位于其指定的文件夹名称中，即A-Z文件夹由A-Z手势图像组成，0–9文件夹分别由0–9手势组成，“_”文件夹由手势图像组成，用于分隔。这里给出了数据集的一些样本。</p></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><blockquote class="kx ky kz"><p id="7c40" class="ie if la ig b ih ii ij ik il im in io lb iq ir is lc iu iv iw ld iy iz ja jb ha bi translated"><strong class="ig hi">预处理和特征提取</strong></p></blockquote><p id="0528" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如图像所示，它是一个RGB(红绿蓝)图像，这意味着它有3 x 50 x 50，其中50 x 50是图像的大小。考虑到真实世界的情况和计算成本，该模型可以仅通过灰度级来建立，在黑白图像中也是如此。这里对图像进行预处理，将它们转换成BW图像。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lf"><img src="../Images/55935e085293a85cb7779ba7a49e5f33.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/0*yOD0i_GQJCiZ7sbt"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lf"><img src="../Images/a5718e3419577a73904192a2e9ed7d64.png" data-original-src="https://miro.medium.com/v2/resize:fit:736/0*_xcee8kweGe5_wCJ"/></div></figure><p id="50d8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是通过调整亮度、高斯阈值二值化来实现的。这里展示了一些图像。图像现在被转换为BW和更低的维度，即50 x 50(因为只有0或255)。预计计算成本会降低。二值图像是任何图像的重要特征之一，因此这就完成了特征提取部分。</p></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><blockquote class="kx ky kz"><p id="368a" class="ie if la ig b ih ii ij ik il im in io lb iq ir is lc iu iv iw ld iy iz ja jb ha bi translated"><strong class="ig hi">模型准备</strong></p></blockquote><p id="3d3f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型准备也是生命周期的重要部分之一。有几种方法可以选择模型。因为问题陈述是关于解决图像的，最合适的最大似然算法是SVM树。但是由于在将某个数据传递给传统的最大似然算法之后<strong class="ig hi">，该模型不再进一步学习。因此，像神经网络和CNN这样的深度学习算法最近变得很受欢迎。</strong></p><pre class="jd je jf jg fd lg lh li lj aw lk bi"><span id="f660" class="ll lm hh lh b fi ln lo l lp lq">class net(nn.Module):</span><span id="8e03" class="ll lm hh lh b fi lr lo l lp lq">def __init__(self,input_size,hidden_layers,num_classes):</span><span id="7299" class="ll lm hh lh b fi lr lo l lp lq">super(net,self).__init__()<br/>    self.input = nn.Linear(in_features=50*50*3,out_features=1024)<br/>    self.relu_1 = nn.ReLU()<br/>    self.hidden1 = nn.Linear(in_features=1024,out_features=2048)<br/>    self.relu_2 = nn.ReLU()<br/>    self.hidden2 = nn.Linear(in_features=2048,out_features=2048)<br/>    self.relu_3 = nn.ReLU()<br/>    self.hidden3 = nn.Linear(in_features=2048,out_features=2048)<br/>    self.relu_4 = nn.ReLU()<br/>    self.hidden4 = nn.Linear(in_features=2048,out_features=1024)<br/>    self.relu_5 = nn.ReLU()<br/>    self.hidden5 = nn.Linear(in_features=1024,out_features=512)<br/>    self.relu_6 = nn.ReLU()<br/>    self.output = nn.Linear(in_features=512,out_features=num_classes)</span><span id="548f" class="ll lm hh lh b fi lr lo l lp lq">def forward(self,X):<br/>    model = self.input(X)<br/>    model = self.relu_1(model)<br/>    model = self.hidden1(model)<br/>    model = self.relu_2(model)<br/>    model = self.hidden2(model)<br/>    model = self.relu_3(model)<br/>    model = self.hidden3(model)<br/>    model = self.relu_4(model)<br/>    model = self.hidden4(model)<br/>    model = self.relu_5(model)<br/>    model = self.hidden5(model)<br/>    model = self.relu_6(model)<br/>    model = self.output(model)</span><span id="4bcb" class="ll lm hh lh b fi lr lo l lp lq">return model</span></pre><p id="d24c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">车型总结</strong></p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ls"><img src="../Images/37a98a9f47102c5c791e50c45c535449.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/format:webp/1*AOytS9NmwA5--Ejc49jcpQ.png"/></div></figure><p id="0f90" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然这些模型有可能过度拟合，因为一些领域如罕见疾病的医学诊断具有较少的数据，但在这些情况下不适合使用这样的算法。由于问题陈述具有如此庞大的数据(55，500张图片平均分布在各个类别中)，深度学习算法将在这种情况下发挥作用。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lt"><img src="../Images/5e0f85517b98c17a7e0815a7b2d6b315.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*9TYPMjh340L39LAp"/></div></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lt"><img src="../Images/c8e30e1e1103c9bc776921725316cb25.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*L1i9zmkQfohv7zJp"/></div></figure><p id="d5c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">选择人工神经网络(ANN)算法作为基本算法。</p><p id="9279" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型建立在Pytorch库下，使用灵活。<strong class="ig hi">分类损失</strong>用作优化器的损失。<strong class="ig hi"> Adam优化器</strong>用于以0.001的<strong class="ig hi">学习率</strong>优化损失函数。以下是所得结果的图表。所以最后考虑的指标是损失、准确性、F1分数。由于损失和准确性对模型性能没有太大影响，所以使用F1-分数(准确性和召回率的HM)。下表给出了关于此模型的度量性能的信息</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lt"><img src="../Images/f98c3f8e2c034b21710b8801f5c2ff67.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*6EEjHIoBNMUpbc8F"/></div></figure></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><blockquote class="kx ky kz"><p id="8690" class="ie if la ig b ih ii ij ik il im in io lb iq ir is lc iu iv iw ld iy iz ja jb ha bi translated"><strong class="ig hi">模型部署</strong></p></blockquote><p id="1b8a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">虽然前面的阶段很重要，但是模型的部署在解决现实世界的问题中起着关键的作用。任何一个有数据的人都可以建立一个简单或复杂的模型，但是如果不把它部署到现实世界中，我们就无法从这项技术中获益。该模型通过Flask web框架进行部署。这个应用程序基本上将图像作为输入，然后将其转换为文本。虽然这是一个基本的应用程序，但可以通过在视频中实现这些算法来改进它。执行完整的循环，完整的培训代码在<a class="ae js" href="https://www.kaggle.com/navaneethsharma2310/hand-gesture-language-detection" rel="noopener ugc nofollow" target="_blank">这里</a>可用，部署代码在这个<a class="ae js" href="https://github.com/Navaneeth-Sharma/Sign_Language_Detection" rel="noopener ugc nofollow" target="_blank"> ithub </a> repo中可用，除了预培训，基本上通过<a class="ae js" href="https://drive.google.com/file/d/1asp49Y5LbjCnRxetISSnXsfn-cHYaRLP/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">驱动</a>提供。</p></div><div class="ab cl kq kr go ks" role="separator"><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv kw"/><span class="kt bw bk ku kv"/></div><div class="ha hb hc hd he"><blockquote class="kx ky kz"><p id="8561" class="ie if la ig b ih ii ij ik il im in io lb iq ir is lc iu iv iw ld iy iz ja jb ha bi translated"><strong class="ig hi">未来范围</strong></p></blockquote><ul class=""><li id="2dae" class="kc kd hh ig b ih ii il im ip ke it kf ix kg jb kh ki kj kk bi translated">一个模型可以被训练来实时识别来自现场视频的手势</li><li id="ddc0" class="kc kd hh ig b ih kl il km ip kn it ko ix kp jb kh ki kj kk bi translated">当模型将图像转换成文本时，可以使用文本到语音模型，就好像说话者在说话一样</li></ul><p id="bd1b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">谢谢你…</p><p id="8de6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">快乐学习…！！！</p></div></div>    
</body>
</html>