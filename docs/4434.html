<html>
<head>
<title>Akira’s Machine Learning news — #issue 31</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Akira的机器学习新闻—#第31期</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/akiras-machine-learning-news-issue-31-d7d5ee127df7?source=collection_archive---------16-----------------------#2021-10-11">https://medium.com/analytics-vidhya/akiras-machine-learning-news-issue-31-d7d5ee127df7?source=collection_archive---------16-----------------------#2021-10-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h2 id="44d8" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">本周特稿/新闻。</h2><ul class=""><li id="6128" class="jj jk hh jl b jm jn jo jp iw jq ja jr je js jt ju jv jw jx bi translated"><a class="ae jy" href="https://mathai-iclr.github.io/papers/papers/MATHAI_29_paper.pdf" rel="noopener ugc nofollow" target="_blank">一项发表的研究</a>显示了随机结果的泛化性能的突然提高:过拟合开始于大约10步，而随机预测的泛化性能的突然提高据报道发生在大约10⁶步。因此，加权衰减似乎是一般化的关键。另一方面，Y <a class="ae jy" href="https://www.youtube.com/watch?v=dND-7llwrpw" rel="noopener ugc nofollow" target="_blank"> annic Kilcher提出了</a>一个假设，即“权重衰减可能会使模型在抑制突变的同时绘制出一条平滑的概括线”，我认为这非常有趣。</li><li id="8746" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ju jv jw jx bi translated">研究人员<a class="ae jy" href="https://openreview.net/forum?id=TVHS5Y4dNvM" rel="noopener ugc nofollow" target="_blank">提出</a>图像系统中的变压器模型的结果，如ViT，可能是由于修补而不是变压器。在需要大量数据的ViT系统中对CIFAR10进行完全刮擦训练就能获得96%的准确率，这是一个很突出的成绩。</li></ul><p id="30da" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><p id="2a1a" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">在下面的章节中，我将介绍各种文章和论文，不仅仅是关于上述内容，还包括以下五个主题。</p><ol class=""><li id="77ec" class="jj jk hh jl b jm kg jo kj iw kv ja kw je kx jt ky jv jw jx bi translated">本周特稿/新闻</li><li id="6fda" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">机器学习用例</li><li id="7797" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">报纸</li><li id="75f1" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">机器学习技术相关文章</li><li id="ccd5" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">其他主题</li></ol><p id="3f0c" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="29c2" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">1.本周特稿/新闻</h1><p id="f1b3" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://mathai-iclr.github.io/papers/papers/MATHAI_29_paper.pdf?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">一段时间后，神经网络突然泛化。</strong></a><strong class="jl hi">—</strong><a class="ae jy" href="https://mathai-iclr.github.io/papers/papers/MATHAI_29_paper.pdf" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">mathai-iclr . github . io</strong></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lt"><img src="../Images/7a97468bc29cfb82a699f5744d47cfb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R76GMjMlBYsQJJbg0WeGBA.png"/></div></div></figure><p id="5e7a" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">【GROKKING:超越对小型算法数据集过度拟合的泛化】<br/>他们发现，数据集越小，优化神经网络所需的时间就越长。虽然过度拟合发生在大约10个步骤中，但是推广到有效集合需要大约10⁵步骤，这导致随机结果的准确性突然增加。对于这种概括，使用重量衰减是必要的。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="5fd5" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://openreview.net/forum?id=TVHS5Y4dNvM&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">打补丁比变压器更关键吗？</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://openreview.net/forum?id=TVHS5Y4dNvM" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">openreview.net</strong></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mf"><img src="../Images/f4bfe6c299b7af6871126f622dce0109.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dbFt3F8p9GvYtzfFnRescg.png"/></div></div></figure><p id="3b39" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[您只需要补丁？| OpenReview] <br/>这是一项使用Conv的变压器编码器类机制的研究，它可以用六行PyTorch实现，比ViT或MLP混合器更有效，即使在CIFAR等小数据集上也可以达到96%的准确率。根据这一结果，作者认为修补图像比变压器本身更重要。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="18d3" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="4746" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">2.机器学习用例</h1><p id="5eb0" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://kaifulee.medium.com/china-is-still-the-worlds-factory-and-it-s-designing-the-future-with-ai-b79123ce3a65?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener"> <strong class="jl hi">中国将继续成为人工智能技术的“世界工厂”</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://kaifulee.medium.com/china-is-still-the-worlds-factory-and-it-s-designing-the-future-with-ai-b79123ce3a65" rel="noopener"><strong class="jl hi">kaifulee.medium.com</strong></a></p><div class="mg mh ez fb mi mj"><a href="https://kaifulee.medium.com/china-is-still-the-worlds-factory-and-it-s-designing-the-future-with-ai-b79123ce3a65" rel="noopener follow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">中国仍然是世界工厂——它正在用人工智能设计未来</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">多年来，中国一直是世界工厂。即使在2020年，当其他经济体还在努力应对…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">kaifulee.medium.com</p></div></div><div class="ms l"><div class="mt l mu mv mw ms mx md mj"/></div></div></a></div><p id="70a5" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">这是一篇关于中国应用AI技术的文章。中国被称为世界工厂，这在2020年仍将如此，并表示随着人口放缓导致劳动力成本上升，中国正在利用人工智能技术在制造业和其他领域进行创新。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="1a6f" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="1999" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">3.报纸</h1><p id="6454" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated">【arxiv.org】<strong class="jl hi"/><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2110.00023" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div class="ab fe cl my"><img src="../Images/f19f74f9d7ac810dfd2036a88651d506.png" data-original-src="https://miro.medium.com/v2/0*6maXHxGgG2y1HRaI"/></div></figure><p id="ebd9" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2110.00023]利用自监督学习挖掘强引力透镜<br/>通过自监督学习寻找引力透镜候选图像的研究。首先，他们使用带有自我监督学习的预训练模型，通过已知图像中的相似性来寻找候选对象。之后，他们使用线性回归和其他方法建立分类模型。他们表示，这可以大大降低处理调查数据的门槛，并开辟许多合作渠道。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="ac72" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">用进化算法优化的<a class="ae jy" href="https://arxiv.org/abs/2109.08668?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2109.08668" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div class="ab fe cl my"><img src="../Images/c972382f109cb416df2ff7f81ace5340.png" data-original-src="https://miro.medium.com/v2/0*-eoIj0jaaVlD4vEs"/></div></figure><p id="5788" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2109.08668]初级读本:为语言建模寻找有效的转换器<br/>这是对进化算法中语言模型转换器的NAS的研究。作为搜索的结果，他们发现了MDHA，它在头部之间卷积信息，以及平方ReLU，平方ReLU，配备它们的Primer可以减少1/3到1/4的训练时间。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="fe15" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2110.00476?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">重新评估ResNet并重新建立学习程序的基线</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2110.00476" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mz"><img src="../Images/e64e4dff2e518c4b389e322184a5eb48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qJblPcbzyHhL4SAwaLfrmg.png"/></div></div></figure><p id="466d" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2110.00476] ResNet反击:timm的改进培训程序<br/>这是一项研究，其中ResNet使用最新的正规化和数据扩充进行了重新评估。结果，Top-1 Acc从75.3%提高到80.4%。此外，不同的论文对ResNet的评分是不同的，但他们的学习过程通过timm公开，并分享了一个新的基线。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="2884" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2104.14294?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi"> ViT可以通过自我监督学习</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2104.14294" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a>来学习语义域切分信息</p><figure class="lu lv lw lx fd ly er es paragraph-image"><div class="ab fe cl my"><img src="../Images/162c8c73e4f0beb12a38ef93e6b12eb5.png" data-original-src="https://miro.medium.com/v2/0*KQOVaNakpA8wSiPY"/></div></figure><p id="0861" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2104.14294]自监督视觉变压器中的新兴特性<br/>这是一项关于vit自监督学习的研究。他们提出了DINO，它通过类似蒸馏的机制执行自我监督学习，来训练vit，以便它们的分布在多个裁剪的图像中保持一致。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="ed17" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2106.04803?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">用更少或更多的数据实现高性能。</strong></a><strong class="jl hi">—</strong><a class="ae jy" href="https://arxiv.org/abs/2106.04803" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es na"><img src="../Images/ea7538009d179c12eb8d1eacffd63f6a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ENclGVlMaQBzuGDNw2c39A.png"/></div></div></figure><p id="9739" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2106.04803] CoAtNet:为所有数据大小结合卷积和注意力<br/>这是结合Transformer和CNN的研究。首先，使用相对位置编码进行自我关注，然后在舞台级别选择CNN或Transformer层，并建立舞台。最后，使用ImageNet获得SotA性能，用更少或更多的数据实现高性能。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="ba9b" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="fa8f" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">4.机器学习技术相关文章</h1><p id="0cc8" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://ai.googleblog.com/2021/08/introducing-omnimattes-new-approach-to.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">背景与前景分离</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://ai.googleblog.com/2021/08/introducing-omnimattes-new-approach-to.html" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">ai.googleblog.com</strong></a></p><div class="mg mh ez fb mi mj"><a href="https://ai.googleblog.com/2021/08/introducing-omnimattes-new-approach-to.html" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">介绍Omnimattes:一种使用分层神经渲染生成遮罩的新方法</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">图像和视频编辑操作通常依赖于精确的图像来定义前景和…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">ai.googleblog.com</p></div></div><div class="ms l"><div class="nb l mu mv mw ms mx md mj"/></div></div></a></div><p id="0b70" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">这是谷歌的博客“Omnimatte:在视频中关联对象及其效果”(CVPR2021)。它指出，通过让CNN学习人和阴影之间的相关性，分离相关性较低的部分是可能的，它可以分离背景和前景。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="3a5e" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://syncedreview.com/2021/08/27/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-92/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">ViT和CNN的区别</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://syncedreview.com/2021/08/27/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-92/" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">syncedreview.com</strong></a></p><div class="mg mh ez fb mi mj"><a href="https://syncedreview.com/2021/08/27/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-92/" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">谷歌大脑揭示了CNN和视觉转换器之间的表征结构差异</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">尽管卷积神经网络(CNN)已经统治了计算机视觉领域多年，但新的视觉…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">syncedreview.com</p></div></div><div class="ms l"><div class="nc l mu mv mw ms mx md mj"/></div></div></a></div><p id="41e5" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">一篇评论文章【视觉变形金刚看起来像卷积神经网络吗？]讨论ViT和CNN的区别。它指出，ViT用于表示传播的跳过连接比ResNet连接更有影响，并且可能会显著影响性能和表示相似性。</p><p id="849f" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="c43b" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">5.其他主题</h1><p id="138f" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://blog.tensorflow.org/2021/09/introducing-tensorflow-similarity.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">张量流相似度</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://blog.tensorflow.org/2021/09/introducing-tensorflow-similarity.html" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">blog.tensorflow.org</strong></a></p><div class="mg mh ez fb mi mj"><a href="https://blog.tensorflow.org/2021/09/introducing-tensorflow-similarity.html" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">引入张量流相似性</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">2021年9月13日-由Elie Bursztein和Owen Vallis发布，Google今天发布了第一版…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">blog.tensorflow.org</p></div></div><div class="ms l"><div class="nd l mu mv mw ms mx md mj"/></div></div></a></div><p id="a8b6" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">【TensorFlow相似度介绍—tensor flow博客】<br/>tensor flow相似度介绍，可以搜索最近邻数据，可以用20行代码实现。</p><p id="bbfd" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="ba92" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">其他博客</h1><div class="mg mh ez fb mi mj"><a href="https://towardsdatascience.com/machine-learning-2020-summary-84-interesting-papers-articles-45bd45c0d35b" rel="noopener follow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">机器学习2020摘要:84篇有趣的论文/文章</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">在这篇文章中，我总共展示了2020年发表的84篇我觉得特别有趣的论文和文章…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">towardsdatascience.com</p></div></div><div class="ms l"><div class="ne l mu mv mw ms mx md mj"/></div></div></a></div><div class="mg mh ez fb mi mj"><a href="https://towardsdatascience.com/recent-developments-and-views-on-computer-vision-x-transformer-ed32a2c72654" rel="noopener follow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">计算机视觉x变形金刚的最新发展和看法</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">《变形金刚》和CNN的区别，为什么《变形金刚》很重要，它的弱点是什么。</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">towardsdatascience.com</p></div></div><div class="ms l"><div class="nf l mu mv mw ms mx md mj"/></div></div></a></div><div class="mg mh ez fb mi mj"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/reach-and-limits-of-the-supermassive-model-gpt-3-5012a6ddff00"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">超大质量模型GPT-3的到达和极限</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">在这篇博文中，我将从技术上解释GPT 3号，GPT 3号取得了什么，GPT 3号没有取得什么…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">medium.com</p></div></div><div class="ms l"><div class="ng l mu mv mw ms mx md mj"/></div></div></a></div><h1 id="6dea" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">关于我</h1><p id="d020" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated">制造工程师/机器学习工程师/数据科学家/物理学硕士/<a class="ae jy" href="https://t.co/hjHHbG24Ph?amp=1" rel="noopener ugc nofollow" target="_blank">http://github.com/AkiraTOSEI/</a></p><p id="9af8" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">推特，我贴一句纸评论。</p></div></div>    
</body>
</html>