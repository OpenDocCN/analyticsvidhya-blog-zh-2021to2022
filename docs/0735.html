<html>
<head>
<title>Akira’s ML News #January, 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Akira的ML新闻# 2021年1月</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/akiras-ml-news-january-2021-34a7249c6bb9?source=collection_archive---------19-----------------------#2021-01-28">https://medium.com/analytics-vidhya/akiras-ml-news-january-2021-34a7249c6bb9?source=collection_archive---------19-----------------------#2021-01-28</a></blockquote><div><div class="ds gz ha hb hc hd"/><div class="he hf hg hh hi"><div class=""/><p id="568d" class="pw-post-body-paragraph ii ij hl ik b il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf he bi translated">以下是我在2021年1月读到的一些我觉得特别有趣的论文和文章。</p><h1 id="8ed8" class="jg jh hl bd ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd bi translated">—每月编辑精选</h1><ul class=""><li id="b1a5" class="ke kf hl ik b il kg ip kh it ki ix kj jb kk jf kl km kn ko bi translated"><a class="ae kp" href="https://arxiv.org/abs/2101.06840" rel="noopener ugc nofollow" target="_blank">在单个GPU上训练130亿个参数</a></li><li id="1d1a" class="ke kf hl ik b il kq ip kr it ks ix kt jb ku jf kl km kn ko bi translated"><a class="ae kp" href="https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/" rel="noopener ugc nofollow" target="_blank">从神经元获得的“观点”解释知识提炼和集成的关系</a></li><li id="06f0" class="ke kf hl ik b il kq ip kr it ks ix kt jb ku jf kl km kn ko bi translated"><a class="ae kp" href="https://arxiv.org/abs/2101.05791?" rel="noopener ugc nofollow" target="_blank">利用重要部件对噪声敏感的事实进行可视化</a></li><li id="333b" class="ke kf hl ik b il kq ip kr it ks ix kt jb ku jf kl km kn ko bi translated"><a class="ae kp" href="https://openai.com/blog/dall-e/?" rel="noopener ugc nofollow" target="_blank">通过OpenAI </a>显著改善文本到图像的转换</li></ul></div></div>    
</body>
</html>