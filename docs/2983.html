<html>
<head>
<title>Machine Learning Approach for Apparent Temperature Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">表观温度预测的机器学习方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-approach-for-apparent-temperature-prediction-6751e750f9d5?source=collection_archive---------8-----------------------#2021-05-28">https://medium.com/analytics-vidhya/machine-learning-approach-for-apparent-temperature-prediction-6751e750f9d5?source=collection_archive---------8-----------------------#2021-05-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="0f8b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">嗨，伙计们，很高兴见到你们。今天，我将向您展示分析天气历史数据集并使用该数据集进行预测的基本工作流程。</p><p id="ce7a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">点击下面的数据集链接。</p><div class="jc jd ez fb je jf"><a href="https://www.kaggle.com/budincsevity/szeged-weather?select=weatherHistory.csv" rel="noopener  ugc nofollow" target="_blank"><div class="jg ab dw"><div class="jh ab ji cl cj jj"><h2 class="bd hi fi z dy jk ea eb jl ed ef hg bi translated">塞格德2006-2016年的天气</h2><div class="jm l"><h3 class="bd b fi z dy jk ea eb jl ed ef dx translated">每小时/每天汇总温度、压力、风速等信息</h3></div><div class="jn l"><p class="bd b fp z dy jk ea eb jl ed ef dx translated">www.kaggle.com</p></div></div><div class="jo l"><div class="jp l jq jr js jo jt ju jf"/></div></div></a></div><p id="4823" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在让我们看看我们的数据集是什么样子的:</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es jv"><img src="../Images/09925389a8b3080656b5accb45a7c932.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yy6x9teKf74kiK9ZVMP3FQ.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">天气历史数据集</figcaption></figure><p id="d9d9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是每小时可用的响应数据:</p><p id="c261" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">格式化日期</strong>:此处日期和可用时间，<strong class="ig hi">汇总</strong>:逐时汇总，<strong class="ig hi">每日汇总</strong>:当日汇总，<strong class="ig hi">降水类型</strong>:降水类型(无论是雪还是雨)，<strong class="ig hi">温度</strong>，<strong class="ig hi">视在温度</strong>:人类感知的温度当量，<strong class="ig hi">湿度</strong>:空气中的水汽量，<strong class="ig hi">风速，风向:</strong></p><p id="de6b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，让我们看一下程序概述:</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kk"><img src="../Images/ceff3e335b7ac1a57b5262f4556ea612.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mDpqzBlzljeHy6YWMFaGTQ.png"/></div></div></figure><p id="ce8b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我们需要做预处理来去除数据集的噪声。大多数情况下，缺失值、异常值或异常值是数据集中出现噪声的原因。此后加载数据集时，我们将首先处理缺失值。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="c160" class="kq kr hh km b fi ks kt l ku kv">import warnings<br/>warnings.filterwarnings('ignore')<br/>import os<br/>import numpy as np<br/>import pandas as pd<br/>import scipy.stats as stats<br/>from matplotlib import pyplot as plt<br/>%matplotlib inline<br/>import sklearn<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.linear_model import LinearRegression<br/>import tensorflow as tf<br/>from tensorflow import keras<br/>from sklearn import preprocessing<br/>import pandas as pd</span><span id="e753" class="kq kr hh km b fi kw kt l ku kv">#Mount the drive<br/>from google.colab import drive<br/>drive.mount('/content/drive')</span><span id="6b10" class="kq kr hh km b fi kw kt l ku kv">#loading the dataset<br/>df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/weatherHistory.csv')<br/>df.head(10)</span><span id="98f6" class="kq kr hh km b fi kw kt l ku kv">#checking if there any null or NAN value<br/>df.isnull().any() </span></pre><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es kx"><img src="../Images/16d1a4e946598d34cd4c1d7b528748ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hfMAl3TWMzMQpeeQVipZ8Q.png"/></div></div></figure><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es ky"><img src="../Images/5f851160cb597f2589c9a7306f9e112f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UsTfmp7Qz6zbB65490drPg.png"/></div></div></figure><p id="b6cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里precip类型中有缺失值，这些值的数量很少考虑到整个数据集。整个数据集中缺少的数量是0.536%，因此我们可以使用下面的代码删除这些行。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="7d62" class="kq kr hh km b fi ks kt l ku kv">df = df.dropna()<em class="kz">#drop all nan</em></span></pre><p id="10cf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">之后，我们将删除重复如下。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es la"><img src="../Images/7fdeb0fb4ec7fc018090dc08c21ddf36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OsdukP5A5MPj-cmnNIwPpA.png"/></div></div></figure><p id="de4d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里你可以看到压力有异常值，但当我检查时，有1288个零值，所以它是一个异常值。如果值不仅远离正态分布，而且只有很少一部分应该在那里，我们就认为它们是异常值。</p><p id="2fd6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们将检查是否有可用的异常值或异常值。当谈到异常时，大多数时候我们需要添加一个类别，但这里湿度和压力值为0是不可接受的。可以看出，它们是误读，在湿度中，只有22个数据点的值为零。所以，我决定放弃这几行。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="f143" class="kq kr hh km b fi ks kt l ku kv">#Removing humidity 0 rows<br/>X.drop(X[X['Humidity'] == 0].index, inplace = <strong class="km hi">True</strong>)</span></pre><p id="6e14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当谈到压力时，它有1288个数据点，零值可用。因为百分比不低于0.5%，我们不能放弃它。这里我认为压力值0是一个缺失值，因为压力值0是一个不可接受的值。所以我决定用最小百分位值0.1%来代替它们</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es lb"><img src="../Images/5edfcd3ecf924311d006351cda72382a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ovKF1aKD0SJATGeJ44tVCA.png"/></div></div></figure><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="915a" class="kq kr hh km b fi ks kt l ku kv">fig, axes = plt.subplots(1,2)<br/>plt.tight_layout(0.2)<br/>print("Previous Shape : ",X.shape)<br/>sns.boxplot(X['Pressure (millibars)'],orient='v',ax=axes[0])<br/>axes[0].title.set_text("Before")<br/>Q1 = X["Pressure (millibars)"].quantile(0.10)<br/>Q3 = X["Pressure (millibars)"].quantile(0.95)<br/>print(Q1,Q3)<br/>IQR = Q3-Q1<br/>print(IQR)<br/>lower_limit = Q1 - 1.5*IQR<br/>upper_limit = Q3 + 1.5*IQR<br/>print(lower_limit,upper_limit)</span><span id="9861" class="kq kr hh km b fi kw kt l ku kv">X['Pressure (millibars)'] = np.where(X['Pressure (millibars)']&gt;upper_limit,upper_limit,X['Pressure (millibars)'])</span><span id="9cec" class="kq kr hh km b fi kw kt l ku kv">X['Pressure (millibars)'] = np.where(X['Pressure (millibars)']&lt;lower_limit,lower_limit,X['Pressure (millibars)'])</span><span id="1a60" class="kq kr hh km b fi kw kt l ku kv">print("Shape After :", X.shape)<br/>sns.boxplot(X['Pressure (millibars)'],orient='v',ax=axes[1])<br/>axes[1].title.set_text("After")<br/>plt.show()</span></pre><p id="24f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于下面提到的原因，我们将放弃这些值。</p><p id="50b0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">大声覆盖:整个数据集只有一个值</p><p id="15d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">格式化日期:对于每个数据行都是唯一的</p><p id="a191" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每日汇总:可以根据汇总属性导出</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="8819" class="kq kr hh km b fi ks kt l ku kv">X=X.drop([ 'Daily Summary','Loud Cover','Formatted Date'], axis = 1)</span></pre><p id="4011" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后我们在这里进行编码，主要有两种编码方式。</p><ol class=""><li id="d574" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated">标签编码</li><li id="f24b" class="lc ld hh ig b ih ll il lm ip ln it lo ix lp jb lh li lj lk bi translated">一个热编码</li></ol><p id="b377" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">标签编码</strong>是指将标签转换成数字形式，从而转换成机器可读的形式。</p><div class="jc jd ez fb je jf"><a href="https://www.geeksforgeeks.org/ml-label-encoding-of-datasets-in-python/" rel="noopener  ugc nofollow" target="_blank"><div class="jg ab dw"><div class="jh ab ji cl cj jj"><h2 class="bd hi fi z dy jk ea eb jl ed ef hg bi translated">Python - GeeksforGeeks中数据集的ML |标签编码</h2><div class="jm l"><h3 class="bd b fi z dy jk ea eb jl ed ef dx translated">在机器学习中，我们通常处理包含一列或多列多个标签的数据集…</h3></div><div class="jn l"><p class="bd b fp z dy jk ea eb jl ed ef dx translated">www.geeksforgeeks.org</p></div></div><div class="jo l"><div class="lq l jq jr js jo jt ju jf"/></div></div></a></div><p id="9aee" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个热编码</p><p id="ff68" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">移除整数编码变量，并为每个唯一的整数值添加新的二进制变量。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es lr"><img src="../Images/fcd992782fa18c4bee6055286a3dc383.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nw4KFF5BTwr8NOr1-aey8g.png"/></div></div></figure><p id="130c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，我使用了一个热点编码，当谈到标签编码时，它不适合线性模型，因为数字可以被解释为具有顺序，并且模型可以假设线性关系。同时，如果我们对有许多类别的属性使用一键编码，由于它有许多虚拟变量，这是不合适的，并且这会引入冗余信息。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="e627" class="kq kr hh km b fi ks kt l ku kv">def encode_features(before_coding):<br/>encoded_df_1 = pd.get_dummies(before_coding['Summary'])<br/>encoded1 = pd.concat([before_coding,encoded_df_1],axis=1)<br/>encoded_df_2 = pd.get_dummies(before_coding['Precip Type'])<br/>encoded2 = pd.concat([before_coding,encoded_df_2],axis=1)<br/>df_new=pd.concat([encoded1,encoded2.iloc[:,-2:]],axis=1)<br/>coded_df = df_new.drop(['Summary','Precip Type'],axis=1)<br/>return coded_df</span><span id="2951" class="kq kr hh km b fi kw kt l ku kv">X = encode_features(X)</span></pre><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es ls"><img src="../Images/e2c057b20aeb3be2b8fcc290e08eff8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fAMEFGZIAy5zqURgH_WcSw.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">编码后</figcaption></figure><p id="0173" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">移除缺失值和异常后，我们需要分割数据集。这里这样做的原因是为了避免数据泄漏。假设我们有一个数据集，我们获得了99%的准确率，但当我们在真实世界的数据中测试它时，它失败了。当我们在不分割数据集和单独应用的情况下进行标准化、转换和裂缝提取等预处理技术时，就会发生这种情况。这将影响性能的水平。因此，在本例中，我们将首先分成80%的训练数据集和20%的测试数据集。如下面的代码所示。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="4169" class="kq kr hh km b fi ks kt l ku kv">target_column = pd.DataFrame(X['Apparent Temperature (C)'])</span><span id="b260" class="kq kr hh km b fi kw kt l ku kv">X = X.drop(['Apparent Temperature (C)'], axis='columns')</span><span id="c3bd" class="kq kr hh km b fi kw kt l ku kv">X_train, X_test, y_train, y_test = train_test_split(X, target_column, test_size=0.2)</span></pre><p id="f402" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我们查看箱线图、Q-Q图或直方图时，可以看到湿度是左偏的，风速是右偏的。我们总是喜欢正态分布而不是偏态分布。在方框中也可以看到它们是倾斜的。</p><p id="469c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">什么是左斜或右斜？</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es lt"><img src="../Images/6d3efee2b33186f5013683f3f076f77b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1196/format:webp/1*q9PqE45aEriZERCwc_fXhw.png"/></div></figure><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es lu"><img src="../Images/a7c8060824b6973bd3e7a01b07b550b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RMlL-tMmp98QMqMGivPHDA.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">移除异常值和异常值后的箱线图</figcaption></figure><figure class="jw jx jy jz fd ka er es paragraph-image"><div class="er es lv"><img src="../Images/9e26c8e517c44eef06ef88815a109942.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/format:webp/1*1o_EZL89fJo58ij7fNt9ew.png"/></div></figure><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es lw"><img src="../Images/8b2f9f051e7de2add52565da39630a00.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f7ym9t3stbgSRfNKE25pLQ.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">非分类变量直方图</figcaption></figure><p id="22fb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了解决这个问题，我们可以使用转换。这里，对于湿度和能见度(左偏)，我们可以使用exp，对于风速(右偏)，我们可以使用对数变换或sqrt变换。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="71e2" class="kq kr hh km b fi ks kt l ku kv">#Do the  trasnformations for required features</span><span id="28a1" class="kq kr hh km b fi kw kt l ku kv">from sklearn.preprocessing import FunctionTransformer<br/>X = df.copy()<br/>#Righ skewed transformation</span><span id="4ad2" class="kq kr hh km b fi kw kt l ku kv">sqrt_transformer = FunctionTransformer(np.sqrt)<br/>data_new = sqrt_transformer.transform(X['Wind Speed (km/h)'])<br/>X['Wind Speed (km/h)']=data_new</span><span id="6882" class="kq kr hh km b fi kw kt l ku kv">#left skewed tranformation<br/>exp_transformer = FunctionTransformer(np.exp)<br/>data_new1 = exp_transformer.transform(X['Humidity'])<br/>X['Humidity']=data_new1</span><span id="424a" class="kq kr hh km b fi kw kt l ku kv">expo_transformer = FunctionTransformer(np.exp)data_new1 = expo_transformer.transform(X['Visibility (km)'])<br/>X['Visibility (km)']=data_new1</span><span id="2036" class="kq kr hh km b fi kw kt l ku kv">X.hist()</span></pre><p id="1ffc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">转换后，直方图如下所示</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es lx"><img src="../Images/0adc15f2adc19d8267220165e82e698b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qc5Fd8oKlmykpewfM29Psw.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">变换后的直方图</figcaption></figure><h2 id="da4b" class="kq kr hh bd ly lz ma mb mc md me mf mg ip mh mi mj it mk ml mm ix mn mo mp mq bi translated">标准化</h2><p id="8c35" class="pw-post-body-paragraph ie if hh ig b ih mr ij ik il ms in io ip mt ir is it mu iv iw ix mv iz ja jb ha bi translated">然后我们将标准化数据集的非分类变量。我们这样做是为了使数据内部一致和规范化。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="137a" class="kq kr hh km b fi ks kt l ku kv">from sklearn.preprocessing import StandardScaler</span><span id="1d1d" class="kq kr hh km b fi kw kt l ku kv">noncategoricaldata =  ['Temperature (C)','Humidity','Wind Speed (km/h)','Wind Bearing (degrees)','Visibility (km)','Pressure (millibars)']</span><span id="b286" class="kq kr hh km b fi kw kt l ku kv">standardization = StandardScaler()<br/>standardization.fit(X[noncategoricaldata])<br/>X_Scaled=standardization.transform(X[noncategoricaldata])<br/>X[noncategoricaldata] = X_Scaled</span></pre><p id="15a0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">标准化后的数据集如下图所示</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es mw"><img src="../Images/027c9456ce93ddcb9f92a8d21851a623.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BEbSlC4tsU2YAV6_f1AR4A.png"/></div></div></figure><p id="cd0d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">标准化后的箱线图和直方图如下</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es mx"><img src="../Images/41c518d1eacda665f7062d15d423f471.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nlR-BnPzxiE0eaoujwrT1A.png"/></div></div></figure><p id="32c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，我们可以专注于对风向进行离散化，因为它与风向有关，当我们考虑360度时，我们知道主要有8个方向。因此，我们可以将面元大小设置为8，并将连续值转换为离散值，使其平滑且易于理解。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="d06e" class="kq kr hh km b fi ks kt l ku kv"># create the scaler object<br/>scaler = StandardScaler()<br/>data1 = pd.DataFrame(X3_train, columns=['Wind Bearing (degrees)'])</span><span id="2000" class="kq kr hh km b fi kw kt l ku kv">data1 = data1.dropna()<br/>data2 = pd.DataFrame(Y3_test, columns=['Wind Bearing (degrees)'])<br/>data2 = data2.dropna()</span><span id="f8e9" class="kq kr hh km b fi kw kt l ku kv"># fit the scaler to the  data</span><span id="fa0c" class="kq kr hh km b fi kw kt l ku kv">discretizer = KBinsDiscretizer(n_bins=8, encode='ordinal', strategy='uniform')<br/>discretizer.fit(data1)</span><span id="9b59" class="kq kr hh km b fi kw kt l ku kv">_discretize1 = discretizer.transform(data1)<br/>_discretize2 = discretizer.transform(data2)<br/>X_dis = pd.DataFrame(_discretize1)<br/>Y_dis = pd.DataFrame(_discretize2)<br/>X_dis.hist()</span></pre><p id="46a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们将使用特征提取技术，如降维和相关矩阵。谈到降维，我们可以删除冗余数据，保留对训练模型有用的相关信息。为此，我们可以使用不同的技术，如PCA，SVG。在这里，我将使用主成分分析，这是众所周知的主成分分析(PCA)。这里实际发生的是增加可解释性，同时最小化信息损失。它通过创建新的不相关变量来实现方差的连续最大化。</p><p id="3a00" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，通过使用训练数据集，我们分析维度，然后根据这些维度转换训练数据集和测试数据集。这里，我使用主成分分析将维度最小化到11。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="767c" class="kq kr hh km b fi ks kt l ku kv">from sklearn.decomposition import PCA<br/>from sklearn.preprocessing import StandardScaler<br/>pca = PCA(n_components=11)<br/>pca.fit(X1_train)<br/>X_train_pca = pca.transform(X1_train)<br/>X_test_pca = pca.transform(Y1_test)<br/></span></pre><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es my"><img src="../Images/0fea14d79aff3bc8bb4543e51b00fcfe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8f9XYI6iXEjEDmaYQzHJ2Q.png"/></div></div></figure><p id="3d93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是主成分分析的协方差矩阵。</p><p id="4269" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最大化总扩散=最小化重建误差</p><p id="e142" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果我们可以最小化重建误差，那么我们可以进行降维，因为这个动作的损失是低的。当我们考虑每个属性的主成分分析方差比时，如果它低于该维度，则不符合数据的主要分布。因此，移除这些维度不会有太大影响，并且这些维度的重建误差很低。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="b374" class="kq kr hh km b fi ks kt l ku kv">pca.explained_variance_ratio_</span></pre><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es mz"><img src="../Images/9983fe1790e6cfea9fdb7f4616e39ec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sqF0MQo-Z0ZdeMfEWgnY4w.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">主成分分析比率</figcaption></figure><p id="8c76" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，为了决定我们需要的维数，我们将从最高比率增加到最低比率，直到我们得到一个大于90%的值</p><p id="2ecb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">那么我们可以认为90%的数据细节都可以在这些维度上获得</p><p id="5e9d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">另一种特征提取技术是相关矩阵。它将给出每两个属性之间的关联。如果有高度相关的属性，我们需要删除它们。正如你们所看到的，没有任何属性与另一个属性有更高的相关性。其具有高度接近颜色1.0。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es na"><img src="../Images/c3bb88d471e9960422de91587ff53e0e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1362/format:webp/1*ZQgt9gz3fIDmBd2rRXIQtQ.png"/></div></div></figure><p id="6fbd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里，当有两个维度时，举个例子，如果我们决定得到目标，因为湿度和温度以及表观温度是特征，那么我们可以看到表观温度和温度是高度相关的。然后，我们可以删除其中一个，检查删除它是否对模型有影响，并决定删除它。</p><p id="685c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当谈到显著性矩阵时，正如您在下面看到的，我们在本例中将目标“表观温度”包括在相关矩阵中。如果与目标相关的矩阵值接近于零。然后，根据我们减少维度的要求，我们可以删除它，因为它们不会影响目标值。</p><pre class="jw jx jy jz fd kl km kn ko aw kp bi"><span id="4497" class="kq kr hh km b fi ks kt l ku kv">d_data = standardized_df_train.copy()<br/>d_data['Apparent Temperature (C)'] = train_y<br/>d_data.head(10)<br/>print(d_data.corr())<br/>sns.heatmap(d_data.corr(),annot=True)</span></pre><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es nb"><img src="../Images/445ad63a1bcb872d2d58db95732c0ef1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z7bnTizpdPjeVwESoIyQ7w.png"/></div></div></figure><p id="035a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当谈到线性回归时，它所做的是模拟标量响应和一个或多个解释变量之间的关系。这里我们给出了数据集，并检验线性模型是否能准确预测测试值。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es nc"><img src="../Images/6787c338487700b730ab20d8d40f89e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_0Dl3fmcxtmH4-nKv2F0tQ.png"/></div></div></figure><p id="46ec" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是逻辑回归方程。人口斜率被称为权数。当权重较低且准确度较高且均方误差较低时。我们可以把它作为一个好的模型。具有99%的准确度和较大的权重可能是过度拟合模型的结果。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es nd"><img src="../Images/4eb05313d421e2339ef6a0f32f0f8bae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ynI0dMzH_xae_H-60kmLhw.png"/></div></div></figure><p id="2d37" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">均方误差(MSE)被广泛地用作确定算法性能的度量。均方差是目标值和预测值之差的平方的平均值。</p><figure class="jw jx jy jz fd ka er es paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="er es ne"><img src="../Images/5dcdb9141dc8f9fe430e8a4f630317f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XmsXmJ_amF0vpFDtQhB0ZQ.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">MSE方程</figcaption></figure><p id="8cd1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里yi是真值，其他yi帽子是预测值。当它更低时，模型变得更好。</p><p id="9fa8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">RMSE:均方根误差，这里指的是预测误差的标准差。意思是“数据点离回归线有多远”。</p><p id="77fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">RMSE应该小于0到1。那就好了。</p><p id="aff9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型的准确性是正确预测的百分比。在这个模型中，准确率为97%。</p><p id="d00e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">希望你了解了应用线性回归模型的步骤。谢谢你。</p></div></div>    
</body>
</html>