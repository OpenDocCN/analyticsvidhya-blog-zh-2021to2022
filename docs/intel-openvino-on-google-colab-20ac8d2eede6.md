# Google Colab ä¸Šçš„è‹±ç‰¹å°” OpenVINO

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/intel-openvino-on-google-colab-20ac8d2eede6?source=collection_archive---------6----------------------->

è‹±ç‰¹å°”çš„ OpenVINO å‘è¡Œç‰ˆä½¿ ***äººå·¥æ™ºèƒ½æ¨ç†*** å˜å¾—å¿«é€Ÿè€Œç®€å•ã€‚æ¨ç†åŸºæœ¬ä¸Šæ˜¯æ¨¡å‹è·å¾—äº†æ‰€æœ‰æ•™è‚²(è®­ç»ƒ)å¹¶éœ€è¦é€šè¿‡åŸºäºå…¶èƒ½åŠ›æ¨æ–­æ–°ä¿¡æ¯æ¥ç‚«è€€çš„é˜¶æ®µã€‚

![](img/0971412ac4a65d113bd7b1a81cad10ea.png)

æ¥æº:[https://software . Intel . com/content/www/us/en/develop/tools/open vino-toolkit . html](https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html)

OpenVINO æ¡†æ¶ä½¿å¾—è·¨å„ç§æ¶æ„çš„æ¨æ–­å’Œéƒ¨ç½²å˜å¾—éå¸¸å®¹æ˜“ã€‚æ›´å¤šå…³äºæ¡†æ¶çš„[åœ¨è¿™é‡Œ](https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit.html)ã€‚

æœ¬æ•™ç¨‹å°†æ•™ä½ å¦‚ä½•åœ¨ Google Colab ä¸Šæµ‹è¯• OpenVINO çš„èƒ½åŠ›ã€‚

# ä¸€èˆ¬æ¥è¯´ï¼Œä½¿ç”¨ OpenVINO çš„æ­¥éª¤æ˜¯:

â€”ä½¿ç”¨æ¥è‡ª [**è‹±ç‰¹å°”æ¨¡å‹åŠ¨ç‰©å›­**](https://github.com/IntelAI/models) çš„ ***é¢„è®­ç»ƒæ¨¡å‹*** æˆ–ä½¿ç”¨æ‚¨è‡ªå·±çš„ ***æ¨¡å‹(æ„å»º)***

â€”ä½¿ç”¨æ¨ç†å¼•æ“ç”Ÿæˆ xml å’Œ bin æ–‡ä»¶(ä¼˜åŒ–)

â€”ä½¿ç”¨æ‚¨é¦–é€‰çš„ç¯å¢ƒè¿›è¡Œéƒ¨ç½²

# ä½¿ç”¨ Google Colab éƒ¨ç½²

é¦–å…ˆï¼Œæˆ‘ä»¬å°†å…³æ³¨ç¬¬ä¸‰æ­¥ã€‚è¿™é‡Œï¼Œ**å‡è®¾**æ‚¨å·²ç»æœ‰äº† xml å’Œ bin æ–‡ä»¶ã€‚æˆ‘åœ¨æˆ‘çš„å­˜å‚¨åº“ä¸­æ·»åŠ äº†ä¸€äº›ç”¨äºè‹±ç‰¹å°”é¢„è®­ç»ƒæ¨¡å‹çš„ xml å’Œ bin æ–‡ä»¶ã€‚è¯·éšæ„ä½¿ç”¨:[https://github . com/jojo 96/Intel-open vino-colab/tree/main/models](https://github.com/jojo96/intel-openvino-colab/tree/main/models)

**å®‰è£…åº“:**

![](img/2a75e67747b40e9f6c2d5132d86a882c.png)

**è¿›è¡Œå¿…è¦çš„å¯¼å…¥:**

![](img/a199783d254a0cab2381f1f49545e0b8.png)

**è·å–å¯æ‰§è¡Œç½‘ç»œ:**

![](img/aa41d2928099e245a5e2dd9fd8067190.png)

**æ¨æ–­æ—¶é—´:**

![](img/2f367159ff0a32225e7857c073cda99b.png)

**TLDR** > >ä½¿ç”¨æœ¬ç¬”è®°æœ¬:[**https://github . com/jojo 96/Intel-open vino-colab/blob/main/notebooks/all models . ipynb**](https://github.com/jojo96/intel-openvino-colab/blob/main/notebooks/AllModels.ipynb)

# ä¸€äº›ä½¿ç”¨æ¡ˆä¾‹:

è¿™é‡Œç”¨åˆ°çš„æ‰€æœ‰ xml å’Œ bin æ–‡ä»¶éƒ½å¯ä»¥åœ¨æˆ‘çš„ repo:[https://github . com/jojo 96/Intel-open vino-colab/tree/main/models](https://github.com/jojo96/intel-openvino-colab/tree/main/models)

**å¹´é¾„æ£€æµ‹ç¤ºä¾‹:**

**å¹´é¾„-æ€§åˆ«-è¯†åˆ«-é›¶å”®-0013** :è¿™ç§ç»è¿‡é¢„å…ˆè®­ç»ƒçš„è‹±ç‰¹å°”æ¨¡å‹èƒ½å¤Ÿæ£€æµ‹å‡º[18â€“75]å¹´é¾„ç»„çš„äººã€‚ä¸‹é¢çš„ä»£ç ç‰‡æ®µå†³å®šäº†*ä¸€ä¸ªäººçš„å¹´é¾„ã€‚*

![](img/f61ddf0a955d19c3a7e464da391d9331.png)

æ¥æº:[https://github . com/openvinotoolkit/open _ model _ zoo/tree/master/models/Intel/age-gender-recognition-retail-0013](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/age-gender-recognition-retail-0013)

```
#age detection age-gender-recognition-retail-0013en = load_IR_to_IE('age.xml')import cv2
image = cv2.imread('age1.png')**#input image for age prediction**
resized = cv2.resize(image, (62,62), interpolation = cv2.INTER_AREA)from torchvision import transforms
tran = transforms.ToTensor()  # Convert the numpy array or PIL.Image #read image to (C, H, W) Tensor format and /255 normalize to [0, #1.0]
img_tensor = tran(resized)
img_tensor = img_tensor.unsqueeze_(0)res = synchronous_inference(en, img_tensor)
cv2_imshow(cv2.imread('age1.png'))**#input image for age prediction**
print("age is:"+str(round(res['age_conv3'][0][0][0][0]*100)))
```

![](img/353ed6b0e244f5961f7a5f1d19d20ea8.png)

è¾“å‡º

**æƒ…æ„Ÿæ£€æµ‹ç¤ºä¾‹(å‹å·:** [**æƒ…æ„Ÿ-è¯†åˆ«-é›¶å”®-0003**](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/emotions-recognition-retail-0003) **):**

![](img/e228694d52dbcde071a0f81dbfa022cf.png)

æ¥æº:[https://github . com/openvinotoolkit/open _ model _ zoo/tree/master/models/Intel/emotions-recognition-retail-0003](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/emotions-recognition-retail-0003)

```
#emotion detection emotions-recognition-retail-0003en = load_IR_to_IE('**emo.xml**')import cv2
image = cv2.imread('angry.jpg')**#input image for emotion prediction**
resized = cv2.resize(image, (64,64), interpolation = cv2.INTER_AREA)from torchvision import transforms
tran = transforms.ToTensor()  # Convert the numpy array or PIL.Image #read image to (C, H, W) Tensor format and /255 normalize to [0, #1.0]
img_tensor = tran(resized)
img_tensor = img_tensor.unsqueeze_(0)res = synchronous_inference(en, img_tensor)
cv2_imshow(cv2.imread('angry.jpg'))**#input image for emotion #prediction**print(res)
```

ç»“æœ:åŒ…å« 5 ä¸ªæƒ…æ„Ÿæ¦‚ç‡æµ®ç‚¹æ•°çš„æ•°ç»„ï¼Œé¡ºåºä¸º:( **0:ä¸­æ€§ï¼Œ1:å¿«ä¹ï¼Œ2:æ‚²ä¼¤ï¼Œ3:æƒŠè®¶ï¼Œ4:æ„¤æ€’**)

**è½¦è¾†æ£€æµ‹ç¤ºä¾‹(å‹å·:** [**è½¦è¾†-å±æ€§-è¯†åˆ«-æŠ¤æ -0039**](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/vehicle-attributes-recognition-barrier-0039) **):**

![](img/360677ed9c987c65a40d2ffdc4b83f08.png)

æ¥æº:[https://github . com/openvinotoolkit/open _ model _ zoo/tree/master/models/Intel/vehicle-attributes-recognition-barrier-0039](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/vehicle-attributes-recognition-barrier-0039)

```
#vehicle detectionen = load_IR_to_IE('vehicle.xml')import cv2
image = cv2.imread('truck.jpg')**#input image for vehicle prediction**
resized = cv2.resize(image, (72,72), interpolation = cv2.INTER_AREA)from torchvision import transformstran = transforms.ToTensor() 
img_tensor = tran(resized)
img_tensor = img_tensor.unsqueeze_(0)res = synchronous_inference(en, img_tensor)cv2_imshow(cv2.imread('truck.jpg'))**#input image for #vehicle prediction**print(res)
```

ç‚¹å‡»æ­¤å¤„æŸ¥çœ‹æ•´ä¸ªç¬”è®°æœ¬:

# å¥–é‡‘

è€¶ï¼ä½ å·²ç»èµ°åˆ°è¿™ä¸€æ­¥äº†ã€‚ä¸€ä»½å°ç¤¼ç‰©ğŸ€

å› æ­¤ï¼Œä¸‹é¢çš„ç¬”è®°æœ¬å¯ä»¥ç”¨äºä»[è‹±ç‰¹å°”æ¨¡å‹åŠ¨ç‰©å›­](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel)çš„æ¨¡å‹ç”Ÿæˆ xml å’Œ bin æ–‡ä»¶ã€‚æœ‰ä¸€ä¸ªå®Œæ•´çš„ä¾‹å­å±•ç¤ºäº† xml å’Œ bijn æ–‡ä»¶çš„ç”Ÿæˆå’Œé¢„æµ‹ã€‚

*å‚è€ƒèµ„æ–™:è¿™é‡Œå¾ˆå¤šä»£ç éƒ½æ˜¯ç”±*[*https://github.com/alihussainia/openvino-colab*](https://github.com/alihussainia/openvino-colab)ä¿®æ”¹æ”¹ç¼–è€Œæ¥