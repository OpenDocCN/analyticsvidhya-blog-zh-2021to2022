<html>
<head>
<title>Optimize Hyperparameters with GridSearch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GridSearch优化超参数</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/optimize-hyperparameters-with-gridsearch-d351b0fd339d?source=collection_archive---------5-----------------------#2021-05-07">https://medium.com/analytics-vidhya/optimize-hyperparameters-with-gridsearch-d351b0fd339d?source=collection_archive---------5-----------------------#2021-05-07</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/ffe8a0c980fc04d6016e57dbfa46acd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*uDjUb7eY-yBN5wA7ymWsYA.jpeg"/></div></figure><p id="395c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这篇博客中，我们将介绍什么是超参数，它们如何与网格搜索相联系，然后介绍一个使用网格搜索优化我们的模型的<a class="ae jj" href="https://github.com/Lewis34cs/gridsearch_blog" rel="noopener ugc nofollow" target="_blank">示例笔记本</a>。</p><h1 id="f0ff" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">什么是超参数？</h1><p id="f346" class="pw-post-body-paragraph il im hh in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">超参数是其值不能从数据中确定的参数。超参数的值必须在模型经历其学习过程之前设置。例如，在RandomForestClassifier模型中，一些超参数包括:n_estimators、criterion、max_depth、mn_samples_split等。(有关参数的完整列表，请访问Sci-kit Learn的RandomForestClassifier模型页面<a class="ae jj" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" rel="noopener ugc nofollow" target="_blank">此处</a>)。</p><p id="5ecf" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">出于这个博客的目的，我们不会深入每个超参数的细节。超参数非常重要，因为它们直接控制训练算法的行为，并对被训练模型的性能有重大影响。每个超参数可以接受不同数量的值。例如，<strong class="in hi"> n_estimators </strong>可以接受任何整数，而<strong class="in hi">标准</strong>只能接受“基尼”或“熵”。剩下的问题是，我们如何为我们的模型选择最佳超参数，以产生最佳结果？</p><h1 id="4008" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">输入GridSearch</h1><p id="6110" class="pw-post-body-paragraph il im hh in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">网格搜索是一种工具，它为我们指定的每个超参数组合建立一个模型，并评估每个模型，以查看哪个超参数组合创建了最佳模型。我们不必手动选择参数，我们可以提供一个字典，其中的键是超参数名称，值是我们想要为该参数尝试的值的列表。假设我们想要计算出<strong class="in hi"> n_estimators </strong>的最佳数量和<strong class="in hi">criterion</strong>的最佳值，应该是这样的:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="4557" class="kw jl hh ks b fi kx ky l kz la"># example<br/>param_grid = {<br/>'n_estimators': [10, 20, 50, 100],<br/>'criterion': ['gini', 'entropy']<br/>} </span></pre><p id="d9b9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi"> param_grid </strong>字典将包含我们想要为模型调整的每个超参数，以及该超参数的不同输入列表。</p><h1 id="7649" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">安装</h1><p id="e659" class="pw-post-body-paragraph il im hh in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">我们将在本博客中使用的数据集将是Sci-kit Learn的乳腺癌数据集。如果你想在笔记本上跟随，你可以在这里找到它！首先，我们将导入必要的库:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="e9fb" class="kw jl hh ks b fi kx ky l kz la"># Importing first libraries<br/>import pandas as pd<br/>from sklearn.datasets import load_breast_cancer</span></pre><p id="0b38" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">接下来，我们设置数据:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="6b65" class="kw jl hh ks b fi kx ky l kz la"># Setting the variable 'dataset' to hold the Bunch object<br/># (special kind of dictionary)<br/>dataset = load_breast_cancer()</span><span id="f084" class="kw jl hh ks b fi lb ky l kz la"># Creating variables to reference the target and feature columns<br/>features = dataset.data<br/>target = dataset.target</span></pre><p id="4474" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果我们想进一步探索数据，我们可以创建一个数据框架来保存特性和目标！</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="127a" class="kw jl hh ks b fi kx ky l kz la"># Creating a dataframe to hold the feature columns<br/>df = pd.DataFrame(features)</span><span id="9a9c" class="kw jl hh ks b fi lb ky l kz la"># Accessing the Bunch object (dataset) to provide feature names for # the feature columns in our dataframe<br/>df.columns = dataset.feature_names</span><span id="8149" class="kw jl hh ks b fi lb ky l kz la"># Adding the target to our dataframe by creating the 'target' column<br/>df['target'] = target</span></pre><p id="9efb" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">从这里我们可以尽情探索！让我们继续查看数据帧的前5行:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="9076" class="kw jl hh ks b fi kx ky l kz la">df.head()</span></pre><figure class="kn ko kp kq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ld le di lf bf lg"><div class="er es lc"><img src="../Images/77f6d55cc647dae43ee1e858cf39ff6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MfvjU7aBD_J1cJo8yleS4Q.jpeg"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">查看前5行</figcaption></figure><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="29e0" class="kw jl hh ks b fi kx ky l kz la">df.isna().sum()</span></pre><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es ll"><img src="../Images/55aaa02860099b25a98575f8080b1476.png" data-original-src="https://miro.medium.com/v2/resize:fit:602/format:webp/1*8mp6emf4_G3Th1BPcNqtpg.jpeg"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">确保数据中没有缺失值</figcaption></figure><p id="1c5d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们将快速交换类别，使恶性类别为1，良性类别为0。我们可以通过创建一个小函数，然后将该函数应用于dataframe的目标列来实现。请注意，我们不需要这样做，我只是希望将恶性类设置为1。</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="51f9" class="kw jl hh ks b fi kx ky l kz la">def convert_class(num):<br/>   return abs(num — 1)</span></pre><p id="5ee9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在我们简单地将函数应用于数据帧:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="68e2" class="kw jl hh ks b fi kx ky l kz la">converted_target = df[‘target’].apply(convert_class)<br/>df['target'] = converted_target</span></pre><p id="0b40" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，让我们继续查看班级分布情况:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="7673" class="kw jl hh ks b fi kx ky l kz la"># Setting labels for plot<br/>labels ='Benign=0   |   ' + 'Malignant=1'</span><span id="55e5" class="kw jl hh ks b fi lb ky l kz la"># Viewing number of patients within each class<br/>sns.countplot(x=df[‘target’])<br/>plt.title(‘Class Distribution’)<br/>plt.xlabel(labels);</span></pre><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es lm"><img src="../Images/3caa0103ce89b03d3e2145b6824e10f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*4LQxywHfutjP244Ftkauuw.jpeg"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">查看班级分布</figcaption></figure><h1 id="0a21" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">随机森林分类器信息</h1><p id="78fd" class="pw-post-body-paragraph il im hh in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">因为我们在这篇博客中使用了RandomForestClassifier模型，所以让我们来看看这个模型的一些基本细节:</p><ol class=""><li id="e0a8" class="ln lo hh in b io ip is it iw lp ja lq je lr ji ls lt lu lv bi translated">随机森林模型没有任何假设</li><li id="d564" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji ls lt lu lv bi translated">数字数据不需要缩放</li><li id="df72" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji ls lt lu lv bi translated">缺失数据会影响Sci-kit学习模型</li><li id="708b" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji ls lt lu lv bi translated">对异常值稳健</li></ol><p id="5521" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">与线性和逻辑回归等其他模型不同，随机森林模型对数据没有任何假设。这意味着我们不需要担心要素之间的多重共线性或残差是否呈正态分布。用于训练随机森林模型的数据不需要缩放，但是如果数据被缩放，也不会对模型产生负面影响。因为我们将使用来自Sci-kit Learn的RandomForest分类器，所以我们需要确保数据集中没有丢失数据。请注意，RandomForest模型的一些其他版本不需要对缺失数据进行任何预先处理。这个模型对异常值是健壮的，所以我们不需要担心定位和删除任何异常值。</p><h2 id="0c97" class="kw jl hh bd jm mb mc md jq me mf mg ju iw mh mi jy ja mj mk kc je ml mm kg mn bi translated">RandomForest的一些缺点</h2><ul class=""><li id="ce82" class="ln lo hh in b io ki is kj iw mo ja mp je mq ji mr lt lu lv bi translated">不预测连续输出(用于回归)</li><li id="897e" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji mr lt lu lv bi translated">不会预测超出训练集中值的范围</li><li id="e09e" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji mr lt lu lv bi translated">偏向有几个类别的分类变量</li><li id="f7e6" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji mr lt lu lv bi translated">在多类问题上偏向更频繁的类</li></ul><p id="dfe0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">由于我们专注于二进制分类，并且在我们的特征中使用严格的数字数据，所以我们不需要担心RandomForest的缺点。以下是一些优点。</p><h2 id="57a9" class="kw jl hh bd jm mb mc md jq me mf mg ju iw mh mi jy ja mj mk kc je ml mm kg mn bi translated">RandomForest的优势</h2><ul class=""><li id="e3c3" class="ln lo hh in b io ki is kj iw mo ja mp je mq ji mr lt lu lv bi translated">可解释性</li><li id="eca9" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji mr lt lu lv bi translated">渲染特征重要性</li><li id="b5b7" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji mr lt lu lv bi translated">需要更少的数据预处理</li><li id="0bdf" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji mr lt lu lv bi translated">(理论上)不要过度拟合</li><li id="9050" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji mr lt lu lv bi translated">良好的性能/准确性</li><li id="b09e" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji mr lt lu lv bi translated">抗噪声能力强</li><li id="9fe0" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji mr lt lu lv bi translated">几乎不需要任何参数调整</li><li id="480e" class="ln lo hh in b io lw is lx iw ly ja lz je ma ji mr lt lu lv bi translated">适用于几乎任何机器学习问题</li></ul><p id="2bf0" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果你对RandomForests有任何问题，欢迎在下面的评论中提问或给我发电子邮件！现在，我们将进入博客的主菜。</p><h1 id="768a" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">创建训练集和测试集</h1><p id="c04b" class="pw-post-body-paragraph il im hh in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">这是重要的一步，我们必须始终确保至少创建一个训练集和测试集——否则，我们如何知道我们的模型是否过度拟合数据？先来导入Sci-kit Learn的train_test_split:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="6e29" class="kw jl hh ks b fi kx ky l kz la">from sklearn.model_selection import train_test_split</span></pre><p id="a1ce" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们可以输入我们的特征和目标来创建训练集和测试集:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="7a4b" class="kw jl hh ks b fi kx ky l kz la">X = df.drop(columns=‘target’)<br/>y = df[‘target’]</span><span id="83b0" class="kw jl hh ks b fi lb ky l kz la">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)</span></pre><h1 id="02ee" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">基线模型</h1><p id="36b7" class="pw-post-body-paragraph il im hh in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">基线模型的目的是，你猜对了，设置基线性能！它本质上是陈述一个人盲目猜测职业的准确性。我们创建和评估基线模型的原因是为了确定与基线模型相比，我们的实际模型改进了多少。要设置它，我们需要导入一些东西:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="5053" class="kw jl hh ks b fi kx ky l kz la">from sklearn.dummy import DummyClassifier<br/>from sklearn.metrics import plot_confusion_matrix, classification_report</span></pre><p id="83e7" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在让我们创建DummyClassifier模型:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="ed94" class="kw jl hh ks b fi kx ky l kz la"># Creating and fitting our dummy classifier to train set<br/>dummy = DummyClassifier(strategy='stratified')<br/>dummy.fit(X_train, y_train)</span><span id="40e6" class="kw jl hh ks b fi lb ky l kz la"># Creating our y_pred variable off of test features<br/>y_pred = dummy.predict(X_test)</span><span id="2093" class="kw jl hh ks b fi lb ky l kz la"># Printing out the classification report<br/>print(classification_report(y_test, y_pred))</span></pre><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es ms"><img src="../Images/c174598656de7d76d547e87b683c3809.png" data-original-src="https://miro.medium.com/v2/resize:fit:1054/format:webp/1*bt7jK52kG9AehCKWVfLzMA.jpeg"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">DummyClassifier的分类报告</figcaption></figure><p id="81f1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请记住，<strong class="in hi">0级是良性的</strong>，而<strong class="in hi">1级是恶性的</strong>。由于我们正在处理一个涉及癌症的数据集，准确性不是最重要的分数。我们希望确保我们不会告诉某人他们没有患癌症，而事实上他们患了癌症。由于我们想要极低的假阴性率，我们的焦点是恶性类别的<strong class="in hi">召回分数</strong>。在这里，我们看到DummyClassifier对恶性分类的召回率为24%。让我们看看我们是否能改善这一点！</p><h1 id="45cb" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">制作类别权重字典</h1><p id="c86b" class="pw-post-body-paragraph il im hh in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">因为我们的类是不平衡的，所以我们可以制作一个类权重字典来输入到模型中，以帮助模型进一步区分类，方法是针对不正确的猜测对模型进行更严厉的惩罚。我们可以通过导入以下内容进行设置:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="d86e" class="kw jl hh ks b fi kx ky l kz la">from sklearn.utils import class_weight</span></pre><p id="3ee9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">既然我们已经导入了Sci-kit Learn的class_weight，我们现在可以创建一个字典来保存我们的类权重！</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="6ef8" class="kw jl hh ks b fi kx ky l kz la"># A array object that contains the weights for both classes<br/>class_weights = class_weight.compute_class_weight(‘balanced’, classes=np.unique(y_train), y=y_train)</span><span id="7b45" class="kw jl hh ks b fi lb ky l kz la"># A dictionary object containing key-value pairs of both classes and # their weights<br/>class_weights_dict = {0: class_weights[0], 1: class_weights[1]}<br/>print(f”Our class weights:\n{class_weights_dict}”)</span></pre><h1 id="35e5" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">实例化RandomForestClassifier</h1><p id="9b39" class="pw-post-body-paragraph il im hh in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">我们已经快到GridSearch了——我们现在需要做的就是实例化我们的模型，创建一个超参数网格，其中包含我们想要研究的每个超参数的值范围，然后将它与GridSearchCV对象相匹配。让我们从创建模型开始:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="b223" class="kw jl hh ks b fi kx ky l kz la"># Importing necessary library to create our model<br/>from sklearn.ensemble import RandomForestClassifier</span><span id="7c50" class="kw jl hh ks b fi lb ky l kz la"># Creating our model and passing in the class weights<br/>forest = RandomForestClassifier(class_weight=class_weights_dict)</span></pre><h1 id="295b" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">超参数网格</h1><p id="95e3" class="pw-post-body-paragraph il im hh in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">现在让我们创建我们的网格！这个网格将是一个字典，其中的键是我们要关注的超参数的名称，值将是包含特定超参数可以接受的不同值的列表。</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="ec64" class="kw jl hh ks b fi kx ky l kz la"># Creating a dictionary called params to hold our grid<br/>params = {<br/>‘n_estimators’: [10, 25, 50, 100, 200], <br/>‘criterion’: [‘gini’, ‘entropy’], <br/>‘max_depth’: [3, 5, 10, 15, 20, 25, None], <br/>‘min_samples_leaf’: [1, 2, 5, 10]<br/>}</span></pre><p id="a2e1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated"><strong class="in hi">重要提示</strong>:注意你选择在gridsearch中评估多少不同的超参数，以及列表中的值的数量。gridsearches的一个缺点是运行时间长…如果我们有一个大的数据集，这将需要非常长的时间(我以前运行过超过8个小时的gridsearches)。</p><h1 id="d34c" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">设置GridSearchCV</h1><p id="e8e4" class="pw-post-body-paragraph il im hh in b io ki iq ir is kj iu iv iw kk iy iz ja kl jc jd je km jg jh ji ha bi translated">现在我们已经创建了一个模型和一个网格，我们最终可以创建一个GridSearchCV对象并使它适合我们的训练数据！首先让我们导入必要的库:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="9a35" class="kw jl hh ks b fi kx ky l kz la">from sklearn.model_selection import GridSearchCV</span></pre><p id="130c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">接下来，我们将创建GridSearchCV的一个实例:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="0165" class="kw jl hh ks b fi kx ky l kz la">clf = GridSearchCV(estimator=forest, param_grid=params, scoring=’recall’, cv=5)</span></pre><p id="603e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">注意上面，我们为<strong class="in hi">估计器</strong>提供了我们的模型，为<strong class="in hi"> param_grid </strong>提供了我们的超参数网格，选择了<strong class="in hi">评分</strong>来关注召回，并保留<strong class="in hi"> cv </strong>为默认整数5。CV是交叉验证，它决定了交叉验证拆分策略中的折叠数。</p><p id="25ac" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在让我们让GridSearchCV对象适合我们的训练集:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="d580" class="kw jl hh ks b fi kx ky l kz la"># fitting clf to train set<br/>clf.fit(X_train, y_train)</span></pre><p id="7d2d" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">请注意，这可能需要相当长的时间，具体取决于参数的数量、每个参数要尝试的值的数量以及我们使用的数据量。拟合完成后，我们可以通过调用以下命令来查看最佳参数:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="d390" class="kw jl hh ks b fi kx ky l kz la">best_params = clf.best_params_<br/>print(best_params)</span></pre><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es mt"><img src="../Images/8697ee9cc6328fe0b6c015cbf86cf04f.png" data-original-src="https://miro.medium.com/v2/resize:fit:484/format:webp/1*7MbHZBa534CU-EgXJ4TLaw.jpeg"/></div></figure><p id="3d42" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们已经根据提供的值计算出了所选超参数的最佳值，我们将创建一个使用这些超参数值的新随机森林模型。我们不必根据网格搜索手动输入每个参数的最佳值。相反，我们可以通过在<strong class="in hi"> best_params </strong>前添加两个星号来轻松地将<strong class="in hi"> best_params </strong>字典解包到新模型中，如下所示:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="31b0" class="kw jl hh ks b fi kx ky l kz la"># unpacking the best_params into our new model<br/>best_forest = RandomForestClassifier(**best_params, class_weight=class_weights_dict)</span></pre><p id="53af" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在，我们已经创建了具有最佳参数的模型，让我们将它与训练数据进行拟合:</p><pre class="kn ko kp kq fd kr ks kt ku aw kv bi"><span id="0f9f" class="kw jl hh ks b fi kx ky l kz la"># Fitting our model to the train set<br/>fit_forest = best_forest.fit(X_train, y_train)</span><span id="94ae" class="kw jl hh ks b fi lb ky l kz la"># Creating predicted variables to compare against y_test<br/>y_pred = fit_forest.predict(X_test)</span><span id="1bc7" class="kw jl hh ks b fi lb ky l kz la"># making classification report and confusion matrix<br/>print(classification_report(y_test, y_pred))<br/>plot_confusion_matrix(fit_forest, X_test, y_test, normalize=’true’, cmap=’Reds’)</span></pre><figure class="kn ko kp kq fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/b301b3b2a9a296b430d258128642d4a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1070/format:webp/1*ae6qlC4I1v4kY-OaTRpq0A.jpeg"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">最优模型的分类报告和混淆矩阵</figcaption></figure><p id="4b5b" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">简而言之，这是如何网格搜索模型的超参数的基本方法，以便为网格中的每个指定参数找到最佳值。请记住，gridsearch中的键、值和数据越多，grid search完成彻底搜索所需的时间就越长。在这篇博客中，我们只对RandomForestClassifier的几个超参数进行了基本的网格搜索。笔记本的链接可以在<a class="ae jj" href="https://github.com/Lewis34cs/gridsearch_blog" rel="noopener ugc nofollow" target="_blank">这里</a>找到。我希望你喜欢，随时联系，如果你有任何问题！</p></div></div>    
</body>
</html>