<html>
<head>
<title>AutoEncoders with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">带TensorFlow的自动编码器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/autoencoders-with-tensorflow-2f0a7315d161?source=collection_archive---------4-----------------------#2021-01-24">https://medium.com/analytics-vidhya/autoencoders-with-tensorflow-2f0a7315d161?source=collection_archive---------4-----------------------#2021-01-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="0da3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自动编码器是无监督的神经网络模型，旨在学习用较少的参数表示多维数据。数据压缩算法早已为人所知，然而，学习将数据映射到较低维度的非线性操作是自动编码器对文献的贡献。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/23cbc5057a29ad9cce095be32b14add9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ViBG49eTCKqqO2UVRL9mEw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">自动编码器的一般方案(图取自[1])</figcaption></figure><h2 id="0a2f" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">介绍</h2><p id="7e90" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">自动编码器提供了一种非常基本的方法，通过去除冗余来提取数据中最重要的特征。当数据集的多个部分(. csv文件中的一列或图像数据集中的一个像素位置)相互之间高度相关时，就会出现冗余。在这种情况下，仅保持其中一列或忽略除一列之外的相关像素将允许我们以可接受的信息损失存储相同的数据。</p><p id="82ae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在图像压缩领域，最受欢迎的技术之一是JPEG算法，该算法采用了<em class="ks">离散余弦变换</em> [2]和线性变换，该变换在简单的整数舍入后产生一个主要由零占据的图像矩阵。基本上，只保存非零元素而忽略其余的元素将创建一个具有更少参数的数据表示。应用变换的逆变换将几乎没有损失地重建相同的图像。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es kt"><img src="../Images/18af1d5c8320c86f7460d11036bd4535.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*32BOM5UIO28mpvwoHqdqAg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">JPEG管道(图取自[3])</figcaption></figure><p id="2e00" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">利用离散余弦变换和应用某种线性变换的想法背后有一种数学直觉，但是我们不能确保这是最好的映射。JPEG是一个很好的算法，今天仍然被广泛使用，但是如果我们提出一个模型，学习特定于相关数据的更好的映射，会怎么样呢？自动编码器正是通过学习参数压缩和重建数据来做到这一点的。根据输入数据和重建数据，该损失定义为<em class="ks">重建损失</em>，通常为<a class="ae ku" href="https://afteracademy.com/blog/what-are-l1-and-l2-loss-functions" rel="noopener ugc nofollow" target="_blank"> L1或【L2】损失。</a></p><p id="c406" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Gallinari &amp; LeCun等人[4]于1987年提出了使用自动编码器对数据进行去噪的想法，这是利用<a class="ae ku" href="https://igi-web.tugraz.at/lehre/NNB/SS10/Lecture_Hopfield_nets.pdf" rel="noopener ugc nofollow" target="_blank">联想记忆</a>完成任务的Hoplied网络的替代方案[5]。如今，自动编码器不仅广泛用于去噪和压缩，还用于数据生成。</p><h2 id="d264" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">一个简单的张量流自动编码器</h2><p id="33a6" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">实际上，自动编码器并不是新颖的神经网络，这意味着它们没有一个自身具有独特属性的架构。相反，自动编码器结构是使用其他类型模块(全连接层、卷积层、复制、裁剪等)的流水线。)互相跟随。根据数据和任务的性质，模型的复杂性是灵活的。在本文中，我们将在<a class="ae ku" href="http://yann.lecun.com/exdb/mnist/" rel="noopener ugc nofollow" target="_blank"> MNIST数据集</a>上构建并测试一个具有全连接层的简单自动编码器。</p><p id="9cb8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于一个简单的实现，TensorFlow 后端上的<a class="ae ku" href="https://www.tensorflow.org/api_docs/python/tf/keras" rel="noopener ugc nofollow" target="_blank"> Keras API优先于</a><a class="ae ku" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> Google Colab </a> GPU服务。</p><p id="a800" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，导入所需的库。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="cef3" class="js jt hh kw b fi la lb l lc ld">import tensorflow as tf<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from tensorflow.keras import datasets, layers, models, losses, Modelfrom random import randint</span></pre><p id="b02e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ks">数据</em> </strong></p><p id="8213" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">MNIST的数据可以在Keras上获得，只需一行代码就可以在几秒钟内导入。由于模型的目的将是学习如何重建数据，这是一项无人监督的任务，或者用一个我喜欢的更好的术语来说，它是自我监督的。因此，在加载数据时，标签不是必需的，也不会被存储。</p><p id="d0a0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练集有60000个，测试集有10000个28×28大小的单通道图像。该测试集将用于培训期间的验证。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="946a" class="js jt hh kw b fi la lb l lc ld">(x_train, _), (x_test, _)=tf.keras.datasets.mnist.load_data()</span></pre><p id="35db" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ks">编码器</em> </strong></p><p id="b455" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，图像将被展平成具有784 (28乘28)个元素的向量。然后，在具有100个神经元的隐藏层之后，编码器的输出将具有20个参数。这被称为数据的潜在表示。如果模型训练成功，它将能够仅用20个数字来表示MNIST图像。这是我们压缩数据的阶段，数据被命名为<em class="ks">瓶颈层</em>。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="f4bd" class="js jt hh kw b fi la lb l lc ld">hidden_size = 100<br/>latent_size = 20</span><span id="ada2" class="js jt hh kw b fi le lb l lc ld">input_layer = layers.Input(shape = x_train.shape[1:])</span><span id="2a83" class="js jt hh kw b fi le lb l lc ld">flattened = layers.Flatten()(input_layer)<br/>hidden = layers.Dense(hidden_size, activation = 'relu')(flattened)<br/>latent = layers.Dense(latent_size, activation = 'relu')(hidden)<br/>encoder = Model(inputs = input_layer, outputs = latent, name = 'encoder')</span><span id="1817" class="js jt hh kw b fi le lb l lc ld">encoder.summary()</span></pre><p id="c9aa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">不一定要包括隐藏层，但是试探性地增加几层会增加编码器的表示能力。为完全连接的层选择ReLU激活。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="fa9c" class="js jt hh kw b fi la lb l lc ld">Model: "encoder" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= input_1 (InputLayer)         [(None, 28, 28)]          0          _________________________________________________________________ flatten (Flatten)            (None, 784)               0          _________________________________________________________________ dense (Dense)                (None, 100)               78500      _________________________________________________________________ dense_1 (Dense)              (None, 20)                2020       ================================================================= Total params: 80,520 Trainable params: 80,520 Non-trainable params: 0</span></pre><p id="3f38" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ks">解码器</em> </strong></p><p id="4607" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">解码器旨在通过反向操作撤销编码器所做的操作。这意味着，潜在变量将分别被上采样到100和784。最后，向量将被整形为图像矩阵。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="661c" class="js jt hh kw b fi la lb l lc ld">input_layer_decoder = layers.Input(shape = encoder.output.shape)<br/>upsampled = layers.Dense(hidden_size, activation = 'relu')(input_layer_decoder)<br/>upsampled = layers.Dense(encoder.layers[1].output_shape[-1], activation = 'relu')(upsampled)<br/>constructed = layers.Reshape(x_train.shape[1:])(upsampled)</span><span id="3dd5" class="js jt hh kw b fi le lb l lc ld">decoder = Model(inputs = input_layer_decoder, outputs = constructed, name= 'decoder')</span><span id="97d0" class="js jt hh kw b fi le lb l lc ld">decoder.summary()</span></pre><p id="f372" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，解码器的输入大小等于编码器的输出大小。同样，最终层的输出大小等于展平层的输出大小。上面你可以看到它是(<em class="ks">无，784) </em>。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="26e1" class="js jt hh kw b fi la lb l lc ld">Model: "decoder" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= input_2 (InputLayer)         [(None, None, 20)]        0          _________________________________________________________________ dense_2 (Dense)              (None, None, 100)         2100       _________________________________________________________________ dense_3 (Dense)              (None, None, 784)         79184      _________________________________________________________________ reshape (Reshape)            (None, 28, 28)            0          ================================================================= Total params: 81,284 Trainable params: 81,284 Non-trainable params: 0</span></pre><p id="b14f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> <em class="ks">自动编码器</em> </strong></p><p id="fa29" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">模型的计算图被构造成使得总输入是编码器的输入，总输出是解码器在处理编码器的输出时的输出。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="c31d" class="js jt hh kw b fi la lb l lc ld">autoencoder = Model(inputs = encoder.input, outputs = decoder(encoder.output))<br/>autoencoder.summary()</span><span id="02be" class="js jt hh kw b fi le lb l lc ld">Layer (type)                 Output Shape              Param #    ================================================================= input_1 (InputLayer)         [(None, 28, 28)]          0          _________________________________________________________________ flatten (Flatten)            (None, 784)               0          _________________________________________________________________ dense (Dense)                (None, 100)               78500      _________________________________________________________________ dense_1 (Dense)              (None, 20)                2020       _________________________________________________________________ decoder (Functional)         (None, 28, 28)            81284      ================================================================= Total params: 161,804 Trainable params: 161,804 Non-trainable params: 0</span></pre><p id="2655" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">损失是输入图像和重建图像之间的均方误差，即L2损失。该模型用64个样本的批次训练50个时期。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="c465" class="js jt hh kw b fi la lb l lc ld">autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())</span><span id="5c44" class="js jt hh kw b fi le lb l lc ld">history = autoencoder.fit(x_train, x_train, epochs=50, batch_size=64, validation_data = (x_test, x_test))</span><span id="522a" class="js jt hh kw b fi le lb l lc ld">Epoch 1/50 938/938 [==============================] - 3s 2ms/step - loss: 3085.7667 - val_loss: 1981.6154 <br/>Epoch 2/50 938/938 [==============================] - 2s 2ms/step - loss: 1917.1781 - val_loss: 1790.9906<br/>...<br/>Epoch 50/50 938/938 [==============================] - 2s 2ms/step - loss: 1456.5116 - val_loss: 1454.8712</span></pre><p id="1861" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于这不是一个分类示例，因此没有准确性度量，要跟踪的重要度量是损失。尽管1456可能看起来是一个很大的数字，但与最初的时期相比，误差的下降意味着一个学习阶段。此外，损失不是像<a class="ae ku" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html" rel="noopener ugc nofollow" target="_blank">F1-得分</a>的准确性那样的绝对指标，它应该根据上下文来评论。</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="4d73" class="js jt hh kw b fi la lb l lc ld">fig, axs = plt.subplots(figsize=(15,15))<br/>axs.plot(history.history['loss'])<br/>axs.plot(history.history['val_loss'])<br/>axs.title.set_text('Training Loss vs Validation Loss')<br/>axs.set_xlabel('Epochs')<br/>axs.set_ylabel('Loss')<br/>axs.legend(['Train','Val'])</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lf"><img src="../Images/e5369a6bd7b34e40daaca5460748edb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eOCf6JUxl_dVqgMhjBysig.png"/></div></div></figure><p id="0000" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，定性分析(目测)比定量分析更能提供模型成功的信息。首先，一些随机重建被可视化:</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="3011" class="js jt hh kw b fi la lb l lc ld">fig, axs = plt.subplots(3,2,figsize=(10,15))<br/>for i in range(3):<br/>  sample1 = x_train[randint(0,x_train.shape[0])]<br/>  axs[i][0].imshow(sample1, cmap = 'gray')<br/>  axs[i][1].imshow(autoencoder(np.expand_dims(sample1,0))[0], cmap = 'gray')</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lg"><img src="../Images/358e6acfdfcd1c32d3e5442e4c19d3e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*9Ru0IchcaVIFYsGLPfyCvw.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">重建结果(左侧为原始结果，右侧为重建结果)</figcaption></figure><p id="19e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如您所看到的，由于它是一个非常基本的自动编码器，因此发生了一些信息丢失，但是在大多数情况下，仍然有可能了解哪个数字受模型支配。</p><p id="dae7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个更有趣的视觉化想法是在潜在空间上玩耍并观察结果。每个图像首先被编码成大小为20的向量。如果我们取两个潜在向量的平均值，并将其传递给解码器，会发生什么？重建的图像会与两个原始数字相似吗？还是会出现一些完全没有意义的图像？此外，我们可以采用潜在变量的加权平均值，并可视化潜在向量中逐渐变化的影响:</p><pre class="jd je jf jg fd kv kw kx ky aw kz bi"><span id="4f8a" class="js jt hh kw b fi la lb l lc ld">sample1_idx = randint(0,x_train.shape[0])<br/>sample1 = x_train[sample1_idx]</span><span id="6b8e" class="js jt hh kw b fi le lb l lc ld">sample2_idx = randint(0,x_train.shape[0])<br/>sample2 = x_train[sample2_idx]</span><span id="fcce" class="js jt hh kw b fi le lb l lc ld">latent1 = encoder(np.expand_dims(sample1,0))<br/>latent2 = encoder(np.expand_dims(sample2,0))</span><span id="246f" class="js jt hh kw b fi le lb l lc ld">weights = np.arange(0.05,0.95,0.15)</span><span id="2a92" class="js jt hh kw b fi le lb l lc ld">fig, axs = plt.subplots(2,4,figsize=(20,10))<br/>axs = axs.ravel()</span><span id="871a" class="js jt hh kw b fi le lb l lc ld">axs[0].imshow(sample2, cmap = 'gray')<br/>axs[-1].imshow(sample1, cmap = 'gray')</span><span id="ea91" class="js jt hh kw b fi le lb l lc ld">for i in range(6):<br/>  latent = latent1*weights[i] + latent2*(1-weights[i])<br/>  constructed = decoder(latent)<br/>  axs[i+1].imshow(constructed[0], cmap='gray')</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lh"><img src="../Images/b9d5b9e739298816863b292229850078.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CI3Kc9FkVufz0ABER7PDJw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">从一个数字到另一个数字的逐渐变化</figcaption></figure><p id="fd99" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上图中，我们将两个潜在向量的加权重要性从95%-5%改为5%-95%。因此，重建图像首先类似于<em class="ks">【0】</em>。到了50%-50%就变得面目全非，既不是<em class="ks">【0】</em>，也不是<em class="ks">【1】</em>。最后，随着第二个潜在向量的重要性成为主导，解码器产生看起来像<em class="ks">“1”</em>的图像。</p><h2 id="cf39" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">autoencoder_tensorflow.ipynb</h2><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="li lj l"/></div></figure><h2 id="5439" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">结论</h2><p id="af38" class="pw-post-body-paragraph ie if hh ig b ih kn ij ik il ko in io ip kp ir is it kq iv iw ix kr iz ja jb ha bi translated">自动编码器通过学习高效的特定于数据的映射和减少维数，创建了一种压缩数据的替代方法。在MNIST的这篇文章中，由784个像素组成的图像已经由大小为20的向量表示并被重构回来。尽管结果并不完美，但仍然可以看出潜在向量保留了大部分信息，但丢失了细节。潜在变量所包含的信息决定了重构的成功与否。通过操纵潜在向量，有可能产生中间结果。</p><p id="44c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">希望你喜欢。在下面的自动编码器应用中再见。</p><p id="af80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最美好的祝愿…</p><p id="d3f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">mrgrhn</p><p id="9091" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">后续帖子，请访问:</p><div class="lk ll ez fb lm ln"><a href="https://mrgrhn.medium.com/convolutional-autoencoders-cae-with-tensorflow-97e8d8859cbe" rel="noopener follow" target="_blank"><div class="lo ab dw"><div class="lp ab lq cl cj lr"><h2 class="bd hi fi z dy ls ea eb lt ed ef hg bi translated">带张量流的卷积自动编码器(CAE)</h2><div class="lu l"><h3 class="bd b fi z dy ls ea eb lt ed ef dx translated">自动编码器在深度学习文献中已经存在很长时间了，最受欢迎的是数据压缩任务…</h3></div><div class="lv l"><p class="bd b fp z dy ls ea eb lt ed ef dx translated">mrgrhn.medium.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb jm ln"/></div></div></a></div><h2 id="f8cf" class="js jt hh bd ju jv jw jx jy jz ka kb kc ip kd ke kf it kg kh ki ix kj kk kl km bi translated">参考</h2><ol class=""><li id="d669" class="mc md hh ig b ih kn il ko ip me it mf ix mg jb mh mi mj mk bi translated">崇高，Jeremie &amp; Kalinicheva，叶卡捷琳娜。(2019).“利用深度学习技术进行变化检测的灾后损失自动绘图:东北海啸案例研究”。遥感。11.1123.10.3390/rs11091123。</li><li id="3b54" class="mc md hh ig b ih ml il mm ip mn it mo ix mp jb mh mi mj mk bi translated">NN，Ahmed &amp; Natarajan，T. &amp; Rao，Kamisetty。(1974).“离散余弦变换”。计算机，IEEE汇刊。C-23。90–93.10.1109</li><li id="7baf" class="mc md hh ig b ih ml il mm ip mn it mo ix mp jb mh mi mj mk bi translated">李树生、津田宏、张刚、许世生、罗福祥、李泰荣..(2020).“通过视频记录的取样云纹法进行动态变形测量及其在桥梁工程中的应用”。实验技术。44.10.1007/s 40799–019–00358–4。</li><li id="da68" class="mc md hh ig b ih ml il mm ip mn it mo ix mp jb mh mi mj mk bi translated">加利纳里，p .，勒昆，y .，蒂里亚，s .，，福格尔曼-苏利，F. (1987)。“备忘录联合发行”。认知程序87。巴黎，拉维莱特。</li><li id="c957" class="mc md hh ig b ih ml il mm ip mn it mo ix mp jb mh mi mj mk bi translated"><a class="ae ku" href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.536.3644&amp;rep=rep1&amp;type=pdf" rel="noopener ugc nofollow" target="_blank">https://citeseerx.ist.psu.edu/viewdoc/download?doi = 10 . 1 . 1 . 536 . 3644&amp;rep = rep 1&amp;type = pdf</a></li></ol></div></div>    
</body>
</html>