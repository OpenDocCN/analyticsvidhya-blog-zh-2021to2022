# æ–‡æœ¬åˆ†ç±»â€”ä»è¯è¢‹åˆ° BERT â€”ç¬¬ 4 éƒ¨åˆ†(å·ç§¯ç¥ç»ç½‘ç»œ)

> åŸæ–‡ï¼š<https://medium.com/analytics-vidhya/text-classification-from-bag-of-words-to-bert-part-4-convolutional-neural-network-53aa63941ade?source=collection_archive---------7----------------------->

![](img/370340608fa46dfb3b4b82edd97a4901.png)

åœ¨ [Unsplash](https://unsplash.com?utm_source=medium&utm_medium=referral) ä¸Šæ‹æ‘„çš„ [ThisisEngineering RAEng](https://unsplash.com/@thisisengineering?utm_source=medium&utm_medium=referral)

è¿™ä¸ªæ•…äº‹æ˜¯ä¸€ç³»åˆ—æ–‡æœ¬åˆ†ç±»çš„ä¸€éƒ¨åˆ†â€”â€”ä»è¯è¢‹åˆ° BERT åœ¨åä¸ºâ€œ [*æœ‰æ¯’è¯„è®ºåˆ†ç±»æŒ‘æˆ˜â€*](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) ***çš„ Kaggle æ¯”èµ›ä¸Šå®æ–½å¤šç§æ–¹æ³•ã€‚*** åœ¨è¿™åœºæ¯”èµ›ä¸­ï¼Œæˆ‘ä»¬é¢ä¸´çš„æŒ‘æˆ˜æ˜¯å»ºç«‹ä¸€ä¸ªå¤šå¤´æ¨¡å‹ï¼Œèƒ½å¤Ÿæ£€æµ‹ä¸åŒç±»å‹çš„æ¯’æ€§ï¼Œå¦‚*å¨èƒã€æ·«ç§½ã€ä¾®è¾±å’ŒåŸºäºèº«ä»½çš„ä»‡æ¨ã€‚å¦‚æœä½ è¿˜æ²¡çœ‹è¿‡ä¹‹å‰çš„æŠ¥é“ï¼Œé‚£å°±å»çœ‹çœ‹å§*

[ç¬¬ä¸€éƒ¨åˆ†(BagOfWords)](https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-1e628a2dd4c9)

[ç¬¬äºŒéƒ¨åˆ†(Word2Vec)](https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-part-2-word2vec-35c8c3b34ee3)

[ç¬¬ä¸‰éƒ¨åˆ†(å¿«é€Ÿæ–‡æœ¬)](https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-part-3-fasttext-8313e7a14fce)

åœ¨ä¹‹å‰çš„æ•…äº‹ä¸­([ç¬¬ä¸‰éƒ¨åˆ†(fastText)](https://anirbansen3027.medium.com/text-classification-from-bag-of-words-to-bert-part-3-fasttext-8313e7a14fce) )ï¼Œæˆ‘ä»¬ä½¿ç”¨äº† fastText åº“æ¥ç”Ÿæˆå¥å­çš„åµŒå…¥ä»¥åŠè¾“å‡ºå˜é‡çš„å¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»ã€‚

åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Keras åº“(TensorFlow ä¸Šçš„ä¸€ä¸ªåŒ…è£…å™¨)ä¸ºå¤šæ ‡ç­¾æ–‡æœ¬åˆ†ç±»åˆ›å»ºä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œ(CNN)ã€‚æˆ‘ä»¬è¿˜å°†çœ‹çœ‹æ¨¡å‹çš„ä¸€äº›èƒŒæ™¯å·¥ä½œã€‚

# ***ç›´è§‰***

***æ€ä¹ˆå¼€å§‹çš„ï¼Ÿ***CNN æœ€æ—©æ˜¯ç”± Yann LeCun åœ¨ 20 ä¸–çºª 80 å¹´ä»£æå‡ºçš„ï¼Œç”¨æ¥è¯†åˆ«æ‰‹å†™æ•°å­—ã€‚ä½† ConvNets ä»ç„¶å¤„äºè§‚æœ›çŠ¶æ€ï¼Œå› ä¸ºä»–ä»¬é¢ä¸´ç€ä¸€ä¸ªä¸¥é‡çš„é—®é¢˜ï¼Œå³éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºæ¥æœ‰æ•ˆåœ°å¤„ç†å¤§å‹å›¾åƒã€‚

2012 å¹´ï¼ŒAlexNet è¡¨æ˜ï¼Œä¹Ÿè®¸æ˜¯æ—¶å€™é‡æ–°å®¡è§†æ·±åº¦å­¦ä¹ äº†ï¼Œå› ä¸ºå®ƒå·²ç»èµ¢å¾—äº†å„ç§æ¯”èµ›ã€‚å¤§å‹æ•°æ®é›†å’Œå¤§é‡è®¡ç®—èµ„æºçš„å¯ç”¨æ€§ä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿåˆ›å»ºå¤æ‚çš„ CNNï¼Œå¯ä»¥æ‰§è¡Œä»¥å‰ä¸å¯èƒ½å®Œæˆçš„è®¡ç®—æœºè§†è§‰ä»»åŠ¡ã€‚

***ä»€ä¹ˆæ˜¯ CNNï¼Ÿ***

![](img/b08de85915ea06039a2a2ff0367b0349.png)

[http://www.jetir.org/papers/JETIR2004207.pdf](http://www.jetir.org/papers/JETIR2004207.pdf)

åœ¨ä¸Šå›¾æ‰€ç¤ºçš„ ConvNet ä¸­æœ‰å››ç§ä¸»è¦æ“ä½œ:

***1ã€‚å·ç§¯***

![](img/4f8aba34507c05537424961c7763b984.png)

[https://miro . medium . com/max/1920/1 * D6iRfzDkz-sezyjyovz 73w . gif](https://miro.medium.com/max/1920/1*D6iRfzDkz-sEzyjYoVZ73w.gif)

è¿™ä¸€å±‚æ˜¯ CNN çš„å¿ƒè„ã€‚CNN ä½¿ç”¨ç‰¹å¾æ˜ å°„/æ ¸æ¥å­¦ä¹ è¾“å…¥çš„ç‰¹å¾ã€‚ä¾‹å¦‚ï¼Œå›¾åƒä¸­çš„æ ¸[[1ï¼Œ0ï¼Œ-1]ï¼Œ[1ï¼Œ0ï¼Œ-1]ï¼Œ[1ï¼Œ0ï¼Œ-1]]æ£€æµ‹å›¾åƒä¸­çš„å‚ç›´çº¿ã€‚ç¥å¥‡çš„æ˜¯æˆ‘ä»¬ä¸éœ€è¦æŒ‡å®šå†…æ ¸ã€‚æˆ‘ä»¬åªéœ€è¦æåˆ°å†…æ ¸çš„æ•°é‡ï¼Œæ¨¡å‹å°±ä¼šè‡ªå·±å­¦ä¹ å†…æ ¸ï¼Œå°±åƒæ™®é€šäººå·¥ç¥ç»ç½‘ç»œä¸­çš„æƒé‡ä¸€æ ·ã€‚æ€»ä½“æ€è·¯æ˜¯ï¼Œéšç€ Conv å’Œæ± å›¾å±‚æ•°é‡çš„ä¸æ–­å¢åŠ ï¼Œæ¨¡å‹èƒ½å¤Ÿæ£€æµ‹çš„å¤æ‚è¦ç´ ä¹Ÿè¶Šå¤šã€‚ç¬¬ä¸€å±‚è¯†åˆ«ç®€å•çš„ä¸œè¥¿ï¼Œå¦‚çº¿æ¡/é¢œè‰²ï¼Œéšåçš„å±‚è¯†åˆ«æ›´å¤æ‚çš„å›¾æ¡ˆã€‚

***2ã€‚éçº¿æ€§***

![](img/0d04568397a5229f0a9150155feb63f3.png)

[https://machine learning knowledge . ai/Activation-Functions-Neural-Network/# Why _ we _ needle _ Activation _ Functions _ in _ Neural _ Network](https://machinelearningknowledge.ai/activation-functions-neural-network/#Why_we_need_Activation_Functions_in_Neural_Network)

æ²¡æœ‰æ¿€æ´»å‡½æ•°çš„ ANN å±‚å°†åªäº§ç”Ÿæ‰€æœ‰è¾“å…¥åŠå…¶æƒé‡ä¹‹é—´çš„ç‚¹ç§¯ä¹‹å’Œã€‚é€šè¿‡ä½¿ç”¨åˆé€‚çš„éçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥å¸®åŠ©ç¥ç»ç½‘ç»œç†è§£è¿™ç§éçº¿æ€§å…³ç³»ã€‚è¿™æ˜¯ä¸€ç¯‡å…³äº[åˆ›æ–°åŠŸèƒ½](https://machinelearningknowledge.ai/activation-functions-neural-network/#Why_we_need_Activation_Functions_in_Neural_Network)çš„æ·±åº¦åšå®¢ã€‚

åœ¨äºŒè¿›åˆ¶åˆ†ç±»é—®é¢˜çš„æƒ…å†µä¸‹ï¼Œåœ¨è¾“å‡ºç¥ç»å…ƒä¸­ä½¿ç”¨ *sigmoid* å‡½æ•°ï¼Œå°†è¾“å…¥ä¿¡å·è½¬æ¢ä¸º 0 åˆ° 1 çš„èŒƒå›´ï¼Œä»¥ä¾¿å°†å…¶è§£é‡Šä¸ºæ¦‚ç‡ã€‚

åœ¨éšè—å±‚ä¸­ï¼ŒReLU é€šå¸¸æ¯”å…¶ä»–å‡½æ•°æ›´å—æ¬¢è¿ï¼Œå› ä¸ºå®ƒè®­ç»ƒç¥ç»ç½‘ç»œçš„é€Ÿåº¦æ¯”å…¶ä»–å‡½æ•°å¿«å‡ å€ï¼Œè€Œä¸”ä¸ä¼šæ˜¾è‘—é™ä½æ³›åŒ–ç²¾åº¦ã€‚ReLU æˆ–æ•´æµçº¿æ€§å•å…ƒï¼Œåº”ç”¨éé¥±å’Œæ¿€æ´»å‡½æ•° f(x)=max(0ï¼Œx)ã€‚å®ƒä¹Ÿä¸ä¼šé­å—æ¶ˆå¤±çš„ç±»ä¼¼æ¢¯åº¦çš„ Sigmoid å’Œ Tanh æ¿€æ´»å‡½æ•°çš„ç°è±¡

***3ã€‚*** æ··åˆæŠ½æ ·æˆ–æ¬¡çº§æŠ½æ ·

![](img/41091c6f5393840d7fd3ff0b8141b29c.png)

[https://miro.medium.com/max/700/0*5xJdbktSufBcH7n5.gif](https://miro.medium.com/max/700/0*5xJdbktSufBcH7n5.gif)

æ± å›¾å±‚ç”¨äºå‡å°‘è¦ç´ åœ°å›¾çš„ç»´åº¦ã€‚å› æ­¤ï¼Œå®ƒå‡å°‘äº†è¦å­¦ä¹ çš„å‚æ•°æ•°é‡å’Œç½‘ç»œä¸­æ‰§è¡Œçš„è®¡ç®—é‡ã€‚æ±‡é›†å›¾å±‚æ±‡æ€»äº†ç”±å·ç§¯å›¾å±‚ç”Ÿæˆçš„è¦ç´ åœ°å›¾åŒºåŸŸä¸­çš„è¦ç´ ã€‚

è¿™é‡Œæœ‰ä¸€ä¸ªå…³äºå±‚ç±»å‹çš„æ·±åº¦åšå®¢[æ± ](https://www.machinecurve.com/index.php/2020/01/30/what-are-max-pooling-average-pooling-global-max-pooling-and-global-average-pooling/)å±‚

**4*ã€‚*åˆ†ç±»(å…¨è¿æ¥å±‚)**

æœ€åï¼Œåœ¨å‡ ä¸ªå·ç§¯å’Œæœ€å¤§æ± å±‚ä¹‹åï¼ŒNN ä¸­çš„é«˜çº§æ¨ç†é€šè¿‡å®Œå…¨è¿æ¥çš„å±‚æ¥å®Œæˆã€‚FC å±‚æ ¹æ®å‰å‡ å±‚æå–çš„ç‰¹å¾è¿›è¡Œåˆ†ç±»ã€‚é€šå¸¸ï¼Œè¿™ä¸€å±‚æ˜¯ä¼ ç»Ÿçš„äººå·¥ç¥ç»ç½‘ç»œï¼Œå®ƒå°†æƒé‡ä¸è¾“å…¥å’Œä¼ é€’æ¿€æ´»ç›¸ä¹˜ï¼Œä»¥ç»™å‡ºè¾“å‡º

å¯¹å®Œæ•´ä»£ç æ„Ÿå…´è¶£çš„äººï¼Œå¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°[ã€‚é‚£ä¹ˆè®©æˆ‘ä»¬æ·±å…¥ç ”ç©¶ä»£ç ğŸ‘¨â€ğŸ’»](https://www.kaggle.com/anirbansen3027/jtcc-cnn)

# **å®æ–½**

## ***1ã€‚è¯»å–æ•°æ®é›†***

![](img/0543de08e345f6b77adbe68a2a0922ba.png)

æé†’ä¸€ä¸‹ï¼Œè¿™æ˜¯è®­ç»ƒæ•°æ®çš„æ ·å­

## **â‘¡*ã€‚æ–‡æœ¬é¢„å¤„ç†***

æ–‡æœ¬æ•°æ®å¿…é¡»ç¼–ç ä¸ºæ•°å­—ï¼Œæ‰èƒ½ç”¨ä½œ ML/DL æ¨¡å‹çš„è¾“å…¥æˆ–è¾“å‡ºã€‚Keras åº“æä¾›äº†ä¸€äº›åŸºæœ¬å·¥å…·æ¥å¸®åŠ©æˆ‘ä»¬å‡†å¤‡æ–‡æœ¬æ•°æ®ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ Tokenizer ç±»ï¼Œè¿™æ˜¯ä¸€ä¸ªå®ç”¨ç¨‹åºç±»ï¼Œå…è®¸å¯¹æ–‡æœ¬è¯­æ–™åº“è¿›è¡ŒçŸ¢é‡åŒ–ï¼Œæ–¹æ³•æ˜¯å°†æ¯ä¸ªæ–‡æœ¬è½¬æ¢ä¸ºæ•´æ•°åºåˆ—æˆ–å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªæ ‡è®°çš„ç³»æ•°å¯ä»¥æ˜¯äºŒè¿›åˆ¶çš„ï¼ŒåŸºäºå­—æ•°ï¼ŒåŸºäº tf-idfã€‚è¿™å°†æ˜¯ä¸€ä¸ª 3 æ­¥æµç¨‹:

**1ã€‚åˆå§‹åŒ–è®°å·èµ‹äºˆå™¨ç±»**

*   é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ ‡ç‚¹ç¬¦å·éƒ½è¢«åˆ é™¤ï¼Œå°†æ–‡æœ¬è½¬æ¢ä¸ºç©ºæ ¼åˆ†éš”çš„å•è¯åºåˆ—(å•è¯å¯èƒ½åŒ…å«'å­—ç¬¦)ã€‚ç„¶åï¼Œè¿™äº›åºåˆ—è¢«åˆ†å‰²æˆè®°å·åˆ—è¡¨ã€‚ç„¶åå®ƒä»¬å°†è¢«ç´¢å¼•æˆ–çŸ¢é‡åŒ–ã€‚0 æ˜¯ç”¨äºå¡«å……çš„ä¿ç•™ç´¢å¼•ã€‚
*   æˆ‘ä»¬å°† num_words è®¾ç½®ä¸º MAX_NUM_WORDS (20000 ),è¿™æ˜¯åŸºäºè¯é¢‘è¦ä¿ç•™çš„æœ€å¤§å­—æ•°ã€‚åªä¼šä¿ç•™æœ€å¸¸è§çš„ num_words-1 ä¸ªå•è¯ã€‚

**2ã€‚è°ƒç”¨ fit_on_texts å‡½æ•°** â€”æ ¹æ®æ–‡æœ¬åˆ—è¡¨æ›´æ–°å†…éƒ¨è¯æ±‡

è¯¥æ–¹æ³•åŸºäºè¯é¢‘åˆ›å»ºè¯æ±‡ç´¢å¼•ã€‚æ‰€ä»¥å¦‚æœä½ ç»™å®ƒè¿™æ ·çš„è¯ï¼Œâ€œçŒ«ååœ¨å«å­ä¸Šã€‚â€å®ƒå°†åˆ›å»ºä¸€ä¸ªå­—å…¸ s . t . word _ index[" the "]= 1ï¼›word_index["cat"] = 2 å®ƒæ˜¯ word -> index å­—å…¸ï¼Œæ‰€ä»¥æ¯ä¸ªå•è¯éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„æ•´æ•°å€¼ã€‚æ‰€ä»¥è¾ƒå°çš„æ•´æ•°æ„å‘³ç€æ›´é¢‘ç¹çš„å•è¯(é€šå¸¸å‰å‡ ä¸ªæ˜¯åœç”¨è¯)ã€‚

**3ã€‚è°ƒç”¨ texts_to_sequences å‡½æ•°** â€”å°†æ–‡æœ¬ä¸­çš„æ¯ä¸ªæ–‡æœ¬è½¬æ¢ä¸ºä¸€ä¸ªæ•´æ•°åºåˆ—

æ‰€ä»¥å®ƒåŸºæœ¬ä¸Šæ˜¯å°†æ–‡æœ¬ä¸­çš„æ¯ä¸ªå•è¯æ›¿æ¢ä¸º word_index å­—å…¸ä¸­ç›¸åº”çš„æ•´æ•°å€¼ã€‚

*æ³¨æ„:* *åœ¨ fit_on_texts ä¹‹åï¼Œå®è´¨ä¸Šæ˜¯ä¸ºè¯æ±‡è¡¨åˆ›å»ºä¸€ä¸ª word_index çŸ©é˜µï¼Œæˆ‘ä»¬å¯ä»¥åšä¸¤ä»¶äº‹æƒ…ä¸­çš„ä»»ä½•ä¸€ä»¶*

*   *ä½¿ç”¨åµŒå…¥å±‚æ—¶ä½¿ç”¨çš„æ–‡æœ¬åºåˆ—*
*   *text_to_matrix å°†æ–‡æœ¬è½¬æ¢æˆä¸€ä¸ªå•è¯åŒ…*

```
#Initializing the class
tokenizer = Tokenizer(num_words = MAX_NUM_WORDS)
#Updates internal vocabulary based on a list of texts.
tokenizer.fit_on_texts(train_texts)
#Transforms each text in texts to a sequence of integers.
train_sequences = tokenizer.texts_to_sequences(train_texts)
test_sequences = tokenizer.texts_to_sequences(test_texts)
word_index = tokenizer.word_index
print(â€œLength of word Index:â€, len(word_index))
print(â€œFirst 5 elements in the word_index dictionary:â€, dict(list(word_index.items())[0: 5]) )
print(â€œFirst comment text in training set:\nâ€, train_sequences[0])
```

![](img/ef546c6029f2e5f75e03cbf20763c148.png)

æ—¢ç„¶æˆ‘ä»¬å·²ç»æ ‡è®°äº†æ³¨é‡Šæ–‡æœ¬ï¼Œæˆ‘ä»¬éœ€è¦å¡«å……å¥å­ä»¥ä½¿æ‰€æœ‰çš„å¥å­é•¿åº¦ç›¸ç­‰ã€‚

**ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Ÿ**æ·±åº¦å­¦ä¹ åº“å‡è®¾ä½ çš„æ•°æ®æ˜¯çŸ¢é‡åŒ–çš„è¡¨ç¤ºã€‚åœ¨å¯å˜é•¿åº¦åºåˆ—é¢„æµ‹é—®é¢˜çš„æƒ…å†µä¸‹ï¼Œè¿™è¦æ±‚æ‚¨çš„æ•°æ®è¢«è½¬æ¢ä¸ºæ¯ä¸ªåºåˆ—å…·æœ‰ç›¸åŒçš„é•¿åº¦ã€‚è¿™ç§çŸ¢é‡åŒ–å…è®¸ä»£ç é’ˆå¯¹æ‚¨é€‰æ‹©çš„æ·±åº¦å­¦ä¹ ç®—æ³•é«˜æ•ˆåœ°æ‰¹é‡æ‰§è¡ŒçŸ©é˜µè¿ç®—ã€‚

è¿™ä¹Ÿæ˜¯åœ¨è®¡ç®—æœºè§†è§‰ä¸­å®Œæˆçš„ï¼Œåœ¨è®¡ç®—æœºè§†è§‰ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸å€¾å‘äºå°†æ‰€æœ‰å›¾åƒçš„å¤§å°è°ƒæ•´åˆ°å›ºå®šçš„å¤§å°ï¼Œè¿™å°†æ˜¯ç¥ç»ç½‘ç»œçš„è¾“å…¥å¤§å°

```
#Pad tokenized sequences
trainvalid_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)
test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)
print(â€œShape of padded sequence list:\nâ€, trainvalid_data.shape)
print(â€œFirst comment text in training set â€” 0 for padding â€” only last 50 sequences as the rest are paddings:\nâ€, trainvalid_data[0][-50:])
```

![](img/1fa37c32677814963625e8c07696613d.png)

## *3ã€‚å®šä¹‰ 1D CNN æ¨¡å‹*

åœ¨ Keras ä¸­ï¼Œå®šä¹‰æ¨¡å‹æœ€ç®€å•çš„æ–¹æ³•æ˜¯å¯åŠ¨ä¸€ä¸ªé¡ºåºæ¨¡å‹ç±»ï¼Œå¹¶ä¸æ–­æ·»åŠ æ‰€éœ€çš„å±‚ã€‚åºåˆ—æ¨¡å‹æ˜¯ä¸€ä¸ªç®€å•çš„å±‚å †æ ˆï¼Œå…¶ä¸­æ¯ä¸€å±‚éƒ½æœ‰ä¸€ä¸ªè¾“å…¥å¼ é‡å’Œä¸€ä¸ªè¾“å‡ºå¼ é‡ã€‚

æ–‡æ¡£åˆ†ç±»çš„æ ‡å‡†æ¨¡å‹æ˜¯ä½¿ç”¨åµŒå…¥å±‚ä½œä¸ºè¾“å…¥ï¼Œæ¥ç€æ˜¯ 1D å·ç§¯ç¥ç»ç½‘ç»œã€æ± å±‚ï¼Œç„¶åæ˜¯é¢„æµ‹è¾“å‡ºå±‚ã€‚æˆ‘ä»¬ä½¿ç”¨äº† 1 ä¸ªåµŒå…¥å±‚ã€3 ç»„å·ç§¯å’Œæ± åŒ–å±‚ä»¥åŠ 2 ç»„å¯†é›†å±‚ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„åµŒå…¥(å¦‚ Word2Vec)æ¥ç”Ÿæˆå¤§å°ä¸ºè¯æ±‡*åµŒå…¥ç»´åº¦çš„åµŒå…¥çŸ©é˜µï¼Œæˆ–è€…è®­ç»ƒæ–°çš„åµŒå…¥ï¼Œå°†å…¶ä½œä¸ºè¾“å…¥å±‚ä¸å…¶ä»–æƒé‡ä¸€èµ·ä½¿ç”¨ã€‚

![](img/b7265e4a6457c9f4b5f751eb9f7b3f61.png)

**Conv1D**:CNN æ˜¯ä¸ºå›¾åƒåˆ†ç±»å¼€å‘çš„ï¼Œå…¶ä¸­æ¨¡å‹æ¥å—è¡¨ç¤ºå›¾åƒåƒç´ å’Œé¢œè‰²é€šé“çš„äºŒç»´è¾“å…¥ã€‚åŒæ ·çš„è¿‡ç¨‹å¯ä»¥åº”ç”¨äº 1D æ•°æ®åºåˆ—ã€‚è¯¥æ¨¡å‹ä»åºåˆ—æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œå¹¶æ˜ å°„åºåˆ—çš„å†…éƒ¨ç‰¹å¾ã€‚CNN è€ƒè™‘å•è¯çš„æ¥è¿‘åº¦æ¥åˆ›å»ºå¯è®­ç»ƒçš„æ¨¡å¼ã€‚å·ç§¯å±‚ä¸­çš„å†…æ ¸å¤§å°/é«˜åº¦å®šä¹‰äº†å½“å·ç§¯é€šè¿‡è¾“å…¥æ–‡æœ¬æ–‡æ¡£æ—¶è¦è€ƒè™‘çš„å•è¯æ•°ï¼Œæä¾›äº†åˆ†ç»„å‚æ•°ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œå®ƒå°†ä¸€æ¬¡è€ƒè™‘ 5 ä¸ªå•è¯ï¼Œè€Œåœ¨å›¾åƒä¸­ï¼Œå®ƒå°†ä¸€æ¬¡è€ƒè™‘ 2 ä¸ªå•è¯

æœ€å¤§æ± å±‚å°†åˆå¹¶å·ç§¯å±‚çš„è¾“å‡ºã€‚

æˆ‘ä»¬åœ¨è¾“å‡ºå±‚ä½¿ç”¨ sigmoid æ¿€æ´»ã€‚sigmoid å‡½æ•°ä¸ºæˆ‘ä»¬æä¾›äº†æ¯ä¸ªè¾“å‡ºèŠ‚ç‚¹çš„ 0 åˆ° 1 ä¹‹é—´çš„æ¦‚ç‡å¾—åˆ†ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨ softmaxï¼Œå®ƒä¼šç»™å‡ºè·¨è¾“å‡ºèŠ‚ç‚¹çš„æ¦‚ç‡åˆ†å¸ƒï¼ŒåŠ  1ã€‚

æ€»çš„æ¥è¯´ï¼Œ

*   å¯¹äºäºŒè¿›åˆ¶åˆ†ç±»ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ 1 ä¸ªè¾“å‡ºå•å…ƒï¼Œåœ¨è¾“å‡ºå±‚ä½¿ç”¨ sigmoid æ¿€æ´»ï¼Œå¹¶ä½¿ç”¨äºŒè¿›åˆ¶äº¤å‰ç†µæŸå¤±
*   å¯¹äºå¤šç±»åˆ†ç±»ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ N ä¸ªè¾“å‡ºå•å…ƒï¼Œåœ¨è¾“å‡ºå±‚ä½¿ç”¨ softmax æ¿€æ´»ï¼Œå¹¶ä½¿ç”¨åˆ†ç±»äº¤å‰ç†µæŸå¤±
*   å¯¹äºå¤šæ ‡ç­¾åˆ†ç±»ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰ N ä¸ªè¾“å‡ºå•å…ƒï¼Œåœ¨è¾“å‡ºå±‚ä½¿ç”¨ sigmoid æ¿€æ´»ï¼Œå¹¶ä½¿ç”¨äºŒè¿›åˆ¶äº¤å‰ç†µæŸå¤±

![](img/cacd2fb340f2b6aa5cf1c987fff4f7ab.png)

cnn _ model.summar çš„ç»“æœ

```
cnn_model = Sequential()
cnn_model.add(Embedding(MAX_NUM_WORDS, 128))
cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = â€œreluâ€))
cnn_model.add(MaxPooling1D(pool_size = 5))
cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = â€œreluâ€))
cnn_model.add(MaxPooling1D(pool_size = 5))
cnn_model.add(Conv1D(filters = 128, kernel_size = 5, activation = â€œreluâ€))
cnn_model.add(GlobalMaxPool1D())
cnn_model.add(Dense(units = 128, activation = â€˜reluâ€™))
cnn_model.add(Dense(units = 6, activation = â€˜sigmoidâ€™))
print(cnn_model.summary())
```

## 4.ç¼–è¯‘å¹¶æ‹Ÿåˆ CNN æ¨¡å‹

åœ¨å¼€å§‹è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹å…¶è¿›è¡Œé…ç½®ã€‚æˆ‘ä»¬éœ€è¦æåˆ°*æŸå¤±å‡½æ•°*ï¼Œå®ƒå°†ç”¨äºè®¡ç®—æ¯æ¬¡è¿­ä»£çš„è¯¯å·®ï¼Œ*ä¼˜åŒ–å™¨*ï¼Œå®ƒå°†æŒ‡å®šå¦‚ä½•æ›´æ–°æƒé‡ï¼Œä»¥åŠ*æŒ‡æ ‡*ï¼Œå®ƒå°†ç”±æ¨¡å‹åœ¨è®­ç»ƒå’Œæµ‹è¯•æœŸé—´è¿›è¡Œè¯„ä¼°

åœ¨æ‹Ÿåˆ/è®­ç»ƒæ¨¡å‹æ—¶ï¼Œé™¤äº†è®­ç»ƒé›†ï¼Œæˆ‘ä»¬è¿˜ä¼ é€’ä»¥ä¸‹å‚æ•°:

*   batch_size =ä¸€æ¬¡é€šè¿‡ç½‘ç»œçš„æ ·æœ¬æ•°é‡ã€‚
*   epochs =æ•´ä¸ªè®­ç»ƒæ ·æœ¬é›†é€šè¿‡ç½‘ç»œçš„æ¬¡æ•°
*   validation_data =å°†ç”¨äºåœ¨æ¯ä¸ªæ—¶æœŸç»“æŸæ—¶è¯„ä¼°æŸå¤±å’Œä»»ä½•æ¨¡å‹æŒ‡æ ‡çš„æ•°æ®é›†ã€‚è¿™å¥—ä¸ä¼šç”¨äºè®­ç»ƒã€‚

```
#Configures the model for training
cnn_model.compile(loss **=** "binary_crossentropy", optimizer **=** "adam", metrics **=** ["AUC"])
#Split the dataset into train and validation set for training and evaludating the model
X_train, X_val, y_train, y_val **=** train_test_split(trainvalid_data, train_labels, shuffle **=** **True**, random_state **=** 123)
print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)
#Trains the model for a fixed number of epochs (iterations on a dataset)
history **=** cnn_model.fit(X_train, y_train, batch_size **=** 128, epochs **=** 1, validation_data **=** (X_val, y_val)
```

![](img/2f4ddce307761f467ec188920179ece9.png)

## 5.**æ”¹è¿›çš„ç»“æœå’ŒèŒƒå›´**

![](img/b1742d6860f8e3b86b7f386a481827ac.png)

Kaggle æ’è¡Œæ¦œåˆ†æ•°(ç›¸å½“æƒŠäººçš„ä¸€ä¸ªæ—¶ä»£å§ï¼Ÿ)

*   ä½¿ç”¨ä¸€ä¸ªå¤šé¢‘é“ CNNï¼Œå®ƒå¯ä»¥åŒæ—¶æŸ¥çœ‹ä¸åŒé•¿åº¦çš„å¥å­(ä¾‹å¦‚ï¼Œå†…æ ¸å¤§å°ä¸º 3ã€5 å’Œ 7)
*   è°ƒæ•´æ¨¡å‹å±‚å’Œè¶…å‚æ•°ä»¥æé«˜æ€§èƒ½

è¿™æ˜¯å…³äº CNN çš„ã€‚ä¸‹ä¸€ä¸ªå°†æ˜¯å…³äº**é•¿** - **çŸ­æ—¶è®°å¿†** ( **LSTM** )ï¼Œè¿™æ˜¯å¯¹è‡ªç„¶è¯­è¨€å¤„ç†ä¸­è‡ªç„¶ä½¿ç”¨çš„ rnn çš„æ”¹è¿›ã€‚åœ¨é‚£ä¹‹å‰ä¿æŒå®‰å…¨ã€‚åŒæ ·ï¼Œæ•´ä¸ªä»£ç å‡ºç°åœ¨[(è¿™é‡Œ)](https://www.kaggle.com/anirbansen3027/jtcc-cnn)ã€‚è¯·ä»¥å›ç­”å’Œé¼“æŒçš„å½¢å¼æä¾›æ‚¨çš„åé¦ˆ:)