<html>
<head>
<title>Neural Style Transfer Part 2 : Fast Style Transfer</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ç¥ç»é£æ ¼è½¬ç§»ç¬¬2éƒ¨åˆ†:å¿«é€Ÿé£æ ¼è½¬ç§»</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/analytics-vidhya/neural-style-transfer-part-2-fast-style-transfer-c2654f854f4?source=collection_archive---------16-----------------------#2021-01-01">https://medium.com/analytics-vidhya/neural-style-transfer-part-2-fast-style-transfer-c2654f854f4?source=collection_archive---------16-----------------------#2021-01-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/20eb45346ab02d2f8a5d3eb29258473d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4XwQ0vrR01KW7WnT.jpg"/></div></div></figure><p id="18b3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">è¿™æ˜¯é£æ ¼è½¬æ¢ç³»åˆ—çš„ç¬¬2éƒ¨åˆ†ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬ç”¨TensorFlowçš„ç†è®ºå’Œå®ç°æ¥ä»‹ç»ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨çš„å¿«é€Ÿé£æ ¼è½¬æ¢ã€‚</p><p id="d42f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">è¿™æ˜¯ç¥ç»ç±»å‹è½¬æ¢çš„ç¬¬äºŒéƒ¨åˆ†ï¼Œåœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºå¦ä¸€ç§ç±»å‹è½¬æ¢çš„æŠ€æœ¯ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºå¿«é€Ÿç±»å‹è½¬æ¢ã€‚è¿™æ˜¯å¯¹<a class="ae jn" href="https://tarunbisht11.medium.com/neural-style-transfer-part-1-introduction-dc17a3eb86d2" rel="noopener">ä¸Šä¸€ç¯‡æ–‡ç« </a>çš„è·Ÿè¿›ï¼Œå¦‚æœä½ æ­£åœ¨ç›´æ¥é˜…è¯»å®ƒçš„ç¬¬äºŒéƒ¨åˆ†ï¼Œé‚£ä¹ˆæˆ‘å»ºè®®ä½ å…ˆé˜…è¯»<a class="ae jn" href="https://tarunbisht11.medium.com/neural-style-transfer-part-1-introduction-dc17a3eb86d2" rel="noopener">ä¸Šä¸€éƒ¨åˆ†</a>ï¼Œå› ä¸ºè®¸å¤šè¯é¢˜éƒ½æ˜¯ä»é‚£ç¯‡æ–‡ç« è·Ÿè¿›çš„ã€‚</p><p id="012e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">åœ¨gatysé£æ ¼è½¬ç§»ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰è®­ç»ƒä»»ä½•ç½‘ç»œï¼Œæˆ‘ä»¬åªæ˜¯æ ¹æ®æŸå¤±å‡½æ•°(style_loss + content_loss)ä¼˜åŒ–è¾“å‡ºå›¾åƒï¼Œå¹¶ä¸”ä¼˜åŒ–éœ€è¦ä¸€äº›è½®æ¬¡ï¼Œå› æ­¤ç”Ÿæˆé£æ ¼åŒ–å›¾åƒæ˜¯ä¸€ä¸ªéå¸¸ç¼“æ…¢çš„è¿‡ç¨‹ã€‚å°†è¿™ç§æŠ€æœ¯ç”¨äºå®æ—¶è§†é¢‘ğŸ˜­åˆ«æäº†ã€‚</p><p id="08e5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">è¿™ä¼¼ä¹æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼Œå¦‚æœæˆ‘ä»¬æƒ³è¦ç”Ÿæˆå¤šä¸ªç›¸åŒæ ·å¼çš„å›¾åƒï¼Œå› ä¸ºæˆ‘ä»¬æ¯æ¬¡éƒ½åœ¨ä¸ºç›¸åŒæ ·å¼çš„å›¾åƒä¼˜åŒ–è¾“å‡ºå›¾åƒã€‚å¦‚æœæœ‰ä¸€ç§æ–¹æ³•å¯ä»¥å­¦ä¹ æ ·å¼å›¾åƒçš„è¾“å…¥-è¾“å‡ºæ˜ å°„ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥ä¸€æ¬¡æ€§ç”Ÿæˆè¯¥æ ·å¼çš„å›¾åƒã€‚ğŸ¤”æ˜¯çš„ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è‡ªåŠ¨ç¼–ç å™¨æ¥å­¦ä¹ è¾“å…¥å›¾åƒå’Œæ ·å¼åŒ–è¾“å‡ºå›¾åƒä¹‹é—´çš„æ˜ å°„ï¼Œæ–¹æ³•æ˜¯ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„æŸå¤±å‡½æ•°æ¥è®­ç»ƒå®ƒã€‚</p><p id="66ea" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">å¿«é€Ÿé£æ ¼è½¬ç§»è®©æˆ‘ä»¬è®­ç»ƒä¸€æ¬¡ï¼Œå¹¶ç”Ÿæˆæ— é™çš„å›¾åƒï¼Œæ˜¯çš„ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥è®¾è®¡è§†é¢‘ï¼Œç”šè‡³æ˜¯å®æ—¶ç½‘ç»œè§†é¢‘ã€‚</p><h1 id="590c" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">è¦ç‚¹</h1><p id="74c6" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">å¿«é€Ÿçš„é£æ ¼è½¬æ¢è®©æˆ‘ä»¬ä¸€æ¬¡è®­ç»ƒå°±èƒ½ç”Ÿæˆæ— é™çš„å›¾åƒã€‚æˆ‘ä»¬è®¨è®ºçš„å…³äºæŸå¤±å‡½æ•°ç†è®ºçš„å¤§éƒ¨åˆ†è¦ç‚¹æ˜¯ç›¸åŒçš„ï¼Œè¿™é‡Œçš„ä¸»è¦åŒºåˆ«æ˜¯æˆ‘ä»¬å°†æ›´å¤šåœ°å…³æ³¨ä½¿ç”¨æŸå¤±å‡½æ•°çš„è®­ç»ƒæ¨¡å‹å’Œå­¦ä¹ æ˜ å°„ã€‚</p><p id="0e5a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">åœ¨é˜…è¯»è¿™ç¯‡æ–‡ç« ä¹‹å‰ï¼Œå…ˆå¤ä¹ ä¸€ä¸‹å…³äºè‡ªåŠ¨ç¼–ç å™¨çš„çŸ¥è¯†ï¼Œç‰¹åˆ«æ˜¯å·ç§¯è‡ªåŠ¨ç¼–ç å™¨å’Œæ·±åº¦å­¦ä¹ ä¸­çš„æ®‹å·®å±‚(è·³è¿‡è¿æ¥),å› ä¸ºæˆ‘ä¸ä¼šè§£é‡Šå®ƒä»¬ï¼Œä½†æˆ‘ä»¬å°†åœ¨è¿™é‡Œå®ç°å®ƒä»¬ï¼Œæ‰€ä»¥å…ˆå¤ä¹ ä¸€äº›å…³äºå·ç§¯è‡ªåŠ¨ç¼–ç å™¨å’Œæ®‹å·®å±‚çš„åŸºæœ¬çŸ¥è¯†ï¼Œè¿™å°†æœ‰åŠ©äºè½»æ¾ç†è§£å®ç°</p><p id="1686" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">1.æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªå‰é¦ˆç½‘ç»œï¼Œä½¿ç”¨<a class="ae jn" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank"> Gatysç­‰äºº</a>è®ºæ–‡ä¸­å®šä¹‰çš„æŸå¤±å‡½æ•°å°†è‰ºæœ¯é£æ ¼åº”ç”¨äºå›¾åƒï¼Œæ›´å¤šè§£é‡Šå‚è§<a class="ae jn" href="https://tarunbisht11.medium.com/neural-style-transfer-part-1-introduction-dc17a3eb86d2" rel="noopener">ä¹‹å‰çš„æ–‡ç« </a>ã€‚</p><p id="584e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">2.æˆ‘ä»¬å°†ä½¿ç”¨çš„å‰é¦ˆç½‘ç»œæ˜¯ä¸€ä¸ªæ®‹å·®è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œï¼Œå®ƒå°†å†…å®¹å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªé£æ ¼åŒ–çš„å›¾åƒã€‚è¿™ä¸åœ¨<a class="ae jn" href="https://arxiv.org/abs/1603.08155" rel="noopener ugc nofollow" target="_blank">åŸå§‹å®ç°</a>ä¸­ä½¿ç”¨çš„ç½‘ç»œç›¸åŒ</p><p id="10d9" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">3.Modelè¿˜ä½¿ç”¨å®ä¾‹è§„èŒƒåŒ–ï¼Œè€Œä¸æ˜¯åŸºäºçº¸å¼ å®ä¾‹è§„èŒƒåŒ–çš„æ‰¹å¤„ç†è§„èŒƒåŒ–:å¿«é€Ÿæ ·å¼åŒ–ç¼ºå°‘çš„è¦ç´ ï¼Œå› ä¸ºè¿™æä¾›äº†æ›´å¥½çš„ç»“æœã€‚</p><p id="469f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">4.æˆ‘ä»¬å°†ä½¿ç”¨vgg19æ¥è®¡ç®—æ„ŸçŸ¥æŸå¤±æ›´å¤šçš„å·¥ä½œæè¿°åœ¨çº¸ä¸Šã€‚</p><p id="47e1" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">å¦‚æœç°åœ¨æœ‰äººæƒ³å°è¯•è§†é¢‘å’Œå›¾åƒçš„é£æ ¼è½¬æ¢ï¼Œæˆ‘å·²ç»ä¸ºåŒæ ·çš„ç›®çš„åˆ›å»ºäº†ä¸€ä¸ª<a class="ae jn" href="https://github.com/tarun-bisht/fast-style-transfer" rel="noopener ugc nofollow" target="_blank"> GitHubåº“</a>ï¼Œå¹¶é™„æœ‰è¯´æ˜ã€‚</p><h1 id="dac4" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">å¯¼å…¥å¿…è¦çš„æ¨¡å—</h1><p id="e7bb" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">è®©æˆ‘ä»¬ä»å¯¼å…¥æ‰€æœ‰å¿…éœ€çš„æ¨¡å—å¼€å§‹:</p><ul class=""><li id="ff87" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">numpy:ç”¨äºæ•°ç»„æ“ä½œ</li><li id="947e" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">å¼ é‡æµ:ç”¨äºå¼ é‡è¿ç®—</li><li id="32b0" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">tensor flow . keras:tensor flowçš„é«˜çº§ç¥ç»ç½‘ç»œåº“ï¼Œç”¨äºåˆ›å»ºç¥ç»ç½‘ç»œ</li><li id="4745" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">pillow:ç”¨äºå°†å›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œå°†numpyæ•°ç»„è½¬æ¢ä¸ºå›¾åƒï¼Œä¿å­˜è¾“å‡ºå›¾åƒã€‚</li><li id="023a" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">æ—¶é—´:ç”¨äºè®¡ç®—æ¯æ¬¡è¿­ä»£çš„æ—¶é—´</li><li id="d3e4" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">matplotlib:ç”¨äºæ˜¾ç¤ºç¬”è®°æœ¬ä¸­çš„å›¾åƒå’Œå›¾å½¢</li><li id="93f9" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">è¯·æ±‚ï¼Œbase64ï¼Œio:ç”¨äºä»URLä¸‹è½½å’ŒåŠ è½½å›¾åƒ</li><li id="3ab4" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">os:æ“ä½œç³»ç»Ÿçº§å‘½ä»¤</li></ul><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="8945" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">import</strong> numpy <strong class="lk hi">as</strong> np<br/><strong class="lk hi">import</strong> tensorflow <strong class="lk hi">as</strong> tf<br/><strong class="lk hi">from</strong> tensorflow.keras.applications <strong class="lk hi">import</strong> vgg19<br/><strong class="lk hi">from</strong> tensorflow.keras.models <strong class="lk hi">import</strong> load_model,Model<br/><strong class="lk hi">from</strong> PIL <strong class="lk hi">import</strong> Image<br/><strong class="lk hi">import</strong> time<br/><strong class="lk hi">import</strong> matplotlib.pyplot <strong class="lk hi">as</strong> plt<br/><strong class="lk hi">import</strong> matplotlib<br/><strong class="lk hi">import</strong> requests<br/><strong class="lk hi">import</strong> base64<br/><strong class="lk hi">import</strong> os<br/><strong class="lk hi">from</strong> pathlib <strong class="lk hi">import</strong> Path<br/><strong class="lk hi">from</strong> io <strong class="lk hi">import</strong> BytesIO<br/>matplotlib.rcParams['figure.figsize'] = (12,12)<br/>matplotlib.rcParams['axes.grid'] = <strong class="lk hi">False</strong></span></pre><h1 id="af63" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">å®šä¹‰æ•ˆç”¨å‡½æ•°</h1><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="7e3e" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">def</strong> <strong class="lk hi">load_image</strong>(image_path, dim=None, resize=False):<br/>    img= Image.open(image_path)<br/>    <strong class="lk hi">if</strong> dim:<br/>        <strong class="lk hi">if</strong> resize:<br/>            img=img.resize(dim)<br/>        <strong class="lk hi">else</strong>:<br/>            img.thumbnail(dim)<br/>    img= img.convert("RGB")<br/>    <strong class="lk hi">return</strong> np.array(img)</span></pre><p id="c8e8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ä¸Šé¢çš„å‡½æ•°ç”¨äºä»æŒ‡å®šçš„è·¯å¾„åŠ è½½å›¾åƒå¹¶å°†å…¶è½¬æ¢æˆnumpyæ•°ç»„</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="b9d4" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">def</strong> <strong class="lk hi">load_url_image</strong>(url,dim=None,resize=False):<br/>    img_request=requests.get(url)<br/>    img= Image.open(BytesIO(img_request.content))<br/>    <strong class="lk hi">if</strong> dim:<br/>        <strong class="lk hi">if</strong> resize:<br/>            img=img.resize(dim)<br/>        <strong class="lk hi">else</strong>:<br/>            img.thumbnail(dim)<br/>    img= img.convert("RGB")<br/>    <strong class="lk hi">return</strong> np.array(img)</span></pre><p id="6591" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">è¿™ä¸ªå‡½æ•°ä»URLåŠ è½½å›¾åƒï¼Œå¹¶å°†å…¶è½¬æ¢æˆnumpyæ•°ç»„</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="b35e" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">def</strong> <strong class="lk hi">array_to_img</strong>(array):<br/>    array=np.array(array,dtype=np.uint8)<br/>    <strong class="lk hi">if</strong> np.ndim(array)&amp;gt;3:<br/>        <strong class="lk hi">assert</strong> array.shape[0]==1<br/>        array=array[0]<br/>    <strong class="lk hi">return</strong> Image.fromarray(array)</span><span id="02cc" class="lo jp hh lk b fi lt lq l lr ls"><strong class="lk hi">def</strong> <strong class="lk hi">show_image</strong>(image,title=None):<br/>    <strong class="lk hi">if</strong> len(image.shape)&amp;gt;3:<br/>        image=tf.squeeze(image,axis=0)<br/>    plt.imshow(image)<br/>    <strong class="lk hi">if</strong> title:<br/>        plt.title=title</span><span id="d013" class="lo jp hh lk b fi lt lq l lr ls"><strong class="lk hi">def</strong> <strong class="lk hi">plot_images_grid</strong>(images,num_rows=1):<br/>    n=len(images)<br/>    <strong class="lk hi">if</strong> n &amp;gt; 1:<br/>        num_cols=np.ceil(n/num_rows)<br/>        fig,axes=plt.subplots(ncols=int(num_cols),nrows=int(num_rows))<br/>        axes=axes.flatten()<br/>        fig.set_size_inches((15,15))<br/>        <strong class="lk hi">for</strong> i,image <strong class="lk hi">in</strong> enumerate(images):<br/>            axes[i].imshow(image)<br/>    <strong class="lk hi">else</strong>:<br/>        plt.figure(figsize=(10,10))<br/>        plt.imshow(images[0])</span></pre><p id="4007" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ä»¥ä¸Šä¸‰ä¸ªå‡½æ•°ç”¨äºè½¬æ¢å’Œç»˜åˆ¶å›¾åƒ:</p><ul class=""><li id="4ca4" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">å°†ä¸€ä¸ªæ•°ç»„è½¬æ¢æˆå›¾åƒ</li><li id="a2f1" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">show_image:ç»˜åˆ¶å•ä¸ªå›¾åƒ</li><li id="b58f" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">plot_images_grid:åœ¨ç½‘æ ¼ä¸­ç»˜åˆ¶æ‰¹é‡å›¾åƒ</li></ul><h1 id="9b73" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">å¿«é€Ÿé£æ ¼è½¬æ¢çš„æ­¥éª¤</h1><p id="4a26" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">è®­ç»ƒæ¨¡å‹æ˜¯å…·æœ‰æ®‹å·®å±‚çš„ç¼–ç å™¨-è§£ç å™¨æ¶æ„ã€‚è¾“å…¥å›¾åƒè¢«ä¼ é€’åˆ°ç¼–ç å™¨éƒ¨åˆ†ï¼Œå¹¶ä¼ æ’­åˆ°è§£ç å™¨éƒ¨åˆ†ã€‚è¾“å‡ºä¸è¾“å…¥å¤§å°ç›¸åŒï¼Œå¹¶æ˜¾ç¤ºç”Ÿæˆçš„å›¾åƒã€‚</p><p id="7472" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">è¿™ä¸ªæ¨¡å‹æ˜¯æ ¹æ®ä¸€ç§ç§°ä¸ºæ„ŸçŸ¥æŸå¤±çš„æŸå¤±è®­ç»ƒçš„ï¼Œè¿™ç§æŸå¤±çš„è®¡ç®—æ–¹æ³•ä¸æˆ‘ä»¬åœ¨gatysé£æ ¼è½¬ç§»ä¸­è®¡ç®—çš„æ–¹æ³•ç›¸åŒã€‚ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ä»å®šä¹‰çš„æ ·å¼å’Œå†…å®¹å±‚æå–ç‰¹å¾å›¾ï¼Œå¹¶ä½¿ç”¨å®ƒä»¬æ¥è®¡ç®—æ ·å¼æŸå¤±å’Œå†…å®¹æŸå¤±ã€‚(æ›´å¤šç»†èŠ‚è¯·é˜…è¯»<a class="ae jn" href="https://tarunbisht11.medium.com/neural-style-transfer-part-1-introduction-dc17a3eb86d2" rel="noopener">ä¹‹å‰çš„å¸–å­</a>ï¼Œé‚£é‡Œæœ‰è§£é‡Š)</p><p id="2a69" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ä½œä¸ºè®­ç»ƒæ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬éœ€è¦è®­ç»ƒæ•°æ®ï¼Œå¯¹äºè®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸åŒå›¾åƒçš„æ•°æ®é›†(å¯ä»¥æ˜¯ä»»ä½•åƒäººã€ç‹—ã€æ±½è½¦ç­‰)..)æ•£è£…ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯<a class="ae jn" href="http://images.cocodataset.org/zips/train2014.zip" rel="noopener ugc nofollow" target="_blank">å¯å¯æ•°æ®é›†</a>ï¼Œå®ƒæœ‰å¾ˆå¤šå›¾ç‰‡ã€‚æˆ‘ä¹Ÿä½¿ç”¨è¿‡<a class="ae jn" href="https://www.kaggle.com/c/gan-getting-started" rel="noopener ugc nofollow" target="_blank"> KaggleæŒ‘æˆ˜æ•°æ®é›†</a>ï¼Œå®ƒæœ‰ä¸åŒé£æ™¯çš„å›¾åƒï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œæ£€æŸ¥ä»£ç å†…æ ¸<a class="ae jn" href="https://www.kaggle.com/tarunbisht11/generate-art-using-fast-style-transfer-in-a-second" rel="noopener ugc nofollow" target="_blank">ã€‚æˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªæ ·å¼å›¾åƒï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨autoencoderå­¦ä¹ å®ƒçš„æ ·å¼ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»»ä½•ç»˜ç”»æˆ–ç´ æ(ä»äº’è”ç½‘ä¸Šé€‰æ‹©ä¸€ä¸ª)</a></p><p id="09da" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">å¯¹äºè®­ç»ƒï¼Œè¯¥æ¨¡å‹æˆ‘ä»¬å°†ä¸€æ‰¹å„ç§å†…å®¹çš„è¾“å…¥è®­ç»ƒå›¾åƒå‘é€åˆ°autoencoderï¼Œauto encoderä¸ºæˆ‘ä»¬æä¾›è¾“å‡ºã€‚è¯¥è¾“å‡ºå¿…é¡»æ˜¯æˆ‘ä»¬çš„é£æ ¼å›¾åƒï¼Œè€Œè®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬å°†è¿™äº›è¾“å‡ºå›¾åƒåˆ†æ‰¹ä¼ é€’åˆ°æˆ‘ä»¬çš„æŸå¤±æ¨¡å‹(vgg19 ),å¹¶æå–ä¸åŒå±‚(å†…å®¹å±‚å’Œé£æ ¼å±‚)çš„ç‰¹å¾ã€‚è¿™äº›ç‰¹å¾ç„¶åç”¨äºè®¡ç®—é£æ ¼æŸå¤±å’Œå†…å®¹æŸå¤±ï¼Œå…¶åŠ æƒå’Œäº§ç”Ÿè®­ç»ƒç½‘ç»œçš„æ„ŸçŸ¥æŸå¤±ã€‚ä¸‹é¢è¿™å¼ æ¥è‡ªè®ºæ–‡çš„å›¾ç‰‡å¾ˆå¥½åœ°æè¿°äº†å®ƒã€‚</p><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lu"><img src="../Images/8d597d6d43c6576d28c7327ead5f3c5e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UlLnY4Vb4jbBF7Gd"/></div></div></figure><p id="a15f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ç»è¿‡è®­ç»ƒåï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¯¥ç½‘ç»œä¸€æ¬¡æ€§è®¾è®¡ä»»ä½•å›¾åƒï¼Œè€Œæ— éœ€ä¼˜åŒ–</p><p id="d834" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">è¯¥ç½‘ç»œçš„ä¸»è¦äº®ç‚¹:</p><ul class=""><li id="a587" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">æ®‹ç•™å±‚</li><li id="b895" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹</li><li id="b0d0" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">è§£ç å™¨çš„è¾“å‡ºè¢«ä¼ é€’åˆ°æŸè€—æ¨¡å‹(VGG)ä»¥è®¡ç®—æŸè€—</li><li id="a554" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">è®­ç»ƒéœ€è¦è®¡ç®—ï¼Œå› ä¸ºæˆ‘ä»¬æ¯ä¸€æ­¥éƒ½è¦å°†è¿™äº›å›¾åƒä¼ é€’ç»™ä¸¤ä¸ªç½‘ç»œ</li></ul><h1 id="b223" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">å®šä¹‰æŸå¤±</h1><p id="f752" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">ä¸ºäº†è®¡ç®—é£æ ¼æŸå¤±å’Œå†…å®¹æŸå¤±ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªé¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ‘ä»¬ä½¿ç”¨vgg19ï¼ŒåŸå§‹å®ç°ä½¿ç”¨vgg16ã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="052a" class="lo jp hh lk b fi lp lq l lr ls">vgg=vgg19.VGG19(weights='imagenet',include_top=<strong class="lk hi">False</strong>)<br/>vgg.summary()</span><span id="a08c" class="lo jp hh lk b fi lt lq l lr ls">Model: "vgg19"<br/>_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>input_1 (InputLayer)         [(<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 3)]   0         <br/>_________________________________________________________________<br/>block1_conv1 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 64)    1792      <br/>_________________________________________________________________<br/>block1_conv2 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 64)    36928     <br/>_________________________________________________________________<br/>block1_pool (MaxPooling2D)   (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 64)    0         <br/>_________________________________________________________________<br/>block2_conv1 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 128)   73856     <br/>_________________________________________________________________<br/>block2_conv2 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 128)   147584    <br/>_________________________________________________________________<br/>block2_pool (MaxPooling2D)   (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 128)   0         <br/>_________________________________________________________________<br/>block3_conv1 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 256)   295168    <br/>_________________________________________________________________<br/>block3_conv2 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 256)   590080    <br/>_________________________________________________________________<br/>block3_conv3 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 256)   590080    <br/>_________________________________________________________________<br/>block3_conv4 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 256)   590080    <br/>_________________________________________________________________<br/>block3_pool (MaxPooling2D)   (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 256)   0         <br/>_________________________________________________________________<br/>block4_conv1 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 512)   1180160   <br/>_________________________________________________________________<br/>block4_conv2 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 512)   2359808   <br/>_________________________________________________________________<br/>block4_conv3 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 512)   2359808   <br/>_________________________________________________________________<br/>block4_conv4 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 512)   2359808   <br/>_________________________________________________________________<br/>block4_pool (MaxPooling2D)   (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 512)   0         <br/>_________________________________________________________________<br/>block5_conv1 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 512)   2359808   <br/>_________________________________________________________________<br/>block5_conv2 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 512)   2359808   <br/>_________________________________________________________________<br/>block5_conv3 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 512)   2359808   <br/>_________________________________________________________________<br/>block5_conv4 (Conv2D)        (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 512)   2359808   <br/>_________________________________________________________________<br/>block5_pool (MaxPooling2D)   (<strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, <strong class="lk hi">None</strong>, 512)   0         <br/>=================================================================<br/>Total params: 20,024,384<br/>Trainable params: 20,024,384<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="df4b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®šä¹‰å°†ç”¨äºè®¡ç®—æŸå¤±çš„å±‚ã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="13f5" class="lo jp hh lk b fi lp lq l lr ls">content_layers=['block4_conv2']</span><span id="e4c2" class="lo jp hh lk b fi lt lq l lr ls">style_layers=['block1_conv1',<br/>            'block2_conv1',<br/>            'block3_conv1',<br/>            'block4_conv1',<br/>            'block5_conv1']</span></pre><p id="8a34" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">è®©æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç±»ï¼Œè¯¥ç±»ä½¿ç”¨ä¸€äº›é¢å¤–çš„æ–¹æ³•æ¥åˆ›å»ºæŸå¤±æ¨¡å‹ï¼Œä»¥ä¾¿ä»ç½‘ç»œè®¿é—®è¦ç´ åœ°å›¾ã€‚æˆ‘ä»¬åœ¨<a class="ae jn" href="https://tarunbisht11.medium.com/neural-style-transfer-part-1-introduction-dc17a3eb86d2" rel="noopener">ä¹‹å‰çš„æ–‡ç« </a>ä¸­ä¹Ÿä½¿ç”¨è¿‡è¿™äº›å‡½æ•°ï¼Œè¿™é‡Œæˆ‘ä»¬åªæ˜¯å°†å®ƒä»¬å°è£…åœ¨ä¸€ä¸ªç±»ä¸­ã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="0aa2" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">class</strong> <strong class="lk hi">LossModel</strong>:<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">__init__</strong>(self,pretrained_model,content_layers,style_layers):<br/>        self.model=pretrained_model<br/>        self.content_layers=content_layers<br/>        self.style_layers=style_layers<br/>        self.loss_model=self.get_model()</span><span id="a0cf" class="lo jp hh lk b fi lt lq l lr ls">    <strong class="lk hi">def</strong> <strong class="lk hi">get_model</strong>(self):<br/>        self.model.trainable=<strong class="lk hi">False</strong><br/>        layer_names=self.style_layers + self.content_layers<br/>        outputs=[self.model.get_layer(name).output <strong class="lk hi">for</strong> name <strong class="lk hi">in</strong> layer_names]<br/>        new_model=Model(inputs=self.model.input,outputs=outputs)<br/>        <strong class="lk hi">return</strong> new_model<br/>    <br/>    <strong class="lk hi">def</strong> <strong class="lk hi">get_activations</strong>(self,inputs):<br/>        inputs=inputs*255.0<br/>        style_length=len(self.style_layers)<br/>        outputs=self.loss_model(vgg19.preprocess_input(inputs))<br/>        style_output,content_output=outputs[:style_length],outputs[style_length:]<br/>        content_dict={name:value <strong class="lk hi">for</strong> name,value <strong class="lk hi">in</strong> zip(self.content_layers,content_output)}<br/>        style_dict={name:value <strong class="lk hi">for</strong> name,value <strong class="lk hi">in</strong> zip(self.style_layers,style_output)}<br/>        <strong class="lk hi">return</strong> {'content':content_dict,'style':style_dict}</span></pre><p id="7b78" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ç°åœ¨æˆ‘ä»¬ä½¿ç”¨ä¸Šé¢çš„ç±»åˆ›å»ºæˆ‘ä»¬çš„æŸå¤±æ¨¡å‹</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="493d" class="lo jp hh lk b fi lp lq l lr ls">loss_model = LossModel(vgg, content_layers, style_layers)</span></pre><p id="f9ee" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">è®©æˆ‘ä»¬å®šä¹‰æŸå¤±å‡½æ•°æ¥è®¡ç®—å†…å®¹å’Œé£æ ¼æŸå¤±ï¼Œä¸‹é¢æ–¹æ³•<code class="du lv lw lx lk b">content_loss</code>å’Œ<code class="du lv lw lx lk b">style _loss</code>åˆ†åˆ«è®¡ç®—å†…å®¹å’Œé£æ ¼æŸå¤±ã€‚é€šè¿‡å¯¹è¿™äº›æŸå¤±è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œæˆ‘ä»¬å¾—åˆ°äº†å®šä¹‰åœ¨<code class="du lv lw lx lk b">preceptual_loss</code>å‡½æ•°ä¸­çš„æ„ŸçŸ¥æŸå¤±ã€‚è¿™äº›æŸå¤±å‡½æ•°çš„ç»†èŠ‚åŒ…å«åœ¨<a class="ae jn" href="https://tarunbisht11.medium.com/neural-style-transfer-part-1-introduction-dc17a3eb86d2" rel="noopener">å‰ä¸€ç¯‡æ–‡ç« </a>ä¸­ã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="c2c6" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">def</strong> <strong class="lk hi">content_loss</strong>(placeholder,content,weight):<br/>    <strong class="lk hi">assert</strong> placeholder.shape == content.shape<br/>    <strong class="lk hi">return</strong> weight*tf.reduce_mean(tf.square(placeholder-content))</span><span id="58d1" class="lo jp hh lk b fi lt lq l lr ls"><strong class="lk hi">def</strong> <strong class="lk hi">gram_matrix</strong>(x):<br/>    gram=tf.linalg.einsum('bijc,bijd-&amp;gt;bcd', x, x)<br/>    <strong class="lk hi">return</strong> gram/tf.cast(x.shape[1]*x.shape[2]*x.shape[3],tf.float32)</span><span id="88bc" class="lo jp hh lk b fi lt lq l lr ls"><strong class="lk hi">def</strong> <strong class="lk hi">style_loss</strong>(placeholder,style, weight):<br/>    <strong class="lk hi">assert</strong> placeholder.shape == style.shape<br/>    s=gram_matrix(style)<br/>    p=gram_matrix(placeholder)<br/>    <strong class="lk hi">return</strong> weight*tf.reduce_mean(tf.square(s-p))</span><span id="d3c5" class="lo jp hh lk b fi lt lq l lr ls"><strong class="lk hi">def</strong> <strong class="lk hi">preceptual_loss</strong>(predicted_activations,content_activations,<br/>                    style_activations,content_weight,style_weight,<br/>                    content_layers_weights,style_layer_weights):<br/>    pred_content = predicted_activations["content"]<br/>    pred_style = predicted_activations["style"]<br/>    c_loss = tf.add_n([content_loss(pred_content[name],content_activations[name],<br/>                                  content_layers_weights[i]) <strong class="lk hi">for</strong> i,name <strong class="lk hi">in</strong> enumerate(pred_content.keys())])<br/>    c_loss = c_loss*content_weight<br/>    s_loss = tf.add_n([style_loss(pred_style[name],style_activations[name],<br/>                                style_layer_weights[i]) <strong class="lk hi">for</strong> i,name <strong class="lk hi">in</strong> enumerate(pred_style.keys())])<br/>    s_loss = s_loss*style_weight<br/>    <strong class="lk hi">return</strong> c_loss+s_loss</span></pre><h1 id="5846" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">åˆ›å»ºè‡ªåŠ¨ç¼–ç å™¨</h1><p id="2ad9" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é¦–å…ˆä¸ºæˆ‘ä»¬çš„ç½‘ç»œå®šä¹‰äº†æ‰€æœ‰å¿…è¦çš„å±‚:</p><ul class=""><li id="6729" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">ReflectionPadding2D:ç”¨äºå°†åå°„å¡«å……åº”ç”¨åˆ°convç½‘ä¸­çš„å›¾åƒ</li><li id="c645" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">å®ä¾‹è§„èŒƒåŒ–:æˆ‘ä»¬ä½¿ç”¨å®ä¾‹è§„èŒƒåŒ–è€Œä¸æ˜¯æ‰¹å¤„ç†è§„èŒƒåŒ–ï¼Œå› ä¸ºå®ƒèƒ½ç»™å‡ºæ›´å¥½çš„ç»“æœã€‚å®ƒå°†é€šé“ä¸Šçš„è¾“å…¥æ ‡å‡†åŒ–ã€‚</li><li id="be19" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">conv layer:convå›¾å±‚çš„å—ï¼Œå…·æœ‰å¡«å……-&gt; conv _å›¾å±‚-&gt;å®ä¾‹_è§„èŒƒåŒ–ç»„åˆ</li><li id="1ef9" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">å‰©ä½™å±‚:å…·æœ‰ä¸¤ä¸ªè½¬åŒ–å±‚å—çš„å‰©ä½™å±‚</li><li id="035b" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">UpsampleLayer:å¯¹autoencoderä¸­çš„ç“¶é¢ˆè¡¨ç¤ºè¿›è¡Œä¸Šé‡‡æ ·(å¦‚æœä½ è¯»è¿‡å…³äºauto encoderçš„æ–‡ç« ï¼Œä½ å°±ä¼šæ˜ç™½æˆ‘çš„æ„æ€)ã€‚å®ƒå¯ä»¥è¢«è®¤ä¸ºæ˜¯åå·ç§¯å±‚ã€‚</li></ul><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="2b33" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">class</strong> <strong class="lk hi">ReflectionPadding2D</strong>(tf.keras.layers.Layer):<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">__init__</strong>(self, padding=(1, 1), **kwargs):<br/>        super(ReflectionPadding2D, self).__init__(**kwargs)<br/>        self.padding = tuple(padding)<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">call</strong>(self, input_tensor):<br/>        padding_width, padding_height = self.padding<br/>        <strong class="lk hi">return</strong> tf.pad(input_tensor, [[0,0], [padding_height, padding_height], <br/>                                     [padding_width, padding_width], [0,0] ], 'REFLECT')</span><span id="19e2" class="lo jp hh lk b fi lt lq l lr ls"><strong class="lk hi">class</strong> <strong class="lk hi">InstanceNormalization</strong>(tf.keras.layers.Layer):<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">__init__</strong>(self,**kwargs):<br/>        super(InstanceNormalization, self).__init__(**kwargs)<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">call</strong>(self,inputs):<br/>        batch, rows, cols, channels = [i <strong class="lk hi">for</strong> i <strong class="lk hi">in</strong> inputs.get_shape()]<br/>        mu, var = tf.nn.moments(inputs, [1,2], keepdims=<strong class="lk hi">True</strong>)<br/>        shift = tf.Variable(tf.zeros([channels]))<br/>        scale = tf.Variable(tf.ones([channels]))<br/>        epsilon = 1e-3<br/>        normalized = (inputs-mu)/tf.sqrt(var + epsilon)<br/>        <strong class="lk hi">return</strong> scale * normalized + shift</span><span id="2595" class="lo jp hh lk b fi lt lq l lr ls"><strong class="lk hi">class</strong> <strong class="lk hi">ConvLayer</strong>(tf.keras.layers.Layer):<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">__init__</strong>(self,filters,kernel_size,strides=1,**kwargs):<br/>        super(ConvLayer,self).__init__(**kwargs)<br/>        self.padding=ReflectionPadding2D([k//2 <strong class="lk hi">for</strong> k <strong class="lk hi">in</strong> kernel_size])<br/>        self.conv2d=tf.keras.layers.Conv2D(filters,kernel_size,strides)<br/>        self.bn=InstanceNormalization()<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">call</strong>(self,inputs):<br/>        x=self.padding(inputs)<br/>        x=self.conv2d(x)<br/>        x=self.bn(x)<br/>        <strong class="lk hi">return</strong> x</span><span id="5e3d" class="lo jp hh lk b fi lt lq l lr ls"><strong class="lk hi">class</strong> <strong class="lk hi">ResidualLayer</strong>(tf.keras.layers.Layer):<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">__init__</strong>(self,filters,kernel_size,**kwargs):<br/>        super(ResidualLayer,self).__init__(**kwargs)<br/>        self.conv2d_1=ConvLayer(filters,kernel_size)<br/>        self.conv2d_2=ConvLayer(filters,kernel_size)<br/>        self.relu=tf.keras.layers.ReLU()<br/>        self.add=tf.keras.layers.Add()<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">call</strong>(self,inputs):<br/>        residual=inputs<br/>        x=self.conv2d_1(inputs)<br/>        x=self.relu(x)<br/>        x=self.conv2d_2(x)<br/>        x=self.add([x,residual])<br/>        <strong class="lk hi">return</strong> x</span><span id="4c46" class="lo jp hh lk b fi lt lq l lr ls"><strong class="lk hi">class</strong> <strong class="lk hi">UpsampleLayer</strong>(tf.keras.layers.Layer):<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">__init__</strong>(self,filters,kernel_size,strides=1,upsample=2,**kwargs):<br/>        super(UpsampleLayer,self).__init__(**kwargs)<br/>        self.upsample=tf.keras.layers.UpSampling2D(size=upsample)<br/>        self.padding=ReflectionPadding2D([k//2 <strong class="lk hi">for</strong> k <strong class="lk hi">in</strong> kernel_size])<br/>        self.conv2d=tf.keras.layers.Conv2D(filters,kernel_size,strides)<br/>        self.bn=InstanceNormalization()<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">call</strong>(self,inputs):<br/>        x=self.upsample(inputs)<br/>        x=self.padding(x)<br/>        x=self.conv2d(x)<br/>        <strong class="lk hi">return</strong> self.bn(x)</span></pre><p id="e094" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ä½¿ç”¨ä¸Šé¢å®šä¹‰çš„è¿™äº›å±‚ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå·ç§¯è‡ªåŠ¨ç¼–ç å™¨ã€‚</p><p id="bdc3" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">å»ºç­‘:</p><ul class=""><li id="1150" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">3ä¸ªConvLayer</li><li id="83ea" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">5ä¸ªæ®‹æ¸£å±‚</li><li id="cecd" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">3ä¸ªä¸Šé‡‡æ ·å±‚</li></ul><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="10db" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">class</strong> <strong class="lk hi">StyleTransferModel</strong>(tf.keras.Model):<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">__init__</strong>(self,**kwargs):<br/>        super(StyleTransferModel, self).__init__(name='StyleTransferModel',**kwargs)<br/>        self.conv2d_1= ConvLayer(filters=32,kernel_size=(9,9),strides=1,name="conv2d_1_32")<br/>        self.conv2d_2= ConvLayer(filters=64,kernel_size=(3,3),strides=2,name="conv2d_2_64")<br/>        self.conv2d_3= ConvLayer(filters=128,kernel_size=(3,3),strides=2,name="conv2d_3_128")<br/>        self.res_1=ResidualLayer(filters=128,kernel_size=(3,3),name="res_1_128")<br/>        self.res_2=ResidualLayer(filters=128,kernel_size=(3,3),name="res_2_128")<br/>        self.res_3=ResidualLayer(filters=128,kernel_size=(3,3),name="res_3_128")<br/>        self.res_4=ResidualLayer(filters=128,kernel_size=(3,3),name="res_4_128")<br/>        self.res_5=ResidualLayer(filters=128,kernel_size=(3,3),name="res_5_128")<br/>        self.deconv2d_1= UpsampleLayer(filters=64,kernel_size=(3,3),name="deconv2d_1_64")<br/>        self.deconv2d_2= UpsampleLayer(filters=32,kernel_size=(3,3),name="deconv2d_2_32")<br/>        self.deconv2d_3= ConvLayer(filters=3,kernel_size=(9,9),strides=1,name="deconv2d_3_3")<br/>        self.relu=tf.keras.layers.ReLU()<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">call</strong>(self, inputs):<br/>        x=self.conv2d_1(inputs)<br/>        x=self.relu(x)<br/>        x=self.conv2d_2(x)<br/>        x=self.relu(x)<br/>        x=self.conv2d_3(x)<br/>        x=self.relu(x)<br/>        x=self.res_1(x)<br/>        x=self.res_2(x)<br/>        x=self.res_3(x)<br/>        x=self.res_4(x)<br/>        x=self.res_5(x)<br/>        x=self.deconv2d_1(x)<br/>        x=self.relu(x)<br/>        x=self.deconv2d_2(x)<br/>        x=self.relu(x)<br/>        x=self.deconv2d_3(x)<br/>        x = (tf.nn.tanh(x) + 1) * (255.0 / 2)<br/>        <strong class="lk hi">return</strong> x<br/>    <br/>    ## used to print shapes of each layer to check if input shape == output shape<br/>    ## I don't know any better solution to this right now<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">print_shape</strong>(self,inputs):<br/>        print(inputs.shape)<br/>        x=self.conv2d_1(inputs)<br/>        print(x.shape)<br/>        x=self.relu(x)<br/>        x=self.conv2d_2(x)<br/>        print(x.shape)<br/>        x=self.relu(x)<br/>        x=self.conv2d_3(x)<br/>        print(x.shape)<br/>        x=self.relu(x)<br/>        x=self.res_1(x)<br/>        print(x.shape)<br/>        x=self.res_2(x)<br/>        print(x.shape)<br/>        x=self.res_3(x)<br/>        print(x.shape)<br/>        x=self.res_4(x)<br/>        print(x.shape)<br/>        x=self.res_5(x)<br/>        print(x.shape)<br/>        x=self.deconv2d_1(x)<br/>        print(x.shape)<br/>        x=self.relu(x)<br/>        x=self.deconv2d_2(x)<br/>        print(x.shape)<br/>        x=self.relu(x)<br/>        x=self.deconv2d_3(x)<br/>        print(x.shape)</span></pre><p id="8a83" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">åœ¨æ­¤å®šä¹‰è¾“å…¥å½¢çŠ¶å’Œæ‰¹é‡å¤§å°</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="d8b7" class="lo jp hh lk b fi lp lq l lr ls">input_shape=(256,256,3)<br/>batch_size=4</span></pre><p id="eb0f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ä½¿ç”¨<code class="du lv lw lx lk b">StyleTransferModel</code>ç±»åˆ›å»ºæ ·å¼æ¨¡å‹</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="db59" class="lo jp hh lk b fi lp lq l lr ls">style_model = StyleTransferModel()</span></pre><p id="5bfc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ£€æŸ¥æ‰€æœ‰å±‚çš„å½¢çŠ¶ï¼Œå¹¶éªŒè¯è¾“å…¥å½¢çŠ¶å’Œè¾“å‡ºå½¢çŠ¶</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="538a" class="lo jp hh lk b fi lp lq l lr ls">style_model.print_shape(tf.zeros(shape=(1,*input_shape)))</span><span id="ebf0" class="lo jp hh lk b fi lt lq l lr ls">(1, 256, 256, 3)<br/>(1, 256, 256, 32)<br/>(1, 128, 128, 64)<br/>(1, 64, 64, 128)<br/>(1, 64, 64, 128)<br/>(1, 64, 64, 128)<br/>(1, 64, 64, 128)<br/>(1, 64, 64, 128)<br/>(1, 64, 64, 128)<br/>(1, 128, 128, 64)<br/>(1, 256, 256, 32)<br/>(1, 256, 256, 3)</span></pre><h1 id="94d5" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">åŸ¹è®­æ¨¡å¼</h1><p id="7338" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">è¿™é‡Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªç”¨äºè®­ç»ƒçš„ä¼˜åŒ–å™¨ï¼Œæˆ‘ä»¬ä½¿ç”¨å­¦ä¹ ç‡ä¸º1e-3çš„Adamä¼˜åŒ–å™¨</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="806a" class="lo jp hh lk b fi lp lq l lr ls">optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)</span><span id="15c0" class="lo jp hh lk b fi lt lq l lr ls"><strong class="lk hi">def</strong> <strong class="lk hi">train_step</strong>(dataset,style_activations,steps_per_epoch,style_model,loss_model,optimizer,<br/>               checkpoint_path="./",content_weight=1e4, style_weight=1e-2,<br/>               total_variation_weight=0.004):<br/>    batch_losses=[]<br/>    steps=1<br/>    save_path=os.path.join(checkpoint_path,f"model_checkpoint.ckpt")<br/>    print("Model Checkpoint Path: ",save_path)<br/>    <strong class="lk hi">for</strong> input_image_batch <strong class="lk hi">in</strong> dataset:<br/>        <strong class="lk hi">if</strong> steps-1 &amp;gt;= steps_per_epoch:<br/>            <strong class="lk hi">break</strong><br/>        <strong class="lk hi">with</strong> tf.GradientTape() <strong class="lk hi">as</strong> tape:<br/>            outputs=style_model(input_image_batch)<br/>            outputs=tf.clip_by_value(outputs, 0, 255)<br/>            pred_activations=loss_model.get_activations(outputs/255.0)<br/>            content_activations=loss_model.get_activations(input_image_batch)["content"] <br/>            curr_loss=preceptual_loss(pred_activations,content_activations,style_activations,content_weight,<br/>                                      style_weight,content_layers_weights,style_layers_weights)<br/>            curr_loss += total_variation_weight*tf.image.total_variation(outputs)<br/>        batch_losses.append(curr_loss)<br/>        grad = tape.gradient(curr_loss,style_model.trainable_variables)<br/>        optimizer.apply_gradients(zip(grad,style_model.trainable_variables))<br/>        <strong class="lk hi">if</strong> steps % 1000==0:<br/>            print("checkpoint saved ",end=" ")<br/>            style_model.save_weights(save_path)<br/>            print(f"Loss: {tf.reduce_mean(batch_losses).numpy()}")<br/>        steps+=1<br/>    <strong class="lk hi">return</strong> tf.reduce_mean(batch_losses)</span></pre><p id="ffa2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">åœ¨ä¸Šé¢çš„å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªå•ç‹¬çš„è®­ç»ƒæ­¥éª¤ã€‚åœ¨å‡½æ•°å†…éƒ¨:</p><ul class=""><li id="3fd7" class="kr ks hh ir b is it iw ix ja kt je ku ji kv jm kw kx ky kz bi translated">é¦–å…ˆï¼Œæˆ‘ä»¬ä¸ºæ¨¡å‹æ£€æŸ¥ç‚¹å®šä¹‰äº†save_path</li><li id="3905" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">å¯¹äºæ¯ä¸ªæ—¶æœŸçš„æ­¥æ•°ï¼Œæˆ‘ä»¬è¿è¡Œä¸€ä¸ªè®­ç»ƒå¾ªç¯</li><li id="0195" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">å¯¹äºæ¯ä¸€æ­¥ï¼Œæˆ‘ä»¬å‘å‰ä¼ é€’ä¸€æ‰¹å›¾åƒå°†å…¶ä¼ é€’ç»™æˆ‘ä»¬çš„æŸå¤±æ¨¡å‹</li><li id="b04d" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">è·å–æ‰¹é‡å›¾åƒçš„å†…å®¹å±‚æ¿€æ´»</li><li id="a405" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">è¿åŒæ¥è‡ªæ ·å¼å›¾åƒçš„æ ·å¼æ¿€æ´»å’Œå†…å®¹æ¿€æ´»ï¼Œæˆ‘ä»¬è®¡ç®—æ„ŸçŸ¥æŸå¤±</li><li id="66de" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">ä¸ºäº†å¹³æ»‘ï¼Œæˆ‘ä»¬ç»™å›¾åƒå¢åŠ äº†ä¸€äº›æ€»å˜å·®æŸå¤±</li><li id="5d16" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">è®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äºæ¨¡å‹å¯è®­ç»ƒå‚æ•°çš„æ¢¯åº¦</li><li id="2b74" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">æœ€ååå‘ä¼ æ’­ä¼˜åŒ–</li><li id="7247" class="kr ks hh ir b is la iw lb ja lc je ld ji le jm kw kx ky kz bi translated">æ¯1000æ­¥ä¿å­˜ä¸€ä¸ªæ£€æŸ¥ç‚¹</li></ul><h1 id="aa25" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">ä¸ºè®­ç»ƒé…ç½®æ•°æ®é›†</h1><p id="291a" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">ä¸‹è½½cocoæ•°æ®é›†ç”¨äºè®­ç»ƒï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä»»ä½•å…¶ä»–æ‰¹é‡å›¾åƒçš„å›¾åƒæ•°æ®é›†ã€‚ä½¿ç”¨wgetä»¥zipæ ¼å¼ä¸‹è½½cocoæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç›®å½•ï¼Œå°†ä¸‹è½½zipæ–‡ä»¶è§£å‹ç¼©ã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="4bcf" class="lo jp hh lk b fi lp lq l lr ls">wget <a class="ae jn" href="http://images.cocodataset.org/zips/train2014.zip" rel="noopener ugc nofollow" target="_blank">http://images.cocodataset.org/zips/train2014.zip</a></span><span id="e499" class="lo jp hh lk b fi lt lq l lr ls">--2020-07-12 08:14:59--  http://images.cocodataset.org/zips/train2014.zip<br/>Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.224.88<br/>Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.224.88|:80... connected.<br/>HTTP request sent, awaiting response... 200 OK<br/>Length: 13510573713 (13G) [application/zip]<br/>Saving to: â€˜train2014.zipâ€™</span><span id="eccd" class="lo jp hh lk b fi lt lq l lr ls">train2014.zip       100%[===================&amp;gt;]  12.58G  25.0MB/s    <strong class="lk hi">in</strong> 6m 56s  </span><span id="6b18" class="lo jp hh lk b fi lt lq l lr ls">2020-07-12 08:21:55 (31.0 MB/s) - â€˜train2014.zipâ€™ saved [13510573713/13510573713]</span><span id="73b5" class="lo jp hh lk b fi lt lq l lr ls">mkdir coco<br/>unzip -qq train2014.zip -d coco</span></pre><p id="57b0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">å¯¹äºè®­ç»ƒï¼Œè¯¥æ¨¡å‹å…è®¸åˆ›å»ºtensorflowæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä»æŒ‡å®šçš„è·¯å¾„åŠ è½½æ‰€æœ‰å›¾åƒï¼Œè°ƒæ•´å®ƒä»¬çš„å¤§å°ä½¿å…¶å…·æœ‰ç›¸åŒçš„å¤§å°ï¼Œä»¥ä¾¿è¿›è¡Œæœ‰æ•ˆçš„æ‰¹é‡è®­ç»ƒï¼Œå¹¶å®ç°æ‰¹å¤„ç†å’Œé¢„å–ã€‚ä¸‹é¢çš„ç±»ä¸ºè®­ç»ƒåˆ›å»ºtfdatasetã€‚</p><p id="8a66" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨å›ºå®šå¤§å°çš„å›¾åƒè®­ç»ƒæ¨¡å‹ï¼Œä½†æˆ‘ä»¬å¯ä»¥ç”Ÿæˆä»»ä½•å¤§å°çš„å›¾åƒï¼Œå› ä¸ºæ¨¡å‹ä¸­çš„æ‰€æœ‰å±‚éƒ½æ˜¯å·ç§¯å±‚ã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="b578" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">class</strong> <strong class="lk hi">TensorflowDatasetLoader</strong>:<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">__init__</strong>(self,dataset_path,batch_size=4, image_size=(256, 256),num_images=None):<br/>        images_paths = [str(path) <strong class="lk hi">for</strong> path <strong class="lk hi">in</strong> Path(dataset_path).glob("*.jpg")]<br/>        self.length=len(images_paths)<br/>        <strong class="lk hi">if</strong> num_images <strong class="lk hi">is</strong> <strong class="lk hi">not</strong> <strong class="lk hi">None</strong>:<br/>            images_paths = images_paths[0:num_images]<br/>        dataset = tf.data.Dataset.from_tensor_slices(images_paths).map(<br/>            <strong class="lk hi">lambda</strong> path: self.load_tf_image(path, dim=image_size),<br/>            num_parallel_calls=tf.data.experimental.AUTOTUNE,<br/>        )<br/>        dataset = dataset.batch(batch_size,drop_remainder=<strong class="lk hi">True</strong>)<br/>        dataset = dataset.repeat()<br/>        dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)<br/>        self.dataset=dataset<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">__len__</strong>(self):<br/>        <strong class="lk hi">return</strong> self.length<br/>    <strong class="lk hi">def</strong> <strong class="lk hi">load_tf_image</strong>(self,image_path,dim):<br/>        image = tf.io.read_file(image_path)<br/>        image = tf.image.decode_jpeg(image, channels=3)<br/>        image= tf.image.resize(image,dim)<br/>        image= image/255.0<br/>        image = tf.image.convert_image_dtype(image, tf.float32)<br/>        <strong class="lk hi">return</strong> image</span></pre><p id="000b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ä½¿ç”¨ä¸Šé¢çš„ç±»ï¼Œè®©æˆ‘ä»¬ä»cocoæ•°æ®é›†å›¾åƒåˆ›å»ºtfdatasetã€‚æˆ‘ä»¬æŒ‡å®šå›¾åƒæ–‡ä»¶å¤¹çš„è·¯å¾„(æ‰€æœ‰å›¾åƒéƒ½åœ¨è¿™é‡Œ)å’Œæ‰¹é‡å¤§å°</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="e72f" class="lo jp hh lk b fi lp lq l lr ls">loader=TensorflowDatasetLoader("coco/train2014/",batch_size=4)</span><span id="bf44" class="lo jp hh lk b fi lt lq l lr ls">loader.dataset.element_spec</span><span id="e07c" class="lo jp hh lk b fi lt lq l lr ls">TensorSpec(shape=(4, 256, 256, 3), dtype=tf.float32, name=<strong class="lk hi">None</strong>)</span></pre><p id="76df" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ç»˜åˆ¶ä¸€äº›å›¾åƒä»¥æŸ¥çœ‹æ•°æ®é›†ä¸­çš„å›¾åƒ</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="c4d5" class="lo jp hh lk b fi lp lq l lr ls">plot_images_grid(next(iter(loader.dataset.take(1))))</span></pre><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ly"><img src="../Images/d68216635928afc810ea1ead0fd04f53.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*h7ML704t6GyiHdGV"/></div></div></figure><p id="1018" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨<code class="du lv lw lx lk b">load_url_image</code>ä»URLåŠ è½½æ ·å¼å›¾åƒå¹¶ç»˜åˆ¶å®ƒã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="8f4e" class="lo jp hh lk b fi lp lq l lr ls"># setting up style image<br/>url="https://www.edvardmunch.org/images/paintings/the-scream.jpg"<br/>style_image=load_url_image(url,dim=(input_shape[0],input_shape[1]),resize=<strong class="lk hi">True</strong>)<br/>style_image=style_image/255.0</span><span id="6204" class="lo jp hh lk b fi lt lq l lr ls">show_image(style_image)</span></pre><p id="6c61" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">æ¥ä¸‹æ¥ï¼Œåˆ©ç”¨æŸå¤±æ¨¡å‹æå–é£æ ¼å›¾åƒçš„é£æ ¼å±‚ç‰¹å¾å›¾</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="2518" class="lo jp hh lk b fi lp lq l lr ls">style_image=style_image.astype(np.float32)<br/>style_image_batch=np.repeat([style_image],batch_size,axis=0)<br/>style_activations=loss_model.get_activations(style_image_batch)["style"]</span></pre><h1 id="287f" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">åŸ¹è®­æ¨¡å¼</h1><p id="4729" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">å®šä¹‰å†…å®¹æƒé‡ã€æ ·å¼æƒé‡å’Œæ€»å˜åŒ–æƒé‡è¿™äº›æ˜¯æˆ‘ä»¬å¯ä»¥è°ƒæ•´ä»¥æ”¹å˜è¾“å‡ºå›¾åƒä¸­æ ·å¼å’Œå†…å®¹çš„å¼ºåº¦çš„è¶…å‚æ•°</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="59b3" class="lo jp hh lk b fi lp lq l lr ls">content_weight=1e1<br/>style_weight=1e2<br/>total_variation_weight=0.004</span></pre><p id="6232" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ç°åœ¨å®šä¹‰è¦è®­ç»ƒçš„æ—¶æœŸæ•°ã€æ¯ä¸ªæ—¶æœŸçš„æ­¥æ•°å’Œæ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="6003" class="lo jp hh lk b fi lp lq l lr ls">epochs=2</span><span id="7992" class="lo jp hh lk b fi lt lq l lr ls">num_images=len(loader)<br/>steps_per_epochs=num_images//batch_size<br/>print(steps_per_epochs)</span><span id="6c14" class="lo jp hh lk b fi lt lq l lr ls">20695</span><span id="5ab5" class="lo jp hh lk b fi lt lq l lr ls">save_path = "./scream"</span><span id="dead" class="lo jp hh lk b fi lt lq l lr ls">os.makedirs(save_path, exist_ok=<strong class="lk hi">True</strong>)</span></pre><p id="c825" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒé€šè¿‡ä»¥åŠç²¾åº¦æ ¼å¼æ‰§è¡Œè¿ç®—ï¼Œå®ƒæä¾›äº†æ˜¾è‘—çš„è®¡ç®—åŠ é€Ÿã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="6dfe" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">try</strong>:<br/>    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')<br/>    tf.keras.mixed_precision.experimental.set_policy(policy) <br/><strong class="lk hi">except</strong>:<br/>    <strong class="lk hi">pass</strong></span></pre><p id="e163" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">å¦‚æœå…ˆå‰çš„æ£€æŸ¥ç‚¹å­˜åœ¨äºè¯¥è·¯å¾„ï¼Œåˆ™åŠ è½½è¯¥æ£€æŸ¥ç‚¹å¹¶ç»§ç»­è¿›ä¸€æ­¥è®­ç»ƒï¼Œå¦åˆ™æˆ‘ä»¬ä»å¤´å¼€å§‹è®­ç»ƒ</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="d35a" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">if</strong> os.path.isfile(os.path.join(save_path,"model_checkpoint.ckpt.index")):<br/>    style_model.load_weights(os.path.join(save_path,"model_checkpoint.ckpt"))<br/>    print("resuming training ...")<br/><strong class="lk hi">else</strong>:<br/>    print("training scratch ...")</span><span id="d3bd" class="lo jp hh lk b fi lt lq l lr ls">training scratch ...</span></pre><p id="041b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">æœ€åï¼Œæˆ‘ä»¬å¼€å§‹è®­ç»ƒæ¨¡å‹ã€‚åœ¨æ¯ä¸ªæ—¶æœŸï¼Œæˆ‘ä»¬è°ƒç”¨<code class="du lv lw lx lk b">train_step</code>å‡½æ•°ï¼Œè¯¥å‡½æ•°è¿è¡Œåˆ°æ¯ä¸ªæ—¶æœŸå®šä¹‰çš„æ­¥éª¤æ•°ï¼Œå¹¶ä¸”åœ¨æ¯ä¸ªæ—¶æœŸä¹‹åä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œç”¨äºè¿›ä¸€æ­¥çš„æ¨ç†å’Œè®­ç»ƒã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="146e" class="lo jp hh lk b fi lp lq l lr ls">epoch_losses=[]<br/><strong class="lk hi">for</strong> epoch <strong class="lk hi">in</strong> range(1,epochs+1):<br/>    print(f"epoch: {epoch}")<br/>    batch_loss=train_step(loader.dataset,style_activations,steps_per_epochs,style_model,loss_model,optimizer,<br/>                          save_path,<br/>                          content_weight,style_weight,total_variation_weight,<br/>                          content_layers_weights,style_layers_weights)<br/>    style_model.save_weights(os.path.join(save_path,"model_checkpoint.ckpt"))<br/>    print("Model Checkpointed at: ",os.path.join(save_path,"model_checkpoint.ckpt"))<br/>    print(f"loss: {batch_loss.numpy()}")<br/>    epoch_losses.append(batch_loss)</span><span id="ce75" class="lo jp hh lk b fi lt lq l lr ls">epoch: 1<br/>Model Checkpoint Path:  ./scream/model_checkpoint.ckpt<br/>checkpoint saved  Loss: 6567731.5<br/>checkpoint saved  Loss: 6464426.5<br/>checkpoint saved  Loss: 6402768.0<br/>checkpoint saved  Loss: 6336974.5<br/>checkpoint saved  Loss: 6281922.5<br/>checkpoint saved  Loss: 6232056.0<br/>checkpoint saved  Loss: 6191586.5<br/>checkpoint saved  Loss: 6155332.0<br/>checkpoint saved  Loss: 6119712.5<br/>checkpoint saved  Loss: 6085571.5<br/>checkpoint saved  Loss: 6062698.0<br/>checkpoint saved  Loss: 6036787.0<br/>checkpoint saved  Loss: 6011265.5<br/>checkpoint saved  Loss: 5988809.5<br/>checkpoint saved  Loss: 5969908.0<br/>checkpoint saved  Loss: 5950925.0<br/>checkpoint saved  Loss: 5931179.5<br/>checkpoint saved  Loss: 5912791.5<br/>checkpoint saved  Loss: 5894602.0<br/>checkpoint saved  Loss: 5880713.0<br/>Model Checkpointed at:  ./scream<br/>loss: 5869695.5<br/>epoch: 2<br/>Model Checkpoint Path:  ./scream/model_checkpoint.ckpt<br/>checkpoint saved  Loss: 5520494.5<br/>checkpoint saved  Loss: 5532450.5<br/>checkpoint saved  Loss: 5529669.0<br/>checkpoint saved  Loss: 5524684.0<br/>checkpoint saved  Loss: 5518524.5<br/>checkpoint saved  Loss: 5508913.5<br/>checkpoint saved  Loss: 5503493.5<br/>checkpoint saved  Loss: 5501864.0<br/>checkpoint saved  Loss: 5497016.0<br/>checkpoint saved  Loss: 5491713.0<br/>checkpoint saved  Loss: 5491244.5<br/>checkpoint saved  Loss: 5484620.0<br/>checkpoint saved  Loss: 5482881.0<br/>checkpoint saved  Loss: 5476766.5<br/>checkpoint saved  Loss: 5472491.0<br/>checkpoint saved  Loss: 5466294.5<br/>checkpoint saved  Loss: 5459984.0<br/>checkpoint saved  Loss: 5454912.5<br/>checkpoint saved  Loss: 5449535.5<br/>checkpoint saved  Loss: 5446370.0<br/>Model Checkpointed at:  ./scream<br/>loss: 5442546.5</span></pre><p id="5137" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">åœ¨è®­ç»ƒæ¨¡å‹ä¹‹åï¼Œè®©ç»˜åˆ¶ä¸æ—¶æœŸç›¸å…³çš„æŸå¤±ï¼Œå¹¶æ£€æŸ¥æŸå¤±æ‘˜è¦</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="cd95" class="lo jp hh lk b fi lp lq l lr ls">plt.plot(epoch_losses)<br/>plt.xlabel("Epochs")<br/>plt.ylabel("Loss")<br/>plt.title("Training Process")<br/>plt.show()</span></pre><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/a29608337530d1fd411dc7bc3e02c982.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/0*LbhIqYwtgiiKtF-s"/></div></figure><p id="2447" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ç°åœ¨æ˜¯æ—¶å€™ç”Ÿæˆä¸€äº›æ ·å¼å›¾åƒäº†ã€‚æˆ‘ä»¬é¦–å…ˆå°†ä¿å­˜çš„æ¨¡å‹æ£€æŸ¥ç‚¹åŠ è½½åˆ°autoencoderä¸­ã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="dbe9" class="lo jp hh lk b fi lp lq l lr ls"><strong class="lk hi">if</strong> os.path.isfile(os.path.join(save_path,"model_checkpoint.ckpt.index")):<br/>    style_model.load_weights(os.path.join(save_path,"model_checkpoint.ckpt"))<br/>    print("loading weights ...")<br/><strong class="lk hi">else</strong>:<br/>    print("no weights found ...")</span><span id="04a1" class="lo jp hh lk b fi lt lq l lr ls">loading weights ...</span></pre><p id="7d89" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">åŠ è½½å›¾åƒè¿›è¡Œæ ·å¼åŒ–ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºæµ®ç‚¹å‹ã€‚</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="8cf6" class="lo jp hh lk b fi lp lq l lr ls">test_image_url="https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/chicago-skyline-on-a-clear-day-royalty-free-image-115891582-1557159569.jpg"</span><span id="e8bf" class="lo jp hh lk b fi lt lq l lr ls">test_image=load_url_image(test_image_url,dim=(640,480))<br/>test_image=np.expand_dims(test_image,axis=0)</span><span id="00a5" class="lo jp hh lk b fi lt lq l lr ls">test_image=test_image.astype(np.float32)</span></pre><p id="6de8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">åœ¨æ¨¡å‹çš„ä¸€æ¬¡å‘å‰ä¼ é€’ä¸­ï¼Œæˆ‘ä»¬å¾—åˆ°ç”Ÿæˆçš„æ ·å¼å›¾åƒ</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="4826" class="lo jp hh lk b fi lp lq l lr ls">predicted_image=style_model(test_image)</span></pre><p id="0eec" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">å°†ç”Ÿæˆçš„å›¾åƒåƒç´ ç®ä½åœ¨0åˆ°255ä¹‹é—´ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºuint8ã€‚æˆ‘ä»¬å¾—åˆ°äº†æˆ‘ä»¬ç”Ÿæˆçš„é£æ ¼å›¾åƒï¼Œç»˜åˆ¶å®ƒå¹¶æ£€æŸ¥å®ƒçš„å¤–è§‚ï¼Œè¿˜ä¿å­˜å®ƒå¹¶ä¸æœ‹å‹åˆ†äº«</p><pre class="lf lg lh li fd lj lk ll lm aw ln bi"><span id="6814" class="lo jp hh lk b fi lp lq l lr ls">predicted_image=np.clip(predicted_image,0,255)<br/>predicted_image=predicted_image.astype(np.uint8)</span><span id="c26d" class="lo jp hh lk b fi lt lq l lr ls">test_output=test_image.astype(np.uint8)<br/>test_output=tf.squeeze(test_output).numpy()<br/>predicted_output=tf.squeeze(predicted_image).numpy()</span><span id="d8e2" class="lo jp hh lk b fi lt lq l lr ls">plot_images_grid([test_output,predicted_output])</span></pre><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ma"><img src="../Images/7fae5e2b8c87ece1f8ec80fa4fb523ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nTfFZhxBbczxzBRq"/></div></div></figure><p id="c3ef" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">å¦‚æœä½ æ²¡æœ‰è¶³å¤Ÿçš„è®¡ç®—èƒ½åŠ›ï¼Œä½¿ç”¨colabæˆ–kaggleå†…æ ¸ï¼Œä»–ä»¬æä¾›å…è´¹çš„GPUç”šè‡³TPUæ¥è®­ç»ƒè¿™äº›æ¨¡å‹ï¼Œä¸€æ—¦è®­ç»ƒå®Œæ¯•ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è®­ç»ƒå¥½çš„æ£€æŸ¥ç‚¹åœ¨ä»»ä½•æœ‰GPUæˆ–CPUçš„ç³»ç»Ÿä¸­è¿›è¡Œé£æ ¼è½¬æ¢ã€‚</p><p id="6e66" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ä½¿ç”¨<code class="du lv lw lx lk b">opencv</code>,æˆ‘ä»¬ä¹Ÿå¯ä»¥è½»æ¾åˆ›å»ºé£æ ¼è§†é¢‘ã€‚</p><h1 id="0069" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">ç»“æœ</h1><p id="3602" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated">ä¸€äº›å›¾åƒç»“æœ</p><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mb"><img src="../Images/9d984165b4867ca837d678d1a2db0bed.png" data-original-src="https://miro.medium.com/v2/resize:fit:952/0*yqH_9IGEYwHkIt4L"/></div></figure><figure class="lf lg lh li fd ii er es paragraph-image"><div class="er es mc"><img src="../Images/32196514533bbba2ad1699a058dbd11c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/0*b8Eupi3yXSWN8T6P"/></div></figure><figure class="lf lg lh li fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es md"><img src="../Images/ef22dea7bce9e50dad92a2e787c1a46e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*fbhZ8MWmJPdeAU5h"/></div></div></figure><p id="dece" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æœ‰å®æ—¶è§†é¢‘é£æ ¼åŒ–çš„è¡ŒåŠ¨</p><figure class="lf lg lh li fd ii"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="b99a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ä¸‹é¢æ˜¯è§†é¢‘é£æ ¼åŒ–çš„è¡ŒåŠ¨</p><figure class="lf lg lh li fd ii"><div class="bz dy l di"><div class="mg mf l"/></div></figure><figure class="lf lg lh li fd ii"><div class="bz dy l di"><div class="mg mf l"/></div></figure><p id="3df2" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">ç°åœ¨ç”Ÿæˆä¸åŒçš„å›¾åƒå’Œè§†é¢‘ï¼Œç©å®ƒï¼Œåˆ†äº«ä»¤äººå…´å¥‹çš„ç»“æœã€‚</p><p id="f206" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">å¦‚æœç°åœ¨æœ‰äººæƒ³å°è¯•è§†é¢‘å’Œå›¾åƒçš„é£æ ¼è½¬æ¢ï¼Œæˆ‘å·²ç»ä¸ºåŒæ ·çš„ç›®çš„åˆ›å»ºäº†ä¸€ä¸ª<a class="ae jn" href="https://github.com/tarun-bisht/fast-style-transfer" rel="noopener ugc nofollow" target="_blank"> githubåº“</a>ï¼Œå¹¶é™„æœ‰è¯´æ˜ã€‚</p><p id="3753" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">æ„Ÿè°¢é˜…è¯»ã€‚âœŒâœŒâœŒ</p><h1 id="c48b" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">å‚è€ƒ</h1><p id="88be" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated"><a class="ae jn" href="https://arxiv.org/abs/1607.08022" rel="noopener ugc nofollow" target="_blank">å®ä¾‹è§„èŒƒåŒ–:å¿«é€Ÿé£æ ¼åŒ–ç¼ºå°‘çš„è¦ç´ </a></p><p id="17b8" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae jn" href="https://arxiv.org/abs/1603.08155" rel="noopener ugc nofollow" target="_blank">å®æ—¶é£æ ¼è½¬æ¢å’Œè¶…åˆ†è¾¨ç‡çš„æ„ŸçŸ¥æŸå¤±</a></p><p id="25ce" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae jn" href="https://arxiv.org/abs/1508.06576" rel="noopener ugc nofollow" target="_blank">è‰ºæœ¯é£æ ¼çš„ç¥ç»ç®—æ³•</a></p><h1 id="627f" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">é‡è¦é“¾æ¥</h1><p id="c5ca" class="pw-post-body-paragraph ip iq hh ir b is km iu iv iw kn iy iz ja ko jc jd je kp jg jh ji kq jk jl jm ha bi translated"><a class="ae jn" href="https://github.com/tarun-bisht/fast-style-transfer" rel="noopener ugc nofollow" target="_blank"> Githubåº“</a></p><p id="9952" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae jn" href="https://github.com/tarun-bisht/blogs-notebooks/blob/master/style-transfer/Neural%20Style%20Transfer%20Part%202.ipynb" rel="noopener ugc nofollow" target="_blank">è°·æ­ŒColabç¬”è®°æœ¬</a></p><p id="2d05" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><a class="ae jn" href="https://www.youtube.com/watch?v=GrS4rWifdko" rel="noopener ugc nofollow" target="_blank"> Youtubeè§†é¢‘</a></p></div></div>    
</body>
</html>