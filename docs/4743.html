<html>
<head>
<title>A Simple Neural Network Classifier using PyTorch, from Scratch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一个简单的使用PyTorch的神经网络分类器，从零开始</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-simple-neural-network-classifier-using-pytorch-from-scratch-7ebb477422d2?source=collection_archive---------0-----------------------#2022-01-31">https://medium.com/analytics-vidhya/a-simple-neural-network-classifier-using-pytorch-from-scratch-7ebb477422d2?source=collection_archive---------0-----------------------#2022-01-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/381f9a0753d22a31355b5bd7658216e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oRWDq-aupHGn_qku3auPUA.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来源:<a class="ae iu" href="https://i0.wp.com/msalimali.com/wp-content/uploads/2019/06/connected-artificial-neural-network-nodes-msalimali.jpg?ssl=1" rel="noopener ugc nofollow" target="_blank">https://i0 . WP . com/msalimali . com/WP-content/uploads/2019/06/connected-artificial-neural-network-nodes-msalimali . jpg？ssl=1 </a></figcaption></figure><p id="5e5d" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">在本文中，我们将使用PyTorch构建一个简单的神经网络分类器模型。在本文中，我们将涵盖以下内容:</p><ul class=""><li id="3809" class="jt ju hi ix b iy iz jc jd jg jv jk jw jo jx js jy jz ka kb bi translated">步骤1:生成并分割数据</li><li id="e0a7" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">步骤2:处理生成的数据</li><li id="31ad" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">步骤3:从头开始构建神经网络分类器</li><li id="1417" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">步骤4:训练神经网络分类器</li><li id="c5f3" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">步骤5:保存训练好的模型</li><li id="1a61" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">步骤6:加载保存的模型</li><li id="3ee7" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">步骤7:测试训练好的模型</li></ul><h1 id="be1e" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated"><strong class="ak">依赖关系</strong></h1><ul class=""><li id="d93a" class="jt ju hi ix b iy lf jc lg jg lh jk li jo lj js jy jz ka kb bi translated">PyTorch v1.10.0</li><li id="72ea" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">sci kit-learn 1 . 0 . 2版</li><li id="6e25" class="jt ju hi ix b iy kc jc kd jg ke jk kf jo kg js jy jz ka kb bi translated">Numpy v1.19.5</li></ul><h1 id="a5d2" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">步骤1:生成并分割数据</h1><p id="48b6" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lk ji jj jk ll jm jn jo lm jq jr js hb bi translated">让我们使用Scikit-learn制作或生成我们的分类数据集</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="d8eb" class="lw ki hi ls b fi lx ly l lz ma">from sklearn.datasets import make_classification</span><span id="2eb2" class="lw ki hi ls b fi mb ly l lz ma">X, Y = make_classification(<br/>  n_samples=100, n_features=4, n_redundant=0,<br/>  n_informative=3,  n_clusters_per_class=2, n_classes=3<br/>)</span></pre><p id="0464" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们只生成很少的样本<code class="du mc md me ls b">100</code>，这可以通过改变<code class="du mc md me ls b">n_samples</code>参数来增加</p><p id="8e79" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，让我们将数据分为训练和测试。33 %的数据用于测试。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="caca" class="lw ki hi ls b fi lx ly l lz ma">from sklearn.model_selection import train_test_split</span><span id="b8db" class="lw ki hi ls b fi mb ly l lz ma">X_train, X_test, Y_train, Y_test = train_test_split(<br/>  X, Y, test_size=0.33, random_state=42)</span></pre><h1 id="a0df" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">步骤2:处理生成的数据</h1><p id="0ee8" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lk ji jj jk ll jm jn jo lm jq jr js hb bi translated">一旦获得训练和测试数据集，我们就使用PyTorch <code class="du mc md me ls b">Dataset</code>和<code class="du mc md me ls b">DataLoader</code>处理数据。<code class="du mc md me ls b">Dataset</code>存储样品及其相应的标签，<code class="du mc md me ls b">DataLoader</code>在<code class="du mc md me ls b">Dataset</code>周围包裹一个可重复标签，以便于获取样品。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="f4ee" class="lw ki hi ls b fi lx ly l lz ma">import numpy as np<br/>import torch<br/>from torch.utils.data import Dataset, DataLoader</span><span id="10f2" class="lw ki hi ls b fi mb ly l lz ma">class Data(Dataset):</span><span id="768a" class="lw ki hi ls b fi mb ly l lz ma">  def __init__(self, X_train, y_train):<br/>    # need to convert float64 to float32 else <br/>    # will get the following error<br/>    # RuntimeError: expected scalar type Double but found Float<br/>    self.X = torch.from_numpy(X_train.astype(np.float32))<br/>    # need to convert float64 to Long else <br/>    # will get the following error<br/>    # RuntimeError: expected scalar type Long but found Float<br/>    self.y = torch.from_numpy(y_train).type(torch.LongTensor)<br/>    self.len = self.X.shape[0]<br/>  <br/>  def __getitem__(self, index):<br/>    return self.X[index], self.y[index]</span><span id="b69e" class="lw ki hi ls b fi mb ly l lz ma">  def __len__(self):<br/>    return self.len</span></pre><p id="73c0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们创建了一个继承了<code class="du mc md me ls b">torch.utils.data.Dataset</code>属性的类。然后，训练数据按如下方式传递:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="39b7" class="lw ki hi ls b fi lx ly l lz ma">traindata = Data(X_train, Y_train)</span></pre><p id="e704" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在，可以使用索引轻松访问培训数据:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="8929" class="lw ki hi ls b fi lx ly l lz ma">print(traindata[25])<br/>'''<br/># Output<br/>(tensor([-0.9528,  1.6890, -0.6810,  0.7165]), tensor(1))<br/>'''</span></pre><p id="1b4e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还可以对训练数据进行如下分割:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="29d4" class="lw ki hi ls b fi lx ly l lz ma">print(traindata[25:34])<br/>'''<br/># Output<br/>(tensor([[-0.9528,  1.6890, -0.6810,  0.7165],<br/>         [ 0.6994,  4.5166,  0.5078, -2.0575],<br/>         [ 0.8508,  1.6109,  0.3014,  0.9455],<br/>         [ 1.1293, -0.8988,  1.6426, -0.0171],<br/>         [-0.2316,  1.9337, -0.9727, -0.1864],<br/>         [-1.0156,  1.1438, -0.0883,  0.6976],<br/>         [ 1.2509, -1.6992,  1.8562, -1.7159],<br/>         [ 1.1714,  0.9062, -1.5627, -0.5184],<br/>         [-1.1780, -2.7274, -1.0570,  1.9610]]),<br/> tensor([1, 2, 0, 0, 1, 1, 0, 0, 1]))<br/>'''</span></pre><p id="9acf" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来，我们使用<code class="du mc md me ls b">DataLoader</code>加载训练数据，我们将batch_size设置为4。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="129f" class="lw ki hi ls b fi lx ly l lz ma">batch_size = 4<br/>trainloader = DataLoader(traindata, batch_size=batch_size, <br/>                         shuffle=True, num_workers=2)</span></pre><h1 id="c438" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">步骤3:从头开始构建神经网络分类器</h1><p id="4664" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lk ji jj jk ll jm jn jo lm jq jr js hb bi translated">现在让我们建立我们的神经网络分类器</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="b09b" class="lw ki hi ls b fi lx ly l lz ma">import torch.nn as nn</span><span id="6fe3" class="lw ki hi ls b fi mb ly l lz ma"># number of features (len of X cols)<br/>input_dim = 4<br/># number of hidden layers<br/>hidden_layers = 25<br/># number of classes (unique of y)<br/>output_dim = 3</span><span id="72a9" class="lw ki hi ls b fi mb ly l lz ma">class Network(nn.Module):<br/>  def __init__(self):<br/>    super(Network, self).__init__()<br/>    self.linear1 = nn.Linear(input_dim, hidden_layers)<br/>    self.linear2 = nn.Linear(hidden_layers, output_dim)</span><span id="0c2b" class="lw ki hi ls b fi mb ly l lz ma">  def forward(self, x):<br/>    x = torch.sigmoid(self.linear1(x))<br/>    x = self.linear2(x)<br/>    return x</span></pre><p id="a9f0" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们可以通过调用它来初始化分类器:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="f223" class="lw ki hi ls b fi lx ly l lz ma">clf = Network()</span></pre><p id="6f51" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">我们还可以列出如下网络参数:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="380e" class="lw ki hi ls b fi lx ly l lz ma">print(clf.parameters)<br/>'''<br/># Output<br/>&lt;bound method Module.parameters of Network(<br/>  (linear1): Linear(in_features=4, out_features=25, bias=True)<br/>  (linear2): Linear(in_features=25, out_features=3, bias=True)<br/>)&gt;<br/>'''</span></pre><p id="64f4" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">接下来让我们定义我们的损失函数和优化器</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="cd8f" class="lw ki hi ls b fi lx ly l lz ma">criterion = nn.CrossEntropyLoss()<br/>optimizer = torch.optim.SGD(clf.parameters(), lr=0.1)</span></pre><h1 id="4e14" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">步骤4:训练神经网络分类器</h1><p id="c852" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lk ji jj jk ll jm jn jo lm jq jr js hb bi translated">现在我们已经为我们的训练做好了准备，让我们为我们的训练编码:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="ed1c" class="lw ki hi ls b fi lx ly l lz ma">epochs = 2<br/>for epoch in range(epochs):<br/>  running_loss = 0.0<br/>  for i, data in enumerate(trainloader, 0):<br/>    inputs, labels = data<br/>    # set optimizer to zero grad to remove previous epoch gradients<br/>    optimizer.zero_grad()<br/>    # forward propagation<br/>    outputs = clf(inputs)<br/>    loss = criterion(outputs, labels)<br/>    # backward propagation<br/>    loss.backward()<br/>    # optimize<br/>    optimizer.step()<br/>    running_loss += loss.item()<br/>  # display statistics<br/>  print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.5f}')</span></pre><p id="9d0c" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">出于演示的目的，我正在为<code class="du mc md me ls b">2</code>纪元进行培训，它可以根据需要进行更改。输出将如下所示:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="b80b" class="lw ki hi ls b fi lx ly l lz ma">[1,    17] loss: 0.00522<br/>[2,    17] loss: 0.00508</span></pre><h1 id="e46f" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">步骤5:保存训练好的模型</h1><p id="7d1f" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lk ji jj jk ll jm jn jo lm jq jr js hb bi translated">现在让我们保存我们训练好的模型:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="ec83" class="lw ki hi ls b fi lx ly l lz ma"># save the trained model<br/>PATH = './mymodel.pth'<br/>torch.save(clf.state_dict(), PATH)</span></pre><h1 id="3743" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">步骤6:加载保存的模型</h1><p id="7cd7" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lk ji jj jk ll jm jn jo lm jq jr js hb bi translated">然后可以加载本地保存的模型进行推理，使用以下代码:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="7523" class="lw ki hi ls b fi lx ly l lz ma">clf = Network()<br/>clf.load_state_dict(torch.load(PATH))<br/>'''<br/># Output<br/>&lt;All keys matched successfully&gt;<br/>'''</span></pre><h1 id="9c8a" class="kh ki hi bd kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le bi translated">步骤7:测试训练好的模型</h1><p id="3815" class="pw-post-body-paragraph iv iw hi ix b iy lf ja jb jc lg je jf jg lk ji jj jk ll jm jn jo lm jq jr js hb bi translated">一旦模型被加载，我们就可以测试我们训练好的模型。让我们测试一个小批量。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="1900" class="lw ki hi ls b fi lx ly l lz ma">testdata = Data(X_test, Y_test)<br/>testloader = DataLoader(testdata, batch_size=batch_size, <br/>                        shuffle=True, num_workers=2)</span></pre><p id="7bfa" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">从<code class="du mc md me ls b">DataLoader</code>获取一个小批量</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="a9f7" class="lw ki hi ls b fi lx ly l lz ma">dataiter = iter(testloader)<br/>inputs, labels = dataiter.next()</span></pre><p id="4352" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">测试输入将如下所示:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="5fdb" class="lw ki hi ls b fi lx ly l lz ma">print(inputs)<br/>'''<br/># Output<br/>tensor([[ 1.6876, -1.2382,  1.5971, -2.2628],<br/>        [ 0.7683,  0.3534,  0.0460, -1.2109],<br/>        [-1.0097,  1.1584, -0.0593,  0.7738],<br/>        [ 1.7332,  0.1764,  0.5259, -2.3073]])<br/>'''</span></pre><p id="cb3e" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">测试标签将如下所示:</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="e976" class="lw ki hi ls b fi lx ly l lz ma">print(labels)<br/>'''<br/># Output<br/>tensor([0, 2, 1, 0])<br/>'''</span></pre><p id="ae0a" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">现在让我们做推论</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="82d3" class="lw ki hi ls b fi lx ly l lz ma">outputs = clf(inputs)<br/>__, predicted = torch.max(outputs, 1)<br/>print(predicted)<br/>'''<br/># Output<br/>tensor([0, 0, 1, 0])<br/>'''</span></pre><p id="da93" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">看起来我们的代码像预期的那样工作，让我们对整个测试数据集进行推断。</p><pre class="ln lo lp lq fd lr ls lt lu aw lv bi"><span id="d110" class="lw ki hi ls b fi lx ly l lz ma">correct, total = 0, 0<br/># no need to calculate gradients during inference<br/>with torch.no_grad():<br/>  for data in testloader:<br/>    inputs, labels = data<br/>    # calculate output by running through the network<br/>    outputs = clf(inputs)<br/>    # get the predictions<br/>    __, predicted = torch.max(outputs.data, 1)<br/>    # update results<br/>    total += labels.size(0)<br/>    correct += (predicted == labels).sum().item()<br/>print(f'Accuracy of the network on the {len(testdata)} test data: {100 * correct // total} %')</span><span id="2f6f" class="lw ki hi ls b fi mb ly l lz ma">'''<br/># Output<br/>Accuracy of the network on the 33 test data: 75 %<br/>'''</span></pre><p id="ae25" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">该模型可以进一步改变以提高精确度。</p><p id="d666" class="pw-post-body-paragraph iv iw hi ix b iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js hb bi translated">编码快乐！！！</p></div></div>    
</body>
</html>