<html>
<head>
<title>SMOTE vs Deep Augmenter — testing the predictive power on imbalanced data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SMOTE与Deep Augmenter —测试不平衡数据的预测能力</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/smote-vs-deep-augmenter-testing-the-predictive-power-on-imbalanced-data-c85b34bd706b?source=collection_archive---------0-----------------------#2022-02-20">https://medium.com/analytics-vidhya/smote-vs-deep-augmenter-testing-the-predictive-power-on-imbalanced-data-c85b34bd706b?source=collection_archive---------0-----------------------#2022-02-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/304a57e902a03d8caf3ae486a7e5eb51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Q4jJ0efSrq6W2WIv"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">由<a class="ae it" href="https://unsplash.com/@kazuend?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> kazuend </a>在<a class="ae it" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</figcaption></figure><p id="efe3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这篇博客中，我想测试深度学习增强方法与流行的<a class="ae it" href="https://arxiv.org/pdf/1106.1813.pdf" rel="noopener ugc nofollow" target="_blank"> SMOTE </a>方法。为此，我再次使用了<a class="ae it" href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener ugc nofollow" target="_blank">信用卡欺诈数据集</a>。这个数据集是高度不平衡的，这意味着我们的欺诈案件比非欺诈案件少得多。目标是训练一个RandomForest模型来预测非欺诈与欺诈案例。为此，我将使用三种方法:</p><ul class=""><li id="e70d" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr jx jy jz ka bi translated">为欺诈案例分配更高的权重(随机森林的sklearn模型内置)</li><li id="639b" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">使用实施的SMOTE方法<a class="ae it" href="https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html" rel="noopener ugc nofollow" target="_blank">此处</a></li><li id="b8c2" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">使用<a class="ae it" href="https://github.com/lschmiddey/deep_tabular_augmentation" rel="noopener ugc nofollow" target="_blank">深度增强器</a></li></ul><p id="7491" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如何使用深度增强器包我已经在这里写了<a class="ae it" href="https://lasse-schmidt90.medium.com/comparison-randomforest-with-oversampling-vs-augmented-data-bd7fcb96ef0f" rel="noopener">这里写了</a>和<a class="ae it" rel="noopener" href="/analytics-vidhya/data-augmentation-for-tabular-data-f75c94398c3e">这里写了</a>。在信用卡欺诈数据集中，我们有199.032个非欺诈案例和332个欺诈案例。因此，让我们首先准备深度增强器，加载数据，只选择我们想要为其构建假数据的数据(在这种情况下是欺诈案例)，将其分为训练集和测试集，并将它们放入数据加载器。然后我们建立了我们的模型:</p><figure class="kg kh ki kj fd ii"><div class="bz dy l di"><div class="kk kl l"/></div></figure><p id="5a43" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在我们的模型被训练之后，我们现在可以使用它来创建欺诈案例的数据:</p><figure class="kg kh ki kj fd ii"><div class="bz dy l di"><div class="kk kl l"/></div></figure><p id="f189" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里的一个好处是，我们可以为每一列添加sigma参数。适马定义了标准差，我们把它作为一个列表传递，如果我们想让一些列有一个特定的标准差，你可以把它放在列表里。我确实使用了欺诈案例的标准差，但只有25%，因为这似乎给了数据足够的“回旋”空间，同时仍然保持了变量之间经过训练的关系(查看我关于潜在因素的博客<a class="ae it" href="https://lasse-schmidt90.medium.com/understand-latent-factors-in-deep-tabular-augmentation-fd6d9e2c1307" rel="noopener">这里</a>)。</p><p id="f08c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在我们使用SMOTE包来创建数据。SMOTE只需要(完整的)列车组和该列车组的目标值:</p><figure class="kg kh ki kj fd ii"><div class="bz dy l di"><div class="kk kl l"/></div></figure><p id="5040" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">所以基本上SMOTE会创建尽可能多的少数类条目，直到我们在两个类中得到相同数量的案例。我们也可以用深度学习增强器来做到这一点:</p><figure class="kg kh ki kj fd ii"><div class="bz dy l di"><div class="kk kl l"/></div></figure><p id="f4e8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在这两种情况下，我们现在模拟了199.032个欺诈案例。虽然SMOTE几乎可以立即创建这些合成数据，但深度学习增强需要大约一分钟。</p><h1 id="3b12" class="km kn hh bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">训练随机森林</h1><p id="12fd" class="pw-post-body-paragraph iu iv hh iw b ix lk iz ja jb ll jd je jf lm jh ji jj ln jl jm jn lo jp jq jr ha bi translated">我们想要比较内置的class_weight功能与新方法和SMOTE的性能。因此，我们将建立三个训练集:原始的一个，具有来自SMOTE的附加数据的一个，以及具有来自深度学习增强的附加数据的一个。</p><figure class="kg kh ki kj fd ii"><div class="bz dy l di"><div class="kk kl l"/></div></figure><p id="650f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，让我们在原始数据上训练模型，同时使用类出现的差异作为权重。</p><figure class="kg kh ki kj fd ii"><div class="bz dy l di"><div class="kk kl l"/></div></figure><p id="4bfd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们还可以为SMOTE和Deep Augmenter方法定义随机森林:</p><figure class="kg kh ki kj fd ii"><div class="bz dy l di"><div class="kk kl l"/></div></figure><p id="e1db" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">让我们运行所有这些模型:</p><figure class="kg kh ki kj fd ii"><div class="bz dy l di"><div class="kk kl l"/></div></figure><p id="1594" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">然后最后让我们比较结果。首先，class_weight方法:</p><figure class="kg kh ki kj fd ii er es paragraph-image"><div class="er es lp"><img src="../Images/b61689dea9d33767c64fca48089e5b22.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/1*dDqB7qvIjfUMipWFEv26ag.png"/></div></figure><p id="c570" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">二、SMOTE结果:</p><figure class="kg kh ki kj fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/0a98de4c492dddf5d098f0dda9a9c616.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/1*oebuxQqZj0IhhB0_2HVI6w.png"/></div></figure><p id="8234" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最后，深度增强器的结果是:</p><figure class="kg kh ki kj fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/2a34a54486841765f834672421b06c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:780/format:webp/1*GDbWrzilXCAEJ8RiGJjb4w.png"/></div></figure><p id="716d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们看到了这三种方法之间的巨大差异。简单地增加欺诈级别的权重没有任何帮助，我们只能正确识别4个欺诈案例。SMOTE方法可以发现更多的欺诈案例，在136个案例中发现了125个。这导致召回率为0.92。然而，这是有代价的:我们有惊人的1283个错误分类的欺诈案例，导致欺诈案例的精确度为0.09。深度学习增强正确预测了136个案例中的107个，但仅错误分类了58个案例——这导致欺诈案例的精确度为0.65。</p><p id="1513" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">总之，我认为这个博客能够展示深度学习增强的优点。在增加正确识别的欺诈案例的同时，我们还能够在这种情况下保持高精确度，这意味着我们只有少数错误分类的案例。虽然SMOTE能够正确识别更多的欺诈案例，但它也造成了大量错误分类的欺诈案例，这在资源分配方面可能代价高昂。</p><p id="3088" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果你有任何问题或者想在包裹里添加什么，就问我。</p><p id="4e65" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">拉塞</p><p id="ad88" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><em class="ls">原载于2022年2月19日</em><a class="ae it" href="https://lschmiddey.github.io/fastpages_/2022/02/19/DataAugmentation_vs_SMOTE.html" rel="noopener ugc nofollow" target="_blank"><em class="ls">https://lschmiddey . github . io</em></a><em class="ls">。</em></p></div></div>    
</body>
</html>