<html>
<head>
<title>Spam Classification using NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用自然语言处理的垃圾邮件分类</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/spam-classification-using-nlp-f360bdad5723?source=collection_archive---------5-----------------------#2021-09-17">https://medium.com/analytics-vidhya/spam-classification-using-nlp-f360bdad5723?source=collection_archive---------5-----------------------#2021-09-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/3bb79968d073117e976f2b634c25e1f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1226/format:webp/1*swa4O9TEexdIxNks-l-ptg.png"/></div></figure><h1 id="762a" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">介绍</h1><p id="5b6b" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">自然语言处理(NLP)是人工智能的一个子集，它帮助计算机理解、解释和利用人类语言。它还为计算机提供了读取文本数据、语音数据等并解释它们的能力。</p><p id="c297" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">NLP在现实世界中有多种应用，其中包括:</p><ol class=""><li id="c4e1" class="km kn hh jl b jm kh jq ki ju ko jy kp kc kq kg kr ks kt ku bi translated">情感分析</li><li id="00d8" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated">问答应用程序</li><li id="e340" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated">文本摘要</li><li id="09ed" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated">机器翻译</li><li id="410b" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated">垃圾邮件分类器</li><li id="b2c4" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated">命名实体识别</li></ol><p id="bbed" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">这些只是在NLP概念的基础上工作的几个例子。在本文中，我们将通过NLP项目中使用的基本演练，讨论一个使用NLP技术的关于<strong class="jl hi">垃圾邮件分类器</strong>的迷你项目。</p><p id="c1f2" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">以下是解决垃圾邮件分类器的小型NLP项目的步骤</p><ol class=""><li id="ab71" class="km kn hh jl b jm kh jq ki ju ko jy kp kc kq kg kr ks kt ku bi translated"><strong class="jl hi">标记化。</strong></li><li id="70b3" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated"><strong class="jl hi">删除停用词、标点符号和大小写(文本数据清理)。</strong></li><li id="868a" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated"><strong class="jl hi">词干化/词汇化。</strong></li><li id="b7c9" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated"><strong class="jl hi">通过单词包(BOW)将单词转换成向量。</strong></li><li id="029a" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated"><strong class="jl hi">数据集中的自变量和因变量。</strong></li><li id="8519" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated"><strong class="jl hi">创建模型和训练模型。</strong></li></ol><p id="be6a" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">现在让我们详细了解上述每个步骤:</p><h1 id="88b0" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">A]标记化</h1><p id="31e0" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">数据科学项目的第一步是获得正确的数据集。在垃圾邮件分类器数据集的情况下，包括输入和输出的大部分数据将是文本格式的。我们的第一项工作是将这些大量的文本转换成更小的标记(最小的语言单位)。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es la"><img src="../Images/a5118c2640a49c6e3fd6de15725f6f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UAehtcYeRQQzqWLAmEkSzQ.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">原始数据集图像</figcaption></figure><p id="2066" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">标记化是将大块文本分割成小块文本(标记)的过程。对一个段落来说，句子是一个记号，对一个句子来说，单词是一个记号。</p><p id="680d" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated"><strong class="jl hi">标记化的重要性是什么？</strong></p><p id="a338" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">大多数文本预处理模型，如单词袋、TF-IDF，通过将每个单词转换为向量并将其馈送给模型，在标记级别对每个单词进行预处理。这就是为什么我们把大文本转换成令牌。</p><h1 id="46e9" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">B]删除停用词、标点符号、大小写等(文本的数据清理)</h1><p id="bc1e" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">当我们在数据集中观察这些大量的文本时，我们必须在将它们转换成向量之前清理这些文本。在处理文本数据时，诸如is、on、if、as、the、why等词经常出现。我们的工作是删除这些停用词，因为它们在与标点符号一起进行预处理时不会发挥很大的作用。</p><p id="e404" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">在此之前，我们首先删除不需要的列，并更改所需列的名称。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es ln"><img src="../Images/c3e39337a293d5e8c62581ea4ceaec33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*JqVQi9QEQUeEtx_J-qQ-dg.png"/></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">删除列</figcaption></figure><p id="5582" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">现在我们有了包含两列的数据集:“消息”包含传入的文本,“标签”包含垃圾邮件或垃圾邮件。</p><p id="11bf" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">下一步是删除停用词，标点符号，并将其转换为小写，否则不同大小写的相同单词将被不同对待。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es lo"><img src="../Images/1560cf387445ae081e659902d0fb39d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5jkieFNwxkuLbA9siYsNXQ.png"/></div></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">文本数据清理代码</figcaption></figure><p id="dcef" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">我们将使用NLTK库并导入所有必需的类来完成必要的工作。</p><p id="6518" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">for循环将对“messages”列中的每一行运行，它将首先用空格替换所有不是a-z或A-Z的字符。然后它会使用lower()函数降低所有单词的大小写。下一步是在每一行上使用split()函数，这样它将转换为单词列表，然后我们可以处理每个单词。</p><p id="e774" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">最后一步是对那些不在停用词列表中的词进行词汇化，然后用空格将其连接起来。</p><h1 id="f24e" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">C]什么是词汇化？</h1><p id="ef28" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">词元化是通过去除词尾将所有相似的词还原到其词根形式的过程，因为它出现在字典中。我们这样做是为了实现一致性，因为在我们的数据中会有许多单词有相同的词根。</p><p id="7d9f" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">像研究、学习这样的词被转化为学习。</p><p id="2102" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">词干化类似于词汇化，但是词干化有时不会产生有意义的单词。因此，在单词的含义至关重要的情况下，如聊天机器人和Q/A应用程序，词汇化通常是首选，而词干在情感分析中大量使用。</p><h1 id="37cd" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">D]单词袋(蝴蝶结)</h1><p id="1a50" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">既然我们已经对文本数据进行了清理，现在是时候将该文本转换为数字/向量了，因为该模型不理解人类语言，所以我们通过一些技术将单词转换为向量，如单词包、TF-IDF和单词嵌入。</p><p id="644b" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">让我们在这里谈论一大堆单词。</p><h2 id="c6de" class="lp im hh bd in lq lr ls ir lt lu lv iv ju lw lx iz jy ly lz jd kc ma mb jh mc bi translated">什么是弓？</h2><p id="40db" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">单词包(BOW)是一种技术，其中我们首先创建文本中存在的唯一单词的词汇表，并通过每个单词在文档中的出现次数来表示每个单词。</p><p id="23ad" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">我们用一个例子来理解这个。让我们假设一个列包含一部电影的评论。</p><p id="6b99" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">评论1:电影很搞笑。</p><p id="fc3c" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">评论二:电影很长。</p><p id="dea0" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">点评3:电影不错。</p><p id="3647" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">首先创建独特单词的词汇表，然后为每个评论创建向量，在每一行中包含它们独特的外观。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="lf lg di lh bf li"><div class="er es md"><img src="../Images/5f692a4f3f115b1c450b1410f437aad0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7u1x7Wi8NdJYCjM58KmADg.png"/></div></div></figure><p id="c0c8" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">这只是一个简短的例子来解释工作弓。</p><h2 id="9fe7" class="lp im hh bd in lq lr ls ir lt lu lv iv ju lw lx iz jy ly lz jd kc ma mb jh mc bi translated">弓的缺点</h2><ol class=""><li id="f9e4" class="km kn hh jl b jm jn jq jr ju me jy mf kc mg kg kr ks kt ku bi translated">如果新句子包含新单词，那么词汇量也会增加，从而向量的长度也会增加。</li><li id="e68b" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated">向量将包含许多1和0，导致稀疏矩阵，并且稀疏矩阵在计算上是低效的。</li><li id="e8e5" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated">我们不保留文本的语法和排序信息。</li><li id="80d2" class="km kn hh jl b jm kv jq kw ju kx jy ky kc kz kg kr ks kt ku bi translated">更重要的词有时并不重要。</li></ol><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mh"><img src="../Images/7568e22c982818819000e0e03c00bc4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*HIsS3AYmr6YJqn1KqVKcmg.png"/></div></figure><p id="660d" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">CountVectorizer是用于单词包的类。在创建向量时，向量的大小可能会呈指数增长。为了避免这种情况，我们使用一个名为max_features的参数来避免这个问题。</p><p id="c10a" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">现在我们终于把单词转换成了向量。现在，我们将向量输入模型，用于训练目的。</p><h1 id="5c75" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">E]虚拟变量陷阱</h1><p id="ff6d" class="pw-post-body-paragraph jj jk hh jl b jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg ha bi translated">Label是我们数据集中的目标变量。标签包含两类:垃圾邮件和火腿。Model不理解spam和ham的含义，所以我们使用熊猫的get_dummies函数将spam和ham转换为1和0。</p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es mi"><img src="../Images/4fc554b388d7ca83f664fc1c49da6775.png" data-original-src="https://miro.medium.com/v2/resize:fit:712/format:webp/1*5e8ckYYe54hzoNtsmth0Rw.png"/></div><figcaption class="lj lk et er es ll lm bd b be z dx translated">虚拟变量陷阱</figcaption></figure><p id="8152" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">现在我们还有自变量(X)(消息)和因变量(y)(标签)。</p><p id="3f02" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">我们现在将数据分为训练和测试，并将训练数据提供给模型。我们将使用多项式朴素贝叶斯，我将在下一篇文章中讨论这一部分。</p><p id="6083" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">这就是这个迷你项目的特征工程部分，我们在其中处理了停用词、标点符号、大小写、词干、词汇化、单词包等。</p><p id="0c2e" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">我希望你们都喜欢这篇文章！</p><p id="196a" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">我将很快提出这个项目的最后阶段。</p><p id="2514" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">也可以在LinkedIn上与我联系，阅读更多与数据科学相关的帖子和文章。下面将提供链接。</p><div class="mj mk ez fb ml mm"><a href="https://www.linkedin.com/in/sameer-kumar-20988b1a6/" rel="noopener  ugc nofollow" target="_blank"><div class="mn ab dw"><div class="mo ab mp cl cj mq"><h2 class="bd hi fi z dy mr ea eb ms ed ef hg bi translated">Sameer Kumar -研究实习生- SCAAI -应用人工智能共生中心| LinkedIn</h2><div class="mt l"><h3 class="bd b fi z dy mr ea eb ms ed ef dx translated">嗨，我是Sameer，目前我正在共生技术学院攻读工程学士学位。当我还是个孩子的时候，我…</h3></div><div class="mu l"><p class="bd b fp z dy mr ea eb ms ed ef dx translated">www.linkedin.com</p></div></div><div class="mv l"><div class="mw l mx my mz mv na ij mm"/></div></div></a></div><p id="bfb7" class="pw-post-body-paragraph jj jk hh jl b jm kh jo jp jq ki js jt ju kj jw jx jy kk ka kb kc kl ke kf kg ha bi translated">快乐学习！！</p></div></div>    
</body>
</html>