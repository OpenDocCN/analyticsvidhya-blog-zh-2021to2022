<html>
<head>
<title>Auto Encoder Tutorial with TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlow自动编码器教程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/auto-encoder-tutorial-with-tensorflow-3bc53f0b29a2?source=collection_archive---------27-----------------------#2021-02-23">https://medium.com/analytics-vidhya/auto-encoder-tutorial-with-tensorflow-3bc53f0b29a2?source=collection_archive---------27-----------------------#2021-02-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="e495" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">自动编码器是一种无监督的神经网络，它有效地压缩数据(编码)，然后重建数据(解码)。它们被用于图像去噪和GANs(生成对抗网络)。GANs是将照片转换为绘画以及生成人脸照片等任务的首选网络。自动编码器有3个主要部分:</p><ol class=""><li id="9597" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated"><strong class="ig hi">编码器</strong>:通过缩小输入尺寸来压缩输入图像。</li><li id="af14" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated"><strong class="ig hi">解码器:</strong>将编码后的数据重建回原始图像。n这样做，有一个<strong class="ig hi">重建损失</strong>。神经网络的目标是尽量减少这种损失。</li><li id="be68" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated"><strong class="ig hi">瓶颈:</strong>它是编码器和解码器之间的层，包含最压缩的输入形式。</li></ol><p id="bc80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们看一下在TensorFlow中训练自动编码器的代码。首先，我们导入所有必要的模块:</p><pre class="jq jr js jt fd ju jv jw jx aw jy bi"><span id="aef2" class="jz ka hh jv b fi kb kc l kd ke">from tensorflow.keras import Layers<br/>from tensorflow.keras.datasets import fashion_mnist<br/>from tensorflow.keras.optimizers import Adam<br/>from tensorflow.keras.models import Model<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>from matplotlib.figure import Figure</span></pre><p id="ee93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">接下来，我们将导入并格式化数据。在这个例子中，我们将使用MNIST数据集。</p><pre class="jq jr js jt fd ju jv jw jx aw jy bi"><span id="4504" class="jz ka hh jv b fi kb kc l kd ke">(x_train, y_train), (x_test, y_test) = mnist.load_data()<br/>x_train = x_train.astype('float32')/255.<br/>x_train = np.expand_dims(x_train, axis=1)<br/>x_train = np.reshape(x_train, (60000, 28, 28, 1))</span><span id="9878" class="jz ka hh jv b fi kf kc l kd ke">x_test = x_test.astype('float32')/255.<br/>x_test = np.expand_dims(x_test, axis=1)<br/>x_test = np.reshape(x_test, (10000, 28, 28, 1))</span></pre><p id="6566" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这段代码可能看起来有些混乱，所以让我们一行一行地检查一下。</p><p id="8442" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，我们将这些值转换成。浮点数，并在0-1的范围内对数据进行规范化，而不是0-255。如果我们跳过这一步，损失将会非常大，因为我们将会处理更大的数字。接下来的两行用于将数据格式化为正确的维度，以供模型使用。测试数据<code class="du kg kh ki jv b">x_test</code>经历完全相同的过程(标准化和格式化尺寸)。</p><p id="d4c2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们现在将定义编码器的架构:</p><pre class="jq jr js jt fd ju jv jw jx aw jy bi"><span id="7ba3" class="jz ka hh jv b fi kb kc l kd ke"># encoder<br/>input = Input((28, 28, 1))<br/>x = Conv2D(8, (4, 4), activation="relu", padding="same")(input)<br/>x = MaxPooling2D((2, 2), padding="same")(x)<br/>x = Conv2D(4, (4, 4), padding="same", activation="relu")(x)<br/>x = MaxPooling2D((2, 2), padding="same")(x)<br/>x = Conv2D(4, (4, 4), padding="same", activation="relu")(x)</span><span id="c29e" class="jz ka hh jv b fi kf kc l kd ke">encoded = MaxPooling2D((2, 2), padding="same")(x) # bottleneck</span><span id="9c3e" class="jz ka hh jv b fi kf kc l kd ke">#decoder<br/>x = Conv2D(4, (4, 4), activation="relu", padding="same")(encoded)<br/>x = UpSampling2D((2, 2))(x)<br/>x = Conv2D(4, (4, 4), activation="relu", padding="same")(x)<br/>x = UpSampling2D((2, 2))(x)<br/>x = Conv2D(8, (4, 4), activation="relu", padding="same")(input)<br/>decoded = Conv2D(1, (4, 4), padding="same")(x)</span></pre><p id="f3b6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在编码器和解码器中，卷积层与MaxPooling结合使用以降低维度，而上采样则增加维度。</p><p id="0f55" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一步是编译、训练和评估模型。<code class="du kg kh ki jv b">binary_crossentropy</code>在这里，指重建损失。我们正在使用亚当优化器进行训练。最后，我们使用测试数据集评估模型，并打印平均重建损失。</p><pre class="jq jr js jt fd ju jv jw jx aw jy bi"><span id="87a0" class="jz ka hh jv b fi kb kc l kd ke">model = Model(inputs=input, outputs=decoded)<br/>model.compile(loss="binary_crossentropy", optimizer=Adam())</span><span id="16f6" class="jz ka hh jv b fi kf kc l kd ke">model.fit(x_train, x_train, epochs=5, batch_size=64, shuffle=True)<br/>scores = model.evaluate(x_test, x_test)<br/>print("loss: ", scores)</span></pre><p id="0fc8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了更好地理解模型，并验证它的训练，我们可以在通过自动编码器之前和之后显示一些图像。</p><pre class="jq jr js jt fd ju jv jw jx aw jy bi"><span id="5fa7" class="jz ka hh jv b fi kb kc l kd ke">in_imgs = x_train[:5] # 5 images from the training data<br/>out_imgs = model.predict(in_imgs) # model output for the images</span><span id="4907" class="jz ka hh jv b fi kf kc l kd ke">Figure(figsize=(20, 4)) # creating a matplotlib figure<br/>for i in range(5):<br/>    # image processing for input images<br/>    ax = plt.subplot(2, 5, i + 1)<br/>    plt.imshow(in_imgs[i].reshape(28, 28))<br/>    plt.gray()<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)</span><span id="adc7" class="jz ka hh jv b fi kf kc l kd ke">    # image processing for output images<br/>    ax = plt.subplot(2, 5, i + 1 + 5)<br/>    plt.imshow(out_imgs[i].reshape(28, 28))<br/>    plt.gray()<br/>    ax.get_xaxis().set_visible(False)<br/>    ax.get_yaxis().set_visible(False)</span><span id="e402" class="jz ka hh jv b fi kf kc l kd ke">plt.show()</span></pre><figure class="jq jr js jt fd kk er es paragraph-image"><div class="er es kj"><img src="../Images/d5658592d14f48c3201e940ea3957d9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*Aaq1m_GaDWnvDs9D9IMJpw.png"/></div><figcaption class="kn ko et er es kp kq bd b be z dx translated">自动编码器几乎完美地重建了数字</figcaption></figure><p id="3e8a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，您已经成功地在MNIST数据集上构建并训练了一个简单的自动编码器。敬请关注更多关于AI/ML的文章！</p></div></div>    
</body>
</html>