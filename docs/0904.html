<html>
<head>
<title>TensorFlow 2.0 for Deep Learning - Convolutional Neural Networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于深度学习的TensorFlow 2.0卷积神经网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tensorflow-2-0-for-deep-learning-convolutional-neural-networks-26153b2d078?source=collection_archive---------14-----------------------#2021-02-05">https://medium.com/analytics-vidhya/tensorflow-2-0-for-deep-learning-convolutional-neural-networks-26153b2d078?source=collection_archive---------14-----------------------#2021-02-05</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/3dd7f4e207afdba130558f3d5e241166.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VojPKNOr1_WApkZED7Jezw.jpeg"/></div></div></figure><h1 id="c7f7" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">什么是卷积神经网络？</h1><p id="0e20" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">卷积神经网络是一种主要用于图像数据集的神经网络，卷积网络的共享参数特征减少了模型的参数数量，这也使其在模式<strong class="jp hi">边缘检测中有效。<em class="kl"> </em> </strong>这篇博文包含了用tensorflow 2.0在猫和狗的数据集上实现卷积神经网络</p><h1 id="fe0d" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">关于数据集</h1><p id="c280" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">猫对狗数据集是机器学习领域最著名的数据集之一，由pathfinder.com的<strong class="jp hi">和微软的<strong class="jp hi">合作开发。</strong></strong></p><p id="a626" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><em class="kl">数据集位于:</em><strong class="jp hi"><em class="kl"/></strong><a class="ae kr" href="https://www.microsoft.com/en-us/download/details.aspx?id=54765" rel="noopener ugc nofollow" target="_blank"><em class="kl">https://www.microsoft.com/en-us/download/details.aspx?id = 54765</em>T17】</a></p><p id="8598" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><em class="kl">在我们开始创建神经网络之前，先看看我的</em> <a class="ae kr" rel="noopener" href="/analytics-vidhya/create-your-own-real-image-dataset-with-python-deep-learning-b2576b63da1e"> <em class="kl">“如何准备图像数据集”</em> </a> <em class="kl">博客，进行图像预处理。</em></p><h1 id="fd64" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">Tensorflow 2卷积神经网络</h1><ol class=""><li id="0566" class="ks kt hh jp b jq jr ju jv jy ku kc kv kg kw kk kx ky kz la bi translated"><strong class="jp hi">导入数据集</strong></li></ol><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="8712" class="lk iq hh lg b fi ll lm l ln lo">#importing the libraries<br/>import tensorflow as tf<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import cv2</span><span id="38ee" class="lk iq hh lg b fi lp lm l ln lo">#importing the data<br/>dataset = np.load('dogsvscats.npy')<br/>labels = np.load('targets.npy')<br/>print("shape of the data is : ",dataset.shape)</span></pre><p id="bc7f" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">我们在这里所做的就是导入所需的库和数据集。<br/> <em class="kl">查看我的</em> <a class="ae kr" rel="noopener" href="/analytics-vidhya/create-your-own-real-image-dataset-with-python-deep-learning-b2576b63da1e"> <em class="kl">【如何准备图像数据集】</em> </a> <em class="kl">博客进行图像预处理，了解图像数据是如何存储的。</em></p><p id="1448" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">我们将图像和标签存储在。npy文件</p><p id="8d5d" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi"> 2。列车试运行</strong></p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="dacf" class="lk iq hh lg b fi ll lm l ln lo">#shuffling the dataset<br/>seed = np.random.randint(0,1000)<br/>np.random.seed(seed)<br/>np.random.shuffle(dataset)<br/>np.random.seed(seed)<br/>np.random.shuffle(labels)<br/>plt.imshow(dataset[0])<br/>print(labels[0])</span><span id="8d5b" class="lk iq hh lg b fi lp lm l ln lo">#training and test set split<br/>from sklearn.model_selection import train_test_split<br/>x_train, x_test, y_train, y_test = train_test_split(dataset,labels)</span></pre><p id="74bc" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">只需将数据集打乱并分成训练集和测试集</p><p id="98d1" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi"> 3。缩放图像</strong></p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="dece" class="lk iq hh lg b fi ll lm l ln lo">#scaling the images<br/>x_train = x_train/255.<br/>x_test = x_test/255.</span></pre><p id="7797" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">这听起来可能很简单，但是对于算法的工作非常重要。</p><p id="b6fc" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi"> 4。神经网络</strong></p><p id="5374" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">在你的机器或Google Colab的GPU上运行下面的代码</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="de9e" class="lk iq hh lg b fi ll lm l ln lo">#creating a model<br/>i = tf.keras.layers.Input(shape=(50,50,3))<br/><br/>#first layer<br/>conv1 = tf.keras.layers.Conv2D(filters=10,kernel_size=(5,5),strides=(1,1),padding='same',activation=tf.keras.activations.relu)(i)<br/>pool1 = tf.keras.layers.MaxPool2D((2,2))(conv1)<br/>batch1 = tf.keras.layers.BatchNormalization()(pool1)<br/><br/>#second layer<br/>conv2 = tf.keras.layers.Conv2D(filters=28,kernel_size=(3,3),strides=(1,1),padding='same',activation=tf.keras.activations.relu)(batch1)<br/>pool2 = tf.keras.layers.MaxPool2D((2,2))(conv2)<br/>batch2 = tf.keras.layers.BatchNormalization()(pool2)<br/><br/>#third layer<br/>conv3 = tf.keras.layers.Conv2D(filters=50,kernel_size=(5,5),strides=(1,1),padding='same',activation=tf.keras.activations.relu)(batch2)<br/>pool3 = tf.keras.layers.MaxPool2D((2,2))(conv3)<br/>batch3 = tf.keras.layers.BatchNormalization()(pool3)<br/><br/>#fourth layer<br/>conv4 = tf.keras.layers.Conv2D(filters=100,kernel_size=(3,3),strides=(1,1),padding='same',activation=tf.keras.activations.relu)(batch3)<br/>pool4 = tf.keras.layers.MaxPool2D((2,2))(conv4)<br/>batch4 = tf.keras.layers.BatchNormalization()(pool4)<br/><br/>#fifth layer<br/>conv5 = tf.keras.layers.Conv2D(filters=180,kernel_size=(3,3),strides=(1,1),padding='same',activation=tf.keras.activations.relu)(batch4)<br/>pool5 = tf.keras.layers.MaxPool2D((2,2))(conv5)<br/>batch5 = tf.keras.layers.BatchNormalization()(pool5)<br/><br/>#sixth layer<br/>flatten1 = tf.keras.layers.Flatten()(batch5)<br/>fc1 = tf.keras.layers.Dense(512,activation=tf.keras.activations.relu)(flatten1)<br/>fc2 = tf.keras.layers.Dense(700,activation=tf.keras.activations.relu,kernel_regularizer=tf.keras.regularizers.l1(l1=0.01))(fc1)<br/><br/>#final layer<br/>output = tf.keras.layers.Dense(1,activation=tf.keras.activations.sigmoid)(fc2)<br/><br/>model = tf.keras.models.Model(i,output)</span><span id="d4fb" class="lk iq hh lg b fi lp lm l ln lo">#optimizer and loss<br/>model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),loss=tf.keras.losses.binary_crossentropy,metrics=['accuracy'])</span><span id="2da0" class="lk iq hh lg b fi lp lm l ln lo">#train the model<br/>train = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=5)</span></pre><p id="0198" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">这类似于我们在之前的博客文章中创建的模型。但是，我们在这里使用卷积层<strong class="jp hi"> ( Conv2D ) </strong>，它允许您指定滤波器的数量、内核大小和其他东西，如步长等。<br/>然后我们还使用<strong class="jp hi">汇集</strong>和<strong class="jp hi">批量规格化</strong>层。使用的损失函数是二元交叉熵，因为这是一个二元分类问题。然后我们训练这个模型</p><p id="4f90" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">输出:</strong></p><figure class="lb lc ld le fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lq"><img src="../Images/76c6eb12b7b35316f7cf5a7e223b74d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K2K6dyisbFITZQOglLkVhg.png"/></div></div></figure><p id="8d28" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi"> 5。模型性能分析</strong></p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="9cd1" class="lk iq hh lg b fi ll lm l ln lo">#plotting accuracy<br/>plt.plot(train.history['accuracy'],label='train acc')<br/>plt.plot(train.history['val_accuracy'],label='validation acc')<br/>plt.legend()</span><span id="4d78" class="lk iq hh lg b fi lp lm l ln lo">#plotting loss<br/>plt.plot(train.history['loss'],label='train loss')<br/>plt.plot(train.history['val_loss'],label='validation loss')<br/>plt.legend()</span></pre><p id="6949" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">输出:</strong></p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/3aee5369c3f8510a084cb6ce417d26e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:772/format:webp/1*B2qOpJHEV-iwXk1alDCIpA.png"/></div></figure><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es ls"><img src="../Images/a3806f21724ab25cb37f179e44e6e960.png" data-original-src="https://miro.medium.com/v2/resize:fit:826/format:webp/1*TTbcpGCpRVLb6gSZskBzzw.png"/></div></figure><p id="481b" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi"> 6。保存模型</strong></p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="021c" class="lk iq hh lg b fi ll lm l ln lo">#saving the model<br/>model.save('catsvsdogs1.h5')</span></pre><p id="9299" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">不要忘记保存模型，因为卷积神经网络需要很长时间来训练</p><p id="3bff" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi"> 7。从测试集</strong>中进行随机预测</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="728f" class="lk iq hh lg b fi ll lm l ln lo">#making a random prediction<br/>import random <br/>ran = random.randint(0,5000)<br/>y_pred = model.predict(x_test[ran].reshape(-1,50,50,3))<br/>plt.imshow(x_test[ran])<br/>y_pred.round()<br/>if y_pred == 1:<br/>    print("Dog")<br/>else:<br/>    print("Cat")</span></pre><p id="c0bc" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">输出:</strong></p><figure class="lb lc ld le fd ii er es paragraph-image"><div class="er es lt"><img src="../Images/4be0183e0559eb2074f78f71f8834852.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*CCCHpZCE37y9-4pgBlUqWQ.png"/></div></figure><h1 id="5329" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">结论</h1><p id="85e5" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">这就是创建卷积神经网络的方法。对于图像预处理步骤，如果你正在使用google colab，请参考我在上面分享的链接。</p><h2 id="1aa9" class="lk iq hh bd ir lu lv lw iv lx ly lz iz jy ma mb jd kc mc md jh kg me mf jl mg bi translated">谢谢你</h2></div></div>    
</body>
</html>