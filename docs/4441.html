<html>
<head>
<title>ArcFace: Facial Recognition Model</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ArcFace:面部识别模型</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/arcface-facial-recognition-model-2eb77080aa80?source=collection_archive---------3-----------------------#2021-10-13">https://medium.com/analytics-vidhya/arcface-facial-recognition-model-2eb77080aa80?source=collection_archive---------3-----------------------#2021-10-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="91bb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ArcFace是用于面部识别的开源先进模型。作者姜康等人在2018年发表了一篇题为<a class="ae jc" href="https://arxiv.org/abs/1801.07698" rel="noopener ugc nofollow" target="_blank"><strong class="ig hi">arc Face:深度人脸识别的加性角裕度损失</strong> </a>的论文。在<a class="ae jc" href="http://vis-www.cs.umass.edu/lfw/" rel="noopener ugc nofollow" target="_blank"> LFW数据集</a>中表现出了<strong class="ig hi"> 99.82% </strong>准确率的优异表现。本文对论文进行了简要的分析和说明。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/3162c570e31d8cdc4fd07069e5c05d9b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-L4iFnTh7ZJlgMgB8HPfyg.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated"><a class="ae jc" href="https://www.iflexion.com/blog/facial-recognition-software" rel="noopener ugc nofollow" target="_blank">https://www.iflexion.com/blog/facial-recognition-software</a></figcaption></figure></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="958e" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">介绍</h1><p id="f687" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">DCNNs用于面部识别已经有一段时间了。有许多研究论文提出了各种版本的模型来完善识别和验证人脸的技术。一些是使用Softmax分类器的<a class="ae jc" href="https://papers.nips.cc/paper/2014/hash/e5e63da79fcd2bebbd7cb8bf1c1d0274-Abstract.html" rel="noopener ugc nofollow" target="_blank">多类分类器</a>，其他的产生人脸的<a class="ae jc" href="https://arxiv.org/abs/1503.03832" rel="noopener ugc nofollow" target="_blank">嵌入(FaceNet) </a>。然而，许多这种方法的一个主要问题是损失函数缺乏区分人脸的强辨别能力。</p><p id="0a80" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以前的工作，如<a class="ae jc" href="https://arxiv.org/abs/1704.08063" rel="noopener ugc nofollow" target="_blank"> Sphereface </a>提出了DCNN的最后一个全连接层的权重与不同类别的人脸具有相似性的想法。这被用来开发一个损失函数，该函数实现了“类内紧密性和类间差异”。然而，为了实现这一点，sphereface必须做出许多假设，导致网络训练不稳定。<a class="ae jc" href="https://arxiv.org/abs/1801.09414" rel="noopener ugc nofollow" target="_blank"> CosFace </a>更进一步使损失函数更有效，但它也遭受不一致性。</p><p id="7cac" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">相反，Arcface会对DCNN要素的点积和最后一个完全连接图层的权重进行附加惩罚。根据论文作者的说法，这最大限度地减少了以前工作中解决的问题，并证明更具吸引力、更有效、更易于实施和更高效。</p><h1 id="22cd" class="ka kb hh bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">方法</h1><p id="38e5" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">最广泛使用的分类损失函数softmax loss如下所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es li"><img src="../Images/eb79e6a7f3bdaba0fa2d4c6e7b9cd076.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*G4XBsSDA0ErBigojJzgfjg.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">最大损失函数</figcaption></figure><p id="0a98" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中'<strong class="ig hi"/>'表示深度特征，<strong class="ig hi"> b </strong>为偏差，<strong class="ig hi"> N </strong>为批量，<strong class="ig hi"> n </strong>为类号，<strong class="ig hi">【w】</strong>为最后一层的权重，<strong class="ig hi">嵌入特征</strong>维数为512。这对于区分不同类别的高相似性嵌入来说不是最佳的，这导致了性能差距。这就是Arcface的用武之地。它在损失函数中提供了以下变化。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lj"><img src="../Images/cbf172dae108d9b3c620d242dfbdc3d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eM6PMwew5TgP4wujTi8xww.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">弧面损失函数</figcaption></figure><p id="c611" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">弧面损失函数本质上取权重<strong class="ig hi">‘w’</strong>和<strong class="ig hi">‘x’</strong>特征的点积，其中<strong class="ig hi"> θ </strong>是<strong class="ig hi">‘w’</strong>和<strong class="ig hi">‘x’</strong>之间的角度，然后对其加上罚值<strong class="ig hi">‘m’</strong>。<strong class="ig hi">‘w’</strong>使用l2范数进行归一化，<strong class="ig hi">‘x’</strong>已经使用l2范数进行归一化，并通过因子<strong class="ig hi">s’进行缩放。</strong>这使得预测仅依赖于角度<strong class="ig hi"> θ </strong>或权重和特征之间的余弦距离。整个过程如下所示。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lk"><img src="../Images/52b5f35a2185542ea700ec8b3d0bb56a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M1Xmxeuy8ULH_sGDI3w7iA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来自原始纸张的图像</figcaption></figure><h1 id="c2d5" class="ka kb hh bd kc kd ld kf kg kh le kj kk kl lf kn ko kp lg kr ks kt lh kv kw kx bi translated">估价</h1><p id="5dcf" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">本文提出的损失函数显示了清晰的类间区别，并减少了类内差距，使其优于以前提出的其他方法。该论文还对最近的面部识别方法进行了特别广泛的评估，并在各种基准数据集上与ArcFace进行了比较。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/cc6bee5f0c5450d6de9dcfba4af96ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eFB6ucd6IObRxoug7t4fDA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来自原始纸张的图像</figcaption></figure><p id="0d16" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">上图显示了二元分类情况下不同损失函数的决策余量。虚线代表决策边界，灰色区域是决策余量。此外，下表详细介绍了ArcFace在3个不同基准数据集上的性能，并与其他几种方法进行了对比。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lm"><img src="../Images/bb75b26422c2738b8bd7fa98c5f517c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2sgbv7hi9ToaScxf9tVQKA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">来自原始纸张的图像</figcaption></figure></div><div class="ab cl jt ju go jv" role="separator"><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy jz"/><span class="jw bw bk jx jy"/></div><div class="ha hb hc hd he"><h1 id="c290" class="ka kb hh bd kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx bi translated">结论</h1><p id="231b" class="pw-post-body-paragraph ie if hh ig b ih ky ij ik il kz in io ip la ir is it lb iv iw ix lc iz ja jb ha bi translated">文章浓缩了ArcFace的关键概念，并说明了它的意义。原文链接<a class="ae jc" href="https://arxiv.org/abs/1801.07698" rel="noopener ugc nofollow" target="_blank">这里</a>代码可以在<a class="ae jc" href="https://github.com/deepinsight/insightface" rel="noopener ugc nofollow" target="_blank">这里</a>找到。它的一个优秀pytorch实现可以从这个<a class="ae jc" href="https://github.com/ronghuaiyang/arcface-pytorch" rel="noopener ugc nofollow" target="_blank"> repo中复制。</a></p></div></div>    
</body>
</html>