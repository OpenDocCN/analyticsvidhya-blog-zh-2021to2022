<html>
<head>
<title>Building a web scraper from start to finish</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从头到尾构建一个web刮刀</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/building-a-web-scraper-from-start-to-finish-4ad567043af0?source=collection_archive---------31-----------------------#2021-01-17">https://medium.com/analytics-vidhya/building-a-web-scraper-from-start-to-finish-4ad567043af0?source=collection_archive---------31-----------------------#2021-01-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="ed0a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用美丽的汤和硒。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/47c2034b6a9bff2870364c820703adb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*sct9FWdT4Yi5Uxox"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">在<a class="ae js" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上<a class="ae js" href="https://unsplash.com/@enginakyurt?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> engin akyurt </a>拍摄的照片</figcaption></figure><p id="170d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">什么是网络刮刀？</strong></p><p id="698d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">web scraper是一种从网站上抓取或提取数据的程序。从网站上简单的复制粘贴数据也被称为网络抓取。网络抓取用于在线价格比较，并通过从竞争对手的网站中提取数据来了解他们的表现，还可以用于许多其他方面。</p><p id="b8a1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">我们需要具备哪些先决条件来打造一个web scraper？</strong></p><p id="5809" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">看看下面的简单工作流程:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jt"><img src="../Images/65f3ce7c9ea258b24bfea6a5743a7118.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9p4yJ2WG69ECs4PQ_8NfFA.jpeg"/></div></div></figure><p id="b459" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">web抓取的基本思想是我们获取现有的HTML数据，使用web scraper来识别数据并将其转换为有用的格式。最后一步是以JSON或其他有用的格式存储数据。在这个例子中，我们将数据存储在一个列表中。我们将重点介绍如何使用Python，以及它的库美汤进行抓取。这里需要注意的是，为了成功地抓取数据，我们必须具备HTML结构的基础知识。</p><p id="cf50" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">安装库</strong></p><p id="df5e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在开始这个例子之前，让我们使用pip安装一些库。</p><blockquote class="ju jv jw"><p id="6dd6" class="ie if jx ig b ih ii ij ik il im in io jy iq ir is jz iu iv iw ka iy iz ja jb ha bi translated">pip安装bs4</p><p id="e4f9" class="ie if jx ig b ih ii ij ik il im in io jy iq ir is jz iu iv iw ka iy iz ja jb ha bi translated">pip安装硒</p></blockquote><p id="1d1a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这个例子中，我们将使用美丽的汤和硒来收集数据。</p><p id="9ee1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> Beautiful Soup </strong>是一个Python库，用于web抓取目的，从HTML和XML文件中提取数据。</p><p id="2053" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> Selenium </strong>是一个用于测试自动化的开源工具。</p><h1 id="ef97" class="kb kc hh bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky bi translated">所以让我们从这个例子开始吧！！！！</h1><p id="67cb" class="pw-post-body-paragraph ie if hh ig b ih kz ij ik il la in io ip lb ir is it lc iv iw ix ld iz ja jb ha bi translated">在本例中，我们将构建一个刮刀，从<a class="ae js" href="https://www.icc-cricket.com/" rel="noopener ugc nofollow" target="_blank"> ICC </a>官方网站收集数据。谁不看板球，嗯？我们将根据球员在ODI(一日国际赛)中的表现收集他们的详细信息。</p><p id="3173" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每个web抓取项目都需要有一个<a class="ae js" href="https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting" rel="noopener ugc nofollow" target="_blank"> URL </a>来抓取。点击网址打开网站并复制网址。</p><p id="c126" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">导入已安装的库</strong></p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="b7d5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">导入库后，我们将创建一个webdriver实例来加载URL。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="1df0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们分解代码。</p><p id="d2e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先，我创建了一个URL变量来存储URL。然后创建了webdriver的一个实例，并传递了webdriver的下载路径。</p><blockquote class="lg"><p id="ae22" class="lh li hh bd lj lk ll lm ln lo lp jb dx translated">driver = webdriver。PhantomJS(executable _ path = r ' c:\ PhantomJS-2 . 1 . 1-windows \ PhantomJS-2 . 1 . 1-windows \ bin \ PhantomJS . exe ')</p></blockquote><p id="2f86" class="pw-post-body-paragraph ie if hh ig b ih lq ij ik il lr in io ip ls ir is it lt iv iw ix lu iz ja jb ha bi translated">这里我用过PhantomJS，它是一个无头浏览器，你可以从<a class="ae js" href="https://phantomjs.org/download.html" rel="noopener ugc nofollow" target="_blank">这里</a>下载。您也可以使用自己选择的浏览器。对于chrome，你可以使用chrome webdriver。</p><p id="37f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jx"> get() </em>方法帮助导航到页面，或者我们可以说它打开网页，而<em class="jx"> page_source </em>驱动程序方法获取该页面的源代码。</p><p id="c240" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们已经得到了网页的来源，我们可以开始刮网站。在这里，我提取了一级玩家的详细信息。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="c3f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以我创建了一个Beautiful Soup的实例，并传递了页面的源代码和一个解析器。这里我使用了lxml解析器，它是专门为解析HTML而设计的。您可以使用pip安装lxml，</p><blockquote class="ju jv jw"><p id="3a26" class="ie if jx ig b ih ii ij ik il im in io jy iq ir is jz iu iv iw ka iy iz ja jb ha bi translated">pip安装lxml</p></blockquote><p id="5bcc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们将使用美汤提供的选择器来提取具体的数据。</p><blockquote class="lg"><p id="ebf6" class="lh li hh bd lj lk ll lm ln lo lp jb dx translated"><em class="lv"> table = soup.find('table '，class _ = ' table rankings-table ')</em></p></blockquote><p id="61ea" class="pw-post-body-paragraph ie if hh ig b ih lq ij ik il lr in io ip ls ir is it lt iv iw ix lu iz ja jb ha bi translated">方法搜索指定的标签。这段代码基本上是告诉scraper选择属性为“class”=“table rankings-table”的&lt;表&gt;标签。这为我们提供了包含所有玩家详细信息的表格。</p><p id="0987" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jx">你可以通过查看网页，找出哪个标签负责某个数据。要检查，右键单击网页并从列表中选择检查工具。</em></p><p id="c0b5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">主要策略是找到负责存储我们想要的数据的标签。因此，在获得包含所有玩家的表格后，找到负责存储他们的姓名、国籍、等级和个人资料链接的标签。的。<em class="jx"> text </em>告诉Python，如果我们找到&lt; div &gt;标签，带有类“‘rankings-block _ _ banner—name-large”，我们将只选择这个标签的文本内容。由于变量名是不言自明的，这个代码片段给了我们玩家的名字，同样我们提取了玩家的其他细节。</p><blockquote class="lg"><p id="fe41" class="lh li hh bd lj lk ll lm ln lo lp jb dx translated">name = player.find('div '，class _ = ' rankings-block _ _ banner—name-large ')。文本</p></blockquote><p id="8885" class="pw-post-body-paragraph ie if hh ig b ih lq ij ik il lr in io ip ls ir is it lt iv iw ix lu iz ja jb ha bi translated">现在提取所有球员的数据后，我们将把它保存在一个列表中。所以我创建了一个类播放器和一个空列表。所有提取的球员数据都将存储在这个列表中。这里我只提取了一级玩家的详细信息，同样你也可以使用for循环提取其他玩家的数据。你可以从<a class="ae js" href="https://github.com/varunbelgaonkar/web-scraping/blob/main/icc_odi_ranking.py" rel="noopener ugc nofollow" target="_blank">这里</a>访问整个代码。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="le lf l"/></div></figure><p id="4c27" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当前版本的代码只抓取第一页，提取姓名、国籍、级别和个人资料链接等详细信息，并将它们存储在一个列表中。因为抓取在任何时候都很容易失败，所以这段代码可能会也可能不会正常工作，因为这取决于网页的结构。</p><p id="0a8c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">记得恭恭敬敬的刮！</p></div><div class="ab cl lw lx go ly" role="separator"><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb mc"/><span class="lz bw bk ma mb"/></div><div class="ha hb hc hd he"><p id="6395" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">感谢阅读！！！</strong></p></div></div>    
</body>
</html>