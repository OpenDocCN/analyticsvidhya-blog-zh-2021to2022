<html>
<head>
<title>Sentiment Analysis of Tweets using Tweepy</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Tweepy的推文情感分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/sentiment-analysis-of-tweets-using-tweepy-b67327ac832c?source=collection_archive---------2-----------------------#2021-01-25">https://medium.com/analytics-vidhya/sentiment-analysis-of-tweets-using-tweepy-b67327ac832c?source=collection_archive---------2-----------------------#2021-01-25</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="d325" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">介绍</h1><p id="0706" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">本文中我们的主要目标是使用tweepy从twitter中收集数据，并对废弃的tweepy执行情感分析，以获得关于某个主题的公众意见。</p><p id="19f9" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">维基百科定义的情感分析:</p><blockquote class="kf kg kh"><p id="36c7" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">情感分析(也称为意见挖掘或情感人工智能)是指使用自然语言处理、文本分析、计算语言学和生物统计学来系统地识别、提取、量化和研究情感状态和主观信息</p></blockquote><p id="93db" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">因此，我们在这里要做的是使用NLTK对文本进行预处理，并在TextBlob的帮助下将其分类为正面、负面或中性。</p><p id="2dde" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在开始之前，我们需要从twitter上收集数据。为此，你需要一个Twitter开发者账户。此外，您将需要安装NLTK、Tweepy和Wordcloud来进行编码。如果你用的是google colab，这些库已经安装好了。</p><p id="4180" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">可以使用以下命令安装这些库:</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="e692" class="kv if hh kr b fi kw kx l ky kz">pip install <strong class="kr hi">nltk</strong></span><span id="6534" class="kv if hh kr b fi la kx l ky kz">pip install <strong class="kr hi">wordcloud</strong></span><span id="22be" class="kv if hh kr b fi la kx l ky kz">pip install <strong class="kr hi">tweepy</strong></span></pre><h1 id="d241" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><strong class="ak">代码</strong></h1><h2 id="c57e" class="kv if hh bd ig lb lc ld ik le lf lg io jn lh li is jr lj lk iw jv ll lm ja ln bi translated"><strong class="ak">导入所需的库</strong></h2><p id="647c" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">让我们从导入所需的模块开始。</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="9faf" class="kv if hh kr b fi kw kx l ky kz"><strong class="kr hi">import</strong> <strong class="kr hi">re</strong> <br/><strong class="kr hi">import</strong> <strong class="kr hi">tweepy</strong> <br/><strong class="kr hi">import</strong> <strong class="kr hi">nltk</strong><br/><strong class="kr hi">import</strong> <strong class="kr hi">pandas</strong> <strong class="kr hi">as</strong> <strong class="kr hi">pd</strong><br/><strong class="kr hi">import</strong> <strong class="kr hi">matplotlib.pyplot</strong> <strong class="kr hi">as</strong> <strong class="kr hi">plt</strong><br/><strong class="kr hi">from</strong> <strong class="kr hi">wordcloud</strong> <strong class="kr hi">import</strong> WordCloud,STOPWORDS<br/>nltk.download('punkt')   <br/>nltk.download('stopwords')<br/><strong class="kr hi">from</strong> <strong class="kr hi">nltk.corpus</strong> <strong class="kr hi">import</strong> stopwords<br/><strong class="kr hi">from</strong> <strong class="kr hi">nltk.tokenize</strong> <strong class="kr hi">import</strong> word_tokenize<br/><strong class="kr hi">from</strong> <strong class="kr hi">nltk.stem</strong> <strong class="kr hi">import</strong> PorterStemmer<br/><strong class="kr hi">from</strong> <strong class="kr hi">tweepy</strong> <strong class="kr hi">import</strong> OAuthHandler <br/><strong class="kr hi">from</strong> <strong class="kr hi">textblob</strong> <strong class="kr hi">import</strong> TextBlob</span></pre><h2 id="c7de" class="kv if hh bd ig lb lc ld ik le lf lg io jn lh li is jr lj lk iw jv ll lm ja ln bi translated"><strong class="ak">认证</strong></h2><p id="cbd3" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">导入所需的模块后，我们需要连接到Twitter API，这是通过创建一个身份验证对象来完成的。</p><p id="6533" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们使用OAuth将凭证传递给应用程序，也就是说，按照Wikipedia的定义:</p><blockquote class="kf kg kh"><p id="6fe9" class="jc jd ki je b jf ka jh ji jj kb jl jm kj kc jp jq kk kd jt ju kl ke jx jy jz ha bi translated">“OAuth是一种开放的访问授权标准，通常用于互联网用户授权网站或应用程序访问他们在其他网站上的信息，但不需要给他们密码。亚马逊、谷歌、脸书、微软和Twitter等公司使用这一机制，允许用户与第三方应用程序或网站共享其账户信息。”</p></blockquote><p id="f294" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">简单地说，OAuth允许我们的代码通过我们的Twitter帐户访问数据，而不需要我们给它我们帐户的用户名和密码。</p><p id="776e" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">下面的代码创建了一个函数，帮助你使用你的twitter账户来抓取推文:</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="d4fc" class="kv if hh kr b fi kw kx l ky kz"><strong class="kr hi">def</strong> connect():<br/>  <em class="ki"># Replace the xxxxx with your twitter api keys</em><br/>  consumer_key = 'xxxxx'<br/>  consumer_secret = 'xxxxx'<br/>  access_token = 'xxxxx'<br/>  access_token_secret = 'xxxxx'<br/><br/>  <strong class="kr hi">try</strong>:<br/>    auth = OAuthHandler(consumer_key, consumer_secret)<br/>    auth.set_access_token(access_token, access_token_secret)<br/>    api = tweepy.API(auth)<br/>    <strong class="kr hi">return</strong> api<br/>  <strong class="kr hi">except</strong>:<br/>    print("Error")<br/>    exit(1)</span></pre><p id="143b" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">在这里，用您的凭证替换标有“xxxxx”的参数，您将在通过您的twitter开发人员帐户创建应用程序后获得这些凭证。作为参考，您可以使用这两个视频:</p><p id="333d" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">1) <a class="ae lo" href="https://www.youtube.com/watch?v=ae62pHnBdAg&amp;t=2s" rel="noopener ugc nofollow" target="_blank"> Twitter API初学者教程(Python) </a></p><p id="973c" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">2) <a class="ae lo" href="https://www.youtube.com/watch?v=vlvtqp44xoQ&amp;t=199s" rel="noopener ugc nofollow" target="_blank">如何轻松获取Twitter API KEY </a></p><p id="eaf3" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">虽然视频中显示的申请表有点过时，但它应该会让你对需要什么有一个很好的了解。</p><h2 id="6df0" class="kv if hh bd ig lb lc ld ik le lf lg io jn lh li is jr lj lk iw jv ll lm ja ln bi translated"><strong class="ak">数据预处理</strong></h2><p id="9a43" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我们在这里主要要做的是删除<strong class="je hi"><em class="ki"/></strong><em class="ki"/><strong class="je hi"><em class="ki">所有提到的</em> </strong> (@ username) <em class="ki">、</em> <strong class="je hi"> <em class="ki">停用词</em> </strong>(如“the”、“and”等词)。).这些参数意义不大，因为它们不给出任何情绪的指示，并且移除这些参数节省了我们的存储器、计算能力，并且有时还增加了模型的准确性。</p><p id="d4b5" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们将在这里使用正则表达式来做预处理。我们还将执行<strong class="je hi"> <em class="ki">词干</em> </strong>，因为这也有助于节省内存和计算能力。</p><p id="3cc9" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">可以参考下面的代码来更好地理解数据是如何预处理的。</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="f164" class="kv if hh kr b fi kw kx l ky kz"><strong class="kr hi">def</strong> cleanText(text):<br/>  text = text.lower()<br/>  <em class="ki"># Removes all mentions (@username) from the tweet since it is of no use to us</em><br/>  text = re.sub(r'(@[A-Za-z0-9_]+)', '', text)<br/>    <br/>  <em class="ki"># Removes any link in the text</em><br/>  text = re.sub('http://\S+|https://\S+', '', text)<br/><br/>  <em class="ki"># Only considers the part of the string with char between a to z or digits and whitespace characters</em><br/>  <em class="ki"># Basically removes punctuation</em><br/>  text = re.sub(r'[^\w\s]', '', text)<br/><br/>  <em class="ki"># Removes stop words that have no use in sentiment analysis </em><br/>  text_tokens = word_tokenize(text)<br/>  text = [word <strong class="kr hi">for</strong> word <strong class="kr hi">in</strong> text_tokens <strong class="kr hi">if</strong> <strong class="kr hi">not</strong> word <strong class="kr hi">in</strong> stopwords.words()]<br/><br/>  text = ' '.join(text)<br/>  <strong class="kr hi">return</strong> text</span></pre><p id="6ac1" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">下面的函数演示了词干处理是如何完成的:</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="a8dd" class="kv if hh kr b fi kw kx l ky kz"><strong class="kr hi">def</strong> stem(text):<br/>  <em class="ki"># This function is used to stem the given sentence</em><br/>  porter = PorterStemmer()<br/>  token_words = word_tokenize(text)<br/>  stem_sentence = []<br/>  <strong class="kr hi">for</strong> word <strong class="kr hi">in</strong> token_words:<br/>    stem_sentence.append(porter.stem(word))<br/>  <strong class="kr hi">return</strong> " ".join(stem_sentence)</span></pre><h2 id="e200" class="kv if hh bd ig lb lc ld ik le lf lg io jn lh li is jr lj lk iw jv ll lm ja ln bi translated"><strong class="ak">情绪分析</strong></h2><p id="c4df" class="pw-post-body-paragraph jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ha bi translated">我们将使用TextBlob对象执行情感分析。要了解更多，你可以参考这篇博文。</p><p id="d699" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们将把文本转换成TextBlob对象，然后使用它的。情感方法来获得给定的陈述是积极的、消极的还是中性的。</p><p id="27c1" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">使用。情绪法，我们得到每种说法的极性和主观性。Polarity是一个范围在[-1，1]之间的整数，其中-1表示该语句为负数，1表示该语句为正数。主观性告诉我们给出的陈述是个人观点还是基于事实。在这里，我们不会使用主观性，而只是根据极性对推文进行分类。</p><p id="c9e5" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们将首先编写一个函数，它将一个TextBlob对象作为输入，然后将其分类为阳性、阴性或中性。下面给出的函数是它的一个实现。</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="9488" class="kv if hh kr b fi kw kx l ky kz"><strong class="kr hi">def</strong> sentiment(cleaned_text):<br/>  <em class="ki"># Returns the sentiment based on the polarity of the input TextBlob object</em><br/>  <strong class="kr hi">if</strong> cleaned_text.sentiment.polarity &gt; 0:<br/>    <strong class="kr hi">return</strong> 'positive'<br/>  <strong class="kr hi">elif</strong> cleaned_text.sentiment.polarity &lt; 0:<br/>    <strong class="kr hi">return</strong> 'negative'<br/>  <strong class="kr hi">else</strong>:<br/>    <strong class="kr hi">return</strong> 'neutral'</span></pre><p id="36b9" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">现在，我们要做的是使用Twitter API来获取tweets，然后使用我们之前编写的cleanText函数来清理它们，然后将其附加到一个列表中来存储数据。我们还需要确保不考虑retweets，我们将通过在API向Twitter发出的查询中添加-filter:retweets来修改查询。</p><p id="2a6f" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">这可以通过以下方式实现:</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="7a9b" class="kv if hh kr b fi kw kx l ky kz"><strong class="kr hi">def</strong> fetch_tweets(query, count = 50):<br/>  api = connect() <em class="ki"># Gets the tweepy API object</em><br/>  tweets = [] <em class="ki"># Empty list that stores all the tweets</em><br/><br/>  <strong class="kr hi">try</strong>:<br/>    <em class="ki"># Fetches the tweets using the api</em><br/>    fetched_data = api.search(q = query + ' -filter:retweets', <br/>count = count)<br/>    <strong class="kr hi">for</strong> tweet <strong class="kr hi">in</strong> fetched_data:<br/>      txt = tweet.text<br/>      clean_txt = cleanText(txt) <em class="ki"># Cleans the tweet</em><br/>      stem_txt = TextBlob(stem(clean_txt)) <em class="ki"># Stems the tweet</em><br/>      sent = sentiment(stem_txt) <em class="ki"># Gets the sentiment from the tweet</em><br/>      tweets.append((txt, clean_txt, sent))<br/>    <strong class="kr hi">return</strong> tweets<br/>  <strong class="kr hi">except</strong> tweepy.TweepError <strong class="kr hi">as</strong> e:<br/>    print("Error : " + str(e))<br/>    exit(1)</span></pre><p id="fec3" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我们已经完成了主要逻辑的实现，现在我们将调用这些函数，之后我们将在wordcloud中绘制这些函数。</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="46bd" class="kv if hh kr b fi kw kx l ky kz">tweets = fetch_tweets(query = 'Hindi Language Imposition', count = 200)<br/><em class="ki"># Converting the list into a pandas Dataframe</em><br/>df = pd.DataFrame(tweets, columns= ['tweets', 'clean_tweets','sentiment'])<br/><br/><em class="ki"># Dropping the duplicate values just in case there are some tweets that are copied and then stores the data in a csv file</em><br/>df = df.drop_duplicates(subset='clean_tweets')<br/>df.to_csv('data.csv', index= <strong class="kr hi">False</strong>)</span><span id="b24e" class="kv if hh kr b fi la kx l ky kz">ptweets = df[df['sentiment'] == 'positive']<br/>p_perc = 100 * len(ptweets)/len(tweets)<br/>ntweets = df[df['sentiment'] == 'negative']<br/>n_perc = 100 * len(ntweets)/len(tweets)<br/>print(f'Positive tweets <strong class="kr hi">{</strong>p_perc<strong class="kr hi">}</strong> %')<br/>print(f'Neutral tweets <strong class="kr hi">{</strong>100 - p_perc - n_perc<strong class="kr hi">}</strong> %')<br/>print(f'Negative tweets <strong class="kr hi">{</strong>n_perc<strong class="kr hi">}</strong> %')</span></pre><p id="7204" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">这里我们调用函数并将数据保存在一个csv文件中。然后我们找出正面、负面和中性推文的百分比。</p><p id="1fa0" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">最后，我们将使用下面给出的代码绘制一个包含最常用单词的单词云:</p><pre class="km kn ko kp fd kq kr ks kt aw ku bi"><span id="4e4d" class="kv if hh kr b fi kw kx l ky kz">twt = " ".join(df['clean_tweets'])<br/>wordcloud = WordCloud(stopwords=STOPWORDS, background_color='black', width=2500, height=2000).generate(twt)<br/><br/>plt.figure(1,figsize=(13, 13))<br/>plt.imshow(wordcloud)<br/>plt.axis('off')<br/>plt.show()</span></pre><figure class="km kn ko kp fd lq er es paragraph-image"><div class="er es lp"><img src="../Images/1b25374a07493e20f26f4fb06e32e513.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*hI3ZjxjeX7QdOYSUVXRgzA.png"/></div><figcaption class="lt lu et er es lv lw bd b be z dx translated">单词云的输出</figcaption></figure><p id="3f1f" class="pw-post-body-paragraph jc jd hh je b jf ka jh ji jj kb jl jm jn kc jp jq jr kd jt ju jv ke jx jy jz ha bi translated">我希望这篇文章让你很好地理解了如何使用Twitter API对推文进行情感分析。你可以在这里找到我的代码的链接。</p></div></div>    
</body>
</html>