<html>
<head>
<title>Neural networks backward propagation deep dive 103</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">神经网络反向传播深潜103</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/backward-propagation-deep-dive-103-60390714d2b0?source=collection_archive---------12-----------------------#2021-07-08">https://medium.com/analytics-vidhya/backward-propagation-deep-dive-103-60390714d2b0?source=collection_archive---------12-----------------------#2021-07-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/8f5aadfd095287cc57a68ea4769a1d6c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7XryJtBBZPn25PkKNJWGWQ.jpeg"/></div></div></figure><p id="3445" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">反向传播是一个很难解释的问题。让我们在这里试一试，展示代码和输出数据。</p><p id="94fc" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">这是我的神经网络系列的第3部分。如果你只是想要代码，欢迎从第一部分的开始，或者跳到第五部分的<a class="ae jn" href="https://shaun-enslin.medium.com/implementing-neural-networks-in-matlab-105-6b71c5872b3c" rel="noopener"/>。</p><p id="2a65" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，为了执行梯度下降或成本优化，我们需要编写一个成本函数，它执行:</p><ol class=""><li id="f639" class="jo jp hh ir b is it iw ix ja jq je jr ji js jm jt ju jv jw bi translated"><a class="ae jn" href="https://shaun-enslin.medium.com/forward-propagation-deep-dive-102-bbeabe4d2fb2" rel="noopener">正向传播</a></li><li id="8d65" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated"><a class="ae jn" href="https://shaun-enslin.medium.com/backward-propagation-deep-dive-103-60390714d2b0" rel="noopener">反向传播</a></li><li id="f0b1" class="jo jp hh ir b is jx iw jy ja jz je ka ji kb jm jt ju jv jw bi translated"><a class="ae jn" href="https://shaun-enslin.medium.com/cost-and-gradient-calculation-in-neural-networks-deep-dive-104-2e16f26ce3f3" rel="noopener">计算成本&amp;坡度</a></li></ol><p id="f2ab" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">本文关注于(2)反向传播。</strong></p><p id="1dcf" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">因此，我们在图1中简化了我们的神经网络，仅显示了在每层的一个单元(圆)中计算S3和S2的细节。</p><figure class="kd ke kf kg fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kc"><img src="../Images/e9c02f1a6d14e8d89f6fc2bc6bfebcb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dB4MXkS6Ex6QSjBT1DboEw.png"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">图1</figcaption></figure><h1 id="827d" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">砝码</h1><p id="1bd6" class="pw-post-body-paragraph ip iq hh ir b is lj iu iv iw lk iy iz ja ll jc jd je lm jg jh ji ln jk jl jm ha bi translated">从<a class="ae jn" href="https://shaun-enslin.medium.com/forward-propagation-deep-dive-102-bbeabe4d2fb2" rel="noopener">第2部分</a>中，我们了解了我们的权重(θs)是如何初始化的，所以为了直观显示图1所指的权重(φ),请参见图2。</p><figure class="kd ke kf kg fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lo"><img src="../Images/60e64bfd73ee289724f119a3b840db79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1190/format:webp/1*pYaYXYDNXeqgKXcELec8qA.png"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">图2</figcaption></figure><h1 id="7229" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">重新格式化Y</h1><p id="ba0a" class="pw-post-body-paragraph ip iq hh ir b is lj iu iv iw lk iy iz ja ll jc jd je lm jg jh ji ln jk jl jm ha bi translated">在我们继续之前，如果您理解(<a class="ae jn" href="https://shaun-enslin.medium.com/explaining-neural-networks-101-a36356113cbd" rel="noopener">第1部分</a>)我们的Y列，其中包含用于对客户进行分类的标签。然后，为了继续反向传播，我们需要将Y重新格式化为一个对应于标签数量的矩阵。在我们的案例中，我们的客户有7个类别。</p><p id="5dad" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">图3显示了如何将<strong class="ir hi"> Y </strong>转换为矩阵<strong class="ir hi"> yv </strong>并且标签现在在适当的列中显示为二进制。</p><pre class="kd ke kf kg fd lp lq lr ls aw lt bi"><span id="3f45" class="lu km hh lq b fi lv lw l lx ly">yv = [1:num_labels] == y;</span></pre><figure class="kd ke kf kg fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lz"><img src="../Images/7dcd54ffd88953b9b81ec32d4a54841b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BxHrINBRw3mscIQtTx9hyA.png"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">图3</figcaption></figure><h1 id="81b1" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">正向传播</h1><p id="0dae" class="pw-post-body-paragraph ip iq hh ir b is lj iu iv iw lk iy iz ja ll jc jd je lm jg jh ji ln jk jl jm ha bi translated">计算图1中的S3相当容易，是一个相当简单的成本函数，将我们在A3中的假设与我们在yv中的实际类别进行比较。您将在图4中看到结果。</p><pre class="kd ke kf kg fd lp lq lr ls aw lt bi"><span id="fa83" class="lu km hh lq b fi lv lw l lx ly">s3 = a3 — yv;</span></pre><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es ma"><img src="../Images/cadcf8a0eb8b20dd879d2ee4876c6db0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/1*z7LfOSe-6WDhOONfLSZ1Vw.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">图4</figcaption></figure><p id="b04c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">S3结束后，我们可以转移到S2，这是一个更棘手的问题。我们将θ应用于S3，并乘以这一层的梯度。这就是我们把Z2放在前进档的原因。</p><blockquote class="mc md me"><p id="fa7f" class="ip iq mb ir b is it iu iv iw ix iy iz mf jb jc jd mg jf jg jh mh jj jk jl jm ha bi translated">请注意，我们删除了back prop中的偏置列</p></blockquote><pre class="kd ke kf kg fd lp lq lr ls aw lt bi"><span id="87bb" class="lu km hh lq b fi lv lw l lx ly">s2 = (s3*Theta2).*sigmoidGradient([ones(size(z2, 1), 1) z2]); <br/>s2 = s2(:, 2:end); </span></pre><p id="8c61" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">下面可以看到sigmoid函数，它计算sigmoid函数的梯度。</p><pre class="kd ke kf kg fd lp lq lr ls aw lt bi"><span id="9efd" class="lu km hh lq b fi lv lw l lx ly">function g = sigmoidGradient(z)<br/> g = sigmoid(z).*(1-sigmoid(z));<br/>end</span></pre><p id="ca5b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">图5显示了S2的输出。</p><figure class="kd ke kf kg fd ii er es paragraph-image"><div class="er es mi"><img src="../Images/7911265ddbfcb0b763cec2211668b80e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*zJrn_B1J1Mlza1g5ggZE9w.png"/></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">图5</figcaption></figure><h1 id="6b15" class="kl km hh bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">结论</h1><p id="f68b" class="pw-post-body-paragraph ip iq hh ir b is lj iu iv iw lk iy iz ja ll jc jd je lm jg jh ji ln jk jl jm ha bi translated">这篇关于反向传播的文章到此结束。如果您继续阅读本系列的第一篇文章，那么我们仍然需要计算成本和梯度。<a class="ae jn" href="https://shaun-enslin.medium.com/cost-and-gradient-calculation-in-neural-networks-deep-dive-104-2e16f26ce3f3" rel="noopener">点击这里进入本系列关于神经网络的第四篇文章</a>。</p><p id="039b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">接下来，我们计算向前/向后道具的成本和梯度。</p><p id="ff3f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">如果你需要一门很棒的机器学习课程，那么<a class="ae jn" href="https://www.coursera.org/learn/machine-learning" rel="noopener ugc nofollow" target="_blank">这个</a>就是为你准备的课程。</p></div></div>    
</body>
</html>