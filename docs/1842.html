<html>
<head>
<title>Data Analysis: Anti-Vaxxers using NLP</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据分析:使用NLP的反病毒软件</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/data-analysis-anti-vaxxers-using-nlp-e1038cc40875?source=collection_archive---------23-----------------------#2021-03-21">https://medium.com/analytics-vidhya/data-analysis-anti-vaxxers-using-nlp-e1038cc40875?source=collection_archive---------23-----------------------#2021-03-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/0170568047b7c22ce1de05bf098824ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*IyVO8R2HYrTB92Ro"/></div></figure><p id="ff45" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi jj translated">鉴于世界各地普遍存在的疫苗犹豫，我想研究一下流传的阴谋论。还有什么地方比Reddit更适合查找数据呢？</p><p id="2125" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">从这里下载数据。</p><div class="js jt ez fb ju jv"><a href="https://www.kaggle.com/gpreda/reddit-vaccine-myths" rel="noopener  ugc nofollow" target="_blank"><div class="jw ab dw"><div class="jx ab jy cl cj jz"><h2 class="bd hi fi z dy ka ea eb kb ed ef hg bi translated">Reddit疫苗神话</h2><div class="kc l"><h3 class="bd b fi z dy ka ea eb kb ed ef dx translated">疫苗神话子编辑帖子和评论</h3></div><div class="kd l"><p class="bd b fp z dy ka ea eb kb ed ef dx translated">www.kaggle.com</p></div></div><div class="ke l"><div class="kf l kg kh ki ke kj ij jv"/></div></div></a></div><blockquote class="kk kl km"><p id="6426" class="il im kn in b io ip iq ir is it iu iv ko ix iy iz kp jb jc jd kq jf jg jh ji ha bi translated">本文主要是代码，我试图涵盖文本数据分析所需的最重要的库，这些代码可以用于多种文本相关的分析。</p></blockquote><p id="e91a" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我进行分析的主要动机是找出反暴力者常用的阴谋论，以便提高一些意识。可以通过使用自然语言处理和其他python库来完成。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="8396" class="la lb hh kw b fi lc ld l le lf">import pyforest<br/>df=pd.read_csv("reddit_vm.csv")<br/>print(df.head())</span></pre><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lg"><img src="../Images/813ef251c8209f66fe877cdd4339f0ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yDg4FwkOxSO8vIYaDBqjJQ.png"/></div></div></figure><p id="2d1e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我想根据分数降序排列列表，这样我们就知道最离谱的理论了。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="8a84" class="la lb hh kw b fi lc ld l le lf">df.sort_values(by=['score'], ascending =False)</span></pre><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ll"><img src="../Images/3d0d3451538f4d6a10897e5fe9003c2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tvoPgh0EYTa3tvutphKX2w.png"/></div></div></figure><p id="3316" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">你可以看到人们在流传什么理论。通过打印大约100列而不是仅仅5列，可以知道更多。</p><p id="fc8c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我刚刚意识到有两个栏“标题”和“正文”将有助于我的分析。理想情况下，我只喜欢一个专栏。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="e002" class="la lb hh kw b fi lc ld l le lf">df['body'] = df['body'].replace(np.nan, "empty")<br/>df['tb'] = df['title'].str.cat(df['body'], sep =" ")</span></pre><p id="d7d1" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我合并了两列的文本，并创建了一个名为“bp”的新列，它将包含两列的文本。但是，在此之前，我必须将“nan”值转换为“空”文本，以便添加2个字符串。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lm"><img src="../Images/0ce863f307f0ab6bdac326173bda24ba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u2Gp5LUODZCDHyIqHgoEIw.png"/></div></div></figure><p id="aec8" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">现在我已经在一个名为“tb”的列中收集了文本数据，我可以使用NLP工具来分析这些文本。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="48f4" class="la lb hh kw b fi lc ld l le lf">import nltk<br/>nltk.download()<br/>from nltk.tokenize import sent_tokenize, word_tokenize</span><span id="4234" class="la lb hh kw b fi ln ld l le lf">from nltk.corpus import stopwords<br/>stop_words=set(stopwords.words("english"))<br/>print(stop_words)</span></pre><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lo"><img src="../Images/2ccf61519ff1e1da4899a7bec228335a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gl6rAFC5K4M7tVhEGwkFvg.png"/></div></div></figure><blockquote class="kk kl km"><p id="6dff" class="il im kn in b io ip iq ir is it iu iv ko ix iy iz kp jb jc jd kq jf jg jh ji ha bi translated">停用词是在英语中使用的词，但不传达任何信息，因此我们试图从我们的词表中删除它们。我们通过导入单词列表词汇表并创建单词列表词汇表中不存在的新单词列表来实现这一点，</p></blockquote><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="f1e2" class="la lb hh kw b fi lc ld l le lf">df1=df['tb']<br/>x=str(df1)</span><span id="2cee" class="la lb hh kw b fi ln ld l le lf">word_tokenized=word_tokenize(x)<br/>filtered_reddit_comments=[]<br/>for w in word_tokenized:<br/>            if w not in stop_words:<br/>                    filtered_reddit_comments.append(w)</span></pre><p id="79da" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们首先创建一个只有1列“tb”的新数据框，以使分析更容易。然后，我们将数据帧转换成一个字符串，以便可以与其他字符串进行比较。<strong class="in hi"> word_tokenize </strong>将只接受一个字符串输入。然后我们使用一个<em class="kn"> for </em>循环来遍历整个字符串并删除所有多余的单词(称为停用词)。可以显示新的已处理的令牌化列表。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lp"><img src="../Images/a59aac1ec428cbac2de622d9dd44393a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SGvM9Z-3MoY6vEIAJVAWyA.png"/></div></div></figure><blockquote class="kk kl km"><p id="fa8e" class="il im kn in b io ip iq ir is it iu iv ko ix iy iz kp jb jc jd kq jf jg jh ji ha bi translated">我可以看到一些人正在传播一个神话，即疫苗含有汞化合物。</p></blockquote><p id="bd17" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">如果您想检查列表中每个单词的词性。没有必要，但在其他情况下可能会有帮助。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="716f" class="la lb hh kw b fi lc ld l le lf">POS=nltk.pos_tag(filtered_reddit_comments)</span></pre><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lq"><img src="../Images/bb3ff0e492a7731a7b6b10d42beeb0b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jevwGD8OmTHUMwAoUd4MXg.png"/></div></div></figure><p id="cc42" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了进一步简化POS的意思，我粘贴了一个缩写列表。希望这能有所帮助。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lr"><img src="../Images/4dddb6f97ba760520d816d0dfe7006c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MkfTRzYj5Fbgwq6L-wletA.png"/></div></div></figure><p id="a42c" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我还通过根据词类划分单词来对文本数据进行分块，这可能对分析没有帮助，但出于教育目的。在某些情况下，它对于文本数据分析非常方便。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="774e" class="la lb hh kw b fi lc ld l le lf">chunkgram= r"""Chunk:{&lt;RB.?&gt;*&lt;VB.?&gt;*&lt;NNP&gt;+&lt;NN&gt;?}"""  <br/>chunkParser=nltk.RegexpParser(chunkgram)<br/>chunked=chunkParser.parse(POS)<br/>chunked.draw()</span></pre><p id="3cc3" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我使用正则表达式找出动词、名词等单词，然后使用draw函数将其可视化。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es ls"><img src="../Images/e10bb6a6c58fe4ce06f609ecc40c5647.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2E27Sxfr2mgJTlcmbLPuUA.png"/></div></div></figure><p id="2da9" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">这就是VIZ的样子。正则表达式实际上是分析师最有力的工具。</p><p id="619e" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们还可以从数据集中找到著名的实体。例如组织，人，GPE的地理位置。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="57ea" class="la lb hh kw b fi lc ld l le lf">namedent=nltk.ne_chunk(POS)<br/>namedent.draw()</span></pre><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lt"><img src="../Images/83cbaa6779414554a74b390f5a8ed565.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oD2vB5-wYZDb4tFQVrIoVw.png"/></div></div></figure><p id="cc18" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">无论我们到目前为止做了什么，都不会对这个分析有帮助，但是我想涵盖NLP的所有重要功能，所以我决定在这里添加它们。</p><p id="d357" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们现在可以继续进行频率计算和情感分析。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="c388" class="la lb hh kw b fi lc ld l le lf">words = nltk.FreqDist(filtered_reddit_comments)</span><span id="2d88" class="la lb hh kw b fi ln ld l le lf">bag_of_words = pd.DataFrame(words.most_common(),<br/>                             columns=["WORD","COUNT"])<br/>print(bag_of_words.head())</span></pre><p id="1669" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">对于频率计算，我使用没有停用词并且已经被过滤的列表。函数<strong class="in hi"> <em class="kn"> most_common </em> </strong>可以用来查找词频。而<strong class="in hi"> <em class="kn"> pd.dataframe </em> </strong>用于创建新的数据帧。</p><figure class="kr ks kt ku fd ii er es paragraph-image"><div class="er es lu"><img src="../Images/2f93e6c39e9cddbde0755e3785a3f699.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/1*VXUYs7Iwx3onQ5vgwkV-TQ.png"/></div></figure><h2 id="6340" class="la lb hh bd lv lw lx ly lz ma mb mc md iw me mf mg ja mh mi mj je mk ml mm mn bi translated">情感分析</h2><p id="b4ac" class="pw-post-body-paragraph il im hh in b io mo iq ir is mp iu iv iw mq iy iz ja mr jc jd je ms jg jh ji ha bi translated">这是分析中最重要的部分之一。我们将使用<strong class="in hi"> <em class="kn">维达</em> </strong>库进行情感分析。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="beb9" class="la lb hh kw b fi lc ld l le lf">nltk.download("vader_lexicon")<br/>from nltk.sentiment.vader import SentimentIntensityAnalyzer<br/>vader = SentimentIntensityAnalyzer()</span><span id="cc03" class="la lb hh kw b fi ln ld l le lf">df["scores"] = df["tb"].apply(lambda tb: vader.polarity_scores(tb))<br/>df["compound"]=df["scores"].apply(lambda score_dict:score_dict["compound"])<br/>df["sentiment"]=df["compound"].apply(lambda c:"pos" if c&gt;=0 else "neg")<br/>df.head()</span></pre><figure class="kr ks kt ku fd ii er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mt"><img src="../Images/d69129ac49c609948f29bbecbd46806d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2snDcxJDwuNwGTisfjp1mA.png"/></div></div></figure><p id="d7a5" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我增加了3个新的栏目，给出分数和观点。但是让我们看看对疫苗的负面评价。</p><pre class="kr ks kt ku fd kv kw kx ky aw kz bi"><span id="9bba" class="la lb hh kw b fi lc ld l le lf">count = df['sentiment'].value_counts()<br/>print(count)</span></pre><figure class="kr ks kt ku fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/3f449704591d15704b26fb6a03adb85e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*nLiZKfRbiQs8_rQeGRHJIw.png"/></div></figure><p id="924f" class="pw-post-body-paragraph il im hh in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">总共有696人传播对疫苗的负面看法。</p><h2 id="d882" class="la lb hh bd lv lw lx ly lz ma mb mc md iw me mf mg ja mh mi mj je mk ml mm mn bi translated">结论</h2><p id="2e17" class="pw-post-body-paragraph il im hh in b io mo iq ir is mp iu iv iw mq iy iz ja mr jc jd je ms jg jh ji ha bi translated">我知道不能从文本中分析很多东西，我保持这个博客代码重。如果你能从头到尾做好这篇文章，你就能很容易地在市场上找到一份NLP相关的数据分析师工作。</p></div></div>    
</body>
</html>