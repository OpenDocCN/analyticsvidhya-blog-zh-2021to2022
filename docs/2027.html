<html>
<head>
<title>Fundamentals of Machine Learning part 4- Logistic Regression and PLA</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习基础第4部分-逻辑回归和PLA</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/fundamentals-of-machine-learning-part-4-logistic-regression-and-pla-19f27c769866?source=collection_archive---------10-----------------------#2021-04-01">https://medium.com/analytics-vidhya/fundamentals-of-machine-learning-part-4-logistic-regression-and-pla-19f27c769866?source=collection_archive---------10-----------------------#2021-04-01</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="53de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们深入研究逻辑回归和PLA的功能。</p><p id="1427" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">先决条件:- </strong></p><p id="88ea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">线性回归和梯度下降。</strong></p><h1 id="2a14" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">逻辑回归:-</h1><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ka"><img src="../Images/03d65b6e8a2667093984831559c3bbf6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dm6ZaX5fuSmuVvM4Ds-vcg.jpeg"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">逻辑回归使用sigmoid函数。</figcaption></figure><p id="17fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们已经讨论过线性回归，它对回归任务很有用。逻辑回归用于分类任务，其中因变量仅包含离散值。逻辑回归是一个“误称”。之所以称之为回归，是因为它利用了线性回归的基本性质。逻辑回归是根模型的子模型，被称为<strong class="ig hi">“广义线性模型”</strong>。</p><p id="8179" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">逻辑回归试图找到区分不同类别的最佳<strong class="ig hi">“决策边界】</strong>。它使用<strong class="ig hi"> "sigmoid" </strong>函数，也称为<strong class="ig hi"> "logistic" </strong>，因此它给出0和1之间的值。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es kq"><img src="../Images/93719124da4986926e2aa249e0270db4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*s46r3dzbts_9y3r3wBPFHA.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">乙状结肠或逻辑函数。</figcaption></figure><p id="839b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> g(z) = 1/(1+ exp(-z)) (sigmoid或逻辑函数)</strong></p><p id="0490" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如您所见，如果<strong class="ig hi"> z是一个非常大的数字</strong>，那么<strong class="ig hi"> g(z) ≈ 1 </strong>的值和当<strong class="ig hi"> z非常小时g(z) ≈ 0 </strong>。</p><h2 id="cff6" class="kr jd hh bd je ks kt ku ji kv kw kx jm ip ky kz jq it la lb ju ix lc ld jy le bi translated">假设:-</h2><p id="d09e" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">我们希望我们的假设给出0到1之间的值，这是一个估计的概率。</p><p id="bbd5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> h(X) = g(θ。T*X) </strong></p><p id="9a78" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> g(z) = 1/(1+ exp(-z)) </strong></p><p id="ff84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> h(X) = 1/(1+ exp(-θ。T*X)) </strong></p><p id="51d2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> X :-输入，g(z) :- Sigmoid函数，h(X) :-假设。</strong></p><p id="7098" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个假设的输出是一个估计的概率。这用于推断在给定输入x的情况下，预测值与实际值之间的可信度。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es lk"><img src="../Images/2a290ba9637fcec1a8ca72a29884fad2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*ibca3uIKi2XR-yZXkdi2YQ.png"/></div><figcaption class="km kn et er es ko kp bd b be z dx translated">假设背后的数学。</figcaption></figure><h2 id="2205" class="kr jd hh bd je ks kt ku ji kv kw kx jm ip ky kz jq it la lb ju ix lc ld jy le bi translated">决策界限:-</h2><p id="b1dd" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">为了预测数据属于哪一类，可以设置一个阈值。基于该阈值，将所获得的估计概率分类。</p><p id="cad1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">也就是说，如果<strong class="ig hi">预测值≥ 0.5 </strong>，则归类为1类，否则归类为0类。</p><p id="bf73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">决策边界可以是线性或非线性的。多项式阶可以增加，以获得复杂的决策边界。</p><h2 id="a5a8" class="kr jd hh bd je ks kt ku ji kv kw kx jm ip ky kz jq it la lb ju ix lc ld jy le bi translated">成本函数:-</h2><p id="9805" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">线性回归使用<strong class="ig hi">均方误差</strong>作为其成本函数。如果这用于逻辑回归，那么它将是参数(θ)的非凸函数。梯度下降只有在函数是凸的情况下才会收敛到全局极小值。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ll"><img src="../Images/61520ce021e47c96d95d37144678281f.png" data-original-src="https://miro.medium.com/v2/resize:fit:926/format:webp/1*IZQywT8DCz_SKxKnfvCkXg.png"/></div></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lm"><img src="../Images/437c70e11b4e93848e380693616bec85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I3wMiov99Ca6D4jku0ZRhQ.jpeg"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">成本函数解释。</figcaption></figure><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es ln"><img src="../Images/7192adc0240b644d0a66c7c2bf289ee4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bD9zDgx8Lw_DMB9ZAT6YlA.jpeg"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">成本函数解释。</figcaption></figure><p id="51a8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">简化成本函数:- </strong></p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lo"><img src="../Images/dcc517bbb49b712dc288ea9127ac1610.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JWvYunYNRvkTz7ROGR43_w.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">成本函数的最终形式。</figcaption></figure><p id="e599" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">m:-#例题</strong></p><p id="d6b3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">y:——真实值</strong></p><p id="ee11" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> h(x) :-预测值</strong></p><h2 id="4633" class="kr jd hh bd je ks kt ku ji kv kw kx jm ip ky kz jq it la lb ju ix lc ld jy le bi translated">梯度上升:-</h2><p id="af19" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">在看到成本函数和sigmoid函数之后，现在让我们考虑一个算法，它可以将这两个函数结合起来，并给出我们想要的结果。算法是<strong class="ig hi">梯度上升</strong>算法。</p><p id="b994" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以梯度上升是一种寻找可微函数局部最大值的迭代优化算法。该算法沿着在成本函数曲线的每个点计算的梯度方向移动，直到满足停止标准。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lp"><img src="../Images/1f4c3a36eed0b91c1c5688ae1eb65068.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TW-GNOFP25w9eFXqbYOoTg.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">梯度上升</figcaption></figure><p id="4302" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">说得够多了，让我们开始实施吧。</p><h2 id="fdd7" class="kr jd hh bd je ks kt ku ji kv kw kx jm ip ky kz jq it la lb ju ix lc ld jy le bi translated">实施:-</h2><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="lq lr l"/></div></figure><h1 id="cef2" class="jc jd hh bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz bi translated">PLA(感知学习算法):-</h1><p id="3124" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">PLA或感知器学习算法是用于分类问题的最古老的监督学习算法之一。在分类问题中，因变量只包含离散值，它们也被称为<strong class="ig hi">【标签】</strong>。在一个数据集中，我们可以有两个或两个以上的标签。建议使用PLA进行<strong class="ig hi">二元类分类</strong>，其中类是线性可分的。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div class="er es ls"><img src="../Images/42d3d12d966ad97afe80a4ddb541611d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*7qPWz-1cAUa4vhTnVVfDPg.jpeg"/></div><figcaption class="km kn et er es ko kp bd b be z dx translated">在这种情况下，这两类是线性可分的。</figcaption></figure><p id="b3e1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">分隔这两个类的线被称为<strong class="ig hi">“决策边界”</strong>。该算法想要找到将平原分成两个区域的最佳决策边界。如果点位于边界的右侧，它们就是正标签数据。如果它们位于边界的左侧，它们被称为负标签数据。让我们试着找到这条线。</p><h2 id="8c0e" class="kr jd hh bd je ks kt ku ji kv kw kx jm ip ky kz jq it la lb ju ix lc ld jy le bi translated">感知器假设:-</h2><p id="2fbb" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">设<strong class="ig hi">【g】</strong>为某种函数，<strong class="ig hi">【z】</strong>为输入。该函数只接受输入，如果输出大于或等于零，则返回<strong class="ig hi"> "1" </strong>正标签，否则返回<strong class="ig hi"> "0" </strong>负标签。</p><p id="7e0e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">如果z≥0，g(z) = 1，否则为0 </strong></p><p id="ad4b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">X:——数据集/自变量的特征(x1，x2，x3…… ) </strong></p><p id="75ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> W :-参数的权重(w0，w1，w2 ......)。)w0是偏置。</strong></p><p id="7e31" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> g(z) :-激活函数/亥维赛阶跃函数。</strong></p><p id="ea8e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">我们简单的假设是:- </strong></p><p id="93bd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> h(X) = g(W.T*X) </strong></p><p id="3d07" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了简单起见，我们在x中包括偏差“x0”。</p><h2 id="7cb4" class="kr jd hh bd je ks kt ku ji kv kw kx jm ip ky kz jq it la lb ju ix lc ld jy le bi translated">算法:-</h2><p id="c224" class="pw-post-body-paragraph ie if hh ig b ih lf ij ik il lg in io ip lh ir is it li iv iw ix lj iz ja jb ha bi translated">我们尝试调整W的权重，以得到一条将平原分成两半的线。为此，我们需要尝试不同的w值。</p><figure class="kb kc kd ke fd kf er es paragraph-image"><div role="button" tabindex="0" class="kg kh di ki bf kj"><div class="er es lt"><img src="../Images/950e253834245c2b3c3393ca0268fa4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2Eb30oFcp0oSQNlk7pAahQ.png"/></div></div><figcaption class="km kn et er es ko kp bd b be z dx translated">中国人民解放军（the People's Liberation Army）</figcaption></figure><p id="3594" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">给定训练集:- </strong></p><p id="16ce" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> {(x1，y1)，(x1，y2)，……。} </strong></p><p id="73b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">选择一个错误分类的点:- </strong></p><p id="cdc1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> g(W.T*x1)！= y1，然后</strong></p><p id="089f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">更新W的值:- </strong></p><p id="0c88" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> W= W+ alpha*(y-h(x))*x </strong></p><p id="ec3c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">y:——真实值</strong></p><p id="c5f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> h(x) :-预测值</strong></p><p id="6a73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> W :-重量/参数</strong></p><p id="930b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是PLA的一次迭代，我们需要对所有训练数据点重复该过程。</p><p id="59e9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">“alpha”</strong>是<strong class="ig hi">学习率</strong>。</p><h2 id="d342" class="kr jd hh bd je ks kt ku ji kv kw kx jm ip ky kz jq it la lb ju ix lc ld jy le bi translated">实施:-</h2><figure class="kb kc kd ke fd kf"><div class="bz dy l di"><div class="lq lr l"/></div></figure></div></div>    
</body>
</html>