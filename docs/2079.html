<html>
<head>
<title>Mechanism of Action (MoA) Prediction</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">作用机理(MoA)预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/mechanism-of-action-moa-prediction-63ced9da471e?source=collection_archive---------30-----------------------#2021-04-03">https://medium.com/analytics-vidhya/mechanism-of-action-moa-prediction-63ced9da471e?source=collection_archive---------30-----------------------#2021-04-03</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/ecc2c5993272a28362817cc4a433a24b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pbJq53Gi3rbm-11x9j9ARA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">来源:Kaggle</figcaption></figure><h1 id="63b2" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">导言和概述</h1><p id="7841" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi kp translated"><span class="l kq kr ks bm kt ku kv kw kx di"> M </span>过去，科学家从天然产物中提取药物，或者从传统疗法中获得灵感。非常常见的药物，如扑热息痛，在美国被称为对乙酰氨基酚，在驱动其药理活性的生物机制被了解之前几十年就被投入临床使用。今天，随着更强大技术的出现，药物发现已经从过去的偶然发现方法转变为基于对疾病潜在生物机制的理解的更有针对性的模型。在这个新的框架中，科学家们试图识别与疾病相关的蛋白质靶标，并开发出一种可以调节该蛋白质靶标的分子。</p><p id="41e6" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated"><strong class="jt hi">如何确定MoA？</strong></p><p id="3c15" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">研究人员过去常常用药物处理人类细胞样本，然后用算法分析细胞反应，这些算法在大型基因组数据库中搜索与已知模式的相似性，如基因表达库或具有已知MoAs的药物的细胞生存模式。</p><h1 id="b398" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">目标</h1><p id="eb74" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">该项目的<em class="ky">目标</em>是通过快速预测药物的MoA，使药物开发更先进、更快速。一般来说，研究人员用药物处理一个样本细胞，并在基因组数据库中找到相似性，这需要花费大量的时间和金钱，并使这个过程非常缓慢。所以，这个项目的目标是加速这个过程，使它更有效率。</p><h1 id="a82a" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">数据</h1><blockquote class="le lf lg"><p id="e404" class="jr js ky jt b ju kz jw jx jy la ka kb lh lb ke kf li lc ki kj lj ld km kn ko ha bi translated">链接到数据集:<a class="ae lk" href="https://www.kaggle.com/c/lish-moa/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/lish-moa/data</a></p></blockquote><p id="aa93" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">数据集由许多csv文件组成，如下所示:</p><ul class=""><li id="15db" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated"><code class="du lu lv lw lx b">train_features.csv</code> -训练集的特征。</li><li id="3d24" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><code class="du lu lv lw lx b">train_drug.csv</code> -该文件包含一个仅用于训练集的匿名drug_id。</li><li id="717e" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><code class="du lu lv lw lx b">train_targets_scored.csv</code> -被得分的二元MoA目标。</li><li id="7d60" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><code class="du lu lv lw lx b">train_targets_nonscored.csv</code> -训练数据的附加(可选)二进制MoA响应。这些都是不预测也不打分的。</li><li id="9246" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><code class="du lu lv lw lx b">test_features.csv</code> -用于测试数据的特性。您必须预测测试数据中每行的每个得分MoA的概率。</li></ul><p id="f20f" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated"><strong class="jt hi">训练和测试集由876个特征组成:</strong></p><ul class=""><li id="f5ac" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated"><strong class="jt hi">第一个</strong>列是sig_id，是每个样品的id。</li><li id="bdcf" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi">第二</strong>列为cp_type，表示用化合物(<code class="du lu lv lw lx b">cp_vehicle</code>)或对照微扰(<code class="du lu lv lw lx b">ctrl_vehicle</code>)处理的样品。</li><li id="b734" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi">第三个</strong>栏是cp_time，表示治疗持续时间(24、48、72小时)。</li><li id="bfc9" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi">第四个</strong>栏是cp_dose，表示剂量的多少(高或低)。</li><li id="e7e1" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi">第5至第775th】列包含关于基因的信息，列名为g-0、g-1、g-2、…、g-771。</strong></li><li id="8bff" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi">第776至第876th】列包含有关单元格的信息，列名为c-0、c-1、c-2、…、c-99。</strong></li></ul><p id="52af" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated"><em class="ky">目标设置由</em><strong class="jt hi"><em class="ky">207</em></strong><em class="ky">特征组成。</em>第一个特征是sig_id，所有其他206个特征是MoAs的名称。前nfkb抑制剂、蛋白酶体抑制剂、环加氧酶抑制剂、多巴胺受体拮抗剂、血清素受体拮抗剂等。<em class="ky">有</em><strong class="jt hi"><em class="ky">23814</em></strong><em class="ky">数据点训练模型和</em><strong class="jt hi"><em class="ky">3982</em></strong><em class="ky">数据点测试模型。</em></p><p id="1a2d" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated"><strong class="jt hi">挑战解决</strong></p><p id="f532" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">这是一个多标签问题，因为我们必须预测206个目标特征。因此，这里的主要挑战是找到使用机器学习算法为这些目标变量训练一个或多个模型的方法，该算法通过提供最佳准确性来训练更快。</p><blockquote class="le lf lg"><p id="c888" class="jr js ky jt b ju kz jw jx jy la ka kb lh lb ke kf li lc ki kj lj ld km kn ko ha bi translated">我只使用了机器学习算法来训练模型。我没有接触过以训练为目的的深度学习。</p></blockquote><h1 id="dd75" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">评估指标</h1><p id="2d71" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated"><em class="ky"> log-loss </em>，我使用了Log-loss评估指标，因为目标集中的每个标签都高度不平衡，Log-loss考虑了预测概率来计算损失。因此，log-loss对于不平衡数据集是健壮的。我们还可以使用F1分数等其他指标进行评估。</p><figure class="me mf mg mh fd ii er es paragraph-image"><div class="er es md"><img src="../Images/d655709adcb4f4081dbcdbbdf9fe41bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*i257q1dNjSfujX1ijxwkAg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">对数损失公式</figcaption></figure><h1 id="fc6f" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">我的第一次切入</h1><p id="09a3" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">从读取数据集开始，然后首先我将对数据集以及基因和细胞列进行探索性数据分析(EDA)。我会把它们分开，然后把它们可视化。然后，在特征工程中，我将对数据集的分类特征进行编码，首先，我将尝试对训练和测试数据集分别应用缩放(StandardScaler或QuantileTransformer ),但在研究过程中，我发现分别应用缩放会大幅降低准确性，然后，我将尝试同时对训练和测试数据集应用缩放。然后，我将使用PCA和VarianceThreshold进行特征选择，之后，我将尝试通过添加一些新特征并组合所有特征(cp、基因和细胞以及新特征)来增加一些数据。最后，我将在for循环中将训练数据拆分为训练和验证数据集(使用简单的训练测试拆分或分层采样),并在同一个循环中进行训练和预测，这样每次迭代for循环时，我们都会获得不同的验证和训练数据。得到最佳算法后，我就开始在整个数据集上训练模型。由于我将主要尝试使用机器学习算法而不是深度学习，所以我将尝试不同的技术来预测这些多标签，从为每个标签创建不同的模型到尝试scikit-MultiLearn库。</p><h1 id="42c6" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">探索性数据分析</h1><p id="386b" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">本案例研究的第一步是执行EDA，以便我们可以分析和可视化数据集的内容，并提取关于数据的有价值的信息。</p><p id="3786" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated"><strong class="jt hi">读取数据集</strong></p><p id="ecfd" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">我们使用熊猫图书馆来读取数据集。</p><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">读取数据集</figcaption></figure><ul class=""><li id="6229" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated">定型数据集中不存在空值。</li></ul><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">检查空值的代码</figcaption></figure><ul class=""><li id="d5a2" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated">我们还必须检查数据集中的重复值。在我们的数据集中可能存在重复的独立变量。还可能存在具有不同特征值的重复sig_id，并且还可能存在数据的sig_id不同但其余特征值相同的可能性。所以，我们会检查所有的可能性。</li></ul><p id="3125" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">数据集中没有重复的行和重复的id。</p><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">检查重复值的代码</figcaption></figure><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mk"><img src="../Images/00a585a15816f81336298c42eeb5c061.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8wenLhSfkttlU06txPcNig.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">检查重复值的代码输出</figcaption></figure><ul class=""><li id="fd90" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated">在检查异常值时，我们发现在所有基因和细胞列中都有<em class="ky">高方差</em>，我们不能将它们声明为异常值。通过随机绘制50个基因列的方框图，我们发现其值位于10到-10之间，通过随机绘制50个细胞列的方框图，我们发现所有细胞列的值位于6到-10之间。</li></ul><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ml"><img src="../Images/f18854ad6855332b32d9f9dfc14b4887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V0pEYChadYIWJthy0Bn_vw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">50个随机基因柱的分布</figcaption></figure><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mm"><img src="../Images/c2fdaa45b714d5abb7dee3122d556234.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tnT48Dj7PVgvCTePbh8HvQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">50个随机单元列的分布</figcaption></figure><ul class=""><li id="6c84" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated">在数据集中，cp_type、cp_time和cp_dose列只是分类特征，所有其他特征都是数值特征。在对每个分类特征cp_type、cp_time和cp_dose中的唯一数据点的数量进行可视化计数的过程中，我们发现，在cp_type特征中，trt_cp数据点高度支配ctl_vehicle数据点，这使得cp_type特征高度不平衡。其余两个分类特征cp_time和cp_dose是平衡的。</li></ul><figure class="me mf mg mh fd ii er es paragraph-image"><div class="er es mn"><img src="../Images/5ef0ce16a9f85591c490689eb8321a2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/format:webp/1*DkBkZgWdJZ5ZNjkP-aUqKg.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">分类列中的数据点分布</figcaption></figure><ul class=""><li id="3fd5" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated">现在检查基因列和细胞列之间的相关性。在基因栏中，我们可以看到没有很大的相关性，但我们可以看到一些小点。放大这些小点后，我们发现有一些相关性，而这些淡色点很少，我们可以忽略它们。单元格列之间没有这种相关性。</li></ul><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mo"><img src="../Images/e2e14a70aa7befec68992d562deccac2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EAQ7fwbYSEOzm4OL6X_OSA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">基因列间的相关性</figcaption></figure><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mo"><img src="../Images/1e24310fe615b57f697db1db220cf799.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0RRakogoHJeNi9LdK7ugxg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">放大微小的光点</figcaption></figure><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mp"><img src="../Images/024e4b6cc1462afb18dec1b2ce7cad24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ewESM2sm8v89RYtvqntMyw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">单元列之间的相关性</figcaption></figure><ul class=""><li id="8864" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated">还有一个csv文件(train_drug.csv ),其中包含药品id和样品id。它显示哪个样本用哪个药物处理。在这里，我们发现drog id“cacb2b 860”最常用，其次是“87d714366”。如下图所示，使用最多的是前9种药物，其余药物很少使用。</li></ul><figure class="me mf mg mh fd ii er es paragraph-image"><div class="er es mq"><img src="../Images/0958ab6a23a4d29f5a63d7193547aecf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1076/format:webp/1*t3HnWjRoojxq-4m3n5HhIA.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">药物的使用</figcaption></figure><ul class=""><li id="735c" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated">为了直观显示每个样品中的氧化膜数量，首先我计算了每个样品每行中氧化膜的数量。在绘制这些计数后，我发现大多数样品具有0、1和2个moa，也有一些样品具有7个moa，极少数样品具有3、4、5、6和7个moa。</li></ul><figure class="me mf mg mh fd ii er es paragraph-image"><div class="er es mr"><img src="../Images/be33e12801dbbf659e293be814a9de9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*HdEOMZllUBDRR5O0oGxh9Q.png"/></div></figure><h1 id="f779" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">特征工程</h1><p id="f115" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">这是数据预处理中最重要的步骤之一。在这一步中，我们修改数据，并根据我们在探索性数据分析(EDA)中发现的数据做好使用准备。</p><ul class=""><li id="534d" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated">从编码分类变量开始，cp_type是名词性的，cp_time和cp_dose是有序分类特征。在cp_type和cp_dose中有2个唯一值，但是在cp_tine中有3个唯一值。我将对训练和测试数据集的这些特征进行编码。</li></ul><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">编码分类值</figcaption></figure><ul class=""><li id="628f" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated">从我们的EDA中，我们发现在基因和细胞特征上有很大的差异。所以我们将使用<em class="ky">sk learn . preprocessing . quantile transformer</em>库来规范化它们。</li></ul><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">规范化数字特征的代码</figcaption></figure><p id="136b" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">下面是标准化后50个随机基因和细胞柱的箱线图。因此，在这里我们可以看到，基因和细胞列没有很大的差异，它们都变得正常化了。</p><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ms"><img src="../Images/5397586314d05291c13a1a079501e7b1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GIhxSEgW0y2fKeVrTUiyJQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">归一化后随机50个基因列的分布</figcaption></figure><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ms"><img src="../Images/ae145a7a6dbfbaf8d41461e415b79652.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M1rVz9k7_EpepG5SOZwo7w.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">归一化后随机50个单元格列的分布</figcaption></figure><ul class=""><li id="984d" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated">现在，我试图在<strong class="jt hi">自动编码器</strong>的帮助下，使用原始特征生成一些特征。为了使用自动编码器，首先我只使用训练自变量来训练<em class="ky">编码器-解码器模型</em>，这意味着我将训练自变量(875列)作为训练变量和目标变量。</li></ul><p id="ce8b" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">编码器-解码器模型所做的是，它获取输入特征，如下图所示，在编码器部分，它试图减少特征的数量，在解码器部分，它试图重新创建与输出相同的特征。如图所示的粉色部分称为<em class="ky">瓶颈</em>。</p><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mt"><img src="../Images/3cd52dd4eb3bfb549564f94020cea40f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mzrZCn7FB-b5zKkPprQr-g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">来源:<a class="ae lk" href="https://towardsdatascience.com/generating-images-with-autoencoders-77fd3a8dd368" rel="noopener" target="_blank">https://towards data science . com/generating-images-with-auto encoders-77 FD 3a 8 DD 368</a></figcaption></figure><p id="b542" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">因此，为了生成新的功能，我只使用了编码器部分，直到瓶颈。使用encoder section I生成了50个新功能(尝试了各种数量的新功能，如10、50、100和200个，但50个效果最好)。现在将50个新生成的定型和测试数据集列与其原始列合并。合并后列数增加到<strong class="jt hi"> 926列</strong>。</p><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">编码器-解码器模型代码</figcaption></figure><p id="8e51" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">编码器-解码器模型概述。</p><figure class="me mf mg mh fd ii er es paragraph-image"><div class="er es mu"><img src="../Images/c9e4c6afaf54063de1b805328d448268.png" data-original-src="https://miro.medium.com/v2/resize:fit:1198/format:webp/1*BGjVLLPRQXq1GSpVxg2FRw.jpeg"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">编解码模型综述</figcaption></figure><p id="55be" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">获得预训练的编码器模型后，保存该模型以备后用(在创建web应用程序期间),这样我就不必定期训练编码器-解码器模型。</p><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">仅保存编码器型号</figcaption></figure><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">加载编码器模型并生成特征</figcaption></figure><h1 id="206e" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">模型创建</h1><p id="0144" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">由于我们已经完成了探索性数据分析、数据清洗、特征工程和所有数据预处理步骤，现在我们准备将机器学习算法应用于预处理数据集。</p><p id="fbe2" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">由于这是一个<em class="ky">多标签</em>问题，所以我尝试了各种方法来解决这个问题。但是，在这里，我将只讨论那种工作得非常好、速度快、精确度最高的方法，我将在本博客的后面讨论其他方法。</p><p id="bde4" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">解决这种多标签问题的最佳方法是使用带有<strong class="jt hi"> OneVsRestClassifier() </strong>的机器学习算法。</p><p id="097d" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated"><em class="ky">那么，OneVsRestClassifier是什么？</em></p><p id="0dfc" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">OneVsRestClassifier用于使机器学习算法适合多类别以及多标签问题。它也被称为一对一分类器。为了使用这种策略，目标标签应该是2D二进制矩阵。</p><blockquote class="le lf lg"><p id="8bc2" class="jr js ky jt b ju kz jw jx jy la ka kb lh lb ke kf li lc ki kj lj ld km kn ko ha bi translated">要了解有关OneVsRestClassifier的更多信息，请访问:<a class="ae lk" href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html" rel="noopener ugc nofollow" target="_blank">https://scikit-learn . org/stable/modules/generated/sk learn . multi class . OneVsRestClassifier . html</a></p></blockquote><p id="6332" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">我在OneVsRestClassifier中使用的机器学习算法有:</p><ul class=""><li id="b39b" class="ll lm hh jt b ju kz jy la kc ln kg lo kk lp ko lq lr ls lt bi translated"><strong class="jt hi">逻辑回归</strong></li><li id="c5d4" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi">朴素贝叶斯分类器</strong></li><li id="6113" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi">随机森林分类器</strong></li></ul><p id="fc90" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">所有其他集合模型或KNN模型或SVM与径向基函数将需要大量的时间来训练。</p><h2 id="64fc" class="mv iu hh bd iv mw mx my iz mz na nb jd kc nc nd jh kg ne nf jl kk ng nh jp ni bi translated">逻辑回归</h2><p id="f288" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">在所有算法中，逻辑回归用OneVsRestClassifier执行得最好。它花费较少的时间训练，并给出了非常低的日志损失。我还进行了超参数调整，以找到超参数的最佳值。</p><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">训练模型的逻辑回归代码</figcaption></figure><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nj"><img src="../Images/06e0bda560929f83b769625ee7c89425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8aPF_4TtDA8m76g2qRjiPw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">逻辑回归交叉验证输出</figcaption></figure><p id="46fb" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">通过使用逻辑回归，我们得到了大约0.016的对数损失，这是非常低的，意味着我们的模型是好的。</p><blockquote class="le lf lg"><p id="c29e" class="jr js ky jt b ju kz jw jx jy la ka kb lh lb ke kf li lc ki kj lj ld km kn ko ha bi translated">由于这是一个多类问题，因此，为了计算对数损失，我们必须使用循环来计算每个标签的对数损失，最终损失将是所有损失的平均值。</p></blockquote><h2 id="1110" class="mv iu hh bd iv mw mx my iz mz na nb jd kc nc nd jh kg ne nf jl kk ng nh jp ni bi translated">朴素贝叶斯分类器</h2><p id="9efa" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">朴素贝叶斯分类器在这种情况下表现不佳。</p><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">训练模型的朴素贝叶斯分类器代码</figcaption></figure><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nk"><img src="../Images/a94eac9ebaefd2b97dc24b8d940a0fd9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9lDKS80PSb8wHG12naaB3g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">朴素贝叶斯分类器交叉验证输出</figcaption></figure><p id="9746" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">通过使用朴素贝叶斯分类器，我们得到了大约7的对数损失，这是不好的，意味着朴素贝叶斯分类器表现不好。</p><h2 id="7c1c" class="mv iu hh bd iv mw mx my iz mz na nb jd kc nc nd jh kg ne nf jl kk ng nh jp ni bi translated">随机森林分类器</h2><p id="478e" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">随机森林分类器也表现良好，但不如逻辑回归好，而且需要更多的时间来训练。</p><figure class="me mf mg mh fd ii"><div class="bz dy l di"><div class="mi mj l"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">训练模型的随机森林分类器代码</figcaption></figure><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nl"><img src="../Images/afb6436c8a42ccc915a9768d64e638c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jCN8ly0TC3OXmJWYUFzxdw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">随机森林分类器交叉验证输出</figcaption></figure><p id="a54b" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">通过使用随机森林分类器，我们得到了大约0.020的对数损失，这是非常低的，意味着我们的模型表现良好。</p><p id="dcc1" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated"><strong class="jt hi">所有型号对比</strong></p><figure class="me mf mg mh fd ii er es paragraph-image"><div class="er es nm"><img src="../Images/ad213c3ef7c8ff8d3a38fb302981eb7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1028/format:webp/1*7vTUSqz3vs3al5P8OEhtyQ.png"/></div></figure><p id="f590" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated"><strong class="jt hi">在所有这些模型中，以OneVsRestClassifier的Logistic回归表现最好。</strong></p><p id="828b" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">下面是我提交最终模型后在Kaggle上得到的分数。</p><figure class="me mf mg mh fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nn"><img src="../Images/283d219122108bd6bb4c90e3594743dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IEF5x5XgEBBAI1v8MBuR0g.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">Kaggle分数</figcaption></figure><h1 id="93d1" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">我们尝试过但没有成功的事情</h1><ul class=""><li id="de8a" class="ll lm hh jt b ju jv jy jz kc no kg np kk nq ko lq lr ls lt bi translated"><strong class="jt hi">scikit-multi learn library</strong>—我尝试用这个库来训练这个多标签问题，但是由于这个问题有大量的标签，所以这个库花了很多时间来训练模型，但是失败了。这个scikit-multilearn库在我们有少量标签的小数据集时工作得很好。</li><li id="e15c" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi">将多标签转换为多类</strong> —我试图将这个多标签问题转换为多类问题，它创建了许多类，几乎所有的数据点都变得唯一，变得非常难以处理。</li><li id="66f4" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi"> Xgboost和SVM使用带有OneVsResClassifier </strong>的rbf内核—尝试使用这些算法来训练模型，他们花费了大量时间(超过7个小时)来训练，但在这些时间内没有完全训练好，因此取消了训练过程。</li><li id="960b" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi">过采样</strong> —由于我们的目标标签高度不平衡，所以我试图在训练模型之前进行过采样，但这并没有改善模型的性能，所以放弃了这个想法。</li><li id="24e1" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><strong class="jt hi"> PCA </strong> —对于特征选择，我使用PCA来选择特征，并与原始数据集合并，但它没有提高模型性能。所以，我用自动编码器代替了它，它提高了模型的性能。</li></ul><h1 id="886b" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">我们尝试过并且也成功了的事情</h1><p id="247c" class="pw-post-body-paragraph jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ha bi translated">还有一种方法，我尝试过，效果很好，表现得和使用OneVsRestClassifier的逻辑回归一样好，那就是，对于每个标签，我训练了一个逻辑回归模型，训练了总共206个模型，并存储它们以在预测过程中使用。在预测过程中，我使用循环调用所有模型来预测每个标签的值。我没有选择这个方法的原因是它比OneVsRestClassifier方法花费更多的时间。</p><h1 id="5726" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">未来的工作</h1><ul class=""><li id="dec1" class="ll lm hh jt b ju jv jy jz kc no kg np kk nq ko lq lr ls lt bi translated">我想试试两步法。在这种方法中，首先我将预测样品中是否存在氧化钼，如果存在氧化钼，则进入第二步，我们将预测氧化钼。</li><li id="16ce" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated">我想尝试深度学习技术来解决这个问题。</li></ul><h1 id="0473" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">结论</h1><ul class=""><li id="5096" class="ll lm hh jt b ju jv jy jz kc no kg np kk nq ko lq lr ls lt bi translated">使用OneVsRestClassifier的逻辑回归表现最佳，对数损失约为0.016，并且训练也非常快。</li><li id="2eb5" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated">在EDA过程中，如果数据点远离箱线图的须状线，那么它不一定是异常值。</li><li id="24cb" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated">如果我们有大量特征和大量目标标签的数据集，那么时间复杂度较低的机器学习模型工作得最好，而时间复杂度较高的机器学习算法不起作用。</li></ul><p id="7423" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated"><strong class="jt hi"> <em class="ky">感谢阅读:)</em> </strong></p><p id="1bf4" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">完整的代码你可以访问我的<a class="ae lk" href="https://github.com/NIKsaurabh/Mechanism-of-Action-Predictor/tree/main/notebooks" rel="noopener ugc nofollow" target="_blank"> <strong class="jt hi"> <em class="ky"> Github仓库</em> </strong> </a>包含Jupyter笔记本，整个项目你可以访问<a class="ae lk" href="https://github.com/NIKsaurabh/Mechanism-of-Action-Predictor" rel="noopener ugc nofollow" target="_blank"> <strong class="jt hi"> <em class="ky">这里</em> </strong> </a>。</p><h1 id="c5d3" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">参考</h1><ul class=""><li id="faf1" class="ll lm hh jt b ju jv jy jz kc no kg np kk nq ko lq lr ls lt bi translated"><a class="ae lk" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">https://www.appliedaicourse.com/</a></li><li id="7ca6" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><a class="ae lk" href="https://www.kaggle.com/c/lish-moa/data" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/c/lish-moa/data</a></li><li id="4cba" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><a class="ae lk" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC147203/" rel="noopener ugc nofollow" target="_blank">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC147203/</a></li><li id="c9a4" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated">https://www . ka ggle . com/viktorurushkin/scaler-PCA-cv-logistic-regression</li><li id="a214" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><a class="ae lk" href="https://www.kaggle.com/maithiltandel/moa-submission" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/maithiltandel/moa-submission</a></li><li id="6a40" class="ll lm hh jt b ju ly jy lz kc ma kg mb kk mc ko lq lr ls lt bi translated"><a class="ae lk" href="https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-la" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2017/08/introduction-to-multi-la</a>bel-class ification/</li></ul><p id="4371" class="pw-post-body-paragraph jr js hh jt b ju kz jw jx jy la ka kb kc lb ke kf kg lc ki kj kk ld km kn ko ha bi translated">也可以在<a class="ae lk" href="https://linkedin.com/in/niksaurabh/" rel="noopener ugc nofollow" target="_blank"> <strong class="jt hi"> <em class="ky"> linkedin </em> </strong> </a>上联系我。</p></div></div>    
</body>
</html>