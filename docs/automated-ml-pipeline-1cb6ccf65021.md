# 自动化 ML 管道

> 原文：<https://medium.com/analytics-vidhya/automated-ml-pipeline-1cb6ccf65021?source=collection_archive---------8----------------------->

在我之前的文章中:[https://ssahuupgrad-93226 . medium . com/designing-a-continuous-learning-framework-d 5b 5 ea 7979 CB](https://ssahuupgrad-93226.medium.com/designing-a-continuous-learning-framework-d5b5ea7979cb)我们学习了一个小用例，以了解自动机器学习管道的连续学习是如何工作的。

在这里，我们可以自动化 ML 生产管道，根据我们的用例，用新数据重新训练模型:

*   按需:它是基于我们的需要，特别手动执行管道。没有运行任何调度程序来定期执行管道。
*   按时间表:管道执行取决于数据模式改变的频率，重新训练模型的成本，以及基于每天、每周或每月发生的 ML 管道执行。
*   关于新训练数据的可用性:当新数据被收集并在源数据库中可用时，管道执行发生。
*   关于模型性能退化:当有明显的性能退化时，模型被重新训练。
*   数据分布的重大变化。当我们注意到用于执行预测的特征的数据分布发生显著变化时，会重新训练该模型。

**挑战**:

当管道的新实现不经常与新的 ML 思想一起部署时会发生什么？

当我们基于新数据部署新模型时，这种设置是合适的，而不是基于新的 ML 思想。

但是在真实的 ML 环境中，我们需要用新的模型和算法来尝试新的 ML 思想，并快速部署 ML 组件的新实现，为此我们需要 CI/CD 设置来自动化 ML 管道的构建、测试和部署。

为了快速可靠地更新生产中的管道，我们需要一个强大的自动化 CI/CD(持续集成/持续部署)系统，帮助数据科学家探索有关特征工程、模型架构和超参数的新想法，并可以构建、测试和部署新的管道组件到目标环境。

下图显示了使用 CI/CD 的 ML 管道的实现，通常称为 MLOps，它具有自动 ML 管道设置和自动 CI/CD 例程的特征。

该 MLOps 设置包括以下组件:

*   源代码控制
*   测试和构建服务
*   部署服务
*   模型注册表
*   功能存储
*   ML 元数据存储
*   ML 管道编排器

**MLOps 阶段**:

下图是 ML CI/CD 自动化管道的流程图:

![](img/ed683cec712487c177f10c79cf717df0.png)

管道由以下阶段组成:

1.  开发和实验:我们迭代地构建、训练、评估和验证新的 ML 算法，其中实验步骤被编排。这个阶段的输出是 ML 管道步骤的源代码，然后这些源代码被推送到源存储库。
2.  管道持续集成:我们构建源代码并运行各种测试。这个阶段的输出是将在稍后阶段部署的管道组件(包、可执行文件和工件)。
3.  管道连续交付:我们将 CI 阶段产生的工件部署到目标环境中。这个阶段的输出是一个部署了模型的新实现的管道。
4.  自动触发:流水线在生产中根据计划或响应触发自动执行。这一阶段的输出是被推送到模型注册中心的经过训练的模型。
5.  模型连续交付:我们将经过训练的模型作为预测服务来提供。此阶段的输出是一个已部署的模型预测服务。
6.  监控:我们基于实时数据收集模型性能的统计数据。这个阶段的输出是执行流水线或执行新的实验周期的触发器。

**持续集成**:在这个阶段中，当新代码被提交或被推送到源代码库时，管道及其组件被构建、测试和打包。除了构建包、容器映像和可执行文件之外，CI 流程还可以包括以下测试:

*   单元测试我们的特征工程逻辑，在你的模型中实现的不同方法和模型的测试。
*   测试管道中的每个组件产生预期的工件。
*   测试管道组件之间的集成。

**持续交付:**在这个阶段，我们的系统持续地向目标环境交付新的管道实现，而目标环境又交付新训练的模型的预测服务。为了快速可靠地连续交付管道和模型，我们应该考虑以下几点:

*   在部署模型之前，验证模型与目标基础结构的兼容性。
*   通过使用预期的输入调用服务 API 来测试预测服务，并确保我们得到预期的响应。测试预测服务性能，包括对服务进行负载测试以获取指标和模拟延迟。
*   在部署之前，验证模型是否满足预测性能目标。
*   测试环境的自动化部署，例如，通过将代码推送到开发分支而触发的部署。
*   预生产环境的半自动部署，例如，在审阅者批准变更后，通过将代码合并到主分支而触发的部署。
*   在预生产环境中成功运行几次管道后，手动部署到生产环境中。

**连续训练。** CT 是不断训练模型的过程，意思是自动化的模型训练。它包含模型生命周期的所有步骤，从数据接收到跟踪其在生产中的性能，包括以下步骤:

*   ML 专家创建培训管道，预处理新功能，监控培训过程并解决问题。
*   运营专家测试管道组件，并将它们部署到目标环境中。

模型训练管道是连续训练过程和整个 MLOps 工作流程的关键组成部分，执行频繁的模型训练和再训练。

**模型注册:**在这个阶段，ML 专家共享模型，并与 Ops 专家合作，以改进模型管理。

当找到适合生产的模型时，它会被推送到模型注册中心——一个集中的中心，捕获已发布模型的所有元数据，如

*   标识符，
*   姓名，
*   版本，
*   添加该版本的日期，
*   序列化模型的远程路径，
*   模型的部署阶段(开发、生产、存档等。),
*   关于用于训练的数据集的信息，
*   运行时指标，
*   用于高度管控行业(如医疗保健或金融)审计目标的治理数据，以及
*   其他附加元数据取决于您的系统和业务需求。

注册中心充当研究和生产环境之间的通信层，为部署的模型提供运行时所需的信息。

**模型服务:**运营专家控制模型部署，而 ML 专家启动生产测试。最新的方法称为模型即服务，是目前最受欢迎的方法，因为它简化了部署，将机器学习部分与软件代码分离，通过这种方法，我们可以更新模型版本，而无需重新部署应用程序。

**结论:**在生产环境中实现 ML 并不意味着将我们的模型作为预测 API 进行部署，而是继续部署一个 ML 管道，使新模型的再训练和部署自动化。CI/CD 系统使我们能够自动测试和部署新的 ML 管道实现。该系统让我们能够应对数据和业务环境的快速变化。