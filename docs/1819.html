<html>
<head>
<title>Text Detection, Recognition and Translation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本检测、识别和翻译</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/scene-text-detection-recognition-and-translation-ad20c31e869e?source=collection_archive---------0-----------------------#2021-03-21">https://medium.com/analytics-vidhya/scene-text-detection-recognition-and-translation-ad20c31e869e?source=collection_archive---------0-----------------------#2021-03-21</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/d7d9e737fa261f425db7b71595018b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4IlQiYC2vYl0MrGa27hEPw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">用于文本检测的ICDAR-2015图像</figcaption></figure><h1 id="73cc" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">目录:-</h1><ol class=""><li id="9215" class="jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">问题介绍。</li><li id="e36f" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">商业问题的深度学习公式。</li><li id="b0da" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">业务限制。</li><li id="6a49" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">数据的来源。</li><li id="d490" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">探索性数据分析。</li><li id="da9e" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">最终创建数据，以便使用机器学习和深度学习模型。</li><li id="c9be" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">用于检测和识别的模型。</li><li id="0faf" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">文本翻译。</li><li id="0c22" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">使用最佳模型的最终管道。</li><li id="060f" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">使用烧瓶部署</li><li id="69b7" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">未来的工作。</li><li id="bda9" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">Github和LinkedIn个人资料。</li><li id="b779" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">参考文献。</li></ol><h1 id="73b6" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated"><strong class="ak"> 1)简介</strong></h1><p id="0a85" class="pw-post-body-paragraph ko kp hh jt b ju jv kq kr jw jx ks kt jy ku kv kw ka kx ky kz kc la lb lc ke ha bi translated">由于自然图像中的文本阅读在文档分析、场景理解、机器人导航和图像检索中的大量实际应用，它已经在计算机视觉领域吸引了越来越多的关注。尽管以前的工作在文本检测和文本识别方面都取得了显著的进展，但是由于文本模式的巨大变化和高度复杂的背景，这仍然是一个挑战。</p><p id="e6d3" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">场景文本阅读最常见的方式是将其分为文本检测和文本识别，作为两个独立的任务来处理。基于深度学习的方法在这两个领域都占据了主导地位。</p><h1 id="c92c" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">2)业务问题的深度学习公式</h1><p id="570a" class="pw-post-body-paragraph ko kp hh jt b ju jv kq kr jw jx ks kt jy ku kv kw ka kx ky kz kc la lb lc ke ha bi translated">文本检测:文本检测是一种技术，其中图像将被提供给模型，文本区域通过在其周围绘制边界框来检测。</p><p id="1184" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">文本识别:在文本检测之后是文本识别，其中检测到的文本区域被进一步处理，以便识别什么是文本。</p><p id="f984" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">文本翻译:在我的博客中，识别出的英语文本被翻译成印地语。</p><p id="78ed" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">为了执行上述任务，在每个阶段使用不同的深度学习模型，我们将在本博客稍后讨论。</p><h1 id="64f3" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">3)业务限制</h1><p id="b63b" class="pw-post-body-paragraph ko kp hh jt b ju jv kq kr jw jx ks kt jy ku kv kw ka kx ky kz kc la lb lc ke ha bi translated">图像可能模糊、有噪声、质量差，或者具有复杂背景的多方向(旋转/弯曲)图像。这使得难以检测文本区域。</p><p id="5aa2" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">如果部署模型来实时检测、识别和翻译图像中的文本，低延迟是必不可少的。</p><h1 id="6500" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">4)数据的来源</h1><p id="8228" class="pw-post-body-paragraph ko kp hh jt b ju jv kq kr jw jx ks kt jy ku kv kw ka kx ky kz kc la lb lc ke ha bi translated">1.数据由ICDAR 2015提供。它是ICDAR 2015鲁棒阅读竞赛的挑战4，常用于面向场景的文本检测和定位。这个数据集包括1000个使用可穿戴相机的训练图像。对于文本识别任务，它提供了3个特定的单词列表:</p><ul class=""><li id="d945" class="jr js hh jt b ju ld jw le jy li ka lj kc lk ke ll kg kh ki bi translated">每张图片100个单词，包括图片中出现的单词和干扰词。</li><li id="e5fe" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke ll kg kh ki bi translated">出现在训练集中的所有单词(3个字符或更长的单词，仅包含字母)的词汇表。</li><li id="1bc6" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke ll kg kh ki bi translated">1000个文本文件与单词水平本地化和转录地面真相。</li></ul><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lm"><img src="../Images/8756e56bbe1f5dd651e2ff687deefb18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ARIIc67TSymksO_9HUeM1A.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">ICDAR-2015</figcaption></figure><p id="a11a" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">2.ICDAR 2013由229幅训练图像组成。与上面不同的是，它由水平文本组成。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lr"><img src="../Images/012204ba88450d117ca22a16bd1c14b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pr7mRFUkgvg7wz__bEIVWg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">ICDAR-2013</figcaption></figure><p id="d896" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">所有上述数据仅由英语文本组成。它们中的大多数是水平方向的，而一些具有多方向的文本区域。</p><h1 id="6737" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">5)探索性数据分析</h1><h2 id="9f81" class="ls iu hh bd iv lt lu lv iz lw lx ly jd jy lz ma jh ka mb mc jl kc md me jp mf bi translated">ICDAR-2013–15</h2><p id="d00b" class="pw-post-body-paragraph ko kp hh jt b ju jv kq kr jw jx ks kt jy ku kv kw ka kx ky kz kc la lb lc ke ha bi translated">函数加载边界框，并将其绘制在ICDAR _ 2013–15图像的文本区域周围。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mi"><img src="../Images/97e96f6ca29c57725f730e82cedc27b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NEvnhqLKBwZWRuUddneDAw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">ICDAR-2013的输出图像</figcaption></figure><ol class=""><li id="10d2" class="jr js hh jt b ju ld jw le jy li ka lj kc lk ke kf kg kh ki bi translated">以上图片来自ICDAR 2013，由229张训练图片组成。</li><li id="2409" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">它由水平文本组成。</li><li id="0cfd" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">它只包含英文文本。</li></ol><h2 id="87d5" class="ls iu hh bd iv lt lu lv iz lw lx ly jd jy lz ma jh ka mb mc jl kc md me jp mf bi translated">ICDAR-2015</h2><p id="1a06" class="pw-post-body-paragraph ko kp hh jt b ju jv kq kr jw jx ks kt jy ku kv kw ka kx ky kz kc la lb lc ke ha bi translated">类似地，使用源ICDAR-2015以与上述相同的方式编写另一个函数，并获得图像。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mj"><img src="../Images/f42f8954c12acdf30faf36209a1f1505.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vgUfraa7Qy-WcFRKr9666Q.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">ICDAR-2015</figcaption></figure><ol class=""><li id="9275" class="jr js hh jt b ju ld jw le jy li ka lj kc lk ke kf kg kh ki bi translated">以上图片来自ICDAR 2015数据附带场景文字。</li><li id="6bbe" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">这里的文本只有一种语言，即英语，但是文本区域是多方向的，其中一些也是模糊的。</li></ol><h2 id="97b7" class="ls iu hh bd iv lt lu lv iz lw lx ly jd jy lz ma jh ka mb mc jl kc md me jp mf bi translated">图像的大小</h2><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><ol class=""><li id="bd58" class="jr js hh jt b ju ld jw le jy li ka lj kc lk ke kf kg kh ki bi translated">图像的大小与ICDAR 2015附带场景文本的大小相同，为1280 x 720。</li></ol><p id="d1f0" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">IC Dar _ 2013–15 _ focused _ Scene _ Text数据的图像大小不同。</p><p id="6005" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">使用上述代码打印前10幅图像的高度和宽度。</p><h1 id="3022" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">6)最终创建数据，以便使用深度学习模型。</h1><p id="8de5" class="pw-post-body-paragraph ko kp hh jt b ju jv kq kr jw jx ks kt jy ku kv kw ka kx ky kz kc la lb lc ke ha bi translated">每个数据帧包含:</p><ol class=""><li id="ce4f" class="jr js hh jt b ju ld jw le jy li ka lj kc lk ke kf kg kh ki bi translated">图像的路径</li><li id="8d9f" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">地面实况; 真值（机器学习）</li><li id="6dbc" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">边界框的坐标。</li><li id="3d5d" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">矩形的方向和矩形的中心。</li><li id="0cb3" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">标签用于表示哪个图像属于哪个数据集。所以必须在训练测试分割中平均分割数据。df_2013的标签为1，df_2015的标签为2</li></ol><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mk"><img src="../Images/b5b58579b073ac3432409d09cb2e1d04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SKHtFuy8-7PnUgAzhXLnzA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">数据框已创建</figcaption></figure><h1 id="2178" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">7)用于检测和识别的模型</h1><ul class=""><li id="f175" class="jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke ll kg kh ki bi translated">MSER(最大稳定极值区域):</li></ul><p id="56c4" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">MSER是一种图像中斑点检测的方法。MSER算法从图像中提取多个共变区域，称为mser:MSER是图像的一些灰度级集合的稳定连通分量。它可以用来异步检测文本。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ml"><img src="../Images/5685fbb181b4b75fc489bde8530b9eb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6bkDoULF6c5mDXNzSLPxyg.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">ICDAR-2013图片上的MSER</figcaption></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mm"><img src="../Images/d5fd642a0c5b8979e282925e1340e455.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*npPGLFMvmGDU6Fh1P06Ykw.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">ICDAR-2015图片上的MSER</figcaption></figure><p id="57a8" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">上述内容在文本检测方面做得不太好。尽管它对水平文本数据非常有效。</p><ul class=""><li id="e440" class="jr js hh jt b ju ld jw le jy li ka lj kc lk ke ll kg kh ki bi translated">东方和Pytesseract模型</li></ul><p id="d700" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">EAST(高效精确的场景文本检测器):</p><p id="9567" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">这是一个基于这篇<a class="ae mn" href="https://arxiv.org/abs/1704.03155v2" rel="noopener ugc nofollow" target="_blank">论文</a>的非常健壮的文本检测深度学习方法。值得一提的是，这只是一种文本检测方法。它可以找到水平和旋转的边界框。它可以与任何文本识别方法结合使用。</p><p id="f60b" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">本文中的文本检测流水线排除了冗余和中间步骤，只有两个阶段。</p><p id="3c96" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">人们利用全卷积网络直接产生字或文本行级预测。产生的预测可以是旋转的矩形或四边形，通过非最大值抑制步骤进一步处理，以产生最终输出。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div class="er es mo"><img src="../Images/c1b4f6497637de3ddf28a32ab13585b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*mt_1jb8DqS3KvGTrmH4deQ.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">东方模型</figcaption></figure><p id="2ba7" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">EAST可以检测图像和视频中的文本。正如论文中提到的，它在720p图像上以13FPS的速度近乎实时地运行，具有很高的文本检测准确性。这项技术的另一个好处是它的实现在OpenCV 3.4.2和OpenCV 4中可用。我们将看到这个EAST模型与文本识别一起运行。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="d7ac" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">文本识别的Pytesseract模型；</p><p id="38d7" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">Pytesseract是Tesseract-OCR引擎的包装器。它作为tesseract的独立调用脚本也很有用，因为它可以读取Pillow和Leptonica图像库支持的所有图像类型，包括jpeg、png、gif、bmp、tiff等。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><p id="85d0" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">使用East和Pytesseract后ICDAR- 2013的一些输出图像:</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mp"><img src="../Images/79d03f3ab604f65517e891ae7770b68e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M8VySmkQw__CQm6kOJjHcQ.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mq"><img src="../Images/de98ac7baaa650abd43044ae0a600551.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FZkJoyksl_kL0DGt2x6A6g.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mr"><img src="../Images/a3081a14c480f1620574d4284b884c1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ObuBNlocnP-udGcfvL7u1A.png"/></div></div></figure><p id="581e" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">使用East和Pytesseract后ICDAR- 2015的一些输出图像:</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ms"><img src="../Images/a0251b5ef6329eb72cc2a9b6e1edf02a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vfUwGYH5lag0TJCPMkgMeA.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mt"><img src="../Images/4f591abdd702ca69bb48997bed7eb110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hW2D-VC2BlQoHr2a5yVfUA.png"/></div></div></figure><p id="e80b" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">上述模型非常适合检测不模糊的水平文本。它在模糊图像的文本识别方面做得并不好。</p><p id="a3bc" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">文本检测对于模糊图像是有益的，它检测模糊的文本区域，但是不能理解文本。</p><ul class=""><li id="8a1e" class="jr js hh jt b ju ld jw le jy li ka lj kc lk ke ll kg kh ki bi translated">简易OCR:</li></ul><p id="e591" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">检测部分采用CRAFT算法，识别模型为CRNN。它由3个主要部分组成，特征提取(我们目前使用的是<a class="ae mn" href="https://analyticsindiamag.com/guide-to-building-a-resnet-model-with-without-dropout/" rel="noopener ugc nofollow" target="_blank"> Resnet </a>)、序列标注(<a class="ae mn" href="https://analyticsindiamag.com/how-to-implement-lstm-rnn-network-for-sentiment-analysis/" rel="noopener ugc nofollow" target="_blank"/>)和解码(CTC)。EasyOCR没有太多的软件依赖，可以直接和它的API一起使用。</p><p id="b370" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">EasyOCR可以同时处理多种语言，只要它们相互兼容。</p><p id="e5cd" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">Reader类是EasyOCR的基类，它包含一个语言代码和其他参数的列表，比如默认设置为True的GPU。只需要运行一次就可以加载必要的模型。模型重量可以自动下载，也可以手动下载。</p><p id="9b40" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">然后是readtext方法，这是Reader类的主要方法。</p><p id="a083" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">输出显示了文本的4个边界框坐标(x，y)以及识别的文本和置信度得分。</p><p id="4f03" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">在代码中，我将语言设置为“en ”,意思是英语。</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mu"><img src="../Images/284e1d751de13e9d2aaffa6d83ab6c2c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EtnZAo9Qj1jGFAIVMXoHfQ.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mv"><img src="../Images/c0df1171bd1ca1a8a0348120ae615bcd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IRKjpQI28YPz5oSmWHWsjg.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mw"><img src="../Images/ab3f9ee62faa7d62a8e3d7cc23c92d99.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wRoM0ujeKBFNqN6_iHtuwQ.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mx"><img src="../Images/41e1ee976bd10bf54576076870324a1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mt1hNbX0TNUsHOP4MvivIw.png"/></div></div></figure><ol class=""><li id="dff7" class="jr js hh jt b ju ld jw le jy li ka lj kc lk ke kf kg kh ki bi translated">上述算法在文本检测方面相当好，不仅对于水平文本，而且对于不同方向的文本区域。</li><li id="30d8" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">文字识别对于清晰的横排文字非常好。在模糊的和多方向的文本区域的情况下，精确度下降。</li></ol><p id="eca2" class="pw-post-body-paragraph ko kp hh jt b ju ld kq kr jw le ks kt jy lf kv kw ka lg ky kz kc lh lb lc ke ha bi translated">EasyOCR在很多方面比tessera CT(Google创建的另一个OCR引擎，与python包Pytesseract一起使用)表现更好。它易于使用，只需要几行代码就可以实现，对于大多数经过测试的图像都具有适当的准确性，并且可以扩展到多种语言。</p><h1 id="ebd9" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">8)文本翻译</h1><p id="f75e" class="pw-post-body-paragraph ko kp hh jt b ju jv kq kr jw jx ks kt jy ku kv kw ka kx ky kz kc la lb lc ke ha bi translated">我正在使用<strong class="jt hi"> englisttohindi </strong>模块将英语单词翻译成印地语单词。</p><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es my"><img src="../Images/85b932ddca1c04f179b58c033cb77e79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5YWJ6B8K-1nGbDai6K2ibw.png"/></div></div></figure><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><h1 id="e52b" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">9)使用最佳模型(即Easy OCR)的最终管道</h1><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="mg mh l"/></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mz"><img src="../Images/346ac8c4c89ca513c0d5288717218a3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*q0GHVgDO15CChlGTVVCN0Q.png"/></div></div></figure><figure class="ln lo lp lq fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es na"><img src="../Images/3ecb728e3e513f19c11e91defc80f2c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*X0DJ-SU6ugoRdflctAR1Xg.png"/></div></div></figure><ol class=""><li id="d1cb" class="jr js hh jt b ju ld jw le jy li ka lj kc lk ke kf kg kh ki bi translated">上述模型使用easy ocr进行文本识别和检测，并使用EngtoHindi python库将英语单词翻译成印地语单词。</li><li id="3dc2" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">该模型适用于高分辨率(清晰的文本区域)，但不适用于模糊的文本区域。</li><li id="f238" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">有些单词被发现有微小的拼写错误</li></ol><h1 id="4ed9" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">10)使用烧瓶展开</h1><p id="b7d2" class="pw-post-body-paragraph ko kp hh jt b ju jv kq kr jw jx ks kt jy ku kv kw ka kx ky kz kc la lb lc ke ha bi translated">上面的管道也是使用flask部署的:</p><figure class="ln lo lp lq fd ii"><div class="bz dy l di"><div class="nb mh l"/></div></figure><h1 id="9c60" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">11)未来的工作</h1><ol class=""><li id="cdb1" class="jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated">我们可以探索更多，并尝试建立模型，更好地为具有多方向文本区域的模糊图像工作。</li><li id="0c9e" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">此外，我们不仅可以尝试将语言翻译成印地语，还可以翻译成其他流行语言。</li><li id="2aff" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated">尝试建立一个检测任何语言文本区域的模型，而不仅仅是英语。</li></ol><h1 id="a148" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">12) Github和LinkedIn个人资料</h1><p id="3772" class="pw-post-body-paragraph ko kp hh jt b ju jv kq kr jw jx ks kt jy ku kv kw ka kx ky kz kc la lb lc ke ha bi translated"><strong class="jt hi"> <em class="nc">完整的教程代码你可以在github </em> </strong> <a class="ae mn" href="https://github.com/Mansisarda1999/Text-Detection-recognition-and-translation" rel="noopener ugc nofollow" target="_blank"> <strong class="jt hi"> <em class="nc">这里</em> </strong> </a>找到</p><div class="nd ne ez fb nf ng"><a href="https://www.linkedin.com/in/mansi-sarda-87b76a168/" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hi fi z dy nl ea eb nm ed ef hg bi translated">曼西·萨尔达-毛拉纳·阿布·卡拉姆·阿扎德技术大学，西孟加拉邦，前称WBUT …</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">查看曼西·萨尔达在全球最大的职业社区LinkedIn上的个人资料。曼西有一份工作列在他们的…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">www.linkedin.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu in ng"/></div></div></a></div><h1 id="149f" class="it iu hh bd iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq bi translated">13)参考文献</h1><ol class=""><li id="3b4b" class="jr js hh jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki bi translated"><a class="ae mn" href="https://analyticsindiamag.com/hands-on-tutorial-on-easyocr-for-scene-text-detection-in-images/" rel="noopener ugc nofollow" target="_blank">https://analyticsindiamag . com/hands-on-tutorial-on-easy ocr-for-scene-text-detection-in-images/</a></li><li id="cf61" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated"><a class="ae mn" href="https://jaafarbenabderrazak-info.medium.com/opencv-east-model-and-tesseract-for-detection-and-recognition-of-text-in-natural-scene-1fa48335c4d1" rel="noopener">https://jaafarbenabderrazak-info . medium . com/opencv-east-model-and-tesse ract-for-detection-and-recognition-of-text-in-natural-scene-1fa 48335 C4 D1</a></li><li id="453d" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated"><a class="ae mn" href="https://www.geeksforgeeks.org/build-an-application-to-translate-english-to-hindi-in-python/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/build-an-application-to-translate-English-to-Hindi-in-python/</a></li><li id="7ec6" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated"><a class="ae mn" href="https://www.geeksforgeeks.org/text-detection-and-extraction-using-opencv-and-ocr/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/text-detection-and-extraction-using-opencv-and-ocr/</a></li><li id="87c3" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated"><a class="ae mn" href="https://github.com/oyyd/frozen_east_text_detection.pb/blob/master/frozen_east_text_detection.pb" rel="noopener ugc nofollow" target="_blank">https://github . com/oyyd/frozen _ east _ text _ detection . Pb/blob/master/frozen _ east _ text _ detection . Pb</a></li><li id="2fcc" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated"><a class="ae mn" href="https://stackoverflow.com/questions/13928155/spell-checker-for-python/48280566#:~:text=The%20best%20way%20for%20spell,The%20fastest%20one%20is%20SymSpell" rel="noopener ugc nofollow" target="_blank">https://stack overflow . com/questions/13928155/spell-checker-for-python/48280566 #:~:text = The % 20 best % 20 way % 20 for % 20 spell，The % 20 fast % 20 one % 20 is % 20 sym spell</a></li><li id="8ae1" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated"><a class="ae mn" href="https://www.geeksforgeeks.org/python-opencv-cv2-puttext-method/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/python-opencv-cv2-puttext-method/</a></li><li id="ccd4" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated"><a class="ae mn" href="https://www.geeksforgeeks.org/python-opencv-cv2-puttext-method/" rel="noopener ugc nofollow" target="_blank">https://www . geeks forgeeks . org/python-opencv-cv2-puttext-method/</a></li><li id="2ea9" class="jr js hh jt b ju kj jw kk jy kl ka km kc kn ke kf kg kh ki bi translated"><a class="ae mn" href="https://www.appliedaicourse.com/course/11/Applied-Machine-learning-course" rel="noopener ugc nofollow" target="_blank">https://www . Applied ai course . com/course/11/Applied-Machine-learning-course</a></li></ol></div></div>    
</body>
</html>