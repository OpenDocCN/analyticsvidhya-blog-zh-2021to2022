<html>
<head>
<title>How SVM constructs boundaries? Math explained.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">SVM如何构建边界？数学解释道。</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/support-vector-machines-math-explained-d48c4edb3d4e?source=collection_archive---------6-----------------------#2021-04-22">https://medium.com/analytics-vidhya/support-vector-machines-math-explained-d48c4edb3d4e?source=collection_archive---------6-----------------------#2021-04-22</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="77cf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">SVM如何在高维空间中分离数据点背后的数学概念</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/c3a5a8214e70ba5fec4958e25c8a7262.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gsYyjHVqe5jqRbNdlhNp2g.jpeg"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">澳大利亚悉尼海港大桥——我们生活在一个美丽的三维世界里，时间是第四维</figcaption></figure><p id="7101" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi jt translated">1992年，Vladmir Vapnik和他的同事在贝尔实验室首次推出了支持向量机。然而，许多人不知道支持向量机的基础知识早在20世纪60年代他在莫斯科大学的博士论文中就已经得到了发展。几十年来，SVM一直是许多人的首选，因为它使用较少的计算资源，同时允许数据科学家实现显著的准确性。更不用说它同时解决了分类和回归问题。</p><h2 id="44d1" class="kc kd hi bd ke kf kg kh ki kj kk kl km iq kn ko kp iu kq kr ks iy kt ku kv kw bi translated"><strong class="ak"> 1。基本概念</strong></h2><p id="2aae" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">SVM可以解决线性和非线性问题，并能很好地解决许多实际的商业问题。SVM的原则思想是直截了当的。学习模型绘制一条线，将数据点分成多个类。在二元问题中，该决策边界采用<strong class="ih hj">最宽街道方法</strong>，最大化到每个类的最近数据点的距离。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lc"><img src="../Images/23e808c8882e1b050746f776d4a02766.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ym1E7v0HMmmP1GMAOtkMHg.png"/></div></div></figure><p id="8eeb" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在向量演算中，<strong class="ih hj">点积</strong>测量一个向量沿着另一个向量“有多远”,并告诉你在位移方向或另一个向量方向上的力的大小。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ld"><img src="../Images/f577dadc9ac4f407095fbe75e66f7cad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NeDZWiG2VHAFEGf7rvzHRw.png"/></div></div></figure><p id="946e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">例如，我们有未知向量<em class="le"> u </em>和垂直于决策边界的法向量<em class="le"> w </em>。<em class="le"> w u </em>的点积表示<em class="le"> u </em>在矢量<em class="le"> w </em>方向上的力的大小。在这方面，如果未知向量<em class="le"> u </em>位于边界的正侧，则可以用常数<em class="le"> b </em>描述如下。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/63c4d7f2cf531cc5e525f8f73d6e8682.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*5kRb_iB7lxiHgaKerxq5Wg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">SVM基本法则</figcaption></figure><p id="7757" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">位于分类正样本的边界之上(+1)或分类负样本的边界之下(-1)的样本可以相应地表示。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lg"><img src="../Images/5262943d3bbf27d1417c5e661225525a.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*lL1cexbBi3rHJFIMT4CQdg.png"/></div></figure><h2 id="e25d" class="kc kd hi bd ke kf kg kh ki kj kk kl km iq kn ko kp iu kq kr ks iy kt ku kv kw bi translated">2.决策规则—约束</h2><p id="378f" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">确定决策边界后，正边界和负边界的绘制方式应使每组中最接近的样本的宽度最大化，因此这些样本被放置在每组的边界上。</p><p id="ba95" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该规则将成为寻找边界最大宽度的约束。鉴于<em class="le"> y </em>对于正样本为+1，对于负样本为-1，上述两个方程都可以通过方程两边的<em class="le"> y </em>相乘来表示正边界或负边界的槽上的样本<em class="le"> x </em>。它们也被称为<em class="le">支持向量</em>。<a class="ae lh" href="https://www.mathcha.io/editor/XPgE9hqLS21T87r230UDzpE2xuJYBBk8InJowXV" rel="noopener ugc nofollow" target="_blank">见这里的数学解释。</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/25f076cdada860b1cf469758734a5775.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*poluhJC7FK2DaWGbBWvwew.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">SVM决策规则1 —约束(边界上的样本)</figcaption></figure><h2 id="c745" class="kc kd hi bd ke kf kg kh ki kj kk kl km iq kn ko kp iu kq kr ks iy kt ku kv kw bi translated">3.决策规则—最大宽度</h2><p id="d485" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">假设我们在正边界的檐槽上有向量<strong class="ih hj"><em class="le"/></strong><em class="le">x</em>+<strong class="ih hj"/>，在负边界的檐槽上有向量<em class="le"> x- </em>。<strong class="ih hj"> </strong> <em class="le"> x+ </em>减去<strong class="ih hj"> </strong> <em class="le"> x- </em>代表从负矢量<em class="le"> x- </em>到正矢量<em class="le"> x+ </em>的方向力。如果我们用垂直于决策边界的单位向量<em class="le"> w </em>对这个方向力进行点积，那么这就变成了正负边界之间的宽度。注意<em class="le"> w </em>是法向量|| <em class="le"> w </em> ||是w的大小<a class="ae lh" href="https://www.mathcha.io/editor/XPgE9hqLS21T87r230UDzpE2xuJYBBk8InJowXV" rel="noopener ugc nofollow" target="_blank">见这里解释的数学。</a></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es li"><img src="../Images/97dbe4c63fef917d437bc1e8f673e445.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*-vMK58QbdtRb8VuD9Nfvtg.png"/></div></figure><p id="9fb4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们基本上最大化了这个宽度，以区分正负数据点。这可以简化如下。最后一种形式是对<em class="le"> w </em>的幅度取平方，并为了数学上的方便将其除以2。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lj"><img src="../Images/25fd751ba221c706faf02012c715c6b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*rqgxUEiuoPA0XovJIE71kg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">SVM决策规则2—最大宽度</figcaption></figure><h2 id="7e41" class="kc kd hi bd ke kf kg kh ki kj kk kl km iq kn ko kp iu kq kr ks iy kt ku kv kw bi translated">3.约束优化-通过约束找到最大宽度</h2><p id="797c" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated"><strong class="ih hj">拉格朗日方程</strong>可用于解决约束优化问题。如果约束改变一个单位，那么目标函数的最大值减少λ。该方程通常用于在给定约束的情况下寻找目标函数的最大值或最小值。</p><ul class=""><li id="dbd4" class="lk ll hi ih b ii ij im in iq lm iu ln iy lo jc lp lq lr ls bi translated">L(x，λ) = f(x)- λ g(x)</li><li id="d7f3" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated"><em class="le"> f(x):目标函数</em></li><li id="8857" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated"><em class="le"> g(x):约束</em></li><li id="ff13" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated"><em class="le"> λ:拉格朗日</em></li></ul><p id="fd6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">前面我们提到过，SVM采用最宽街道法来寻找正负边界之间的最大宽度。这个问题可以用拉格朗日方程来描述，目标函数和约束条件定义如下。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lj"><img src="../Images/25fd751ba221c706faf02012c715c6b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1168/format:webp/1*rqgxUEiuoPA0XovJIE71kg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">目标函数:f(x) —最大宽度</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/25f076cdada860b1cf469758734a5775.png" data-original-src="https://miro.medium.com/v2/resize:fit:452/format:webp/1*poluhJC7FK2DaWGbBWvwew.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">约束函数:g(x) —边界上的样本</figcaption></figure><p id="6b58" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">总之，拉格朗日函数最小化目标函数(最终最大化正负边界之间的宽度),给定样本是槽上的支持向量的约束。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ly"><img src="../Images/d078796242d5ad1cc87cbf1e3a4dc0e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:798/format:webp/1*xa4IS_UIA4ekqZHIBUgDgg.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">用拉格朗日法求最大宽度</figcaption></figure><p id="6da8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上式中找到相对于<em class="le"> w </em>和<em class="le"> b </em>的导数后，可简化如下。由于<em class="le"> y i </em>和<em class="le"> y j </em>是标签或响应变量，因此可以通过<strong class="ih hj">最大化矢量<em class="le"> x i </em>和<em class="le">x j</em>T53】的点积来简单地最小化方程。换句话说，宽度的最大化<strong class="ih hj">完全取决于绘制边界线时对支持向量对</strong>的点积求和。</strong></p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lz"><img src="../Images/c7e4571e15408be5983b909cb8fd687c.png" data-original-src="https://miro.medium.com/v2/resize:fit:556/format:webp/1*7Iwbzfq9J20lqyWQD6l-OQ.png"/></div></figure><p id="f88a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，根据支持向量<em class="le"> x </em>和<em class="le"> u </em>的点积来确定未知向量<em class="le"> u </em>是否位于决策边界的正侧。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ma"><img src="../Images/3920917b71de8bac6dd3452de1e1141a.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*yQ4NGBRKrEtKT4i6ZcBoAA.png"/></div></figure><h2 id="38ff" class="kc kd hi bd ke kf kg kh ki kj kk kl km iq kn ko kp iu kq kr ks iy kt ku kv kw bi translated">4.内核技巧</h2><p id="3e9d" class="pw-post-body-paragraph if ig hi ih b ii kx ik il im ky io ip iq kz is it iu la iw ix iy lb ja jb jc hb bi translated">在线性问题中，SVM可以很容易地画出一个决策界限，将样本分成多个类别。然而，如果数据点不能用线性切片分离，那么可以在绘制决策边界之前转换数据点，这被称为核技巧。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mb"><img src="../Images/b8ab3ba9b1606e2ac8741962eec9f33f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gjyh3VvhB3taXnph3Dj17g.png"/></div></div></figure><p id="9374" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的例子中，非线性的SVM在用核技巧变换后变成了线性的SVM问题。内核基本上<strong class="ih hj">通过使用称为内核的特殊函数进行非线性变换，将问题从输入空间映射到一个新的高维空间(称为特征空间)<em class="le"> (x) </em> </strong>。然后使用线性模型来分离特征空间中的数据点。特征空间中的线性模型对应于输入空间中的非线性模型。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es mc"><img src="../Images/156e46198985ace98f42dede340990fd.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*wp4GV7zRyzd_zty5FH5ZMA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">将输入空间(非线性)映射到特征空间(线性)</figcaption></figure><p id="a379" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在特征空间中，SVM基本规则可以表达如下。下面的等式是当<em class="le"> w </em>的大小被替换为<em class="le"> a，y </em>和<em class="le"> x. </em> <a class="ae lh" href="https://www.mathcha.io/editor/XPgE9hqLS21T87r230UDzpE2xuJYBBk8InJowXV" rel="noopener ugc nofollow" target="_blank">的线性和时，见这里解释的数学。</a>使用内核的美妙之处在于原始方程不会改变，因为内核变换是在phi <strong class="ih hj"> 𝜙 </strong>中抽象的。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es md"><img src="../Images/444b097fbbdc4619fc8634386147a222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xk5ATS1chFKotiAMyKivIA.png"/></div></div></figure><p id="4978" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下面是内核函数的例子。通常，您可以从最简单的转换版本开始，逐步用越来越高级的内核函数建模，以避免过度拟合。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es me"><img src="../Images/5447828568fa0f9b63926a1bbae4cfbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1156/format:webp/1*caq4F5JjyiL1H9lqgb-fuA.png"/></div><figcaption class="jp jq et er es jr js bd b be z dx translated">核函数的例子</figcaption></figure><p id="b99c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">既然我们已经介绍了SVM在绘制边界时如何解决分类问题，我们将在下一篇文章中使用样本数据集构建一个模型。</p><p id="c99b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><em class="le">参考文献:</em></p><ul class=""><li id="b6c0" class="lk ll hi ih b ii ij im in iq lm iu ln iy lo jc lp lq lr ls bi translated"><a class="ae lh" href="http://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote09.html" rel="noopener ugc nofollow" target="_blank"> <em class="le">科内尔讲座:SVM </em> </a></li><li id="f99a" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated"><a class="ae lh" href="https://www.youtube.com/watch?v=_PwhiWxHK8o" rel="noopener ugc nofollow" target="_blank"> <em class="le">麻省理工学院公开课:SVM </em> </a></li><li id="d4ba" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated"><a class="ae lh" href="https://www.youtube.com/watch?v=bM4_AstaBZo" rel="noopener ugc nofollow" target="_blank"> <em class="le"> SVM(数学):数据科学概念</em> </a></li><li id="a454" class="lk ll hi ih b ii lt im lu iq lv iu lw iy lx jc lp lq lr ls bi translated"><a class="ae lh" href="https://www.youtube.com/watch?v=tEx-iqUX9Z4" rel="noopener ugc nofollow" target="_blank"><em class="le">SVM内核</em> </a></li></ul></div></div>    
</body>
</html>