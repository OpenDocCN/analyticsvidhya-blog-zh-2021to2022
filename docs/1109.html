<html>
<head>
<title>A Step by Step Guide to Generate Tabular Synthetic Dataset with GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用GANs生成表格合成数据集的分步指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-step-by-step-guide-to-generate-tabular-synthetic-dataset-with-gans-d55fc373c8db?source=collection_archive---------0-----------------------#2021-02-15">https://medium.com/analytics-vidhya/a-step-by-step-guide-to-generate-tabular-synthetic-dataset-with-gans-d55fc373c8db?source=collection_archive---------0-----------------------#2021-02-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><h1 id="385c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">目标</h1><p id="13a2" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在本文中，我们将指导如何使用GANs生成表格合成数据。预计生成的数据将与模型训练和测试的真实数据相似。</p><h1 id="aba6" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">介绍</h1><p id="cbd4" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在机器学习工作中，我们经常会遇到数据不足以训练模型，需要更多人工数据的情况。GANs是由Ian Goodfellow等人提出的深度学习架构。2014年(1)。GANs可以从零开始生成合成数据，由两部分组成:生成器和鉴别器。发生器用于从输入随机噪声中产生假数据；鉴别器用于区分样品是真的还是假的(由发生器产生)。鉴别器的性能用于更新和优化发生器和鉴别器。目前流行应用GANS生成图像数据，但关于表格数据的文章并不多。原因之一是非图像合成数据难以评价质量。在本帖中，我们将尝试从头开始生成一维合成数据。</p><h1 id="8487" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">资料组</h1><p id="b84c" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">糖尿病数据集来自Kaggle公共数据集:<a class="ae kb" href="https://www.kaggle.com/uciml/pima-indians-diabetes-database" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/uciml/pima-indians-diabetes-database</a></p><h1 id="9ce9" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">真实数据集的基本精度</h1><p id="476a" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">在本节中，我们将使用真实数据来训练随机森林模型，并获得模型的准确性。从真实数据训练的模型的准确度被用作与生成的假数据进行比较的基础准确度。完整的代码可以在git repo中找到:https://github . com/fzhurd/FZ work/tree/master/medium/gans post</p><p id="6219" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们首先输入所有请求的python模块，将csv文件作为Dataframe读取给pandas，并粗略地浏览数据集。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="023b" class="kq ig hi km b fi kr ks l kt ku">import numpy as np<br/>import pandas as pd<br/>import os<br/>import matplotlib.pyplot as plt</span><span id="1e83" class="kq ig hi km b fi kv ks l kt ku">from keras.models import Sequential<br/>from keras.layers import Dense<br/>from numpy.random import randn<br/>from matplotlib import pyplot<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.ensemble import RandomForestClassifier<br/>from sklearn import metrics</span><span id="c5ea" class="kq ig hi km b fi kv ks l kt ku">data = pd.read_csv('/content/diabetes.csv')<br/>print (data.shape)<br/>print (data.tail())<br/>print (data.columns)</span></pre><p id="989c" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">糖尿病数据集包括9列:妊娠、血糖、血压、皮肤厚度、胰岛素、身体质量指数、糖尿病、糖尿病功能、年龄和结果。结果列将是标签。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="d131" class="kq ig hi km b fi kr ks l kt ku">(768, 9)      <br/>Pregnancies  Glucose  ...  Age  Outcome 763           10      101  ...   63        0 764            2      122  ...   27        0 765            5      121  ...   30        0 766            1      126  ...   47        1 767            1       93  ...   23        0  [5 rows x 9 columns] </span><span id="26d2" class="kq ig hi km b fi kv ks l kt ku">Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',        'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],       dtype='object')</span></pre><p id="2893" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将使用除结果列之外的所有列作为特征来训练模型。结果列将用作模型的标签。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="296c" class="kq ig hi km b fi kr ks l kt ku">features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']</span><span id="879a" class="kq ig hi km b fi kv ks l kt ku">label = ['Outcome']</span><span id="4f33" class="kq ig hi km b fi kv ks l kt ku">X = data[features]<br/>y = data[label] </span></pre><p id="4912" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">真实数据集被分成训练和测试数据集。对随机森林分类器模型进行了训练和精度评估。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="d69e" class="kq ig hi km b fi kr ks l kt ku">X_true_train, X_true_test, y_true_train, y_true_test = train_test_split(X, y, test_size=0.30, random_state=42)</span><span id="dc48" class="kq ig hi km b fi kv ks l kt ku">clf_true = RandomForestClassifier(n_estimators=100)<br/>clf_true.fit(X_true_train,y_true_train)</span><span id="1c0c" class="kq ig hi km b fi kv ks l kt ku">y_true_pred=clf_true.predict(X_true_test)</span><span id="bb72" class="kq ig hi km b fi kv ks l kt ku">print("Base Accuracy:",metrics.accuracy_score(y_true_test, y_true_pred))</span><span id="a2ce" class="kq ig hi km b fi kv ks l kt ku">print("Base classification report:",metrics.classification_report(y_true_test, y_true_pred))</span></pre><p id="9f1f" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们得到真实数据的基本模型的精度大约是0.76；精度在0.82左右。从真实数据训练的模型的准确度将是在进一步的步骤中与从生成的假数据训练的模型进行比较的基础准确度。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="a74a" class="kq ig hi km b fi kr ks l kt ku">Base Accuracy: 0.7575757575757576 Base classification report:               precision    recall  f1-score   support             <br/>0       0.82      0.81      0.81       151            <br/>1       0.65      0.66      0.65        80      </span><span id="af40" class="kq ig hi km b fi kv ks l kt ku">accuracy                           0.76       231    <br/>macro avg       0.73      0.74      0.73       231 <br/>weighted avg       0.76      0.76      0.76       231</span></pre><h1 id="4880" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">生成合成数据</h1><p id="6b91" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">从这一节开始，我们将开始使用GANs生成假数据。第一步，我们定义一个generate_latent_points函数，它将在潜在空间中产生随机噪声，并被整形到与生成器模型的输入相匹配的维度。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="466a" class="kq ig hi km b fi kr ks l kt ku">def generate_latent_points(latent_dim, n_samples):<br/>    x_input = randn(latent_dim * n_samples)<br/>    x_input = x_input.reshape(n_samples, latent_dim)</span><span id="13dc" class="kq ig hi km b fi kv ks l kt ku">    return x_input</span></pre><p id="6b6c" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们定义generate_fake_samples函数来产生假数据。生成器的输入将是创建的潜在点(随机噪声)。生成器将预测输入随机噪声并输出一个numpy数组。因为是假数据，所以标签会是0。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="83ce" class="kq ig hi km b fi kr ks l kt ku"># use the generator to generate n fake examples, with class labels<br/>def generate_fake_samples(generator, latent_dim, n_samples):<br/>    x_input = generate_latent_points(latent_dim, n_samples)<br/>    X = generator.predict(x_input)<br/>    y = np.zeros((n_samples, 1))<br/>    <br/>    return X, y</span></pre><p id="83c0" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将定义另一个函数来生成真实样本，它将从真实数据集中随机选择样本。真实数据样本的标签是1。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="4cad" class="kq ig hi km b fi kr ks l kt ku"># generate n real samples with class labels; We randomly select n samples from the real data<br/>def generate_real_samples(n):<br/>    X = data.sample(n)<br/>    y = np.ones((n, 1))</span><span id="9590" class="kq ig hi km b fi kv ks l kt ku">    return X, y</span></pre><p id="8cc0" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将用Keras模块创建一个简单的序列模型作为生成器。输入维度将与输入样本的维度相同。内核将由‘he _ uniform’初始化。该模型将有3层，其中两层将由“relu”功能激活。输出层将由“线性”函数激活，输出层的维度与数据集的维度相同(9列)。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="80af" class="kq ig hi km b fi kr ks l kt ku">def define_generator(latent_dim, n_outputs=9):<br/>    model = Sequential()<br/>    model.add(Dense(15, activation='relu',  kernel_initializer='he_uniform', input_dim=latent_dim))<br/>    model.add(Dense(30, activation='relu'))<br/>    model.add(Dense(n_outputs, activation='linear'))</span><span id="ad03" class="kq ig hi km b fi kv ks l kt ku">    return model</span></pre><p id="7d56" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们可以通过输入一些参数值来检查发电机型号的信息。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="991e" class="kq ig hi km b fi kr ks l kt ku">generator1 = define_generator(10, 9)<br/>generator1.summary()</span></pre><p id="4282" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">发电机模型的输出如下:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="e358" class="kq ig hi km b fi kr ks l kt ku">Model: "sequential" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= dense (Dense)                (None, 15)                165        _________________________________________________________________ dense_1 (Dense)              (None, 30)                480        _________________________________________________________________ dense_2 (Dense)              (None, 9)                 279        ================================================================= Total params: 924 Trainable params: 924 Non-trainable params: 0 _________________________________________________________________</span></pre><p id="7385" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在我们定义了生成器之后，下一步我们将定义鉴别器。鉴别器也是一个简单的序列模型，包括3个密集层。前两层由“relu”函数激活，输出层由“sigmoid”函数激活，因为它将区分输入样本是真(True)还是假(False)。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="98c1" class="kq ig hi km b fi kr ks l kt ku">def define_discriminator(n_inputs=9):<br/>    model = Sequential()<br/>    model.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))<br/>    model.add(Dense(50, activation='relu'))<br/>    model.add(Dense(1, activation='sigmoid'))</span><span id="d15d" class="kq ig hi km b fi kv ks l kt ku">    # compile model<br/>    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])<br/>    <br/>    return model</span></pre><p id="b213" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们可以通过输入一些参数值来检查鉴别器模型的信息。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="f64d" class="kq ig hi km b fi kr ks l kt ku">discriminator1 = define_discriminator(9)<br/>discriminator1.summary()</span></pre><p id="43fb" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">鉴别器摘要的输出如下:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="5697" class="kq ig hi km b fi kr ks l kt ku">Model: "sequential_7" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= dense_15 (Dense)             (None, 25)                250        _________________________________________________________________ dense_16 (Dense)             (None, 50)                1300       _________________________________________________________________ dense_17 (Dense)             (None, 1)                 51         ================================================================= Total params: 1,601 Trainable params: 1,601 Non-trainable params: 0</span></pre><p id="d169" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">在定义了发生器和鉴别器模型之后，我们将定义Gan模型。它还是一个时序模型，并将生成器与鉴别器结合起来。注意:鉴别器模型重量必须是不可训练的。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="e2fe" class="kq ig hi km b fi kr ks l kt ku"># define the combined generator and discriminator model, for updating the generator</span><span id="f8fc" class="kq ig hi km b fi kv ks l kt ku">def define_gan(generator, discriminator):<br/>    # make weights in the discriminator not trainable<br/>    discriminator.trainable = False</span><span id="67d4" class="kq ig hi km b fi kv ks l kt ku">    model = Sequential()</span><span id="01e0" class="kq ig hi km b fi kv ks l kt ku">    # add generator<br/>    model.add(generator)</span><span id="2dbf" class="kq ig hi km b fi kv ks l kt ku">    # add the discriminator<br/>    model.add(discriminator)</span><span id="0d32" class="kq ig hi km b fi kv ks l kt ku">    # compile model<br/>    model.compile(loss='binary_crossentropy', optimizer='adam')</span><span id="784e" class="kq ig hi km b fi kv ks l kt ku">    return model</span></pre><p id="84bf" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将制作一个plot_history函数，以在图中显示最终的发生器和鉴频器损耗。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="80ef" class="kq ig hi km b fi kr ks l kt ku"># create a line plot of loss for the gan and save to file<br/>def plot_history(d_hist, g_hist):<br/>    # plot loss<br/>    plt.subplot(1, 1, 1)<br/>    plt.plot(d_hist, label='d')<br/>    plt.plot(g_hist, label='gen')<br/>    plt.show()<br/>    plt.close()</span></pre><p id="cc7d" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">最后，我们将训练生成器和鉴别器。对于每个时期，我们将结合半批真实数据和半批虚假数据，然后计算平均损失。组合模型将基于train_on_batch函数进行更新。经过训练的发电机将被保存以备将来使用。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="0db1" class="kq ig hi km b fi kr ks l kt ku"># train the generator and discriminator<br/>def train(g_model, d_model, gan_model, latent_dim, n_epochs=10000, n_batch=128, n_eval=200):</span><span id="dec1" class="kq ig hi km b fi kv ks l kt ku">    # determine half the size of one batch, for updating the  discriminator<br/>    half_batch = int(n_batch / 2)<br/>    d_history = []<br/>    g_history = []</span><span id="71dc" class="kq ig hi km b fi kv ks l kt ku">    # manually enumerate epochs<br/>    for epoch in range(n_epochs):<br/>    <br/>    # prepare real samples<br/>    x_real, y_real = generate_real_samples(half_batch)</span><span id="81ac" class="kq ig hi km b fi kv ks l kt ku">    # prepare fake examples<br/>    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)</span><span id="73c7" class="kq ig hi km b fi kv ks l kt ku">    # update discriminator<br/>    d_loss_real, d_real_acc = d_model.train_on_batch(x_real, y_real)<br/>    d_loss_fake, d_fake_acc = d_model.train_on_batch(x_fake, y_fake)<br/>    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)</span><span id="62a9" class="kq ig hi km b fi kv ks l kt ku">    # prepare points in latent space as input for the generator<br/>    x_gan = generate_latent_points(latent_dim, n_batch)</span><span id="f437" class="kq ig hi km b fi kv ks l kt ku">    # create inverted labels for the fake samples<br/>    y_gan = np.ones((n_batch, 1))</span><span id="8514" class="kq ig hi km b fi kv ks l kt ku">    # update the generator via the discriminator's error<br/>    g_loss_fake = gan_model.train_on_batch(x_gan, y_gan)</span><span id="d8d0" class="kq ig hi km b fi kv ks l kt ku">    print('&gt;%d, d1=%.3f, d2=%.3f d=%.3f g=%.3f' % (epoch+1, d_loss_real, d_loss_fake, d_loss,  g_loss_fake))</span><span id="aee1" class="kq ig hi km b fi kv ks l kt ku">    d_history.append(d_loss)<br/>    g_history.append(g_loss_fake)</span><span id="0dce" class="kq ig hi km b fi kv ks l kt ku">    plot_history(d_history, g_history)</span><span id="2d59" class="kq ig hi km b fi kv ks l kt ku">    g_model.save('trained_generated_model.h5')</span></pre><p id="b68e" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们输入latent_dim值为10来开始训练。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="7e89" class="kq ig hi km b fi kr ks l kt ku"># size of the latent space<br/>latent_dim = 10</span><span id="3884" class="kq ig hi km b fi kv ks l kt ku"># create the discriminator<br/>discriminator = define_discriminator()</span><span id="7d26" class="kq ig hi km b fi kv ks l kt ku"># create the generator<br/>generator = define_generator(latent_dim)</span><span id="1701" class="kq ig hi km b fi kv ks l kt ku"># create the gan<br/>gan_model = define_gan(generator, discriminator)</span><span id="a133" class="kq ig hi km b fi kv ks l kt ku"># train model<br/>train(generator, discriminator, gan_model, latent_dim)</span></pre><p id="28b2" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">根据您的计算机，培训过程将需要几分钟时间，具体如下:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="682b" class="kq ig hi km b fi kr ks l kt ku">.........<br/>&gt;9991, d1=0.858, d2=0.674 d=0.766 g=0.904 <br/>&gt;9992, d1=1.023, d2=0.833 d=0.928 g=0.816 <br/>&gt;9993, d1=0.737, d2=0.863 d=0.800 g=0.910 <br/>&gt;9994, d1=0.780, d2=0.890 d=0.835 g=0.846 <br/>&gt;9995, d1=0.837, d2=0.773 d=0.805 g=0.960 <br/>&gt;9996, d1=0.762, d2=0.683 d=0.723 g=1.193 <br/>&gt;9997, d1=0.906, d2=0.515 d=0.710 g=1.275 <br/>&gt;9998, d1=0.814, d2=0.412 d=0.613 g=1.228 <br/>&gt;9999, d1=0.701, d2=0.668 d=0.685 g=1.105 &gt;10000, d1=0.461, d2=0.814 d=0.638 g=1.097</span></pre><p id="2822" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">发生器损耗和鉴别器变化绘制如下:蓝色-鉴别器损耗；橙色-发电机损失</p><figure class="kh ki kj kk fd kx er es paragraph-image"><div class="er es kw"><img src="../Images/dca3e01219697809dddc30071a03527c.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/1*Z90NEv5yobZ52G-Xj4PP8w.png"/></div></figure><h1 id="691d" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">用模型评估生成的假数据的质量</h1><p id="9a2d" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">我们已经在上述步骤中成功地训练了生成器。在本节中，我们将使用经过训练的模型生成假数据，并测试假数据的质量。首先，我们将加载经过训练的生成器模型。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="f246" class="kq ig hi km b fi kr ks l kt ku">from keras.models import load_model<br/>model =load_model('/content/trained_generated_model')</span></pre><p id="8d65" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将使用经过训练的发电机模型创建假数据。假数据是750行。然后，我们将创建的假数据转换为熊猫数据帧。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="a958" class="kq ig hi km b fi kr ks l kt ku">latent_points = generate_latent_points(10, 750)<br/>X = model.predict(latent_points)</span><span id="2ed3" class="kq ig hi km b fi kv ks l kt ku">data_fake = pd.DataFrame(data=X,  columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'])</span><span id="7dfe" class="kq ig hi km b fi kv ks l kt ku">data_fake.head()</span></pre><p id="c41c" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">5行假数据信息的输出如下:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="eedc" class="kq ig hi km b fi kr ks l kt ku">Pregnancies Glucose BloodPressure SkinThickness Insulin BMI DiabetesPedigreeFunction Age Outcome <br/>3.042421 84.372429 41.264584 15.499371 75.576080 16.862654 0.643298 30.715979 0.131986<br/>2.379814 65.569473 34.632591 9.681239 153.032700 14.792008 0.301202 11.963096 -0.200955<br/>-0.212970 104.455383 40.059303 9.538709 0.783831 20.410034 0.439094 13.447835 0.229936 <br/>12.437524 257.148895 125.773453 2.465484 1.408619 50.760799 0.756833 113.432060 0.949813 <br/>3.571342 34.856190 30.242983 17.523539 1.804614 18.132822 0.289309 23.509460 -0.023842</span></pre><p id="daf2" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">真实数据中的结果列是0或1。因此，我们需要将生成的假数据的值映射到0或1。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="c6d7" class="kq ig hi km b fi kr ks l kt ku">outcome_mean = data_fake.Outcome.mean()</span><span id="6d6e" class="kq ig hi km b fi kv ks l kt ku">data_fake['Outcome'] = data_fake['Outcome'] &gt; outcome_mean<br/>data_fake["Outcome"] = data_fake["Outcome"].astype(int)</span></pre><p id="5bbb" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将在假数据中做同样的特征工程。标签是结果列。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="f1ac" class="kq ig hi km b fi kr ks l kt ku">features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']</span><span id="fd8d" class="kq ig hi km b fi kv ks l kt ku">label = ['Outcome']<br/>X_fake_created = data_fake[features]<br/>y_fake_created = data_fake[label]</span></pre><p id="03d9" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">我们将使用虚假数据训练随机森林分类器模型，并获得准确性。它将用于与基本模型精度进行比较。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="e009" class="kq ig hi km b fi kr ks l kt ku">X_fake_train, X_fake_test, y_fake_train, y_fake_test = train_test_split(X_fake_created, y_fake_created, test_size=0.30, random_state=42)</span><span id="0d99" class="kq ig hi km b fi kv ks l kt ku">clf_fake = RandomForestClassifier(n_estimators=100)<br/>clf_fake.fit(X_fake_train,y_fake_train)</span><span id="6731" class="kq ig hi km b fi kv ks l kt ku">y_fake_pred=clf_fake.predict(X_fake_test)</span><span id="a1e9" class="kq ig hi km b fi kv ks l kt ku">print("Accuracy of fake data model:",metrics.accuracy_score(y_fake_test, y_fake_pred))</span><span id="998a" class="kq ig hi km b fi kv ks l kt ku">print("Classification report of fake data model:",metrics.classification_report(y_fake_test, y_fake_pred))</span></pre><p id="3dc7" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">该模式的输出如下:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="a018" class="kq ig hi km b fi kr ks l kt ku">Accuracy of fake data model: 0.88 </span><span id="c767" class="kq ig hi km b fi kv ks l kt ku">Classification report of fake data model: precision    recall  f1-score   support             <br/>0       0.86      0.94      0.90       127            <br/>1       0.92      0.80      0.85        98      </span><span id="e4d6" class="kq ig hi km b fi kv ks l kt ku">accuracy                           0.88       225    <br/>macro avg       0.89      0.87      0.88       225 <br/>weighted avg       0.88      0.88      0.88       225</span></pre><p id="6316" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">用生成的假数据训练的新模型的准确率在0.88左右；与用真实数据训练的模型相比，在0.75左右。与真实数据相比，假数据模型似乎仍然是扭曲的。</p><h1 id="b58e" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">使用Table_evaluator评估生成的假数据的质量</h1><p id="3a48" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">Table_evaluator是一个库，用于评估合成数据集与真实数据集的相似程度。它适用于评估生成的合成数据。首先，我们将安装table_evaluator模块。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="35df" class="kq ig hi km b fi kr ks l kt ku">!pip install table_evaluator</span></pre><p id="c5da" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">安装完成后，我们将使用table_evaluator分析结果列，并与真实数据中的结果列进行比较。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="4925" class="kq ig hi km b fi kr ks l kt ku">from table_evaluator import load_data, TableEvaluator</span><span id="a634" class="kq ig hi km b fi kv ks l kt ku">table_evaluator = TableEvaluator(data, data_fake)<br/>table_evaluator.evaluate(target_col='Outcome')</span></pre><p id="d158" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">相似之处的输出如下。我们可以发现生成的合成数据与真实数据相似。假列和真列之间的平均相关性为0.9359，相似性得分约为0.6011。</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="4e04" class="kq ig hi km b fi kr ks l kt ku">Correlation metric: pearsonr<br/><br/>Classifier F1-scores and their Jaccard similarities:<br/>                                     f1_real  f1_fake  jaccard_similarity<br/>index                                                                    <br/>LogisticRegression_real_testset       0.7467   0.6333              0.5075<br/>LogisticRegression_fake_testset       0.4867   0.9267              0.3514<br/>RandomForestClassifier_real_testset   0.7267   0.6133              0.4634<br/>RandomForestClassifier_fake_testset   0.4467   0.9200              0.2658<br/>DecisionTreeClassifier_real_testset   0.7200   0.6333              0.4634<br/>DecisionTreeClassifier_fake_testset   0.4600   0.8733              0.3043<br/>MLPClassifier_real_testset            0.6800   0.5600              0.3393<br/>MLPClassifier_fake_testset            0.3800   0.9133              0.2000<br/><br/>Miscellaneous results:<br/>                                         Result<br/>Column Correlation Distance RMSE         0.4230<br/>Column Correlation distance MAE          0.3552<br/>Duplicate rows between sets (real/fake)  (0, 0)<br/>nearest neighbor mean                    1.5898<br/>nearest neighbor std                     0.7154<br/><br/>Results:<br/>                                                Result<br/>Basic statistics                                0.9364<br/>Correlation column correlations                 0.1430<br/>Mean Correlation between fake and real columns  0.9337<br/>1 - MAPE Estimator results                      0.3912<br/>Similarity Score                                0.6011<br/></span><span id="c616" class="kq ig hi km b fi kv ks l kt ku">{'1 - MAPE Estimator results': 0.3911924307763016,<br/> 'Basic statistics': 0.9364221364221365,<br/> 'Correlation column correlations': 0.1430372959033057,<br/> 'Mean Correlation between fake and real columns': 0.9336602090844196,<br/> 'Similarity Score': 0.6010780180465408}</span></pre><p id="7e05" class="pw-post-body-paragraph jd je hi jf b jg kc ji jj jk kd jm jn jo ke jq jr js kf ju jv jw kg jy jz ka hb bi translated">使用table_evaluator工具，我们还可以通过可视化绘图探索真实数据和合成数据，如下所示:</p><pre class="kh ki kj kk fd kl km kn ko aw kp bi"><span id="b936" class="kq ig hi km b fi kr ks l kt ku">table_evaluator.visual_evaluation()</span></pre><figure class="kh ki kj kk fd kx er es paragraph-image"><div class="er es la"><img src="../Images/08e147b53de2527b584fec4b558f6447.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/format:webp/1*b8jUcDc8H38EHbNGMf6BeA.png"/></div></figure><figure class="kh ki kj kk fd kx er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lb"><img src="../Images/81ef54dc4afc266a9660b786b0527f84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5rQyVYuyEf9V9Gv4PPeIrQ.png"/></div></div></figure><figure class="kh ki kj kk fd kx er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lg"><img src="../Images/9922f3e925cf49cf17e46805d38234ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*saWGinahcTfeQBCYnx22xQ.png"/></div></div></figure><figure class="kh ki kj kk fd kx er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lh"><img src="../Images/8f8f86b708492b52066ada52a0119a42.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u-su8J774BAH-uqDv_JuXQ.png"/></div></div></figure><h1 id="1b9c" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">摘要</h1><p id="effd" class="pw-post-body-paragraph jd je hi jf b jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka hb bi translated">从模型精度评估和table_evaluator评估可以得出结论，部分特征与真实数据非常接近。其他一些功能需要进一步训练。我们可以在模型训练和数据标准化方面进一步努力，以获得更好的结果。</p><h1 id="e9b7" class="if ig hi bd ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc bi translated">参考</h1><ol class=""><li id="dcb8" class="li lj hi jf b jg jh jk jl jo lk js ll jw lm ka ln lo lp lq bi translated"><a class="ae kb" href="https://arxiv.org/abs/1406.2661" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1406.2661</a></li><li id="b7aa" class="li lj hi jf b jg lr jk ls jo lt js lu jw lv ka ln lo lp lq bi translated"><a class="ae kb" href="https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/" rel="noopener ugc nofollow" target="_blank">https://machine learning mastery . com/how-to-develop-a-generative-adversarial-network-for-a-dimension-function-from-scratch-in-keras/</a></li></ol></div></div>    
</body>
</html>