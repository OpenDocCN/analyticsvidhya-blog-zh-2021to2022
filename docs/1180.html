<html>
<head>
<title>How to make a Sentiment Analysis for your favorite topics on Twitter</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在Twitter上为自己喜欢的话题做情感分析</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-make-a-sentiment-analysis-for-your-favorite-topics-on-twitter-ce6427f4d5b?source=collection_archive---------22-----------------------#2021-02-17">https://medium.com/analytics-vidhya/how-to-make-a-sentiment-analysis-for-your-favorite-topics-on-twitter-ce6427f4d5b?source=collection_archive---------22-----------------------#2021-02-17</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="b794" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在我的例子中，我将使用巴西最大的媒体节目——BBB或“老大哥巴西”,它目前已经是第21届了。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/dd6f29da31a1ca51360c2bac461f8240.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zis9S9_AOD294-teHQwFNA.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">巴西收视率最高的电视节目之一的20名参与者</figcaption></figure><p id="7faf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">受到其他教程的启发(在帖子的最后给它们命名)，我决定使用Python、Twitter的API tweepy和其他一些我在这个过程中需要的NLP库来制作自己的教程。</p><p id="1d14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我这样做是作为一个有趣的项目，其他人可能也想这样做，但请记住，这是一个简化的项目，使用预先训练的模型。</p></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="c02e" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">安装</h1><p id="a5e4" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">首先，我在我的机器上创建了一个新的虚拟环境。当你像我一样，试图同时做大量的事情时，虚拟环境有助于让事情井然有序</p><ul class=""><li id="f049" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated">在提示符下键入<em class="ll"> pipenv shell </em>来启动虚拟环境</li></ul><p id="14a6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">之后，我们将导入我们要使用的库:</p><ul class=""><li id="f389" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated">tweepy——Twitter的API</li><li id="7177" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">熊猫——使用数据框架</li><li id="aa3f" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">NLTK——自然语言工具包，NLP项目中使用的公共库</li><li id="aa1a" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">Sklearn — Sci-kit learning，用于机器学习项目</li><li id="0d05" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">re-正则表达式，用于清理文本</li></ul><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="7b3b" class="lw ka hh ls b fi lx ly l lz ma">import tweepy<br/>import pandas as pd<br/>from nltk import word_tokenize<br/>import nltk<br/>import re<br/>import pandas as pd<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.naive_bayes import MultinomialNB<br/>from sklearn import svm<br/>from sklearn import metrics<br/>from sklearn.model_selection import cross_val_predict<br/>from nltk.tokenize import TweetTokenizer</span></pre><p id="9196" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这是我们将要使用的所有库和导入。<strong class="ig hi">您可能需要在您的虚拟环境中安装这些库，因此您需要<em class="ll"> pipenv安装“库”</em>T5】</strong></p><p id="ea21" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了使用他们的API，你还需要创建一个Twitter开发者账户。它非常快，您可以从这里开始:</p><div class="mb mc ez fb md me"><a href="https://developer.twitter.com/en/apply-for-access" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">申请访问——Twitter开发者</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">申请准入。Twitter APIs和工具入门。所有新开发人员必须申请一个开发人员帐户…</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">developer.twitter.com</p></div></div><div class="mn l"><div class="mo l mp mq mr mn ms jm me"/></div></div></a></div><p id="8d59" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我在申请访问权限时遇到了一些奇怪的问题，比如页面不允许我填写表格，但在解决这些问题后，事情就变得非常简单了。通过这样做，你将从Twitter的开发API中获得4样东西:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mt"><img src="../Images/9c2cb397c732b60b3ae3168391d61d67.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*vLIov5QqT-0VzkGikRcg8g.png"/></div></figure><ul class=""><li id="1ba6" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated">消费者_密钥</li><li id="0b50" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">消费者_秘密</li><li id="4d85" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">访问令牌</li><li id="8630" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">访问令牌密码</li></ul><p id="16de" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请记住，你不应该显示这个，因为它们是你进入Twitter API的个人密码。</p></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="78e7" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">获取推文</h1><p id="74f0" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">完成所有设置后，我们将开始从Twitter获取推文。</p><p id="512a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">首先设置密钥和tweepy的身份验证:</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="e1c3" class="lw ka hh ls b fi lx ly l lz ma">consumer_key= 'insert key here'<br/>consumer_secret= 'insert key here'<br/>access_token='insert key here'<br/>access_token_secret='insert key here'<br/>auth = tweepy.OAuthHandler(consumer_key, consumer_secret)<br/>auth.set_access_token(access_token, access_token_secret)<br/>api = tweepy.API(auth, wait_on_rate_limit=True)</span></pre><p id="61a6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我要设置三个空列表来包含我们的数据。在这种情况下，我决定搜索包含参与者姓名、推文文本和创建日期的特定推文。</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="6c47" class="lw ka hh ls b fi lx ly l lz ma">tweet_pessoa, tweet_text, tweet_date = ([],[],[])<br/>lista = ["#Karol", "#Fiuk", "#Juliette"]</span></pre><p id="8848" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，下面的代码将遍历列表中的每个参与者，对于每个参与者，它将使用tweepy的api搜索，并将名称作为搜索参数。我还补充道:</p><ul class=""><li id="26f2" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated"><em class="ll">既然=那么我可以选择开始日期</em></li><li id="2411" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">lang =所以它专注于葡萄牙语推文</li><li id="6fa7" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">tweet_mode = extended带给我完整的推文</li><li id="8072" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">。items(500) =每位参与者的最大推文数。您可以添加更多，但这会增加处理时间</li></ul><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="9462" class="lw ka hh ls b fi lx ly l lz ma">for participante in lista:</span><span id="5b3e" class="lw ka hh ls b fi mu ly l lz ma">    for tweet in tweepy.Cursor(api.search , q=participante, since='2021–02–01',lang="pt", tweet_mode="extended").items(500):</span><span id="3d4d" class="lw ka hh ls b fi mu ly l lz ma">        if tweet is not None:<br/>            tweet_pessoa.append(participante)<br/>            tweet_text.append(tweet.full_text)<br/>            tweet_date.append(tweet.created_at)</span></pre><p id="114f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在此之后，我们将获得三个列表<em class="ll"> tweet_pessoa、tweet_text和tweet_date </em>，将它们保存到一个dataframe中并删除重复的值。</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="7497" class="lw ka hh ls b fi lx ly l lz ma">df = pd.DataFrame(zip(tweet_date,tweet_pessoa, tweet_text))<br/>df.columns =[‘Data’,’Tag’,’Tweet’]<br/>df.drop_duplicates(['Tweet'], inplace=True)</span></pre><p id="96f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">运行这个程序后，我们得到了这个结果:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mv"><img src="../Images/2451a3f5ae6ca34cc04ea8b72042b1d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PE9AEY3M_vNz0698d08cPg.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">我对每个搜索查询测试了100个项目，因为这样加载更快</figcaption></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="4057" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">清理文本并导入模型</h1><p id="6776" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">正如我之前所说，我们将导入一个数据库，其中包含推文及其分类，如正面、负面或中性。</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="8813" class="lw ka hh ls b fi lx ly l lz ma">dataset = pd.read_csv('Tweets_Mg.csv', encoding='utf-8')<br/>tweets = dataset["Text"].values<br/>classes = dataset["Classificacao"].values</span><span id="6e7f" class="lw ka hh ls b fi mu ly l lz ma">#here we're setting our scraped tweets<br/>testes = df["Tweet"].values</span></pre><p id="cb24" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了清理文本，我将使用这个函数来清理推文中常见的<em class="ll"> @、# </em>和<em class="ll"> https </em>等内容。我们还将使用nltk的词干分析器。关于词干的更多信息可以在这里找到。</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="0ed0" class="lw ka hh ls b fi lx ly l lz ma">def Preprocessing(instancia):<br/>    stemmer = nltk.stem.RSLPStemmer()<br/>    instancia = re.sub(r"http\S+", "", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','').replace('rt','')<br/>    instancia = re.sub(r"#(\w+)", ' ', instancia, flags=re.MULTILINE)<br/>    instancia = re.sub(r"@(\w+)", ' ', instancia, flags=re.MULTILINE)<br/>    stopwords = set(nltk.corpus.stopwords.words('portuguese'))<br/>    palavras = [stemmer.stem(i) for i in instancia.split() if not i in stopwords]<br/>    return (" ".join(palavras))</span></pre><p id="b59e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">清理测试数据库和我们收集的tweets:</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="c750" class="lw ka hh ls b fi lx ly l lz ma">tweets = [Preprocessing(i) for i in tweets]</span><span id="5bfb" class="lw ka hh ls b fi mu ly l lz ma">testes = [Preprocessing(i) for i in testes]</span></pre><p id="1cc3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一部分将首先创建一个<a class="ae mw" rel="noopener" href="/@paritosh_30025/natural-language-processing-text-data-vectorization-af2520529cf7">矢量器，</a>然后将其应用于我们之前的tweets数据库(不是我们搜集的，而是我们导入的)，并使用<a class="ae mw" href="https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html" rel="noopener ugc nofollow" target="_blank">朴素贝叶斯作为我们的模型</a>，我们<em class="ll">训练</em>它。</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="03a4" class="lw ka hh ls b fi lx ly l lz ma">vectorizer = CountVectorizer(ngram_range = (1, 2))<br/>freq_tweets = vectorizer.fit_transform(tweets)<br/>modelo = MultinomialNB()<br/>modelo.fit(freq_tweets, classes)</span></pre><p id="dcd5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以在这之后，我们可以对我们抓取的tweets做同样的程序，但不是。适合，我们用。预测</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="0b18" class="lw ka hh ls b fi lx ly l lz ma">freq_testes = vectorizer.transform(testes)<br/>df["Classificacao"] = modelo.predict(freq_testes)</span></pre><p id="36fa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，如果您愿意，可以将生成的数据帧导出到excel文件中。</p><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="1b0c" class="lw ka hh ls b fi lx ly l lz ma">df.to_excel("output_tweets.xlsx", index=True)</span></pre><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es mx"><img src="../Images/7ec035c7674189303933cba7ab0fe895.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3POafb-motogn7Usc4qI_A.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">结果推文分类</figcaption></figure></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="cde5" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">完整代码</h1><pre class="jd je jf jg fd lr ls lt lu aw lv bi"><span id="8ea8" class="lw ka hh ls b fi lx ly l lz ma">import tweepy<br/>import pandas as pd<br/>from nltk import word_tokenize<br/>import nltk<br/>import re<br/>import pandas as pd<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>from sklearn.naive_bayes import MultinomialNB<br/>from sklearn import svm<br/>from sklearn import metrics<br/>from sklearn.model_selection import cross_val_predict<br/>from nltk.tokenize import TweetTokenizer</span><span id="c018" class="lw ka hh ls b fi mu ly l lz ma">consumer_key= 'insert key here'<br/>consumer_secret= 'insert key here'<br/>access_token='insert key here'<br/>access_token_secret='insert key here'<br/>auth = tweepy.OAuthHandler(consumer_key, consumer_secret)<br/>auth.set_access_token(access_token, access_token_secret)<br/>api = tweepy.API(auth, wait_on_rate_limit=True)</span><span id="63c9" class="lw ka hh ls b fi mu ly l lz ma">def Preprocessing(instancia):<br/>    stemmer = nltk.stem.RSLPStemmer()<br/>    instancia = re.sub(r"http\S+", "", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','').replace('rt','')<br/>    instancia = re.sub(r"#(\w+)", ' ', instancia, flags=re.MULTILINE)<br/>    instancia = re.sub(r"@(\w+)", ' ', instancia, flags=re.MULTILINE)<br/>    stopwords = set(nltk.corpus.stopwords.words('portuguese'))<br/>    palavras = [stemmer.stem(i) for i in instancia.split() if not i in stopwords]<br/>    return (" ".join(palavras))</span><span id="26d4" class="lw ka hh ls b fi mu ly l lz ma">tweet_pessoa, tweet_text, tweet_date = ([],[],[])<br/>lista = ["#Karol", "#Fiuk", "#Juliette"]</span><span id="bfb8" class="lw ka hh ls b fi mu ly l lz ma">for participante in lista:</span><span id="7575" class="lw ka hh ls b fi mu ly l lz ma">    for tweet in tweepy.Cursor(api.search , q=participante, since='2021–02–01',lang="pt", tweet_mode="extended").items(500):</span><span id="bf86" class="lw ka hh ls b fi mu ly l lz ma">        if tweet is not None:<br/>            tweet_pessoa.append(participante)<br/>            tweet_text.append(tweet.full_text)<br/>            tweet_date.append(tweet.created_at)</span><span id="d1a2" class="lw ka hh ls b fi mu ly l lz ma">df = pd.DataFrame(zip(tweet_date,tweet_pessoa, tweet_text))<br/>df.columns =[‘Data’,’Tag’,’Tweet’]<br/>df.drop_duplicates(['Tweet'], inplace=True)</span><span id="ba4d" class="lw ka hh ls b fi mu ly l lz ma">dataset = pd.read_csv('Tweets_Mg.csv', encoding='utf-8')<br/>tweets = dataset["Text"].values<br/>classes = dataset["Classificacao"].values</span><span id="f2c7" class="lw ka hh ls b fi mu ly l lz ma">#here we're setting our scraped tweets<br/>testes = df["Tweet"].values</span><span id="174b" class="lw ka hh ls b fi mu ly l lz ma">tweets = [Preprocessing(i) for i in tweets]</span><span id="bbe7" class="lw ka hh ls b fi mu ly l lz ma">testes = [Preprocessing(i) for i in testes]</span><span id="3886" class="lw ka hh ls b fi mu ly l lz ma">vectorizer = CountVectorizer(ngram_range = (1, 2))<br/>freq_tweets = vectorizer.fit_transform(tweets)<br/>modelo = MultinomialNB()<br/>modelo.fit(freq_tweets, classes)</span><span id="01d2" class="lw ka hh ls b fi mu ly l lz ma">freq_testes = vectorizer.transform(testes)<br/>df["Classificacao"] = modelo.predict(freq_testes)</span><span id="673d" class="lw ka hh ls b fi mu ly l lz ma">df.to_excel("output_tweets.xlsx", index=True)</span></pre></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="539a" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">要考虑的事项和来源</h1><p id="a66e" class="pw-post-body-paragraph ie if hh ig b ih kx ij ik il ky in io ip kz ir is it la iv iw ix lb iz ja jb ha bi translated">如果你仔细看看结果，大多数推文被标记为中性，你会发现推文被错误地分类。这意味着我们需要重新训练我们的模型来改进它。但是像这样做情感分析有几个问题:</p><ul class=""><li id="877e" class="lc ld hh ig b ih ii il im ip le it lf ix lg jb lh li lj lk bi translated">我们使用葡萄牙语，大部分关于情感分析的数据都是英文的</li><li id="4a01" class="lc ld hh ig b ih lm il ln ip lo it lp ix lq jb lh li lj lk bi translated">推文本身已经很具体了，那些关于“BBB”的甚至更复杂。电视节目有自己的语言，像“天使”和“xepa”这样的词在游戏中有自己的意思。</li></ul><p id="5401" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">提高准确性的一种方法是翻译推文，然后应用模型。另一种方法是创建你自己的正确分类的推文数据库，然后用它来分类其他推文。</p><p id="1887" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但请记住，这是作为一个学习项目，因为这是我第一次涉足这样的东西。</p><p id="fd24" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">以下是我用来建立这个的来源:</p><div class="mb mc ez fb md me"><a href="https://github.com/minerandodados/mdrepo/blob/master/Classifica%C3%A7%C3%A3o_tweets.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">minerandodos/MD repo</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">博客和博客笔记的资料库。-minerandodos/MD repo</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">github.com</p></div></div><div class="mn l"><div class="my l mp mq mr mn ms jm me"/></div></div></a></div><div class="mb mc ez fb md me"><a href="https://www.kaggle.com/leandrodoze/sentiment-analysis-in-portuguese" rel="noopener  ugc nofollow" target="_blank"><div class="mf ab dw"><div class="mg ab mh cl cj mi"><h2 class="bd hi fi z dy mj ea eb mk ed ef hg bi translated">葡萄牙语情感分析</h2><div class="ml l"><h3 class="bd b fi z dy mj ea eb mk ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用来自MG/BR的推文数据</h3></div><div class="mm l"><p class="bd b fp z dy mj ea eb mk ed ef dx translated">www.kaggle.com</p></div></div><div class="mn l"><div class="mz l mp mq mr mn ms jm me"/></div></div></a></div><p id="6bcf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在搜索这个主题的时候出现了大量的网站。</p></div></div>    
</body>
</html>