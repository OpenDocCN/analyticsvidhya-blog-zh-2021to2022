<html>
<head>
<title>Tips and Tricks for advancing Tensorflow API: Subclassing, Data processing, Extensions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">提升Tensorflow API的技巧和诀窍:子类化、数据处理、扩展</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/using-advanced-tensorflow-api-for-training-nns-subclassing-data-processing-extensions-a56a784f4084?source=collection_archive---------3-----------------------#2021-07-17">https://medium.com/analytics-vidhya/using-advanced-tensorflow-api-for-training-nns-subclassing-data-processing-extensions-a56a784f4084?source=collection_archive---------3-----------------------#2021-07-17</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/336b22facb7c6da7342f10dc9c70ba44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SgO-uWRrIazDDyIN"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">照片由<a class="ae iu" href="https://unsplash.com/@thoutbox?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">李勇云</a>在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</figcaption></figure><h2 id="f7d3" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">张量流</h2><p id="258d" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">TensorFlow框架为端到端的机器学习管道提供了许多有用的类和功能。从读取数据到训练逻辑，所提供功能的大多数方面都是高度可定制的。我们将探索Tensorflow的许多功能，以实现复杂的深度学习算法或加速深度学习应用程序的开发进程，重点是图像数据和CNN。</p><p id="c909" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">这篇文章不是对某些主题的深入解释，而是对低级的TF和有用的TF类的一般性介绍，同时我将链接参考文档和有用的资源以获得进一步的信息和例子。我的目标是在开发机器学习项目时，使用TensorFlow为<em class="kt"> </em>介绍<em class="kt">我的技术</em>。欢迎通过评论讨论利用TensorFlow训练模型的更好方法。</p><p id="f710" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">在本帖中，我们将讨论张量流的各个方面:</p><ul class=""><li id="b9f4" class="ku kv hi jv b jw ko ka kp jg kw jk kx jo ky kn kz la lb lc bi translated">tf.data .数据集</li><li id="e406" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">预处理数据</li><li id="a171" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">数据扩充(ImageDataGenerator，tf.keras.preprocessing.image)</li><li id="08af" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">张量流数据集</li><li id="2741" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">自定义训练循环</li><li id="8da3" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">覆盖tf.keras.Model，TensorFlow对象的子类化</li><li id="5e39" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">Tensorboard日志记录、检查点、保存/加载模型</li><li id="d552" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">TensorFlow扩展(tf_a、tfg等)</li></ul><h2 id="689d" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">tf.data.Dataset对象<a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank">【文档】</a></h2><blockquote class="li lj lk"><p id="7183" class="jt ju kt jv b jw ko jy jz ka kp kc kd ll kq kf kg lm kr ki kj ln ks kl km kn hb bi translated">表示一个潜在的大型元素集。</p></blockquote><p id="7a25" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">tf.data.Dataset是TensorFlow提供的用于实现输入管道的API。加载、预处理、扩充和迭代数据的过程属于API的范围。整个程序设计用于操作一个<code class="du lo lp lq lr b">tf.data.Dataset</code>对象。</p><p id="639c" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">我们可以简单地通过映射一个列表来创建<code class="du lo lp lq lr b">tf.data.Dataset</code>对象，如下面的代码片段所示。在第一个例子中，我们可以简单地使用for循环按顺序遍历数据集。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="d4ac" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">数据集也有非常方便的方法，比如第二个例子中描述的<code class="du lo lp lq lr b">shuffle</code>和<code class="du lo lp lq lr b">batch</code>操作。这些操作实际上会打乱数据集，并从数据集生成批次。<code class="du lo lp lq lr b">repeat(n)</code>操作将数据集重复n次，而当n未定义时，数据集将无限重复。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="2f82" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">有时数据集可以被定义为更复杂的结构。一种常见的数据形式是一对(图像、标签)中的数据。这样的数据可以使用上面例子中的字典来定义。我们还可以看到图像和标签在混洗操作后被分组。</p><p id="ab4c" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">我们还可以用3+组件构建数据集，或者使用其他函数来代替<code class="du lo lp lq lr b">tf.data.Dataset.from_tensor_slices</code>，这将在文档中进一步描述。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="2dd2" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">最后一个方法<code class="du lo lp lq lr b">tf.data.Dataset</code>是<code class="du lo lp lq lr b">dataset.map(map_f)</code>方法，它对数据集中的所有元素分别应用某种<code class="du lo lp lq lr b">map_f</code>方法。在上面的例子中，应用了<code class="du lo lp lq lr b">example_map</code>函数给所有的标签值加5。</p><h1 id="0728" class="ly iw hi bd ix lz ma mb jb mc md me jf mf mg mh jj mi mj mk jn ml mm mn jr mo bi translated">读取数据</h1><p id="a66f" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">每个机器学习应用的第一部分是读取数据。你可以简单地使用其他库(例如NumPy、PIL、OpenCV……)读取数据，并将它们存储在NumPy数组(或者简单数组)中。在一个变量中实际读取和存储<em class="kt">所有数据</em>的一个缺点是，它消耗了太多的RAM，对于一个大型数据集来说是不可行的。</p><p id="c838" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">TensorFlow提供了读取数据的动态方法，这可以表示为定义一个函数，在运行时动态读取和存储一批数据，而不是直接存储数据。因为训练是基于输入管道的输出完成的，所以该函数还必须包含预处理和扩充步骤的定义。使用多重处理可以加速这一过程。</p><p id="7c74" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">TF提供了大多数一般情况下的步骤，同时它们也可以完全定制。TF中读取数据的两个关键功能是使用all-in-one pipeline(如<code class="du lo lp lq lr b">image_dataset_from_directory</code>)和直接定义一个函数来创建一个<code class="du lo lp lq lr b">tf.data.Dataset</code>对象，这更具可定制性。</p><h2 id="2c20" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">image _ dataset _ from _ directory<a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory" rel="noopener ugc nofollow" target="_blank">【文档】</a> <a class="ae iu" href="https://keras.io/api/preprocessing/" rel="noopener ugc nofollow" target="_blank">【教程】</a></h2><blockquote class="li lj lk"><p id="0680" class="jt ju kt jv b jw ko jy jz ka kp kc kd ll kq kf kg lm kr ki kj ln ks kl km kn hb bi translated">从目录中的图像文件生成一个<code class="du lo lp lq lr b"><a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset" rel="noopener ugc nofollow" target="_blank">tf.data.Dataset</a></code>。</p></blockquote><p id="f4b6" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">image_dataset_from_directory是一个方便的函数，用于读取特定目录结构中的数据。例如，以下结构的数据在ImageNet等图像数据集中很常见，我们可以使用以下代码读取。我们还可以针对不同类型的数据对应用程序进行细微的修改，并通过调整参数来添加一些基本的预处理。</p><pre class="ls lt lu lv fd mp lr mq mr aw ms bi"><span id="abea" class="iv iw hi lr b fi mt mu l mv mw">training_data/<br/>...class_a/<br/>......a_image_1.jpg<br/>......a_image_2.jpg<br/>...class_b/<br/>......b_image_1.jpg<br/>......b_image_2.jpg</span></pre><p id="5da1" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">代码:</p><pre class="ls lt lu lv fd mp lr mq mr aw ms bi"><span id="2368" class="iv iw hi lr b fi mt mu l mv mw">train_ds = image_dataset_from_directory(<br/>    directory='training_data/',<br/>    labels='inferred',<br/>    label_mode='categorical',<br/>    batch_size=32,<br/>    image_size=(256, 256))</span></pre><h2 id="6619" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">自定义函数+ dataset.map <a class="ae iu" href="https://www.tensorflow.org/tutorials/generative/pix2pix" rel="noopener ugc nofollow" target="_blank">【示例】</a></h2><p id="fc02" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">由于我在Pix2Pix Tensorflow教程中发现了这个从目录中读取图像的自定义实现片段，所以我个人主要使用这个自定义实现来读取数据。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="ffee" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">上面的代码片段映射了一个tf。数据。通过<code class="du lo lp lq lr b">read_image</code>函数的路径数据集，该函数以张量流图形模式读取图像。这种方法的一个优点是，它在目录结构和数据格式方面是非常可定制的，因为当使用image_dataset_from_directory时，我经常努力集成不同形式的标签。</p><p id="6389" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">当我们定义像<code class="du lo lp lq lr b">train_dataset</code>这样的变量时，Tensorflow并不总是<em class="kt">实际上</em>读取并存储变量中的所有数据。相反，在train_dataset中创建了一个映射函数(Tensorflow graph ),每当我们使用迭代器访问数据集的值时，就会执行映射并读取数据。因为变量<em class="kt">是虚拟的</em>，我们不能简单的打印出值或者索引<code class="du lo lp lq lr b">train_dataset</code>比如<code class="du lo lp lq lr b">print(train_dataset) or train_dataset[2]</code>。</p><h1 id="ede5" class="ly iw hi bd ix lz ma mb jb mc md me jf mf mg mh jj mi mj mk jn ml mm mn jr mo bi translated">数据扩充</h1><h2 id="83bb" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">ImageDataGenerator <a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank">【文档】</a> <a class="ae iu" href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" rel="noopener ugc nofollow" target="_blank">【教程】</a></h2><blockquote class="li lj lk"><p id="6010" class="jt ju kt jv b jw ko jy jz ka kp kc kd ll kq kf kg lm kr ki kj ln ks kl km kn hb bi translated">通过实时数据扩充生成批量张量图像数据。</p></blockquote><p id="b39d" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated"><code class="du lo lp lq lr b">ImageDataGenerator</code>提供了实现数据扩充的工具。要使用<code class="du lo lp lq lr b">ImageDataGenerator</code>进行数据增强，我们必须首先声明一个实例，该实例包含下面增强池中的增强设置。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="3c0e" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">使用两种方法对数据进行扩充。首先，当数据集已经被加载或定义为tf.data.Dataset变量时，我们可以使用<code class="du lo lp lq lr b">datagen.flow(x, y)</code>构建一个扩充的数据集，如下面的代码所示。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/keras/preprocessing/image/imagedata generator</a></figcaption></figure><p id="fe46" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">我们也可以使用<code class="du lo lp lq lr b">datagen.flow_from_dirctory(directory)</code>直接从文件中读取，如下面的代码所示。这种方法非常常用，因为它既简洁又相对适用于许多数据集。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/keras/preprocessing/image/imagedata generator</a>x</figcaption></figure><h2 id="1a85" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">使用tf.image定制增强<a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/image" rel="noopener ugc nofollow" target="_blank">【文档】</a></h2><p id="2d80" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">您可以使用<code class="du lo lp lq lr b">tf.image.random_*</code>中提供的功能执行自定义数据扩充，并定义一个tf图。这可以通过将扩充管道映射到数据集对象来应用于数据。</p><h2 id="a38e" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">tf.keras.layers.experimental .预处理<a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing" rel="noopener ugc nofollow" target="_blank">【文档】</a> <a class="ae iu" href="https://www.tensorflow.org/tutorials/images/data_augmentation" rel="noopener ugc nofollow" target="_blank">【教程】</a></h2><blockquote class="li lj lk"><p id="9fa0" class="jt ju kt jv b jw ko jy jz ka kp kc kd ll kq kf kg lm kr ki kj ln ks kl km kn hb bi translated">使用层接口将预处理集成到模型中。</p></blockquote><p id="3623" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">该模块在Keras层中提供数据扩充功能。因此，我们可以将增强过程表示为顺序模型，或者简单地将增强层添加到现有神经网络的开头。</p><figure class="ls lt lu lv fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es mx"><img src="../Images/d384fe2a8114add4f3b1be201a3454be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9Ptc14-kBmOai88hzbeviA.png"/></div></div></figure><p id="f3d6" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">例如，下面的代码将定义和执行数据扩充。这些层在测试时不做任何事情。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="176a" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">我个人认为这种将数据增强作为一个层引入的概念是惊人的。我们还可以使用子类化将自定义数据扩充(如mixup、cut mix)定义为自定义层，这将在下面介绍。</p><h2 id="c8d0" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">TFDS(张量流数据集)<a class="ae iu" href="https://www.tensorflow.org/datasets/catalog/overview" rel="noopener ugc nofollow" target="_blank">【目录】</a></h2><p id="390a" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">TensorFlow提供的最后一个方便的功能是<code class="du lo lp lq lr b">tensorflow_datasets</code>，或<code class="du lo lp lq lr b">tfds</code>库，它提供了可能最简单的方式来下载和阅读大约300个不同格式的主要数据集。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="fda0" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">使用上面的<em class="kt">单行代码</em>，可以下载TFDS数据集并将其读入tf.data.Dataset对象。要使用TFDS下载数据集，您可以简单地找到数据集的键，这是TFDS目录中的确切名称，并调用<code class="du lo lp lq lr b">tfds.load(key)</code>。每个数据集的结构在解释页面上单独描述。</p><h1 id="0c8e" class="ly iw hi bd ix lz ma mb jb mc md me jf mf mg mh jj mi mj mk jn ml mm mn jr mo bi translated">自定义训练循环</h1><p id="6fbf" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">你们很多人可能已经习惯的Keras &amp; TF2.0风格的编程很可能利用了高级API，比如<code class="du lo lp lq lr b">model.compile</code>和<code class="du lo lp lq lr b">model.fit</code>。虽然默认的训练程序在一定程度上是高度可定制的，但一些任务，如GANs，需要更复杂和定制的训练循环。</p><p id="1da1" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">在这种情况下，我们可以手动实现一个训练步骤的过程，并在数据迭代器之后重复该步骤。下面的代码片段实现了网络的一般训练步骤。第2行的<code class="du lo lp lq lr b">tf.GradientTape</code>声明了一个变量<code class="du lo lp lq lr b">tape</code>，该变量在其作用域内执行自动微分。第3行和第4行实现了推理过程，并映射了损耗值和网络参数之间的关系。在第5行中，<code class="du lo lp lq lr b">tape</code>变量执行自动微分并返回网络权重的梯度。最后，第6行通过优化器应用计算出的梯度。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="882b" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">上面的代码是定制培训步骤的基础。对于默认的CNN和简单的网络来说，这可能是不必要的，但对于构建复杂的训练程序来说，这是TensorFlow的一个关键API。</p><p id="c4aa" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">在TensorFlow中实现DCGAN的官方TF <a class="ae iu" href="https://www.tensorflow.org/tutorials/generative/dcgan" rel="noopener ugc nofollow" target="_blank">教程</a>也在更复杂的环境中很好地解释了这个概念。</p><h1 id="0719" class="ly iw hi bd ix lz ma mb jb mc md me jf mf mg mh jj mi mj mk jn ml mm mn jr mo bi translated">TF类的子类化</h1><p id="8cf5" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">根据Tensorflow的说法，<code class="du lo lp lq lr b">tf.Module</code>类是其实现的最基本模块。所有层的基底<code class="du lo lp lq lr b">tf.keras.layers.Layer</code>继承自<code class="du lo lp lq lr b">tf.Module</code>，而所有模型的基底<code class="du lo lp lq lr b">tf.keras.Model</code>继承自<code class="du lo lp lq lr b">tf.keras.layers.Layer</code>。</p><p id="ef79" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">就像Keras中的每一层是如何定义的一样，比如<code class="du lo lp lq lr b">Conv2D</code>、<code class="du lo lp lq lr b">MaxPooling2D</code>，我们可以覆盖layer类来创建一个自定义层。我们还可以对基本模型接口进行子类化，并覆盖自定义训练循环的默认方法。</p><h2 id="4e1d" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">自定义图层:tf.keras.layers.Layer <a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer" rel="noopener ugc nofollow" target="_blank">【文档】</a></h2><blockquote class="li lj lk"><p id="f097" class="jt ju kt jv b jw ko jy jz ka kp kc kd ll kq kf kg lm kr ki kj ln ks kl km kn hb bi translated">这是所有层继承的类。</p></blockquote><p id="aeaa" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">一般来说，为了构建一个自定义层，我们子类化<code class="du lo lp lq lr b">tf.keras.layers.Layer </code>并覆盖默认方法来进行操作和初始化权重。</p><p id="283a" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">一些重要的覆盖方法有:</p><ul class=""><li id="fb82" class="ku kv hi jv b jw ko ka kp jg kw jk kx jo ky kn kz la lb lc bi translated">__init__(self):初始化层设置。</li><li id="78f1" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">build(self，input_shape):使用<code class="du lo lp lq lr b">add_weights()</code>或<code class="du lo lp lq lr b">tf.Variable</code>初始化权重。</li><li id="c967" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">call(self，inputs，*args，**kwargs):网络的实际正向传递逻辑。</li></ul><p id="48c3" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">与前一层的输入尺寸信息一起调用<code class="du lo lp lq lr b">build</code>方法。权重初始化通常在这种方法中实现。<code class="du lo lp lq lr b">__init__</code>方法，初始化图层时调用Python构造函数。在<code class="du lo lp lq lr b">call</code>方法中，必须使用TF图函数实现实际的正向传递。<code class="du lo lp lq lr b">call</code>方法接收输入数据和一些参数，比如<code class="du lo lp lq lr b">trainable</code>，它告诉我们它是当前正在训练还是仅仅在执行推理。</p><p id="ebe4" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">在Python保留方法<code class="du lo lp lq lr b">__call__</code>处调用<code class="du lo lp lq lr b">tf.keras.layers.Layer</code>的<code class="du lo lp lq lr b">call</code>方法，该方法在实例作为函数被调用时执行。这就是为什么像<code class="du lo lp lq lr b">layer(data) or model(data)</code>这样的代码把层实例当作一个函数来处理。</p><p id="6e1b" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">更多的方法可以被覆盖，在文档中有进一步的描述。</p><h2 id="5515" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">更多自定义:tf.keras.Model <a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="noopener ugc nofollow" target="_blank">【文档】</a> <a class="ae iu" href="https://keras.io/examples/generative/dcgan_overriding_train_step/" rel="noopener ugc nofollow" target="_blank">【教程】</a></h2><p id="6a61" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">模型类是<code class="du lo lp lq lr b">tf.keras.Model</code>的一个表示，实际上是从层类中派生出来的，因此包含了一个类似于层类方法的接口。然而，每种方法的一般用法会因实现层的不同而略有不同。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="a853" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">上面的简单模型就是定制模型的一个例子。在这种情况下，网络架构和权重在<code class="du lo lp lq lr b">__init__</code>中定义。<code class="du lo lp lq lr b">call</code>方法传达关于模型的完整推理过程的信息，类似于<code class="du lo lp lq lr b">tf.keras.layers.Layer</code>的方法。在<code class="du lo lp lq lr b">tf.keras.Model</code>中还有其他方法可以被覆盖。</p><p id="0ef1" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">基本上，当覆盖<code class="du lo lp lq lr b">tf.keras.Model</code>时，我们应用两个主要技术。一种是仅覆盖<code class="du lo lp lq lr b">call</code>，如上面的示例代码所示。通过这种方式，我们可以定制正向传递，同时保留所有其他内容，包括编译过程和训练循环。</p><p id="d4de" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">我们还可以使用<code class="du lo lp lq lr b">model.fit</code>来训练模型，同时通过覆盖<code class="du lo lp lq lr b">train_step</code>方法来使用定制的训练循环。如教程(或下面的代码)所述，我们可以覆盖<code class="du lo lp lq lr b">compile</code>来为GAN训练定义2个优化器，然后覆盖<code class="du lo lp lq lr b">train_step</code>来实现一个定制的训练循环。我们也可以根据您的需要覆盖其他方法，如<code class="du lo lp lq lr b">predict</code>或<code class="du lo lp lq lr b">test_step</code>。基本上，文档中列出的每个公共方法都可以被覆盖。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><h1 id="48cf" class="ly iw hi bd ix lz ma mb jb mc md me jf mf mg mh jj mi mj mk jn ml mm mn jr mo bi translated">保存模型</h1><p id="cc6c" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">保存模型:<code class="du lo lp lq lr b">model.save(directory)</code></p><p id="94cf" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">负载型号:<code class="du lo lp lq lr b">tf.keras.models.load_model(directory)</code></p><p id="3b56" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">在TensorFlow中保存和加载模型只需要一行代码。有一点需要注意的是<code class="du lo lp lq lr b">model.save</code>和<code class="du lo lp lq lr b">model.save_weights</code>的区别。第二种情况只保存权重，不记录模型结构。要加载权重文件，我们必须首先在<code class="du lo lp lq lr b">model</code>中定义一个模型架构，并调用<code class="du lo lp lq lr b">model.load_weights(directory)</code>。</p><h2 id="f6b1" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">检查点<a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint" rel="noopener ugc nofollow" target="_blank">【文档】</a></h2><p id="eaa8" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">TensorFlow的检查点功能提供了一种简单的方法来重新加载模型并继续训练。检查点API仅保存模型权重，因此在加载之前需要构建模型架构。</p><p id="b765" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">我们可以使用一个已定义的<code class="du lo lp lq lr b">tf.keras.callbacks.ModelChechpoint</code>回调。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div><figcaption class="iq ir et er es is it bd b be z dx translated"><a class="ae iu" href="https://www.tensorflow.org/tutorials/keras/save_and_load#save_checkpoints_during_training" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/tutorials/keras/save _ and _ load # save _ check points _ during _ training</a></figcaption></figure><p id="b6fe" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">或者我们可以手动定义一个<code class="du lo lp lq lr b">tf.train.Checkpoint</code>对象来保存和加载检查点。如下面的代码所述，我们可以使用<code class="du lo lp lq lr b">ckpt.restore</code>从检查点加载，使用<code class="du lo lp lq lr b">manager.save</code>保存。当我们使用显式训练循环而不是<code class="du lo lp lq lr b">model.fit</code>来训练模型时，经常使用这种手动保存。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><h2 id="bfc4" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">登陆冲浪板<a class="ae iu" href="https://www.tensorflow.org/tensorboard/scalars_and_keras" rel="noopener ugc nofollow" target="_blank">【教程】</a></h2><p id="9761" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">TensorBoard是一个可视化TF实验的API。一些特征包括图像/视频/音频的可视化、查看训练期间的损失/准确性、以及观察训练期间的体重量值直方图。结核病本身是一个非常大的主题，值得写一篇完整的文章。我们将讨论TB回调的实现以及如何实现手动日志记录。同时，你可以查看<a class="ae iu" href="https://www.tensorflow.org/tensorboard/get_started" rel="noopener ugc nofollow" target="_blank">官方教程</a>了解更多信息。</p><p id="54b5" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">使用<code class="du lo lp lq lr b"><a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard" rel="noopener ugc nofollow" target="_blank">tf.keras.callbacks.TensorBoard</a></code>:</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="68ea" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated"><code class="du lo lp lq lr b">tf.keras.callbacks.TensorBoard</code>提供了一个通用的日志管道，可以接收日志权重直方图、度量(损失/增加)、图形、嵌入可视化等参数。此回调将在每个时期结束时调用，以TensorBoard格式记录配置的数据。</p><p id="8460" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">使用<code class="du lo lp lq lr b">tf.summary.create_file_writer</code>自定义日志记录:</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><p id="127f" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">我们可以使用<code class="du lo lp lq lr b">tf.summary.&lt;type&gt;(path, data, step)</code>记录任何变量。我们还可以使用这种方法构建定制的TB日志回调。</p><h1 id="0c20" class="ly iw hi bd ix lz ma mb jb mc md me jf mf mg mh jj mi mj mk jn ml mm mn jr mo bi translated">扩展<a class="ae iu" href="https://www.tensorflow.org/resources/libraries-extensions" rel="noopener ugc nofollow" target="_blank">【目录】</a></h1><p id="ef67" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">最后，我们将回顾一些将增强TF体验的便利扩展。我建议查看以下库，它们在许多应用程序中非常有用。</p><h2 id="121b" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">TF集线器</h2><blockquote class="li lj lk"><p id="17e6" class="jt ju kt jv b jw ko jy jz ka kp kc kd ll kq kf kg lm kr ki kj ln ks kl km kn hb bi translated">TensorFlow Hub是一个经过训练的机器学习模型的存储库。</p></blockquote><p id="25d8" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">TF Hub提供对许多可用的预训练模型的访问<a class="ae iu" href="https://tfhub.dev/" rel="noopener ugc nofollow" target="_blank"> tfhub.de </a> v。每个模型都有不同的应用方式，如网站上所述。例如，根据<a class="ae iu" href="https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3" rel="noopener ugc nofollow" target="_blank">解释</a>，可以使用下面的代码来使用BERT模型。</p><figure class="ls lt lu lv fd ij"><div class="bz dy l di"><div class="lw lx l"/></div></figure><h2 id="6e94" class="iv iw hi bd ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js bi translated">TensorFlow插件<a class="ae iu" href="https://www.tensorflow.org/addons/api_docs/python/tfa" rel="noopener ugc nofollow" target="_blank">【文档】</a></h2><p id="9545" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">Tensorflow插件(或tfa)为TensorFlow提供了有用的额外功能。这些包括尖端层的实现、激活、优化、处理技术和损耗。该库更新相对较快(我在2021年6月找到了2021年4月的一篇论文的实现)。</p><p id="9311" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">tfa中提供了大多数主要DL技术的实现。</p><p id="468f" class="pw-post-body-paragraph jt ju hi jv b jw ko jy jz ka kp kc kd jg kq kf kg jk kr ki kj jo ks kl km kn hb bi translated">还有用于特殊目的的扩展库，例如:</p><ul class=""><li id="38a2" class="ku kv hi jv b jw ko ka kp jg kw jk kx jo ky kn kz la lb lc bi translated">TF Cloud:用于连接GCP(谷歌云平台)</li><li id="ed67" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">TF _ agents:RL著名代理的实现</li><li id="651f" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">tensorflow_probability:更多样的概率分布，更多的概率工具</li><li id="b354" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">tensorflow_text:自然语言处理库，文本处理</li><li id="b892" class="ku kv hi jv b jw ld ka le jg lf jk lg jo lh kn kz la lb lc bi translated">tensorflow_graphics: 3D数据处理，包括可微分相机、网格操作、图形层</li></ul><h1 id="91f9" class="ly iw hi bd ix lz ma mb jb mc md me jf mf mg mh jj mi mj mk jn ml mm mn jr mo bi translated">结论</h1><p id="6c7d" class="pw-post-body-paragraph jt ju hi jv b jw jx jy jz ka kb kc kd jg ke kf kg jk kh ki kj jo kk kl km kn hb bi translated">我们回顾了一些技术来增强我们的TensorFlow编程技能，并定制后台正在进行的一切。TensorFlow是一个很棒的库，有许多扩展和很好的可伸缩性，有一个活跃的社区。我希望你能够通过这篇文章中介绍的技术提高你在TensorFlow中构建DL系统的技能。</p></div></div>    
</body>
</html>