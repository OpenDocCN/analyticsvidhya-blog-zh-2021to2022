<html>
<head>
<title>Polynomial Regression in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中的多项式回归</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/polynomial-regression-in-python-4a7c60e8c902?source=collection_archive---------10-----------------------#2021-01-22">https://medium.com/analytics-vidhya/polynomial-regression-in-python-4a7c60e8c902?source=collection_archive---------10-----------------------#2021-01-22</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/158ac8db69ea4d858d35370f0ac5772e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*ZeheNdpbYX3yea2pK0Hadw.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">多项式回归</figcaption></figure><p id="d19c" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">当您的线性回归算法(穿过数据集的直线)无法拟合数据点时，那么使用<strong class="ir hi">多项式回归(PR) </strong>可能是理想的。</p><h2 id="df8a" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated">多项式回归:</h2><p id="f9ac" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">多项式回归是自变量(X)和因变量(y)之间的<strong class="ir hi">非线性</strong>关系，建模为X中的<em class="kn"> n </em>次多项式</p><blockquote class="ko kp kq"><p id="0bb7" class="ip iq kn ir b is it iu iv iw ix iy iz kr jb jc jd ks jf jg jh kt jj jk jl jm ha bi translated">问:如果它是非线性的，那么为什么它被称为多项式线性回归？</p><p id="2c4b" class="ip iq kn ir b is it iu iv iw ix iy iz kr jb jc jd ks jf jg jh kt jj jk jl jm ha bi translated">回答:是线性回归的形式。在每个线性回归方程中，为了找到因变量(y)的值，我们首先需要找到系数(b1，b2，…，bn)和截距(b0)的值。对于自变量(X)的任何值，系数和截距的值将保持不变。在多项式回归中，我们做同样的事情，这就是为什么它被称为多项式线性回归。</p></blockquote><figure class="kv kw kx ky fd ii er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es ku"><img src="../Images/59187cd23923f7b9de7278f7dcb62050.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rq1BcTJ1psI0SY0QrblvGg.jpeg"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">多项式线性回归方程</figcaption></figure><p id="663e" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">现在，是时候使用python编写多项式回归代码了，</p><p id="95d6" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated"><strong class="ir hi">最后我会给出代码的链接！！！</strong></p><h2 id="85de" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated">1.首先，我们必须导入将用于训练模型的库和数据集。</h2><p id="97a7" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">下载数据集的链接:<a class="ae ld" href="https://www.kaggle.com/jaspreet007bhatia/weather-history" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/jaspreet007bhatia/weather-history</a></p><figure class="kv kw kx ky fd ii er es paragraph-image"><div role="button" tabindex="0" class="kz la di lb bf lc"><div class="er es le"><img src="../Images/c850e6d70f6459d94ea63cee6f1b13c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ji9w80vFogsVhxGGTusqdw.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">天气历史数据</figcaption></figure><h2 id="792b" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated">2.现在我们需要清理我们的数据，</h2><ul class=""><li id="1ea6" class="lf lg hh ir b is ki iw kj ja lh je li ji lj jm lk ll lm ln bi translated">我们必须检查是否有丢失的值。</li><li id="9297" class="lf lg hh ir b is lo iw lp ja lq je lr ji ls jm lk ll lm ln bi translated">现在，我们将删除不必要的列，如“<strong class="ir hi">格式的日期</strong>列。</li><li id="f86b" class="lf lg hh ir b is lo iw lp ja lq je lr ji ls jm lk ll lm ln bi translated">之后，我们需要<strong class="ir hi">编码分类数据</strong>意味着，我们将把我们的字符串值转换成1和0。</li><li id="ba8f" class="lf lg hh ir b is lo iw lp ja lq je lr ji ls jm lk ll lm ln bi translated">最后，我们将数据集分成<strong class="ir hi">独立(X) </strong>和<strong class="ir hi">非独立(y) </strong>变量。</li></ul><h2 id="15e1" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated">3.是时候将数据集分成训练集和测试集了，</h2><p id="6be0" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">我们将数据集分为训练集和测试集，以避免数据差异的影响。我们将把大部分数据分成一个训练集和一小部分测试集。</p><h2 id="1537" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated">4.训练数据集，</h2><p id="2810" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">为了训练数据集，我们将使用scikit-learn库中的<strong class="ir hi">多项式特性</strong>和<strong class="ir hi">线性回归</strong>类。</p><ul class=""><li id="49ae" class="lf lg hh ir b is it iw ix ja lt je lu ji lv jm lk ll lm ln bi translated">使用<strong class="ir hi">多项式特性</strong>类，我们将定义多项式的次数。</li><li id="cd44" class="lf lg hh ir b is lo iw lp ja lq je lr ji ls jm lk ll lm ln bi translated">我们将使用<strong class="ir hi"> LinearRegression </strong>类来训练数据集。</li></ul><h2 id="6e68" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated">5.预测结果，</h2><p id="2e4b" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">使用predict()方法，我们将预测测试数据集的结果，或者我们也可以预测我们自己的结果。</p><h2 id="8161" class="jn jo hh bd jp jq jr js jt ju jv jw jx ja jy jz ka je kb kc kd ji ke kf kg kh bi translated">6.系数和拦截器，</h2><p id="c9cc" class="pw-post-body-paragraph ip iq hh ir b is ki iu iv iw kj iy iz ja kk jc jd je kl jg jh ji km jk jl jm ha bi translated">为了完成多项式回归方程，我们需要系数和截距的值。</p><p id="81b0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">代码链接:</p><blockquote class="ko kp kq"><p id="6e74" class="ip iq kn ir b is it iu iv iw ix iy iz kr jb jc jd ks jf jg jh kt jj jk jl jm ha bi translated">Kaggle笔记本代码链接:<a class="ae ld" href="https://www.kaggle.com/rahulkadam0909/polynomial" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/rahulkadam0909/polynomial</a></p><p id="387f" class="ip iq kn ir b is it iu iv iw ix iy iz kr jb jc jd ks jf jg jh kt jj jk jl jm ha bi translated">Github代码链接:<a class="ae ld" href="https://github.com/RAHUL-KAD/Machine-Learning/blob/main/Regrassion/Code/Polynomial_Regression.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/RAHUL-KAD/Machine-Learning/blob/main/Regrassion/Code/多项式_回归. ipynb </a></p></blockquote><blockquote class="lw"><p id="38cf" class="lx ly hh bd lz ma mb mc md me mf jm dx translated">编码快乐！！！</p></blockquote></div></div>    
</body>
</html>