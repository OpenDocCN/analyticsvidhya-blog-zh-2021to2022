<html>
<head>
<title>Web scraping: Google search results with Selenium and BeautifulSoup</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">网络抓取:带Selenium和BeautifulSoup的谷歌搜索结果</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scraping-google-search-results-with-selenium-and-beautifulsoup-4c534817ad88?source=collection_archive---------3-----------------------#2021-01-05">https://medium.com/analytics-vidhya/web-scraping-google-search-results-with-selenium-and-beautifulsoup-4c534817ad88?source=collection_archive---------3-----------------------#2021-01-05</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="94bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">越来越多的数据科学项目(不仅仅是)需要额外的数据，这些数据可以通过网络搜集的方式获得。谷歌搜索并不是一个不寻常的起点。</p><p id="9127" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在本指南中，我们将浏览从google搜索结果中获取链接的脚本。</p><p id="629b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从导入开始，为了从google搜索结果的前n页获得链接，我使用了selenium和BeautifulSoup。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="aab4" class="jm jn hi ji b fi jo jp l jq jr">from bs4 import BeautifulSoup<br/>from selenium import webdriver<br/>from webdriver_manager.chrome import ChromeDriverManager</span></pre><p id="ae09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我也在使用webdriver_manager包，它有时非常方便。使用这个包，没有必要下载一个web驱动到你的本地机器，如果你没有的话，它也有助于避免手动输入web驱动的自定义路径。该软件包支持大多数浏览器。</p><p id="2467" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，我们为web浏览器设置一些首选项。为了避免运行代码时浏览器弹出，我使用了“headless”参数。还有一些其他选项，允许定制网络浏览器，以适应手头的任务。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="d2bd" class="jm jn hi ji b fi jo jp l jq jr">chrome_options = webdriver.ChromeOptions()<br/>chrome_options.add_argument("--headless")</span></pre><p id="ccd1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在可以启动ChromeDriver了。第一个输入参数需要驱动程序的路径，但是通过webdriver_manager，我们可以使用installation来代替。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="1de2" class="jm jn hi ji b fi jo jp l jq jr">driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=chrome_options)</span></pre><p id="4a74" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦建立了web驱动程序，我们就可以进入代码的主要部分，在那里我们可以获得google搜索结果的web链接。</p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="2610" class="jm jn hi ji b fi jo jp l jq jr"># Query to obtain links<br/>query = 'comprehensive guide to web scraping in python'<br/>links = [] # Initiate empty list to capture final results</span><span id="fa26" class="jm jn hi ji b fi js jp l jq jr"># Specify number of pages on google search, each page contains 10 #links<br/>n_pages = 20 <br/>for page in range(1, n_pages):<br/>    url = "http://www.google.com/search?q=" + query + "&amp;start=" +      str((page - 1) * 10)<br/>    driver.get(url)<br/>    soup = BeautifulSoup(driver.page_source, 'html.parser')<br/>    # soup = BeautifulSoup(r.text, 'html.parser')<br/><br/>    search = soup.find_all('div', class_="yuRUbf")<br/>    for h in search:<br/>        links.append(h.a.get('href'))</span></pre><p id="71b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">该代码需要两个输入，感兴趣的查询和谷歌搜索的页数。每页包含10个搜索结果。</p><p id="fcc3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">一旦参数就绪，我们使用selenium webdriver加载url，然后使用BeautifulSoup，我们使用html.parser解析网站数据。网站数据以html格式出现，我们可以通过检查网页来查看网站背后的脚本。</p><figure class="jd je jf jg fd ju er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es jt"><img src="../Images/56c899db145fadb144bf33d1016cb33c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z8F33NV38RBHI8fss5PPJA.png"/></div></div></figure><p id="c880" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们对存储在<div class="’yuRUbf’">容器中的搜索结果的超链接感兴趣。使用BeautifulSoup命令找到所有元素。find_all()，其中我们指定元素和类作为输入。</div></p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="5f18" class="jm jn hi ji b fi jo jp l jq jr">search = soup.find_all('div', class_="yuRUbf")</span></pre><p id="feba" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于我们获得的每个搜索结果，我们需要提取超链接，并将其存储为<a>元素的href属性。</a></p><pre class="jd je jf jg fd jh ji jj jk aw jl bi"><span id="4d63" class="jm jn hi ji b fi jo jp l jq jr">for h in search:<br/>        links.append(h.a.get('href'))</span></pre><p id="9bec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们现在已经拥有了获取google搜索结果链接所需的所有代码块。</p><figure class="jd je jf jg fd ju er es paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="er es kb"><img src="../Images/3d7ce790529c58be183ad2276b63676f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bSigVRd2Hc69HkRtIeyibQ.png"/></div></div></figure></div></div>    
</body>
</html>