<html>
<head>
<title>Noise removal in images using deep learning models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习模型去除图像中的噪声</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/noise-removal-in-images-using-deep-learning-models-3972544372d2?source=collection_archive---------0-----------------------#2021-04-23">https://medium.com/analytics-vidhya/noise-removal-in-images-using-deep-learning-models-3972544372d2?source=collection_archive---------0-----------------------#2021-04-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ih ii ij ik er es paragraph-image"><div class="er es ig"><img src="../Images/7fd42964e712f32c0a648ee2aaf96ed1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/1*kKM8vTeM1zuKpPQ5H655jw.jpeg"/></div></figure><h1 id="6b00" class="in io hi bd ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk bi translated"><em class="if">目录:</em></h1><ol class=""><li id="8194" class="jl jm hi jn b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><strong class="jn hj">问题概述。</strong></li><li id="0402" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><strong class="jn hj">深度学习模型的使用。</strong></li><li id="d839" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><strong class="jn hj">资料收集和准备。</strong></li><li id="4d4c" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><strong class="jn hj">绩效指标。</strong></li><li id="9947" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><strong class="jn hj">先切进场。</strong></li><li id="3cb9" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><strong class="jn hj">试验不同的模型。</strong></li><li id="20d7" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><strong class="jn hj">模型量化。</strong></li><li id="c09d" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><strong class="jn hj">模型分析。</strong></li><li id="579c" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><strong class="jn hj">构建web应用程序。</strong></li><li id="c140" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><strong class="jn hj">未来的工作。</strong></li><li id="6b4c" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><strong class="jn hj">参考文献。</strong></li></ol></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="88f7" class="in io hi bd ip iq kp is it iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk bi translated">1.问题概述</h1><p id="0243" class="pw-post-body-paragraph ku kv hi jn b jo jp kw kx jq jr ky kz js la lb lc ju ld le lf jw lg lh li jy hb bi translated">图像去噪是从图像中去除噪声的过程。噪声的增加会造成信息的丢失。噪声可以由多种方式产生，例如在弱光环境下拍摄图像时，由于热量、数码相机的传感器照明水平或由于硬件中的错误存储位置或长距离数据传输中的位错误而导致的电路损坏。</p><p id="58fb" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated"><strong class="jn hj">什么是噪音？</strong></p><p id="0b2a" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">额外的不必要的像素值被添加到图像中，导致信息丢失。噪音可以是各种类型的，比如-</p><p id="9162" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">像素值与周围像素值完全不同的脉冲噪声(IN)。脉冲噪声有两种类型，即椒盐脉冲噪声(SPIN)和随机值脉冲噪声(RVIN)。</p><p id="a35d" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">加性高斯白噪声(AWGN)，图像中的每个像素都会从其原始值发生少量变化。</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="ae90" class="in io hi bd ip iq kp is it iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk bi translated"><strong class="ak">2<em class="if">2。深度学习模型的使用</em> </strong></h1><p id="dc81" class="pw-post-body-paragraph ku kv hi jn b jo jp kw kx jq jr ky kz js la lb lc ju ld le lf jw lg lh li jy hb bi translated">在获取原始图像对于稳健性能非常重要的情况下，或者在填充缺失信息非常有用的情况下，例如从非常远的物体拍摄的天文图像，从降级图像中去除噪声并恢复原始图像是非常重要的。</p><p id="0c58" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">卷积神经网络适用于图像。我们尝试了一些研究论文中提到的多个深度神经网络架构，并比较了每个模型的结果。</p><h1 id="7b0f" class="in io hi bd ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk bi translated"><strong class="ak"> <em class="if"> 3。数据收集和准备</em>和</strong></h1><p id="7a35" class="pw-post-body-paragraph ku kv hi jn b jo jp kw kx jq jr ky kz js la lb lc ju ld le lf jw lg lh li jy hb bi translated">我们将使用公开可用的图像，并根据我们的要求进行修改。</p><p id="f894" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">数据来源:<a class="ae lo" href="https://github.com/BIDS/BSDS500" rel="noopener ugc nofollow" target="_blank">https://github.com/BIDS/BSDS500</a></p><p id="06ab" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">该数据集由加州伯克利大学提供，包含500幅自然图像。</p><p id="911b" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">我们将这500幅图像分成400幅训练图像和100幅测试图像。</p><p id="a9eb" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">现在，我们从这些图像中创建补丁，补丁大小为40 x 40，步幅为40，裁剪大小不同。这样做之后，我们得到了85600个训练补丁和21400个测试数据补丁。</p><p id="f853" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">可以使用以下代码从给定的图像中获取补丁:</p><figure class="lp lq lr ls fd ik"><div class="bz dy l di"><div class="lt lu l"/></div></figure></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="5305" class="in io hi bd ip iq kp is it iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk bi translated"><strong class="ak"> <em class="if"> 4。绩效指标</em> </strong></h1><p id="89dd" class="pw-post-body-paragraph ku kv hi jn b jo jp kw kx jq jr ky kz js la lb lc ju ld le lf jw lg lh li jy hb bi translated"><strong class="jn hj"> PSNR </strong>是最常用的度量标准，用于测量从噪声压缩中获得的图像质量。</p><p id="79a7" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">术语<strong class="jn hj">峰值信噪比(PSNR) </strong>是信号的最大可能值(功率)与影响其表示质量的失真噪声功率之间的比率的表达式。PSNR通常用对数分贝标度来衡量。</p><p id="a872" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">给定地面真实图像(g)，噪声图像(f) PSNR可由下式计算</p><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es lv"><img src="../Images/c95c9ee852cdaafe7c2663eedcd67b79.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/format:webp/1*qSwV9sd2Dkf0bIyzMCcpnw.png"/></div></figure><p id="3cc0" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">其中MSE由下式给出:</p><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es lw"><img src="../Images/48cb4c62267514093e5a7c1da72abb64.png" data-original-src="https://miro.medium.com/v2/resize:fit:764/format:webp/1*USvsQe0O_ydeLAbniUZryQ.png"/></div></figure><figure class="lp lq lr ls fd ik"><div class="bz dy l di"><div class="lt lu l"/></div></figure></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="855e" class="in io hi bd ip iq kp is it iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk bi translated"><em class="if"> 5。第一次切割方法</em></h1><p id="8344" class="pw-post-body-paragraph ku kv hi jn b jo jp kw kx jq jr ky kz js la lb lc ju ld le lf jw lg lh li jy hb bi translated">在第一次切割方法中，我们将创建输入管道，将面片数据作为输入，并向其添加一些随机噪声，利用这些噪声面片，我们将使用tensorflow keras训练一个简单的卷积自动编码器模型。</p><p id="e738" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">使用tf.data的输入管道代码:</p><figure class="lp lq lr ls fd ik"><div class="bz dy l di"><div class="lt lu l"/></div></figure><figure class="lp lq lr ls fd ik er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es lx"><img src="../Images/2073f171718077697d9169a0c6e8f6b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rV6zEwSlxtleWKhKqRtObw.png"/></div></div></figure><p id="c0a8" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">现在，我们将训练一个自动编码器模型，其中均方误差(MSE)作为损失函数，初始学习速率为1e-03的Adam作为优化器。</p><figure class="lp lq lr ls fd ik"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="dc9e" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">使用自动编码器，我们获得了0.0020的训练损失和0.0021的测试损失</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="8d4f" class="in io hi bd ip iq kp is it iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk bi translated"><strong class="ak"> <em class="if"> 6。不同型号的试验</em> </strong></h1><p id="0294" class="pw-post-body-paragraph ku kv hi jn b jo jp kw kx jq jr ky kz js la lb lc ju ld le lf jw lg lh li jy hb bi translated">我们将尝试用于图像去噪任务的不同深度学习架构。</p><p id="d9c0" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated"><strong class="jn hj"> 6.1。DNCNN </strong></p><p id="24ef" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">研究论文:<a class="ae lo" href="https://arxiv.org/pdf/1608.03981v1.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1608.03981v1.pdf</a></p><p id="5315" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">建筑:</p><figure class="lp lq lr ls fd ik er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es mc"><img src="../Images/e1ebb6475f32b788d567985d64a64658.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3n1-ZtgpyFPEbWrxBZDAWA.png"/></div></div></figure><p id="fca0" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">给定有噪声的图像输入“y ”,模型预测残留图像“R ”,我们可以通过<strong class="jn hj"> x=y-R </strong>得到干净的图像“x”</p><p id="7250" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">该模型包括三种类型的层，总深度为D:</p><p id="af72" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">(i) Conv+ReLU:对于第一层，大小为3×3×c的64个滤波器被用于生成64个特征图，然后校正线性单元(ReLU)被用于非线性。这里，c表示图像通道的数量，即，对于灰度图像，c = 1，对于彩色图像，c = 3。</p><p id="2694" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">(ii) Conv+BN+ReLU:对于层2 *(D -1)，使用大小为3×3×64的64个滤波器，并且在卷积和ReLU之间添加批量归一化。</p><p id="00dd" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">㈢conv:对于最后一层，使用大小为3×3×64的c个滤波器来重建输出。</p><p id="6a16" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">该模型主要有两个特点，即学习“R”的残差学习公式和批量归一化，它加快了训练速度，提高了去噪性能。</p><p id="0689" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">模型已经用学习率=0.001的Adam优化器训练了30个时期，每个时期学习率衰减5%，并且均方误差(MSE)被用作损失函数。</p><figure class="lp lq lr ls fd ik"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="6491" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">绘制降噪补丁:</p><figure class="lp lq lr ls fd ik er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es md"><img src="../Images/6aa86eca9f1995855bea3c9f5378e1aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_QUJx4iltMqnBHf8aAJcZA.png"/></div></div></figure><p id="8504" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">现在，我们结合所有的图像去噪补丁，以获得完整的图像。我们可以通过下面的代码做到这一点:</p><figure class="lp lq lr ls fd ik"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="8efe" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated"><strong class="jn hj">剩余学习:</strong></p><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es me"><img src="../Images/d80716d1d57b60487e685f9d4a84d458.png" data-original-src="https://miro.medium.com/v2/resize:fit:1186/format:webp/1*sekd6Pg2za6RNmdDety1Rw.png"/></div></figure><p id="7021" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">在学习了这个残留图像之后，我们将从输入中减去它。因此，我们在模型的末尾添加了一个减法层，得到去噪后的图像作为输出。</p><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es mf"><img src="../Images/f16ccdac818fe3c155e9334f3b250144.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/format:webp/1*8fKq9sHHizKRaMeYSKaH9Q.png"/></div></figure><p id="aa6c" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated"><strong class="jn hj"> 6.2。RIDNET </strong></p><p id="53e7" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">研究论文:<a class="ae lo" href="https://arxiv.org/pdf/1904.07396.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1904.07396.pdf</a></p><p id="3970" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">建筑:</p><figure class="lp lq lr ls fd ik er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es mg"><img src="../Images/376f192da9a7f144b3cccd6a38f378c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pAWpsfdMOj0P7JTZ08zoFA.jpeg"/></div></div></figure><p id="b51d" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">该模型由三个主要模块组成，即特征提取、残差模块上的特征学习残差和重构，如图所示。</p><p id="cbec" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">增强注意模块(EAM)使用具有局部跳跃和短跳跃连接的剩余结构上的剩余。每个EAM进一步由D块组成，其后是特征关注。由于残差架构上的残差，现在可以使用非常深的网络来提高去噪性能。</p><p id="edbe" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">模型已经用学习率= 0.001 Adam优化器训练了20个时期，每个时期学习率衰减10%，平均绝对误差(MAE)用作损失函数。</p><figure class="lp lq lr ls fd ik"><div class="bz dy l di"><div class="lt lu l"/></div></figure><p id="357d" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">绘制降噪补丁:</p><figure class="lp lq lr ls fd ik er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es mh"><img src="../Images/61c89eef9a4cea6ab5bb4f0c38b1b482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sNQurR3pTE9zcMdWLrjFuw.png"/></div></div></figure><p id="77c4" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">绘制由补片构建的图像:</p><figure class="lp lq lr ls fd ik er es paragraph-image"><div role="button" tabindex="0" class="ly lz di ma bf mb"><div class="er es mi"><img src="../Images/9c6eb45a194f26666fca7be49e034a59.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bTvlmYaANmCB2XxwxBBYAg.png"/></div></div></figure><p id="9207" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated"><strong class="jn hj"> 6.3。车型对比:</strong></p><p id="5e06" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">将模型在具有不同噪声水平的图像上获得的性能(以db为单位的PSNR)制成表格:</p><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es mj"><img src="../Images/0fcd7663d5054804d61b5cc08ea3a5b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:832/format:webp/1*hcSJd9zUR_kCr6x26LLH9A.png"/></div></figure></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="0d56" class="in io hi bd ip iq kp is it iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk bi translated"><em class="if"> 7。模型量化</em></h1><p id="7a3c" class="pw-post-body-paragraph ku kv hi jn b jo jp kw kx jq jr ky kz js la lb lc ju ld le lf jw lg lh li jy hb bi translated">深度学习的量化是通过低位宽数的神经网络来逼近使用浮点数的神经网络的过程。这极大地降低了使用神经网络的内存需求和计算成本。</p><p id="525e" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">量化后，DNCNN模型的大小从7 MB减少到2 MB，RIDNET模型从18 MB减少到6 MB。</p><p id="ce0d" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">在我们有计算限制的情况下，这种量化模型是非常有效的。这些型号的性能将接近原始型号。</p><p id="f1d2" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">以下是一些统计值，显示了DNCNN和RIDNET的量化和原始模型的性能:</p><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es mk"><img src="../Images/3a94fa02bd5093549e4abff2f0d66cae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1304/format:webp/1*QWoRn4nBZ51gINqsK1lEHA.png"/></div></figure><p id="a947" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">通过以上观察，我们可以看到RIDNET比DnCNN模型<br/>获得了略高的PSNR值，但是RIDNET模型花费的时间要高得多，并且模型的大小也很大。</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="7e08" class="in io hi bd ip iq kp is it iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk bi translated"><strong class="ak"> <em class="if"> 8。模型分析</em> </strong></h1><p id="c133" class="pw-post-body-paragraph ku kv hi jn b jo jp kw kx jq jr ky kz js la lb lc ju ld le lf jw lg lh li jy hb bi translated">我们对DNCNN模型进行了一些模型分析。</p><p id="033b" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated"><strong class="jn hj"> 8.1。不同的噪音等级:</strong></p><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es ml"><img src="../Images/4f62196bdd978894b19c36c376bc49d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:786/format:webp/1*4AH6myrrte2OS0fDo-RV-Q.png"/></div></figure><p id="d7e8" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">我们可以观察到，该模型在噪声水平在10-35范围内的图像上表现良好。随着噪声水平的增加，PSNR的改善很小。</p><p id="eebe" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">在噪声水平60以上，模型很难从给定的噪声图像中重建图像。</p><p id="9d33" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated"><strong class="jn hj"> 8.2。不同图像上的性能:</strong></p><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es mm"><img src="../Images/4d33b65c043e034d136872fcc74e0893.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*3vRAscWGtDFMQmYygKhXYg.png"/></div><figcaption class="mn mo et er es mp mq bd b be z dx translated"><em class="if">普通图像，噪声容易被观察到，PSNR较高。</em></figcaption></figure><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es mr"><img src="../Images/59197d241eefd6742bdf4e24d56e141e.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*yOw3Q0ch3uJ4t7eq9VCdzg.png"/></div><figcaption class="mn mo et er es mp mq bd b be z dx translated"><em class="if">具有单一背景的图像也具有良好的PSNR。</em></figcaption></figure><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es ms"><img src="../Images/9bc86a4e082dcea39bd7dd30cd63e09b.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*axS24x75c2RVGOsCqwMPsQ.png"/></div></figure><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es mt"><img src="../Images/fc779020a26c3ef51137dbb10391c9bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*7B8o23mr0iytbJqTbhDjaw.png"/></div><figcaption class="mn mo et er es mp mq bd b be z dx translated"><em class="if">由于像素分布(大量的颜色变化)导致PSNR相对较低，图像的复杂性增加。</em></figcaption></figure><figure class="lp lq lr ls fd ik er es paragraph-image"><div class="er es mu"><img src="../Images/a0612bfb3e4ffdb393fd5f464df4b041.png" data-original-src="https://miro.medium.com/v2/resize:fit:702/format:webp/1*6bGmlXckgbLxv_19fCfM9Q.png"/></div><figcaption class="mn mo et er es mp mq bd b be z dx translated"><em class="if">图像中每个区域的大量颜色变化降低了PSNR。</em></figcaption></figure><p id="2dec" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">该模型试图通过观察分布在像素周围的像素来预测图像中的残留。<br/>我们可以看到，在颜色变化和像素分布方面，模型性能随着图像复杂度的增加而降低。然而，这种影响是可以协商的，因为我们是通过对较小的图像块进行预测来重建图像的。</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="e0df" class="in io hi bd ip iq kp is it iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk bi translated"><strong class="ak"> <em class="if"> 9。构建web应用</em> </strong></h1><p id="8938" class="pw-post-body-paragraph ku kv hi jn b jo jp kw kx jq jr ky kz js la lb lc ju ld le lf jw lg lh li jy hb bi translated">整个项目是使用streamlit部署的。</p><p id="6801" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">链接到正在运行的应用:<a class="ae lo" href="https://share.streamlit.io/sunilbelde/imagedenoising-dncnn-ridnet-keras/main/app.py" rel="noopener ugc nofollow" target="_blank">https://share . streamlit . io/sunilbelde/image降噪-dn CNN-ridnet-keras/main/app . py</a></p><p id="517d" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">运行应用程序的演示:</p><figure class="lp lq lr ls fd ik"><div class="bz dy l di"><div class="mv lu l"/></div></figure></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="60b4" class="in io hi bd ip iq kp is it iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk bi translated"><em class="if"> 10。未来工作</em></h1><p id="12dc" class="pw-post-body-paragraph ku kv hi jn b jo jp kw kx jq jr ky kz js la lb lc ju ld le lf jw lg lh li jy hb bi translated">目前，这些深度学习模型仅在具有加性高斯白噪声(AWGN)的图像上训练。</p><p id="b695" class="pw-post-body-paragraph ku kv hi jn b jo lj kw kx jq lk ky kz js ll lb lc ju lm le lf jw ln lh li jy hb bi translated">在未来，我们将尝试使用带有脉冲噪声(In)、椒盐脉冲噪声(SPIN)和随机值脉冲噪声(RVIN)等噪声的图像。我们将用更适合此类噪声的体系结构来训练模型。</p></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><h1 id="39b3" class="in io hi bd ip iq kp is it iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk bi translated"><em class="if"> 11。参考文献</em></h1><ol class=""><li id="5f5c" class="jl jm hi jn b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc bi translated"><a class="ae lo" href="https://www.appliedaicourse.com/" rel="noopener ugc nofollow" target="_blank">https://www.appliedaicourse.com/</a></li><li id="7bbb" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><a class="ae lo" href="https://towardsai.net/p/deep-learning/image-de-noising-using-deep-learning" rel="noopener ugc nofollow" target="_blank">https://toward sai . net/p/deep-learning/image-de-noise-using-deep-learning</a></li><li id="2873" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><a class="ae lo" href="https://arxiv.org/pdf/1608.03981v1.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1608.03981v1.pdf</a></li><li id="9e1a" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><a class="ae lo" href="https://arxiv.org/pdf/1904.07396.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1904.07396.pdf</a></li><li id="11bd" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated"><a class="ae lo" href="https://www.ni.com/en-in/innovations/white-papers/11/peak-signal-to-noise-ratio-as-an-image-quality-metric.html" rel="noopener ugc nofollow" target="_blank">https://www . ni . com/en-in/innovations/white-papers/11/peak-signal-to-noise-ratio-as-an-image-quality-metric . html</a></li><li id="0108" class="jl jm hi jn b jo kd jq ke js kf ju kg jw kh jy jz ka kb kc bi translated">【https://www.tensorflow.org/tutorials/generative/autoencoder】</li></ol></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><blockquote class="mw mx my"><p id="acf6" class="ku kv mz jn b jo lj kw kx jq lk ky kz na ll lb lc nb lm le lf nc ln lh li jy hb bi translated"><strong class="jn hj"> <em class="hi">如果您需要任何与代码相关的文件，请通过下面给出的链接进入我的GitHub库:</em> </strong></p></blockquote><div class="nd ne ez fb nf ng"><a href="https://github.com/sunilbelde/Imagedenoising-dncnn-ridnet-keras" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">sunilbelde/image降噪-dncnn-ridnet-keras</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">额外的不必要的像素值被添加到图像中，导致信息丢失。噪音可能是由…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">github.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu il ng"/></div></div></a></div><blockquote class="mw mx my"><p id="bc1f" class="ku kv mz jn b jo lj kw kx jq lk ky kz na ll lb lc nb lm le lf nc ln lh li jy hb bi translated">如果你想在LinkedIn上和我联系，下面是链接。 </p></blockquote><div class="nd ne ez fb nf ng"><a href="https://www.linkedin.com/in/sunil-belde-1b4151129/" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab dw"><div class="ni ab nj cl cj nk"><h2 class="bd hj fi z dy nl ea eb nm ed ef hh bi translated">sunil belde -学生应用人工智能课程| LinkedIn</h2><div class="nn l"><h3 class="bd b fi z dy nl ea eb nm ed ef dx translated">查看世界上最大的职业社区LinkedIn上sunil belde的个人资料。sunil有4个工作列在他们的…</h3></div><div class="no l"><p class="bd b fp z dy nl ea eb nm ed ef dx translated">www.linkedin.com</p></div></div><div class="np l"><div class="nv l nr ns nt np nu il ng"/></div></div></a></div></div><div class="ab cl ki kj gp kk" role="separator"><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn ko"/><span class="kl bw bk km kn"/></div><div class="hb hc hd he hf"><blockquote class="nw"><p id="ceb0" class="nx ny hi bd nz oa ob oc od oe of jy dx translated"><em class="if">——————感谢您的阅读——————</em></p></blockquote></div></div>    
</body>
</html>