<html>
<head>
<title>Web Scraping Using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python进行Web抓取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/web-scrapping-using-python-9422b1b04633?source=collection_archive---------13-----------------------#2021-01-23">https://medium.com/analytics-vidhya/web-scrapping-using-python-9422b1b04633?source=collection_archive---------13-----------------------#2021-01-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="8dc0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们从网站上提取信息，方法是将信息复制并粘贴到我们的文件中。然而，如果我们想尽快从网站上获取大量信息，这种手动提取数据的过程可能会很麻烦。在这种情况下，网络抓取会有所帮助，因为它是一种使用代码或API从网站下载大量数据的方法。</p><p id="d0ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Python是最流行的网络抓取语言，因为它有Scrapy、Beautiful Soup和Selenium等库，这些库使得抓取网站变得轻而易举。Web抓取包括检查网页，找到与我们需要的信息相关的合适的HTML标记，使用熊猫库(如Beautiful Soup或Selenium)来抓取HTML页面。在这一步之后，我们使用pandas库以我们需要的形式操作抓取的数据。</p><p id="72be" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个任务我们需要的包是请求，熊猫，和漂亮的汤。</p><ul class=""><li id="0f32" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">请求包允许我们连接到我们选择的站点。在本例中，我们希望连接到IMDB top 1000 movies网页。</li><li id="180f" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">Beautifulsoup4允许我们解析站点的HTML并将其转换为一个漂亮的soup对象，将HTML表示为一个嵌套的数据结构。</li><li id="bc5d" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">Pandas包允许数据集操作。</li></ul><p id="9b46" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面的代码可以帮助理解这个概念。</p><pre class="jq jr js jt fd ju jv jw jx aw jy bi"><span id="bd38" class="jz ka hh jv b fi kb kc l kd ke">import requests<br/>from bs4 import BeautifulSoup<br/>import pandas as pd<br/>url = "<a class="ae kf" href="https://www.imdb.com/search/title/?count=100&amp;groups=top_1000&amp;sort=user_rating" rel="noopener ugc nofollow" target="_blank">https://www.imdb.com/search/title/?count=100&amp;groups=top_1000&amp;sort=user_rating</a>"<br/># makes a request to the web page and gets its HTML<br/>r = requests.get(url)<br/># stores the HTML page in 'soup', a BeautifulSoup object<br/>soup = BeautifulSoup(r.content,'lxml')</span></pre><p id="6856" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们希望从IMDB网页中提取电影标题、电影发行年份、IMDB评级、运行时间和类型。要检查包含我们需要的信息的所需标签，右键单击浏览器并选择<strong class="ig hi"> Inspect </strong>。</p><p id="2c67" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用下面的代码，我们可以下载所需的信息。</p><pre class="jq jr js jt fd ju jv jw jx aw jy bi"><span id="bb6b" class="jz ka hh jv b fi kb kc l kd ke">#Extracting text: Movie titles and release year<br/>Titleandreleaseyear= soup.findAll('h3', {"class":'lister-item-header'})<br/>titles = [movie.find('a').text for movie in Titleandreleaseyear]<br/>release = [movie.find('span', class_='lister-item-year text-muted unbold').text for movie in Titleandreleaseyear]</span><span id="e785" class="jz ka hh jv b fi kg kc l kd ke">#Extracting audience rating<br/>Rating = soup.findAll('div', {"class":'inline-block ratings-imdb-rating'})<br/>imdbrating = [i.find('strong').text for i in Rating]</span><span id="2e11" class="jz ka hh jv b fi kg kc l kd ke"># Extracting Runtime<br/>Runtime = soup.findAll('span', {"class":'runtime'})<br/>a = len(Runtime)<br/>Movieruntime = []<br/>for i in range(a):<br/>    Movieruntime.append((Runtime[i]).text)</span><span id="07c7" class="jz ka hh jv b fi kg kc l kd ke"># Extracting Genre<br/>Genre = soup.findAll('span', {"class":'genre'})<br/>a = len(Genre)<br/>Genres = []<br/>for i in range(a):<br/>    Genres.append(((Genre[i]).text).replace('\n', '').strip())</span></pre><p id="7507" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">从HTML中提取的数据是非结构化格式的；因此，需要使用下面的代码将其转换为结构化形式。</p><pre class="jq jr js jt fd ju jv jw jx aw jy bi"><span id="eed6" class="jz ka hh jv b fi kb kc l kd ke">#pandas dataframe        <br/>moviesdata = pd.DataFrame({<br/>'movie': titles,<br/>'year': release,<br/>'Runtime': Runtime,<br/>'imdb': imdbrating,<br/>'genre': Genres})<br/>#Create csv file named 'movies.csv'<br/>moviesdata.to_csv('movies.csv')</span></pre><p id="052d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我们探讨了web抓取的基础知识，并且对这个概念有了更高层次的理解。点击💚如果你喜欢这篇文章。有问题可以写在下面的评论区，我会尽力解答。</p></div></div>    
</body>
</html>