<html>
<head>
<title>Machine Learning Summary ;February 2021</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习总结；2021年2月</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-summary-february-2021-fd4d3d1cdc5a?source=collection_archive---------16-----------------------#2021-03-02">https://medium.com/analytics-vidhya/machine-learning-summary-february-2021-fd4d3d1cdc5a?source=collection_archive---------16-----------------------#2021-03-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="dfd9" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">2020年2月特稿/新闻。</h1><ul class=""><li id="6d72" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">上个月发表在OpenAI博客上的DALL-E现在可以在arXiv 上看到了。这是一个非常高性能的文本到图像模型，并使用像VQ-VAE码本生成图像。</li><li id="1a33" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp jq jr js jt bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.06171" rel="noopener ugc nofollow" target="_blank"> NFNet，一个超越EfficientNet无需批量归一化的图像分类模型，已经发布</a>。批量标准化是一项重要的技术，但它存在的问题是，当批量很小时，它不起作用，并且推理期间的行为不同于训练，因此在这个方向上的研究发展对工业也很重要。</li><li id="3ba9" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp jq jr js jt bi translated"><a class="ae ju" href="https://www.microsoft.com/en-us/research/blog/microsoft-vision-model-resnet-50-combines-web-scale-data-and-multi-task-learning-to-achieve-state-of-the-art/" rel="noopener ugc nofollow" target="_blank">微软发布了非常高性能的预训练ResNet，通过多任务学习训练，性能超过OpenAI的CLIP </a>。与CLIP一样，为了训练高性能的预训练模型，在多任务和多媒体中包含多种见解可能是必不可少的。</li><li id="6546" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp jq jr js jt bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.10772" rel="noopener ugc nofollow" target="_blank">提出了一个模型，该模型可以用相同的参数运行7个图像和语言相关的任务(不需要对每个任务进行微调</a>)。它用的是Transformer，论文题目是《Transformer是你需要的全部》。</li></ul></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><h1 id="0c51" class="ie if hh bd ig ih kh ij ik il ki in io ip kj ir is it kk iv iw ix kl iz ja jb bi translated">机器学习用例</h1><ul class=""><li id="69f9" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated"><a class="ae ju" href="https://techhq.com/2021/02/ai-and-iot-5-use-cases-where-its-gathering-pace/" rel="noopener ugc nofollow" target="_blank">物联网和AI可以结合起来，让很多事情自动化</a>。随着机器学习的快速发展和5G的广泛使用，我们可能会来到一个结合物联网和人工智能的全自动化和优化系统将成为常态的社会。但是，<a class="ae ju" href="https://www.nytimes.com/2021/02/11/style/disabled-fashion-facebook-discrimination.html" rel="noopener ugc nofollow" target="_blank">脸书误判不当广告的故事</a>显示了机器学习完全自动化的危险。现阶段的机器学习模型还不具备人类的认知能力，所以我认为它们在一段时间内需要适当的人类支持。另外，正如<a class="ae ju" href="https://thegradient.pub/catching-cyberbullies-with-neural-networks/" rel="noopener ugc nofollow" target="_blank">那篇关于自动消除说或做冒犯性事情的用户的文章</a>中提到的，如果我们不小心使用它，我们最终会陷入反乌托邦，所以我认为伦理讨论是必要的。</li><li id="a79b" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp jq jr js jt bi translated">我觉得自动驾驶系统对攻击的脆弱性是一个主要问题。就汽车而言，被攻击与人的死亡直接相关，因此在自动驾驶变得普遍之前，对策将是必要的。</li><li id="127e" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp jq jr js jt bi translated">用Transformer筛选出高质量的文章，我觉得是个很有意思的<a class="ae ju" href="https://mondaynote.com/deepnews-has-transformed-5746a0fba2e1?gi=dfe16615de22" rel="noopener ugc nofollow" target="_blank">做法。在今天的社会中，有如此多的信息，如果有一种方法可以筛选出低质量的信息，那就太好了。同样有趣的是，可以了解到“文章质量”这一非常模糊的指标。</a></li></ul></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><h1 id="503e" class="ie if hh bd ig ih kh ij ik il ki in io ip kj ir is it kk iv iw ix kl iz ja jb bi translated">报纸</h1><ul class=""><li id="a55d" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">已经发表了很多使用变形金刚的论文，比如使用变形金刚的<a class="ae ju" href="https://arxiv.org/abs/2102.05644" rel="noopener ugc nofollow" target="_blank">图像检索，使用变形金刚</a> s的<a class="ae ju" href="https://arxiv.org/abs/2102.05095?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%28ja%29&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">动作识别，仅使用变形金刚</a>的<a class="ae ju" href="https://arxiv.org/abs/2102.07074" rel="noopener ugc nofollow" target="_blank">甘。正如在</a><a class="ae ju" href="https://arxiv.org/abs/2010.11929" rel="noopener ugc nofollow" target="_blank"> ViT </a>中指出的，电感偏差很小，因此在没有非常大的数据集的情况下，可能还需要实施各种措施。</li><li id="c050" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp jq jr js jt bi translated">有一项研究表明，在大型数据集上进行训练，即使有一点噪音，也会产生高性能。自2019年<a class="ae ju" href="https://arxiv.org/abs/1912.11370" rel="noopener ugc nofollow" target="_blank">大转移</a>以来，在成像界，向更大数据和模型发展的趋势已经变得相当明显，如果没有大数据集，可能很难参与SotA竞争。</li><li id="4874" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp jq jr js jt bi translated">有很多关于视觉和语言的研究，并且已经发表了两项研究(<a class="ae ju" href="https://arxiv.org/abs/2102.02779" rel="noopener ugc nofollow" target="_blank"> 1 </a>、<a class="ae ju" href="https://arxiv.org/abs/2102.10772" rel="noopener ugc nofollow" target="_blank"> 2 </a>)，其中单个模型可以执行多项任务。Transformer系统不仅将文本视为令牌，还将图像视为令牌，这可能是Vision &amp;语言的一个很好的匹配，因为通过自我关注很容易获得图像和文本之间的交互。</li></ul></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="55fd" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi">— — — — — — — — — — — — — — — — — — –</p><p id="a0b1" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">在下面的章节中，我将介绍各种文章和论文，不仅仅是关于上述内容，还包括以下五个主题。</p><ol class=""><li id="a68f" class="jc jd hh je b jf ko jh kr jj ld jl le jn lf jp lg jr js jt bi translated">本月特稿/新闻</li><li id="f7eb" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp lg jr js jt bi translated">机器学习的真实使用案例</li><li id="2d36" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp lg jr js jt bi translated">报纸</li><li id="a3dc" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp lg jr js jt bi translated">机器学习技术相关文章</li><li id="f59b" class="jc jd hh je b jf jv jh jw jj jx jl jy jn jz jp lg jr js jt bi translated">其他主题</li></ol><p id="8697" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="2938" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">1.本月特稿/新闻</h1><p id="af14" class="pw-post-body-paragraph km kn hh je b jf jg kp kq jh ji ks kt jj lh kv kw jl li ky kz jn lj lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.12092?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">高性能文本到图像模型DALL-E的论文</strong>发表</a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es lk"><img src="../Images/100b7e473f4d9c2e6047dd54cebf9839.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*mSj6mQNXjj-NmBZv.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自<a class="ae ju" href="https://openai.com/blog/dall-e/" rel="noopener ugc nofollow" target="_blank"> OpenAI博客</a>。</figcaption></figure><p id="a354" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.12092】零镜头文本到图像生成</em> <br/>他们提出了DALL-E，用零镜头从文本生成图像。首先，正如在VQVAE中一样，他们使用编码器将图像压缩为32x32，从码本中重新选择一个接近每个网格表示的表示，并学习离散VAE以从中生成图像。接下来，使用图像和文本的配对数据，他们训练了一个自回归模型，以使用文本作为输入，使用码本中的8192个表达式作为词汇来生成“图像令牌”。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="8c16" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.06171?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"/></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es mb"><img src="../Images/afacba4fca64a79c8015c498645ffec3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*HTHkd5OThd_ROZ7-"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="22bf" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.06171】无需归一化的高性能大规模图像识别</em> <br/>他们提出的NFNets优于无需批量归一化的EfficientNet。虽然采用了一种机制，模拟网络的缩放与先前的工作(<a class="ae ju" href="https://arxiv.org/abs/2101.08692?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/2101.08692</a>)批量归一化，他们使用自适应梯度裁剪(AGC)来根据权重的大小自适应地限制梯度大小。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="9a42" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://www.microsoft.com/en-us/research/blog/microsoft-vision-model-resnet-50-combines-web-scale-data-and-multi-task-learning-to-achieve-state-of-the-art/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">来自微软</strong> </a>的超高性能培训ResNet50</p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es mb"><img src="../Images/c442caf02c6548c89acb3fd9663c1d0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*U08FqMHMTA_Ndxyl"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">这张图片引自这个<a class="ae ju" href="https://pypi.org/project/microsoftvision/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">博客</a>。</figcaption></figure><p id="bd12" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">微软发布了一个非常高性能的训练过的ResNet50模型，它可以在多个大型数据集上进行多任务处理。它可以在多个大型数据集上进行多任务处理，并显示出超越Google的Big Transfer和OpenAI的Clip的迁移学习性能。此处有训练有素的模特。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="15e6" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.10772?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">用相同的参数做一个模型中的七个任务</strong> </a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es mc"><img src="../Images/fd7ac0007ef4ecfa15c1ee0b04f3eb4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*wOhknkjaVyJxHoLz.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="f89e" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.10772】Transformer是你需要的全部:用统一的Transformer进行多模态多任务学习</em> <br/>他们提出了UniT(统一的Transformer)，一种使用Transformer的模型，可以同时学习和推断视觉、文本视觉&amp;语言等多项任务。每个任务都不需要微调，所有七个任务都可以使用相同的模型参数。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="5b1f" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="ac70" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">2.机器学习用例</h1><p id="f885" class="pw-post-body-paragraph km kn hh je b jf jg kp kq jh ji ks kt jj lh kv kw jl li ky kz jn lj lb lc jp ha bi translated"><a class="ae ju" href="https://www.nytimes.com/2021/02/11/style/disabled-fashion-facebook-discrimination.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">脸书广告系统拒绝残疾人时尚广告</strong> </a></p><div class="md me ez fb mf mg"><a href="https://www.nytimes.com/2021/02/11/style/disabled-fashion-facebook-discrimination.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">为什么脸书拒绝这些时尚广告？</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">Instagram和脸书的自动情报系统一再拒绝小企业发布的广告…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.nytimes.com</p></div></div><div class="mp l"><div class="mq l mr ms mt mp mu lu mg"/></div></div></a></div><p id="026e" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">脸书的广告系统正在使用机器学习来确定广告是否合适，但针对残疾人的时尚广告因不合适而被拒绝。当这样的事件发生时，拒绝的原因是不公开的，所以广告发送者自己需要猜测原因。正如你所看到的，机器学习模型并不完美，但被脸书这样的大型平台拒绝广告对小企业来说是一个很大的打击。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="733a" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://venturebeat.com/2021/02/22/eu-report-warns-that-ai-makes-autonomous-vehicles-highly-vulnerable-to-attack/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">自动驾驶系统易受网络攻击</strong> </a></p><div class="md me ez fb mf mg"><a href="https://venturebeat.com/2021/02/22/eu-report-warns-that-ai-makes-autonomous-vehicles-highly-vulnerable-to-attack/" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">欧盟报告警告称，人工智能使自动驾驶汽车“极易”受到攻击</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">自动驾驶汽车的梦想是它们可以避免人为错误并拯救生命，但一个新的欧盟机构…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">venturebeat.com</p></div></div><div class="mp l"><div class="mv l mr ms mt mp mu lu mg"/></div></div></a></div><p id="abe0" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">欧盟网络安全机构(ENISA)指出，自动驾驶系统非常容易受到攻击，包括机器学习对抗性攻击。可以考虑采取一些措施，比如让行人看不见。已经发表的许多研究表明，这些是非常危险的，可以通过多种方式进行攻击。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="fc59" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://techhq.com/2021/02/ai-and-iot-5-use-cases-where-its-gathering-pace/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">物联网x AI的五个用例</strong> </a></p><div class="md me ez fb mf mg"><a href="https://techhq.com/2021/02/ai-and-iot-5-use-cases-where-its-gathering-pace/" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">人工智能和物联网-it加速发展的5个用例- TechHQ</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">人工智能(AI)和物联网(IoT)的融合释放出巨大的商业潜力…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">techhq.com</p></div></div><div class="mp l"><div class="mw l mr ms mt mp mu lu mg"/></div></div></a></div><p id="17bf" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">介绍了物联网和AI结合可以做的五个用例。举例来说，通过管理建筑能源、防止网络攻击和预测图像检测系统中的设备故障，能耗降低了20%。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="0ee2" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://www.reddit.com/r/MachineLearning/comments/la0uux/d_how_widespread_deep_learning_really_is_in/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="je hi"/></a><strong class="je hi">——</strong><a class="ae ju" href="https://www.reddit.com/r/MachineLearning/comments/la0uux/d_how_widespread_deep_learning_really_is_in/?utm_campaign=Akira%27s+Machine+Learning+News+++&amp;utm_medium=email&amp;utm_source=Revue+newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="je hi">【www.reddit.com】</strong></a></p><figure class="ll lm ln lo fd lp"><div class="bz dy l di"><div class="mx my l"/></div></figure><p id="c53a" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">一个讨论深度学习在工业界有多广泛的帖子。就这个线程来说，很多公司都在用深度学习(但注意这个线程属于机器学习板，所以有偏差)。关于预测股票价格的努力已经有了很多讨论。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="436a" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://newatlas.com/medical/ai-ugly-duckling-melanoma-skin-cancer/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">从智能手机拍摄的图像中检测皮肤癌。</strong></a><strong class="je hi">——</strong><a class="ae ju" href="https://newatlas.com/medical/ai-ugly-duckling-melanoma-skin-cancer/" rel="noopener ugc nofollow" target="_blank">【newatlas.com】T21</a></p><div class="md me ez fb mf mg"><a href="https://newatlas.com/medical/ai-ugly-duckling-melanoma-skin-cancer/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">人工智能利用“丑小鸭”技术高精度识别黑色素瘤</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">人工智能开始与智能手机技术相结合，这可能会对……产生深远的影响</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">newatlas.com</p></div></div><div class="mp l"><div class="mz l mr ms mt mp mu lu mg"/></div></div></a></div><p id="d218" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">利用深度学习，他们根据痣的变化与正常痣的特征有多么不同来测量痣的异常，并创建了一个与皮肤科医生的判断88%一致的模型。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="40b9" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://hai.stanford.edu/blog/how-large-language-models-will-transform-science-society-and-ai?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">大规模的语言模型会如何改变社会？</strong></a><strong class="je hi">——</strong><a class="ae ju" href="https://hai.stanford.edu/blog/how-large-language-models-will-transform-science-society-and-ai" rel="noopener ugc nofollow" target="_blank"><strong class="je hi">hai.stanford.edu</strong></a></p><div class="md me ez fb mf mg"><a href="https://hai.stanford.edu/blog/how-large-language-models-will-transform-science-society-and-ai?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">大型语言模型将如何改变科学、社会和人工智能</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">计算机科学、语言学和哲学领域的学者探索了GPT-3的痛苦和希望。</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">hai.stanford.edu</p></div></div><div class="mp l"><div class="na l mr ms mt mp mu lu mg"/></div></div></a></div><p id="428b" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">一篇讨论大型语言模型GPT-3将如何改变社会的文章。它表示，GPT 3号越来越接近人类的认知能力，但仍不够接近，未来，它将像DALL-E一样，不仅能够从语言中学习，还能从图像中学习。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="6975" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://mondaynote.com/deepnews-has-transformed-5746a0fba2e1?gi=2a20c5ced5bf&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="je hi"/></a><strong class="je hi">——</strong><a class="ae ju" href="https://mondaynote.com/deepnews-has-transformed-5746a0fba2e1?gi=2a20c5ced5bf" rel="noopener ugc nofollow" target="_blank"><strong class="je hi">mondaynote.com</strong></a></p><div class="md me ez fb mf mg"><a href="https://mondaynote.com/deepnews-has-transformed-5746a0fba2e1" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">深度新闻已经转型了</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">Deepnews.ai现在由基于Transformer架构的全新算法提供支持。在…中</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">mondaynote.com</p></div></div><div class="mp l"><div class="nb l mr ms mt mp mu lu mg"/></div></div></a></div><p id="85e2" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">deepnews.ai开发了一种算法，可以使用transformer自动确定文章的质量。1-5分用于训练一个模型，根据文章的质量对其进行分类，准确率约为80-90%。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="dd92" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://thegradient.pub/catching-cyberbullies-with-neural-networks/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">识别网络游戏中的有害玩家。</strong></a><strong class="je hi">——</strong><a class="ae ju" href="https://thegradient.pub/catching-cyberbullies-with-neural-networks/" rel="noopener ugc nofollow" target="_blank"><strong class="je hi">the gradient . pub</strong></a></p><div class="md me ez fb mf mg"><a href="https://thegradient.pub/catching-cyberbullies-with-neural-networks/" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">用神经网络捕捉网络恶霸</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">数字骚扰在互联网的许多角落都是一个问题，像互联网论坛，评论区和游戏聊天…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">thegradient.pub</p></div></div><div class="mp l"><div class="nc l mr ms mt mp mu lu mg"/></div></div></a></div><p id="ec36" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">一篇早期识别网游中骚扰诽谤玩家的文章。由于只检测特定单词(例如，fuck)的算法经常出现故障，因此使用机器学习模型提高了检测精度。文章提到，早期发现这些玩家可以对他们的社区产生积极影响，但也存在许多道德问题和挑战。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="cedb" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="2b0e" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">3.报纸</h1><h1 id="588c" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.02779?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="ak">单一模型下的多种视觉语言任务</strong> </a></h1><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es nd"><img src="../Images/f97f425aae5824d5aef6c8fcd72ca284.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*IhKLdKP7u_WMitoBV8JXiQ.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="ed67" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.02779】通过文本生成统一视觉和语言任务<br/> </em>他们提出了VL-巴特和VL-T5，通过使用具有自回归语言模型的文档生成，可以用单一模型执行各种图像语言任务。这个结果比以前那些需要特定任务的大脑的研究要好。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="f377" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.05095?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">变压器动作识别任务</strong> </a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es mb"><img src="../Images/ccfd00743df1e8f08a3fc177c5b031e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*aTq2gGfVOIXKSEM3"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="fbe7" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.05095】视频理解只需要时空注意力吗？</em> <br/>他们提出了仅使用变形金刚的TimeSformer，在动作识别任务上超越了基于CNN的模型。它计算时间方向上的注意力，然后像在ViT中一样在修补每一帧后计算空间方向上的注意力。它在Kinetics-400，600上实现了Sota性能，在Something-Something-V2上也实现了高精度。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="dc6e" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.06108?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">生成型模型用小波提高分辨率</strong> </a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es ne"><img src="../Images/b5719adb17fe1149e428e097d4b45327.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*97fLZA3s2tn8jk6CapmUXg.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="18f6" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.06108】SWAGAN:一种基于风格的小波驱动生成模型</em> <br/>在StyleGAN中，这项研究通过渐进增长小波而不是RGB图像来生成高分辨率图像，并且它可以实现与基于RGB的方法相同的质量，而只需要计算资源。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="b386" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.06529?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">检测艺术品中的人物</strong> </a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es nf"><img src="../Images/12b20dcfe65d28d0069517d8fb1a5760.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zykyC-fhK2HBh-mGSgtfGw.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="dbb2" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.06529】仅使用风格转换改进艺术图像中的对象检测</em> <br/>这是一项研究，通过使用修改后的样式转换为艺术风格的COCO女士进行微调来检测艺术作品中的人物。原则上，它可以用于非人类的检测，并且它可以用于收集描绘某个对象的艺术品。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="8931" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.03141?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="je hi"/></a><strong class="je hi">——</strong><a class="ae ju" href="https://arxiv.org/abs/2102.03141?utm_campaign=Akira%27s+Machine+Learning+News+++&amp;utm_medium=email&amp;utm_source=Revue+newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="je hi">arxiv.org</strong></a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es ng"><img src="../Images/1075448bbff0943dfb0fa341737931d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tDqhHGjfqXkncMVs7rpSpg.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="e62d" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.03141】Character gan:少镜头关键点角色动画和寄托</em> <br/>这是一个从多个图像创建动画的研究。通过将图像的每个部分分成三层，他们可以生成不会混淆前景和背景的图像，同时通过预测遮罩，他们可以让模型学会保持各个部分之间的联系。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="cb83" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.10056?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">分子的自我监督学习</strong> </a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es nh"><img src="../Images/111b909fa706e43ddfac6342913d7d21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cz7cnij0BLRoCVyyqp8xIg.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="789e" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.10056】MolCLR:通过图形神经网络进行表征的分子对比学习</em> <br/>提出了MolCLR，一种分子的自我监督学习方法。该方法被设计用于学习分子的相同表示，即使原子被掩蔽或键被消除。通过微调，SotA性能在各种任务中得以实现。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="a139" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.01645?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">从图像中生成最佳字幕</strong> </a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es ni"><img src="../Images/062e34fe58252d9db4d6fd36a650db65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sPfr2EvRAwYYy_oxtAYMpg.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="7b2b" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.01645】通过CLIP引导的生成式潜在空间搜索，从字幕生成图像，反之亦然</em> <br/>研究将遗传算法与CLIP相结合，从图像生成最优字幕，通过分别嵌入文本和图像，计算一致度，实现零镜头推理。他们使用预先训练的GAN生成器，通过遗传算法搜索最佳潜在空间，以使生成的图像与剪辑中的文本相匹配。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="1e53" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.07074?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">配置一个只有变形金刚的GAN</strong></a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es nj"><img src="../Images/a43d6cd814c63ae64f5099667160f286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K1UHslYImJlYbd_qomiVgA.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="fa35" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.07074】trans GAN:两个变压器可以组成一个强大的GAN </em> <br/>一项仅使用变压器构建GAN的研究发现，位置感知初始化(如CNN中那样逐渐打开可见部分)是有效的，并且它也可以很容易地受益于数据增强和多任务学习。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="92f9" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.05644?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">利用变压器进行图像检索</strong> </a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div role="button" tabindex="0" class="lq lr di ls bf lt"><div class="er es nk"><img src="../Images/6735ace2c745b07cded90ed7b3ae447b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*15Jh1cApr3TJvqSU9T_LXA.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="cf6a" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.05644】训练用于图像检索的视觉变形器<br/> </em>他们提出用变形器进行图像检索的IRT(图像检索变形器)。除了对比损失之外，他们还使用了最近邻不会靠得太近的损失项，以防止硬阴性样本靠得太近。SotA性能是在三个数据集上获得的。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="b627" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" href="https://arxiv.org/abs/2102.05918?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">在嘈杂但庞大的数据集上训练</strong> </a></p><figure class="ll lm ln lo fd lp er es paragraph-image"><div class="er es nl"><img src="../Images/7791d0562c417d2b8e4b80899db65885.png" data-original-src="https://miro.medium.com/v2/resize:fit:1338/format:webp/1*yxoaKSvO4NXWGnf168YxUw.png"/></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">图片引自本文</figcaption></figure><p id="d1ca" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><em class="ma">【2102.05918】利用噪声文本监督按比例放大视觉和视觉语言表征学习<br/> </em>复杂的过滤过程会产生干净的数据，但数据会变小。因此，他们采用一种策略，通过简单的预处理，在有噪声但数据量大的图像/文本对上进行对比损失的学习，以获得良好的表示。在从图像中检索字幕方面实现了强大的性能。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="f468" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="e442" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">4.机器学习技术相关文章</h1><p id="1fd5" class="pw-post-body-paragraph km kn hh je b jf jg kp kq jh ji ks kt jj lh kv kw jl li ky kz jn lj lb lc jp ha bi translated"><a class="ae ju" href="https://www.edge-ai-vision.com/2021/02/optimizing-image-processing-for-computer-vision/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">通过优化摄像机参数，目标检测的地图性能提升高达48%</strong></a></p><div class="md me ez fb mf mg"><a href="https://www.edge-ai-vision.com/2021/02/optimizing-image-processing-for-computer-vision/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">为计算机视觉优化图像处理-边缘人工智能和视觉联盟</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">一家汽车1级供应商如何使用Atlas在几天内将计算机视觉精度提高了48%。</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.edge-ai-vision.com</p></div></div><div class="mp l"><div class="nm l mr ms mt mp mu lu mg"/></div></div></a></div><p id="64fd" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">目标检测技术是自动驾驶系统中的核心技术之一，但手动调整图像处理(ISP)非常耗时。在这里，他们报告说，通过使用Atlas <a class="ae ju" href="http://applewebdata//46DD55F3-A15D-456E-8910-BD7370194D89/Camera%20Optimization%20Suite?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">相机优化套件</a>来优化对象检测模型的ISP方法，他们能够在几天内将mAP提高48%。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="d988" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="9783" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">5.其他主题</h1><p id="c5c8" class="pw-post-body-paragraph km kn hh je b jf jg kp kq jh ji ks kt jj lh kv kw jl li ky kz jn lj lb lc jp ha bi translated"><a class="ae ju" href="https://ai.googleblog.com/2021/02/introducing-model-search-open-source.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="je hi">谷歌发布模型搜索代码</strong> </a></p><div class="md me ez fb mf mg"><a href="https://ai.googleblog.com/2021/02/introducing-model-search-open-source.html?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">介绍模型搜索:一个寻找最佳ML模型的开源平台</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">神经网络(NN)的成功通常取决于它对各种任务的推广能力。然而，设计…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">ai.googleblog.com</p></div></div><div class="mp l"><div class="nn l mr ms mt mp mu lu mg"/></div></div></a></div><p id="66a9" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">Google已经发布了一个网络探索库，不仅可以处理变形金刚和LSTM组合探索，还可以处理蒸馏等等。这里的代码是<a class="ae ju" href="https://github.com/google/model_search?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank">这里是</a>。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="c973" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated"><a class="ae ju" rel="noopener" href="/pytorch/introducing-lightning-flash-the-fastest-way-to-get-started-with-deep-learning-202f196b3b98?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter"> <strong class="je hi">闪电来自Pytorch闪电</strong> </a></p><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/pytorch/introducing-lightning-flash-the-fastest-way-to-get-started-with-deep-learning-202f196b3b98"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">闪电简介—从深度学习基线到研究瞬间完成</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">Flash是一个任务集合，用于快速原型制作、基线和微调，以实现快速和可扩展的DL，构建于…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="no l mr ms mt mp mu lu mg"/></div></div></a></div><p id="68ee" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi translated">Pytorch闪电放出了闪电闪，比Pyroch闪电还要简单。它可以在几行代码中使用训练好的模型执行文本分类、表格数据分类和图像表示向量获取。</p></div><div class="ab cl ka kb go kc" role="separator"><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf kg"/><span class="kd bw bk ke kf"/></div><div class="ha hb hc hd he"><p id="bd33" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="2db0" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">每周新闻信！请订阅！</h1><div class="md me ez fb mf mg"><a href="https://www.getrevue.co/profile/akiratosei" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">阿基拉的机器学习新闻- Revue</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">由Akira的机器学习新闻-由Akihiro FUJII:制造工程师/机器学习工程师/硕士…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.getrevue.co</p></div></div><div class="mp l"><div class="np l mr ms mt mp mu lu mg"/></div></div></a></div><p id="f20d" class="pw-post-body-paragraph km kn hh je b jf ko kp kq jh kr ks kt jj ku kv kw jl kx ky kz jn la lb lc jp ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="9411" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">过去的时事通讯</h1><div class="md me ez fb mf mg"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-machine-learning-news-week-9-2021-417831" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">Akira的机器学习新闻-# 2021年第9周</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">Akira的机器学习新闻-第9周(2月22日~)，2021年</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.getrevue.co</p></div></div><div class="mp l"><div class="nq l mr ms mt mp mu lu mg"/></div></div></a></div><div class="md me ez fb mf mg"><a href="https://www.getrevue.co/profile/akiratosei/issues/akira-s-ml-news-week-7-2021-372359" rel="noopener  ugc nofollow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">Akira的ML新闻-# 2021年第7周</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">以下是我在2021年第7周(2月7日~)读到的一些我觉得特别有趣的论文和文章…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">www.getrevue.co</p></div></div><div class="mp l"><div class="nr l mr ms mt mp mu lu mg"/></div></div></a></div><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/akiras-ml-news-january-2021-34a7249c6bb9"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">Akira的ML新闻# 2021年1月</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">以下是我在2021年1月读到的一些我觉得特别有趣的论文和文章。</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="ns l mr ms mt mp mu lu mg"/></div></div></a></div><div class="md me ez fb mf mg"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/akiras-ml-news-december-2020-44f9235fb250"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">Akira的ML新闻# 2020年12月</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">以下是我在2020年12月读到的一些我觉得特别有趣的论文和文章。</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">medium.com</p></div></div><div class="mp l"><div class="nt l mr ms mt mp mu lu mg"/></div></div></a></div><div class="md me ez fb mf mg"><a href="https://towardsdatascience.com/machine-learning-2020-summary-84-interesting-papers-articles-45bd45c0d35b" rel="noopener follow" target="_blank"><div class="mh ab dw"><div class="mi ab mj cl cj mk"><h2 class="bd hi fi z dy ml ea eb mm ed ef hg bi translated">机器学习2020摘要:84篇有趣的论文/文章</h2><div class="mn l"><h3 class="bd b fi z dy ml ea eb mm ed ef dx translated">在这篇文章中，我总共展示了2020年发表的84篇我觉得特别有趣的论文和文章…</h3></div><div class="mo l"><p class="bd b fp z dy ml ea eb mm ed ef dx translated">towardsdatascience.com</p></div></div><div class="mp l"><div class="nu l mr ms mt mp mu lu mg"/></div></div></a></div></div></div>    
</body>
</html>