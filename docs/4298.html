<html>
<head>
<title>YOLO Object Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO物体检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/yolo-object-detection-343a430f3b48?source=collection_archive---------3-----------------------#2021-09-19">https://medium.com/analytics-vidhya/yolo-object-detection-343a430f3b48?source=collection_archive---------3-----------------------#2021-09-19</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/0d403b3843f69ab9a806edf9643d4196.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zlWrCk1hBBFRXa5t84lmHQ.jpeg"/></div></div></figure><h1 id="632c" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">介绍</h1><p id="1203" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">YOLO(你只看一次)是一个广泛使用的对象检测系统，由于其速度优势，最适合用于实时对象检测。它与<a class="ae kl" href="https://james-han.medium.com/ssd-single-shot-multibox-detector-86e891113896" rel="noopener">单次多盒检测器(SSD) </a>相似，都是在卷积网络的一次通过中预测边界盒和类别概率。这不同于其他先进的对象检测系统，如更快的R-CNN，因为后者使用区域提议网络。</p><p id="abb5" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">YOLO系列的主要优势是这些系统运行速度更快，但有时与R-CNN系列相比，这是以较低的平均精度为代价的。</p><p id="3af7" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">本文总结了YOLO系列的每个版本，并展示了它如何在多年的发展中保持作为截至2021年9月的最先进的物体探测系统之一。</p><h1 id="b581" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">YOLOv1</h1><p id="1543" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">对象检测问题被构造为单个回归问题，并且单个卷积网络被用于同时预测多个包围盒和类别概率。YOLO在训练和测试期间看到整个图像，所以它使用从边界框和背景中的对象提取的特征。</p><p id="9159" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">图像被分成一个<em class="kr"> S * S </em>网格，网格中的每个单元负责检测位于该单元中心的对象。每个单元格预测<em class="kr"> B </em>边界框和物体在框中存在的可能性的置信分数。对于每个边界框，产生5个输出:框中心的<em class="kr"> (x，y) </em>坐标、框的宽度和高度以及置信度得分。每个网格单元还预测<em class="kr"> C </em>条件类概率，这意味着如果一个对象确实在盒子里，那么该对象在每个类中的概率是多少。总的来说，YOLO模型输出一个<strong class="jp hi"> <em class="kr"> S * S * (5B + C) </em> </strong>张量。</p><p id="b4e1" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">网络架构由24个卷积层和2个全连接层组成，卷积层在1 x 1和3 x 3滤波器之间交替。一个名为“快速YOLO”的较小网络使用9层卷积层，而不是24层，其他一切都与YOLO相同。</p><h1 id="ab99" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">YOLOv2 (YOLO9000)</h1><p id="1790" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">YOLOv2被命名为YOLO9000，因为它能够检测超过9000个对象类。为了实现这一点，最大的障碍是获得足够大的标记数据集，这对于9000个对象类来说是非常昂贵的。因此，使用分层的对象分类结构，这使得能够使用多个不同的数据集进行训练(使得每个数据集不需要包含所有9000个类)，甚至使用对象分类数据集，这比对象检测数据集的获得便宜得多。</p><p id="93f2" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">YOLOv2的重点是在保持分类精度的同时提高YOLO的召回率和定位率。YOLOv2中引入了以下方法:</p><p id="b79d" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">批量归一化。</strong>通过向所有卷积层添加批量归一化，我们可以将正则化引入到模型中，并且它能够在不过度拟合的情况下移除丢失步骤。</p><p id="b97a" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">高分辨率分类器。</strong>训练时，原始YOLO将所有输入图像的大小调整为224 x 224，并将分辨率提高到448 x 448，以便检测。YOLOv2使用448 x 448分辨率进行训练和检测，这使得学习更加容易。</p><p id="d395" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">锚箱。</strong>yolov 2没有使用全连通层来预测包围盒坐标，而是去除了全连通层，使用锚盒来预测偏移量而不是坐标，简化了问题，也更便于网络学习。使用锚盒还允许网络预测更多的盒子，这极大地提高了召回率，而精度仅略有下降。</p><p id="e670" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">维度集群。</strong>不是手动选取锚框，而是在训练集边界框上运行k-means聚类，以自动找到好的先验。</p><p id="8325" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">直接位置预测。使用锚盒会引入稳定性问题:因为预测的盒不受约束，预测的偏移值会在迭代之间波动，并且需要很长时间来稳定。因此，将约束添加到位置预测中，以使网络更加稳定，学习速度更快。</strong></p><p id="326c" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">细粒度特征。</strong>通过将相邻要素堆叠到不同的通道而不是空间位置，添加了一个直通图层来连接较高分辨率要素和较低分辨率要素。这使得网络可以访问更细粒度的功能，以捕捉更小的细节。</p><p id="c24b" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">多尺度训练。</strong>网络不是固定输入图像尺寸，而是每隔几批随机调整输入图像尺寸。这种技术允许网络在预测不同输入图像尺寸时变得更加稳健。</p><p id="7dae" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">暗网-19。</strong>这种新的网络架构包括19个卷积层和5个最大池层，用于提高预测速度。</p><p id="91b1" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">等级分类。</strong>一些数据集有“狗”和“人”等宽泛的类别，而其他数据集有更具体的类别，如不同品种的狗。使用类别的分层树来描述可用标记数据集中的所有类别，以便可以使用多个数据集来训练相同的分类模型。这就是YOLOv2能够检测9000多个类的原因。</p><h1 id="513a" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">YOLOv3</h1><p id="db3d" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">YOLOv3比YOLOv2有了更大的改进。这些改进包括:</p><p id="b67d" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">多类预测。</strong>每个标签盒可能包含多个标签，如“狗”、“柯基”。不使用softmax，而是使用多个独立的逻辑分类器。</p><p id="6dec" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">跨尺度的预测。</strong> YOLOv3可以预测3种不同比例的盒子，因此它更擅长寻找小物体，这是YOLOv2的一个主要缺点。</p><p id="f667" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">暗网-53。</strong>这个新的主干有53层卷积层，而不是YOLOv2使用的Darknet-19中的19层。这种改变以牺牲速度为代价提高了预测的准确性。</p><h1 id="eab2" class="ip iq hh bd ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm bi translated">YOLOv4</h1><p id="fba5" class="pw-post-body-paragraph jn jo hh jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ha bi translated">YOLOv4不是由前三个YOLO版本的原始开发者Joseph Redmon开发的，由于对计算机视觉在军事应用中的应用和数据保护问题的道德关注，他停止了他的研究。</p><p id="a653" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated">由Bochkovskiy、王和廖开发的YOLOv4在YOLOv3的基础上提供了一些额外的改进，这些改进包括:</p><p id="2769" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi"> CSPDarknet53。</strong>这种新的主干基于Darknet-53，它使用CSPNet(跨级局部网络)策略将基础层的特征图分成两部分。一部分经过密集区块和过渡层，然后与另一部分合并，形成下一层。</p><p id="6564" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi">空间金字塔汇集。</strong>通过应用大小过滤器尺寸的金字塔，这个新层有助于增加特征的感受域。</p><p id="95b4" class="pw-post-body-paragraph jn jo hh jp b jq km js jt ju kn jw jx jy ko ka kb kc kp ke kf kg kq ki kj kk ha bi translated"><strong class="jp hi"> PANet。</strong> YOLOv4使用PANet(路径聚合网络)的参数聚合技术，通过自底向上的路径增强，在较低层使用精确的定位信号来增强特征层次，从而缩短层间的信息路径。</p></div></div>    
</body>
</html>