<html>
<head>
<title>AI Classical Music Composer — Bi-LSTM &amp; CNN-GAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">艾古典音乐作曲家——毕&amp;甘</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ai-classical-music-composer-63d983ee5fc0?source=collection_archive---------1-----------------------#2021-10-25">https://medium.com/analytics-vidhya/ai-classical-music-composer-63d983ee5fc0?source=collection_archive---------1-----------------------#2021-10-25</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="ee17" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated">如何在没有古典音乐理论知识和背景的情况下，为作曲家、音乐家，甚至是非专业人士创作古典音乐。</h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/6496538fe3df5eff6681e3db0d0ff031.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gGvEAL-VIIFTYXvTxPA4ow.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">2个提议的人工智能模型</figcaption></figure><p id="4177" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">注:这个项目的源代码可以在这里访问<a class="ae kj" href="https://github.com/chiatsekuo/AI_Classical_Music_Composer" rel="noopener ugc nofollow" target="_blank">。</a></p><h1 id="d322" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">1.摘要</h1><p id="7f06" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">作为人类音乐家或人工智能音乐家本身的助手，人工智能可以将音乐创作带到另一个水平，具有无限的可能性。生活在数字时代，古典音乐在商业电影、电影预告片、游戏原声等等中起着主导作用。但是，没有现存的产生不同时代古典音乐的作品。为了填补这一空白，该项目提出了一种适用于古典音乐的人工智能音乐生成器。因此，对于作曲家、音乐家，或者甚至没有古典音乐理论和背景的先前知识的非专业人士来说，为了许多实际目的，可以根据他们喜爱的音乐时代快速创作古典音乐。它使用生成模式，即Bi-LSTM和CNNGAN，为某些特定的古典音乐流派创作古典音乐，并分别和共同评价它们的演奏。</p><h1 id="5950" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">2.文献评论</h1><h2 id="0f62" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">2.1现有方法及其局限性</h2><p id="02d7" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">先前的研究显示了通过实现马尔可夫链、递归神经网络和生成对抗网络来生成音乐的潜力。然而，每项研究都有其局限性；因此，与早期的方法相比，仍有改进的空间。</p><h2 id="dce5" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">马尔可夫链</h2><p id="c017" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">根据特定的概率规则，马尔可夫链是一个以固定的时间步长从一个状态改变到另一个状态的系统。当将马尔可夫链应用于音乐生成时，训练集中的每个音符被分配一个唯一的状态。然后，模型将生成新的状态(注释)，从过去的状态中依次学习。马尔可夫链最直接的设计是限制模型使用单一的先前状态来预测另一个状态。由于音乐家通常会自发地演奏，因此应用马尔可夫链来辅助爵士乐等实时即兴演奏是合理可行的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lv"><img src="../Images/2ee5cb3e363cc573377bed2ca693dd04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UloSPWFjsPGbrNEJE6W82Q.png"/></div></div></figure><p id="ed16" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然而，当马尔可夫链从具有完整作品的现有音乐语料库中生成音乐时，结果并不令人满意。它展示了非音乐性的音符和和弦的怪异排列(Moorer，1972)。</p><h2 id="a340" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">2.1.2递归神经网络</h2><p id="f8da" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">递归神经网络(RNN)是一种神经网络，其中当前输入被馈入来自先前隐藏单元的输出。RNN的每个节点都有一个隐藏状态，这使得网络能够记忆过去的一系列结果。记忆的这一特征意味着RNN可以应用于自然语言处理(NLP)、时间序列模式预测等任务。由于传统的RNNs的缺点是不能记忆长序列的数据，并遭受爆炸和消失梯度的问题，大多数研究应用长短期记忆(LSTM，一种RNN)作为产生更长序列信息的替代方法，如文本、语音和音乐。通常，LSTM由删除无用信息的遗忘门、将有用信息相加的输入门以及提取有价值信息作为当前单元输出的输出门组成。Eck和Schmidhuber (2002)证明了LSTM模型能够以类似于其训练(输入)数据的风格创作新颖的蓝调音乐。然而，Hadjeres等人(2016)评论说，例如，音乐缺乏灵活性，不能在巴赫中进行重新和声。</p><p id="02b1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Choi等人(2016年)进行了另一项研究，该研究显示了一种基于文本的自动音乐创作LSTM算法，该算法使用不同的字符作为唯一的音符来学习和弦进行和鼓轨道之间的关系。然而，他们发现基于字符的RNN无法通过产生不希望的任意0和1作为输出来生成有意义的鼓轨道结构。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lw"><img src="../Images/7af7357ff67a887a0b0e2a919d17151d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zrTk7On1Nol9wdbNm_mhJw.png"/></div></div></figure><p id="a8fb" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">布朗热-莱万多夫斯基等人(2012)提出了一种组合方法，通过引入RNN-RBM模型，改进了他们以前在产生复调音乐方面的研究。每个RNN隐藏单元都与一个RBM组合在一起。RBM或受限玻尔兹曼机器是一个双向连接的随机(或生成)系统，具有可见节点和隐藏节点，其中所有可见节点都连接，但隐藏节点不连接。RNN单元的每个状态都从其先前状态和RBM观测向量获得输入，这允许模型通过从音符的先前时间步长中学习来更好地预测即将到来的音符。然而，Magenta项目(Shiebler，2016年)评论说，这种模型很难生成更长时间步长的有节奏和旋律的音乐。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lx"><img src="../Images/38df9dd2952e93103b0d1570e5f1a2f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JxQksQEzYrkOq3YYQexseA.png"/></div></div></figure><h2 id="b26c" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">2.1.3生成对抗网络</h2><p id="1691" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">生成对抗网络(GAN) (Goodfellow等人，2014年)是一种从零开始产生似是而非的数据的神经网络。GAN中有两个系统——发生器和鉴别器。发生器试图通过产生假数据来欺骗鉴别器，而鉴别器则鉴别真假样本。通过竞争，鉴别器惩罚生成假数据的生成器，而生成器在创建看起来真实的新实例方面变得更好。董等人(2017)的一项研究采用具有Wasserstein损耗的卷积GAN来生成多轨道钢琴卷帘窗的四个小节。对于模型训练，输入数据大小以钢琴卷帘窗格式设置为96(时间步长)乘以84(音符)乘以5(音轨)。与大多数图像分类问题类似，钢琴卷帘窗上的每个音符都被认为是一个有效像素，表示音符的存在。因此，使用卷积层结合GAN的概念，该系统就像从头开始生成图像，然后将它们转换回音频格式。研究表明，该方法是可行的，能够学习短和弦进行的结构和特征。然而，它不能产生更长时间的音乐。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ly"><img src="../Images/b2051119cac915a3f0e03927d926808b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SJ1rxuMpblPKK64_hCX3BQ.png"/></div></div></figure><h2 id="f24a" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">2.2建议的方法</h2><p id="aa90" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">该项目将评估两种神经网络架构——深度双向LSTM模型和具有卷积层的GAN模型。假设深度双向LSTM模型可以通过预测具有更长时间步长和更有意义的旋律的音乐结构来改善现有研究的缺点。另一方面，GAN模型试图通过从零开始开发音乐(随机噪声)来解决LSTM模型陷入循环(生成相同的音乐结构)的问题。这两个提议的模型都应该解决当前研究的缺点，所有结果都将通过适当的评估指标进行比较和评估——弗雷歇初始距离(FID)评分和最近邻搜索——以及人类调查。</p><h1 id="6450" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">3.设计、解决方案和系统</h1><h2 id="b4f7" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">3.1深度双向LSTM RNN</h2><h2 id="2bec" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">3.1.1深度神经网络</h2><p id="6bd0" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">据信，较深的神经网络比浅的神经网络更能够分析和处理信息的全面特征。通常，浅层神经网络只包含一个或两个隐藏层，而深层神经网络包含两个以上的隐藏层。因此，为了让所提出的模型更好地理解输入数据，在本项目中采用了深度神经网络。</p><h2 id="5f27" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">LSTM建筑</h2><p id="a484" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">每个LSTM层都包含LSTM单元块，这些单元块有多个门来存储信息序列。细胞状态将有价值的信息传递给其他细胞和具有独特功能的多个门，以保持LSTM网络学习和记忆信息。下图说明了LSTM单元的架构。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lz"><img src="../Images/16f137629aa407ec1bc5c692bab4fe57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1110/format:webp/1*y97mhqtvktw3UNuCE_YWaA.png"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/12038fca876382e4c3736cca94057d29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dK-4es0iwE8MyY6OyFdX2A.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mb"><img src="../Images/554801613bf5d8678ea548dbd96ebee8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*832XLLph6eOcBNpxZAA0fg.png"/></div></figure><h2 id="5040" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">3.1.3双向LSTM</h2><p id="4049" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">双向LSTM模型是一个包含两个LSTM层的系统，这两个层以相反的方向传递数据。系统的每个输出接收来自向后和向前层的隐藏状态的信息。与单向lstm相比，双向lstm不仅从过去学习信息，也从未来学习信息。这个特征允许模型15更准确地预测顺序信息。从下图可以看出，这是一个无环图。每个时间步长的输出可推导如下:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mc"><img src="../Images/3a3c4bb3a985658915dcd133a7708ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B4q74R5U8Ow5PqiFADy32w.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es md"><img src="../Images/30e7d6c2899a3d476937224f4487ebea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/1*Ygj6oEMM-G4t1Z9_5CNG-A.png"/></div></figure><h2 id="d1f2" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">3.1.3综合方法</h2><p id="c18c" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">深层双向LSTM RNN是多个双向LSTM层堆叠在一起的模型。据推测，结合深度神经网络和双向层的特征将比以前研究的方法执行得更好。因此，这个项目中的第一个模型将基于这个设计。</p><p id="f19a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">该模型包含三个双向LSTM层，每个层具有128个神经元，随后是两个完全连接的层，以修改输入向量的维度并适应所需的输出形状。激活函数和优化器的最初计划是使用校正线性单元(ReLU)和RMSProp，因为它们最广泛地用于LSTM模型。但是，其他优化器和激活函数将在实现步骤中进一步测试。</p><h2 id="175c" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">3.2基于CNN的GAN</h2><p id="ca2d" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">GAN由一个生成器和一个鉴别器组成，具有最适合对训练数据进行分类的任何神经网络架构。它主要用于通过CNN生成图像。然而，其他神经网络，如LSTM或RNN，也被用来预测序列数据。一般来说，GAN的训练过程可以分为两个部分——鉴别器的训练和发生器的训练。首先，随机生成的数据将被输入生成器。</p><p id="c37a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">随机生成的输入大小不一定需要与期望生成的输出相同。由于输入数据的维度可以在生成器中更改，因此通常会使用比输出数据维度更小的维度。在发生器产生一个假(生成的)输出后，假输出将被传入鉴别器，与真实数据进行比较。此时，鉴别器将根据鉴别器损失函数在训练过程的所有迭代中学习区分数据的真假。发生器还将根据仅连接到鉴别器的发生器损耗函数，通过鉴别器和发生器从反向传播获得的梯度中学习。下图是一个通用的GAN架构(“真实图像”代表真实世界的数据)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es me"><img src="../Images/a5e26d4bb8febf2114dc3f22689ad74d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TmAgtDC51Wv1ABw6OI81hg.png"/></div></div></figure><p id="cb63" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">该模型利用卷积层作为鉴别器和发生器的主要神经网络。由于midi文件是具有随时间推移而变化的不同频率的文件，因此每个midi文件都可以转换为二维数组，其中x轴表示时间步长，y轴表示音符的不同音高。在这种情况下，我们可以很容易地将2-D阵列视为要在基于卷积神经网络的GAN模型中训练的图像。</p><p id="6f42" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">生成器由一个具有许多神经元的全连接层组成，其后是四个卷积层，这些卷积层逐渐将数据向量的形状修改为所需的数据形状。发生器的最终输出形状将是生成的音乐的形状。这里，我们将输出形状设置为1000乘以84，其中1000代表音乐17中的时间步长数，84代表音高数。值得注意的是，为了节省计算成本，音调的数量被设置为84。由于几乎所有作品的音符和和弦都在midi索引24到108之间，总共包含84个音符，因此最好截断不必要的0以加快训练过程。在训练和生成过程之后，生成的片段将被添加到两个0数组中，成为大小为1000乘128的数组。每个卷积层的内核大小为5乘5，步长为(2，1)、(1，2)或(2，2)以适应最终的图像形状。最后一个卷积2D转置层使用tanh作为激活函数来确定每个神经元的最终输出。</p><p id="79c4" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">鉴别器包含两个卷积层和一个全连接层。每个卷积层的内核大小为5乘5，步长为(2，2)，与生成器的设置类似。</p><h2 id="e3a2" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">3.3 Midi文件的一键编码</h2><p id="64e1" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">一键编码是将分类信息转换为二进制形式的过程，表示在特定时间步长内，只有该信息的值(1)高于其他不相关信息的值(0)。例如，在特定的时间步长t中，演奏音符“C4 ”,则时间步长t上的数据向量将在该向量中的特定位置包含一个1，其对应于音符“C4 ”,具有127个0，考虑了128个唯一音符。由于音符和和弦被分类存储在所有midi文件中，因此所有此类信息将通过一键编码进行处理，以获得更好的模型训练性能。两个神经网络模型将使用这种技术用相同的训练数据集来训练。</p><h2 id="6edd" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">3.4评估指标</h2><h2 id="b663" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">3.4.1弗雷歇起始距离(FID)</h2><p id="c2a2" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">弗雷歇初始距离(FID)被设计用于评估由具有真实数据的GAN模型产生的生成结果(虚假数据)。计算评估分数的公式如下所示。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mf"><img src="../Images/355cf13de296049f4bd181db3fb7f8f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*tyLSIl7rasZk3gs4j8eVsA.png"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ma"><img src="../Images/f0c7f5bc232c84f824684a57a269f9ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uG3xJTA5_2OKxBFBkpZ9uw.png"/></div></div></figure><h2 id="4af1" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">音高直方图</h2><p id="16f5" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">音符一致性和音符多样性可以通过绘制音高直方图来可视化。音高直方图是通过以直方图形式对音符和弦的每个唯一频率计数求和而绘制的。人们认为这是对不同音乐流派进行分类的有效措施。在这个项目中，它可以用作区分所有模型生成的所有音乐片段的时代的工具。</p><h2 id="a462" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">最近邻搜索</h2><p id="6d93" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">检查生成的片段和来自训练集的片段之间是否有任何相似性的一种方法是通过搜索该生成的片段的最近邻。通过计算生成的片段和来自训练集的所有片段之间的均方根误差，我们应该通过搜索最低误差来检索最接近的片段。</p><h1 id="29d0" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">4方法和实施</h1><h2 id="d3b0" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">4.1 Midi文件预处理</h2><p id="27c3" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">该项目使用Music21和Pypianoroll python库将所有midi文件中的信息提取到音符和和弦序列中。它们的音高和八度音程对应每个时间步长。由于这个项目的范围只包括单个乐器的生成，所以训练数据将只包含钢琴演奏的音乐片段。</p><p id="4b5c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">所有的训练数据都是从字节跳动GitHub库的GiantMIDI-Piano库中获取的。根据他们的文档，有10854个古典音乐的midi文件可用。然而，在数据清理和分类过程之后，在获取的数据集中发现了重复和空文件。最终的数据集包含546首巴洛克音乐、412首古典音乐、637首浪漫音乐和238首现代主义音乐。</p><p id="09db" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">每个四个类别的音乐片段然后被独立处理。提取并连接所有的音符和和弦，该程序将形成一个字典，记录每个独特的音符和和弦(音符的组合)与索引。例如，音符“A2”与索引“0”成对出现，和弦“C#3”与索引“1”成对出现。以后会简化onehot编码的过程。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mg"><img src="../Images/2882ee0c8ea849ec62ef3f2271547576.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*FcgkFHyoIpxMHeZ7Tddl7w.png"/></div></figure><p id="9875" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">由于LSTM模型从给定的序列及其下一次预测中学习，因此需要一个额外的过程来构建一系列序列及其相应的输出(下一次预测)。这个项目将序列长度设置为50，这意味着LSTM网络学习在给定其前50个音符或和弦的情况下预测下一个音符。首先，程序将存储前50个音符或和弦，然后根据前面构建到输入序列数组中的唯一音符-和弦字典将它们转换为整数。最后序列20的下一个相应的音符或和弦然后被存储在输出数组中。检索所有音符和和弦序列，输出数组中的每个元素都在0和1之间归一化，以便于后面的训练过程。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mh"><img src="../Images/4d6040bdaa50925a02acce29800718ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8OxdiDG-PkXn0wI_MkRudw.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mi"><img src="../Images/cf016faaaedeb8b43a120f93e1319150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MUpPZTv4BntkJL71PCo8Iw.png"/></div></div></figure><p id="2cc3" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">将midi文件视为图像，基于CNN的GAN模型可以有效地生成在垂直和水平方向上都具有合理结构的音乐。输入训练数据包含2-D数组，可以将其视为只有两种颜色的图像数组。x轴表示时间步长，y轴表示音符(和和弦)的不同音高。假设一个音符或和弦出现在任何时间步长中，该特定时间步长的数组存储“1”。另一方面，空音符用“-1”表示。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mj"><img src="../Images/f01490e6a1fee53e2d7c30bc6859e032.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9EzJdnCTznUWTpe1NoqFVA.png"/></div></div></figure><p id="7a59" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">最后一步是将所有图像存储到一个形状为(x，y，z)的NumPy数组中，其中x表示唯一音乐片段的数量，y表示每个训练片段的时间步长，z表示音符的范围。在这个项目中，为了简单起见，阵列形状设置为(x，1000，84 ),因为目标是评估CNN-GAN模型生成结构化音乐和有意义旋律的能力，而不是生成通常需要过多计算能力来完成任务的长片段。在标准的Midi表达中，总共有128个音符。然而，通过观察来自训练集的所有图像，它们中的大多数仅具有从最小C1(索引24)到最大C7(索引108)的音符跨度。这意味着索引24以下和索引108以上的音符可以被忽略，因为它们是空音符，不利于后面的训练过程。因此，在训练之前对所有图像进行修剪处理。它产生(x，1000，84)的最终输入数据形状，其中x表示独特音乐片段的数量。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es me"><img src="../Images/a24146090a8054d2e2a81c7138969270.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7miDh61xbLKMwa7uFy4VfA.png"/></div></div></figure><h2 id="7a1d" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">4.1模型构建</h2><p id="9685" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">在这个项目中，所有的神经网络都将使用TensorFlow库及其更高级的API — Keras API用python编程。高级Keras API允许更快地实现任何神经网络。一般来说，开发者只需要提供训练数据的输入形状、损失函数、优化器和一些特定的超参数。</p><h2 id="da80" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">4.1.1深度双向LSTM RNN</h2><p id="a078" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">该模型的当前实现是将一个双向LSTM层和两个LSTM层堆叠在一起。接着是两个完全连接的层。每个LSTM层包含256个节点，之后的丢失率为0.3。在最后一个LSTM图层和第一个完全连接的图层之后，将添加批量归一化。第一个完全连接的层包含128个具有整流线性激活函数(ReLU)的节点。最后一层包含x个节点，其中x由来自训练语料库的不同音符或和弦确定。因为已知如果音符或和弦不在训练语料库内，它将不会出现或在将来被神经网络预测，所以我们可以以这种方式安全地实现最终的完全连接层，以节省存储器和计算时间。该模型是用交叉熵损失的损失函数和RMSprop为其优化器编译的。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mk"><img src="../Images/916016df12ecb97aebb3da62e8593b20.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/format:webp/1*mBorH11j_hb333uwmtrqWA.png"/></div></figure><p id="4619" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">类似于训练步骤，预测网络拥有与训练模型相同的结构。唯一的区别是来自训练过程的最后一个时期的最佳权重被添加到神经网络中用于序列预测。</p><p id="2772" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">生成随机数作为确定预测序列的起始点的索引，以基于训练集预测音乐序列。音符初始序列的长度也是预先确定的。决定了上述设置后，模型可以在预测的每次迭代中预测单个音符或和弦(一组音符)。</p><p id="83f9" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在每次迭代中，模型通过选择该元素(音符或和弦)的最高概率来预测输入序列的下一个音符或和弦。然后，最有可能成为序列中下一个元素的音符或和弦将被连接到前一个序列。同时，该序列的第一个元素将在下一次迭代之前被删除。这允许窗口大小(序列长度)与从预测开始滑动到结束的窗口相同。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ml"><img src="../Images/19f75e470cf53cfb4839553b49eb8f75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jGtfAAitCkgJRrNvSokGkA.png"/></div></div></figure><h2 id="ed69" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">4.2.2 CNN基GAN</h2><p id="d790" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">这个CNN-GAN模型由两个神经网络组成——一个鉴别器和一个生成器。两个网络都通过计算预测标签和真实标签之间的差异来采用交叉熵损失作为它们的损失函数。由于生成器试图通过生成假图像来欺骗鉴别器，使鉴别器难以辨别真伪，因此生成器的损失函数将鉴别器对假图像的决策与一系列决策进行比较。至于鉴频器，有两步(两次损耗)。它将真实图像与一组1进行比较，将虚假图像与一组0进行比较。将两种损耗相加，得出鉴频器的总损耗。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mm"><img src="../Images/3255c7104e9885aa8e9168be92750f7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z55efrRTRxbo67FdklD0Lw.png"/></div></div></figure><p id="c336" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">生成器的网络结构从引入一个小的随机种子作为输入开始，输入到一个具有大得多的输出大小的全连接层。对输出数据进行整形后，四个转置卷积层堆叠在一起，以对数据进行上采样。每个卷积层具有5的核大小(高度和宽度)和(2，1)或(1，2)或(2，2)的步长，以对数据进行上采样，从而满足输入数据的相同形状(1000，84)。填充是相同的，以保持数据的原始大小。最后，除了最后一层使用tanh作为激活函数之外，所有层之后都是LeakyReLU激活层。</p><p id="f2dc" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">另一方面，与发生器相比，鉴别器的神经元层较浅。它在开始时有两个卷积层，每个卷积层都有一个5乘5的内核和一个2的步长。最后，具有单个输出的完全连接的层确定这个输入图像是来自训练集(真实的)还是来自生成器(虚假的)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mn"><img src="../Images/f2ea59d60217d5d13a7fe136fc5573cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gtOyIal9ojtrb-X_M5Ii9g.png"/></div></div></figure><h2 id="a32f" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">4.2数据转换</h2><p id="2fb5" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">对于双LSTM模型，在生成新的数字序列之后，序列中的所有元素将首先通过参考来自训练集的唯一的一组音符和弦来相应地转换成音符或和弦的表示，然后转换成Midi格式的音符或和弦。这里，需要指定音符数和和弦的限制，速度也是如此。以现代主义音乐为例:最多300个音符，音符间偏移0.3是很好的设置。这里，偏移控制音乐的速度。数字越大，速度越慢，反之亦然。</p><p id="d46e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">对于CNN-GAN模型，最后一步是将大小为(1000，84)的数组转换回Pypianoroll库可接受的数据格式(1000，128)，然后将其转换为midi文件。预测数组连接一个大小为(1000，24)的空数组，组合数组由另一个大小为(1000，20)的空数组连接。</p><h2 id="be49" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">4.3评估</h2><h2 id="90e3" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">音高直方图</h2><p id="49db" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">使用音高直方图来分析生成的音乐的目的是，该图是可视化给定音乐片段的音符相似性和差异性的有效方式。通过计算乐曲中出现最频繁的音符，通常可以确定乐曲。然而，假设大多数音符只属于几个(1或2个)音符类别。在这种情况下，它可能表明音乐生成的失败，因为几乎大多数作品都具有特定的音符分布多样性。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mo"><img src="../Images/cf87a45e32cfa6fdec7fa3a9c7e82b44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*thHO4VY3XUy0HoyM3rvIAQ.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mp"><img src="../Images/9d1b4dd2f286c43e78453e9eab24b6da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1jew5GgfF3DQ2Zvqd8KGXA.png"/></div></div></figure><h2 id="4883" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">4.3.2 FID</h2><p id="4c46" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">计算FID分数需要两个组成部分——真实图像集和生成的图像。对于每个流派，来自训练集的所有音乐都属于“真实”图像集，而生成的图像属于“生成”图像集。将为“真实”和“生成”集提取的特征是图像本身的一部分，并且将只提取每个图像的一部分。片段是具有(400，48)形状的图像，其中400表示时间步长，48表示音符范围。将音符范围设置为48的原因是，从观察来看，大多数音符和弦都落在这个范围内，从训练集中检索每首音乐的特征可以节省大量计算成本。接下来，首先计算“真实”和“生成”集合的所有特征向量的平均值和所有特征向量的协方差矩阵。然后可以从下面的等式中检索FID分数。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mq"><img src="../Images/70ba20dd0872ce6c310d5e7eb18a0ae9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*T-Azdso54HlKiSwvyHjjeg.png"/></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mr"><img src="../Images/4afe8f1117a349ed699066256b737c33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jokxwC5OxOoSgIn0HL6jWQ.png"/></div></div></figure><h2 id="3202" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">调查</h2><p id="5cca" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">我们进行了两项调查来评估Bi-LSTM和GAN模型的结果，这两项调查都是在第三方调查平台phonic.ai上进行的。每项调查都包含八个选择题，每个问题只有一个答案。受访者需要播放调查每页提供的音频，并选择他们听到的音乐是由人类作曲家还是人工智能算法创作的。如果他们觉得无法决定，他们可以选择“我不知道”选项。它允许回答者仔细回答每个问题，并希望尽量减少他们猜测的机会，这可能会降低调查结果的质量。</p><p id="4e5e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">从每个流派和每个类别(“真实的”和“生成的”)中选择一个片段，并且只有该片段的摘录(15到30秒之间)可供回答者使用，因为让回答者在调查中听完整个片段会使他们疲劳，并因此恶化调查结果。在每次调查中,“真实的”和“生成的”音乐的数量是平衡的，并且为了公平随机排序。下面的片段是一个问题的例子。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ms"><img src="../Images/aeee2e9f12b366d69575460ee0919044.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DkhWkCV9ZL5EnX9Ljzmw9Q.png"/></div></div></figure><h1 id="d123" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">5结果和评估</h1><h2 id="282a" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">5.1深度双向LSTM RNN</h2><h2 id="bc14" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">5.1.1注意多样性和分析</h2><p id="422a" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">下面是四个不同风格的生成音乐的例子。从巴洛克、古典风格开始，接着是浪漫主义和现代主义风格。下面显示的结果证明了双LSTM模型通过从给定的训练集中学习来创作新颖音乐段落的能力。</p><ul class=""><li id="0a78" class="mt mu hi jp b jq jr jt ju jw mv ka mw ke mx ki my mz na nb bi translated">一个生成的巴洛克风格音乐的例子</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nc"><img src="../Images/0aaed11eef063f01ff7c2d891d2e4c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dZ_7F6mQrh57vUwT5PmrJg.png"/></div></div></figure><p id="7d1c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">根据音高直方图(Figure 5–6左上角)，很明显，音符在大调音阶中均匀分布，但没有多少升半音。虽然直到巴洛克时期晚期，调号才发展到目前的状态，通常为每首音乐作品定义了调号，但这种生成的音乐作品的音符多样性相对均匀，考虑到这种音乐类型的性质，这是可以接受的。此外，从上面显示的乐谱摘录来看，这首乐曲没有复杂的复调音乐结构，而是表现出了独奏曲的迹象。</p><ul class=""><li id="fe3f" class="mt mu hi jp b jq jr jt ju jw mv ka mw ke mx ki my mz na nb bi translated">一个生成古典风格音乐的例子</li></ul><p id="1a7b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这个时代的音乐通常使用简单的和声旋律来实现平衡的音乐结构。这种创作理念在贝多芬的音乐中经常出现。下面生成的音乐演示了类似华尔兹的相似主题(音乐短语或结构)的重复，这对应于古典时代最常见的音乐创作思想之一。在我看来，这是最成功的作品之一，类似于贝多芬的音乐。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nd"><img src="../Images/7fdc88fa37d0e8c0114548a24818f9ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Xpj9RFhqvsKzEccidVInQA.png"/></div></div></figure><ul class=""><li id="6e3d" class="mt mu hi jp b jq jr jt ju jw mv ka mw ke mx ki my mz na nb bi translated">一个生成浪漫风格音乐的例子</li></ul><p id="8c64" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">根据Music 21库分析，下面这段音乐的预期调是C小调，置信度为70.2%，这与下面的音高直方图精确对应。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ne"><img src="../Images/6492e9d86387a0be1bd5303bcb47f1d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cP6Kj3bE255x_e1H7szhag.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mi"><img src="../Images/1e028369f34b8f6f34a6e88eb8b98857.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OoVnVXJTSbuzGyIiz1dyEg.png"/></div></div></figure><ul class=""><li id="c036" class="mt mu hi jp b jq jr jt ju jw mv ka mw ke mx ki my mz na nb bi translated">一个现代风格音乐的例子</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nf"><img src="../Images/90af5d989aeff427e0339d2d320ba6e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5e9qQmoQwWQl9WaBn1SioQ.png"/></div></div></figure><ul class=""><li id="558f" class="mt mu hi jp b jq jr jt ju jw mv ka mw ke mx ki my mz na nb bi translated">四个生成片段的音高直方图</li></ul><p id="9bcf" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">从下图中，我们可以观察到所有的作品都有不同的音高分布。没有一个音高能明显地支配整首曲子。因此，可以得出结论，双LSTM模型很好地处理了音符多样性，并且不倾向于记忆来自训练集的部分信息。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ng"><img src="../Images/85d9651dfbc9ba138bed7957d9e51145.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eTdQLkSfAUJ4yplFel8P0Q.png"/></div></div></figure><h2 id="9d41" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">调查</h2><p id="638e" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">从下面的堆积柱形图中可以明显看出，超过一半的受访者很难判断给定的音乐是由人工智能还是人类创作的。在所有由人类创作的作品中，只有一半得到超过百分之五十的置信度，表明它们是由人工智能创作的。由人工智能创作的所有作品的结果都是一样的。虽然一些受访者认为“真实”的音乐是由人工智能创作的，但统计数据显示，当让大多数受访者听人工智能创作的音乐时，他们选择了“真实”。这表明提出的双LSTM模型具有欺骗人类判断的能力。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nh"><img src="../Images/38f1a0deebde1e13f4e82e58e9011636.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-vvuYqmFIoTQqPUnK_BBig.png"/></div></div></figure><h2 id="463a" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">5.2生成性对抗网络</h2><h2 id="7900" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">弗雷歇初始距离</h2><p id="ecab" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">生成的四个片段由FID评分进行评估。在下表中，第一行FID是生成的片段和训练集的FID分数，第二行FID (random)是随机片段(图像)的FID分数，它代表GAN训练过程和训练集的初始状态。由于FID分数越低，片段(图像)与训练集越相似，因此我们可以观察到，每个生成的片段的FID分数远低于与之对应的随机片段的FID分数。因此，我们可以说，生成的片段看起来与训练集中的片段相似，这意味着GAN模型很好地模仿了训练集中的音乐。</p><p id="161c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">可能影响FID分数的主要因素可能是特定训练集中的片段数量、片段本身以及为FID评估提取的特征。此外，与通常使用预训练的InceptionV3模型评估生成图像质量的其他图像生成任务不同，由于项目的性质，本项目不采用该模型作为FID分数计算的一部分。生成的片段与具有RGB颜色通道并与ImageNet标签相关联的传统图像并不完全相同。因此，在这种情况下，我认为FID分数是模型性能的参考，而不是确定生成的音乐作品好坏的硬性标准。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ni"><img src="../Images/0cb83795385130823b0a4130f2f213e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Azqr5byJB2-uzYtRh49vw.png"/></div></div></figure><h2 id="3e64" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">5.2.2注意多样性和分析</h2><p id="9cb4" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">下面是四个不同风格的生成音乐的例子。从巴洛克、古典风格开始，接着是浪漫主义和现代主义风格。下面显示的结果证明了GAN模型通过从给定的训练集学习来创作新颖的音符/和弦和结构的能力。</p><ul class=""><li id="d9c0" class="mt mu hi jp b jq jr jt ju jw mv ka mw ke mx ki my mz na nb bi translated">一个生成的巴洛克风格音乐的例子</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ni"><img src="../Images/71c9985493cdbd65ecfb3a7971b11fd5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XQhtkMsbtlBSHbXK_H9wCg.png"/></div></div></figure><p id="0a8a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">从上面的巴洛克-1-甘乐谱摘录中，我们可以观察到一些令人印象深刻的音乐结构，它们比巴洛克-1-比-LSTM更复杂。一个值得注意的特点是，当看一个小节时，上五线谱和下五线谱都有自己的旋律，或者至少下五线谱是上五线谱的伴奏。相比之下，双LSTM模型没有展示这种特征。相反，它将所有重合的和弦或音符组合成一个整体，并将其表示为一个和弦。虽然这可能不会简化音乐结构，但GAN模型可能是一个更好的选择，可以生成更复杂的音乐结构和更可读的乐谱。</p><p id="d115" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">检查生成的片段和来自训练集的片段之间是否有任何相似性的一种方法是通过搜索该生成的片段的最近邻。通过计算Baroque-GAN-1和来自训练集的所有片段之间的均方根误差，我们通过搜索最小误差来获得最接近的片段。下面是Baroque-GAN-1(生成的作品)和通过前面提到的计算找到的最接近的作品之间的比较。观察这两部作品的旋律模式，我们可以说这两部作品在发展连续琶音方面有相似的倾向。这是一个很好的迹象，表明甘模型的学习能力，而不是完全复制训练集的音乐短语。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nj"><img src="../Images/af65c85474ead59685ebfa0642a04e49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DWbKZRz28xsSZVHzwHoJCQ.png"/></div></div></figure><ul class=""><li id="784c" class="mt mu hi jp b jq jr jt ju jw mv ka mw ke mx ki my mz na nb bi translated">一个生成古典风格音乐的例子</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nk"><img src="../Images/011a8cec971cab8da66adb95d6e8cffa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*knpKkLXK_PotUQV9VF7V4g.png"/></div></div></figure><p id="3d01" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">从最近邻搜索来看，经典-1- GAN与其最近片段之间的相似性不明显。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nl"><img src="../Images/98a282aef570ce7343017c002bd37597.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VoyBYAVVK3zbrVPyqz9uUg.png"/></div></div></figure><ul class=""><li id="8615" class="mt mu hi jp b jq jr jt ju jw mv ka mw ke mx ki my mz na nb bi translated">一个生成浪漫风格音乐的例子</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nm"><img src="../Images/eff0fcc715e16f7f234d9ea4f16c1ad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KcgZcUJEYlViWgtK58fSGA.png"/></div></div></figure><p id="5ed7" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">从上面的乐谱中值得注意的一点是红色框中的键。正如前面在双LSTM部分提到的，浪漫风格的音乐通常有多个降半音。此外，比较Romantic-1-GAN和它最近的邻居片段，我们可以观察到两个片段都以相当稳定的音高沿着时间步长前进，没有太大的垂直音高变化。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nn"><img src="../Images/57dadf7e8daa6650912978f3def93f29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*joUtforiB9VYfK_rb3NcFg.png"/></div></div></figure><ul class=""><li id="c914" class="mt mu hi jp b jq jr jt ju jw mv ka mw ke mx ki my mz na nb bi translated">一个现代风格音乐的例子</li></ul><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es no"><img src="../Images/a053bdcb00addf7d98e17f0a6a37ca3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pIHdfIq2cJAJ-6o1BEH6VA.png"/></div></div></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es np"><img src="../Images/869de6bea28331bc9cbea57e207beb80.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AAcXExuW_qvQnngyFoGc9Q.png"/></div></div></figure><p id="f43a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">很多时候，现代主义音乐拒绝调性。它的音乐不固定在任何“调”上，总是倾向于感觉不稳定或“偏离”观察上面的乐谱，听它的配乐，我也是这么想的。与巴洛克或古典音乐等其他音乐风格不同，现代主义音乐在作曲时不需要遵循严格的规则。它被鼓励通过在音乐中注入创新来挑战“传统”。因此，根据所提出的甘模型的性质，我们不需要担心所产生的音乐的令人不安的旋律或节奏。</p><ul class=""><li id="6d03" class="mt mu hi jp b jq jr jt ju jw mv ka mw ke mx ki my mz na nb bi translated">四个生成片段的音高直方图</li></ul><p id="e681" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">根据下面的音高直方图，所有四首曲子都有多个主调，这是音符多样性的一个好迹象。GAN模型不生成特定的音符，而是按比例预测以几个键为主的音符。这是一个好的迹象，因为甘模型使它类似于人类的作曲风格。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lw"><img src="../Images/bc6dea0109a7593e4caf84233581795c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CfBtQHp8x1_rI8VtMf1UXA.png"/></div></div></figure><h2 id="1f11" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">调查</h2><p id="ca93" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">下图是GAN模型的概况。虽然大多数受访者可以清楚地区分“真实”音乐和“人工智能”音乐，但仍有一部分受访者(平均33.4%)无法识别他们的作品是由人工智能还是人类创作的。这是通过对每一个给定的选项的百分比总和进行平均计算得出的，这些选项包括“无法判断”和错误的选项(“人工智能”或“人类”)。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es nq"><img src="../Images/94cbce4959e5d9e1259a48ed05697413.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x46gF0fw29lji2W6vhdjCg.png"/></div></div></figure><h1 id="61fb" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">6结论</h1><h2 id="d50c" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">6.1成就</h2><p id="2ce0" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">从双LSTM模型生成的结果展示了制作古典音乐的强大能力，大多数人很难分辨它们是由人还是由人工智能创作的。双LSTM模型被证明能够产生从连续的角度来看有意义的音乐。</p><p id="ceb9" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">将音符和和弦的序列视为2D阵列的新概念被证明是训练数据集的可行设计。这种输入数据形状允许生成对抗网络以与生成图像相同的方式生成音乐。通过扩大训练集的维度(1000乘84)，它也可以产生比以前的研究(4乘128)长得多的时间步长的音乐。</p><p id="37c8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在四个古典音乐时代中，我发现双LSTM模式适合产生巴洛克、古典和一些浪漫音乐，这是由于双LSTM模式的设计和这些音乐风格的性质。这些类型的音乐需要严格的规则，没有现代音乐复杂。LSTMs的设计非常适合完成这些任务。另一方面，GAN模型在生成音乐方面似乎更具创造性和随机性。因此，我认为它适合创作现代主义音乐。</p><h2 id="539d" class="lh kl hi bd km li lj lk kq ll lm ln ku jw lo lp kw ka lq lr ky ke ls lt la lu bi translated">6.2未来的改进</h2><p id="676d" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">为了进一步提高所生成的音乐的质量，建议对训练集进行扩充和进一步细化。虽然这个项目的训练集包括数百首midi格式的古典音乐，但大多数midi文件都是现场录制的，这意味着一些背景噪音也可能在原始演奏期间与音乐一起录制，这可能会影响制作midi文件的精度。例如，当使用“MuseScore”软件可视化数据集中的一些乐谱时，很明显会观察到与原始乐谱相比过多的音符和和弦。这可能是一个潜在的原因，损害了后来的训练过程，但是，进一步的试验和检查需要证明这一假设。此外，数据清理过程是必不可少的，因为我从数据集中发现了许多重复和无效(空)的音乐。</p><p id="ceff" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">据信，双LSTM模型优于单向LSTM模型从以前的研究。然而，单向LSTM模型和双LSTM模型之间的性能比较应在未来进行，以证实这一论点。</p><h1 id="f1d6" class="kk kl hi bd km kn ko kp kq kr ks kt ku io kv ip kw ir kx is ky iu kz iv la lb bi translated">7参考文献</h1><p id="813c" class="pw-post-body-paragraph jn jo hi jp b jq lc ij js jt ld im jv jw le jy jz ka lf kc kd ke lg kg kh ki hb bi translated">纽约州布朗热-莱万多夫斯基、纽约州本吉奥和文森特出版社(2012年)。高维序列中时间相关性的建模:复调音乐生成和转录的应用。arXiv预印本arXiv:1206.6392。</p><p id="0de7" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Briot，J. P .，Hadjeres，g .，&amp; Pachet，F. D. (2017年)。音乐生成的深度学习技术--一项调查。arXiv预印本arXiv:1709.01620。</p><p id="3df6" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Choi，k .、Fazekas，g .、Sandler，M. (2016年)。基于文本的自动音乐创作LSTM网络。arXiv预印本arXiv:1604.05358。</p><p id="db34" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">董洪伟，萧伟英，杨立成，杨耀辉(2017)。MuseGAN:用于生成多轨道钢琴卷的基于卷积GAN的模型的演示。ISMIR最新消息/演示。</p><p id="3110" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">埃克博士和施密德胡伯律师事务所(2002年)。使用lstm递归神经网络的音乐创作初探。人工智能研究学院，103，48。</p><p id="0899" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Goodfellow，I .、Pouget-Abadie，j .、Mirza，m .、Xu，b .、Warde-Farley，d .、Ozair，s .、… &amp; Bengio，Y. (2014年)。生成对抗网络。神经信息处理系统进展(第2672-2680页)。</p><p id="bef1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">哈杰雷斯，g .，帕切特，f .，&amp;尼尔森，F. (2017，7月)。Deepbach:巴赫合唱曲生成的可操纵模型。在机器学习国际会议上(第1362-1371页)。PMLR。</p><p id="291d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Hochreiter，s .，&amp; Schmidhuber，J. (1997年)。长短期记忆。神经计算，9(8)，1735-1780。</p><p id="0e08" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">穆尔，J. A. (1972年)。音乐和电脑作曲。美国计算机学会的通讯，15 (2)，104-113。47</p><p id="261a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">屏蔽器。(2016).洋红色/洋红色。GitHub。<a class="ae kj" href="https://github.com/magenta/magenta/tree/master/magenta/reviews" rel="noopener ugc nofollow" target="_blank">https://github . com/magenta/magenta/tree/master/magenta/reviews</a></p></div></div>    
</body>
</html>