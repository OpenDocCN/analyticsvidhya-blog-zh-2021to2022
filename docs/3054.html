<html>
<head>
<title>Regularization in Machine Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习中的正则化</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/regularization-in-machine-learning-7fb4e9d51f1d?source=collection_archive---------12-----------------------#2021-05-31">https://medium.com/analytics-vidhya/regularization-in-machine-learning-7fb4e9d51f1d?source=collection_archive---------12-----------------------#2021-05-31</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="9790" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">每个机器学习模型面临的一个关键问题是过拟合问题。那么什么是过度拟合，我们如何将其最小化？什么是正规化？到文章结束的时候，你就会清楚这些概念了。</p><p id="3c75" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了理解这些概念，我们必须回答以下问题</p><ol class=""><li id="7f81" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">什么是过度拟合？</li><li id="2f1b" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">什么是正规化？</li><li id="c722" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">正规化的类型</li></ol><h1 id="0831" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">1.什么是过度拟合？</h1><blockquote class="ko kp kq"><p id="3e9e" class="ie if kr ig b ih ii ij ik il im in io ks iq ir is kt iu iv iw ku iy iz ja jb ha bi translated"><strong class="ig hi">过度拟合</strong>发生在模型学习训练数据中的细节和噪声，以至于对新数据的模型性能产生负面影响的时候。</p></blockquote><p id="0fd0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对上述定义的简单解释是，过度拟合是指一个模型考虑了几乎所有的特征。当这种情况发生时，模型可能会“记住”这些特征。<strong class="ig hi">过度拟合也被称为方差。</strong>下图中的绿线代表过度拟合。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div role="button" tabindex="0" class="lb lc di ld bf le"><div class="er es kv"><img src="../Images/297df5c3d1c7e0684866ff74e8a6fb75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nF6MZQJ431vv-0AGKAj30g.png"/></div></div><figcaption class="lh li et er es lj lk bd b be z dx translated">图片来自<a class="ae ll" href="https://en.wikipedia.org/wiki/Overfitting" rel="noopener ugc nofollow" target="_blank">维基百科</a></figcaption></figure><p id="6174" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">解决过拟合的方法之一是<strong class="ig hi">正则化</strong>。</p><h1 id="26b0" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">2.什么是正规化？</h1><p id="a833" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">正规化的正式定义如下</p><blockquote class="ko kp kq"><p id="bcbd" class="ie if kr ig b ih ii ij ik il im in io ks iq ir is kt iu iv iw ku iy iz ja jb ha bi translated">这是一种回归形式，它将系数估计值约束/调整或缩小到零。</p></blockquote><p id="8b9f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">简而言之，正则化是一种考虑所有要素但限制这些要素对模型输出的影响的技术。让我们通过一个例子来理解这一点。</p><p id="6d4f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们用线性回归来举房价的例子。这个问题可能有很多特点需要考虑。为了简单起见，我们假设它有大约100个特性。在这个问题中，模型将试图考虑所有的特征来给出一个输出。这将最终导致模型“记住”数据集中的要素。因此，该模型在训练集中表现良好，但在测试集中表现很差，因为数据对它来说是新的。</p><p id="58ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这就是正规化发挥重要作用的地方。它确保模型考虑了特征，但使用超参数“正则化常数”λ来限制这些特征对输出的影响，并防止模型过度拟合。</p><h1 id="e3df" class="jq jr hh bd js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn bi translated">3.正规化的类型</h1><p id="4cd0" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">有3种类型的正规化。我们将在本文中讨论前两个问题</p><ol class=""><li id="412b" class="jc jd hh ig b ih ii il im ip je it jf ix jg jb jh ji jj jk bi translated">l1正则化</li><li id="023b" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">l2正则化</li><li id="7063" class="jc jd hh ig b ih jl il jm ip jn it jo ix jp jb jh ji jj jk bi translated">辍学正规化</li></ol><h2 id="2b75" class="lr jr hh bd js ls lt lu jw lv lw lx ka ip ly lz ke it ma mb ki ix mc md km me bi translated">1.l1正则化</h2><p id="bc9f" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">使用l1正则化的模型称为Lasso回归。Lasso回归(最小绝对收缩和选择算子)将系数大小的绝对值作为惩罚项添加到损失函数中。</p><p id="91e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">λ的值必须平衡。非常小的值将导致OLS(普通最小二乘法)，而非常大的值将使系数为零。因此，该模型将会不适合。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es mf"><img src="../Images/db3b8c02a48935699fa1389cc7bc3753.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*q0ekc8YEoIoFI7EfM2ZdfA.png"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">图片来自<a class="ae ll" href="https://stackoverflow.com/questions/58905671/compute-the-loss-of-l1-and-l2-regularization" rel="noopener ugc nofollow" target="_blank"> StackOverflow </a></figcaption></figure><h2 id="05bd" class="lr jr hh bd js ls lt lu jw lv lw lx ka ip ly lz ke it ma mb ki ix mc md km me bi translated">2.l2正则化</h2><p id="1712" class="pw-post-body-paragraph ie if hh ig b ih lm ij ik il ln in io ip lo ir is it lp iv iw ix lq iz ja jb ha bi translated">使用l2正则化的模型称为岭回归。这是应用较为广泛的技术之一。这种技术将系数的“平方值”作为损失函数的惩罚。这里，应该像l1正则化一样适当地选择λ的值。λ的小值将导致OLS，而大值将导致拟合不足的问题。</p><figure class="kw kx ky kz fd la er es paragraph-image"><div class="er es mg"><img src="../Images/90fb80be1c6da7495611faee4d1f0efe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*LJXbFDr8xHq72UOdkGrTDA.png"/></div><figcaption class="lh li et er es lj lk bd b be z dx translated">图片来自<a class="ae ll" href="https://stackoverflow.com/questions/58905671/compute-the-loss-of-l1-and-l2-regularization" rel="noopener ugc nofollow" target="_blank"> StackOverflow </a></figcaption></figure><blockquote class="ko kp kq"><p id="d87c" class="ie if kr ig b ih ii ij ik il im in io ks iq ir is kt iu iv iw ku iy iz ja jb ha bi translated"><strong class="ig hi">注</strong>:这两种技术的主要区别在于惩罚期限。</p></blockquote><p id="f410" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">关于l1正则化(或套索)回归需要注意的一个关键点是，它<strong class="ig hi">将不太重要的特征收缩为零</strong>，这对于<strong class="ig hi">特征选择</strong>非常有用。</p></div><div class="ab cl mh mi go mj" role="separator"><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm mn"/><span class="mk bw bk ml mm"/></div><div class="ha hb hc hd he"><p id="5efa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">总之，有几种其他方法可以解决过拟合问题，但是上面讨论的技术对于大型数据集非常有效。</p></div></div>    
</body>
</html>