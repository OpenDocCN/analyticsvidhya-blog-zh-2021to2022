<html>
<head>
<title>Simple CNN using NumPy Part V (Back Propagation Through Max pool Layer &amp; Convolutional Filter)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用NumPy Part V的简单CNN(通过最大池层和卷积滤波器的反向传播)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/simple-cnn-using-numpy-part-v-back-propagation-through-max-pool-layer-convolutional-filter-7c434a7addd4?source=collection_archive---------17-----------------------#2021-06-20">https://medium.com/analytics-vidhya/simple-cnn-using-numpy-part-v-back-propagation-through-max-pool-layer-convolutional-filter-7c434a7addd4?source=collection_archive---------17-----------------------#2021-06-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div class="er es hf"><img src="../Images/69c29457efab1e78ebcba171c589b704.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*noL5Bt0f-OHu-9D4RmKIzw.png"/></div></figure><div class=""/><p id="11e5" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在之前的博文中，我试图解释以下内容</p><ul class=""><li id="89c9" class="jj jk ho in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><a class="ae js" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-i-introduction-data-processing-b6652615604d">介绍CNN和数据处理</a></li><li id="d4c2" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><a class="ae js" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-ii-convolution-operation-b8c5a02b0844">卷积运算</a></li><li id="fa0f" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><a class="ae js" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-iii-relu-max-pooling-softmax-c03a3377eaf2"> ReLU、Maxpooling和Softmax </a></li><li id="f8a4" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><a class="ae js" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-iv-back-propagation-through-fully-connected-layers-c5035d678307">通过全连接层的反向传播</a></li></ul><p id="09ef" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在这篇文章中，我将尝试通过最大池和卷积层来介绍反向传播。我们一直在计算梯度，直到第一个完全连接的层。让我们通过下面的手绘图片再次参观这个建筑</p><figure class="jz ka kb kc fd hj er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es jy"><img src="../Images/1638dad39ab1933bdb3d6907f6552acd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kFopeGg-JgnZ4AatPEy8DA.png"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">CNN的体系结构</figcaption></figure><p id="79f4" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">到目前为止，我们已经计算了展平层的梯度。</p><p id="0c52" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">我们现在需要计算神经网络其余部分的梯度。</p><h1 id="1968" class="kl km ho bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">计算最大池层的坡度</h1><p id="8c11" class="pw-post-body-paragraph il im ho in b io lj iq ir is lk iu iv iw ll iy iz ja lm jc jd je ln jg jh ji ha bi translated">假设第一个完全连接的层是最大池层的整形版本，我们只需要在第一个完全连接的层整形我们的渐变矩阵，回到最大池层的形状。相同的代码片段如下</p><pre class="jz ka kb kc fd lo lp lq lr aw ls bi"><span id="bdc2" class="lt km ho lp b fi lu lv l lw lx">delta_maxpool = delta_0.reshape(X_maxpool.shape)</span></pre><h1 id="1f62" class="kl km ho bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">计算卷积层的梯度</h1><p id="23b4" class="pw-post-body-paragraph il im ho in b io lj iq ir is lk iu iv iw ll iy iz ja lm jc jd je ln jg jh ji ha bi translated">最大池操作使用固定大小的过滤器来提取与过滤器大小相同的图像区域中的最大像素值。该滤波器使用两个用户定义的参数在图像上移动:步幅和滤波器大小。</p><p id="8534" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">为了计算卷积层的梯度，我们需要将每个梯度元素移回卷积层中提取最大像素值的位置。</p><pre class="jz ka kb kc fd lo lp lq lr aw ls bi"><span id="b8b6" class="lt km ho lp b fi lu lv l lw lx">delta_conv = np.zeros(X_conv.shape)<br/>for image in range(len(max_indices)):<br/>     indices = max_indices[image]<br/>     for p in indices:<br/>          delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]<br/>delta_conv = np.multiply(delta_conv,dReLU(X_conv))</span></pre><h1 id="7b5a" class="kl km ho bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">计算卷积滤波器的梯度</h1><p id="3e66" class="pw-post-body-paragraph il im ho in b io lj iq ir is lk iu iv iw ll iy iz ja lm jc jd je ln jg jh ji ha bi translated">现在我们已经找到了卷积层的梯度，我们需要计算卷积滤波器的梯度。这将用于优化每个学习步骤中的滤波器。</p><h2 id="bd72" class="lt km ho bd kn ly lz ma kr mb mc md kv iw me mf kz ja mg mh ld je mi mj lh mk bi translated">计算误差的简单伪代码</h2><p id="b332" class="pw-post-body-paragraph il im ho in b io lj iq ir is lk iu iv iw ll iy iz ja lm jc jd je ln jg jh ji ha bi translated">设<strong class="in hp"> <em class="ml"> G </em> </strong>为卷积层的梯度矩阵。它的维数为(1，2，24，24)。设<strong class="in hp"> <em class="ml"> I </em> </strong>为shape (1，1，28，28)的输入图像。</p><ol class=""><li id="2cf5" class="jj jk ho in b io ip is it iw jl ja jm je jn ji mm jp jq jr bi translated">对于给定的通道<strong class="in hp"> <em class="ml"> C </em> </strong>在<strong class="in hp"> <em class="ml"> G </em> </strong>中，挑选一个元素</li><li id="8a32" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji mm jp jq jr bi translated">使用步幅=1的5X5过滤器创建5X5的图像输入块<strong class="in hp"> <em class="ml"> I. </em> </strong></li><li id="9606" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji mm jp jq jr bi translated">将选择的渐变元素与连续的块相乘，并将它们相加。</li><li id="06b3" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji mm jp jq jr bi translated">连续相加操作后的结果矩阵是与卷积滤波器中的通道<strong class="in hp"><em class="ml">【C】</em></strong>相关联的梯度。</li><li id="88d6" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji mm jp jq jr bi translated">对<strong class="in hp"><em class="ml"/></strong>中的其余通道重复步骤1至4</li></ol><p id="b310" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">上面的伪代码是针对单个图像的，我们需要对整批图像重复这个过程。</p><p id="69d2" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">下面这张来自<a class="ae js" href="https://hackmd.io/@bouteille/ByusmjZc8#III-Backward-propagation" rel="noopener ugc nofollow" target="_blank"> HackMD </a>的GIF图更好地解释了这个过程</p><figure class="jz ka kb kc fd hj er es paragraph-image"><div role="button" tabindex="0" class="kd ke di kf bf kg"><div class="er es jy"><img src="../Images/905f91c21ee7b4ef71d11bf75eee503a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*yKEMV-2M255WM2O0xOjsLw.gif"/></div></div><figcaption class="kh ki et er es kj kk bd b be z dx translated">通过卷积滤波器反向传播的图解说明</figcaption></figure><p id="7fd5" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">假设我们必须通过像素找到卷积滤波器的梯度，这个过程将花费大量的时间和精力。解决这个问题的一个方法是使用im2col()函数。</p><h2 id="a3f1" class="lt km ho bd kn ly lz ma kr mb mc md kv iw me mf kz ja mg mh ld je mi mj lh mk bi translated">快速计算卷积滤波器梯度的伪码</h2><p id="438f" class="pw-post-body-paragraph il im ho in b io lj iq ir is lk iu iv iw ll iy iz ja lm jc jd je ln jg jh ji ha bi translated">设<strong class="in hp"> <em class="ml"> G </em> </strong>为卷积运算后该层的梯度矩阵。它的形状是(1，2，24，24)。让卷积滤波器的输入由<strong class="in hp"> <em class="ml"> I </em> </strong>定义。它的形状是(1，1，28，28)。</p><ol class=""><li id="e957" class="jj jk ho in b io ip is it iw jl ja jm je jn ji mm jp jq jr bi translated">将输入图像转换为im2col格式；im2col矩阵是2D矩阵，其中每一列是卷积滤波器的单个步长中覆盖的元素的展平向量。</li><li id="def7" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji mm jp jq jr bi translated">将误差矩阵<strong class="in hp"> <em class="ml"> G </em> </strong>重塑为2D矩阵；每行是每个通道中误差的展平向量。</li><li id="d809" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji mm jp jq jr bi translated">将这两个矩阵相乘，重塑结果。</li></ol><p id="a68e" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">下面的代码片段展示了重塑渐变矩阵的函数</p><pre class="jz ka kb kc fd lo lp lq lr aw ls bi"><span id="3a57" class="lt km ho lp b fi lu lv l lw lx">def error_layer_reshape(error_layer):<br/>    test_array = error_layer<br/>    test_array_new = np.zeros((test_array.shape[1],test_array.shape[0]*test_array.shape[2]*test_array.shape[3]))<br/>    for i in range(test_array_new.shape[0]):<br/>        test_array_new[i:i+1,:] = test_array[:,i:i+1,:,:].ravel()<br/>    return test_array_new</span></pre><p id="1de4" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">查找卷积滤波器梯度的代码片段如下</p><pre class="jz ka kb kc fd lo lp lq lr aw ls bi"><span id="d6c5" class="lt km ho lp b fi lu lv l lw lx">X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)<br/>delta_conv = np.random.rand(10,2,24,24)<br/>delta_conv_reshape = error_layer_reshape(delta_conv)<br/>conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)</span></pre><h1 id="6ee2" class="kl km ho bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">有用的资源</h1><ul class=""><li id="b1c8" class="jj jk ho in b io lj is lk iw mn ja mo je mp ji jo jp jq jr bi translated"><a class="ae js" href="https://hackmd.io/@bouteille/B1Cmns09I" rel="noopener ugc nofollow" target="_blank">快速实现CNN </a></li></ul><h1 id="5769" class="kl km ho bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">反馈</h1><p id="495f" class="pw-post-body-paragraph il im ho in b io lj iq ir is lk iu iv iw ll iy iz ja lm jc jd je ln jg jh ji ha bi translated">感谢阅读！如果您有任何反馈/建议，请在下面留言/发邮件给我，地址是padhokshaja@gmail.com</p><h1 id="8fa1" class="kl km ho bd kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li bi translated">下一篇文章</h1><p id="5328" class="pw-post-body-paragraph il im ho in b io lj iq ir is lk iu iv iw ll iy iz ja lm jc jd je ln jg jh ji ha bi translated"><a class="ae js" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-part-v-putting-it-all-together-b4210cd14487">综合起来</a></p></div></div>    
</body>
</html>