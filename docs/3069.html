<html>
<head>
<title>A One-to-Many Approach for Improving Super-Resolution</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">一种提高超分辨率的一对多方法</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-one-to-many-approach-for-improving-super-resolution-a89146df343d?source=collection_archive---------3-----------------------#2021-06-02">https://medium.com/analytics-vidhya/a-one-to-many-approach-for-improving-super-resolution-a89146df343d?source=collection_archive---------3-----------------------#2021-06-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="cd77" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇文章将概述我正在进行的一个项目，该项目旨在改进当前的超分辨率方法。我想读者应该对以前的作品有基本的了解(<a class="ae jc" rel="noopener" href="/analytics-vidhya/super-resolution-with-srresnet-srgan-2859b87c9c7f"> SRGAN </a>和<a class="ae jc" rel="noopener" href="/analytics-vidhya/how-esrgan-improves-super-resolution-performance-15de91d77ada"> ESRGAN </a>)，但是我相信没有任何这方面的背景不会有太大的问题。</p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><h1 id="4292" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">一对多超分辨率</h1><p id="2fa3" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">在给定LR图像的情况下，超分辨率是具有多种可能重建的一对多问题。当在严格的内容损失上进行训练时，当所有似是而非的重建中只有一个解决方案被接受作为基本事实答案时，问题就出现了。在这种情况下，该模型不能选择一个现实的重建，而是倾向于输出可能的解决方案的逐像素平均值。这个一对多的问题是由SRGAN引发的，并且通过使用更感性的训练目标<em class="kn">部分</em>解决了。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es ko"><img src="../Images/d5d48e61b7a817217bf999188c183250.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/0*Y7q05-TBnYyTmyY9.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">SRGAN的问题情况</figcaption></figure><p id="a35e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">SRGAN认为SR是一个一对多的问题，并提出了一个改进的训练目标，但没有提供一个可以生成多个答案的生成器。要真正解决这个问题，生成器必须能够输出真实面片(红色面片)的完整流形，而不是只预测一个样本。</p><p id="008e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们试图提出一个完整的一对多流水线来提高超分辨率的感知质量。</p><h1 id="69aa" class="jk jl hh bd jm jn la jp jq jr lb jt ju jv lc jx jy jz ld kb kc kd le kf kg kh bi translated">埃斯甘</h1><p id="a1f7" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">自ESRGAN的工作以来，大多数基于感知的超分辨率研究都集中在改进模型架构，同时使用ESRGAN的训练目标。那么ESRGAN的培养目标是什么呢？</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es lf"><img src="../Images/659ca55643b2c4989792d568f06b715f.png" data-original-src="https://miro.medium.com/v2/resize:fit:572/format:webp/0*FI2Snrv01gtFuALv.png"/></div><figcaption class="kw kx et er es ky kz bd b be z dx translated">ESRGAN培训目标</figcaption></figure><p id="30a0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如以上公式所述，ESRGAN将L1严格内容损失与感知损失和GAN损失相结合。原因是GAN损耗在提高感知质量的同时，不能保证超分辨率图像与原始图像完全相同。因此，虽然这两种损失根本不一致，L1损失会损害感知质量，但为了学会工作，它们需要混合在一起。</p><p id="04a9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">可以改善内容损失以确保内容，同时最小化对感知训练目标的负面影响。</p></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><p id="1535" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的主要建议如下:</p><ul class=""><li id="467b" class="lg lh hh ig b ih ii il im ip li it lj ix lk jb ll lm ln lo bi translated">我们提出了一种较弱的内容损失，它不会影响图像中高频细节和随机变化的产生。</li><li id="7e84" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">我们通过在每个RRDB模块后添加缩放的逐像素噪声，使发生器能够产生不同的输出。</li><li id="46b7" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">我们使用拉普拉斯激活来过滤训练数据中的模糊区域。</li><li id="3095" class="lg lh hh ig b ih lp il lq ip lr it ls ix lt jb ll lm ln lo bi translated">我们另外向鉴别器提供LR图像，以向发生器提供更好的梯度反馈。</li></ul><h2 id="750c" class="lu jl hh bd jm lv lw lx jq ly lz ma ju ip mb mc jy it md me kc ix mf mg kg mh bi translated">循环一致性内容损失</h2><p id="e421" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">我们将超分辨率问题视为LR和HR图像空间之间的图像到图像转换任务，并应用CycleGAN框架的循环一致性损失。为了简化问题，我们利用G2:HR &gt; LR的先验知识。我们可以将下采样操作表示为f，并将G2设置为f，而不是学习它。因此，我们的管道不需要学习D2，这是一个学习G2的工具。这就只剩下G1和D1值得学习了。我们的周期一致性损失可以写成下面的等式。这种损失不会以任何方式影响高频细节的生成，同时SR图像与LR图像保持一致。下图描述了我们方法的图形概览。</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div class="er es mi"><img src="../Images/50f1ac0fac4f9690e67b1b7df1080428.png" data-original-src="https://miro.medium.com/v2/resize:fit:508/format:webp/1*Da8LGLLeetU3ezoq4eKhDQ.png"/></div></figure><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mj"><img src="../Images/0940086e5d8d79eb7a2bf8a3b4dea63b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*V9DU4rKqWo6UWKzenAm3MQ.png"/></div></div></figure><h2 id="3d82" class="lu jl hh bd jm lv lw lx jq ly lz ma ju ip mb mc jy it md me kc ix mf mg kg mh bi translated">给发电机带来噪音</h2><p id="893a" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">为了使生成器能够在给定单个图像的情况下生成一个以上的解，它必须接收并应用随机信息。StyleGAN通过将逐像素高斯噪声添加到发生器中每个层的输出来实现图像的随机变化。我们采用这种方法，并在生成器的每个RRDB层后添加噪声。</p><p id="a31e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，每个通道的灵敏度和所需的噪声幅度会有所不同。在每一层之后直接添加相同的噪声可能会损害发生器的能力。例如，检测边缘的通道会受到噪声的严重损害。为了减轻这种可能的问题，我们允许每个通道学习所需的噪声幅度。具体来说，在将噪声添加到每层的输出之前，我们将噪声乘以一个可训练的通道比例因子。</p><h2 id="ae26" class="lu jl hh bd jm lv lw lx jq ly lz ma ju ip mb mc jy it md me kc ix mf mg kg mh bi translated">鉴别器的参考图像</h2><p id="866c" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">传统上，鉴别器网络接收单个图像，并被训练来对给定图像是真实图像还是生成图像进行分类。此设置将为生成器提供“任何自然图像”的梯度，而不是朝向相应的HR图像。在一个极端的例子中，传统的鉴别器不会因为生成器从LR图像生成完全不同但同样真实的图像而惩罚它。鉴别器给出的梯度反馈对于超分辨率来说是次优的。上图也说明了这一点。</p><h2 id="e97d" class="lu jl hh bd jm lv lw lx jq ly lz ma ju ip mb mc jy it md me kc ix mf mg kg mh bi translated">模糊检测</h2><p id="7400" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">我们认识到，在来自DIV2K和DIV2K数据集的图像中经常存在严重模糊的区域。这些模糊区域可能会困扰生成器来学习生成这样的模糊补丁。仅基于LR图像，模糊的背景通常无法与更精细的对象区分开来。</p><p id="f235" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们建议在网络在这些斑块上被训练之前检测并移除模糊的斑块。存在各种用于模糊检测的方法，例如算法方法和基于深度学习的方法。然而，在我们的案例中，算法方法已经足够了，如下图所示。上面两行是分类为清晰的补片，下面的行是模糊的补片，</p><figure class="kp kq kr ks fd kt er es paragraph-image"><div role="button" tabindex="0" class="mk ml di mm bf mn"><div class="er es mo"><img src="../Images/65bfdfd38a90e6a442261b6743857c3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HClsX9XEAAiwnGYVt4ZMjw.png"/></div></div></figure></div><div class="ab cl jd je go jf" role="separator"><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji jj"/><span class="jg bw bk jh ji"/></div><div class="ha hb hc hd he"><p id="72b1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们提出了一个超分辨率的一对多流水线和两个额外的改进来提高SR的感知质量，你觉得我的想法怎么样？</p></div></div>    
</body>
</html>