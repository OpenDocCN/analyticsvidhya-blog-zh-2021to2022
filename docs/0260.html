<html>
<head>
<title>Math Intuition Summary on Variational Autoencoder</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">变分自动编码器的数学直觉综述</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/math-intuition-summary-on-variational-autoencoder-c3c57e79a94f?source=collection_archive---------17-----------------------#2021-01-10">https://medium.com/analytics-vidhya/math-intuition-summary-on-variational-autoencoder-c3c57e79a94f?source=collection_archive---------17-----------------------#2021-01-10</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="2492" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">变分自动编码器模型算法详解</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/3a508336ac2a098a8f9bb5e2c2cd5803.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TCTHb7-u1MfFRgZuwM9J5A.jpeg"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">苏美尔人，已知最早的文明</figcaption></figure><p id="08ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我对变分自动编码器(VAEs)的数学直觉总结将基于下面的经典变分自动编码器(VAEs)架构。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es js"><img src="../Images/0a417bf76b314909cfcd1a94020fdf11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nLLC3nrS42oCdzz4hRDmGA.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated"><strong class="bd jt"> VAEs架构</strong>@<a class="ae ju" href="https://github.com/AndrewSpano/Disentangled_Variational_Autoencoder" rel="noopener ugc nofollow" target="_blank">https://github . com/Andrews pano/distangled _ variable _ auto encoder</a></figcaption></figure><ol class=""><li id="f772" class="jv jw hh ig b ih ii il im ip jx it jy ix jz jb ka kb kc kd bi translated">我们期望<strong class="ig hi"> x ≈ x '，</strong>这与自动编码器神经网络相同</li><li id="a845" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated">概率<strong class="ig hi">编码器q </strong> ϕ(z|x)将每个输入<strong class="ig hi"> x </strong>映射到潜在空间中对应的正态分布<strong class="ig hi"> N </strong> (μ，σ)。因此，潜在空间实际上是从整个输入数据集映射的所有正态分布的总和，就像高斯混合模型一样。</li><li id="10aa" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated">概率<strong class="ig hi">解码器p </strong> θ(x|z)将潜在空间样本<strong class="ig hi"> z </strong>映射回输入数据空间。</li><li id="8464" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><strong class="ig hi"> z </strong>是来自潜空间的样本。潜在空间预期遵循标准的多元正态分布，并且通常具有比输入<strong class="ig hi"> x </strong>小得多的维度</li></ol><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kj"><img src="../Images/5239e26ffda21ff1f918fc32982f5cc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:546/format:webp/1*JWVjRHF71ebYxGsIY_O_tA.png"/></div></figure><p id="ca7f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> x </strong>、<strong class="ig hi"> q </strong> ϕ(z|x、<strong class="ig hi"> p </strong> θ(x|z)、以及<strong class="ig hi"> z </strong>之间的空间映射关系如下图所示:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es kk"><img src="../Images/c330746acf1187a938ba78b4472e74d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*s4nlVrDWuPwb-AcJL-r3mQ.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated"><strong class="bd jt"> VAEs空间映射</strong> @ <a class="ae ju" href="https://arxiv.org/abs/1906.02691" rel="noopener ugc nofollow" target="_blank">变分自动编码器简介</a></figcaption></figure><h1 id="413a" class="kl km hh bd jt kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">目标功能构建</h1><p id="bc38" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip lk ir is it ll iv iw ix lm iz ja jb ha bi translated">变分自动编码器(VAEs)的目标函数是建立在最大对数似然。</p><h1 id="287b" class="kl km hh bd jt kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">最大对数似然</strong></h1><p id="e261" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip lk ir is it ll iv iw ix lm iz ja jb ha bi translated">给定VAEs模型输入数据集D ={ <strong class="ig hi"> x1 </strong>，<strong class="ig hi"> x </strong> 2、、、<strong class="ig hi"> x </strong> n }，<strong class="ig hi"> p </strong> θ(x)表示模型输出概率分布函数(输出x上的PDF)，则对数概率VAEs模型旨在最大化如下:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ln"><img src="../Images/3b1edcd9d4a7a01b8957e8ea96af2c9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:852/format:webp/1*Eiwq-9c-nOD857FdVhWQcA.png"/></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">最大对数似然</figcaption></figure><p id="cdaf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了最大化log(pθ(x))的和，我们可以尝试最大化每个log(pθ(x))</p><h1 id="9655" class="kl km hh bd jt kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">最大化log(pθ(x)) </strong></h1><p id="8de0" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip lk ir is it ll iv iw ix lm iz ja jb ha bi translated">下面是来自原始论文的数学归纳。ELBO表示证据下限，KL表示<a class="ae ju" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" rel="noopener ugc nofollow" target="_blank"> KL散度</a>，它是两个分布之间距离的度量。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lo"><img src="../Images/82d14f4a265d6d72922e4e207f032a9e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QCqGe16aOwJhLXLVvCVWfw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">来源于@ <a class="ae ju" href="https://arxiv.org/abs/1906.02691" rel="noopener ugc nofollow" target="_blank">变型自动编码器介绍</a></figcaption></figure><p id="ee84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因为任何KL距离总是⩾ 0，因此</p><p id="f533" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">log(pθ(x)) =埃尔博+kl(qϕ(z|x)||pθ(z|x))⩾·埃尔博</p><h1 id="56ad" class="kl km hh bd jt kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">爱尔博感应</strong></h1><p id="c5d8" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip lk ir is it ll iv iw ix lm iz ja jb ha bi translated">埃尔博= 𝔼qϕ(z|x) [ log ( pθ(x，z)/qϕ(z|x)]</p><p id="1469" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">= 𝔼qϕ(z|x)[log(pθ(x | z)* pθ(z)/qϕ(z|x]]</p><p id="be45" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">= 𝔼qϕ(z|x)[log(pθ(z)/qϕ(z|x))]+𝔼qϕ(z|x][log(pθ(x | z))]</p><p id="0d33" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">= -kl(qϕ(z|x)||pθ(z))+𝔼qϕ(z|x)[log(pθ(x | z))]</p><p id="931a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里pθ(z)是已知分布<strong class="ig hi"> N </strong> (0，I)，所以ELBO只由qϕ(z|x)和pθ(x|z)决定</p><h1 id="b146" class="kl km hh bd jt kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">最大化log(pθ(x))复议</strong></h1><p id="756f" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip lk ir is it ll iv iw ix lm iz ja jb ha bi translated">从log(pθ(x))归纳，我们知道</p><p id="ec49" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">log(pθ(x)) =埃尔博+kl(qϕ(z|x)||pθ(z|x))⩾·埃尔博</p><blockquote class="lp lq lr"><p id="4878" class="ie if ls ig b ih ii ij ik il im in io lt iq ir is lu iu iv iw lv iy iz ja jb ha bi translated">原始论文提到，为了最大化log(pθ(x))我们需要最大化ELBO。这里的直觉是因为ELBO会用qϕ(z|x)来使其值最大化，而qϕ(z|x)不能直接决定log(pθ(x))值，但qϕ(z|x)可以通过ELBO决定log(pθ(x))最小值。</p><p id="b6c9" class="ie if ls ig b ih ii ij ik il im in io lt iq ir is lu iu iv iw lv iy iz ja jb ha bi translated">所以最大化ELBO会使log(pθ(x))的最小值最大化，使log(pθ(x))普遍变大，这是我的理解。</p></blockquote><h1 id="2f66" class="kl km hh bd jt kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated"><strong class="ak">最大化ELBO以最大化log(pθ(x)) </strong></h1><p id="54d4" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip lk ir is it ll iv iw ix lm iz ja jb ha bi translated"><strong class="ig hi">埃尔博</strong>= -kl(qϕ(z|x)||pθ(z))+𝔼qϕ(z|x)[log(pθ(x | z))]</p><p id="f3b8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了最大化ELBO，我们需要</p><p id="e819" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 1。最小化KL(qϕ(z|x)||pθ(z)) </strong></p><p id="1fe4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这意味着我们需要使kl(qϕ(z|x)||pθ(z)= 0，因此<strong class="ig hi">编码器q </strong> ϕ(z|x)需要被训练以逼近标准正态分布pθ(z)</p><p id="e200" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以qϕ(z|x)～<strong class="ig hi">n</strong>(0，I)</p><p id="65ad" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> 2。最大化𝔼qϕ(z|x) [ log ( pθ(x|z) )] </strong></p><p id="5efa" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最大化方程意味着，对于给定的输入<strong class="ig hi"> x </strong>，模型需要最大化概率来产生与输出相同的<strong class="ig hi"> x </strong>。这是试图使<strong class="ig hi"> x' = x </strong></p><p id="e606" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是ELBO的一个很好的演示，从不同的自动编码器架构来看</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lw"><img src="../Images/ba0d6e44e0a172e82da562cc0a19f1ed.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sfk2mutlSbId889HkjcpIQ.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">来源于<a class="ae ju" href="https://www.youtube.com/watch?v=Tc-XfiDPLf4" rel="noopener ugc nofollow" target="_blank">https://www.youtube.com/watch?v=Tc-XfiDPLf4</a></figcaption></figure><h1 id="3639" class="kl km hh bd jt kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">最终目标函数</h1><p id="286a" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip lk ir is it ll iv iw ix lm iz ja jb ha bi translated">总结上述分析，变分自动编码器(vae)的最终损失函数为:</p><p id="a28f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> LOSS = |X - X'| + KL( qϕ(z|x)，N(0，I)) </strong></p><p id="fe30" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">损失函数将指导模型实现:</p><ol class=""><li id="9aa0" class="jv jw hh ig b ih ii il im ip jx it jy ix jz jb ka kb kc kd bi translated">输出尽可能多地再现相同的输入</li><li id="28fa" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated">潜在空间映射区域(正态分布)的输入将试图以0为中心，并在潜在空间中的方差1上扩展</li><li id="e228" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated">潜在空间将被压缩到0，而不是分离的区域</li></ol><h1 id="29af" class="kl km hh bd jt kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">重新参数化技巧</h1><p id="00ce" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip lk ir is it ll iv iw ix lm iz ja jb ha bi translated">变分自动编码器网络训练仍然使用<a class="ae ju" href="https://en.wikipedia.org/wiki/Backpropagation" rel="noopener ugc nofollow" target="_blank">误差反向传播</a>和<a class="ae ju" href="https://en.wikipedia.org/wiki/Chain_rule" rel="noopener ugc nofollow" target="_blank">导数链规则</a>。但是在VAEs网络前向传播过程中，潜在向量<strong class="ig hi"> z </strong>是随机采样的，这导致反向传播不能直接应用。</p><p id="246e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，VAEs通过以下变换解决了采样不可导(或不可微)的问题:</p><p id="aa34" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> z' = μ(x) + σ(x)*ϵ </strong></p><p id="5ebc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ϵ~N(0，I)、μ(x)和σ(x)是编码器<strong class="ig hi"> qϕ(z|x) </strong>的输出</p><p id="54f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">该转换具有以下特征</p><ol class=""><li id="455f" class="jv jw hh ig b ih ii il im ip jx it jy ix jz jb ka kb kc kd bi translated"><strong class="ig hi"> z' </strong>由于随机<strong class="ig hi"> ϵ </strong>仍然是一个随机值</li><li id="c8a4" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><strong class="ig hi"> z' </strong>遵循与<strong class="ig hi"> z </strong>相同的N(μ，σ)分布</li><li id="e635" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><strong class="ig hi"> z' </strong>在参数<strong class="ig hi"> ϕ、</strong>上变得可导，因为σ(x)是<strong class="ig hi"> qϕ(z|x) </strong>的一部分</li></ol><p id="3a9b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">转换后，反向传播衍生链路径重新打开，如下图所示。(注意我们不需要ϵ 上的导数路径)</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es lx"><img src="../Images/8083db75ec4c73c4d80a08d8fb119941.png" data-original-src="https://miro.medium.com/v2/resize:fit:1354/format:webp/1*la1BCOTOgLzClt9OBDLTbA.png"/></div></figure><h1 id="62b6" class="kl km hh bd jt kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">变分自动编码器中的变分推理</h1><p id="f5b8" class="pw-post-body-paragraph ie if hh ig b ih li ij ik il lj in io ip lk ir is it ll iv iw ix lm iz ja jb ha bi translated">在统计学中，变分推断(VI)是一种使用一组易处理的简单分布来近似复杂难处理的分布的技术。</p><p id="b42c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在变分自动编码器模型中，难以处理的分布是P(Z|X)，编码器<strong class="ig hi"> qϕ(z|x) </strong>将每个输入<strong class="ig hi"> x </strong>映射成高斯分布N(μ，σ)，这些高斯通过模型梯度下降训练共同逼近P(Z|X)。</p><h1 id="32b5" class="kl km hh bd jt kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh bi translated">参考</h1><ol class=""><li id="9255" class="jv jw hh ig b ih li il lj ip ly it lz ix ma jb ka kb kc kd bi translated"><a class="ae ju" href="https://arxiv.org/pdf/1312.6114v10.pdf" rel="noopener ugc nofollow" target="_blank">自动编码变分贝叶斯</a></li><li id="2e71" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><a class="ae ju" href="https://arxiv.org/abs/1906.02691" rel="noopener ugc nofollow" target="_blank">变型自动编码器简介</a></li><li id="0433" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><a class="ae ju" href="https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73" rel="noopener" target="_blank">了解变分自动编码器(VAEs) </a></li><li id="6296" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><a class="ae ju" href="https://github.com/AndrewSpano/Disentangled_Variational_Autoencoder" rel="noopener ugc nofollow" target="_blank">https://github . com/Andrews pano/distangled _ variable _ auto encoder</a></li><li id="7e4b" class="jv jw hh ig b ih ke il kf ip kg it kh ix ki jb ka kb kc kd bi translated"><a class="ae ju" href="https://www.youtube.com/watch?v=Tc-XfiDPLf4" rel="noopener ugc nofollow" target="_blank">自动编码变分贝叶斯| AISC基础</a></li></ol></div></div>    
</body>
</html>