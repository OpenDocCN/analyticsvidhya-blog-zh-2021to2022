<html>
<head>
<title>Video Captioning with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras的视频字幕</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/video-captioning-with-keras-511984a2cfff?source=collection_archive---------1-----------------------#2021-03-15">https://medium.com/analytics-vidhya/video-captioning-with-keras-511984a2cfff?source=collection_archive---------1-----------------------#2021-03-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="cd83" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自动生成描述视频事件的字幕</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/feaadc3fc39cfc03125069029ebbf2d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3WApk9iWeIWXuRNKs9tYKw.jpeg"/></div></div></figure><h1 id="f049" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated"><strong class="ak">简介</strong></h1><p id="b519" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">近年来，视频字幕任务变得非常流行。有了所有这些像YouTube、Twitch这样的平台，以及像Instagram Reels这样的短视频，视频已经成为我们日常生活中非常重要的交流方式。据福布斯统计，每天有超过5亿人在脸书上观看视频。每分钟有72小时的视频上传到YouTube。随着视频获得如此高的人气，视频的人工智能产品已经成为一种空前的必需品。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ks"><img src="../Images/c057df2ffe4df6f35691d97c7706b184.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*8f9rMeyNMqDlb9donwAqTg.gif"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">显示视频字幕实时预测的剪辑</figcaption></figure><h1 id="5b9a" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">先验知识</h1><p id="f93a" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">理解这篇文章需要LSTM/RNN的概念和编码器-解码器架构的基础知识以及对Keras的理解。</p><h1 id="297c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">动机</h1><p id="abc0" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我正在寻找一些独特的项目工作时，我遇到了字幕。当我意识到缺乏视频字幕方面的好资源，但却有大量的图像字幕时，我开始深入这个话题。所以，我决定在这方面努力，让人们更容易实现视频字幕。</p><h1 id="15f6" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">现实世界的应用</h1><p id="0bcf" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们必须首先理解这个问题在现实场景中有多重要。</p><ul class=""><li id="1001" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated"><strong class="ih hj">更好的搜索算法</strong>:如果每个视频都能被自动描述，搜索算法会有更好更准确的结果。</li><li id="937d" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated"><strong class="ih hj">推荐系统</strong>:如果视频的内容可以被自动描述，我们可以很容易地根据视频的相似性对其进行分类。</li></ul><h1 id="0c9f" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">数据收集</h1><p id="1fc4" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">出于这项研究的目的，我使用了微软的MSVD数据集。你可以从<a class="ae ll" href="https://www.dropbox.com/sh/whatkfg5mr4dr63/AACKCO3LwSsHK4_GOmHn4oyYa?dl=0" rel="noopener ugc nofollow" target="_blank">这里</a>得到数据集。这个数据集包含1450个经过手动标记用于训练的YouTube短片和100个用于测试的视频。</p><p id="f78a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每个视频都被分配了一个唯一的ID，每个ID有大约15-20个字幕。</p><h1 id="9491" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">了解数据集</h1><p id="4e36" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">在下载数据集时，您会发现<strong class="ih hj"> training_data </strong>和<strong class="ih hj"> testing_data </strong>文件夹。每个文件夹都包含一个<strong class="ih hj">视频</strong>子文件夹，其中包含将用于培训和测试的视频。这些文件夹还包含<strong class="ih hj"> feat </strong>子文件夹，features的简称。feat文件夹包含视频的特征。还有<strong class="ih hj"> training_label </strong>和<strong class="ih hj"> testing_label </strong> json文件。这些json文件包含每个ID的标题。我们可以如下读取json文件:</p><pre class="je jf jg jh fd lm ln lo lp aw lq bi"><span id="65ab" class="lr jq hi ln b fi ls lt l lu lv">train_path='training_data'<br/>TRAIN_LABEL_PATH = os.path.join(train_path, 'training_label.json')<br/><em class="lw"># mentioning the train test split</em><br/>train_split = 0.85<br/><em class="lw"># loading the json file for training</em><br/><strong class="ln hj">with</strong> open(TRAIN_LABEL_PATH) <strong class="ln hj">as</strong> data_file:    <br/>    y_data = json.load(data_file)</span></pre><p id="84cc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">json文件如下所示:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lx"><img src="../Images/871f2e10ae4dd3fa0f04b87c34d0d3f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*JNuNOI0Nhx8o0jzvsYrSRw.png"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">每个视频都有多个字幕，意思相同</figcaption></figure><p id="0a8c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，对于每个视频id，有许多可选的字幕。</p><h1 id="cc4c" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">提取视频特征</h1><p id="324c" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">视频字幕是一个两部分的项目。第一部分，提取视频的特征。</p><p id="5828" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">什么是视频？人们可以说视频是一系列图像的列表，对吗？因此，对于数据集中的视频，从视频中提取每个被称为帧的图像。</p><p id="d935" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">代码可以在这里看到。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="489d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">由于视频的长度不同，提取的帧数也会不同。所以为了简单起见，每个视频只取80帧。80帧中的每一帧都经过预先训练的<strong class="ih hj"> VGG16 </strong>，从每一帧中提取4096个特征。这些特征被堆叠以形成(80，4096)形状的阵列。80是帧数，4096是从每一帧提取的特征数。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ly lz l"/></div></figure><p id="54a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，您可以看到VGG16型号已加载。来自每个视频的80帧中的每一帧都被传递到模型中以提取特征并保存为numpy数组。现在这些特征已经从数据集中提取出来了，所以我们可以继续下一步了。</p><h1 id="61a3" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">清理和预处理字幕</h1><p id="9be7" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">现在，我们将加载所有的字幕，并将它们与它们的视频id配对。以下是我所做的。train_list包含一对标题和视频ID。我所做的唯一的文本预处理是在每个标题之前和之后分别添加<bos>和<eos>标记。</eos></bos></p><ul class=""><li id="3f8a" class="kx ky hi ih b ii ij im in iq kz iu la iy lb jc lc ld le lf bi translated"><strong class="ih hj"> &lt; bos &gt; </strong>表示句子的开始，因此模型知道从这里开始预测</li><li id="0585" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated"><strong class="ih hj"> &lt; eos &gt; </strong>表示语句结束，这是模型知道停止预测的地方。</li></ul><p id="4ffe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是train_list的外观。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ma"><img src="../Images/0efe3ec84ecb8ba6a0dcbb5c0bee6b43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-D1HfBQgqJp667RhpN-fuQ.png"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">一些培训列表项目</figcaption></figure><p id="c8d4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">train_list分为训练和验证两部分。training_list包含85%的数据，其余的数据存在于validation_list中。</p><p id="c63a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">vocab _ list仅包含来自training_list的标题，因为我们将仅使用训练数据中的单词来标记</strong>。标记后，我们将填充标题，使所有的句子长度相同。在我的项目中，我把它们都填充为10个单词。你可能已经看到<strong class="ih hj">我也只使用字数在6到10之间的标题。你可能会问我为什么这么做？</strong></p><p id="6468" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你查看所有数据集中最大字数的标题，它有39个字，但是对于大多数标题，字数在6到10之间。如果我们不过滤掉一些标题，我们将不得不把它们填充到标题的最大长度，在我们的例子中是39。现在，如果大多数句子有10个单词，我们将不得不填充它们，使它们的长度加倍，这将导致大量的填充。这些高度填充的句子将用于训练，这将导致模型预测大部分填充的标记。由于填充基本上意味着添加空格，因此该模型预测的大多数句子将只包含更多空格和更少单词，从而导致不完整的句子。</p><p id="821a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">现在我只使用前1500个单词作为标题的词汇。</strong>你看到的任何标题都必须是1500个单词的一部分。尽管独特单词的数量远远超过1500个，为什么我们只使用1500个单词进行训练呢？</p><p id="e0ec" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">如果你认为大多数单词出现的次数很少，只有1、2或3次，那么这个词汇很容易出现异常值。因此为了安全起见，我们将只使用前1500个最常出现的单词。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="462d" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">培训模型</h1><p id="f30d" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">大多数情况下，对于与文本生成相关的问题，首选模型是编码器-解码器架构。在我们的问题陈述中，由于必须生成文本，我们也将使用这种<strong class="ih hj">序列到序列</strong>架构。为了更好地理解这个架构，我建议查看这篇文章<a class="ae ll" href="https://towardsdatascience.com/understanding-encoder-decoder-sequence-to-sequence-model-679e04af4346" rel="noopener" target="_blank"><strong class="ih hj"/></a>。</p><p id="2f44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这种架构中需要知道的一点是，编码器单元的<strong class="ih hj">最终状态总是作为解码器单元的</strong>初始状态。在我们的问题中，我们将使用编码器来输入视频特征，解码器将接收字幕。</p><p id="0e06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们已经建立了我们将使用一个编码器-解码器模型，让我们看看我们应该如何使用它。</p><p id="04fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">什么是视频来着？我们可以称之为图像序列<strong class="ih hj">对吗？对于任何与序列相关的东西，我们总是喜欢使用RNNs或LSTMs。在我们的例子中，我们将使用LSTM。要了解LSTMs，请参考此<a class="ae ll" href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="noopener ugc nofollow" target="_blank">链接</a>。</strong></p><p id="213c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在我们将LSTM用于编码器，让我们看看解码器。解码器将生成字幕。字幕基本上是一个单词序列，所以我们也将在解码器中使用LSTMs。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mb"><img src="../Images/d3b416274b2d2c78b4934af880b5311c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SvjfrQRH3OmHZ6752bWrnQ.jpeg"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">培训模式</figcaption></figure><p id="d5f4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在图中，第一帧的特征被输入编码器的第一个LSTM单元。接下来是第二帧的特征，这一直持续到第80帧。对于这个问题，我们只对编码器的最终状态感兴趣，因此编码器的所有其他输出都被丢弃。现在编码器LSTM的最终状态作为解码器LSTM的初始状态。这里，在第一个解码器中，LSTM <bos>作为输入开始句子。来自训练数据的字幕的每一个单词都被一个接一个地输入，直到<eos>。</eos></bos></p><p id="609c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">所以对于上面的例子，如果实际的字幕是<strong class="ih hj">女人正在煮东西</strong>，解码器从第一个解码器LSTM中的&lt; bos &gt;开始。在下一个单元格中，实际字幕中的下一个单词<strong class="ih hj">女人</strong>被喂食，接着是<strong class="ih hj">正在煮东西</strong>。这以&lt; eos &gt;令牌结束。</p><p id="510f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">编码器的<strong class="ih hj">时间步长是我们将用于编码器的LSTM单元的数量，等于<strong class="ih hj"> 80 </strong>。<strong class="ih hj">编码器令牌</strong>是视频中特征的数量，在我们的例子中是<strong class="ih hj"> 4096 </strong>。<strong class="ih hj">解码器的时间步长</strong>是解码器的LSTM单元数<strong class="ih hj"> 10 </strong>，而<strong class="ih hj">令牌数</strong>是词汇长度<strong class="ih hj"> 1500 </strong>。</strong></p><p id="73d9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看这个模型的代码。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ly lz l"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">培训模型的代码</figcaption></figure><p id="d3fc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看建筑。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mc"><img src="../Images/cccf2c11363d3da5fc6fcee213cb9f2f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v5qLIIPFJ711gW-zrdProQ.png"/></div></div></figure><h1 id="55f2" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">加载数据集</h1><p id="762f" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">现在我们已经知道了模型，将数据加载到模型中也是培训中非常重要的一部分。</p><p id="2507" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">训练数据点的数量约为14k，这肯定会<strong class="ih hj">导致RAM内存问题</strong>。为了避免这样的问题，我使用了一个<strong class="ih hj">数据生成器</strong>。我用的是一个<strong class="ih hj"> 320 </strong>的批量。因为训练有两个输入。我将其转换为一个列表，然后将两者一起作为编码器输入，其中包含视频输入和解码器输入的特征，这些输入是经过标记化和填充的字幕，转换为具有1500个标签的分类特征，这是我们将使用的词汇长度，或者是我提到的解码器标记的数量。我使用<strong class="ih hj"> yield语句</strong>返回输出。Yield语句用于创建生成器。这里我使用了一个定制的生成器，因为我们有两个输入。我已经以字典的形式加载了所有的特性，这样一次又一次地加载相同的数组会花费更少的时间。</p><figure class="je jf jg jh fd ji"><div class="bz dy l di"><div class="ly lz l"/></div></figure><h1 id="0c7e" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">培养</h1><p id="7939" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我训练了150个纪元的模型。完成一个历元的训练大约需要40秒。<strong class="ih hj">我用colab免费版在特斯拉T4上进行培训</strong>。</p><h1 id="5638" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">推理模型</h1><p id="4f08" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">与大多数神经网络不同，编码器-解码器的训练和测试模型是不同的。我们不会在训练后原样保存整个模型。<strong class="ih hj">我们不同的保存编码器模型和解码器部分。</strong>现在让我们看看推理模型。</p><p id="b115" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，我们将使用编码器模型。来自所有80帧的特征被传递到模型中。模型的这一部分与训练时的一样。编码器模型给了我们预测。同样，我们对最终输出状态感兴趣，因此编码器的所有其他输出都将被丢弃。编码器的最终状态作为其初始状态与<bos>令牌一起被送入解码器，以便解码器预测下一个字。</bos></p><p id="1eb3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有两种方法可以生成标题。<strong class="ih hj">我已经实现了这两种方法，但为了在实时预测中获得更快的结果，我将使用贪婪搜索</strong>。要了解更多关于<strong class="ih hj">贪</strong>和<strong class="ih hj">梁</strong>的搜索点击<a class="ae ll" href="https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj">这里</strong> </a>。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es mb"><img src="../Images/0d6b80d96bfd254eff5cc0c029055110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hYGY2Qj5SFDM-oY6Sav5WQ.jpeg"/></div></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">推理模型</figcaption></figure><p id="25f7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，如果模型被适当地训练，正如你在上面看到的，它应该预测<strong class="ih hj">女人</strong>作为令牌。记住，在训练中，下一个输入总是标题中的下一个单词。因为我们这里没有标题，所以下一个单词是前一个LSTM单元的输出。然后，输出<strong class="ih hj"> woman </strong>与前一个单元的状态一起被送入下一个单元。这继续预测下一个字<strong class="ih hj">是</strong>。这种情况一直持续到模型预测到状态方程。我们将不再需要任何更多的预测，因为这个句子是完整的。</p><h1 id="c1da" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结果</h1><p id="d14b" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">现在我知道每个人都在等待这个，所以让我给你看更多来自<strong class="ih hj">测试数据</strong>的结果。现在，请注意，这些结果使用了贪婪搜索算法。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/a59eaadf598f7102f6be76257ddf50f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*r5J0bsz0OVE77ds-HcxaHA.gif"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">一个男人正在舞台上表演</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/4df37d9fd87096ed018c79af2c8c0c2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*XzKXLhihHiCyDcXR2lygkA.gif"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">一名男子正在碗里搅拌配料</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/39ca24ab836cb3e67cc6022ea5fbbc5b.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*a22K0WrKFxoXvLoDe5yLsA.gif"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">一只猫正在弹钢琴</figcaption></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/cffa9b2747190492b8036ba8374730ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*YazndScnNJcXR_EXZtKe9A.gif"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">一名男子正在摊玉米饼</figcaption></figure><p id="793d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，只显示适当的结果是错误的。以下是一些不太正确的结果。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/7de13c30de357b99842a82b3e6e06526.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*2TLWGM0qRiY9E-5TdkgrPw.gif"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">一个男人正在骑自行车</figcaption></figure><p id="e185" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个模型把自行车和自行车搞混了。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es md"><img src="../Images/e95dccc808faae0af5d78b67dc9c3983.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/1*bA72GzaQXqtV_9P53P4aJA.gif"/></div><figcaption class="kt ku et er es kv kw bd b be z dx translated">一只狗正在跳舞</figcaption></figure><p id="c5d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">不知何故，这个模型把猫和狗搞混了，它没有摆动爪子，而是认为它在跳舞。这个标题在语法上没有什么意义。</p><h1 id="d5be" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论</h1><p id="39de" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">谢谢你读到这里。更多详情请参考我的<a class="ae ll" href="https://github.com/Shreyz-max/Video-Captioning" rel="noopener ugc nofollow" target="_blank"> <strong class="ih hj"> Github </strong> </a>。</p><p id="cce8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让训练更好的一些方法是更多的数据洗牌。添加来自许多不同领域的视频。</p><p id="fc4b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">重要观点</strong></p><p id="be29" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们必须理解<strong class="ih hj">训练数据应该在语义上类似于测试数据</strong>。例如，如果我在动物的视频上训练模型，并在不同的活动上测试它，它肯定会给出不好的结果。</p><h1 id="843e" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">未来的工作</h1><ul class=""><li id="d111" class="kx ky hi ih b ii kn im ko iq me iu mf iy mg jc lc ld le lf bi translated">而不是使用给定的功能提取更多的功能，我自己使用像I3D专门为视频设计的模型</li><li id="9889" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">添加一个用户界面，使其更具吸引力，并将其部署到某个平台。</li><li id="bec6" class="kx ky hi ih b ii lg im lh iq li iu lj iy lk jc lc ld le lf bi translated">添加嵌入层和关注块来训练更长的视频。</li></ul><h1 id="66c8" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">参考</h1><p id="460f" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">【https://github.com/CryoliteZ/Video2Text T2】号</p><p id="aa66" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ll" href="https://github.com/PacktPublishing/Intelligent-Projects-Using-Python/tree/master/Chapter05" rel="noopener ugc nofollow" target="_blank">https://github . com/packt publishing/Intelligent-project-Using-Python/tree/master/chapter 05</a></p><div class="mh mi ez fb mj mk"><a href="https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8" rel="noopener follow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hj fi z dy mp ea eb mq ed ef hh bi translated">使用Keras的图像字幕——“教计算机描述图片”</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">目录:</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">towardsdatascience.com</p></div></div><div class="mt l"><div class="mu l mv mw mx mt my jn mk"/></div></div></a></div><div class="mh mi ez fb mj mk"><a href="https://arxiv.org/abs/1505.00487" rel="noopener  ugc nofollow" target="_blank"><div class="ml ab dw"><div class="mm ab mn cl cj mo"><h2 class="bd hj fi z dy mp ea eb mq ed ef hh bi translated">序列到序列-视频到文本</h2><div class="mr l"><h3 class="bd b fi z dy mp ea eb mq ed ef dx translated">真实世界的视频通常具有复杂的动态；和生成开放域视频描述的方法应该…</h3></div><div class="ms l"><p class="bd b fp z dy mp ea eb mq ed ef dx translated">arxiv.org</p></div></div></div></a></div><p id="81b5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">想要更多AI内容？在LinkedIn上关注我的每日更新。</p><h1 id="4d47" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">感谢您的阅读。如果你喜欢这篇文章，请给它一些掌声👏。希望你有美好的一天！</h1></div></div>    
</body>
</html>