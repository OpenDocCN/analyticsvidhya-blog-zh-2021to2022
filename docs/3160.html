<html>
<head>
<title>Azure Machine learning — Reinforcement Learning with Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Azure机器学习——用Tensorflow进行强化学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/azure-machine-learning-reinforcement-learning-with-tensorflow-909f4cadb2ed?source=collection_archive---------6-----------------------#2021-06-13">https://medium.com/analytics-vidhya/azure-machine-learning-reinforcement-learning-with-tensorflow-909f4cadb2ed?source=collection_archive---------6-----------------------#2021-06-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><h1 id="382f" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">在Azure机器学习中运行tensorflow强化学习</h1><h1 id="fe35" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">先决条件</h1><ul class=""><li id="8a34" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">Azure帐户</li><li id="d08e" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure Azure机器学习</li><li id="c93c" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">Azure存储</li><li id="e260" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">需要张量流&gt; 2.2.0</li></ul><h1 id="88e5" class="ie if hh bd ig ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb bi translated">步伐</h1><ul class=""><li id="335b" class="jc jd hh je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt bi translated">创建新计算机</li><li id="34ab" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">创建新笔记本</li><li id="d43e" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">我用的是colab的tensorflow rl样品</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="d2aa" class="ki if hh ke b fi kj kk l kl km">pip install --upgrade tensorflow</span><span id="fc84" class="ki if hh ke b fi kn kk l kl km">!sudo apt-get update<br/>!sudo apt-get install -y xvfb ffmpeg<br/>!pip install 'imageio==2.4.0'<br/>!pip install pyvirtualdisplay<br/>!pip install tf-agents</span></pre><p id="37c9" class="pw-post-body-paragraph ko kp hh je b jf kq kr ks jh kt ku kv jj kw kx ky jl kz la lb jn lc ld le jp ha bi translated">包括库</p><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="c1ea" class="ki if hh ke b fi kj kk l kl km">from __future__ import absolute_import, division, print_function<br/><br/>import base64<br/>import imageio<br/>import IPython<br/>import matplotlib<br/>import matplotlib.pyplot as plt<br/>import numpy as np<br/>import PIL.Image<br/>import pyvirtualdisplay<br/><br/>import tensorflow as tf</span></pre><ul class=""><li id="2e46" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">打印张量流</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="e8aa" class="ki if hh ke b fi kj kk l kl km">import tensorflow as tf<br/>print(tf.__version__)</span></pre><ul class=""><li id="e7cd" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">包括tf代理</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="589e" class="ki if hh ke b fi kj kk l kl km">from tf_agents.agents.dqn import dqn_agent<br/>from tf_agents.environments import suite_gym<br/>from tf_agents.environments import tf_py_environment<br/>from tf_agents.eval import metric_utils<br/>from tf_agents.metrics import tf_metrics<br/>from tf_agents.networks import sequential<br/>from tf_agents.policies import random_tf_policy<br/>from tf_agents.replay_buffers import tf_uniform_replay_buffer<br/>from tf_agents.trajectories import trajectory<br/>from tf_agents.specs import tensor_spec<br/>from tf_agents.utils import common</span></pre><ul class=""><li id="1798" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">设置显示</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="708b" class="ki if hh ke b fi kj kk l kl km"># Set up a virtual display for rendering OpenAI gym environments.<br/>display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()<br/>tf.version.VERSION</span></pre><ul class=""><li id="80d6" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">我有2.5.0版本</li><li id="c50e" class="jc jd hh je b jf ju jh jv jj jw jl jx jn jy jp jq jr js jt bi translated">超参数</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="9af2" class="ki if hh ke b fi kj kk l kl km">num_iterations = 20000 # @param {type:"integer"}<br/><br/>initial_collect_steps = 100  # @param {type:"integer"} <br/>collect_steps_per_iteration = 1  # @param {type:"integer"}<br/>replay_buffer_max_length = 100000  # @param {type:"integer"}<br/><br/>batch_size = 64  # @param {type:"integer"}<br/>learning_rate = 1e-3  # @param {type:"number"}<br/>log_interval = 200  # @param {type:"integer"}<br/><br/>num_eval_episodes = 10  # @param {type:"integer"}<br/>eval_interval = 1000  # @param {type:"integer"}</span></pre><ul class=""><li id="7712" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">环境</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="dadc" class="ki if hh ke b fi kj kk l kl km">env_name = 'CartPole-v0'<br/>env = suite_gym.load(env_name)</span><span id="08c1" class="ki if hh ke b fi kn kk l kl km">#@test {"skip": true}<br/>env.reset()<br/>PIL.Image.fromarray(env.render())</span></pre><p id="d056" class="pw-post-body-paragraph ko kp hh je b jf kq kr ks jh kt ku kv jj kw kx ky jl kz la lb jn lc ld le jp ha bi translated">输出</p><figure class="jz ka kb kc fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es li"><img src="../Images/51706a7cace6d66ede754cebf987f10a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uIwJ5PD2mPR3t9LVSgeYHQ.jpeg"/></div></div></figure><ul class=""><li id="081e" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">Tensorflow代理设置</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="40bd" class="ki if hh ke b fi kj kk l kl km">print('Reward Spec:')<br/>print(env.time_step_spec().reward)</span><span id="7fd5" class="ki if hh ke b fi kn kk l kl km">print('Action Spec:')<br/>print(env.action_spec())</span><span id="3d07" class="ki if hh ke b fi kn kk l kl km">time_step = env.reset()<br/>print('Time step:')<br/>print(time_step)<br/><br/>action = np.array(1, dtype=np.int32)<br/><br/>next_time_step = env.step(action)<br/>print('Next time step:')<br/>print(next_time_step)</span><span id="c3df" class="ki if hh ke b fi kn kk l kl km">train_py_env = suite_gym.load(env_name)<br/>eval_py_env = suite_gym.load(env_name)</span><span id="4952" class="ki if hh ke b fi kn kk l kl km">train_env = tf_py_environment.TFPyEnvironment(train_py_env)<br/>eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)</span></pre><ul class=""><li id="4ddd" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">【计算机】优化程序</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="aeac" class="ki if hh ke b fi kj kk l kl km">optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)<br/><br/>train_step_counter = tf.Variable(0)<br/><br/>agent = dqn_agent.DqnAgent(<br/>    train_env.time_step_spec(),<br/>    train_env.action_spec(),<br/>    q_network=q_net,<br/>    optimizer=optimizer,<br/>    td_errors_loss_fn=common.element_wise_squared_loss,<br/>    train_step_counter=train_step_counter)<br/><br/>agent.initialize()</span></pre><ul class=""><li id="0fe8" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">政策</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="6437" class="ki if hh ke b fi kj kk l kl km">eval_policy = agent.policy<br/>collect_policy = agent.collect_policy</span><span id="22b7" class="ki if hh ke b fi kn kk l kl km">random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),<br/>                                                train_env.action_spec())</span><span id="6c6b" class="ki if hh ke b fi kn kk l kl km">example_environment = tf_py_environment.TFPyEnvironment(<br/>    suite_gym.load('CartPole-v0'))</span><span id="bb51" class="ki if hh ke b fi kn kk l kl km">time_step = example_environment.reset()</span><span id="399b" class="ki if hh ke b fi kn kk l kl km">random_policy.action(time_step)</span></pre><ul class=""><li id="e75d" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">度量和评估</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="a5be" class="ki if hh ke b fi kj kk l kl km">#@test {"skip": true}<br/>def compute_avg_return(environment, policy, num_episodes=10):<br/><br/>  total_return = 0.0<br/>  for _ in range(num_episodes):<br/><br/>    time_step = environment.reset()<br/>    episode_return = 0.0<br/><br/>    while not time_step.is_last():<br/>      action_step = policy.action(time_step)<br/>      time_step = environment.step(action_step.action)<br/>      episode_return += time_step.reward<br/>    total_return += episode_return<br/><br/>  avg_return = total_return / num_episodes<br/>  return avg_return.numpy()[0]<br/><br/><br/># See also the metrics module for standard implementations of different metrics.<br/># https://github.com/tensorflow/agents/tree/master/tf_agents/metrics</span><span id="60e5" class="ki if hh ke b fi kn kk l kl km">compute_avg_return(eval_env, random_policy, num_eval_episodes)</span></pre><ul class=""><li id="a1a7" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">重放缓冲器</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="6d59" class="ki if hh ke b fi kj kk l kl km">replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(<br/>    data_spec=agent.collect_data_spec,<br/>    batch_size=train_env.batch_size,<br/>    max_length=replay_buffer_max_length)</span><span id="af6f" class="ki if hh ke b fi kn kk l kl km">agent.collect_data_spec</span><span id="7d73" class="ki if hh ke b fi kn kk l kl km">agent.collect_data_spec._fields</span></pre><ul class=""><li id="60f7" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">数据收集</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="1b76" class="ki if hh ke b fi kj kk l kl km">#@test {"skip": true}<br/>def collect_step(environment, policy, buffer):<br/>  time_step = environment.current_time_step()<br/>  action_step = policy.action(time_step)<br/>  next_time_step = environment.step(action_step.action)<br/>  traj = trajectory.from_transition(time_step, action_step, next_time_step)<br/><br/>  # Add trajectory to the replay buffer<br/>  buffer.add_batch(traj)<br/><br/>def collect_data(env, policy, buffer, steps):<br/>  for _ in range(steps):<br/>    collect_step(env, policy, buffer)<br/><br/>collect_data(train_env, random_policy, replay_buffer, initial_collect_steps)<br/><br/># This loop is so common in RL, that we provide standard implementations. <br/># For more details see tutorial 4 or the drivers module.<br/># https://github.com/tensorflow/agents/blob/master/docs/tutorials/4_drivers_tutorial.ipynb <br/># https://www.tensorflow.org/agents/api_docs/python/tf_agents/drivers</span><span id="f549" class="ki if hh ke b fi kn kk l kl km"># Dataset generates trajectories with shape [Bx2x...]<br/>dataset = replay_buffer.as_dataset(<br/>    num_parallel_calls=3, <br/>    sample_batch_size=batch_size, <br/>    num_steps=2).prefetch(3)<br/><br/><br/>dataset</span><span id="3f89" class="ki if hh ke b fi kn kk l kl km">iterator = iter(dataset)<br/>print(iterator)</span></pre><ul class=""><li id="ede7" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">培训代理</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="8616" class="ki if hh ke b fi kj kk l kl km">iterator = iter(dataset)<br/>print(iterator)</span></pre><ul class=""><li id="3e74" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">形象化</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="2868" class="ki if hh ke b fi kj kk l kl km">#@test {"skip": true}<br/><br/>iterations = range(0, num_iterations + 1, eval_interval)<br/>plt.plot(iterations, returns)<br/>plt.ylabel('Average Return')<br/>plt.xlabel('Iterations')<br/>plt.ylim(top=250)</span></pre><figure class="jz ka kb kc fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lq"><img src="../Images/fdc5cf9c89baec3b2e10eee6a69d32f7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ryfPIkwKu9MKeRrjbUxxBg.jpeg"/></div></div></figure><ul class=""><li id="f83a" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">录像</li></ul><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="b60f" class="ki if hh ke b fi kj kk l kl km">def embed_mp4(filename):<br/>  """Embeds an mp4 file in the notebook."""<br/>  video = open(filename,'rb').read()<br/>  b64 = base64.b64encode(video)<br/>  tag = '''<br/>  &lt;video width="640" height="480" controls&gt;<br/>    &lt;source src="data:video/mp4;base64,{0}" type="video/mp4"&gt;<br/>  Your browser does not support the video tag.<br/>  &lt;/video&gt;'''.format(b64.decode())<br/><br/>  return IPython.display.HTML(tag)</span><span id="5298" class="ki if hh ke b fi kn kk l kl km">def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):<br/>  filename = filename + ".mp4"<br/>  with imageio.get_writer(filename, fps=fps) as video:<br/>    for _ in range(num_episodes):<br/>      time_step = eval_env.reset()<br/>      video.append_data(eval_py_env.render())<br/>      while not time_step.is_last():<br/>        action_step = policy.action(time_step)<br/>        time_step = eval_env.step(action_step.action)<br/>        video.append_data(eval_py_env.render())<br/>  return embed_mp4(filename)<br/><br/><br/><br/><br/>create_policy_eval_video(agent.policy, "trained-agent")</span></pre><ul class=""><li id="b69d" class="jc jd hh je b jf kq jh kt jj lf jl lg jn lh jp jq jr js jt bi translated">图像</li></ul><figure class="jz ka kb kc fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es lr"><img src="../Images/8904cc8e816338a68b3829a7e3426703.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2TBnlLOnyMnbXaj2ShG7Qw.jpeg"/></div></div></figure><pre class="jz ka kb kc fd kd ke kf kg aw kh bi"><span id="3ab8" class="ki if hh ke b fi kj kk l kl km">create_policy_eval_video(random_policy, "random-agent")</span></pre><figure class="jz ka kb kc fd lj er es paragraph-image"><div role="button" tabindex="0" class="lk ll di lm bf ln"><div class="er es ls"><img src="../Images/0e853f255cc123984da924c9333e0c04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-oqZspbzsg1jKipX6u763A.jpeg"/></div></div></figure><p id="786f" class="pw-post-body-paragraph ko kp hh je b jf kq kr ks jh kt ku kv jj kw kx ky jl kz la lb jn lc ld le jp ha bi translated"><em class="lt">最初发表于</em><a class="ae lu" href="https://github.com/balakreshnan/Samples2021/blob/main/RL/azuremlrl.md" rel="noopener ugc nofollow" target="_blank"><em class="lt">【https://github.com】</em></a><em class="lt">。</em></p></div></div>    
</body>
</html>