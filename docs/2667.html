<html>
<head>
<title>Automated Hyperparameter Tuning with Keras Tuner and TensorFlow 2.0</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras Tuner和TensorFlow 2.0进行自动超参数调谐</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/automated-hyperparameter-tuning-with-keras-tuner-and-tensorflow-2-0-31ec83f08a62?source=collection_archive---------1-----------------------#2021-05-12">https://medium.com/analytics-vidhya/automated-hyperparameter-tuning-with-keras-tuner-and-tensorflow-2-0-31ec83f08a62?source=collection_archive---------1-----------------------#2021-05-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/755722900b23829a5e2a2bf55492b451.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/1*gDp9xrQbRBLRbQkjBBWH3w.png"/></div></figure><h1 id="af54" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">在现实世界中构建深度学习解决方案是一个不断实验和优化的过程。</h1><p id="4b29" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">与任何其他类型的软件应用不同，深度学习应用没有线性的图形生命周期，并且依赖于模型需要不断完善、优化和测试的事实。</p><p id="3a5c" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">一言以蔽之，模型优化和模型鲁棒性成正比！</p><p id="2193" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">作为深度学习实践者，你不能否认为你的模型选择正确的超参数是一项非常关键和痛苦的任务。</p><p id="d58c" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">因此，Google的TensorFlow创建了一个非常棒的框架来解决执行超参数调优和优化的痛点。</p><h2 id="fbdf" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">Keras Tuner是一个库，可以帮助您为真实世界的深度学习应用选择最佳的超参数集。</h2><figure class="lc ld le lf fd ij er es paragraph-image"><div class="er es lb"><img src="../Images/c4a6c3089d652c92db62025a80ce9b5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/1*Cdg9BeKw1Qeao_W8BXlu9g.gif"/></div></figure><p id="faf6" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在本文中，我们将了解如何使用Keras Tuner和TensorFlow 2.0为我们的模型选择最佳超参数！</p><p id="ce94" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在开始介绍Keras Tuner的惊人之处之前，让我们先了解一些重要的概念，以便顺利地阅读这篇博客。</p><h1 id="a49e" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">什么是超参数？</h1><p id="bf3e" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">超参数是控制ML模型的训练过程和拓扑的变量。这些变量在培训过程中保持不变，并直接影响您的ML计划的绩效。</p><p id="53a5" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">超参数优化是调整超参数以获得更好的模型学习和训练的过程。</p><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es lg"><img src="../Images/bc1c6213b3d21c24f88f44090bc076fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mfFEJVpnMwM-FQVn6mMb6w.png"/></div></div></figure><p id="0196" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">超参数有两种类型:</p><ol class=""><li id="2b2f" class="ll lm hi jm b jn ki jr kj jv ln jz lo kd lp kh lq lr ls lt bi translated"><strong class="jm hj">影响模型选择的模型超参数</strong>，如隐藏层的数量和宽度</li><li id="6e6e" class="ll lm hi jm b jn lu jr lv jv lw jz lx kd ly kh lq lr ls lt bi translated"><strong class="jm hj">算法超参数</strong>，影响学习算法的速度和质量，如随机梯度下降(SGD)的学习速率和k近邻(KNN)分类器的近邻数</li></ol><h1 id="6b06" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">为什么选择Keras Tuner？</h1><p id="272a" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">为了用更“深度学习”的直觉向您解释，我将解释某些被认为对您的模型优化很重要的超参数。</p><p id="4460" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">让我们考虑一个简单的卷积神经网络。它受到许多超参数的影响，比如-</p><ul class=""><li id="5707" class="ll lm hi jm b jn ki jr kj jv ln jz lo kd lp kh lz lr ls lt bi translated"><strong class="jm hj">隐藏层数</strong>—<strong class="jm hj">隐藏层</strong>的大小一般在输入和输出的大小之间。它应该是输入层大小加上输出层大小的2/3倍。这对规范模型训练非常重要。</li><li id="8ea7" class="ll lm hi jm b jn lu jr lv jv lw jz lx kd ly kh lz lr ls lt bi translated"><strong class="jm hj">学习率</strong> —所有超参数的教父，学习率量化模型的训练进度，优化其学习能力。</li><li id="5a2c" class="ll lm hi jm b jn lu jr lv jv lw jz lx kd ly kh lz lr ls lt bi translated"><strong class="jm hj">批量</strong> —超参数更新的一个非常重要的概念，批量是给网络的子样本数。它是一个梯度下降的超参数，控制在模型的内部参数更新之前训练样本的数量。</li><li id="a843" class="ll lm hi jm b jn lu jr lv jv lw jz lx kd ly kh lz lr ls lt bi translated"><strong class="jm hj">动量</strong> —这个超参数有助于用前几步的知识知道下一步的方向。它有助于防止振荡。</li></ul><p id="dc50" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">这些超参数中的每一个都在概化您的模型以获得最终稳健性方面发挥着巨大的作用。同时，选择正确的超参数值需要大量的试错过程。</p><p id="d753" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">你想用你的一生来调整深度学习模型吗？</p><p id="b0de" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">嗯，那感觉就像一场噩梦。</p><p id="f56b" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">你可能不需要！</p><blockquote class="ma mb mc"><p id="d9f4" class="jk jl md jm b jn ki jp jq jr kj jt ju me kk jx jy mf kl kb kc mg km kf kg kh hb bi translated"><strong class="jm hj"> Keras Tuner </strong>可以轻松定义搜索空间，并利用包含的算法找到最佳超参数值。<strong class="jm hj"> Keras Tuner </strong>自带<strong class="jm hj">贝叶斯优化</strong>、<strong class="jm hj"> Hyperband </strong>和<strong class="jm hj">随机搜索</strong>算法内置，也设计为便于研究人员扩展，以便试验新的搜索算法。— <a class="ae mh" href="https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html" rel="noopener ugc nofollow" target="_blank"> TensorFlow博客</a></p></blockquote><h2 id="98b5" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">让我们讨论3种不同类型的Keras调谐器，然后，我们将进入代码演练，向您展示它是如何工作的！</h2><h1 id="1632" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">可用的Keras调谐器概述</h1><p id="ab3b" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">到目前为止，有3种类型的Keras调谐器可用。</p><ol class=""><li id="ae0d" class="ll lm hi jm b jn ki jr kj jv ln jz lo kd lp kh lq lr ls lt bi translated"><strong class="jm hj">随机搜索Keras调谐器</strong></li></ol><p id="0b33" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">基本且效率最低的方法，<strong class="jm hj">随机搜索</strong>并不从之前测试的超参数组合中学习。它只是从搜索空间中随机抽取超参数组合。</p><p id="44e5" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">2.<strong class="jm hj">超波段Keras调谐器</strong></p><p id="cadb" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">超波段</strong>调谐器是随机搜索调谐器的优化版本，<strong class="jm hj">使用</strong>提前停止来加速超参数<strong class="jm hj">调谐</strong>过程。主要思想是为几个时期拟合多个模型，并且仅继续训练在验证集上达到最高准确度的模型。</p><p id="c9d0" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">3.<strong class="jm hj">贝叶斯优化Keras调谐器</strong></p><p id="9b98" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated"><strong class="jm hj">贝叶斯优化</strong>通过对超参数组合的子集进行采样，其工作原理与随机搜索相同。但是它们之间有一个关键的区别，这使得贝叶斯理论比随机搜索更聪明。</p><p id="95bd" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">关键区别在于，它不会随机对超参数组合进行采样；它遵循<strong class="jm hj">概率方法</strong>。它挑选已经测试过的组合，并使用这些数据对下一个组合进行采样。</p><blockquote class="mi"><p id="0849" class="mj mk hi bd ml mm mn mo mp mq mr kh dx translated">注意:你可以通过<a class="ae mh" href="https://keras-team.github.io/keras-tuner/documentation/hyperparameters/" rel="noopener ugc nofollow" target="_blank">文档</a>熟悉Keras Tuner的所有语法和方法。</p></blockquote><h1 id="44b8" class="im in hi bd io ip iq ir is it iu iv iw ix ms iz ja jb mt jd je jf mu jh ji jj bi translated">现在，是时候动手使用Keras调谐器了！</h1><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es mv"><img src="../Images/01d1464300504280acb5ef3d2bd6f861.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*cLwC9G_mo6evrYriechaBQ.gif"/></div></div><figcaption class="mw mx et er es my mz bd b be z dx translated">来源— <a class="ae mh" href="https://www.kdnuggets.com/" rel="noopener ugc nofollow" target="_blank"> KDnuggets </a></figcaption></figure><p id="f0ff" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi na translated"><span class="l nb nc nd bm ne nf ng nh ni di">为了</span>让你以更直观的方式理解调谐器搜索循环，我将提供一个代码演练，我们将在著名的<a class="ae mh" href="https://www.kaggle.com/zalando-research/fashionmnist" rel="noopener ugc nofollow" target="_blank">时尚MNIST数据集</a>上使用随机搜索<a class="ae mh" href="https://www.tensorflow.org/tutorials/keras/keras_tuner" rel="noopener ugc nofollow" target="_blank"> Keras调谐器</a>。</p><blockquote class="ma mb mc"><p id="e3cc" class="jk jl md jm b jn ki jp jq jr kj jt ju me kk jx jy mf kl kb kc mg km kf kg kh hb bi translated">注意—您不必从<a class="ae mh" href="https://www.kaggle.com/" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载该数据集，因为Keras已经提供了该数据集。此外，我想推荐使用<a class="ae mh" href="https://research.google.com/colaboratory/" rel="noopener ugc nofollow" target="_blank">谷歌合作实验室</a>来运行代码，因为它给你免费的GPU使用，不需要设置。</p></blockquote><h2 id="e11d" class="kn in hi bd io ko kp kq is kr ks kt iw jv ku kv ja jz kw kx je kd ky kz ji la bi translated">所以，拿起你的咖啡，让我们开始吧！🥤</h2><p id="ad7c" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">首先，让我们安装<strong class="jm hj"> Keras调谐器</strong>。</p><blockquote class="ma mb mc"><p id="6e39" class="jk jl md jm b jn ki jp jq jr kj jt ju me kk jx jy mf kl kb kc mg km kf kg kh hb bi translated"><strong class="jm hj">注意</strong>:在运行这个单元之前，在您的colab环境中，进入运行时&gt;更改运行时类型&gt;硬件加速器&gt; GPU &gt;保存。</p></blockquote><p id="b6b6" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">这将成功地在您的Colab环境中安装Keras调谐器。</p><p id="cc42" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在，让我们导入本实验的依赖项。</p><figure class="lc ld le lf fd ij"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="c8a8" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在，我们将从Keras加载我们的时尚MNIST数据。</p><figure class="lc ld le lf fd ij"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="1191" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在我们将缩小图像尺寸。由于255是RGB图像的最大值，除以255表示0–1。</p><figure class="lc ld le lf fd ij"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="3c99" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">您将收到(28，28)的输出，这表示我们的图像是28像素的。</p><p id="d2a0" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">大多数卷积神经网络被设计成只能接受固定大小的图像。克服这种限制的通常做法是<strong class="jm hj">对输入的<strong class="jm hj">图像</strong>进行</strong>整形，这样它们就可以被输入到网络中。</p><figure class="lc ld le lf fd ij"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="3079" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">太好了！我们已经预处理了我们的数据！</p><p id="f695" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在我们将使用build_model函数构建一个模型，并使用hp作为我们的超参数类实例。</p><p id="4e3a" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在函数内部，我们将定义一组用于调整的超参数，以及一个供Keras调谐器选择的最小-最大值范围。</p><figure class="lc ld le lf fd ij"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="ef0c" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">从上面的代码中可以看出，我们已经创建了一个卷积神经网络，它有2个卷积层、1个平坦层和2个致密层。</p><p id="e8ca" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">对于除最终输出密集层之外的每个层<em class="md">，我们设置了一个最小-最大范围(最小值和最大值), Keras调谐器将从中选取随机值。</em></p><p id="23e9" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在我们都设置为调用Keras调谐器。因此，让我们从Keras进口我们的RandomSearch调谐器。接下来，我们将使用我们的RandomSearch调优器，在3个时期内进行5次试验，看看我们目前达到的最佳验证精度是多少。</p><figure class="lc ld le lf fd ij"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="154b" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">当您运行此单元时，您的RandomSearch调谐器将执行5次试验，在每次试验的3个周期结束时，它将获得一些准确度分数。然后，它将输出5个试验精度中的最佳验证精度。</p><p id="10dd" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">让我们检查输出—</p><figure class="lc ld le lf fd ij er es paragraph-image"><div class="er es nl"><img src="../Images/bef1abb9fc522c6a71c7591cbfab69ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*447dNtU8S6_pJWOHJ4-89A.png"/></div></figure><p id="7db8" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">因此，我们可以看到，我们的调谐器报告了迄今为止最高的val_accuracy，达到91.4%。</p><p id="43b9" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在，进入最精彩的部分，我们将使用这个调谐器附带的一个非常棒的函数，即“tuner_search.get_best_models()”函数，它将向您报告用于图像分类数据的最佳模型的摘要！</p><figure class="lc ld le lf fd ij"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="3bb2" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">我们希望我们的数据有最好的模型；因此，我们将num_models设置为1，我们希望第一个模型是最好的，因此我们使用index [0]，它将输出最佳模型的摘要报告！</p><p id="5e0a" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">让我们看看生成的报告！</p><figure class="lc ld le lf fd ij er es paragraph-image"><div class="er es nm"><img src="../Images/fe53165ba2ef0b25945434377df2a429.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*rbIck2NJULd9WoysM81Gfg.png"/></div></figure><p id="1b0e" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">酷！我们得到了最佳模特报告！</p><p id="0dcd" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在，我们将重新训练我们的数据集，考虑我们的<em class="md">“最佳模型”！</em></p><blockquote class="ma mb mc"><p id="98b4" class="jk jl md jm b jn ki jp jq jr kj jt ju me kk jx jy mf kl kb kc mg km kf kg kh hb bi translated"><strong class="jm hj">注意</strong>:记住将initial_epoch设置为3，因为我们之前已经用3个epoch训练了我们的图像。所以这一次，我们从第四个开始！</p></blockquote><p id="8b3e" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">最后，我们将使用10个历元来训练我们的最佳模型，并查看我们现在达到的精度。</p><figure class="lc ld le lf fd ij"><div class="bz dy l di"><div class="nj nk l"/></div></figure><p id="cfce" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">现在让我们来看看准确度分数。你会惊讶的。😛</p><figure class="lc ld le lf fd ij er es paragraph-image"><div role="button" tabindex="0" class="lh li di lj bf lk"><div class="er es nn"><img src="../Images/8e25e685069b7f944b2174c6a7f40767.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hfY3rERkojAifpXjKzI2Nw.png"/></div></div></figure><p id="befb" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">在第10个纪元时，我们取得了99.02%的准确率！</p><p id="7894" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">仅18行代码就能产生大量结果！</p><blockquote class="ma mb mc"><p id="ba78" class="jk jl md jm b jn ki jp jq jr kj jt ju me kk jx jy mf kl kb kc mg km kf kg kh hb bi translated">⚠确保你把你的模型保存在一个pickle文件中，因为每次你运行单元时分数都会改变。</p></blockquote><h1 id="dc2a" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">结论</h1><p id="c7cb" class="pw-post-body-paragraph jk jl hi jm b jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh hb bi translated">希望你有兴趣探索Keras调谐器与这篇文章。如果你也像我一样是一个深度学习实践者，我建议你访问Keras调谐器文档，并用你选择的任何数据集尝试其他两个调谐器！</p><blockquote class="ma mb mc"><p id="99fe" class="jk jl md jm b jn ki jp jq jr kj jt ju me kk jx jy mf kl kb kc mg km kf kg kh hb bi translated"><strong class="jm hj">如果你是数据科学和机器学习的初学者，并且对数据科学/ML-AI、向数据科学的职业过渡指导、面试/简历准备有一些具体的疑问，或者甚至想在你的D-Day之前获得模拟面试，请随时在这里</strong>  <strong class="jm hj">预约1:1电话</strong> <a class="ae mh" href="https://topmate.io/sukannya" rel="noopener ugc nofollow" target="_blank"> <strong class="jm hj">。我很乐意帮忙！</strong></a></p></blockquote><p id="2834" class="pw-post-body-paragraph jk jl hi jm b jn ki jp jq jr kj jt ju jv kk jx jy jz kl kb kc kd km kf kg kh hb bi translated">你可以从我的<a class="ae mh" href="https://github.com/sukanyabag/ML-DL-NLP-resource-notebooks/blob/main/OptimizeCNNwithKerasTuner.ipynb" rel="noopener ugc nofollow" target="_blank"> GitHub </a>下载上面提供的代码，或者直接在<a class="ae mh" href="https://colab.research.google.com/drive/1kPO_YjAyNjc6YeRnw2b3dTkjEKhq0MOl#scrollTo=4ZKKr1IG3l6p" rel="noopener ugc nofollow" target="_blank"> Colab </a>中运行。</p><blockquote class="ma mb mc"><p id="cd4f" class="jk jl md jm b jn ki jp jq jr kj jt ju me kk jx jy mf kl kb kc mg km kf kg kh hb bi translated">要讨论更多关于深度学习的内容，请通过<a class="ae mh" href="https://www.linkedin.com/in/sukannya/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p></blockquote><h1 id="9d40" class="im in hi bd io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj bi translated">快乐学习！</h1></div></div>    
</body>
</html>