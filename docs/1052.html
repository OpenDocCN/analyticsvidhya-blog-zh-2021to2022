<html>
<head>
<title>Understanding the StyleGAN and StyleGAN2 Architecture</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解StyleGAN和StyleGAN2架构</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/understanding-the-stylegan-and-stylegan2-architecture-add9e992747d?source=collection_archive---------1-----------------------#2021-02-12">https://medium.com/analytics-vidhya/understanding-the-stylegan-and-stylegan2-architecture-add9e992747d?source=collection_archive---------1-----------------------#2021-02-12</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="4a06" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这篇文章包含了对StyleGAN和StyleGAN2架构的介绍，这将让您有所了解。从StyleGAN开始可能对你有帮助。您会发现一些您不知道的度量或操作名称，要深入了解StyleGAN和StyleGAN2，您可以浏览参考资料部分提供了链接的文章。</p><p id="a0e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们从StyleGAN开始，然后我们转向StyleGAN 2。</p><h1 id="16d7" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">StyleGAN</h1><p id="ec0c" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">他们在“GANs渐进增长”架构的发电机部分所做的主要改变。下面你可以看到传统的和基于风格的生成器(新的或风格网络)网络。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kg"><img src="../Images/38560f560b6c72db243bb6ca2649a313.png" data-original-src="https://miro.medium.com/v2/resize:fit:1384/0*nzmrf7VMLsTWt8SX"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">风格建筑</figcaption></figure><p id="22fa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在传统网络中，潜在向量在归一化之后直接进入块，而在StyleGAN网络中，归一化之后的潜在向量通过映射网络(8个完全连接的网络的层)，然后输出被变换(A代表仿射变换，其是线性变换和平移的组合)并被传递到块，并在实例归一化(AdaIN即自适应实例归一化)之后被添加噪声B。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ks"><img src="../Images/f204af339b48f55d40a41750d6296b1b.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/0*0MnUXJStHJb9D6m9"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">自适应实例规范化</figcaption></figure><p id="5afe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面，你可以看到AdaIN的公式，其中x来自conv网，y来自左侧网。很明显，在等式中可以看出，在x归一化后，y(s，I)用于缩放，y(b，I)作为偏差用于变换。下面你可以看到一个简单的样式。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es kt"><img src="../Images/c11c9d5378a9baf5108752a02a3a9d7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:742/0*N3-UCbXgKnIEavOj"/></div></figure><p id="3f02" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在官方论文中，你将看到CelebA和FF(Flickr Faces)高质量数据集上的结果，其中他们使用从训练集中随机抽取的50K张图像显示了FIDs (Frechet inception distances)分数。下面你可以看到结果</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ku"><img src="../Images/3bb04e4a059aa29ab66716e355475f12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1258/0*RxltMheIP8l0yBJ7"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">对应于CelebA和FF高质量数据集上不同配置的FIDs分数</figcaption></figure><p id="1a68" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">他们从基线配置A(渐进式GAN)开始，在添加双线性上/下采样、长训练后，他们看到了改进。然后添加映射网络和AdaIN操作，或者在配置D中，他们从综合网络中移除传统输入，并用4x4x512常数张量来替换它们。</p><p id="c327" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到FIDs值相对于传统生成器(B)的改进，启用混合正则化(该操作也称为样式混合)可以对样式和高级方面(如姿势、发型、眼镜等)进行更多控制。</p><p id="99fd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是对StyleGAN架构的简单介绍，现在让我们看看StyleGAN 2中有哪些改进，并了解其架构。</p><h1 id="8240" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">风格根2</h1><p id="41b3" class="pw-post-body-paragraph if ig hi ih b ii kb ik il im kc io ip iq kd is it iu ke iw ix iy kf ja jb jc hb bi translated">在下图中，您可以看到从64x64分辨率生成的图像中的缺陷或模糊部分。这是重新设计生成器的主要原因，生成的图像质量也有所提高。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es kv"><img src="../Images/05977e6691cba312502a7f744e556628.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*EUBI6MPU8vz3qFw7"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">水滴状伪像</figcaption></figure><p id="9c64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">那么，让我们来看看网络架构中的哪些变化一步步提高了生成图像的性能。下面你可以看到建筑方面的改进</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es la"><img src="../Images/bfc84c53f7851920be139e4a0218846d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*vHNCiQGmbXaTAfH5"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">StyleGAN合成网络改进</figcaption></figure><p id="206e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">A部分是相同的StyleGAN架构，B部分显示了StyleGAN架构的详细视图。在C部分中，他们用调制(或因子的缩放)和归一化替换了AdaIN(自适应实例归一化)。下面你可以看到调制(左侧)和正常化(右侧)方程。</p><div class="kh ki kj kk fd ab cb"><figure class="lb kl lc ld le lf lg paragraph-image"><img src="../Images/dc3363dd1dd2b5b9f0648d9a6d494db5.png" data-original-src="https://miro.medium.com/v2/resize:fit:422/0*swTSEhsjqMYU8WsZ"/></figure><figure class="lb kl lh ld le lf lg paragraph-image"><img src="../Images/1af002d49c36786f90b0d1e94d7e5680.png" data-original-src="https://miro.medium.com/v2/resize:fit:502/0*bquvXS8Pod0bo2gw"/><figcaption class="ko kp et er es kq kr bd b be z dx li di lj lk translated">调制和标准化</figcaption></figure></div><p id="241d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，在C部分，他们将噪声和偏置转移到模块之外。最后，在D部分中，你可以看到权重随着样式而调整，归一化被“解调”操作所取代，组合操作被称为“权重解调”。参见下面的公式。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es ll"><img src="../Images/352d0c27df04ecb7247e5bad3c021ad4.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/0*pX86FIvhWSiioOOF"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">权重解调</figcaption></figure><p id="6b32" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可以看到，这个方程似乎是上述两个调制和归一化方程的组合(ε是一个小的常数值，用于防止被零除之类的数值问题)。结果可以在下面的输出中看到，在用解调代替归一化之后，消除了液滴状伪像。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lm"><img src="../Images/05faa58e1ff7ee25c5864b85f1d43098.png" data-original-src="https://miro.medium.com/v2/resize:fit:1326/0*puk5_F0PZYvMVrhy"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">权重解调后生成的图像</figcaption></figure><p id="04c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，我们已经看到了生成图像形式的改进。让我们看看使用FID、感知路径长度(在StyleGAN的论文中介绍，PPL越低，生成的图像越好)等指标测量的改进。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div role="button" tabindex="0" class="kw kx di ky bf kz"><div class="er es ln"><img src="../Images/5a40aa8dabdc4f1d9cf14a368a4d2260.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6-w3_EZTPjcghAFm"/></div></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">最终样式GAN 2网络的主要结果</figcaption></figure><p id="1a3d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上表可以看出，采用不同方法后，配置有所改善。路径长度正则化和惰性正则化用于保持PPL分数较低，表明生成的图像更清晰或平滑。</p><p id="1686" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">网络的逐步发展产生了高质量的图像，但也导致了特征伪影(或相位伪影)，即无论人脸移动到哪里，人的眼睛和牙齿似乎都停留在一个地方，这在官方StyleGAN2视频中显示(视频链接附在下面的参考资料部分)。</p><p id="9834" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了解决这个问题，他们尝试了发生器和鉴别器网络上的其他连接(跳过连接、剩余网络等),发现跳过连接最适合发生器，剩余网络在鉴别器上给出更好的结果。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lo"><img src="../Images/589964d77ec10293d99e5bc11258fd4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1298/0*oI3NflVujlWTnXqx"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">无递增的发生器和鉴别器结构的比较。(G发生器、D鉴别器)</figcaption></figure><p id="33ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上表显示了各种连接组合的结果。此外，在上面的主结果表中，配置E和F显示了跳过连接类型发生器和剩余鉴别器网络的结果。</p><p id="051e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">下图中，<strong class="ih hj"> b </strong>中突出显示的部分是一个发生器，<strong class="ih hj"> c </strong>中突出显示的部分是一个没有渐进增长的鉴别器。</p><figure class="kh ki kj kk fd kl er es paragraph-image"><div class="er es lp"><img src="../Images/ad971865d013bb7f9a7c7d2e7b0361d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/0*e9EEE2_RiisQZljW"/></div><figcaption class="ko kp et er es kq kr bd b be z dx translated">虚线上方是发生器，下方是鉴别器。在上述主结果表的配置E和F中使用了突出显示的零件。</figcaption></figure><p id="e132" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">几乎所有的图片都来自StyleGAN和StyleGAN 2的官方论文，它们的链接在下面的参考资料部分给出。</p><h1 id="8d28" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">资源:</h1><ol class=""><li id="b74f" class="lq lr hi ih b ii kb im kc iq ls iu lt iy lu jc lv lw lx ly bi translated"><a class="ae lz" href="https://www.youtube.com/watch?v=9QuDh3W3lOY" rel="noopener ugc nofollow" target="_blank">用StyleGAN 2合成高分辨率图像——YouTube</a></li><li id="519f" class="lq lr hi ih b ii ma im mb iq mc iu md iy me jc lv lw lx ly bi translated"><a class="ae lz" href="https://www.youtube.com/watch?v=kSLJriaOumA" rel="noopener ugc nofollow" target="_blank">基于风格的生成性对抗网络生成器架构——YouTube</a></li><li id="0680" class="lq lr hi ih b ii ma im mb iq mc iu md iy me jc lv lw lx ly bi translated"><a class="ae lz" href="https://arxiv.org/pdf/1912.04958.pdf" rel="noopener ugc nofollow" target="_blank">分析并改善StyleGAN </a> (StyleGAN 2)的图像质量</li><li id="3b69" class="lq lr hi ih b ii ma im mb iq mc iu md iy me jc lv lw lx ly bi translated">用于生成式对抗网络的基于风格的生成器架构</li><li id="bb58" class="lq lr hi ih b ii ma im mb iq mc iu md iy me jc lv lw lx ly bi translated"><a class="ae lz" href="https://github.com/NVlabs/stylegan2" rel="noopener ugc nofollow" target="_blank"> NVlabs/stylegan2: StyleGAN2 —官方TensorFlow实现(github.com)</a></li><li id="9958" class="lq lr hi ih b ii ma im mb iq mc iu md iy me jc lv lw lx ly bi translated"><a class="ae lz" href="https://github.com/NVlabs/stylegan" rel="noopener ugc nofollow" target="_blank"> NVlabs/stylegan: StyleGAN —官方TensorFlow实现(github.com)</a></li></ol></div></div>    
</body>
</html>