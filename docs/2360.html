<html>
<head>
<title>TableNet: Deep Learning Model for End-to-end Table Detection and Tabular Data Extraction From
Scanned Document Images</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TableNet:深度学习模型，用于从扫描的文档图像中进行端到端表格检测和表格数据提取</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/tablenet-deep-learning-model-for-end-to-end-table-detection-and-tabular-data-extraction-from-1961fb2f97e1?source=collection_archive---------1-----------------------#2021-04-20">https://medium.com/analytics-vidhya/tablenet-deep-learning-model-for-end-to-end-table-detection-and-tabular-data-extraction-from-1961fb2f97e1?source=collection_archive---------1-----------------------#2021-04-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f32f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">计算机视觉是计算机看到和识别物体的媒介。计算机视觉的目标是使计算机能够分析图像和视频中的对象，解决不同的视觉问题。对象分割为方便分析图像和视频中的对象铺平了道路，为不同领域做出了巨大贡献，如医学、自动驾驶汽车中的视觉以及图像和视频中的背景编辑。</p><p id="23d6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这篇博客中，我将讨论一篇<strong class="ih hj">研究论文</strong> <strong class="ih hj"> TableNet: </strong>一个深度学习模型，通过分割出表格和列区域，从文档图像中进行表格检测和结构识别。</p><h1 id="0c73" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">目录</h1><ol class=""><li id="0c4b" class="kb kc hi ih b ii kd im ke iq kf iu kg iy kh jc ki kj kk kl bi translated">介绍</li><li id="981c" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">数据集源</li><li id="dbf1" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">问题陈述</li><li id="e3f3" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">映射到ML/DL问题</li><li id="fff3" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">数据集准备</li><li id="ee80" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">数据预处理</li><li id="aeed" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">模型开发</li><li id="79d0" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">表格数据提取</li><li id="ac76" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">部署</li><li id="365e" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">未来的工作</li><li id="381e" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">轮廓</li><li id="025f" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">参考</li></ol><h1 id="2785" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">1.介绍</h1><p id="f7f0" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">随着越来越多的移动设备配备了摄像头，越来越多的客户通过这些设备上传文档，使得从这些图像中提取信息的需求更加迫切。目前，这些文档图像通常是手动处理的，导致劳动力成本高和数据处理时间效率低。</p><p id="db67" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">大多数现有的表格信息抽取方法将问题分成两个独立的子问题，即<strong class="ih hj">表格检测</strong>、<strong class="ih hj">表格结构识别、</strong>，试图独立解决每个子问题。</p><p id="1ccd" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> TableNet </strong>获取单个输入图像，并为表和列生成两个不同的语义标记的输出图像。该模型通过使用预训练的<strong class="ih hj"> VGG-19作为基础网络</strong>，然后通过使用从VGG-19提取的特征使用<strong class="ih hj">两个解码器分支</strong>来做到这一点。一个解码器分支负责对表区域进行<strong class="ih hj">分割，另一个分支负责对列区域</strong>进行<strong class="ih hj">分割。检测到表格和列区域后，可以使用<strong class="ih hj"> Tesseract OCR提取表格数据。</strong></strong></p><h1 id="f2c4" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak"> 2。数据集来源</strong></h1><p id="557a" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">TableNet模型在marmot数据集上训练，该数据集包含扫描的文档图像及其对应的XML文件。XML文件包含关于表格和列区域在各个扫描文档图像中的位置的信息。</p><div class="ku kv ez fb kw kx"><a href="https://drive.google.com/drive/folders/1410iMmQCXbA9GJP5CqLEMfjjv-hOWlac?usp=sharing" rel="noopener  ugc nofollow" target="_blank"><div class="ky ab dw"><div class="kz ab la cl cj lb"><h2 class="bd hj fi z dy lc ea eb ld ed ef hh bi translated">土拨鼠_数据-谷歌驱动</h2><div class="le l"><h3 class="bd b fi z dy lc ea eb ld ed ef dx translated">编辑描述</h3></div><div class="lf l"><p class="bd b fp z dy lc ea eb ld ed ef dx translated">drive.google.com</p></div></div><div class="lg l"><div class="lh l li lj lk lg ll lm kx"/></div></div></a></div><h1 id="10ec" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">3.问题陈述</h1><ol class=""><li id="be62" class="kb kc hi ih b ii kd im ke iq kf iu kg iy kh jc ki kj kk kl bi translated">如果存在任何表格状结构，则从图像中分割出表格区域。</li><li id="7bb2" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated">从表中提取数据。</li></ol><h1 id="5275" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">4.映射到ML/DL问题</h1><p id="8ebc" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">为了从给定的输入图像中提取表格信息，我们需要从输入图像中分割出表格和列区域。我们可以将<strong class="ih hj">扫描图像视为输入</strong>，将<strong class="ih hj">表格掩码和列掩码视为输出</strong>。因此，我们需要对每个像素进行分类，即像素是否属于表格。我们可以把这个问题解释为分类问题(<strong class="ih hj">分割任务</strong>)。</p><p id="eb94" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">绩效指标</strong>—<strong class="ih hj">F1-得分</strong>。<br/> F1得分同等考虑<strong class="ih hj">精度</strong>和<strong class="ih hj">召回</strong>，即<strong class="ih hj">假阴性</strong>和<strong class="ih hj">假阳性</strong>案例将被同等扣分。</p><h1 id="48ea" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">5.数据集准备</h1><p id="3df7" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">从给定的marmot数据集，我们在。BMP格式和相应的XML文件。XML文件包含图像中每一列的坐标。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es ln"><img src="../Images/5fe519f35f82f431dbdd4b6666818ab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w5htu0PDkkJS-hr08NIj4g.jpeg"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">样本输入图像</figcaption></figure><figure class="lo lp lq lr fd ls"><div class="bz dy l di"><div class="mc md l"/></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">给定图像的示例xml文件</figcaption></figure><p id="c26c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">XML文件包含许多元素，如文件名、路径、大小、对象。<strong class="ih hj">文件名</strong>定义了相应图像的名称。<strong class="ih hj">尺寸</strong>表示输入图像的尺寸。<strong class="ih hj">对象</strong>给出列坐标。每个对象元素都是输入图像中的一列。</p><p id="fc31" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以看到，对于每一个<strong class="ih hj"> &lt;对象&gt; </strong>我们都有<strong class="ih hj">&lt;&gt;</strong>元素，在<strong class="ih hj"> &lt; bndbox &gt; </strong>内部我们有<strong class="ih hj"> xmin </strong>，<strong class="ih hj"> ymin </strong>，<strong class="ih hj"> xmax </strong>，<strong class="ih hj"> ymax，</strong>给出列(xmin，ymin) (xmax，ymax)的坐标。从给定的XML文件中，我们需要创建表掩码和列掩码图像。下面我给出了从XML文件中提取信息的代码，以创建表格和列掩码。从XML文件创建遮罩时，用像素值255填充带框区域，如果不是带框区域，则填充0。</p><figure class="lo lp lq lr fd ls"><div class="bz dy l di"><div class="mc md l"/></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">从XML文件创建掩码的示例代码</figcaption></figure><p id="8fb1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于每个输入图像，我们需要生成表掩码和列掩码。我们将输入图像和2个蒙版保存为JPEG文件格式。<strong class="ih hj">创建一个熊猫数据帧，有3列</strong> - <strong class="ih hj">原始_图像_路径</strong>、<strong class="ih hj">表格_掩码_路径</strong>、<strong class="ih hj">列_掩码_路径</strong>。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es me"><img src="../Images/4811d402e48ef007a0808c0b11bc8a46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*37vhEwDNQWyMmNskylaZAw.jpeg"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">样品柱掩模</figcaption></figure><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es me"><img src="../Images/da4d8239dbfdc60271b6e91f57cbb2f0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AFC5IMcifUUgiBY9TflqTQ.jpeg"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">样本表掩码</figcaption></figure><h1 id="5d9d" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated"><strong class="ak"> 6。数据预处理</strong></h1><p id="b025" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">研究论文建议将输入图像的尺寸调整为1024*1024。图像只不过是矩阵。我们的输入图像是RGB图像，因此每个像素有3个值(红、绿、蓝)。为了训练出TableNet模型，我们需要将图像加载到内存，然后开始训练过程。但是由于内存的限制，所有的图像不能一次加载到内存中。因此，我们需要一个数据加载器，它将包含批量图像，并通过定义的图像批量模型进行训练。</p><p id="043a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集对象是从熊猫系列创建的。</p><figure class="lo lp lq lr fd ls"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="4a09" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在为训练和测试创建数据集对象之后，我们将读取每个图像、保存的表掩码、列掩码。文件图像的尺寸调整为1024*1024*3，屏蔽图像的尺寸调整为1024*1024*1，即灰度图像。文档图像中的每个像素值可以在0到255之间。每个图像通过除以255.0进行归一化，因此像素值将在0-1之间缩放。</p><figure class="lo lp lq lr fd ls"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="8df7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集对象被给定一个批量大小，因此数据集对象将在给定批量图像中发出图像。</p><figure class="lo lp lq lr fd ls"><div class="bz dy l di"><div class="mc md l"/></div></figure><h1 id="19f1" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">7.模型开发</h1><figure class="lo lp lq lr fd ls"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="7d3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> TableNet </strong>模型主要由3部分组成。<br/> <strong class="ih hj"> i .编码器(VGG-19) </strong> <br/> <strong class="ih hj"> ii .</strong> <br/> <strong class="ih hj"> iii解码器(表格掩码生成器)。解码器(列掩码生成器)</strong></p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mf"><img src="../Images/c2227178a7ec8ccd657ba9775d8e968f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*goRSu7YaCn3Ef8uP7HQZCg.jpeg"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">TableNet模型体系结构</figcaption></figure><p id="b80b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">TableNet模型背后的直觉是使用预训练的VGG-19模型从输入图像中提取特征，然后通过2个解码器分支处理提取的特征，以生成屏蔽输出。编码器层将对图像进行下采样，解码器层将对图像进行上采样。</p><h2 id="1d26" class="mg je hi bd jf mh mi mj jj mk ml mm jn iq mn mo jr iu mp mq jv iy mr ms jz mt bi translated">一.编码器</h2><figure class="lo lp lq lr fd ls"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="14e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">模型输入尺寸为1024*1024*3。然后，输入图像在没有完全连接层的情况下通过预训练的VGG-19模型，从而产生特征向量，该特征向量将被传递到两个解码器分支。</p><p id="2c44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后，经过下采样的输入图像通过两个1x1 conv2D层进行处理。</p><p id="e664" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用(1x1)卷积背后的直觉是降低特征图(通道)的维度，该特征图用于像素的类别预测。</p><h2 id="44bd" class="mg je hi bd jf mh mi mj jj mk ml mm jn iq mn mo jr iu mp mq jv iy mr ms jz mt bi translated">二。解码器(表格掩码)</h2><p id="b92e" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">经过两个conv2D层后的缩减采样图像，再次经过一个1x1 conv2D层处理。然后借助跳池技术，将解码器网络的低分辨率特征映射与编码器网络的高分辨率特征相结合。在向上采样之后，我们将得到形状(1024*1024*2)的输出表掩码。输出图像有2个通道，因为我们有2个类别标签(背景，蒙版区域)。为了预测像素值的输出值，我们需要选择预测概率高的类。</p><h2 id="ec99" class="mg je hi bd jf mh mi mj jj mk ml mm jn iq mn mo jr iu mp mq jv iy mr ms jz mt bi translated">三。解码器(列掩码)</h2><p id="7fb9" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">来自1x1 conv2D层的特征向量被传递到解码器(列掩码)，但与表解码器不同，输入特征向量通过两个1*1 conv2D层进行处理，然后在样本图像中使用跳池技术。列解码器的输出为1024*1024*2。</p><h1 id="af55" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">8.表格数据提取</h1><figure class="lo lp lq lr fd ls"><div class="bz dy l di"><div class="mc md l"/></div></figure><p id="2cbe" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">形状(1，1024，1024，3)的输入图像被传递给模型，模型预测形状(1，1024，1024，2)的col_mask和table_mask。我们需要使用argmax提取最大概率类。然后图像以PNG格式保存。然后，我们从输出蒙版中提取阿尔法通道，这样我们就可以将该阿尔法通道添加到输入图像中，以遮盖原始图像。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div role="button" tabindex="0" class="lt lu di lv bf lw"><div class="er es mu"><img src="../Images/a4316d7840884fa5c8dfa8a9298e09bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ndFRy6Vn-MX9wldV_57rOA.png"/></div></div><figcaption class="ly lz et er es ma mb bd b be z dx translated">掩蔽图像</figcaption></figure><p id="bbcc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">之后，我们将通过Tesseract OCR进行处理，以提取表格数据。</p><figure class="lo lp lq lr fd ls er es paragraph-image"><div class="er es mv"><img src="../Images/d1ed3d4571d57d8bbb1f17d4bb6b5c7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1244/format:webp/1*DgLnSn27mXEqwOxN0uJCDg.png"/></div></figure><figure class="lo lp lq lr fd ls"><div class="bz dy l di"><div class="mc md l"/></div></figure><h1 id="b327" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">9.部署</h1><p id="d7c4" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">使用Flask在本地系统中部署模型。代码可以在<a class="ae mw" href="https://github.com/green93/TableNet-model-deployment-using-Flask" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><h1 id="f4ab" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">10.未来的工作</h1><p id="ef02" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">a.模型的性能可以进一步提高，但由于缺乏计算能力，我们受到限制。</p><h1 id="ca1c" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">11.轮廓</h1><p id="9a27" class="pw-post-body-paragraph if ig hi ih b ii kd ik il im ke io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">在<a class="ae mw" href="https://www.linkedin.com/in/devi-prasad-69865b177/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>和我联系。<a class="ae mw" href="https://github.com/green93/TableNet-Deep-Learning-model-for-Tabular-Data-Extraction-from-Scanned-Document-Image" rel="noopener ugc nofollow" target="_blank">这个</a>是github全部代码的仓库。</p><h1 id="0b82" class="jd je hi bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">12.参考</h1><ol class=""><li id="3f37" class="kb kc hi ih b ii kd im ke iq kf iu kg iy kh jc ki kj kk kl bi translated"><a class="ae mw" href="https://arxiv.org/pdf/2001.01469.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/2001.01469.pdf</a></li><li id="4516" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated"><a class="ae mw" href="https://www.appliedaicourse.com/course/11/Applied-Machine-learning-course" rel="noopener ugc nofollow" target="_blank">https://www . Applied ai course . com/course/11/Applied-Machine-learning-course</a></li><li id="c0f1" class="kb kc hi ih b ii km im kn iq ko iu kp iy kq jc ki kj kk kl bi translated"><a class="ae mw" href="https://www.tensorflow.org/tutorials/images/segmentation" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tutorials/images/segmentation</a></li></ol></div></div>    
</body>
</html>