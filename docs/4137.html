<html>
<head>
<title>Finding “Waldo” using a simple Convolutional Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用简单的卷积神经网络寻找“瓦尔多”</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/finding-waldo-using-a-simple-convolutional-neural-network-1604cb4d2e55?source=collection_archive---------2-----------------------#2021-08-31">https://medium.com/analytics-vidhya/finding-waldo-using-a-simple-convolutional-neural-network-1604cb4d2e55?source=collection_archive---------2-----------------------#2021-08-31</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/c73dbfb5180dec1c1dd79e563654782d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1264/format:webp/1*w7615jlQjQCghLQPQGxzkg.jpeg"/></div></figure><p id="cf10" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi jk translated">我已经拥有了几十个“沃尔多在哪里？”我年轻时读过书，我相信你也读过。如果你不知道是什么，“沃尔多在哪里？”<em class="jt">(有时被称为“沃利在哪里？”是一系列由详细的双页卡通插图组成的书，展示了数百人在给定的地点做各种有趣的事情。我们面临的挑战是找到一个名为“瓦尔多”<em class="jt">(或沃利)</em>的虚构人物，他隐藏在插图中的其他人中间。众所周知，瓦尔多穿着红白条纹衬衫，戴着圆顶礼帽和眼镜，很难找到。</em></p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ju"><img src="../Images/88e6099e603e47eb19e9161fdf7c365b.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*oTiFJL-RIuEJc-GXtK3JIQ.gif"/></div></figure><p id="31ce" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最近，在学习了一些新的对象定位和分类技术后，我想到了回归基础，使用<em class="jt"> Tensorflow </em> functional API从头构建一个对象定位和分类教程。首先，我创建了一些样本图像，然后实现了一个卷积神经网络，最后训练了这个模型，看看它可以预测Waldo在图像中的位置有多好。我还引入了另一个角色“Wilma”，看看模型是否可以在这两个角色之间进行分类，同时找到他们在图像中的位置。在这篇博客中，我描述了从数据合成到模型训练的过程。因此，如果你是对象本地化的初学者，这将是一个简单而有趣的教程。如果你想去查看<em class="jt"> Jupyter笔记本，</em>点击<a class="ae jz" href="https://github.com/kaneelgit/ML-DL-Algorithms/blob/main/Object%20Detection%20and%20Localization%20using%20Tensorflow.ipynb" rel="noopener ugc nofollow" target="_blank">这里。</a></p><p id="3ebb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">合成数据</strong></p><p id="759b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">首先我们需要综合一些数据，以便神经网络能够学习。为此，我们将使用一个示例背景图像，并在图像中随机放置“Waldo”或“Wilma”。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/5b886bb64bde5db2e687e4e2b74ff8dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*i0t8QdH3uws5lLjk4lA5cw.jpeg"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated"><strong class="bd kf">用于合成数据的背景图像</strong></figcaption></figure><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/f5c542c0f28759d012cbabb3d895cbda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*ovYAwclaGvfHBNZB7gbfMg.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated"><strong class="bd kf">用于合成样本图像的Waldo(左)和Wilma(右)的图像</strong></figcaption></figure><p id="8997" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了创建一个样本图像，我们将使用以下函数。该功能导入背景图像，Waldo &amp; Wilma的图像，然后将Waldo或Wilma放置在背景图像的某个随机位置<em class="jt">(注意图像的左上角将与该随机位置重合)。</em>该函数随后输出合成图像、我们放置人的随机位置<em class="jt"> (x，y坐标为元组)和我们放置的</em><em class="jt">(如果是瓦尔多或威尔玛)</em>。</p><pre class="jv jw jx jy fd kg kh ki kj aw kk bi"><span id="fede" class="kl km hi kh b fi kn ko l kp kq"><em class="jt">#create a function to generate images</em><br/><strong class="kh hj">def</strong> generate_sample_image():<br/>    <br/>    <em class="jt">#background image</em><br/>    background_im = Image.open(background_dir)<br/>    background_im = background_im.resize((500, 350))<br/>    <em class="jt">#background_im = Image.new("RGB", (500, 350), (255, 255, 255))</em><br/><br/>    <em class="jt">#waldo</em><br/>    waldo_im = Image.open(waldo_dir)<br/>    waldo_im = waldo_im.resize((60, 100))<br/><br/>    <em class="jt">#wilma</em><br/>    wilma_im = Image.open(wilma_dir)<br/>    wilma_im = wilma_im.resize((60, 100))<br/>    <br/>    <em class="jt">#select x and y coordinates randomly we'll select between (0, 430) and (0, 250)</em><br/>    col = np.random.randint(0, 410)<br/>    row = np.random.randint(0, 230)<br/>    <br/>    <em class="jt">#pic randomly between waldo and wilma. If 1 we will select waldo. if 0 we wills elect wilma</em><br/>    rand_person = np.random.choice([0, 1], p = [0.5, 0.5])<br/>    <br/>    <strong class="kh hj">if</strong> rand_person == 1:<br/>        <br/>        background_im.paste(waldo_im, (col, row), mask = waldo_im)<br/>        cat = 'Waldo'<br/>        <br/>    <strong class="kh hj">else</strong>:<br/>        <br/>        background_im.paste(wilma_im, (col, row), mask = wilma_im)<br/>        cat = 'Wilma'<br/>        <br/>    <strong class="kh hj">return</strong> np.array(background_im).astype('uint8'), (col, row), rand_person, cat</span></pre><p id="3d26" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下面我们有一个由我们的函数创建的样本图像。如果你能在这张图片中找到沃尔多或威尔玛，你自己检查一下吧！</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es ka"><img src="../Images/aba3b1d5144ffef04f5b860678bf113f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*847WXsHfsa3wl0ivIe2mRg.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated"><strong class="bd kf">我们的函数</strong>生成的样本图像</figcaption></figure><p id="e113" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果你没有在这张照片中找到沃尔多或威尔玛，不要担心！，我们的算法会帮助我们找到它们。<em class="jt">(在这个例子中，瓦尔多在两把伞之间)</em></p><p id="5f6d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">创建边界框</strong></p><p id="f978" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">边界框是显示对象在图像中位置的常用方式。通常，我们将向模型提供边界框的坐标，并训练它来预测边界框的坐标。理想情况下，完全训练的模型将预测与实际边界框重叠的边界框。</p><p id="23c6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，我们将创建一个边界框来可视化瓦尔多和威尔玛的位置。正如我以前说过的，瓦尔多或威尔玛的每个图像的左上角，将与随机位置重合。所以边界框的左上角将是这个由<em class="jt"> generate_sample_image </em>函数生成的随机位置。</p><pre class="jv jw jx jy fd kg kh ki kj aw kk bi"><span id="843a" class="kl km hi kh b fi kn ko l kp kq"><strong class="kh hj">def</strong> plot_bounding_box(image, gt_coords, pred_coords = <strong class="kh hj">None</strong>):<br/>    <br/>    <em class="jt">#convert image to array</em><br/>    image = Image.fromarray(image)    <br/>    draw = ImageDraw.Draw(image)<br/>    draw.rectangle((gt_coords[0], gt_coords[1], gt_coords[0] + 60,    gt_coords[1] + 100), outline = 'green', width = 5)<br/>    <br/>    <strong class="kh hj">if</strong> pred_coords:<br/>        <br/>        draw.rectangle((pred_coords[0], pred_coords[1], pred_coords[0] + 60, pred_coords[1] + 100), outline = 'red', width = 5)<br/>    <br/>    <strong class="kh hj">return</strong> image</span></pre><p id="8b99" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">该功能输入图像、真实坐标和预测坐标<em class="jt">(仅在给定的情况下)</em>，然后在给定位置输出带有边界框的图像。下面是我们给出图像中出现的人的实际位置和预测位置时，这个函数生成的图像。注意，真实图像将由绿色矩形表示，而预测图像将由红色矩形表示。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div class="er es kr"><img src="../Images/7ab46d16d6d4a7c3440accf68be732da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hrXwIJgw51P6p1xJh_IK-g.png"/></div><figcaption class="kb kc et er es kd ke bd b be z dx translated"><strong class="bd kf">由函数</strong>生成的实际和预测边界框</figcaption></figure><p id="845b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">数据发生器</strong></p><p id="3815" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来，我们将为我们的模型创建一个数据生成器。这个数据生成器函数用于不断地向我们的模型提供图像。我们将生成训练图像、类<em class="jt">(如果是包含Waldo或Wilma的图像)</em>和边界框的位置<em class="jt">(该位置的x和y坐标)。</em>因为，我们的边界框是同样大小的矩形，我们只需要将边界框的左上角坐标输入到模型中。我们的数据生成器函数将批量输入图像，这里我们使用了默认值16作为批量大小。</p><pre class="jv jw jx jy fd kg kh ki kj aw kk bi"><span id="99af" class="kl km hi kh b fi kn ko l kp kq"><em class="jt">#data generator function </em><br/><strong class="kh hj">def</strong> generate_data(batch_size = 16):<br/>    <br/>    <strong class="kh hj">while</strong> <strong class="kh hj">True</strong>:<br/>        <br/>        <em class="jt">#create empty arrays for the generated data</em><br/>        x_batch = np.zeros((batch_size, 350, 500, 3))<br/>        y_batch = np.zeros((batch_size, 1))<br/>        boundary_box = np.zeros((batch_size, 2))<br/>        <br/>        <strong class="kh hj">for</strong> i <strong class="kh hj">in</strong> range(batch_size):<br/>            <br/>            <em class="jt">#generate an example image</em><br/>            sample_im, pos, person, _ = generate_sample_image()<br/>            <br/>            <em class="jt">#put the images to the arrays</em><br/>            x_batch[i] = sample_im/255 <em class="jt">#normalize</em><br/>            y_batch[i] = person<br/>            boundary_box[i, 0] = pos[0]<br/>            boundary_box[i, 1] = pos[1]<br/>            <br/>        <strong class="kh hj">yield</strong> {'image': x_batch} , {'class': y_batch, 'box':      boundary_box}</span></pre><p id="fa32" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">使用Tensorflow实现模型</strong></p><p id="042d" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们的模型有三个主要部分。我们将使用Tensorflow functional API为每个部分定义一个函数。第一部分提取特征，第二部分创建回归输出，最后部分创建分类输出。下面是我们模型的概述。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es ks"><img src="../Images/b19766b68d32857e837ca9fc21efef5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3YlTTugUQDlSRJfxYpt_zg.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated"><strong class="bd kf">我们模型的概述</strong></figcaption></figure><p id="de61" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如前所述，在模型的第一部分，我们必须检测训练图像的特征。为了做到这一点，我们将使用多个卷积层，每个卷积层后面都有批处理规范化和最大池。下面是执行这部分模型的函数。</p><pre class="jv jw jx jy fd kg kh ki kj aw kk bi"><span id="18c0" class="kl km hi kh b fi kn ko l kp kq">#create the model<br/>def convolutional_block(inputs):<br/>    <br/>    x = tf.keras.layers.Conv2D(16, 3, padding = 'same', activation = 'relu')(inputs)<br/>    x = tf.keras.layers.BatchNormalization()(x)<br/>    x = tf.keras.layers.MaxPool2D(2)(x)<br/>    <br/>    x = tf.keras.layers.Conv2D(32, 3, padding = 'same', activation = 'relu')(x)<br/>    x = tf.keras.layers.BatchNormalization()(x)<br/>    x = tf.keras.layers.MaxPool2D(2)(x)<br/>    <br/>    x = tf.keras.layers.Conv2D(64, 6, padding = 'valid', activation = 'relu')(x)<br/>    x = tf.keras.layers.BatchNormalization()(x)<br/>    x = tf.keras.layers.MaxPool2D(2)(x)<br/>        <br/>    x = tf.keras.layers.Conv2D(64, 6, padding = 'valid', activation = 'relu')(x)<br/>    x = tf.keras.layers.BatchNormalization()(x)<br/>    x = tf.keras.layers.MaxPool2D(2)(x)<br/>    <br/>    return x</span></pre><p id="c85a" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">接下来我们将定义回归块。回归块包含盒子位置的输出。我们将首先展平从卷积模块获得的输出，然后使用几个密集层，最后是没有激活的密集层。</p><pre class="jv jw jx jy fd kg kh ki kj aw kk bi"><span id="1540" class="kl km hi kh b fi kn ko l kp kq">def regression_block(x):<br/>    <br/>    x = tf.keras.layers.Flatten()(x)<br/>    x = tf.keras.layers.Dense(1024, activation = 'relu')(x)<br/>    x = tf.keras.layers.Dense(512, activation = 'relu')(x)<br/>    x = tf.keras.layers.Dense(2, name = 'box')(x)<br/>    <br/>    return x</span></pre><p id="f6e7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最后，我们将定义分类块。这也将具有平坦层，接着是几个致密层，以及具有单个神经元和s形激活的最终致密层。我们使用sigmoid激活，因为我们正在执行二元分类。</p><pre class="jv jw jx jy fd kg kh ki kj aw kk bi"><span id="8f39" class="kl km hi kh b fi kn ko l kp kq">def classification_block(x):<br/>    <br/>    x = tf.keras.layers.Flatten()(x)<br/>    x = tf.keras.layers.Dense(1024, activation = 'relu')(x)<br/>    x = tf.keras.layers.Dense(512, activation = 'relu')(x)<br/>    x = tf.keras.layers.Dense(1, activation = 'sigmoid', name = 'class')(x)<br/>    <br/>    return x</span></pre><p id="fb3b" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">最后，我们将定义输入和输出，并启动模型。</p><pre class="jv jw jx jy fd kg kh ki kj aw kk bi"><span id="4b0f" class="kl km hi kh b fi kn ko l kp kq">#create the model instance<br/>inputs = tf.keras.Input((350, 500, 3))</span><span id="e54b" class="kl km hi kh b fi kx ko l kp kq">#conv block<br/>x = convolutional_block(inputs)</span><span id="bb86" class="kl km hi kh b fi kx ko l kp kq">#outputs<br/>box_output = regression_block(x)<br/>class_output = classification_block(x)</span><span id="30b3" class="kl km hi kh b fi kx ko l kp kq">#model instance<br/>model = tf.keras.Model(inputs = inputs, outputs = [class_output, box_output])</span></pre><p id="a2f1" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这是模型的概要图。<em class="jt">(注意，前几个卷积层未示出)</em></p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es ky"><img src="../Images/31447a79db64ac210cbe101f6e612ccd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*yTbmKRzFp75-iRxFepwcgw.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated"><strong class="bd kf">模型的剧情</strong></figcaption></figure><p id="1d20" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">编译并训练我们的模型</strong></p><p id="bfe0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在让我们编译和训练我们的模型。在此之前，我们将创建一些定制的回调函数来可视化我们在训练期间的输出。我们将创建一个函数来进行预测，并在训练时每两个时期绘制一次。这将让我们看到模型如何通过更多的训练来改进它的预测。</p><p id="22e8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">下面的函数<em class="jt"> test_model </em>创建三个示例图像，然后使用当前模型来预测类别和边界框位置。该功能将用“绿色”绘制真实边界框，用“红色”绘制预测边界框。该函数还将在图像的x标签中打印预测的类。</p><pre class="jv jw jx jy fd kg kh ki kj aw kk bi"><span id="e0e2" class="kl km hi kh b fi kn ko l kp kq">#custom function to visualize the predictions after epochs<br/>def test_model():<br/>    <br/>    fig, ax = plt.subplots(1, 3, figsize = (15, 5))    <br/>    <br/>    for i in range(3):<br/>        <br/>        #get sample image<br/>        sample_im, pos, _, cat = generate_sample_image()<br/>        sample_image_normalized = sample_im.reshape(1, 350, 500, 3)/255<br/>        predicted_class, predicted_box = model.predict(sample_image_normalized)<br/>        <br/>        if predicted_class &gt; 0.5:<br/>            predicted_class = 'Waldo'<br/>        else:<br/>            predicted_class = 'Wilma'<br/>        <br/>        #assign color<br/>        col = 'green' if (predicted_class == cat) else 'red'<br/>        <br/>        #get bounding boxes<br/>        im = plot_bounding_box(sample_im, pos, (predicted_box[0][0], predicted_box[0][1]))<br/>        <br/>        #plot image<br/>        ax[i].imshow(im)<br/>        ax[i].set_xticks([])<br/>        ax[i].set_yticks([])<br/>        ax[i].set_ylabel('True: ' + cat, color = 'green')<br/>        ax[i].set_xlabel('Predicted: ' + predicted_class, color = col)<br/>        <br/>    plt.show()<br/>        <br/>class VisCallback(tf.keras.callbacks.Callback):<br/>    <br/>    def on_epoch_end(self, epoch, logs = None):<br/>        <br/>        if epoch % 2 == 0:<br/>            <br/>            test_model()</span></pre><p id="b7b4" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们还将创建一个函数来降低学习率。这样，我们将能够避免达到次优权重，并更快地训练模型。</p><pre class="jv jw jx jy fd kg kh ki kj aw kk bi"><span id="b2b5" class="kl km hi kh b fi kn ko l kp kq">#learning rate scheduler<br/>def lr_schedule(epoch, lr):<br/>    <br/>    if (epoch + 1) % 5 == 0:<br/>        <br/>        lr *= 0.2<br/>    <br/>    return max(lr, 3e-7)</span></pre><p id="01c9" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">现在让我们最后编译模型和训练。我们将使用Adam优化器，将“二元交叉熵”作为分类损失<em class="jt">(因为我们正在进行二元分类)</em>，将“均方误差”作为回归损失。</p><pre class="jv jw jx jy fd kg kh ki kj aw kk bi"><span id="d612" class="kl km hi kh b fi kn ko l kp kq">#compile <br/>model.compile(optimizer = tf.keras.optimizers.Adam(), loss = {'class': 'binary_crossentropy', 'box': 'mse'}, \<br/>              metrics = {'class': 'accuracy', 'box': 'mse'})</span><span id="b290" class="kl km hi kh b fi kx ko l kp kq">#fit the model<br/>model.fit(generate_data(), epochs = 10, steps_per_epoch = 100, callbacks = [VisCallback(),                                                                         tf.keras.callbacks.LearningRateScheduler(lr_schedule)])</span></pre><p id="a1a0" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">以下是训练中的一些类预测和边界框预测。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es kz"><img src="../Images/4258fe7047cef69c1eafec95cc19c58e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C1W3LQaTW9h4rl-91ZtX_w.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated"><strong class="bd kf">在时段1的末尾:</strong> x标签表示模型预测，y标签表示实际类别。红框是预测边界框，绿框是真实边界框。</figcaption></figure><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es kz"><img src="../Images/9a84e97cfb9e7ab7daa241d947ca67e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xX_xxu8j6MeNIJz--Tq7Zw.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated"><strong class="bd kf">在时段5的末尾:</strong> x标签表示模型预测，y标签表示实际类别。红框是预测边界框，绿框是真实边界框。</figcaption></figure><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es kz"><img src="../Images/ba43cf37812b075867f1792773798853.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4yTjeKI-FsRpkGVRLEOTaw.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated"><strong class="bd kf">在时段9的末尾:</strong> x标签表示模型预测，y标签表示实际类别。红框是预测边界框，绿框是真实边界框。</figcaption></figure><p id="76ca" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">这里我们可以清楚地看到，当纪元增加时，模型正在学习。在第一个纪元之后，我们只看到一个正确的分类。如果我们专注于边界盒，预测的边界盒是非常不准确的。我们可以看到在纪元5有轻微的增加。在纪元9之后，我们看到模型能够正确地分类所有三个测试用例，并且容易地定位边界框。下面是模型完全训练后的一些测试示例<em class="jt"> (10个时期)</em>。</p><figure class="jv jw jx jy fd ij er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es la"><img src="../Images/0dd617a4db282fc5c8522db82a912129.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yfTt75BjAP9u-tH_fiKsXw.png"/></div></div><figcaption class="kb kc et er es kd ke bd b be z dx translated"><strong class="bd kf">完全训练好的模型的预测</strong></figcaption></figure><p id="3f96" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated"><strong class="io hj">结论</strong></p><p id="bc76" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">在这里，我重现了经典游戏“沃尔多在哪里？”为了展示我们如何使用深度学习进行对象定位和分类。我们合成了数据，创建了边界框，创建了数据生成器，最后实现了一个卷积神经网络来分类和定位我们的虚构角色Waldo &amp; Wilma。我们还可以通过使用“瓦尔多在哪里？”的真实图像来测试我们的模型的可推广性。然而，由于我们对所有图像使用相同的背景，我们的模型可能会偏向于我们当前的图像，因此为了进一步改进我们的模型并使其更具普遍性，我们可以使用其他背景来多样化我们的训练数据集。</p><p id="4d17" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">希望你喜欢这篇文章。感谢您的阅读！</p></div></div>    
</body>
</html>