<html>
<head>
<title>Deep Learning for Beginners Using TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用TensorFlow面向初学者的深度学习</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/cnn-german-traffic-signal-recognition-benchmarking-using-tensorflow-accuracy-80-d069b7996082?source=collection_archive---------0-----------------------#2021-04-24">https://medium.com/analytics-vidhya/cnn-german-traffic-signal-recognition-benchmarking-using-tensorflow-accuracy-80-d069b7996082?source=collection_archive---------0-----------------------#2021-04-24</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="c989" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">在GTSRB数据集上构建CNN模型(acc &gt; 80%)</h2></div><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es iw"><img src="../Images/00a2ddd2a615493574a96835cff15aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ns80t1r7482o0jGGOZ6eog.jpeg"/></div></div><figcaption class="ji jj et er es jk jl bd b be z dx translated">Brodie Vissers 在burst上拍摄的照片</figcaption></figure><p id="8e3b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated"><strong class="jp hi">深度学习</strong>也被称为<strong class="jp hi">深度神经学习</strong>或<strong class="jp hi">深度神经网络</strong>。机器学习的这一分支随着技术的进步而进化和发展。<br/>tensor flow就是这样一个实现深度学习的平台。让我们简单讨论一下张量流。</p><ol class=""><li id="5b21" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated"><strong class="jp hi">什么是Tensorflow？<br/> </strong> TensorFlow是机器学习的端到端开源平台。它有一个全面、灵活的工具、库和社区资源的生态系统，让研究人员推动ML的最新发展，让开发人员轻松构建和部署ML驱动的应用程序。</li><li id="9168" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><strong class="jp hi">什么是CNN模型？</strong><br/><strong class="jp hi">卷积神经网络(ConvNet/CNN) </strong>是一种深度学习算法，它可以接受输入图像，为图像中的各个方面/对象分配重要性(可学习的权重和偏差)，并能够区分它们。与其他分类算法相比，ConvNet/CNN中所需的预处理要低得多。因此，CNN是处理图像的最优选算法</li></ol><h1 id="8018" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">关于数据集</h1><p id="b6e3" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">德国交通标志识别<strong class="jp hi">数据集</strong> ( <strong class="jp hi"> GTSRB </strong>)是一个图像分类<strong class="jp hi">数据集</strong>。这些图像是交通标志的照片。这些图像被分为43类。训练集包含39209个标记图像，测试集包含12630个图像。测试集的标签没有发布。</p><h1 id="ef10" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">目录</h1><ol class=""><li id="0e2b" class="kj kk hh jp b jq lp jt lq jw lu ka lv ke lw ki ko kp kq kr bi translated"><a class="ae jm" href="#01aa" rel="noopener ugc nofollow">简介</a></li><li id="9448" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#9664" rel="noopener ugc nofollow">数据预处理</a> <br/> 2.1 <a class="ae jm" href="#7439" rel="noopener ugc nofollow">加载所需库</a> <br/> 2.2 <a class="ae jm" href="#8fc4" rel="noopener ugc nofollow">获取数据</a></li><li id="9e07" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#13b8" rel="noopener ugc nofollow">探索GTRSB数据集</a> <br/> 3.1 <a class="ae jm" href="#c800" rel="noopener ugc nofollow">训练和测试数据集包含多少幅图像？</a> <br/> 3.2 <a class="ae jm" href="#66b2" rel="noopener ugc nofollow">数据集包含多少个输出类？</a> <br/> 3.3 <a class="ae jm" href="#9707" rel="noopener ugc nofollow">来自数据集的图像张量的形状是什么？</a> <br/> 3.4 <a class="ae jm" href="#9e24" rel="noopener ugc nofollow">让我们打印一个样本图像连同它的类？</a> <br/> 3.5 <a class="ae jm" href="#1410" rel="noopener ugc nofollow">确定训练集中属于类别的图像数量？</a></li><li id="410e" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#482e" rel="noopener ugc nofollow">设置CNN模型</a> <br/> 4.1 <a class="ae jm" href="#fcab" rel="noopener ugc nofollow">设置imagedata generators</a><br/>4.2<a class="ae jm" href="#74da" rel="noopener ugc nofollow">配置张量流生成器</a> <br/> 4.3 <a class="ae jm" href="#d4fd" rel="noopener ugc nofollow">构建CNN模型</a></li><li id="254d" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#bdf4" rel="noopener ugc nofollow">训练模型</a> <br/> 5.1 <a class="ae jm" href="#1e96" rel="noopener ugc nofollow">模型训练及结果分析</a> <br/> 5.2 <a class="ae jm" href="#cc90" rel="noopener ugc nofollow">对测试数据运行模型</a> <br/> 5.3 <a class="ae jm" href="#50c9" rel="noopener ugc nofollow">准确率评分</a> <br/> 5.4 <a class="ae jm" href="#b75c" rel="noopener ugc nofollow">混淆矩阵</a> <br/> 5.5 <a class="ae jm" href="#8857" rel="noopener ugc nofollow">分类报告</a></li><li id="d640" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#8c33" rel="noopener ugc nofollow">在测试图像数据集上测试模型</a></li><li id="c131" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#51ef" rel="noopener ugc nofollow">总结</a></li><li id="c192" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#6dd7" rel="noopener ugc nofollow">未来工作</a></li><li id="1cbd" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="#aa71" rel="noopener ugc nofollow">参考文献</a></li></ol><h1 id="01aa" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№1:简介</h1><p id="dbef" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">德国交通标志基准是在2011年国际神经网络联合会议(IJCNN)上举行的多类别、单图像分类挑战赛。以下是数据集的详细信息</p><ol class=""><li id="c8bf" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">单幅图像多类分类问题</li><li id="13d4" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">40多节课</li><li id="adff" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">总共超过50，000张图片</li><li id="0c52" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">大型逼真的数据库</li></ol><h1 id="9664" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№2:数据预处理</h1><h2 id="7439" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">加载所需的库</h2><p id="ac0d" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">我一次性加载了所有的TensorFlow和可视化库。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="8fc4" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">检索数据</h2><p id="48e3" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">我使用库<code class="du mn mo mp mq b">opendatasets</code>从<a class="ae jm" href="https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign" rel="noopener ugc nofollow" target="_blank"> Kaggle </a>下载数据。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="095c" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我用熊猫数据框阅读了所有下载的文件。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="d84f" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我现在从每个数据帧中访问样本记录。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h1 id="13b8" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№3:探索GTRSB数据集</h1><h2 id="c800" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">问:训练和测试数据集包含多少幅图像？</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="66b2" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">问:数据集包含多少个输出类？</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="9707" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">问:数据集中图像的形状是什么？</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="4213" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">很明显，数据集中的所有图像都具有不同的大小。</p><h2 id="9e24" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">问:让我们打印一个样本图像和它的类。</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mr"><img src="../Images/a4854350bc07bbb28258aac1ed35c425.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ALu_t9kLIpflppLemtKlWg.png"/></div></div></figure><h2 id="1410" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">问:确定属于训练集中每个类别的图像数量？</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es ms"><img src="../Images/eac69d2dedcc3c105657c12dd0ef8b86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W3QY_xhWPZPQUHT-CrM1tg.png"/></div></div></figure><p id="9f8b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">观察到少数类别似乎具有高数量的图像(如类别2，3..等等。)其中只有很少的类别具有非常低的图像数量(如19、24…等)</p><h1 id="482e" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№4:设置CNN模型</h1><h2 id="fcab" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">设置图像数据生成器</h2><p id="a45d" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">在TensorFlow中，数据扩充是使用ImageDataGenerator类完成的。它非常容易理解和使用。整个数据集在每个历元中循环，数据集中的图像根据所选的选项和值进行变换。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h1 id="74da" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">配置张量流生成器</h1><p id="694a" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">使用训练生成器的想法是在训练过程中即时获得成批的输入和相应的输出，例如读入32个图像，获得相应的32个标签向量，然后将该集合馈送到gpu进行训练步骤。</p><p id="cb6b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">来自目录的流期望每个类中的图像在一个独立的目录中。这是我们从一开始就有的。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="d4fd" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">构建CNN模型</h2><p id="fff4" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">我使用keras包装器将各层链接在一起。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h1 id="bdf4" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№5:训练模型</h1><h2 id="1e96" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">模型训练和结果分析</h2><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mt"><img src="../Images/837a164754ede198b2215b61f2aae6fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*47CTF4BUi8cOklh9lwr9ow.png"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div class="er es mt"><img src="../Images/cac2ab8531d037743567c254939e3fb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1126/format:webp/1*1nvE8KTHcPTOvxoFIL8UdA.png"/></div></figure><p id="119b" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">达到了85%的准确度。即使在训练模型几个时期后，精度不会提高，但我们可能会结束模型的过度拟合。让我们看看我们的模型在测试数据集上的表现。</p><p id="ab6d" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">注意——我们的模型从未见过测试图像，因此看到预测会很有趣。</p><h2 id="cc90" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">根据测试数据运行模型</h2><p id="b8d4" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">由于测试图像没有被分类到各自的类中，我们将把包含所有测试图像的文件夹名作为“test”传递到“classes”参数中</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="bc14" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">现在，我编写一个代码块，将预测映射到相应的图像</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h2 id="50c9" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">准确度分数</h2><p id="b399" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">我根据实际标签计算预测类的准确性。为此，我利用了sklearn库</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><p id="ae00" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">这太棒了，我们现在已经在测试集上达到了87%的准确率。</p><h2 id="b75c" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">混淆矩阵</h2><p id="b773" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">混淆矩阵是一个表格，通常用于<strong class="jp hi">描述分类模型</strong>(或“分类器”)对一组真实值已知的测试数据的性能。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mu"><img src="../Images/d64d87d9d6a779068ec52fe621db3be1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NWbCuxLrX4a2mmMQQGzesQ.png"/></div></div></figure><h2 id="8857" class="lx ky hh bd kz ly lz ma ld mb mc md lh jw me mf lj ka mg mh ll ke mi mj ln mk bi translated">分类报告</h2><p id="ee47" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated"><strong class="jp hi">分类得分</strong>是算法正在使用(或用户已经设置)的任何<strong class="jp hi">得分</strong>或度量，用于计算<strong class="jp hi">分类</strong>的性能。根据经验，F1的加权平均值应该用于比较分类器模型，而不是全局精度。当前模型展示的得分是87%🆒</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><h1 id="8c33" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№6:使用单个图像进行测试</h1><p id="9db0" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">让我们随机检查预测值和实际值以及图像。</p><figure class="ix iy iz ja fd jb"><div class="bz dy l di"><div class="ml mm l"/></div></figure><figure class="ix iy iz ja fd jb er es paragraph-image"><div role="button" tabindex="0" class="jc jd di je bf jf"><div class="er es mv"><img src="../Images/b96104a82ac065880f599681e6b602ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*De_Jf_ge9iYZ2K8RCYfymA.png"/></div></div></figure><h1 id="51ef" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№7:摘要</h1><p id="2484" class="pw-post-body-paragraph jn jo hh jp b jq lp ii js jt lq il jv jw lr jy jz ka ls kc kd ke lt kg kh ki ha bi translated">下面是我们遵循的一步一步过程的简要总结</p><ol class=""><li id="fb6d" class="kj kk hh jp b jq jr jt ju jw kl ka km ke kn ki ko kp kq kr bi translated">我们简要了解了TensorFlow，以及为什么CNN架构是图像数据集的首选。</li><li id="1e09" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们从Kaggle下载了数据集，并使用Pandas访问它。</li><li id="6ea9" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们研究了GTRSB数据集，了解了每个类拥有的全部图像、训练集中的全部图像、显示的样本图像等。</li><li id="4a47" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们设置了CNN模型，并学习了如何使用ImageDataGenerators，配置测试和训练生成器，以及使用<strong class="jp hi"> Tensorflow </strong>和<strong class="jp hi"> Keras </strong>构建深度神经网络的连接层。</li><li id="4ada" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们对CNN模型进行了训练，达到了约85% 的<strong class="jp hi">准确率。我们还分析了在训练时间间隔数时的准确度和值准确度的变化。我们记下了我们的结论。</strong></li><li id="335f" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">我们通过在几个测试样本上运行来随机检查模型性能</li></ol><h1 id="6dd7" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№8:未来的工作</h1><ol class=""><li id="1d9c" class="kj kk hh jp b jq lp jt lq jw lu ka lv ke lw ki ko kp kq kr bi translated">尝试神经网络中不同层的组合，以进一步提高准确性。</li><li id="5722" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">尝试在PyTorch上构建神经网络，看看是否可以达到类似的精度。</li><li id="ea8f" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated">尝试实现不同CNN架构，如<br/>-LeNet-5<br/>-Alex net<br/>-Google LeNet<br/>-VGGNet<br/>-ResNet</li></ol><h1 id="aa71" class="kx ky hh bd kz la lb lc ld le lf lg lh in li io lj iq lk ir ll it lm iu ln lo bi translated">№9:引用</h1><ol class=""><li id="effa" class="kj kk hh jp b jq lp jt lq jw lu ka lv ke lw ki ko kp kq kr bi translated">完整的笔记本可以在这里访问<a class="ae jm" href="https://github.com/hargurjeet/DeepLearning/blob/main/GTRSB%20-%20CNN%20(TensorFlow).ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/hargurjeet/deep learning/blob/main/gt rsb % 20-% 20 CNN % 20(tensor flow)。ipynb </a></li><li id="fcf3" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="https://www.tensorflow.org/tutorials/keras/classification" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/tutorials/keras/classification</a></li><li id="9d78" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="https://www.kaggle.com/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign" rel="noopener ugc nofollow" target="_blank">https://www . ka ggle . com/meowmeowmeowmeowmeow/gt SRB-german-traffic-sign</a></li><li id="6898" class="kj kk hh jp b jq ks jt kt jw ku ka kv ke kw ki ko kp kq kr bi translated"><a class="ae jm" href="https://www.coursera.org/professional-certificates/tensorflow-in-practice" rel="noopener ugc nofollow" target="_blank">https://www . coursera . org/professional-certificates/tensor flow-in-practice</a></li></ol><p id="f9fb" class="pw-post-body-paragraph jn jo hh jp b jq jr ii js jt ju il jv jw jx jy jz ka kb kc kd ke kf kg kh ki ha bi translated">我真的希望你们能从这篇文章中学到一些东西。请随意给一个👏如果你喜欢你所学的。这让我保持动力。</p></div></div>    
</body>
</html>