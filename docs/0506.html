<html>
<head>
<title>What is UNET?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是UNET？</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/what-is-unet-157314c87634?source=collection_archive---------1-----------------------#2021-01-19">https://medium.com/analytics-vidhya/what-is-unet-157314c87634?source=collection_archive---------1-----------------------#2021-01-19</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="5c4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">UNET是由Olaf Ronneberger等人于2015年在德国弗莱堡大学开发的用于生物医学图像分割的架构。这是当今任何语义分割任务中最常用的方法之一。这是一个完全卷积的神经网络，旨在从较少的训练样本中学习。它是对现有FCN的改进，即Jonathan Long等人在(2014)开发的“用于语义分割的全卷积网络”。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/342f2c88bc2f14bea027a44026df8a50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lvXoKMHoPJMKpKK7keZMEA.png"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">UNET建筑</figcaption></figure><h1 id="4131" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak"> UNET —网络架构</strong></h1><p id="53dd" class="pw-post-body-paragraph if ig hi ih b ii kr ik il im ks io ip iq kt is it iu ku iw ix iy kv ja jb jc hb bi translated">UNET是一种U形编码器-解码器网络架构，它由四个编码器模块和四个解码器模块组成，通过一个桥连接。编码器网络(收缩路径)将空间维度减半，并将每个编码器块的滤波器(特征通道)数量加倍。同样，解码器网络使空间维度加倍，特征通道的数量减半。</p><p id="060c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">编码器网络</strong></p><p id="b129" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">编码器网络充当特征提取器，并通过一系列编码器块学习输入图像的抽象表示。每个编码器模块由两个3×3卷积组成，每个卷积之后是一个ReLU(校正线性单元)激活函数。ReLU激活函数将非线性引入网络，这有助于更好地概括训练数据。ReLU的输出充当对应解码器块的跳跃连接。</p><p id="584d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">接下来，遵循2x2最大池，其中特征地图的空间维度(高度和宽度)减少一半。这通过减少可训练参数的数量来降低计算成本。</p><p id="7760" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">跳过连接</strong></p><p id="21ee" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这些跳过连接提供了帮助解码器生成更好的语义特征的附加信息。它们还充当快捷连接，帮助渐变间接流向早期层，而不会出现任何退化。简而言之，我们可以说，跳过连接有助于在反向传播时更好地流动梯度，这反过来有助于网络学习更好的表示。</p><p id="3f4d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">桥</strong></p><p id="af9b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">网桥连接编码器和解码器网络，并完成信息流。它由两个3x3卷积组成，每个卷积后面都有一个ReLU激活函数。</p><p id="342b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">解码器网络</strong></p><p id="6816" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解码器网络用于获取抽象表示并生成语义分割掩码。解码器模块从2x2转置卷积开始。接下来，它与来自编码器模块的相应跳过连接特征映射相连接。这些跳跃连接提供了早期图层中的要素，这些要素有时会因网络深度而丢失。之后，使用两个3×3卷积，其中每个卷积后都有一个ReLU激活函数。</p><p id="a809" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后一个解码器的输出通过sigmoid激活的1x1卷积。sigmoid激活函数给出了表示逐像素分类的分割掩模。</p><h1 id="22e9" class="jt ju hi bd jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq bi translated"><strong class="ak">注</strong></h1><ul class=""><li id="3ee0" class="kw kx hi ih b ii kr im ks iq ky iu kz iy la jc lb lc ld le bi translated">一些研究人员更喜欢在卷积层和ReLU激活函数之间使用批处理归一化层。批量归一化减少了内部协方差漂移，使网络在训练时更加稳定。</li><li id="e486" class="kw kx hi ih b ii lf im lg iq lh iu li iy lj jc lb lc ld le bi translated">在ReLU激活功能之后的某个时候也使用dropout。它通过丢弃(忽略)一些随机选择的神经元，迫使网络学习不同的表示。这有助于网络减少对某些神经元的依赖。这反过来有助于网络更好地概括和防止它过度拟合。</li></ul></div><div class="ab cl lk ll gp lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="hb hc hd he hf"><p id="f7a4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">原载</strong>:【https://idiotdeveloper.com/what-is-unet/】T4</p></div></div>    
</body>
</html>