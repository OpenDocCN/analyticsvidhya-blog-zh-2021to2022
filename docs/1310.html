<html>
<head>
<title>Principal steps of a Machine Learning project</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习项目的主要步骤</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/principal-steps-of-a-machine-learning-project-7d7dcc6fe68b?source=collection_archive---------13-----------------------#2021-02-23">https://medium.com/analytics-vidhya/principal-steps-of-a-machine-learning-project-7d7dcc6fe68b?source=collection_archive---------13-----------------------#2021-02-23</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/2bddb873046041fe2ce96646ac65bab5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W_6R0TSAPDBOPWVh5BNQgg.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">[图片来源:<a class="ae it" href="https://farm2.staticflickr.com/1816/30212411048_2a1d7200e2_b.jpg" rel="noopener ugc nofollow" target="_blank">https://farm 2 . static Flickr . com/1816/30212411048 _ 2a1d 7200 E2 _ b . jpg</a>]</figcaption></figure><p id="a214" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">机器学习工程师不仅需要有良好的编程技能，他们还需要有一些数据科学家的技能，如收集和管理数据，统计学家分析数据的技能，以及数学家的技能。这是因为一个机器学习项目需要很多步骤，从管理数据，建立和评估机器学习模型，到应用这个模型预测测试集中的新数据。在本文中，我们将探索所有这些步骤，包括:</p><ol class=""><li id="df44" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr jx jy jz ka bi translated">收集数据</li><li id="e628" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">探索性数据分析</li><li id="d6f6" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">预处理数据</li><li id="c1a8" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">建模和评估</li><li id="8b0c" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">超参数调谐</li><li id="3641" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr jx jy jz ka bi translated">预测。</li></ol><p id="0d0d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">所有这些工作都将通过一个对King Country的房价进行预测的项目来详细说明。这个<a class="ae it" href="https://www.kaggle.com/harlfoxem/housesalesprediction" rel="noopener ugc nofollow" target="_blank">数据</a>是从Kaggle收集的。</p></div><div class="ab cl kg kh go ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="ha hb hc hd he"><h1 id="4883" class="kn ko hh bd kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk bi translated">一.收集数据</h1><p id="e85d" class="pw-post-body-paragraph iu iv hh iw b ix ll iz ja jb lm jd je jf ln jh ji jj lo jl jm jn lp jp jq jr ha bi translated">正如我在<a class="ae it" href="https://lekhuyen.medium.com/introduction-to-machine-learning-78e8c5d708e6" rel="noopener">上一篇文章</a>中介绍的那样，数据对于构建机器学习模型非常重要。因为模型将从您提供给它的数据集中学习。因此，收集和管理数据在机器学习项目中起着关键作用。</p><p id="0bcb" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">收集数据的来源有很多，以下是一些开放的来源，您可以下载各种数据集以输入到您的模型中:</p><ul class=""><li id="8f39" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">Kaggle是一个数据科学家的在线社区，在这里你可以找到许多机器学习、深度学习项目以及开放数据源。通过做现实生活中的项目或者参加比赛来学习机器学习是很有用的一页。</li><li id="90a4" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated"><a class="ae it" href="https://archive.ics.uci.edu/ml/index.php" rel="noopener ugc nofollow" target="_blank"> UCI机器学习知识库</a>为机器学习社区提供了一系列数据库。它实际上维护着560个数据集。</li><li id="131c" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated"><a class="ae it" href="https://aws.amazon.com/fr/opendata/?wwps-cards.sort-by=item.additionalFields.sortDate&amp;wwps-cards.sort-order=desc" rel="noopener ugc nofollow" target="_blank">AWS上的开放数据</a>是一个用户可以共享通过AWS资源获得的数据集的地方。</li><li id="5f83" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated"><a class="ae it" href="https://www.opendatasoft.com/blog/2015/11/02/how-we-put-together-a-list-of-1600-open-data-portals-around-the-world-to-help-open-data-community" rel="noopener ugc nofollow" target="_blank"> OpenDataSoft </a>是一个包含全球2600多个开放数据门户的数据源。</li><li id="fd18" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi">…</li></ul><p id="c6c6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们的数据集保存在一个表中。csv)格式。可以通过<strong class="iw hi">熊猫</strong>包中的<strong class="iw hi"> read_csv </strong>函数读取:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="8138" class="ma ko hh lw b fi mb mc l md me">import pandas as pd</span><span id="3bf6" class="ma ko hh lw b fi mf mc l md me">df = pd.read_csv('kc_house_data.csv')</span></pre><p id="dabe" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">检查数据:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="bf2a" class="ma ko hh lw b fi mb mc l md me">df.head()</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mg"><img src="../Images/93b6bab362fcbb027f25a0d304458b4f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3H5QnKJL0cdEROv8LS1tTA.png"/></div></div></figure><h1 id="f420" class="kn ko hh bd kp kq mh ks kt ku mi kw kx ky mj la lb lc mk le lf lg ml li lj lk bi translated">二。探索性数据分析</h1><p id="5a77" class="pw-post-body-paragraph iu iv hh iw b ix ll iz ja jb lm jd je jf ln jh ji jj lo jl jm jn lp jp jq jr ha bi translated">这一步的目标是尽可能多地理解数据集，以便我们能够为模型化步骤制定快速策略。</p><p id="fa66" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因为机器学习在结构化数据上工作很多，这些数据保存在。csv或。xlsx格式，所以在本文中，我们将重点分析这种类型的数据。</p><p id="c14e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，我们可以从一些基本分析开始，如发现目标变量、行数、列数、每列的数据类型，检查数据集中是否存在任何NaN值:</p><p id="029f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">对于我们的数据集<strong class="iw hi"> kc_house_data.csv: </strong></p><ul class=""><li id="e1f9" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">在我们的例子中，目标特性是价格列。</li><li id="bcb8" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated">该数据集包括21613行和21列。</li></ul><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="8062" class="ma ko hh lw b fi mb mc l md me">print(df.shape)</span><span id="0696" class="ma ko hh lw b fi mf mc l md me">&gt;&gt;&gt; (21613, 21)</span></pre><ul class=""><li id="6266" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">发现每列的类型:</li></ul><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="9ccf" class="ma ko hh lw b fi mb mc l md me">df.dtypes</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mm"><img src="../Images/bbcaf0d1df47c9e0d73426b318bb7831.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uu-LrgPCcZxxnkulOxEoag.png"/></div></div></figure><p id="2c1d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这个结果表明，我们几乎所有的特征都有一个数字类型(整数或浮点)。只有列“日期”具有对象类型。</p><ul class=""><li id="f09d" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">通过饼图可视化类型比率:</li></ul><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="3b1d" class="ma ko hh lw b fi mb mc l md me">df.dtypes.value_counts().plot.pie()</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mn"><img src="../Images/8c4be5a7cd5c09d896df283a8347005e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*mkq12IKAvQvQY8IQJKWPwA.png"/></div></div></figure><ul class=""><li id="37a0" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">验证数据集是否包含任何NaN值:</li></ul><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="831e" class="ma ko hh lw b fi mb mc l md me">df.isna().sum()</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mo"><img src="../Images/0be3c2afae82e374cba5f2e2dfbf70e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ScHmeJd5MSvt3c2wXkYfmQ.png"/></div></div></figure><p id="711e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">该结果显示所有列都不包含任何缺失值。</p><ul class=""><li id="e221" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">使用函数<strong class="iw hi"> df.describe() </strong>描述数据集的统计值。该函数允许我们计算每个数字列的一些基本统计值，例如数据点的数量、最小值、最大值、平均值、标准偏差值(std)和分位数。</li></ul><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="956f" class="ma ko hh lw b fi mb mc l md me">df.describe().transpose()</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mp"><img src="../Images/99dff8fb04748c6dbd8bfd6e1d66695e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4KHd_POV_9uWi9WEVGrmwg.png"/></div></div></figure><ul class=""><li id="a2c7" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">为了更好地理解数据集，我们还可以使用直方图或条形图来发现每个特征的分布。</li></ul><p id="2438" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下图显示了价格列的分布情况:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="99ce" class="ma ko hh lw b fi mb mc l md me">plt.figure(figsize = (10,8))</span><span id="5665" class="ma ko hh lw b fi mf mc l md me">sns.distplot(df['price'],hist = True, label = 'Price')</span><span id="9754" class="ma ko hh lw b fi mf mc l md me">plt.show()</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mq"><img src="../Images/0a756eddb8dfc817825d89c915607205.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NUZbKrokdy2MFTvAeHKZnw.png"/></div></div></figure><p id="8a21" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">根据上图，我们看到</p><ul class=""><li id="130e" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">几乎房价都是0到100万美元分布。</li><li id="e7a1" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated">50万美元左右的价格出现得最多。</li><li id="540f" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated">存在一些异常值，我们可以跳过它们来说明它们对我们的ML模型的影响。</li></ul><p id="f17b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">该图不仅有助于我们找出数据的最集中值，而且对于确定异常值也很有用</p><p id="8e69" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">房子的价格显然取决于楼层、卧室、卫生间的数量。因此，将这些特征形象化也很有趣:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="b128" class="ma ko hh lw b fi mb mc l md me">import matplotlib.pyplot as plt<br/>import seaborn as sns</span></pre><p id="84dd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">楼层:</strong></p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="1ef4" class="ma ko hh lw b fi mb mc l md me">plt.figure()</span><span id="d2d4" class="ma ko hh lw b fi mf mc l md me">sns.countplot(df['floors'])</span><span id="aaf5" class="ma ko hh lw b fi mf mc l md me">plt.show()<br/></span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mr"><img src="../Images/e6419557a5ac06b245d667a2db07876e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QGCSilNaPYUaN98voi08Gg.png"/></div></div></figure><p id="0cef" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">浴室:</strong></p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="fcde" class="ma ko hh lw b fi mb mc l md me">plt.figure(figsize = (12,5))</span><span id="e0d2" class="ma ko hh lw b fi mf mc l md me">sns.countplot(df['bathrooms'])</span><span id="f971" class="ma ko hh lw b fi mf mc l md me">plt.show()</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ms"><img src="../Images/3936829ad807cbd6ab0101cd46bfe2c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GNa6uxKQdQ4VSVyAtJ4N5A.png"/></div></div></figure><p id="94b6" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">卧室:</strong></p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="b934" class="ma ko hh lw b fi mb mc l md me">plt.figure(figsize = (7,5))</span><span id="537f" class="ma ko hh lw b fi mf mc l md me">sns.countplot(df['bedrooms'])</span><span id="9a99" class="ma ko hh lw b fi mf mc l md me">plt.show()</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mt"><img src="../Images/13ec1cc01c1d67a35163e8c483fba754.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yWfbEbCU0bLYBD6t0Xhukg.png"/></div></div></figure><ul class=""><li id="1f16" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">再者，发现变量之间的相关性也很重要。由于这种分析，我们可以选择与我们的目标特征最相关的变量，并忽略弱相关的变量。</li></ul><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="de24" class="ma ko hh lw b fi mb mc l md me">plt.figure(figsize = (14,8))</span><span id="5b1e" class="ma ko hh lw b fi mf mc l md me">sns.heatmap(df.corr(), linewidths = 0.5, annot = True)</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mu"><img src="../Images/ff2325bf54e0c9b132d7cb3b313ac6a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z99YUIA_IuoWXruktcTwNA.png"/></div></div></figure><p id="82d0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">找出价格与其他特征的相关性:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="04dd" class="ma ko hh lw b fi mb mc l md me">df.corr()["price"].sort_values(ascending = False)</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mv"><img src="../Images/9c3ec0dd4e316792802b5092530b1b8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*85Nyo2Q6m3bhcFCm9FIOCQ.png"/></div></div></figure><p id="12dc" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">以上结果表明，价格与一些变量高度相关，如<strong class="iw hi"> sqft_living </strong>、<strong class="iw hi">品位</strong>、<strong class="iw hi"> sqft_above </strong>、<strong class="iw hi"> sqft_living15 </strong>、<strong class="iw hi">浴室</strong>。<strong class="iw hi"> Id </strong>和<strong class="iw hi">邮政编码</strong>与价格的相关性很弱。</p><h1 id="a4aa" class="kn ko hh bd kp kq mh ks kt ku mi kw kx ky mj la lb lc mk le lf lg ml li lj lk bi translated">三。预处理数据</h1><p id="394f" class="pw-post-body-paragraph iu iv hh iw b ix ll iz ja jb lm jd je jf ln jh ji jj lo jl jm jn lp jp jq jr ha bi translated">如你所知，机器学习算法从你提供给它的数据中学习。如果数据集不好(存在缺失值、离群值或特征没有以正确的格式呈现)，那么从该数据构建的机器学习模型将非常糟糕。因此，在将数据输入模型之前准备数据非常重要，这需要数据科学家大约80%的工作时间。</p><p id="0d58" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在预处理技术中，通常使用的方法有编码、归一化、插补、异常值和异常值剔除、变量选择、变量提取。在应用这些技术对数据集进行预处理之前，让我们先看看它们是如何工作的。</p><h2 id="64d9" class="ma ko hh bd kp mw mx my kt mz na nb kx jf nc nd lb jj ne nf lf jn ng nh lj ni bi translated">1.编码</h2><p id="f931" class="pw-post-body-paragraph iu iv hh iw b ix ll iz ja jb lm jd je jf ln jh ji jj lo jl jm jn lp jp jq jr ha bi translated"><strong class="iw hi">编码</strong>是一种在使用分类数据拟合模型之前将分类数据编码成数字的方法。最流行的两种技术是<strong class="iw hi"> <em class="nj">顺序编码</em> </strong>和<strong class="iw hi"> <em class="nj">一键编码</em> </strong>。</p><p id="a0a4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在<strong class="iw hi">序数编码</strong>中，每个分类值由一个整数值编码。例如，我们有两个分类值[“狗”、“猫”、“鸟]]，序数编码会将这两个值转换为三个整数0、1和2，根据它们在字典中出现的顺序。因此，“鸟”被指定为0，“猫”被指定为1，“狗”被指定为2。在Python中，这是由模块<strong class="iw hi"> sklearn中的<strong class="iw hi"> OrdinalEncoder </strong>完成的</strong></p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="7ff1" class="ma ko hh lw b fi mb mc l md me">from sklearn.preprocessing import OrdinalEncoder</span><span id="1a62" class="ma ko hh lw b fi mf mc l md me">from numpy import asarray</span><span id="0f30" class="ma ko hh lw b fi mf mc l md me">example = asarray([['dog'], ['cat'],['bird']])</span><span id="ea94" class="ma ko hh lw b fi mf mc l md me">encoder = OrdinalEncoder()</span><span id="38cd" class="ma ko hh lw b fi mf mc l md me">encode_example = encoder.fit_transform(example)</span><span id="1d4e" class="ma ko hh lw b fi mf mc l md me">print(encode_example)</span><span id="539f" class="ma ko hh lw b fi mf mc l md me">&gt;&gt;&gt; [[2.]  <br/>     [1.]  <br/>     [0.]]</span></pre><p id="3c09" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们还可以反向转换以找到编码值的原始分类值:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="fa8e" class="ma ko hh lw b fi mb mc l md me">import numpy as np</span><span id="2a4c" class="ma ko hh lw b fi mf mc l md me">encoder.inverse_transform(np.array([[0],[2],[2]]))</span><span id="0b7f" class="ma ko hh lw b fi mf mc l md me">&gt;&gt;&gt; array([['bird'], ['dog'], ['dog']], dtype='&lt;U4')</span></pre><p id="220d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在变量之间不存在顺序关系的情况下，整数编码可能不合适。它可以被独热编码技术所取代。该技术旨在将每个目标转换为长度等于类别数量的向量。如果一个数据点属于iᵗʰ-category，那么这个向量中的iᵗʰ分量被赋值为1，其他的被赋值为0。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="6016" class="ma ko hh lw b fi mb mc l md me">from sklearn.preprocessing import OneHotEncoder</span><span id="d866" class="ma ko hh lw b fi mf mc l md me">from numpy import asarray</span><span id="d033" class="ma ko hh lw b fi mf mc l md me">example = asarray([['dog'], ['cat'],['bird']])</span><span id="0d71" class="ma ko hh lw b fi mf mc l md me">encoder = OneHotEncoder(sparse = False)</span><span id="9d32" class="ma ko hh lw b fi mf mc l md me">encode_example = encoder.fit_transform(example)</span><span id="1969" class="ma ko hh lw b fi mf mc l md me">print(encode_example)</span><span id="209a" class="ma ko hh lw b fi mf mc l md me">&gt;&gt;&gt; [[0. 0. 1.]  <br/>     [0. 1. 0.]  <br/>     [1. 0. 0.]]</span></pre><p id="454b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在本例中，“狗”被分配给vector [0，0，1]，“猫”被分配给[0，1，0]，“鸟”被分配给[1，0，0]。</p><p id="47ce" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 2。正常化</strong></p><p id="9411" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有时，原始数据中数字特征的范围可能变化很大。因此，在将数据拟合到我们的机器学习模型之前，有必要对它们进行归一化。规范化的目标是将数值列的值更改为一个通用的范围，而不会丢失值范围的差异。现在，让我们来看看<strong class="iw hi"> sklearn </strong>中最流行的标准化功能的技术:</p><ul class=""><li id="af90" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated"><strong class="iw hi">最小-最大归一化:</strong></li></ul><p id="f818" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">此方法将要素的范围重新调整为[0，1]中的新范围。通式由下式给出:</p><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es nk"><img src="../Images/690b25a27af9c8a025c83151dd8a86a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:386/1*zMMwTQBrTJ_iM2j04OBfYg.gif"/></div></figure><p id="bda7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其中X是原始值，X '是标准化值。</p><p id="d0d2" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在Python中，这个公式是由<strong class="iw hi">的最小最大缩放器</strong>从模块<strong class="iw hi"> sklearn中计算出来的</strong></p><p id="6024" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">示例</strong>:向量(1，2，3)被重新缩放为(0，0.5，1)</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="fbdb" class="ma ko hh lw b fi mb mc l md me">from sklearn.preprocessing import MinMaxScaler</span><span id="738b" class="ma ko hh lw b fi mf mc l md me">import numpy as np</span><span id="c96c" class="ma ko hh lw b fi mf mc l md me">X = np.array([[1],[2],[3]])</span><span id="d10c" class="ma ko hh lw b fi mf mc l md me">scaler = MinMaxScaler()</span><span id="fddf" class="ma ko hh lw b fi mf mc l md me">scaler.fit_transform(X)<br/>&gt;&gt;&gt; array([[0. ], [0.5], [1. ]])</span></pre><ul class=""><li id="1270" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated"><strong class="iw hi">标准化(Z分数标准化):</strong></li></ul><p id="4793" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">该方法旨在以零均值和标准差为1在新范围内重新缩放要素。该技术的公式由下式给出:</p><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es nl"><img src="../Images/a53984975b2467a9b3343c83e2846584.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/1*oXlVVMDKmsV7TGSbC2J9uQ.gif"/></div></figure><p id="14d7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其中mean(X)和σ分别表示X的平均值和标准偏差。</p><p id="12e1" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">功能<strong class="iw hi">标准缩放器</strong>属于<strong class="iw hi"> sklearn .预处理</strong>模块<strong class="iw hi">。</strong></p><p id="420b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">例:</strong>用这种方法得到的向量(1，2，3)的新小数位数是(-1.22474487，0，1.22474487)</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="0094" class="ma ko hh lw b fi mb mc l md me">from sklearn.preprocessing import StandardScaler</span><span id="a76b" class="ma ko hh lw b fi mf mc l md me">import numpy as np</span><span id="13ad" class="ma ko hh lw b fi mf mc l md me">X = np.array([[1],[2],[3]])</span><span id="4f8c" class="ma ko hh lw b fi mf mc l md me">scaler = StandardScaler()</span><span id="19ee" class="ma ko hh lw b fi mf mc l md me">scaler.fit_transform(X)</span><span id="aa90" class="ma ko hh lw b fi mf mc l md me">&gt;&gt;&gt; array([[-1.22474487],<br/>          [ 0.        ],<br/>          [ 1.22474487]])</span></pre><ul class=""><li id="f694" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated"><strong class="iw hi">鲁棒定标器:</strong></li></ul><p id="7e79" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当数据集包含异常值时，上述两种方法并不真正适用。这个缺点可以通过稳健的标度法来克服，其中考虑了中位数和四分位间距。该技术的归一化公式由下式给出:</p><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es nm"><img src="../Images/a41c106f0a4dd12e5792e8f96676e881.png" data-original-src="https://miro.medium.com/v2/resize:fit:352/1*od7GJxBAOuYlsyNlNBUe_g.gif"/></div></figure><p id="0c0a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其中<em class="nj">中位数</em> (X)和<em class="nj"> IQR </em>表示数据X的中位数和四分位数范围</p><p id="d819" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 3。南的拒绝</strong></p><p id="5069" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当数据集包含缺失值时，需要在将这些数据拟合到模型中之前拒绝或替换它们。Pandas提供了一些有用的功能来处理这个问题。</p><ul class=""><li id="be64" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">熊猫。DataFrame.isna() 确定数据帧中是否存在任何缺失值</li><li id="6409" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated">熊猫。DataFrame.fillna(α) 用给定值α替换DataFrame中缺失的值</li><li id="233b" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated">熊猫。DataFrame.dropna() 删除DataFrame中所有缺失的值</li></ul><p id="ebf0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">您可以查看<a class="ae it" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html" rel="noopener ugc nofollow" target="_blank">参考</a>了解更多详情。</p><p id="fe2f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 4。插补</strong></p><p id="de27" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有时，删除丢失的值可能会丢失有价值的数据。更好的策略是通过一些统计值来估算这些缺失值，如平均值、中值、最频繁值或一些常数……这可以通过来自<strong class="iw hi"> sklearn.impute </strong>模块的<a class="ae it" href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html" rel="noopener ugc nofollow" target="_blank"> <strong class="iw hi"> SimpleImputer </strong> </a>函数来帮助实现。</p><p id="fcef" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 5。变量选择:</strong></p><p id="a500" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">选择最相关的变量对于构建机器模型非常重要。这是出于某些原因而使用的:</p><ul class=""><li id="8076" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">为了简化模型，使其更容易解释</li><li id="ed55" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated">为了减少训练时间</li><li id="8514" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated">为了减少过度拟合</li></ul><p id="a717" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有一些流行的选择变量的技术，如卡方检验，个人相关性选择，套索，递归特征消除，…</p><p id="17cf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 6。变量提取</strong></p><p id="a6b8" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">有时，我们的数据集由文本和图像等非结构化数据组成。有必要将这些数据中的特征提取为机器学习算法支持的格式。<a class="ae it" href="https://scikit-learn.org/stable/modules/feature_extraction.html" rel="noopener ugc nofollow" target="_blank">sk learn . feature _ extraction</a>是处理这个问题的有用模块。</p><p id="79b3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 7。将数据分成训练集和测试集</strong></p><p id="8a94" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">将数据集分成训练集和测试集是数据预处理的重要部分。训练集用于处理模型，测试集用于测试模型的准确性。因此，训练集应该足够大，以便模型能够正确地“学习”。事实上，大部分数据用于训练，小部分数据用于测试。</p><p id="3065" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">该任务可以通过模块<strong class="iw hi">sk learn . model _ selection</strong>中的函数<a class="ae it" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html" rel="noopener ugc nofollow" target="_blank"><strong class="iw hi">train _ test _ split</strong></a>来帮助完成。</p><p id="691b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，是时候回到我们的项目了！:-) </p><p id="92ea" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">8。应用于我们的房价预测项目</p><p id="a14b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">由于我们的数据集既不包括分类数据也不包括NaN值，因此我们只需要做一些工作，如拒绝离群值，选择最相关的变量并将数据分成训练集和测试集。</p><p id="df8e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> a .异常值剔除</strong></p><p id="c2ce" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">基于价格的分布，只有一些值大于250万。因此，我们可以将𝜏= 250万视为过滤异常值的阈值，所有价格高于𝜏的房屋都将从数据集中删除。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="7904" class="ma ko hh lw b fi mb mc l md me">t = 2.5*10**6</span><span id="e46c" class="ma ko hh lw b fi mf mc l md me">df_new = df[df['price']&lt;= t]</span></pre><p id="91aa" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">新数据集中价格列的分布:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="f9bc" class="ma ko hh lw b fi mb mc l md me">plt.figure(figsize=(10,7))</span><span id="b416" class="ma ko hh lw b fi mf mc l md me">sns.distplot(df_new['price'])</span><span id="5061" class="ma ko hh lw b fi mf mc l md me">plt.xlabel('price', fontsize = 16)</span><span id="c13d" class="ma ko hh lw b fi mf mc l md me">plt.ylabel('Density', fontsize = 16)</span><span id="4ea7" class="ma ko hh lw b fi mf mc l md me">plt.show()</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es nn"><img src="../Images/eba4c7c70bf17890de84ec79191da2b6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cDKP9FAwsPuRCrLdBpzfPA.png"/></div></div></figure><p id="2094" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> b .变量选择</strong></p><p id="257f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">一些特性，如“日期”、“id”和“邮政编码”并没有真正按照我们的目标(价格)进行修正，因此为了简化模型，它们可以被拒绝。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="3b23" class="ma ko hh lw b fi mb mc l md me">df_new = df_new.drop(['id','date', 'zipcode'], axis = 1)</span><span id="45f4" class="ma ko hh lw b fi mf mc l md me">df_new.head()</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es no"><img src="../Images/5e8e2f739fb4662f91e22006bdb7119b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7OS6d4F-iNW_CtfddeH95A.png"/></div></div></figure><p id="8984" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">将剩余变量的相关性可视化:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="8c71" class="ma ko hh lw b fi mb mc l md me">plt.figure(figsize = (8,8))</span><span id="8f79" class="ma ko hh lw b fi mf mc l md me">sns.clustermap(df_new.corr())</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es np"><img src="../Images/8ee4f0c0a016b12458e80a0eec30830d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wABLfySt92YsSbfqVfaVew.png"/></div></div></figure><p id="66c9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> c .将数据分成训练/测试集</strong></p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="a64f" class="ma ko hh lw b fi mb mc l md me">from sklearn.model_selection import train_test_split</span><span id="13b5" class="ma ko hh lw b fi mf mc l md me">train_set, test_set = train_test_split(df_new, test_size = 0.2, random_state = 0)</span><span id="c303" class="ma ko hh lw b fi mf mc l md me">print('Train size: ', train_set.shape[0], 'Test size: ', test_set.shape[0])</span><span id="9e78" class="ma ko hh lw b fi mf mc l md me">&gt;&gt;&gt; Train size:  17212 Test size:  4304</span></pre><p id="d861" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">可视化全国的价格分布:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="5faa" class="ma ko hh lw b fi mb mc l md me">plt.figure()</span><span id="c1ff" class="ma ko hh lw b fi mf mc l md me">df_new.plot(kind = 'scatter', x = 'long', y = 'lat', alpha = 0.8, c = 'price',cmap=plt.get_cmap('jet'), figsize = (12,8))</span><span id="505a" class="ma ko hh lw b fi mf mc l md me">plt.legend()</span><span id="ff38" class="ma ko hh lw b fi mf mc l md me">plt.show()</span></pre><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es nq"><img src="../Images/ee42a0b52b152696cce9db12a7949574.png" data-original-src="https://miro.medium.com/v2/resize:fit:1394/format:webp/1*cr1GOtgcUZDDnNRw_Sofvw.png"/></div></figure><p id="3a83" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> d .正常化</strong></p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="3f47" class="ma ko hh lw b fi mb mc l md me">X_train = train_set.drop('price', axis = 1)</span><span id="ee95" class="ma ko hh lw b fi mf mc l md me">y_train = train_set['price']</span><span id="f854" class="ma ko hh lw b fi mf mc l md me">X_test = test_set.drop('price', axis = 1)</span><span id="d551" class="ma ko hh lw b fi mf mc l md me">y_test = test_set['price']</span><span id="eded" class="ma ko hh lw b fi mf mc l md me">from sklearn.preprocessing import StandardScaler</span><span id="3df5" class="ma ko hh lw b fi mf mc l md me">scaler = StandardScaler()</span><span id="191b" class="ma ko hh lw b fi mf mc l md me">X_train = scaler.fit_transform(X_train)</span><span id="f0d7" class="ma ko hh lw b fi mf mc l md me">X_test = scaler.transform(X_test)</span></pre><p id="a316" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">检查训练集和测试集的大小:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="57d2" class="ma ko hh lw b fi mb mc l md me">print(X_train.shape, X_test.shape)</span><span id="8744" class="ma ko hh lw b fi mf mc l md me">&gt;&gt;&gt; (17212, 17) (4304, 17)</span></pre><p id="f54c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里，我们在训练集中有17 212个观察值，在测试集中有4304个观察值。</p><h1 id="3544" class="kn ko hh bd kp kq mh ks kt ku mi kw kx ky mj la lb lc mk le lf lg ml li lj lk bi translated">四。建模和评估</h1><p id="d14d" class="pw-post-body-paragraph iu iv hh iw b ix ll iz ja jb lm jd je jf ln jh ji jj lo jl jm jn lp jp jq jr ha bi translated">有各种机器学习模型，你可以根据目标选择，如线性回归，支持向量机，决策树，随机森林，K-最近邻，神经网络，K-均值，…</p><p id="5b6e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">特别是，这些算法在<strong class="iw hi"> sklearn </strong>中的实现是相似的，它包含3个主要步骤:</p><ul class=""><li id="6936" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">步骤1:初始化模型</li><li id="7f71" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated">步骤2:在训练集上拟合模型</li><li id="05b8" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated">步骤3:评估测试集中的模型</li></ul><p id="71bf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">举例:</strong></p><ul class=""><li id="15b9" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">线性回归模型:</li></ul><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="7b93" class="ma ko hh lw b fi mb mc l md me">from sklearn.linear_model import LinearRegression</span><span id="a83e" class="ma ko hh lw b fi mf mc l md me"># initialize the model</span><span id="b2a6" class="ma ko hh lw b fi mf mc l md me">model = LinearRegression()</span><span id="d257" class="ma ko hh lw b fi mf mc l md me"># fit the model on the training set</span><span id="fb5d" class="ma ko hh lw b fi mf mc l md me">model.fit(X_train, y_train)</span><span id="ddb4" class="ma ko hh lw b fi mf mc l md me"># evaluate the model on the test set:</span><span id="aa52" class="ma ko hh lw b fi mf mc l md me">y_pred = model.predict(X_test)</span></pre><ul class=""><li id="a84d" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">逻辑回归模型:</li></ul><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="5012" class="ma ko hh lw b fi mb mc l md me">from sklearn.linear_model import LogisticRegression</span><span id="2cf3" class="ma ko hh lw b fi mf mc l md me"># initialize the model</span><span id="5224" class="ma ko hh lw b fi mf mc l md me">model = LogisticRegression()</span><span id="080b" class="ma ko hh lw b fi mf mc l md me"># fit the model on the training set</span><span id="12be" class="ma ko hh lw b fi mf mc l md me">model.fit(X_train, y_train)</span><span id="957b" class="ma ko hh lw b fi mf mc l md me"># evaluate the model on the test set:</span><span id="f1d8" class="ma ko hh lw b fi mf mc l md me">y_pred = model.predict(X_test)</span></pre><ul class=""><li id="2e1d" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">支持向量机模型；</li></ul><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="435c" class="ma ko hh lw b fi mb mc l md me">from sklearn.svm import SVC</span><span id="d06f" class="ma ko hh lw b fi mf mc l md me"># initialize the model</span><span id="c7ae" class="ma ko hh lw b fi mf mc l md me">model = SVC()</span><span id="4130" class="ma ko hh lw b fi mf mc l md me"># fit the model on the training set</span><span id="caf8" class="ma ko hh lw b fi mf mc l md me">model.fit(X_train, y_train)</span><span id="c563" class="ma ko hh lw b fi mf mc l md me"># evaluate the model on the test set:</span><span id="3187" class="ma ko hh lw b fi mf mc l md me">y_pred = model.predict(X_test)</span></pre><ul class=""><li id="d08f" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated">随机森林</li></ul><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="e007" class="ma ko hh lw b fi mb mc l md me">from sklearn.ensemble import RandomForestClassifier</span><span id="a092" class="ma ko hh lw b fi mf mc l md me"># initialize the model</span><span id="28bd" class="ma ko hh lw b fi mf mc l md me">model = RandomForestClassifier()</span><span id="ec90" class="ma ko hh lw b fi mf mc l md me"># fit the model on the training set</span><span id="cb2e" class="ma ko hh lw b fi mf mc l md me">model.fit(X_train, y_train)</span><span id="a15f" class="ma ko hh lw b fi mf mc l md me"># evaluate the model on the test set:</span><span id="8457" class="ma ko hh lw b fi mf mc l md me">y_pred = model.predict(X_test)</span></pre><ul class=""><li id="7dce" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi">…</li></ul><p id="4d87" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">选择评估机器学习算法的指标也非常重要。在监督学习中，根据你的目标是分类还是回归，你可以选择不同的度量标准:</p><ul class=""><li id="e08a" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr lq jy jz ka bi translated"><strong class="iw hi">分类度量</strong>:准确率、损失、ROC曲线、混淆矩阵、分类报告。</li><li id="edd0" class="js jt hh iw b ix kb jb kc jf kd jj ke jn kf jr lq jy jz ka bi translated"><strong class="iw hi">回归度量</strong>:平均绝对误差、均方误差(MSE)、均方根误差(RMSE)、R度量。</li></ul><p id="c7c4" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">我们项目的应用:</strong></p><p id="7502" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">回到我们的房价预测项目上来。我们将尝试不同的模型，如线性回归、决策树回归、随机森林回归。由于我们的目标是回归问题，因此我们选择均方根误差(RMSE)来评估我们的模型:</p><figure class="lr ls lt lu fd ii er es paragraph-image"><div class="er es nr"><img src="../Images/7ceabf2338d361125e24160449023b3f.png" data-original-src="https://miro.medium.com/v2/resize:fit:530/1*SqNkKlBNkBcYHc1tGNcR8A.gif"/></div></figure><p id="19a0" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">其中n是测试集的观测值，y^{(i)}和f(x^{(i)})对应于x^{(i)}.的真实目标和估计目标该指标可以从<strong class="iw hi"> sklearn.metrics </strong>模块导入。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="eec0" class="ma ko hh lw b fi mb mc l md me">from sklearn.metrics import mean_squared_error</span></pre><ol class=""><li id="b7fa" class="js jt hh iw b ix iy jb jc jf ju jj jv jn jw jr jx jy jz ka bi translated"><strong class="iw hi">线性回归</strong></li></ol><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="dcdb" class="ma ko hh lw b fi mb mc l md me">from sklearn.linear_model import LinearRegression</span><span id="89fd" class="ma ko hh lw b fi mf mc l md me"># Initialize the model<br/>lin_reg = LinearRegression()</span><span id="5f25" class="ma ko hh lw b fi mf mc l md me"># Fit the model on the training set<br/>lin_reg.fit(X_train,y_train)</span><span id="71dd" class="ma ko hh lw b fi mf mc l md me"># Evaluate the model on the test set: <br/>y_pred_lin = lin_reg.predict(X_test)<br/>mse_lin = mean_squared_error(y_test,y_pred_lin)<br/>rmse_lin = np.sqrt(mse_lin)</span><span id="7bb4" class="ma ko hh lw b fi mf mc l md me">print('RMSE of Linear Regression is: ', round(rmse_lin,1))<br/>RMSE of Linear Regression is:  167347.9</span></pre><p id="b49c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 2。决策树</strong></p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="8060" class="ma ko hh lw b fi mb mc l md me">from sklearn.tree import DecisionTreeRegressor</span><span id="eb15" class="ma ko hh lw b fi mf mc l md me"># Initialize the model<br/>tree_reg = DecisionTreeRegressor()</span><span id="a0dd" class="ma ko hh lw b fi mf mc l md me"># Fit the model on the training set<br/>tree_reg.fit(X_train, y_train)</span><span id="24e3" class="ma ko hh lw b fi mf mc l md me"># Evaluate the model on the test set<br/>y_pred_tree = tree_reg.predict(X_test)<br/>mse_tree = mean_squared_error(y_test, y_pred_tree)<br/>rmse_tree = np.sqrt(mse_tree)</span><span id="b1fd" class="ma ko hh lw b fi mf mc l md me">print('RMSE of Decision Tree is: ', rmse_tree)<br/>RMSE of Decision Tree is:  156869.0</span></pre><p id="c65d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以看到，决策树算法给出的结果优于线性回归的结果。我们试试随机森林算法，看看是否比这两个算法好。</p><p id="06ac" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> 3。随机森林</strong></p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="eef3" class="ma ko hh lw b fi mb mc l md me">from sklearn.ensemble import RandomForestRegressor</span><span id="aee0" class="ma ko hh lw b fi mf mc l md me"># Initialize the model <br/>forest_reg = RandomForestRegressor()</span><span id="bd06" class="ma ko hh lw b fi mf mc l md me"># Fit the model on the training set<br/>forest_reg.fit(X_train, y_train)</span><span id="395d" class="ma ko hh lw b fi mf mc l md me"># Evaluate the model on the test set<br/>y_pred_forest = forest_reg.predict(X_test)</span><span id="7ef2" class="ma ko hh lw b fi mf mc l md me">mse_forest = mean_squared_error(y_test1, y_pred_forest)</span><span id="ba93" class="ma ko hh lw b fi mf mc l md me">rmse_forest = np.sqrt(mse_forest)</span><span id="0b8d" class="ma ko hh lw b fi mf mc l md me">print('RMSE of Random Forest method is: ', round(rmse_forest,1))<br/>RMSE of Random Forest method is:  114766.6</span></pre><p id="ed6b" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">结论</strong>:在以上三种方法中，随机方法给出的结果最好。在下一节中，我们将通过寻找更好的参数来改进该算法，以便模型获得更高的性能。</p><h1 id="bc47" class="kn ko hh bd kp kq mh ks kt ku mi kw kx ky mj la lb lc mk le lf lg ml li lj lk bi translated">动词 （verb的缩写）超参数调谐</h1><p id="6b11" class="pw-post-body-paragraph iu iv hh iw b ix ll iz ja jb lm jd je jf ln jh ji jj lo jl jm jn lp jp jq jr ha bi translated"><strong class="iw hi">sci kit-learn . model _ selection</strong>模块包中的函数GridSearchCV允许我们用不同的超参数组合来训练模型，它会自动确定为我们提供最佳性能的参数。</p><p id="08ab" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">导入<strong class="iw hi"> GridSearchCV </strong>函数:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="2ff9" class="ma ko hh lw b fi mb mc l md me">from sklearn.model_selection import GridSearchCV</span></pre><p id="7d1e" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">首先，让我们发现实际随机森林模型的参数:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="e062" class="ma ko hh lw b fi mb mc l md me">forest_reg  </span><span id="03a6" class="ma ko hh lw b fi mf mc l md me"><strong class="lw hi">RandomForestRegressor</strong>(bootstrap=True, ccp_alpha=0.0,criterion='mse',                       <br/>max_depth=None, max_features='auto', max_leaf_nodes=None,                                           max_samples=None, min_impurity_decrease=0.0,                          min_impurity_split=None, min_samples_leaf=1,                       min_samples_split=2, min_weight_fraction_leaf=0.0,                       n_estimators=100, n_jobs=None, oob_score=False,                         random_state=None, verbose=0, warm_start=False)</span></pre><p id="8eac" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们可以改变许多参数。现在，让我们尝试一些参数，如bootstrap，max_features，min_samples_split，n_estimors。这些参数的测试值保存在字典<strong class="iw hi"> params_grid </strong>中:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="5993" class="ma ko hh lw b fi mb mc l md me">params_grid = [{'bootstrap': [False, True],<br/>                'min_samples_split': [2,4,5],<br/>                'n_estimators': [100,150,200],<br/>                'max_features': [8,10,12]}]</span></pre><p id="6866" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们有超参数bootstrap、max_features、min_samples_split、n_estimators的2×3×3 = 54个组合。</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="9b2c" class="ma ko hh lw b fi mb mc l md me"># Initialize the model<br/>forest_reg = RandomForestRegressor()</span><span id="73e1" class="ma ko hh lw b fi mf mc l md me"># Apply <strong class="lw hi">GridSearchCV</strong> on our model with all parameters in <strong class="lw hi">params_grid</strong><br/>grid_search = GridSearchCV(forest_reg, params_grid, cv = 5,<br/>                           scoring = 'neg_mean_squared_error',<br/>                           return_train_score = True)</span><span id="785f" class="ma ko hh lw b fi mf mc l md me"># Fit all models in the training set<br/>grid_search.fit(X_train, y_train)</span></pre><p id="e7e9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">每个模型训练5次，对应交叉验证值。因此，我们总共有54 × 5 = 270轮训练。</p><p id="4cdd" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">一旦训练完成，我们可以确定参数，给我们最好的估计模型。</p><p id="9236" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">最佳参数:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="8d2f" class="ma ko hh lw b fi mb mc l md me">grid_search.best_params_<br/>{'bootstrap': True,  <br/> 'max_features': 10,  <br/> 'min_samples_split': 2,  <br/> 'n_estimators': 150}</span></pre><p id="5666" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">因此，对于给定的参数，当bootstrap = True，max_features = 10，min_samples_split = 2，n_estimators = 150时，模型效果最佳。对应于这些参数的模型由下式给出:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="e913" class="ma ko hh lw b fi mb mc l md me">final_model = grid_search.best_estimator_<br/>final_model<br/><strong class="lw hi">RandomForestRegressor</strong>(bootstrap=True, ccp_alpha=0.0,criterion='mse',                       <br/>max_depth=None, max_features=10, max_leaf_nodes=None,                       max_samples=None, min_impurity_decrease=0.0,                       min_impurity_split=None, min_samples_leaf=1,                       min_samples_split=2, min_weight_fraction_leaf=0.0,                       n_estimators=150, n_jobs=None, oob_score=False,                           random_state=None, verbose=0, warm_start=False)</span></pre><h1 id="733b" class="kn ko hh bd kp kq mh ks kt ku mi kw kx ky mj la lb lc mk le lf lg ml li lj lk bi translated">不及物动词预测。</h1><p id="5d3a" class="pw-post-body-paragraph iu iv hh iw b ix ll iz ja jb lm jd je jf ln jh ji jj lo jl jm jn lp jp jq jr ha bi translated">确定最佳模型后，它可用于预测测试集上的新样本:</p><pre class="lr ls lt lu fd lv lw lx ly aw lz bi"><span id="02ee" class="ma ko hh lw b fi mb mc l md me">y_pred_final = final_model.predict(X_test)</span><span id="9d81" class="ma ko hh lw b fi mf mc l md me">mse_final = mean_squared_error(y_test1, y_pred_final)</span><span id="6fe0" class="ma ko hh lw b fi mf mc l md me">rmse_final = np.sqrt(mse_final)</span><span id="5a1e" class="ma ko hh lw b fi mf mc l md me">print('RMSE of final model is: ', round(rmse_final,1))<br/>RMSE of final model is:  110775.0</span></pre><p id="8662" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">下图显示了测试集中100个数据点的真实值和预测值。</p><figure class="lr ls lt lu fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ns"><img src="../Images/9018f46cac44c8dad0f0d137fb5bcc41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1IKdfvr-8wYmmzLFIVpXKg.png"/></div></div></figure><p id="670d" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">听起来我们的预测接近真实值。但是模型仍然可以通过尝试更多的超参数来改进。(<em class="nj">这个任务对你来说是作为一个练习工作来度过的。:-) </em>)</p><p id="eabf" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi">结论:</strong></p><p id="8c15" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在本文中，我们发现了机器学习项目的一些必要步骤。它们包括收集、分析、预处理数据、模型化、评估模型、超参数调整以及最终使用模型预测新数据点。有时，我们必须尝试不同的模型和不同的参数，以选择精度最高的最佳模型。这些模型都有sklearn包支持，sk learn包是机器学习的有力工具。你可以看到<a class="ae it" href="https://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank">这个参考</a>获得这个包的更多细节。</p><p id="d40f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我希望这篇文章有助于规划您的项目。如果你有任何问题，请在评论中告诉我。欢迎所有的贡献。。^</p><p id="a115" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">感谢您的阅读！</p><p id="b75f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><strong class="iw hi"> Github代码:</strong><a class="ae it" href="https://github.com/KhuyenLE-maths/House-price-prediction/blob/main/House_price_prediction.ipynb" rel="noopener ugc nofollow" target="_blank">https://Github . com/khu yenle-maths/House-price-prediction/blob/main/House _ price _ prediction . ipynb</a></p><p id="0290" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">关于机器学习项目的数据准备的其他参考资料:</p><div class="nt nu ez fb nv nw"><a href="https://github.com/KhuyenLE-maths/Project_PublicHealth_France/blob/main/notebook.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nx ab dw"><div class="ny ab nz cl cj oa"><h2 class="bd hi fi z dy ob ea eb oc ed ef hg bi translated">Project _ public health _ France/notebook . ipynb at main khu yenle-maths/Project _ public health _ France</h2><div class="od l"><h3 class="bd b fi z dy ob ea eb oc ed ef dx translated">大型数据集中的探索性数据分析，PCA，test ANOVA-Project _ public health _ France/notebook . ipynb at main…</h3></div><div class="oe l"><p class="bd b fp z dy ob ea eb oc ed ef dx translated">github.com</p></div></div><div class="of l"><div class="og l oh oi oj of ok in nw"/></div></div></a></div><div class="nt nu ez fb nv nw"><a href="https://github.com/KhuyenLE-maths/Project_EDA_Paris_trees/blob/main/Paris_SmartCity.ipynb" rel="noopener  ugc nofollow" target="_blank"><div class="nx ab dw"><div class="ny ab nz cl cj oa"><h2 class="bd hi fi z dy ob ea eb oc ed ef hg bi translated">Project _ EDA _ Paris _ trees/Paris _ smart city . ipynb at main khu yenle-maths/Project _ EDA _ Paris _ trees</h2><div class="od l"><h3 class="bd b fi z dy ob ea eb oc ed ef dx translated">大数据集的探索性数据分析。对khu yenle-maths/Project _ EDA _ Paris _ trees开发的贡献来自…</h3></div><div class="oe l"><p class="bd b fp z dy ob ea eb oc ed ef dx translated">github.com</p></div></div><div class="of l"><div class="ol l oh oi oj of ok in nw"/></div></div></a></div><p id="e330" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">用各种机器学习算法参考收入分类</p><p id="efea" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated"><a class="ae it" href="https://github.com/KhuyenLE-maths/Project_Income_Classification/blob/main/notebook.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/khu yenle-maths/Project _ Income _ Classification/blob/main/notebook . ipynb</a></p></div></div>    
</body>
</html>