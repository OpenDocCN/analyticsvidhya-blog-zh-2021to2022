<html>
<head>
<title>Understanding Semantic Search — (Part 3: Introduction to Knowledge Graphs for Question Answering)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">理解语义搜索—(第3部分:问答知识图介绍)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/open-domain-question-answering-series-part-3-introduction-to-knowledge-graphs-for-question-5d3f8d78812e?source=collection_archive---------0-----------------------#2022-01-10">https://medium.com/analytics-vidhya/open-domain-question-answering-series-part-3-introduction-to-knowledge-graphs-for-question-5d3f8d78812e?source=collection_archive---------0-----------------------#2022-01-10</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/ffb77e6cff5fdbcbc3e1e7d9a744fcef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DNkq1c0iyXt8L_tPi6cvqQ.jpeg"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">作者照片:在约塞米蒂国家公园(2019年7月)用我的iPhone拍摄的美丽照片</figcaption></figure><p id="5ecb" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">你有没有想过，当你搜索一个人或一个地方时，谷歌是如何显示“关于”面板的？</p><p id="4f92" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">他们用<strong class="iw hj">知识图</strong>来做！</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es js"><img src="../Images/2f201d386c625ccb148638a4a48afc83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7AKnfuWmRhjMCTxKjtIkAA.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">作者截图:当有人搜索托尼·斯塔克时，谷歌的“关于”面板会显示关于他的事实和更广泛的话题。通过推断知识图中Tony Stark节点的相邻节点和关系来提取信息。</figcaption></figure><p id="3409" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">一般来说，有两种类型的问题回答。在之前的两篇文章(<a class="ae jx" rel="noopener" href="/analytics-vidhya/open-domain-question-answering-series-part-1-introduction-to-reading-comprehension-question-1898c8c9560e">机器阅读理解简介</a>和<a class="ae jx" rel="noopener" href="/analytics-vidhya/open-domain-question-answering-series-part-2-machine-reading-comprehension-at-scale-7ca0b75dbd3a">机器阅读理解规模</a>)中，我讨论了如何使用语言模型建立神经问答模型，并在文档这样的非结构化数据上进行迁移学习。我将在本文中介绍结构化数据的知识图问答(KGQA)。</p><p id="89e1" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">知识图表是谷歌在2012年首次推出的。知识图使用实体作为节点，实体之间的关系作为边，将文本表示为图形。</p><p id="d492" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">让我们考虑下面的句子，</p><p id="d355" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">《托尼·斯塔克》由作家兼编辑斯坦·李联合创作，编剧赖瑞·理柏开发，艺术家唐·赫克和杰克·科比设计。 ”</p><p id="98aa" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">下图是上述句子的知识图表。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es jz"><img src="../Images/9a0de1d13b3e2560dfb0b1676ea6db43.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1Gd0w2amYjguLMShoGmmRw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自作者的截图</figcaption></figure><p id="e8ea" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">许多公司，如Airbnb、易贝、微软和康卡斯特，都建立了他们特定领域的知识图平台，并使用他们的客户和产品数据来维护它们，以做出数据驱动的商业决策。</p><blockquote class="ka kb kc"><p id="2046" class="iu iv jy iw b ix iy iz ja jb jc jd je kd jg jh ji ke jk jl jm kf jo jp jq jr hb bi translated">知识图中所有产品数据的整合导致流程成本节约高达<strong class="iw hj"> 65% </strong>，并使产品经理能够做出有充分依据的决策。—德勤</p></blockquote><p id="b416" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">构建知识图所需的三个主要NLP任务是命名实体提取、关系提取和共指消解。</p><p id="e5d5" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">命名实体提取:</strong></p><p id="848a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">命名实体提取是预测命名实体或专有名称的任务，如给定文本的个人、组织或位置。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kg"><img src="../Images/14ea3874d1da40e2c3ebb23434359b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*euVMXGr6wBU7SRN8-qKmiQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">从<a class="ae jx" href="https://allenai.org/" rel="noopener ugc nofollow" target="_blank"> AllenNLP </a>中提取命名实体</figcaption></figure><p id="f874" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">关系提取:</strong></p><p id="a89a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">关系提取是提取所提供的实体之间或者主体和客体之间的关系的任务。依存句法分析是一种使用句子结构和语法来寻找关系和实体的方法。例如，below dependency parser将Stark检测为专有名词和主语(实体)，将weapon和tests检测为名词和宾语(实体)，将conducting检测为动词(关系)。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kh"><img src="../Images/d8f5c01f2462796bf9e13edf7cbca552.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DnxUBWMqN2J79-6S72Jzyg.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自<a class="ae jx" href="https://allenai.org/" rel="noopener ugc nofollow" target="_blank"> AllenNLP </a>的依赖解析</figcaption></figure><p id="2320" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">共指消解:</strong></p><p id="6125" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">共指消解的任务是预测文本中不同的词是否指代同一个实体。在下图中，模型发现托尼·斯塔克、他、他、他的和斯塔克是同一个实体。(标有数字0和蓝色)</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es ki"><img src="../Images/348f86ff907449d2dd2b6ba4b0c65835.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BhXVrgVg1j44Dl2yQ0e-Lw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自<a class="ae jx" href="https://allenai.org/" rel="noopener ugc nofollow" target="_blank">allenlp</a>的共指消解</figcaption></figure><p id="f377" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">除了共指解析之外，我们还可以使用<strong class="iw hj">可传递属性</strong>映射<strong class="iw hj">可选标签</strong> (CEO和首席执行官指的是同一个实体)，映射<strong class="iw hj">同义词</strong>(房子、家和住所指的是同一个实体)，其中桑德尔·皮帅是CEO，CEO是雇员，桑德尔·皮帅是雇员。注意:传递性可能不总是正确的(狮子吃羊，羊吃草→狮子不吃草)。</p><p id="4b1c" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">我们可以使用上面列出的方法获得实体和关系三元组(主体、客体和关系)。我们可以使用三元组和像<a class="ae jx" href="https://pypi.org/project/networkx/" rel="noopener ugc nofollow" target="_blank"> Networkx </a>这样的开源库创建一个有向无环图(知识图)。在像<a class="ae jx" href="https://graphdb.ontotext.com/documentation/free/about-graphdb.html" rel="noopener ugc nofollow" target="_blank"> GraphDB </a>这样的健壮的基于图的数据库中存储知识图是一个好主意。</p><p id="96d9" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">知识图谱问答:</strong></p><p id="f7a3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">知识图表可以帮助有效地回答事实问题。当像“纳尔逊·曼德拉出生在哪里？”就是问，期待一个地方作为答案。同样，当一个问题像“印度什么时候获得独立？”我们期待一个日期作为答案。</p><p id="8b54" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">当用户提出一个查询时，它被解析以获得相关实体及其关系，从而从知识图中提取答案。KGQA可以通过将自然语言问题转换成类似于<a class="ae jx" href="https://en.wikipedia.org/wiki/SPARQL" rel="noopener ugc nofollow" target="_blank"> SPARQL </a>和<a class="ae jx" href="https://en.wikipedia.org/wiki/Cypher_%28query_language%29" rel="noopener ugc nofollow" target="_blank"> Cypher </a>的结构化查询来实现这一点。例如，当一个问题像“纳尔逊·曼德拉在南非哪里出生？”被询问时，“纳尔逊·曼德拉”和“南非”被提取为实体，“出生”和“位于”被提取为关系以得到答案——“Mvezo”</p><p id="a8f2" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">对用户查询的实体和关系解析通过简单的基于模板的实体和关系检测方法来执行。然而，最近的研究工作，如<a class="ae jx" href="https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00383-w" rel="noopener ugc nofollow" target="_blank"> <em class="jy">用自然语言查询知识图(2021年1月)</em> </a>提出了一个系统，使用基于树LSTM的神经网络将自然语言问题翻译成SPARQL查询。其他研究工作，如<a class="ae jx" href="https://www.ijcai.org/proceedings/2020/666" rel="noopener ugc nofollow" target="_blank"> <em class="jy">用于探索和查询知识图的用户界面</em> </a> <em class="jy"> </em>为非技术用户引入了语言和视觉系统，以避免在知识图上编写复杂的查询。</p><figure class="jt ju jv jw fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es kj"><img src="../Images/d3d739b1903147d5df3b66261695ed4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IR6jEk1Zdxbgroz7Sm7WCQ.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自作者的截图</figcaption></figure><p id="c883" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">知识图问答相对于神经问答的最大优势是能够提取不同实体之间的逻辑推理，并且易于解释根本原因分析。然而，传统的KGQA在稀疏或小知识图上是失败的，因为它们不能正确地回答用户的问题。此外，知识图不能捕获基于神经或语言模型的问题回答在大型非结构化文本上捕获的更广泛的知识。因此，在问答中已经有了<a class="ae jx" href="https://arxiv.org/abs/2104.06378" rel="noopener ugc nofollow" target="_blank">积极的研究</a>来结合语言模型和知识图的互补优势用于问答。</p><p id="1d0a" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated"><strong class="iw hj">结论:</strong></p><p id="5df3" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">恭喜你，你完成了问答知识图表介绍。在前两篇文章中，我讨论了仿真陈述和抽取式问题回答建模，其中模型指向文档中的精确文本作为给定问题的答案。但是在某些情况下，必须引用不同的文档来为给定的查询生成答案。未来的文章将介绍复杂查询的生成式问答模型。</p><p id="6045" class="pw-post-body-paragraph iu iv hi iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr hb bi translated">敬请关注理解语义搜索系列的更多文章！(点击了解本系列其他文章的更多信息<a class="ae jx" rel="noopener" href="/@kaushikshakkari/list/9df1566193b0"/></p></div><div class="ab cl kk kl gp km" role="separator"><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp kq"/><span class="kn bw bk ko kp"/></div><div class="hb hc hd he hf"><h1 id="87fa" class="kr ks hi bd kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo bi translated">在<a class="ae jx" href="https://www.linkedin.com/in/kaushik-shakkari/" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上加我。谢谢大家！</h1></div></div>    
</body>
</html>