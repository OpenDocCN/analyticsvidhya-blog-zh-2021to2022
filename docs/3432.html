<html>
<head>
<title>Leveraging NMF Topic Modeling in Building Recommendation Systems</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用NMF主题建模构建推荐系统</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/leveraging-nmf-topic-modeling-in-building-recommendation-systems-2e5d2a190106?source=collection_archive---------20-----------------------#2021-06-30">https://medium.com/analytics-vidhya/leveraging-nmf-topic-modeling-in-building-recommendation-systems-2e5d2a190106?source=collection_archive---------20-----------------------#2021-06-30</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div class="er es ie"><img src="../Images/d84acc88bcc4f7e5029f2faa2fd232b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*339YnYMC3cN2IBzJ07YJ6g.jpeg"/></div><figcaption class="il im et er es in io bd b be z dx translated">侍酒师，原创的葡萄酒推荐系统</figcaption></figure></div><div class="ab cl ip iq go ir" role="separator"><span class="is bw bk it iu iv"/><span class="is bw bk it iu iv"/><span class="is bw bk it iu"/></div><div class="ha hb hc hd he"><p id="fb93" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">传统上，葡萄酒推荐建立在机构知识的基础上。非常有才华的人，品味高雅，通过品尝、阅读、闻和谈论葡萄酒来建立自己的心理数据库。通过多年的实践，他们能够为渴望喝酒的人提供细致入微的建议。但是如果有一种方法可以使用无监督的机器学习来增加他们的知识呢？这就是主题建模的用武之地！利用非负矩阵分解(一种无监督的机器学习技术)和余弦相似性(一种非欧几里德相似性技术)可以帮助葡萄酒鉴赏家纯粹基于对各种葡萄酒的描述来理解葡萄酒结构。</p></div><div class="ab cl ip iq go ir" role="separator"><span class="is bw bk it iu iv"/><span class="is bw bk it iu iv"/><span class="is bw bk it iu"/></div><div class="ha hb hc hd he"><h1 id="7324" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">无监督学习</h1><p id="3934" class="pw-post-body-paragraph iw ix hh iy b iz ks jb jc jd kt jf jg jh ku jj jk jl kv jn jo jp kw jr js jt ha bi translated">无监督ML，简单来说就是机器学习的一个分支，利用无标签的输入来检测底层数据中的模式和结构。对于这个项目，输入是葡萄酒描述的集合，通常称为<em class="kx">文档。</em>示例描述如下:</p><p id="e3c0" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated"><em class="kx">充满了阿拉伯树胶、成熟苹果、榛子和不寻常的黑醋味。口感已经进化，失去了大部分水果的丰富和新鲜，取而代之的是蜂蜜矿物质、烤坚果和一丝干柑橘的味道。</em></p><p id="571d" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">数据集中的每种酒都有一个描述，它们合在一起就是一个描述的集合，称为<em class="kx">语料库。从这里我们可以使用一种叫做NMF的技术来构建我们的模型。</em></p></div><div class="ab cl ip iq go ir" role="separator"><span class="is bw bk it iu iv"/><span class="is bw bk it iu iv"/><span class="is bw bk it iu"/></div><div class="ha hb hc hd he"><h1 id="3cb0" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">非负矩阵分解</h1><p id="6775" class="pw-post-body-paragraph iw ix hh iy b iz ks jb jc jd kt jf jg jh ku jj jk jl kv jn jo jp kw jr js jt ha bi translated">NMF的数学支柱是线性代数，特别是矩阵分解。复杂的数学细节太繁琐，本文无法一一介绍。但我会试着简单描述一下</p><figure class="kz la lb lc fd ii er es paragraph-image"><div class="er es ky"><img src="../Images/c926eeeccf6b21500f91c5e08cf35935.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*75E815RPh2HqxMw4O6aGYA.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">重建术语文档矩阵(五)</figcaption></figure><p id="09fe" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">矩阵V是术语文档矩阵。在这个特定的例子中，我们通过使用TF-IDF矢量器构建了矩阵V。这意味着V的每一行都是一个(1 X N)向量，其中N列表示在TF-IDF中找到的单词。V中的几行示例如下所示</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ld"><img src="../Images/895e05aa8ea3fc6790a76231330785d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kFB8jr2_ByUC55WiXKyYzQ.jpeg"/></div></div></figure><p id="532a" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">现在，这个术语文档矩阵包含来自几乎整个语料库的字数(我说几乎是因为TF-IDF允许通过函数传递约束，以限制没有添加语义值的无用单词)。当语料库中的文档数量很大时，这可能意味着高维度的术语文档矩阵。所以NMF的目标是降低维度，我们可以通过实施NMF来实现。这就是W和H矩阵的用武之地。下面是W和H代表什么的简要说明</p><blockquote class="li lj lk"><p id="e7f0" class="iw ix kx iy b iz ja jb jc jd je jf jg ll ji jj jk lm jm jn jo ln jq jr js jt ha bi translated">NMF将产生两个矩阵W和h。W的列可以被解释为基础文档(单词袋)。在这种情况下，我们能对这样一份基础文件作出什么解释？他们代表话题！在不同文档中同时发现的多组单词。h告诉我们如何将不同主题的贡献相加，以重构给定原始文档的单词组合。<a class="ae lo" href="https://blog.acolyer.org/2019/02/18/the-why-and-how-of-nonnegative-matrix-factorization/" rel="noopener ugc nofollow" target="_blank">链接</a></p></blockquote></div><div class="ab cl ip iq go ir" role="separator"><span class="is bw bk it iu iv"/><span class="is bw bk it iu iv"/><span class="is bw bk it iu"/></div><div class="ha hb hc hd he"><h1 id="e91a" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">构建基于内容的推荐系统</h1><p id="aab7" class="pw-post-body-paragraph iw ix hh iy b iz ks jb jc jd kt jf jg jh ku jj jk jl kv jn jo jp kw jr js jt ha bi translated">好了，说够了。更多关于NMF的阅读，你可以点击上面的<a class="ae lo" href="https://blog.acolyer.org/2019/02/18/the-why-and-how-of-nonnegative-matrix-factorization/" rel="noopener ugc nofollow" target="_blank">链接</a>。我们将使用主题矩阵W的行作为向量来构建我们的余弦相似性推荐器。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lp"><img src="../Images/e015e1b095601678c3ace2a374f6b7a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1zwf5gqbEbmvyvlx5Cs_7A.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">主题矩阵(n=30)</figcaption></figure><p id="e844" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">思考上述主题矩阵的最佳方式是将每一列视为一个特定的主题(水果味、红色、混合红色、白色、酸性等)..)并将每一行作为我们语料库中的一个特定文档。因此，每个条目都表示topic_y在多大程度上代表了文档X。因此，在第2行(索引1)中，您可以看到topic_4和topic_2被高度代表。现在是有趣的部分！</p></div><div class="ab cl ip iq go ir" role="separator"><span class="is bw bk it iu iv"/><span class="is bw bk it iu iv"/><span class="is bw bk it iu"/></div><div class="ha hb hc hd he"><h1 id="043c" class="ju jv hh bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">短暂的插曲变成余弦相似</h1><p id="adc8" class="pw-post-body-paragraph iw ix hh iy b iz ks jb jc jd kt jf jg jh ku jj jk jl kv jn jo jp kw jr js jt ha bi translated">给定两个n维向量A和B，我们可以用以下等式求出它们之间的角度</p><figure class="kz la lb lc fd ii er es paragraph-image"><div class="er es lq"><img src="../Images/31de0c96686327edc6be8e6be1322e0f.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/1*CHTUjtaensX3H8pxh9lYLQ.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">余弦相似性</figcaption></figure><p id="f143" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">这在视觉上表现为，</p><figure class="kz la lb lc fd ii er es paragraph-image"><div class="er es lr"><img src="../Images/1186156bd2a6019a1e1741bbd2950429.png" data-original-src="https://miro.medium.com/v2/resize:fit:976/format:webp/1*mJwpCspK1atgt0PJO66NTQ.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">余弦相似性的可视化表示</figcaption></figure><p id="ae89" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">因此，根据两个物体之间角度的大小，它们是相似的。较小的角度表示两个文档之间的相似度较高，而较大的角度表示两个文档之间的相似度较低。幸运的是，Scikit-Learn有一个内置的库来计算余弦相似性，所以它不必在Numpy中单独完成。</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ls"><img src="../Images/999d877e283a4ca5b64d45083fa04809.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cyrRzwgycusvfW2Mq_rHvg.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">余弦相似矩阵</figcaption></figure><p id="1eb8" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">每行和每列代表语料库中的一个特定文档。但是让我们从文档/语料库转向葡萄酒和葡萄酒描述。因此，对于<strong class="iy hi">葡萄酒0 </strong>(第0行)，如果您遍历从0到19，994的列，您可以读取每种葡萄酒与<strong class="iy hi">葡萄酒0相比的相似性得分。</strong></p><p id="021a" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">当你将葡萄酒0与它本身进行比较时，你得到的相似性分数是1。这是有意义的，因为如果你从余弦相似度计算中读取原始角度，你会得到一个0°的角度。两个葡萄酒向量都指向n维空间中的同一个位置。您在上面的代码片段中看到的相似性读数是当您通过余弦函数传递原始角度读数时，余弦(0) = 1。</p><p id="1047" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">现在我们有了相似性得分，我们可以将上面的葡萄酒描述的索引与<a class="ae lo" href="https://www.kaggle.com/zynicide/wine-reviews" rel="noopener ugc nofollow" target="_blank">原始数据集</a>中的葡萄酒标题进行匹配。之后，我们可以按降序排列分数。这是片段，</p><figure class="kz la lb lc fd ii er es paragraph-image"><div class="er es lt"><img src="../Images/deed3fea4b044212976ead956ace6b04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1112/format:webp/1*bEXYZ-ugvbYbCmYYEmdV1w.png"/></div><figcaption class="il im et er es in io bd b be z dx translated">组织葡萄酒相似性得分</figcaption></figure><h1 id="13d4" class="ju jv hh bd jw jx lu jz ka kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr bi translated">简化应用程序</h1><p id="060b" class="pw-post-body-paragraph iw ix hh iy b iz ks jb jc jd kt jf jg jh ku jj jk jl kv jn jo jp kw jr js jt ha bi translated">最后，Streamlit允许我们集成一些交互性。Streamlit使互动烘焙变得非常容易。下面是这个应用程序的一个片段，</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es lz"><img src="../Images/5ede647747e4be17910b515dd87c48cb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rZU8HGM73aH-NHA4PD3xkA.png"/></div></div><figcaption class="il im et er es in io bd b be z dx translated">用户可以从数据库中选择一种葡萄酒，并查看哪些葡萄酒与其最相似</figcaption></figure><p id="c97a" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">用户也可以通过价格范围过滤相似的酒，</p><figure class="kz la lb lc fd ii er es paragraph-image"><div role="button" tabindex="0" class="le lf di lg bf lh"><div class="er es ma"><img src="../Images/ab06f042d8f2707c994168576fa1d698.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*azXzWjLACsJXr0x_hWLhtw.png"/></div></div></figure><h1 id="a9c7" class="ju jv hh bd jw jx lu jz ka kb lv kd ke kf lw kh ki kj lx kl km kn ly kp kq kr bi translated">见解和要点</h1><p id="0348" class="pw-post-body-paragraph iw ix hh iy b iz ks jb jc jd kt jf jg jh ku jj jk jl kv jn jo jp kw jr js jt ha bi translated">这个项目真的很有趣。这是我第一次尝试无监督学习，这本身就是机器学习的一个非常有趣的子学科。</p><p id="18bf" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">从这个项目中有两个主要收获，第一个是从NMF生成的主题矩阵到一个全功能的推荐系统是多么容易。想出一种在余弦相似性中使用的矢量化内容的方法并不是一项简单的任务，如果不是为了主题建模的话，这项工作会更加费力。</p><p id="a1c9" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">第二点是主题建模作为一种降维技术是多么强大。很多时候，当建模很难为你的模型提出一个简洁的特性集，并且你经常会留下太多或太少的特性时，主题建模很容易为我们做到这一点。更有用的是，这些主题可以用作各种监督学习项目的特征，如回归或分类。</p></div><div class="ab cl ip iq go ir" role="separator"><span class="is bw bk it iu iv"/><span class="is bw bk it iu iv"/><span class="is bw bk it iu"/></div><div class="ha hb hc hd he"><p id="48eb" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">感谢您的阅读！如果你有任何问题或者只是想谈论机器学习、主题建模或者任何与数据科学相关的想法，你可以通过<a class="ae lo" href="http://www.linkedin.com/in/jcongard" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>联系我。</p><p id="84f5" class="pw-post-body-paragraph iw ix hh iy b iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ha bi translated">你也可以在我的<a class="ae lo" href="https://github.com/Jgardner91/NLP" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上看看我的项目。特别感谢<a class="ae lo" href="https://www.thisismetis.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="iy hi">梅蒂斯</strong> </a>为我提供了探索数据科学世界的工具:)</p></div></div>    
</body>
</html>