<html>
<head>
<title>Nonlinear Regression Tutorial with Radial Basis Functions</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">径向基函数非线性回归教程</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/nonlinear-regression-tutorial-with-radial-basis-functions-cdb7650104e7?source=collection_archive---------7-----------------------#2021-03-23">https://medium.com/analytics-vidhya/nonlinear-regression-tutorial-with-radial-basis-functions-cdb7650104e7?source=collection_archive---------7-----------------------#2021-03-23</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d7d3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看基函数回归，它允许我们对非线性关系建模。如果你熟悉常规线性回归，那么你应该知道目标是找到参数<em class="jd"> (α，β) </em>，这样我们就可以找到最佳拟合线<em class="jd"> y=αx+β。</em></p><p id="a12c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当执行非线性回归时，我们不再只是求解一条直线的方程。现在，我们的高级目标是求解一组基函数的最佳线性组合，使我们能够对非线性的东西进行建模。</p><p id="3c5e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">换句话说，假设我们有一些简单的数据集</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es je"><img src="../Images/42ef5f7fa5f783ed92f3a39aeb618feb.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*9g_BCd45BgDkhoQe3wnfQw.png"/></div></figure><p id="6842" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">现在，假设我们有一组基函数，它可以是我们想要的任何东西！对于RBF回归，我们将使用这样的高斯函数集合。</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jm"><img src="../Images/884e97bb00b3ecd148bbed79466485da.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/0*1q8K_njTCvKBJRGY.png"/></div><figcaption class="jn jo et er es jp jq bd b be z dx translated">半径基函数示例</figcaption></figure><p id="1fde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们想要的是，对于每个<em class="jd"> x∈ D </em>，有一个映射<em class="jd"> y=∑wₖb(x) </em>，其中<em class="jd"> k </em>是我们希望使用的基函数的数量(这是一个超参数)，<em class="jd"> b(x) </em>是我们的输入<em class="jd"> x </em>的一个变换(在我们的例子中，它将通过一个高斯函数传递…稍后将详细介绍)，并且<em class="jd"> w </em>将加权我们缩放每个RBF函数以产生多少最后，我们将求解一个<em class="jd"> w </em>，对于任何给定的<em class="jd"> x </em>，它可以输出<em class="jd"> y </em>作为我们的一组基函数的组合。</p><p id="ba7a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">对于基于RBF的回归，我们使用以下核来转换输入</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jr"><img src="../Images/8f650281d7150502dfec609a22b9be77.png" data-original-src="https://miro.medium.com/v2/resize:fit:382/format:webp/1*bf5SOXTYmfuGKPvclvf8lg.png"/></div></figure><p id="2724" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中<em class="jd"> cₖ </em>是高斯分布<em class="jd"> k </em>的中心/平均值，而<em class="jd"> σ </em>是所述高斯分布的标准偏差。这些都是我们模型的超参数。更具体地，超参数包括1)多少个基函数2)每个基函数的位置和3)每个高斯函数的方差。在我下面的例子中，我选择每个高斯的中心，使它们沿着我们的训练数据均匀分布，并任意选择标准偏差1。对于其他类型的问题，可能有更聪明的方法来选择这些参数。</p><p id="447a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">综上所述，我们要的是求解最优权重<em class="jd"> w </em>，这样我们就能最好的求解<em class="jd"> y=b(x) </em> ᵗ <em class="jd"> w </em>。我们可以用常规线性回归的方法来求解这些参数。回想一下，对于线性回归，这意味着求解参数<em class="jd"> w </em>需要我们做以下工作:</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es js"><img src="../Images/919150011ad0bc73a9da7fa2f8339710.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*dpOY92z-BzvGNZKl6RCCNQ.png"/></div></figure><p id="84f0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以对非线性回归做同样的事情。也就是说，</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es jt"><img src="../Images/25fe9fb1cfee51ed77c77423c2673dbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*xfxqh2fABZzsyOHW5s1wyQ.png"/></div></figure><p id="d4e9" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们剩下的是一个带有k个权重的权重向量，每个权重向量对应一个径向基函数。正如我们将看到的，我们可以将任何输入<em class="jd"> x </em>转换成输出<em class="jd">y’</em>作为我们基函数的线性组合。</p><p id="0b6c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">让我们看看在尝试将非线性RGB回归量拟合到正弦曲线时，使用不同数量的基函数得到的一些结果</p><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/3fee665da7dee23ed968946452130dbd.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*wKqBgudheWG_6bRN.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/789dd6e681915a811a5611dd179537a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*IHEnvRlLI28fliQJ.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/7cd6014450176afaaa41ca8bf7e0f7c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*mgZTOUEfDD0ABReU.png"/></div></figure><figure class="jf jg jh ji fd jj er es paragraph-image"><div class="er es ju"><img src="../Images/1ceff52657bbeb2b687f26460085f51e.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/format:webp/0*W88F4pQdXCLGce_a.png"/></div></figure><p id="79df" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">正如我们所看到的，当我们使用太少的基函数时，我们无法捕捉正弦曲线的本质。然而，对于太多的基函数，我们严重地过度拟合了数据。</p><p id="c833" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">来源:</p><ul class=""><li id="71bc" class="jv jw hi ih b ii ij im in iq jx iu jy iy jz jc ka kb kc kd bi translated"><a class="ae ke" href="http://www.cs.toronto.edu/~mbrubake/teaching/C11/Handouts/NonlinearRegression.pdf" rel="noopener ugc nofollow" target="_blank">http://www . cs . Toronto . edu/~ mbru bake/teaching/C11/讲义/非线性回归. pdf </a></li></ul></div></div>    
</body>
</html>