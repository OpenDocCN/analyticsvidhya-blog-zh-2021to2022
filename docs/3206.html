<html>
<head>
<title>Color Detection Using Clustering/ Superpixel</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用聚类/超像素的颜色检测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/color-detection-using-clustering-superpixel-ddf04521425a?source=collection_archive---------9-----------------------#2021-06-18">https://medium.com/analytics-vidhya/color-detection-using-clustering-superpixel-ddf04521425a?source=collection_archive---------9-----------------------#2021-06-18</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/6dae0f5133031a4d10c8d55e75ec7a87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t91rGAoqUtAepN4VxDTKVA.png"/></div></div></figure><blockquote class="ip iq ir"><p id="6d71" class="is it iu iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">据科学家兼摄影师罗杰·克拉克博士称，人眼的分辨率为576百万像素(T2)。当你把它与iPhone 7的1200万像素的T4相机相比时，这是一个巨大的数字。</p></blockquote><p id="b302" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">^这使得人眼对光高度敏感，使我们能够观察到视觉上的微小细节。此外，人类可以容易地检测颜色，因为他们从小就学习各种光强度与其相应颜色名称的映射。</p><p id="c76c" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">有趣的是，科学家们已经确定，在实验室中，我们可以看到大约1000种暗光，以及大约100种红绿和黄蓝。所以那大约是<strong class="iv hi">一千万种颜色</strong>就在那里<strong class="iv hi">。</strong>虽然人类对光线强度的微小差异很敏感，可以轻松地将其映射到黑色、白色、红色、绿色、黄色、蓝色、粉色、灰色、棕色、橙色和紫色等基本颜色，但在映射复杂色调时，如Burlywood、橄榄褐色、玫瑰色、玫瑰红、米色，甚至连标准人眼都难以分辨。</p><p id="b4ef" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated"><em class="iu">在这种情况下，计算机可以有效地检测甚至非常复杂的颜色深浅，从而有效地解决许多现实世界的挑战，如丰富电子商务目录，</em>医疗诊断、化妆品、涂料、纺织品和印刷材料的过程控制等。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><figure class="kc kd ke kf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kb"><img src="../Images/7f14d1b2829d284475bdb86bb7f1b61f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wtEvRZ5wsupHtJ6NDaaUmg.png"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">图片1:来源:<a class="ae kk" href="https://ai.stanford.edu/~syyeung/cvweb/tutorial1.html" rel="noopener ugc nofollow" target="_blank">斯坦福人工智能实验室</a></figcaption></figure><p id="ca16" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">注意:图像是按列和行排列的正方形像素(图片元素)的阵列。</p><p id="7868" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">特别是，图像被存储为三维NumPy数组(颜色格式为BGR/ RGB/ CMYK)。阵列的矩形形状对应于图像的形状。</p></div><div class="ab cl ju jv go jw" role="separator"><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz ka"/><span class="jx bw bk jy jz"/></div><div class="ha hb hc hd he"><p id="aa9f" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">为了理解使用OpenCV和Python的基于聚类的解决方案，让我们以印刷在手机外壳上的图像的颜色检测为例。对于任何电子商务平台，自动检测颜色的能力都是必不可少的，因为目录很大，无法手动注释。它还支持基于颜色的过滤器等功能，使产品搜索更加高效。</p><h2 id="831b" class="kl km hh bd kn ko kp kq kr ks kt ku kv jr kw kx ky js kz la lb jt lc ld le lf bi translated">第一步:获取产品图片的边框</h2><figure class="kc kd ke kf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lg"><img src="../Images/854940e09ebfbc9ebe50278f36a37c79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zqraSU1t3u2r2K0QoTfUcw.jpeg"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">图2:从原始图像中提取的手机外壳的边界。</figcaption></figure><pre class="kc kd ke kf fd lh li lj lk aw ll bi"><span id="b35d" class="kl km hh li b fi lm ln l lo lp"># Load required libraries and image<br/>import cv2<br/>import numpy as np<br/>from sklearn.cluster import KMeans<br/>from skimage.segmentation import slic</span><span id="7448" class="kl km hh li b fi lq ln l lo lp">kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))</span><span id="796b" class="kl km hh li b fi lq ln l lo lp">image_path = "sample_image.jpg" # path of the image</span><span id="42f8" class="kl km hh li b fi lq ln l lo lp">img = cv2.imread(image_path)<br/>h, w, e = img.shape</span><span id="bc32" class="kl km hh li b fi lq ln l lo lp"># GrayScale image<br/>grayscale_img = cv2.imread(file, 0)</span></pre><p id="c12c" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">可能会出现图像包含多个产品，或者给定产品图像未正确对齐的情况。因此，我们可以启发式地提取图像中的感兴趣区域。下面的代码片段提取了产品区域，并假设焦点中的产品将覆盖至少50%的图像。</p><pre class="kc kd ke kf fd lh li lj lk aw ll bi"><span id="9c72" class="kl km hh li b fi lm ln l lo lp">cropped_product = img.copy()</span><span id="80fc" class="kl km hh li b fi lq ln l lo lp"># Erosion and contour detection<br/>border = cv2.dilate(grayscale_img, None, iterations=1)<br/>border = border - cv2.erode(border, None)<br/>contours, hierarchy = cv2.findContours(border,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)</span><span id="3447" class="kl km hh li b fi lq ln l lo lp">for c in contours:<br/>    rect = cv2.boundingRect(c)<br/>    area = cv2.contourArea(c)<br/>    <br/>    # Consider countors covering at least 50% of the whole image<br/>    if area &gt; 0.5 * h * w:<br/>         cropped_product = cropped_product[   <br/>             rect[1]:rect[1]+rect[3],<br/>             rect[0]:rect[0]+rect[2]<br/>         ]<br/>         # Run code to identify colors</span></pre><h2 id="3368" class="kl km hh bd kn ko kp kq kr ks kt ku kv jr kw kx ky js kz la lb jt lc ld le lf bi translated">步骤2:执行聚类以将相似的像素隔离在一起</h2><p id="d1ac" class="pw-post-body-paragraph is it hh iv b iw lr iy iz ja ls jc jd jr lt jg jh js lu jk jl jt lv jo jp jq ha bi translated">为了对像素强度进行聚类，我们使用了Kmeans聚类，其中可以根据图像集中可能出现的最大可能颜色来定义最佳聚类数。</p><pre class="kc kd ke kf fd lh li lj lk aw ll bi"><span id="1ce1" class="kl km hh li b fi lm ln l lo lp">cropped_product = cropped_product.reshape((cropped_product.shape[0] * cropped_product.shape[1], 3))</span><span id="3d4e" class="kl km hh li b fi lq ln l lo lp"># cluster the pixel intensities<br/>clt = KMeans(n_clusters = 15)<br/>clt.fit(cropped_product)</span></pre><p id="00cf" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated">我们还可以使用种子(通过能量驱动采样提取的超像素)或SLIC(简单线性迭代聚类)等超像素算法来对图像平面中具有共同特征(如颜色或接近度)的像素进行分组。根据使用情况和性能，我们可能会决定使用Kmeans聚类或超像素来分离图像中的颜色。</p><pre class="kc kd ke kf fd lh li lj lk aw ll bi"><span id="e48f" class="kl km hh li b fi lm ln l lo lp">seeds = cv2.ximgproc.createSuperpixelSEEDS(w, h, e, 100, 4, 2, 5)<br/>seeds.iterate(cv2.cvtColor(img, cv2.COLOR_BGR2HSV), 10)</span><span id="42e3" class="kl km hh li b fi lq ln l lo lp"># retrieve the segmentation result<br/>labels = seeds.getLabels()<br/>mask = seeds.getLabelContourMask(False)</span></pre><figure class="kc kd ke kf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lw"><img src="../Images/f16442795046393041e166011e88e0b3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UEZWivKVMa3g8pukzz0gIw.jpeg"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">图4:从OpenCV::createSuperpixelSEEDS生成的图像遮罩；播种分离的像素</figcaption></figure><h2 id="d457" class="kl km hh bd kn ko kp kq kr ks kt ku kv jr kw kx ky js kz la lb jt lc ld le lf bi translated">步骤3:建立像素值和颜色名称的映射</h2><p id="afcc" class="pw-post-body-paragraph is it hh iv b iw lr iy iz ja ls jc jd jr lt jg jh js lu jk jl jt lv jo jp jq ha bi translated">就像人类学习不同光强度与其相应颜色名称的映射一样，我们必须创建一个RGB像素值与其颜色名称的映射，如下图所示。该映射用于根据最接近聚类质心的像素的RGB值指定颜色名称。一个颜色名称最多可以映射1670万种RGB值组合，但根据所需的颜色精度和颜色名称的可用性，我们只能映射几百种。</p><figure class="kc kd ke kf fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/b4eb210751369380fa651b22ed7fe99f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1396/format:webp/1*kmeCcaqJ3nkElbMH9QcJMw.jpeg"/></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">图RGB值和颜色名称的映射。</figcaption></figure><h2 id="7a8c" class="kl km hh bd kn ko kp kq kr ks kt ku kv jr kw kx ky js kz la lb jt lc ld le lf bi translated">步骤4:根据可用的映射为集群指定颜色名称</h2><p id="0278" class="pw-post-body-paragraph is it hh iv b iw lr iy iz ja ls jc jd jr lt jg jh js lu jk jl jt lv jo jp jq ha bi translated">一旦我们对图像进行了聚类，下一个逻辑步骤就是识别与该聚类最接近的相应颜色名称。为此，我们确定最接近聚类质心的映射中可用的RGB值。</p><pre class="kc kd ke kf fd lh li lj lk aw ll bi"><span id="cd9b" class="kl km hh li b fi lm ln l lo lp"># grab the number of different clusters and create a histogram<br/># based on the number of pixels assigned to each cluster<br/>numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)<br/>(hist, _) = np.histogram(clt.labels_, bins = numLabels)</span><span id="86ed" class="kl km hh li b fi lq ln l lo lp"># normalize the histogram<br/>hist = hist.astype("float")<br/>hist /= hist.sum()</span><span id="41a4" class="kl km hh li b fi lq ln l lo lp"># representing the number of pixels labeled to each color<br/>centroids = clt.cluster_centers_<br/>color_values = centroids.astype("uint8").tolist()</span><span id="9da2" class="kl km hh li b fi lq ln l lo lp">colours = {}<br/>for colour_val, hist_val in zip(color_values, hist):</span><span id="3c0e" class="kl km hh li b fi lq ln l lo lp">    b1,g1,r1 = colour_val<br/>    min_dis = 9999999<br/>    for k in range(0,645):</span><span id="c716" class="kl km hh li b fi lq ln l lo lp">        r2,g2,b2 = color_label[k]<br/>        dist = (b1-b2)*(b1-b2) + (g1-g2)*(g1-g2) + (r1-r2)*(r1-r2)</span><span id="df8d" class="kl km hh li b fi lq ln l lo lp">        if dist &lt; min_dis:<br/>            min_dis = dist<br/>            index = k</span><span id="8bc8" class="kl km hh li b fi lq ln l lo lp">    if color_dict[index] not in colours:   <br/>        colours[color_dict[index]] = round(hist_val * 100, 4)</span></pre><p id="db4c" class="pw-post-body-paragraph is it hh iv b iw ix iy iz ja jb jc jd jr jf jg jh js jj jk jl jt jn jo jp jq ha bi translated"><strong class="iv hi">颜色检测输出:</strong></p><figure class="kc kd ke kf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ly"><img src="../Images/288754267a8b7cbc50c1291e0ace37e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1148/format:webp/1*52XZ-mGSEb_ebKNi8SJehQ.jpeg"/></div></div><figcaption class="kg kh et er es ki kj bd b be z dx translated">图5:图示1)检测到的颜色直方图2)颜色名称和百分比。</figcaption></figure><pre class="kc kd ke kf fd lh li lj lk aw ll bi"><span id="831c" class="kl km hh li b fi lm ln l lo lp"><em class="iu">Output dictionary; <br/>colours = {<br/>  'Sapphire Blur': 52.20,<br/>  'Bubblegum Pink': 20.12,<br/>  'White': 10.67,<br/>  'Voilet Red': 0.79,<br/>  'Grey': 0.83,<br/>  'Black': 1.41,<br/>  'Cadet Blue': 1.52,<br/>  'Midnight Blue': 1.02,<br/>  'Bright Red': 1.15,<br/>  'Light Pink': 2.24<br/>}</em></span></pre></div></div>    
</body>
</html>