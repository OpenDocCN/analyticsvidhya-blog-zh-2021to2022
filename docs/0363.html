<html>
<head>
<title>A Noob’s Guide to Decision Trees</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Noob决策树指南</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/a-noobs-guide-to-decision-trees-171252c5b653?source=collection_archive---------20-----------------------#2021-01-13">https://medium.com/analytics-vidhya/a-noobs-guide-to-decision-trees-171252c5b653?source=collection_archive---------20-----------------------#2021-01-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="d0e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你好，我的伙伴们。今天我为决策树编辑了一个博客，这个概念乍看起来像是一团乱麻，但实际上要简单得多。在这里，我们将掌握决策树的思想和工作原理，以及它是如何让你的生活变得更简单的。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es jc"><img src="../Images/198f3cd241377f82168367b1dd98ba4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/0*3AK84eVYvmsRWlzd.jpg"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">来源:better.sg</figcaption></figure><h1 id="5620" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">介绍</h1><blockquote class="km"><p id="c201" class="kn ko hh bd kp kq kr ks kt ku kv jb dx translated">它是一种用于分类和回归问题的监督学习算法。它使用其树状表示来直观地显示给定问题时可以做出的所有决策。</p></blockquote><p id="2c4b" class="pw-post-body-paragraph ie if hh ig b ih kw ij ik il kx in io ip ky ir is it kz iv iw ix la iz ja jb ha bi translated">用非常简单的术语来说，决策树是一棵代表一个问题所有可能解决方案的树。举个例子，</p><p id="7160" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设我们有一组鸟、鱼、猫和狗。我们想把所有这些动物归入各自的类别。那么我们可以问什么问题来回答这个问题呢？</p><p id="09fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们可以先问，“动物有皮毛吗？”。如果这是真的，那么猫和狗就属于那一类。没有皮毛的动物将会有一个包含鸟类和鱼类的独立群体。</p><p id="ef37" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，让我们把注意力集中在有毛的动物身上。我们现在问，“那种动物会叫吗？”。如果是的话，它就被归类为狗。如果不是，那它就是一只猫。现在，这一组已经分类，我们进入下一组。</p><p id="8d1b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果动物没有皮毛，我们可以问，“那种动物会飞吗？”如果是的话，那它就是一只鸟，否则它就是一条鱼。这个决策可以用下面给出的树的形式来描述:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es lb"><img src="../Images/739eee0aab90a43d0daf1647de909523.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DFT6N3aAbBWAsTWnxh82GQ.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">来源:wiki.tum.de</figcaption></figure><h2 id="efbe" class="lg jp hh bd jq lh li lj ju lk ll lm jy ip ln lo kc it lp lq kg ix lr ls kk lt bi translated">决策树有两种类型:</h2><ul class=""><li id="b87a" class="lu lv hh ig b ih lw il lx ip ly it lz ix ma jb mb mc md me bi translated"><strong class="ig hi">分类变量决策树:</strong>目标值是分类值。例如，如果我们有一个用于诊断糖尿病的数据集，那么诊断的目标值是“是”或“否”。</li><li id="46f1" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated"><strong class="ig hi">连续变量决策树:</strong>目标值是一个像回归中的连续值。例如，根据地下室、一楼、二楼、浴室数量、卧室数量等的平方英尺预测房价。</li></ul><h1 id="2884" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">应用程序</h1><ul class=""><li id="fa9b" class="lu lv hh ig b ih lw il lx ip ly it lz ix ma jb mb mc md me bi translated">它用于多变量系统中的数据挖掘和分类。</li><li id="5739" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated">用于开发目标变量的预测算法。</li><li id="1cd3" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated">用于人口统计数据，以寻找潜在客户。</li><li id="d949" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated">它帮助你规划出不同的选择，并根据不同的情况选择最好的一个。</li></ul><h1 id="b18e" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">基本术语</h1><ul class=""><li id="ed0f" class="lu lv hh ig b ih lw il lx ip ly it lz ix ma jb mb mc md me bi translated"><strong class="ig hi">根节点:</strong>这是我们开始做决定的地方。它代表整个数据集，然后基于所选问题，我们对其进行拆分。</li><li id="e3b7" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated">叶节点:这是我们进入死胡同的地方。也可以说，我们不能使用这样的节点获得任何新的信息，因此，不能被分割。</li><li id="7d56" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated"><strong class="ig hi">修剪:</strong>删除树中不需要的节点的过程。这是分裂的反义词。</li><li id="9f57" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated"><strong class="ig hi">拆分:</strong>是基于某种问题或条件对我们的数据集进行划分的过程。</li><li id="499c" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated"><strong class="ig hi">父/子节点:</strong>被划分的节点是父节点，子节点是从父节点开始的子节点。</li><li id="efc9" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated"><strong class="ig hi">分支或子树:</strong>分割树/节点的结果。</li></ul><h1 id="2c27" class="jo jp hh bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl bi translated">它是如何工作的？</h1><p id="44f3" class="pw-post-body-paragraph ie if hh ig b ih lw ij ik il lx in io ip mk ir is it ml iv iw ix mm iz ja jb ha bi translated"><em class="mn">我们将为使用熵作为度量之一的决策树实现</em> <strong class="ig hi"> <em class="mn"> ID3算法</em> </strong> <em class="mn">。</em> <strong class="ig hi"> <em class="mn">我们将讨论涉及分类目标变量的决策树的度量。</em>T15】</strong></p><p id="d202" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">作为一个决策树，它需要问很多问题。但真正的任务是找到需要问的问题的顺序。</p><p id="72c9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">如何选择一个问题，让我们更容易做出下一步的决定？</strong>为此，我们必须引入某些<strong class="ig hi"> <em class="mn">指标</em> </strong>，通过这些指标我们可以评估我们的问题并对它们进行排序。</p><p id="e0fc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是要理解这些术语，我们需要理解一些更基本的术语:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mo"><img src="../Images/dc4ac4cd224e6c7998b9f2bd1ae813b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/0*Zma5Ea_Smz00ywe6.gif"/></div></figure><ul class=""><li id="2061" class="lu lv hh ig b ih ii il im ip mp it mq ix mr jb mb mc md me bi translated"><strong class="ig hi">杂质:</strong>它是节点标签同质性的度量。让我们以之前定义的同一个组为例。如果我们给这些动物中的任何一种随机贴上标签(比如猫)(比如鱼)<strong class="ig hi">“错误分类的概率有多大？”。这个问题定义了杂质的概念。</strong></li><li id="1c46" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated"><strong class="ig hi">熵:</strong>它是杂质的量度，定义了数据集中的随机性。如果数据集的一部分属于一个类别，而另一部分属于另一个类别，那么我们可以说我们的数据集是随机的，因为我们无法据此做出任何决定。举个例子，</li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es ms"><img src="../Images/e521f7af58f0ae8e27ea2559b6aa5220.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VBCRudaHMqvFmf01.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">来源:www。dataversity.net</figcaption></figure><p id="b4ed" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上图中，我们可以看到，与第二幅图像(纯净)相比，将第一幅图像(不纯净)分组的难度更大。它可以计算如下:</p><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mt"><img src="../Images/faf168621fec106132303a39a07ddb70.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/0*iHWSSXpBsms9tB71.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">p是标签为I的项目的概率，从i=1到c，其中c是组的数量</figcaption></figure><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mu"><img src="../Images/badd9c5ab7806ed6d9ff47856e59a83a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1208/format:webp/0*Cah6QBus9zll1h91.png"/></div></figure><p id="3c2b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如果你想让它更有诗意，那么熵意味着在蒸馏水中加盐，然后将它们分组。它被溶解了，所以它本身不会有什么不同。你得努力把他们分开！！！</p><p id="3376" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">既然同义词库和我的繁琐已经结束，我们将解释基于属性选择问题的度量标准，</p><ul class=""><li id="1390" class="lu lv hh ig b ih ii il im ip mp it mq ix mr jb mb mc md me bi translated"><strong class="ig hi">基尼指数</strong>:衡量杂质的指标，其值介于0和1之间。其计算方法如下:</li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es mv"><img src="../Images/778b4283d5ffbfc4700e50dbf6a97476.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*Ct5iiyX9_hBH90Zo.png"/></div></figure><p id="43a5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">其中，pi是对象被分类到组中的概率。基尼指数只对二元分割有效。基尼系数越高，同质性越高。此指标用于决策树的CART(分类和回归树)实施。</p><ul class=""><li id="318e" class="lu lv hh ig b ih ii il im ip mp it mq ix mr jb mb mc md me bi translated">信息增益(Information Gain):它给出了一个属性能给出多少关于类/组的信息的度量。它指定了使用属性可以减少多少熵。</li></ul><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mw"><img src="../Images/fbcc88b149ab2ba8b66f08ab5f20fbb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*nCRe7C6Ell3773n-.png"/></div></div></figure><p id="bdcb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我们沿着决策树往下走时，我们希望从高熵(非常不确定)到低熵(分类变得简单)。我们还可以直观地看到，如果儿童熵的加权平均值较小，那么，信息增益一定很高，即我们已经获得了许多新的信息来容易地对项目进行分类。</p><p id="c0e7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">也就是说，首先选择具有最高信息增益的属性，并且当我们沿着决策树向下时，重复相同的过程。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="er es mx"><img src="../Images/54097d698c1f39e7a4729e6c8b8973fc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gmjiRIAiNpbgtXuN.png"/></div></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">(来源:towardsdatascience.com)从高熵到低熵。</figcaption></figure><blockquote class="my mz na"><p id="c4e8" class="ie if mn ig b ih ii ij ik il im in io nb iq ir is nc iu iv iw nd iy iz ja jb ha bi translated">基尼系数比熵和信息增益更受欢迎，因为它不像熵和信息增益那样需要大量的计算。</p></blockquote><h2 id="f778" class="lg jp hh bd jq lh li lj ju lk ll lm jy ip ln lo kc it lp lq kg ix lr ls kk lt bi translated">现在我们将看到实施决策树的步骤:</h2><figure class="jd je jf jg fd jh er es paragraph-image"><div class="er es ne"><img src="../Images/62d46a0116a37469c24a3e0b06aad836.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/0*e57puoJopcq_aNZ4.png"/></div><figcaption class="jk jl et er es jm jn bd b be z dx translated">我们这里的目标变量是“Return”。(来源:blog.quantinsti.com)</figcaption></figure><ol class=""><li id="5a61" class="lu lv hh ig b ih ii il im ip mp it mq ix mr jb nf mc md me bi translated">对于数据集的每个属性，我们将从中发现信息增益。例如，对于属性“过去趋势”，这里有两种类型的值，即正值和负值。</li><li id="b6f4" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb nf mc md me bi translated">对于每一种类型，我们根据目标变量找出它们各自的分类。对于“过去趋势”中的正类型，我们有4个“上升”和2个“下降”。对于负类型，我们有“向下”的所有值。所以，负型是同质的。</li><li id="7eed" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb nf mc md me bi translated">对于每种类型，我们将找到熵，然后找到它们的加权平均值。在这个例子中，对于正值，我们的熵将是:(-4/6)log₂(4/6)+(-2/6)log₂(2/6)=(-2/3)log₂(2/3)+(-1/3)log₂(1/3)=0.3899+0.5283=0.9182；同样，对于负值，熵=0</li><li id="b77a" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb nf mc md me bi translated">现在，我们发现它的加权平均值是:(6/10)*(0.9182) + (4/10)*0 = 0.5509</li><li id="6bc6" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb nf mc md me bi translated">找到这个加权平均值后，我们从母体的熵中减去它。然而，对于根节点，我们发现数据集的熵。这是通过找到目标变量中每种类型值的概率，然后对这些概率中的每一个应用熵公式来找到的。</li><li id="d030" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb nf mc md me bi translated">这里，我们的目标变量“回报”有4个“上涨”和6个“下跌”。</li><li id="0806" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb nf mc md me bi translated">应用熵公式，(-4/10)*log₂(4/10)+(-6/10)*log₂(6/10)= 0.9709</li><li id="ad5e" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb nf mc md me bi translated">从数据集的熵中减去加权平均，我们得到0.42，这是从“过去的趋势”中获得的信息。</li><li id="e27c" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb nf mc md me bi translated">对所有其他属性执行步骤(1)到(4 ),然后我们选择具有最大信息增益的属性作为根。</li><li id="705b" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb nf mc md me bi translated">对于“未平仓利息”，(-4/6)log₂(4/6)+(-2/6)log₂(2/6)= 0.9182熵对于“低”类型的值，对于“高”类型的值，我们有1。加权平均值是(6/10)*0.9182 + (4/10)*1 = 0.9509。获得的信息将是0.02。对于“交易价值”，我们得到的信息= 0.9709-0.6896=0.2813。</li><li id="56b6" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb nf mc md me bi translated">因此，我们选择“过去的趋势”作为我们的根，并相应地分割我们的数据集。我们对“过去趋势”的子节点执行所有这些步骤，并构建一个树，直到我们不能从节点中获得任何信息，或者我们已经达到我们的最大指定深度。</li></ol><h2 id="747b" class="lg jp hh bd jq lh li lj ju lk ll lm jy ip ln lo kc it lp lq kg ix lr ls kk lt bi translated">优势:</h2><ul class=""><li id="5335" class="lu lv hh ig b ih lw il lx ip ly it lz ix ma jb mb mc md me bi translated">该算法不需要对数据集进行预处理。离群值对其结果没有太大影响。</li><li id="fe3e" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated">适用于大型数据集。</li><li id="8753" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated">能够处理数字和分类数据。</li><li id="3563" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated">很容易解释它的决策规则。</li></ul><h2 id="45a8" class="lg jp hh bd jq lh li lj ju lk ll lm jy ip ln lo kc it lp lq kg ix lr ls kk lt bi translated">缺点:</h2><ul class=""><li id="30fc" class="lu lv hh ig b ih lw il lx ip ly it lz ix ma jb mb mc md me bi translated">它们倾向于过度拟合，因此不能很好地概括整个数据集。我们使用修剪来避免这种情况。</li><li id="4b42" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated">数据集中的一个小变化可能导致树中的大变化，从而导致最终预测的大变化。</li><li id="38c8" class="lu lv hh ig b ih mf il mg ip mh it mi ix mj jb mb mc md me bi translated">它只能在训练数据中响应变量的最小和最大范围内进行预测。</li></ul><p id="b8b9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">所以，我们以此结束我们的课程。我希望你已经更接近理解决策树了。感谢您的阅读，祝您愉快。</p></div></div>    
</body>
</html>