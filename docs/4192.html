<html>
<head>
<title>ANOMALY DETECTION IN CARDIO DATASET USING DEEP LEARNING TECHNIQUE: AUTOENCODER</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用深度学习技术的心脏数据集中的异常检测:自动编码器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/anomaly-detection-in-cardio-dataset-using-deep-learning-technique-autoencoder-fd24ca9e5c69?source=collection_archive---------1-----------------------#2021-09-07">https://medium.com/analytics-vidhya/anomaly-detection-in-cardio-dataset-using-deep-learning-technique-autoencoder-fd24ca9e5c69?source=collection_archive---------1-----------------------#2021-09-07</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="d3e8" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自过去许多年以来，自动检测并正确地将异常事物分类为异常一直是一个挑战。当涉及到高维数据时，它变得更加复杂，因为传统的机器学习方法无法捕捉不平衡数据中的复杂结构。这就是异常检测的深度学习方法可以用于该任务的地方。在所有深度学习技术中，我们使用Autoencoder进行异常检测。</p><p id="ac45" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，在这篇博客中，我们将了解以下内容:</p><ul class=""><li id="710c" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">什么是Autoencoder？</li><li id="5f68" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">自动编码器的应用</li><li id="9704" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">自动编码器的架构。</li><li id="b0a6" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">不同类型的自动编码器</li><li id="7310" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">简单的自动编码器</li><li id="009a" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">稀疏自动编码器</li><li id="fda5" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">深度自动编码器</li><li id="8438" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">卷积自动编码器</li><li id="176f" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">降噪自动编码器</li><li id="ec3c" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">可变自动编码器</li><li id="8dcc" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">自动编码器的优势</li><li id="b72d" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">自动编码器如何用于异常检测？</li><li id="fbd8" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">使用张量流的心脏数据集中的异常检测。</li></ul><h2 id="a970" class="jr js hi bd jt ju jv jw jx jy jz ka kb iq kc kd ke iu kf kg kh iy ki kj kk kl bi translated">自动编码器的应用:</h2><ul class=""><li id="052c" class="jd je hi ih b ii km im kn iq ko iu kp iy kq jc ji jj jk jl bi translated"><strong class="ih hj">异常检测:</strong>自动编码器以一种特殊的方式使用神经网络的属性来完成一些训练网络学习正常行为的有效方法。当异常数据点到达时，自动编码器不能很好地编码它。它学会了表现这些数据中不存在的模式。当试图从其紧凑表示中重建原始数据时，重建将不会类似于原始数据。从而有助于在异常发生时检测到它们。这种过程的目标是试图从编码数据中重建原始输入，这在构建异常检测模块中是至关重要的。</li><li id="685b" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><strong class="ih hj">降维</strong>:可以学习非线性变换，具有非线性激活函数和多层。自动编码器的目标是学习给定数据的压缩分布式表示，我们可以使用它来降低维数。</li><li id="9a81" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><strong class="ih hj">特征提取:</strong>这里，在减少构造错误的过程中，自动编码器的编码部分有助于学习输入数据中存在的重要隐藏特征。由此，模型生成一组新的原始特征的组合。</li><li id="0560" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><strong class="ih hj">序列到序列预测:</strong>基于LSTMs的自动编码器使用可以在机器翻译过程中捕获句子的时间结构的编码器-解码器模型。</li><li id="16fd" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><strong class="ih hj">推荐系统:</strong>我们可以使用深度自动编码器来了解用户的偏好，以推荐电影、书籍或其他物品。以下是使用autoencoder构建推荐系统的步骤:</li><li id="0514" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">输入数据是基于兴趣的相似用户的聚类。</li><li id="102d" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">用户的兴趣通过观看的视频、每个视频的观看时间等来分类，</li><li id="e410" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">可以使用来自上述过滤器的相似种类的数据来创建聚类。</li><li id="840d" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">编码器部分将捕捉用户的兴趣</li><li id="d4f0" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">解码器部分将试图将兴趣投射到两个部分:现有的看不见的内容</li><li id="d730" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">来自内容创作者的新内容</li></ul><h2 id="77d5" class="jr js hi bd jt ju jv jw jx jy jz ka kb iq kc kd ke iu kf kg kh iy ki kj kk kl bi translated">什么是AUTOENCODER？</h2><p id="9409" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">自动编码器是神经网络，能够发现高维数据的低维表示。由此，它应该能够从输出中重建输入。</p><p id="f961" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自动编码器架构有3个主要部分，如下所示:</p><ul class=""><li id="05f9" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated"><strong class="ih hj">编码器，</strong>将高维数据集的维度降低到低维。</li><li id="5fe7" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><strong class="ih hj">代码</strong>，包含输入解码器的输入的简化表示。</li><li id="93c6" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated"><strong class="ih hj">解码器</strong>，将低维数据扩展为高维数据。</li></ul><p id="1808" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里，压缩和解压缩函数是</p><ul class=""><li id="33d9" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">特定于数据，这意味着模型将能够压缩它所训练的那些数据。模型的这一特性有助于压缩不平衡数据集的多数类。</li><li id="d436" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">有损，这意味着解压缩后的输出与原始输入相比质量下降。</li><li id="1895" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">从示例中自动学习，这意味着它可以更好地处理特定类型的输入。</li></ul><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/bce250acbf2afa32d4d0d3e0292ba8d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tg1tS4MuoNil9x3m5GSeAQ.png"/></div></div></figure><h2 id="23cc" class="jr js hi bd jt ju jv jw jx jy jz ka kb iq kc kd ke iu kf kg kh iy ki kj kk kl bi translated">对建筑的理解</h2><p id="478c" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">编码器部分是特征提取函数f，它根据输入xi计算特征向量h (xi)。我们定义h(xi)=f(xi)，其中h(xi)是特征表示。</p><p id="ef1d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">解码器部分是恢复函数g，它从特征空间h(xi)重建输入空间xi，使得xi~=g(h(xi))</p><p id="fad5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自动编码器正试图学习一个近似值，使xi与xi相似。这意味着，它试图获得尽可能低的重建误差E (xi，xi~)，该误差测量xi和xi~之间的差异。因此得到了下面的方程E (xi，xi~)=||xi-xi~||</p><p id="ff2e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自动编码器主要是作为多层感知器(MLP)开发的。编码器和解码器最常用的形式是保持共线性后跟随非线性的变换:</p><p id="682b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">f (xi)=sf(b+W)</p><p id="097f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">g(xi)=gf(c+W~)</p><p id="ab2f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中sf和sg是编码器和解码器激活函数，例如sigmoid和tanh</p><p id="7dbf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">b和c是编码器和解码器偏置向量，</p><p id="1710" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">W和W~是编码器和解码器权重矩阵。</p><h2 id="ddbf" class="jr js hi bd jt ju jv jw jx jy jz ka kb iq kc kd ke iu kf kg kh iy ki kj kk kl bi translated">自动编码器的类型:</h2><p id="708a" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">简单的自动编码器:</p><p id="8539" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">编码器网络接收输入，并将其转换为更小、更密集的表示，也称为输入的潜在表示。然后，解码器网络可以使用它尽可能将其转换回原始输入。当我们的输入具有许多特征时，生成压缩表示有助于压缩训练样本的输入。因此，当神经网络遍历所有训练数据并微调所有隐藏层节点的权重时，权重将真正代表我们通常看到的输入类型。因此，如果我们尝试输入一些其他类型的数据，例如带有噪声的数据，自动编码器网络将能够检测到噪声。那么当产生输出时，它至少去除了一部分噪声。这真是太棒了，因为现在我们有可能从数据中去除噪声。</p><p id="fb04" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们需要创建一个完全连接的神经层作为编码器和解码器模型，用优化器、损失和评估指标编译模型。损失函数通常是输出和输入之间的均方误差或交叉熵，我们称之为“重建损失”。它惩罚了产生不同于输入的输出的网络。然后，我们需要用测试数据来拟合我们的模型。</p><p id="b1bc" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建简单自动编码器的步骤</p><p id="d22d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们将构建一个简单的全连接神经层作为编码器和解码器来读取图像中的数字</p><ul class=""><li id="b5c2" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">让我们定义编码表示的大小。</li><li id="2d6a" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">encoding _ dim = 32 #假设输入大小= 882浮点数，压缩因子=27.6</li><li id="58f8" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">input_img=Input(shape=(882，)#这是我们的输入占位符</li><li id="532c" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">encoded=Dense(encoding_dim，activation = ' relu ')(input _ img)# " encoded "是输入的编码表示</li><li id="e9b6" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">decoded=Dense(882，activation = ' sigmoid ')(encoded)# ' decoded '是输入的有损重建</li><li id="b46d" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">autoencoder=model(input_img，decoded)#该模型将输入映射到其重建</li><li id="13f1" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">让我们创建一个单独的编码器模型</li><li id="35bf" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">encoder=model(input_img，encoded)#这个模型将输入映射到它的编码表示</li><li id="0e5d" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">让我们创建一个单独的解码模型</li><li id="9688" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">encoded _ Input = Input(shape =(encoding _ dim，))#为编码(32维)输入创建占位符</li><li id="6862" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">decoded _ layer = auto encoder . layers[-1]#检索自动编码器模型的最后一层</li><li id="6ae0" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">decoder=model(encoded_input，decoder _ layer(encoded _ input))#创建解码器模型</li><li id="875f" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">现在，让我们训练我们的自动编码器来重建数字</li><li id="389b" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">auto encoder . compile(optimizer = ' ada '，loss='binary_crossentropy ')</li><li id="5d2e" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">准备训练数据:x_train和测试数据:x_test</li><li id="9a1e" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">让我们训练50个纪元的自动编码器</li><li id="c12f" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">autoencoder.fit(x_train，x_train，epochs=50，batch_size=250，shuffle=True，validation_data=(x_test，x_test))</li><li id="db7e" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">现在，我们将尝试可视化重建的输入和编码表示</li><li id="29ac" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">encoded _ img = encoder . predict(x _ test)</li><li id="5121" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">decoded _ img = decoded . predict(encoded _ img)</li></ul><p id="3fff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">稀疏自动编码器</p><p id="90b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">稀疏自动编码器是其训练标准包括<strong class="ih hj"> </strong>稀疏惩罚的自动编码器。我们将通过惩罚隐藏层的激活来构造我们的损失函数。结果，当单个样本被馈送到网络中时，只有少数节点被鼓励激活。通过确保autoencoder实际学习潜在的表示而不是输入数据中的冗余信息，较少的节点被激活。</p><p id="b8a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">值得注意的是，激活的已训练模型的单个节点是数据相关的，不同的输入将导致通过网络激活不同的节点。</p><p id="8743" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这个事实的一个结果是，我们允许我们的网络使单个隐藏层节点对输入数据的特定属性敏感。欠完整自动编码器将对每个观测值使用整个网络，而稀疏自动编码器将根据输入数据选择性地激活网络区域。因此，我们限制了网络记忆输入数据的能力，而没有限制网络从数据中提取要素的能力。这允许我们分别考虑网络的潜在状态表示和正则化。然后，我们可以根据给定的数据上下文选择有意义的潜在状态表示，同时通过稀疏性约束施加正则化。我们可以通过两种主要方式来施加这种稀疏性约束；两者都涉及测量每个训练批次的隐藏层激活，并向损失函数添加一些项，以便惩罚过度激活。这些术语是</p><p id="5f5c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj"> L1正则化:</strong>对于L1正则化，除了w=0时，梯度不是1就是-1，这意味着不管w的值是多少，L1正则化总是以相同的步长将w移向零，当w=0时，梯度变为零，不再进行更新。</p><p id="fdde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">KL-散度:</strong> Kullback-Leibler (KL)散度罚项量化了一个概率分布与另一个概率分布的差异程度。</p><p id="d36f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">两个分布Q和P之间的KL散度表示为KL(P || Q)</p><p id="ae64" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中“||”运算符表示“<em class="lg">发散</em>或与q的Ps发散。</p><p id="8f25" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">KL(P | | Q)=—sum X in X P(X)* log(Q(X)/P(X))描述了P中每个事件的概率的负和乘以Q中事件的概率对P中事件的概率的对数。</p><p id="c27e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">KL(P | | Q)= sum X in X P(X)* log(P(X)/Q(X))描绘了P中每个事件的概率的正和乘以P中事件的概率对Q中事件的概率的对数。</p><p id="ca89" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当来自P的事件的概率很大，但是来自Q的相同事件的概率很小时，就有很大的差异。当来自P的概率很小，来自Q的概率很大时，也有很大的散度，但没有第一种情况大。</p><p id="6399" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在上面的例子中，隐藏层正在学习降维(PCA)的近似值。压缩表示的另一种方式是通过向我们的<code class="du lh li lj lk b">Dense</code>层添加<code class="du lh li lj lk b">activity_regularizer</code>来对隐藏表示的活动添加稀疏性约束:</p><p id="0f85" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建稀疏自动编码器的步骤</p><ul class=""><li id="3fb3" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">encoded=Dense(encoding_dim，activation='relu '，activation _ regulator = regulators . L1(10e-5))(input _ img)</li></ul><p id="6cf2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">卷积自动编码器:</p><p id="96e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">每当我们的输入是图像时，使用卷积神经网络(convnets或CNN)作为编码器和解码器是有意义的。Autoencoder对重建原始观察足够敏感，但对训练数据不够敏感，因此模型学习可概括的编码和解码。换句话说，概化模型会稍微破坏输入数据。但是仍然将未被破坏的数据作为我们的目标输出。使用这种方法，我们的模型不能简单地开发记忆训练数据的映射，因为我们的输入和目标输出不再相同。相反，该模型学习用于将输入数据映射到低维流形的矢量场。如果这个流形准确地描述了自然数据，我们就有效地“抵消”了增加的噪声。</p><p id="be6a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建卷积自动编码器的步骤</p><ul class=""><li id="8bc5" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">编码器由Conv2D层和MaxPooling2D层组成。</li><li id="282f" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">x=Conv2D(20，(3，3)，activation='relu '，padding='same') (input_img)</li><li id="8b62" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">x=MaxPooling2D((2，2)，padding='same') (x) #SAME将填充应用于输入图像，以便输入图像完全被过滤器和指定步幅覆盖，其中输出将与输入相同。所以，这被称为相同的填充</li><li id="d5ab" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">x=Conv2D(10，(3，3)，activation='relu '，padding='same') (input_img)</li><li id="c420" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">x=MaxPooling2D((2，2)，padding='same') (x)</li><li id="ec5a" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">x=Conv2D(10，(3，3)，activation='relu '，padding='same') (input_img)</li><li id="a56b" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">encoded=MaxPooling2D((2，2)，padding='same') (x)</li><li id="72f7" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">解码器由Conv2D层和UpSampling2D层组成。</li></ul><p id="3622" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可变自动编码器</p><p id="77c7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在变型自动编码器中，来自一些已知概率分布的编码可以被解码以产生合理的输出，即使它们不是实际图像的编码。如果我们从这个分布中采样点，我们可以生成新的输入数据样本:VAE是一个“生成模型”。</p><p id="e998" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">首先，编码器网络将输入样本x转换成潜在空间中的两个参数:z_mean和z_log_sigma。然后，我们通过z = z _ mean+exp(z _ log _ sigma)* epsilon从假设生成数据的潜在正态分布中随机采样相似点z，其中epsilon是随机正态张量。最后，解码器网络将这些潜在空间点映射回原始输入数据。模型的参数通过两个损失函数来训练:</p><ul class=""><li id="c9b6" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">重建损失迫使解码样本匹配初始输入。</li><li id="3215" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">学习的潜在分布和先前分布之间的KL散度，作为正则化项。</li></ul><p id="5676" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建变分编码器的步骤</p><ul class=""><li id="dc71" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">首先，在编码器模型中，我们必须将输入映射到我们的潜在分布参数。</li><li id="b237" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">x =输入(批处理形状=(批处理大小，原始尺寸))</li><li id="37dd" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">h=Dense(intermediate_dim，activation='relu')(x)</li><li id="08d6" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">z _ mean =密集(潜在尺寸)(h)</li><li id="ff75" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">z _ log _ sigma = Dense(latent _ dim)(h)</li><li id="0a58" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">现在，我们可以使用这些参数来获得潜在空间中新的相似点的样本。</li><li id="f886" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">现在，我们可以将这些采样的潜在点映射回重建的输入。</li><li id="c2b0" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">现在，我们可以实例化3个模型:</li><li id="9517" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">将输入映射到重建的端到端自动编码器</li><li id="0ca8" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">将输入映射到潜在空间的编码器。</li><li id="8356" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">可以在潜在空间中取点并将输出相应的重构样本的生成器。</li><li id="d4fe" class="jd je hi ih b ii jm im jn iq jo iu jp iy jq jc ji jj jk jl bi translated">在此之后，我们需要使用端到端模型进行训练，然后用测试数据进行拟合。</li></ul><p id="64b0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">去噪自动编码器:</strong></p><p id="bd48" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">去噪自动编码器会在输入图像中添加一些噪声，并学习如何消除这些噪声。因此，它试图避免在不了解数据特征的情况下将输入复制到输出。这些自动编码器在训练以恢复原始的未失真输入时，采用部分损坏的输入。然后学习用于将输入数据映射到描述自然数据的较低维度的矢量场，以抵消添加的噪声。通过这种方式，编码器将提取最重要的特征，并学习数据的更鲁棒的表示。</p><p id="ce44" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">创建变分编码器的步骤</p><ul class=""><li id="069b" class="jd je hi ih b ii ij im in iq jf iu jg iy jh jc ji jj jk jl bi translated">模型创建步骤类似于卷积自动编码器。唯一的区别是，我们将生成合成的噪声数字:我们只是应用高斯噪声矩阵，并在0和1之间裁剪图像。</li></ul><h2 id="fa6e" class="jr js hi bd jt ju jv jw jx jy jz ka kb iq kc kd ke iu kf kg kh iy ki kj kk kl bi translated">使用案例:</h2><p id="768f" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">为心脏生育描记术(Cardio)数据集构建异常检测模型</p><p id="5bd5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据集:</strong>在这里，我们将使用UCI机器学习库中可用的心育图(Cardio)数据集建立一个模型，该数据集由胎儿心率(FHR)和子宫收缩(UC)的测量值组成。产科专家对心脏分娩图上的特征进行了分类，对所有特征进行了评估，并将每个病例分为正常、可疑和病理性NSP。对于异常值检测，他们将正常类称为内部类，而将病理(异常值)类称为异常值。我们已经丢弃了可疑类。数据集存在于以下位置:</p><p id="ec79" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ll" href="http://odds.cs.stonybrook.edu/cardiotocogrpahy-dataset/" rel="noopener ugc nofollow" target="_blank">心脏分娩数据集</a></p><p id="b97e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集显示在这里:</p><p id="26a1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">以下是一个很好的异常检测数据集存储库:</p><p id="d413" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ll" href="http://odds.cs.stonybrook.edu/" rel="noopener ugc nofollow" target="_blank">离群点检测数据集(ODDS) </a></p><p id="9935" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">自动处理了2126张胎心监护图。三位产科专家对测量的相应诊断特征和ctg进行分类，并给他们每个人分配一个分类标签。已经根据形态学模式(A、B、c……)和胎儿状态(N、S、P)进行了分类。因此，数据集可以用于10类或3类实验，我们已经考虑了3类实验来构建我们的模型。</p><p id="9db5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">数据集是从UCI机器学习知识库收集的，呈现在这里:</p><p id="1ec5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">数据字典:</strong></p><p id="3cf7" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">属性信息:</p><p id="b8bf" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">LB —心率基线(每分钟心跳数) <br/> AC —每秒加速度数<br/> FM —每秒胎动数<br/> UC —每秒子宫收缩数<br/> DL —每秒轻度减速数<br/> DS —每秒重度减速数<br/> DP —每秒持续减速数<br/> ASTV —短期变异性异常的时间百分比<br/> MSTV —短期变异性的平均值<br/> ALTV —短期变异性异常的时间百分比 长期可变性<br/> MLTV —长期可变性的均值/平均值<br/>宽度— FHR直方图的宽度<br/>最小值—FHR直方图的最小值<br/>最大值—FHR直方图的最大值<br/> Nmax —直方图峰值的数量<br/> Nzeros —直方图零点的数量<br/>模式—直方图模式<br/>均值—直方图均值<br/>中值—直方图中值<br/>方差—直方图方差<br/>趋势—直方图趋势<br/>类—FHR模式类代码 s =嫌疑人；p =病理性</p><p id="1ace" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在这里，我们认为NSP=1是内部值，NSP=3是外部值</p><p id="0db0" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">内联程序的总数=1658</p><p id="e47e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">异常值总数=178</p><p id="6a22" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">使用自动编码器的异常检测</strong></p><p id="cad4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤1:导入所有需要的库来构建模型</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="abc1" class="jr js hi lk b fi lq lr l ls lt">import tensorflow as tf</span><span id="6bb9" class="jr js hi lk b fi lu lr l ls lt">from tensorflow import keras</span><span id="3ae0" class="jr js hi lk b fi lu lr l ls lt">from tensorflow.keras import optimizers</span><span id="bbdf" class="jr js hi lk b fi lu lr l ls lt">from tensorflow.keras.models import Sequential, Model</span><span id="b2f7" class="jr js hi lk b fi lu lr l ls lt">from tensorflow.keras.layers import Dense, Input, Dropout, Embedding, LSTM</span><span id="9455" class="jr js hi lk b fi lu lr l ls lt">from tensorflow.keras.optimizers import RMSprop, Adam, Nadam</span><span id="b245" class="jr js hi lk b fi lu lr l ls lt">from tensorflow.keras.preprocessing import sequence</span><span id="eb60" class="jr js hi lk b fi lu lr l ls lt">from tensorflow.keras.callbacks import TensorBoard</span><span id="911e" class="jr js hi lk b fi lu lr l ls lt">import sklearn</span><span id="9c4d" class="jr js hi lk b fi lu lr l ls lt">from sklearn.preprocessing import StandardScaler</span><span id="71eb" class="jr js hi lk b fi lu lr l ls lt">from sklearn.preprocessing import MinMaxScaler</span><span id="8fc2" class="jr js hi lk b fi lu lr l ls lt">from sklearn.model_selection import train_test_split</span><span id="00ef" class="jr js hi lk b fi lu lr l ls lt">from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report</span><span id="dd87" class="jr js hi lk b fi lu lr l ls lt">import seaborn as sns</span><span id="5fb3" class="jr js hi lk b fi lu lr l ls lt">import pandas as pd</span><span id="361e" class="jr js hi lk b fi lu lr l ls lt">import numpy as np</span><span id="693e" class="jr js hi lk b fi lu lr l ls lt">import matplotlib.pyplot as plt</span><span id="fbff" class="jr js hi lk b fi lu lr l ls lt">import matplotlib.gridspec as gridspec</span><span id="9a42" class="jr js hi lk b fi lu lr l ls lt">​</span></pre><p id="8919" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第二步:第二步:在Google Colab中上传数据集。如果我们使用Jupyter Notebook，那么我们可以使用read_csv()从本地系统直接访问数据集。</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="1ddb" class="jr js hi lk b fi lq lr l ls lt">from google.colab import files</span><span id="c951" class="jr js hi lk b fi lu lr l ls lt">uploaded=files.upload()</span><span id="44a7" class="jr js hi lk b fi lu lr l ls lt">import io</span><span id="4f27" class="jr js hi lk b fi lu lr l ls lt">ctg = pd.read_csv(io.BytesIO(uploaded['CTG.csv']))</span></pre><p id="9582" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤3:获取关于数据集的更多信息。</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="c15c" class="jr js hi lk b fi lq lr l ls lt">ctg.head(10) # To access first 10 rows in the dataset</span><span id="06db" class="jr js hi lk b fi lu lr l ls lt">list(ctg) # To know the features present in the dataset</span><span id="a8f4" class="jr js hi lk b fi lu lr l ls lt">ctg.shape # To know the size of the dataset</span><span id="1a5e" class="jr js hi lk b fi lu lr l ls lt">ctg.describe() # To get the descriptive statstics for each feature</span></pre><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lv"><img src="../Images/64552924302eb40baa3b32e38d556b50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*_47eHbVovrHecaZo"/></div></div></figure><p id="1089" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤4:用目标变量:NPS的模式填充缺少的值</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="c58a" class="jr js hi lk b fi lq lr l ls lt">ctg['NSP'].fillna(ctg['NSP'].mode()[0], inplace=True)</span></pre><p id="4fc2" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第五步:获得目标变量“NSP”不同值的数据分布。数据集中的其余特征是预测因素。</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="2de6" class="jr js hi lk b fi lq lr l ls lt">count_classes = pd.value_counts(ctg['NSP'], sort = True)</span><span id="d0f7" class="jr js hi lk b fi lu lr l ls lt">count_classes.plot(kind = 'bar', rot=0)</span><span id="b9b4" class="jr js hi lk b fi lu lr l ls lt">plt.title("NSP Distribution")</span><span id="820a" class="jr js hi lk b fi lu lr l ls lt">plt.xlabel("NSP")</span><span id="c428" class="jr js hi lk b fi lu lr l ls lt">plt.ylabel("Frequency")</span></pre><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lw"><img src="../Images/dc1f570622d6a1e92f3d095ae6315f4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1078/0*EtbCOoyiNtLu3ROm"/></div></figure><p id="2c3e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤6:丢弃所有NSP=2的数据点，因为这不是我们感兴趣的。</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="9211" class="jr js hi lk b fi lq lr l ls lt">ctg=ctg.dropna()</span><span id="f813" class="jr js hi lk b fi lu lr l ls lt">ctg=ctg.drop(ctg[ctg['NSP']==2].index)</span><span id="5e9d" class="jr js hi lk b fi lu lr l ls lt">ctg.shape</span></pre><p id="f823" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">(1831, 23)</p><p id="d2ad" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤7:计算“正常”和“异常”类的数据点数量</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="b7d5" class="jr js hi lk b fi lq lr l ls lt">pd.value_counts(ctg['NSP'])</span></pre><p id="98e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.0 1655 3.0 176姓名:NSP，数据类型:int64</p><p id="c8d5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第八步:拆分训练，测试数据。</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="757e" class="jr js hi lk b fi lq lr l ls lt">from sklearn.model_selection import train_test_split</span><span id="e18e" class="jr js hi lk b fi lu lr l ls lt">train_x, test_x = train_test_split(ctg, test_size=0.3, random_state=42)</span><span id="7922" class="jr js hi lk b fi lu lr l ls lt">train_x = train_x[train_x.NSP == 1] #where normal transactions</span><span id="4d83" class="jr js hi lk b fi lu lr l ls lt">train_x = train_x.drop(['NSP'], axis=1) #drop the class column</span><span id="7f12" class="jr js hi lk b fi lu lr l ls lt">test_y = test_x['NSP'] #save the class column for the test set</span><span id="5c7b" class="jr js hi lk b fi lu lr l ls lt">test_x = test_x.drop(['NSP'], axis=1) #drop the class column</span><span id="6eef" class="jr js hi lk b fi lu lr l ls lt">train_x = train_x.values #transform to ndarray</span><span id="b473" class="jr js hi lk b fi lu lr l ls lt">test_x = test_x.values</span><span id="0bee" class="jr js hi lk b fi lu lr l ls lt">train_x.shape, test_x.shape</span></pre><p id="b183" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi">((1155, 22), (550, 22))</p><p id="5d78" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤9:用input_dim=1(对于2类分类器)，encoding_dim=12建立模型。激活函数=编码层的tanh和解码层的sigmoid。</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="ebcd" class="jr js hi lk b fi lq lr l ls lt">encoding_dim=12</span><span id="8388" class="jr js hi lk b fi lu lr l ls lt">input_dim=train_x.shape[1]</span><span id="1253" class="jr js hi lk b fi lu lr l ls lt">inputArray=Input(shape=(input_dim,))</span><span id="0bff" class="jr js hi lk b fi lu lr l ls lt">encoded=Dense(encoding_dim, activation='tanh')(inputArray)</span><span id="ea98" class="jr js hi lk b fi lu lr l ls lt">decoded=Dense(input_dim, activation='softmax')(encoded)</span><span id="ab48" class="jr js hi lk b fi lu lr l ls lt">autoencoder=Model(inputArray, decoded)</span><span id="8938" class="jr js hi lk b fi lu lr l ls lt">autoencoder.summary()</span></pre><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lx"><img src="../Images/e9e670fc12e33fbe1c5279a69386930e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1328/0*BkXRD030cfguqUfC"/></div></figure><p id="e065" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤10:用optimizer=ADAM，loss=binary-crossentropy，metrics=accuracy编译模型。</p><p id="7bc1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤11:用batch_size=32和epochs=20来拟合模型。</p><p id="e333" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">第12步:评估模型。</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="3810" class="jr js hi lk b fi lq lr l ls lt">autoencoder.compile(optimizer=ADAM,</span><span id="ca53" class="jr js hi lk b fi lu lr l ls lt">loss='binary_crossentropy',</span><span id="c542" class="jr js hi lk b fi lu lr l ls lt">metrics=['accuracy'])</span><span id="53a9" class="jr js hi lk b fi lu lr l ls lt">batch_size=32</span><span id="3cec" class="jr js hi lk b fi lu lr l ls lt">epochs=20</span><span id="a336" class="jr js hi lk b fi lu lr l ls lt">history=autoencoder.fit(train_x,train_x,batch_size=batch_size,epochs=epochs,verbose=1,shuffle=True,</span><span id="e5b8" class="jr js hi lk b fi lu lr l ls lt">validation_data=(test_x,test_x))</span><span id="aa23" class="jr js hi lk b fi lu lr l ls lt">score=autoencoder.evaluate(test_x, test_x, verbose=1)</span><span id="cd50" class="jr js hi lk b fi lu lr l ls lt">print('Test loss:', score[0])</span><span id="8845" class="jr js hi lk b fi lu lr l ls lt">print('Accuracy:', score[1])</span></pre><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lv"><img src="../Images/05fe008b3fe5456d9c4016ee38ced17f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1cJVNI0ZLl2legfD"/></div></div></figure><p id="3444" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤13:重构误差和真实类</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="5b96" class="jr js hi lk b fi lq lr l ls lt">test_x_predictions = autoencoder.predict(test_x)</span><span id="a862" class="jr js hi lk b fi lu lr l ls lt">mse = np.mean(np.power(test_x - test_x_predictions, 2), axis=1)</span><span id="0119" class="jr js hi lk b fi lu lr l ls lt">error_df = pd.DataFrame({'Reconstruction_error': mse,</span><span id="b306" class="jr js hi lk b fi lu lr l ls lt">'True_class': test_y})</span><span id="9c01" class="jr js hi lk b fi lu lr l ls lt">error_df.describe()</span></pre><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es ly"><img src="../Images/5b703075b7c5de896664df544acb6b49.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/0*ZvB-PUpd_40RM8V0"/></div></figure><p id="6b9c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤14:绘制混淆矩阵</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="9ede" class="jr js hi lk b fi lq lr l ls lt">from sklearn.metrics import confusion_matrix</span><span id="fcdd" class="jr js hi lk b fi lu lr l ls lt">import seaborn as sns</span><span id="be0e" class="jr js hi lk b fi lu lr l ls lt">LABELS = ["class1","class3"]</span><span id="5543" class="jr js hi lk b fi lu lr l ls lt">threshold_fixed = 4000</span><span id="8766" class="jr js hi lk b fi lu lr l ls lt">pred_y = [1.0 if e &gt; threshold_fixed else 3.0 for e in error_df.Reconstruction_error.values]</span><span id="263c" class="jr js hi lk b fi lu lr l ls lt">conf_matrix = confusion_matrix(error_df.True_class, pred_y)</span><span id="c3ac" class="jr js hi lk b fi lu lr l ls lt">plt.figure(figsize=(12, 12))</span><span id="d5e0" class="jr js hi lk b fi lu lr l ls lt">sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt="d");</span><span id="f1fd" class="jr js hi lk b fi lu lr l ls lt">plt.title("Confusion matrix")</span><span id="a1a5" class="jr js hi lk b fi lu lr l ls lt">plt.ylabel('True class')</span><span id="ced0" class="jr js hi lk b fi lu lr l ls lt">plt.xlabel('Predicted class')</span><span id="99e2" class="jr js hi lk b fi lu lr l ls lt">plt.show()</span></pre><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lz"><img src="../Images/1653b53ee104bdf9a826def3b3dfd95a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*wuvmYKnTMmSKb_Qb"/></div></div></figure><p id="99e6" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">步骤15:打印分类报告</p><pre class="kv kw kx ky fd lm lk ln lo aw lp bi"><span id="2d76" class="jr js hi lk b fi lq lr l ls lt">print(classification_report(test_y,pred_y))</span></pre><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ma"><img src="../Images/96721072e13fa6f6632763292fd4189e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1294/0*N581M6ISqtQHjius"/></div></div></figure><h2 id="7e86" class="jr js hi bd jt ju jv jw jx jy jz ka kb iq kc kd ke iu kf kg kh iy ki kj kk kl bi translated">结论:</h2><p id="cff8" class="pw-post-body-paragraph if ig hi ih b ii km ik il im kn io ip iq kr is it iu ks iw ix iy kt ja jb jc hb bi translated">在这篇博客中，我们建立了一个自动编码器模型来检测心脏数据中的异常，它有两个分类器:正常和异常。在我们的下一篇博客中，我们将学习一种构建异常检测模型的新技术。</p><p id="06a5" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ll" href="https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf" rel="noopener ugc nofollow" target="_blank">https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf</a></p><p id="2b7b" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><a class="ae ll" href="https://www.quora.com/What-is-the-Kullback-Leibler-KL-divergence" rel="noopener ugc nofollow" target="_blank">https://www . quora . com/What-the-kull back-lei bler-KL-divergence</a></p></div></div>    
</body>
</html>