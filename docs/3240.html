<html>
<head>
<title>Simple CNN using NumPy Part VI (Putting it all together)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">简单的CNN使用NumPy第六部分(把所有的放在一起)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/simple-cnn-using-numpy-part-vi-putting-it-all-together-b4210cd14487?source=collection_archive---------13-----------------------#2021-06-20">https://medium.com/analytics-vidhya/simple-cnn-using-numpy-part-vi-putting-it-all-together-b4210cd14487?source=collection_archive---------13-----------------------#2021-06-20</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><figure class="hg hh ez fb hi hj er es paragraph-image"><div class="er es hf"><img src="../Images/69c29457efab1e78ebcba171c589b704.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/format:webp/1*noL5Bt0f-OHu-9D4RmKIzw.png"/></div></figure><div class=""/><p id="0380" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">在之前的帖子中，我们讨论了以下内容</p><ol class=""><li id="59b6" class="jj jk ho in b io ip is it iw jl ja jm je jn ji jo jp jq jr bi translated"><a class="ae js" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-i-introduction-data-processing-b6652615604d">CNN简介</a></li><li id="105f" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><a class="ae js" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-ii-convolution-operation-b8c5a02b0844">卷积运算</a></li><li id="6a47" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><a class="ae js" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-iii-relu-max-pooling-softmax-c03a3377eaf2"> ReLU功能，最大池功能&amp; Softmax功能。</a></li><li id="154e" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><a class="ae js" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-iv-back-propagation-through-fully-connected-layers-c5035d678307">通过全连接层的反向传播</a></li><li id="e453" class="jj jk ho in b io jt is ju iw jv ja jw je jx ji jo jp jq jr bi translated"><a class="ae js" rel="noopener" href="/@PAdhokshaja/simple-cnn-using-numpy-part-v-back-propagation-through-max-pool-layer-convolutional-filter-7c434a7addd4">通过卷积输出层、最大池层的反向传播&amp;卷积滤波器</a></li></ol><h1 id="75c6" class="jy jz ho bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">最终代码</h1><ol class=""><li id="a4bb" class="jj jk ho in b io kw is kx iw ky ja kz je la ji jo jp jq jr bi translated">获取培训和测试数据</li></ol><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="a934" class="lk jz ho lg b fi ll lm l ln lo"><em class="lp">'''</em><br/><em class="lp">Input functionality</em><br/><em class="lp">'''</em><br/><br/>import pandas as pd<br/>import numpy as np<br/>data = pd.read_csv('../input/Kannada-MNIST/train.csv')<br/><br/>data = data.sample(frac=1)<br/><em class="lp">#print(int(data.shape[0]/2))</em><br/><br/>data_first_half = data.head(30000)<br/>data_second_half = data.tail(30000)<br/><br/><em class="lp">### get 100 data points </em><br/><em class="lp">### making sure that the data  is balanced</em><br/><br/>tmp = pd.DataFrame()<br/>for label <strong class="lg hp">in</strong> range(10):<br/>    if label==0:<br/>        tmp = data_first_half[data_first_half['label']==label].head(600)<br/>    else:<br/>        temp = data_first_half[data_first_half['label']==label].head(600)<br/>        tmp = pd.concat([tmp,temp])<br/>data_balanced = tmp<br/><br/>tmp = pd.DataFrame()<br/>for label <strong class="lg hp">in</strong> range(10):<br/>    if label==0:<br/>        tmp = data_second_half[data_second_half['label']==label].head(100)<br/>    else:<br/>        temp = data_second_half[data_second_half['label']==label].head(100)<br/>        tmp = pd.concat([tmp,temp])<br/>data_test = tmp</span></pre><p id="9e19" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">2.重塑列车和测试</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="72ca" class="lk jz ho lg b fi ll lm l ln lo"><em class="lp">### Convert flattened input train data to image data</em><br/>data_balanced = data_balanced.sample(frac=1)<br/>data_array = np.zeros((data_balanced.shape[0],1,28,28))<br/>image_data = np.array(data_balanced.drop('label',axis=1))<br/><br/>for i <strong class="lg hp">in</strong> range(data_balanced.shape[0]):<br/>    single_image = image_data[i,:].reshape(1,-1)<br/>    single_image = single_image.reshape(-1,28)<br/>    data_array[i,0,:,:] = single_image<br/><br/>data_array = data_array/255.<br/><br/><em class="lp">### Convert flattened input test data to image data</em><br/>data_test = data_test.sample(frac=1)<br/>data_test_input = np.zeros((data_test.shape[0],1,28,28))<br/>image_data = np.array(data_test.drop('label',axis=1))<br/><br/>for i <strong class="lg hp">in</strong> range(data_test.shape[0]):<br/>    single_image = image_data[i,:].reshape(1,-1)<br/>    single_image = single_image.reshape(-1,28)<br/>    data_test_input[i,0,:,:] = single_image<br/>data_test_input = data_test_input/255.</span></pre><p id="9b6a" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">3.一个热编码标签</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="31e5" class="lk jz ho lg b fi ll lm l ln lo"><em class="lp">### Convert Labels to one hot encoding</em><br/><br/>label = data_balanced['label'].tolist()<br/>one_hot_encoding = np.zeros((data_balanced.shape[0],10))<br/>for i <strong class="lg hp">in</strong> range(data_balanced.shape[0]):<br/>    position = label[i]<br/>    one_hot_encoding[i,position] = 1</span></pre><p id="dd68" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">4.Im2col函数定义</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="2544" class="lk jz ho lg b fi ll lm l ln lo">def im2col(X,conv1, stride, pad):<br/>    <em class="lp">"""</em><br/><em class="lp">        Transforms our input image into a matrix.</em><br/><br/><em class="lp">        Parameters:</em><br/><em class="lp">        - X: input image.</em><br/><em class="lp">        - HF: filter height.</em><br/><em class="lp">        - WF: filter width.</em><br/><em class="lp">        - stride: stride value.</em><br/><em class="lp">        - pad: padding value.</em><br/><br/><em class="lp">        Returns:</em><br/><em class="lp">        -cols: output matrix.</em><br/><em class="lp">    """</em><br/>    <em class="lp"># Padding</em><br/>    X_padded = np.pad(X, ((0,0), (0,0), (pad, pad), (pad, pad)), mode='constant')<br/>    X = X_padded<br/>    new_height = int((X.shape[2]+(2*pad)-(conv1.shape[2]))/stride)+1<br/>    new_width =  int((X.shape[3]+(2*pad)-(conv1.shape[3]))/stride)+1<br/>    im2col_vector = np.zeros((X.shape[1]*conv1.shape[2]*conv1.shape[3],new_width*new_height*X.shape[0]))<br/>    c = 0<br/>    for position <strong class="lg hp">in</strong> range(X.shape[0]):<br/><br/>        image_position = X[position,:,:,:]<br/>        for height <strong class="lg hp">in</strong> range(0,image_position.shape[1],stride):<br/>            image_rectangle = image_position[:,height:height+conv1.shape[2],:]<br/>            if image_rectangle.shape[1]&lt;conv1.shape[2]:<br/>                continue<br/>            else:<br/>                for width <strong class="lg hp">in</strong> range(0,image_rectangle.shape[2],stride):<br/>                    image_square = image_rectangle[:,:,width:width+conv1.shape[3]]<br/>                    if image_square.shape[2]&lt;conv1.shape[3]:<br/>                        continue<br/>                    else:<br/>                        im2col_vector[:,c:c+1]=image_square.reshape(-1,1)<br/>                        c = c+1         <br/>            <br/>    return(im2col_vector)</span></pre><p id="d4ac" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">5.最大池功能</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="6658" class="lk jz ho lg b fi ll lm l ln lo">def maxpool_multiple(input_image,stride=2):<br/>    input_width = input_image.shape[3]<br/>    input_height = input_image.shape[2]<br/>    filter_width = 2<br/>    filter_height = 2<br/>    <br/>    output_width = int((input_width-filter_width)/stride)+1<br/>    output_height = int((input_height-filter_height)/stride)+1<br/>    <br/>    output_image = np.zeros((input_image.shape[0],input_image.shape[1],output_width,output_height))<br/>    for i <strong class="lg hp">in</strong> range(output_image.shape[0]):<br/>        output_image[i:i+1,:,:,:] = maxpool(input_image[i:i+1,:,:,:],stride=2)<br/>    return output_image<br/><br/>def maxpool(input_image,stride=2):<br/>    input_width = input_image.shape[3]<br/>    input_height = input_image.shape[2]<br/>    filter_width = 2<br/>    filter_height = 2<br/>    n_channels = input_image.shape[1]<br/>    num_images = input_image.shape[0] <br/>    <br/>    output_width = int((input_width-filter_width)/stride)+1<br/>    output_height = int((input_height-filter_height)/stride)+1<br/>    output = np.zeros((n_channels,output_width*output_height))<br/>    c=0<br/>    for height <strong class="lg hp">in</strong> range(0,input_height,stride):<br/>        if height+filter_height&lt;=input_height:<br/>            image_rectangle = input_image[0,:,height:height+filter_height,:]<br/>            for width <strong class="lg hp">in</strong> range(0,input_width,stride):<br/>                if width+filter_width&lt;=input_width:<br/>                    image_square = image_rectangle[:,:,width:width+filter_width]<br/>                    image_flatten = image_square.reshape(-1,1)<br/><em class="lp">#                     print(image_flatten)</em><br/><em class="lp">#                     print('----')</em><br/>                    output[:,c:c+1] = np.array([float(max(i)) for i <strong class="lg hp">in</strong> np.split(image_flatten,n_channels)]).reshape(-1,1)<br/>                    c+=1<br/>   <br/>            <br/>    final_output = np.array(np.hsplit(output,1)).reshape((1,n_channels,output_height,output_width))<br/>        <br/>    return final_output</span></pre><p id="c977" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">6.ReLU函数、Softmax函数&amp;存储最大池索引的函数</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="c8ab" class="lk jz ho lg b fi ll lm l ln lo">def ReLU(x):<br/>    return (x&gt;0)*x</span><span id="55ed" class="lk jz ho lg b fi lq lm l ln lo"><br/>def softmax(x):<br/>    <br/>    x_exp = np.exp(x-np.max(x))<br/>    <br/>    return x_exp/np.sum(x_exp,axis=0)</span><span id="7b11" class="lk jz ho lg b fi lq lm l ln lo">def dReLU(x):<br/>    return (x&gt;0)*1.0</span><span id="4f81" class="lk jz ho lg b fi lq lm l ln lo">def maxpool_indices(input_image,stride=2,filter_height=2, filter_width=2):<br/>    positional_vector = []<br/><br/>    for channel <strong class="lg hp">in</strong> range(input_image.shape[1]):<br/>        x = -1<br/><br/>        chosen_image_channel = input_image[:,channel,:,:]<br/>        for height <strong class="lg hp">in</strong> range(0,chosen_image_channel.shape[1],stride):<br/>            if height+stride&lt;=chosen_image_channel.shape[1]:<br/>                image_rectangle = chosen_image_channel[:,height:height+filter_height,:]<br/>                x = x+1<br/>                y = -1<br/>                <em class="lp">#print('Value of x:',x)</em><br/>                for width <strong class="lg hp">in</strong> range(0,image_rectangle.shape[2],stride):<br/>                    if width+stride&lt;= image_rectangle.shape[2]:<br/>                        y = y+1<br/>                        <em class="lp">#print('Value of y:',y)</em><br/>                        image_square = image_rectangle[:,:,width:width+filter_width]<br/>                        <br/>                        a,b,c = np.unravel_index(image_square.argmax(),image_square.shape)<br/><br/>                        <br/>                        positional_vector.append([0,channel,int(b)+height,int(c)+width,0,channel,x,y])<br/>    return positional_vector<br/><br/>def maxpool_indices_multiple(input_image,stride=2,filter_height=2, filter_width=2):<br/>    positional_vector =[]<br/>    for i <strong class="lg hp">in</strong> range(input_image.shape[0]):<br/>        positional_vector.append(maxpool_indices(input_image[i:i+1,:,:,:],stride=2,filter_height=2,filter_width=2))<br/>    return positional_vector<br/></span></pre><p id="2365" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">7.为反向传播重塑误差层</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="70cb" class="lk jz ho lg b fi ll lm l ln lo">def error_layer_reshape(error_layer):<br/>    test_array = error_layer<br/>    test_array_new = np.zeros((test_array.shape[1],test_array.shape[0]*test_array.shape[2]*test_array.shape[3]))<br/>    for i <strong class="lg hp">in</strong> range(test_array_new.shape[0]):<br/>        test_array_new[i:i+1,:] = test_array[:,i:i+1,:,:].ravel()<br/>    return test_array_new</span></pre><p id="5ac5" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">8.培训和测试</p><pre class="lb lc ld le fd lf lg lh li aw lj bi"><span id="6a57" class="lk jz ho lg b fi ll lm l ln lo"><em class="lp">'''Simple Architecture for Digit Recognition</em><br/><br/><em class="lp">1) (1,1,28,28)</em><br/><em class="lp">2) Convolution filter (2,1,5,5)</em><br/><em class="lp">3) (Max Pool 2x2)</em><br/><em class="lp">4) Fc layer (1,288)</em><br/><em class="lp">5)Second FC (1,60)</em><br/><em class="lp">6) Output Layer(1,10)</em><br/><br/><em class="lp">'''</em><br/><br/>epochs = 50<br/>batch_size = 128<br/>batches = int(data_array.shape[0]/batch_size)<br/><br/>conv1 = np.random.randn(2,1,5,5)*np.sqrt(1./5.)<br/>W1 = np.random.rand(60,288)/np.sqrt(288)<br/>B0 = np.zeros((60,1))/np.sqrt(288)<br/>W2 = np.random.rand(10,60)/np.sqrt(60)<br/>B1 = np.zeros((10,1))/np.sqrt(60)<br/>learning_rate = 0.001<br/><em class="lp">## Implementing Adam Optimizer</em><br/><br/>beta1 = 0.9<br/>beta2 = 0.995<br/>momentum_w1 = 0<br/>momentum_w2 = 0<br/>momentum_b0 = 0<br/>momentum_b1 = 0<br/>momentum_conv1 = 0<br/>velocity_w1 = 0<br/>velocity_w2 = 0<br/>velocity_b0 = 0<br/>velocity_b1 = 0<br/>velocity_conv1 = 0<br/>for epoch_num <strong class="lg hp">in</strong> range(epochs):<br/>    <br/>    <em class="lp">'''</em><br/><em class="lp">    Choose chunks of data based on batch size  </em><br/><em class="lp">    '''</em><br/>    i = 0<br/>    permutation = np.random.permutation(data_array.shape[0])<br/>    data_array_train = data_array[permutation,:,:,:]<br/>    one_hot_encoding_train = one_hot_encoding[permutation,:]<br/>    for i <strong class="lg hp">in</strong> range(batches):<br/>        start = i*batch_size<br/>        end = min(start+batch_size,data_array.shape[0]-1)<br/>        X_batch = data_array_train[start:end,:,:,:]<br/>        y_batch = one_hot_encoding_train[start:end,:].T<br/>        <em class="lp">### First Convolutional Layer</em><br/>        <em class="lp">#X_conv = conv2dim2col_multiple(input_image=X_batch,conv_filter=conv1,stride=1)</em><br/>        X_im2col = im2col(X=X_batch,conv1=conv1,stride=1,pad=0)<br/>        conv1_reshaped = conv1.reshape(conv1.shape[0],-1)<br/>        X_conv = conv1_reshaped@X_im2col<br/>        X_conv = np.array(np.hsplit(X_conv,X_batch.shape[0])).reshape((X_batch.shape[0],conv1.shape[0],24,24))<br/>        <br/>        <br/>        <em class="lp">### Pass through ReLU</em><br/>        <br/>        X_relu = ReLU(X_conv)<br/>        <br/>        <em class="lp">### Pass Through Max Pool</em><br/>        <br/>        X_maxpool = maxpool_multiple(X_relu,stride=2)<br/>        <br/>        <br/>        <br/>        <br/>        <br/>        <em class="lp">### Get the indices of maxpool</em><br/>        <br/>        max_indices = maxpool_indices_multiple(X_relu,stride=2,filter_height=2, filter_width=2)<br/>        <br/>        <em class="lp">### Flatten the maxpool output</em><br/>        input_shape = X_maxpool.shape[0]<br/>        num_channels = X_maxpool.shape[1]<br/>        input_width = X_maxpool.shape[2]<br/>        input_height = X_maxpool.shape[3]<br/>        X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))<br/>        for image <strong class="lg hp">in</strong> range(input_shape):<br/>            X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].ravel().reshape(-1,1)<br/>        <br/>        <br/>        <br/>        <em class="lp">### Getting into fully connected layers</em><br/>        fc1 = ReLU(W1@X_maxpool_flatten+B0)<br/>        final_fc = softmax(W2@fc1+B1)<br/><em class="lp">#         print('Sum of Final FC')</em><br/><em class="lp">#         print(np.sum(final_fc))</em><br/><em class="lp">#         print(final_fc)</em><br/><em class="lp">#         break</em><br/><em class="lp">#         print('Loss:')</em><br/><em class="lp">#         print(cross_entropy(y=y_batch,y_hat=final_fc))</em><br/><br/>        <em class="lp">### Calculating Loss Through Backprop</em><br/>        <br/>        delta_2 = (final_fc-y_batch)<br/>        delta_1 = np.multiply(W2.T@delta_2,dReLU(W1@X_maxpool_flatten+B0))<br/>        delta_0 = np.multiply(W1.T@delta_1,1.0)<br/>        <br/>        dW1 = delta_1@X_maxpool_flatten.T<br/>        dW2 = delta_2@fc1.T<br/>        dB0 = np.sum(delta_1,axis=1,keepdims=True)<br/>        dB1 = np.sum(delta_2,axis=1,keepdims=True)<br/><em class="lp">#         print('Delta 2')</em><br/><em class="lp">#         print(delta_2)</em><br/>        <br/>        <em class="lp">### Calculating Error for Last Layer before flattening</em><br/>        <br/>        delta_maxpool = delta_0.reshape(X_maxpool.shape)<br/>        <br/>        <em class="lp">### Calculating Error for previous convolutional layer</em><br/>        <br/>        delta_conv = np.zeros(X_conv.shape)<br/>        for image <strong class="lg hp">in</strong> range(len(max_indices)):<br/>            indices = max_indices[image]<br/>            for p <strong class="lg hp">in</strong> indices:<br/>                delta_conv[image:image+1,p[1],p[2],p[3]] = delta_maxpool[image:image+1,p[5],p[6],p[7]]<br/>        delta_conv = np.multiply(delta_conv,dReLU(X_conv))<br/>        <br/>        <em class="lp">### using Im2col</em><br/>        X_batch_im2col = im2col(X=X_batch,conv1=conv1, stride=1, pad=0)<br/>        delta_conv_reshape = error_layer_reshape(delta_conv)<br/>        conv1_delta = (delta_conv_reshape@X_batch_im2col.T).reshape(2,1,5,5)<br/>        <br/>        momentum_w1 = beta1*momentum_w1 + ((1-beta1)*dW1)<br/>        momentum_w2 = beta1*momentum_w2 + ((1-beta1)*dW2)<br/>        momentum_b0 = beta1*momentum_b0 + ((1-beta1)*dB0)<br/>        momentum_b1 = beta1*momentum_b1 + ((1-beta1)*dB1)<br/>        momentum_conv1 = beta1*momentum_conv1 + ((1-beta1)*conv1_delta)<br/>        velocity_w1 = beta2*velocity_w1 + ((1-beta2)*dW1**2)<br/>        velocity_w2 = beta2*velocity_w2 + ((1-beta2)*dW2**2)<br/>        velocity_b0 = beta2*velocity_b0 + ((1-beta2)*dB0**2)<br/>        velocity_b1 = beta2*velocity_b1 + ((1-beta2)*dB1**2)<br/>        velocity_conv1 = beta2*velocity_conv1 + ((1-beta2)*conv1_delta**2)<br/>        <br/>        <br/>        <em class="lp">#conv1_delta = conv_filter_error_multiple(input_image=X_batch,error_layer=delta_conv,conv_filter=conv1,stride=1)</em><br/>        <em class="lp">#print('conv1 delta done')</em><br/>        <em class="lp">## Update Weights</em><br/>        conv1 = conv1 - learning_rate * momentum_conv1/np.sqrt(velocity_conv1+0.0000001)<br/>        W1 = W1 - learning_rate*momentum_w1/np.sqrt(velocity_w1+0.0000001)<br/>        W2 = W2 - learning_rate*momentum_w2/np.sqrt(velocity_w2+0.0000001)<br/>        B0 = B0 - learning_rate*momentum_b0/np.sqrt(velocity_b0+0.0000001)<br/>        B1 = B1 - learning_rate*momentum_b1/np.sqrt(velocity_b1+0.0000001)<br/>        <em class="lp">#print('Back Prop Done!')</em><br/>        <em class="lp">#i+=1</em><br/>    <br/>    X = data_array<br/>    y = one_hot_encoding.T<br/>    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)<br/>    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)<br/>    X_conv = conv1_reshaped@X_im2col<br/>    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))<br/>        <br/>        <br/>    <em class="lp">### Pass through ReLU</em><br/>        <br/>    X_relu = ReLU(X_conv)<br/>        <br/>    <em class="lp">### Pass Through Max Pool</em><br/>        <br/>    X_maxpool = maxpool_multiple(X_relu,stride=2)<br/>    input_shape = X_maxpool.shape[0]<br/>    num_channels = X_maxpool.shape[1]<br/>    input_width = X_maxpool.shape[2]<br/>    input_height = X_maxpool.shape[3]<br/>    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))<br/>    for image <strong class="lg hp">in</strong> range(input_shape):<br/>        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  <br/>    <em class="lp">### Getting into fully connected layers</em><br/>    fc1 = ReLU(W1@X_maxpool_flatten+B0)<br/>    final_fc = softmax(W2@fc1+B1)<br/>    <br/>    <em class="lp">#### Test Data</em><br/>    X = data_test_input<br/>    <em class="lp">#y = one_hot_encoding.T</em><br/>    X_im2col = im2col(X=X,conv1=conv1,stride=1,pad=0)<br/>    conv1_reshaped = conv1.reshape(conv1.shape[0],-1)<br/>    X_conv = conv1_reshaped@X_im2col<br/>    X_conv = np.array(np.hsplit(X_conv,X.shape[0])).reshape((X.shape[0],conv1.shape[0],24,24))<br/>        <br/>        <br/>    <em class="lp">### Pass through ReLU</em><br/>        <br/>    X_relu = ReLU(X_conv)<br/>        <br/>    <em class="lp">### Pass Through Max Pool</em><br/>        <br/>    X_maxpool = maxpool_multiple(X_relu,stride=2)<br/>    input_shape = X_maxpool.shape[0]<br/>    num_channels = X_maxpool.shape[1]<br/>    input_width = X_maxpool.shape[2]<br/>    input_height = X_maxpool.shape[3]<br/>    X_maxpool_flatten= np.zeros((input_width*input_height*num_channels,input_shape))<br/>    for image <strong class="lg hp">in</strong> range(input_shape):<br/>        X_maxpool_flatten[:,image:image+1] = X_maxpool[image:image+1,:,:,:].reshape(-1,1)  <br/>    <em class="lp">### Getting into fully connected layers</em><br/>    fc1 = ReLU(W1@X_maxpool_flatten+B0)<br/>    final_fc_test = softmax(W2@fc1+B1)<br/>    <br/>    <br/>    <br/>    <br/>    if epoch_num % 5  == 0:<br/>        <em class="lp">### Getting accuracy</em><br/>        print('Epoch :', epoch_num)<br/>        labels_predict = np.argmax(final_fc,axis=0)<br/>        labels_df  = data_balanced[['label']]<br/>        labels_predict = labels_predict.tolist()<br/>        labels_predict = [int(value) for value <strong class="lg hp">in</strong> labels_predict]<br/>        <em class="lp">#labels_df.loc[:,'label_predict'] = labels_predict</em><br/>        labels_df.insert(1,'label_predict',labels_predict)<br/>        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]<br/>        print('Train Accuracy')<br/>        print(round(accuracy*100,2),"%")<br/>        <br/>        <em class="lp">### Test Accuracy</em><br/>        <br/>        labels_predict = np.argmax(final_fc_test,axis=0)<br/>        labels_df  = data_test[['label']]<br/>        labels_predict = labels_predict.tolist()<br/>        labels_predict = [int(value) for value <strong class="lg hp">in</strong> labels_predict]<br/>        labels_df.insert(1,'label_predict',labels_predict)<br/>        <em class="lp">#labels_df.loc[:,'label_predict'] = labels_predict</em><br/>        accuracy = np.sum(labels_df['label']==labels_df['label_predict'])/labels_df.shape[0]<br/>        print('Test Accuracy')<br/>        print(round(accuracy*100,2),"%")<br/>        print('-------------------------')<br/>        <br/><em class="lp">#       print(cross_entropy(y=y,y_hat=final_fc))</em><br/>        <br/><br/><br/>        <br/>    <br/>    <br/>print('Done!')</span></pre><p id="82ca" class="pw-post-body-paragraph il im ho in b io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ha bi translated">9.输出</p><figure class="lb lc ld le fd hj er es paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="er es lr"><img src="../Images/48263532631ea141b9b2a10980db3c50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7EqyiR5aohnjS4BntWhc_g.png"/></div></div><figcaption class="lw lx et er es ly lz bd b be z dx translated">测试和训练精度</figcaption></figure><h1 id="3fda" class="jy jz ho bd ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv bi translated">结果</h1><p id="9a56" class="pw-post-body-paragraph il im ho in b io kw iq ir is kx iu iv iw ma iy iz ja mb jc jd je mc jg jh ji ha bi translated">达到了99%的训练精度和95%的测试精度。代码可以在这里找到<a class="ae js" href="https://www.kaggle.com/adhok93/cnn-using-numpy-new-version" rel="noopener ugc nofollow" target="_blank">。</a></p></div></div>    
</body>
</html>