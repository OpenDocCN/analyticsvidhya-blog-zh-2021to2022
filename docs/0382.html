<html>
<head>
<title>Improving Spot Instance Cold Start Time for Machine Learning Inference</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">改进机器学习推理的现场实例冷启动时间</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/improving-spot-instance-cold-start-time-for-machine-learning-inference-4021e967bfdb?source=collection_archive---------12-----------------------#2021-01-14">https://medium.com/analytics-vidhya/improving-spot-instance-cold-start-time-for-machine-learning-inference-4021e967bfdb?source=collection_archive---------12-----------------------#2021-01-14</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="024a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最近，我在做一个项目，构建一个web应用程序来处理低光图像，并使它们变得更亮。为此，我从一篇机器学习论文的PyTorch实现开始；学习在黑暗中看东西。对我来说，挑战是建立一个低成本的推理API作为我的网站的演示。</p><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es jc"><img src="../Images/2593714c2a75036c9bb1de9e5376ef37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JiMPhqC02toWqqF8Eey89w.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">处理暗图像的Web应用程序</figcaption></figure><h1 id="4abe" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">介绍</h1><p id="0ac3" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">完成这个问题需要一些独特的挑战和决策。首先，高效的图像处理需要至少8GB的RAM，理想情况下还需要一个GPU。这些类型的实例类型对于低利用率的爱好项目来说是昂贵的。</p><p id="41ff" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最初，我使用我的后端Flask API在图像上传后立即连续执行推理。这在开发中工作得很好，但是当我开始使用uWSIGI时，我遇到了一个问题，python代码会无限地停留在一行上，但是从来不会抛出错误。在尝试逐行调试代码并检查机器上的资源没有耗尽之后，我得出结论，由于使用了PyTorch，uWSIGI的默认前置fork选项不能用于我的应用程序。</p><blockquote class="kv kw kx"><p id="c819" class="ie if ky ig b ih ii ij ik il im in io kz iq ir is la iu iv iw lb iy iz ja jb ha bi translated"><a class="ae lc" href="http://zarnovican.github.io/2016/02/15/uwsgi-graceful-reload/" rel="noopener ugc nofollow" target="_blank">http://zarnovican . github . io/2016/02/15/uws gi-graceful-reload/</a></p></blockquote><p id="3bdc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这篇博客文章有助于我理解uWSIGI配置，并得出结论，为了防止代码卡住，我需要设置uWSIGI配置:<code class="du ld le lf lg b">lazy-apps = true</code>。我发现这种安排不理想，因为它需要为每个工人加载一次机器学习模型，这将导致应用程序的无效扩展。因此，我决定将推理工作器从Flask API中分离出来，这样两个组件都可以独立伸缩。</p><p id="f072" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我考虑过使用AWS Lambda函数，但最终决定不使用它，因为Lambda不支持GPU，使用容器化的推理工作器可以使项目更加灵活，以便将来部署到其他云平台。</p><p id="ce51" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最后，我决定使用AWS EC2 Spot实例，并在Flask收到推理请求时按需启动一个实例。其优势在于，spot实例可以提供高达90%的按需价格折扣，并且可以通过灵活调整实例大小和可用性区域来最大限度地节省成本。缺点是AWS可以在2分钟的警告后随时终止这些实例。然而，这是可以接受的，因为每个推理只需要几秒钟，如果一个实例被终止，它可能会立即被替换。</p><h1 id="8397" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">系统结构</h1><figure class="jd je jf jg fd jh er es paragraph-image"><div role="button" tabindex="0" class="ji jj di jk bf jl"><div class="er es lh"><img src="../Images/bf753533e8184b14d0c1591381bec1a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FAHySDG4sApH-zTrQ3q_qw.png"/></div></div><figcaption class="jo jp et er es jq jr bd b be z dx translated">架构图</figcaption></figure><p id="b89d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">最终，我决定使用上面显示的架构。前端使用React构建，并将图像作为POST请求发送到Flask后端。后端负责以下工作。</p><ol class=""><li id="84c0" class="li lj hh ig b ih ii il im ip lk it ll ix lm jb ln lo lp lq bi translated">检查图像的有效性和格式</li><li id="5ea8" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">使用uuid创建唯一的文件id。</li><li id="7668" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">上传图像到S3</li><li id="ebe7" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">将文件id添加到SQS，这是EC2 Spot实例在启动时知道要处理哪些图像的方式</li><li id="877a" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">将文件id作为响应发送回前端。</li></ol><p id="5b84" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然后，前端可以定期轮询后端，以检查推断是否完成。</p><p id="0d3e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下面是后端用于处理图像上传的代码片段:</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lw lx l"/></div></figure><h1 id="2a42" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">冷启动挑战</h1><p id="a9a4" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">我面临的主要挑战是尽快启动实例，并最大限度地减少冷启动时间。我的初始部署需要5分钟以上才能启动，我采取了几项措施将启动时间缩短到1-2分钟左右。</p><ol class=""><li id="df84" class="li lj hh ig b ih ii il im ip lk it ll ix lm jb ln lo lp lq bi translated">创建了我自己的AMI (Amazon机器映像),已经安装了Docker，上传了我训练过的模型，并提取了我的基本Docker映像。这节省了大量时间，因为在机器启动后，python代码无需任何额外安装即可运行。</li><li id="4a89" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">我确保docker文件是有序的，这样源代码<code class="du ld le lf lg b">COPY ./app</code>的复制就发生在需求被安装之后。如果顺序颠倒了，那么每次更新源代码时，所有的需求都必须在每次发布时重新安装。</li></ol><pre class="jd je jf jg fd ly lg lz ma aw mb bi"><span id="bceb" class="mc jt hh lg b fi md me l mf mg">FROM python:latest<br/>RUN apt-get update</span><span id="1f6c" class="mc jt hh lg b fi mh me l mf mg">WORKDIR /app<br/>COPY requirements.txt /app<br/>RUN pip install -r requirements.txt</span><span id="2e26" class="mc jt hh lg b fi mh me l mf mg">COPY . /app<br/>RUN mkdir /app/checkpoint</span><span id="c9cd" class="mc jt hh lg b fi mh me l mf mg">CMD ["python", "main.py"]</span></pre><p id="fa96" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">采取这些步骤后，瓶颈不再是docker容器的安装和运行，而是实例的启动时间。因此，我尝试在用户点击我网站上的页面时先发制人地启动实例。尽管存在用户可能不会实际使用演示程序的风险，但它给了我的spot实例在请求实际发送之前启动的时间。为了实现这一点，我设置了一个函数，向服务器发送一个GET请求，检查页面加载后实例是否正在运行。</p><figure class="jd je jf jg fd jh"><div class="bz dy l di"><div class="lw lx l"/></div></figure><h1 id="eead" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">改进的余地</h1><p id="3eae" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">经过这些步骤来有效地使用spot实例进行我的机器学习推理后，我发现我的项目的性能是可以接受的。最后，在部署之后，我发现了一些遗留的问题。</p><ol class=""><li id="dd11" class="li lj hh ig b ih ii il im ip lk it ll ix lm jb ln lo lp lq bi translated">目前，推理工作器不直接与后端通信，S3会定期轮询，直到映像就绪。这很快就成了一个问题，因为往S3打电话的费用很高。目前，我已经将轮询限制为每5秒一次。</li><li id="3f57" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">推理机的故障恢复。后端能够检查以确保spot实例正在运行，并能够在终止时启动新的实例。不幸的是，如果推理挂起或崩溃，那么就没有足够的恢复。目前，我的解决方案是将关键代码包装在“try/except”块中，以尽量保持容器运行。</li><li id="fe86" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">最大的瓶颈之一是图像上传到S3，根据分辨率的不同，这可能是流程中最慢的一步。另一种方法是在EC2实例间共享EFS(弹性文件系统),这样可以提高吞吐量。</li></ol><h1 id="9b20" class="js jt hh bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp bi translated">源代码</h1><p id="bee7" class="pw-post-body-paragraph ie if hh ig b ih kq ij ik il kr in io ip ks ir is it kt iv iw ix ku iz ja jb ha bi translated">最后，该项目的代码分布在几个存储库中，链接如下:</p><ol class=""><li id="5803" class="li lj hh ig b ih ii il im ip lk it ll ix lm jb ln lo lp lq bi translated">前端(React)<a class="ae lc" href="https://github.com/SEANDOUGHTY/learning-to-see-in-the-dark-react" rel="noopener ugc nofollow" target="_blank"><br/>https://github . com/SEANDOUGHTY/learning-to-see-in-the-dark-React</a></li><li id="3e3f" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">后端API服务器(Flask)<br/><a class="ae lc" href="https://github.com/SEANDOUGHTY/learning-to-see-in-the-dark-flask" rel="noopener ugc nofollow" target="_blank">https://github . com/SEANDOUGHTY/learning-to-see-in-the-dark-Flask</a></li><li id="501b" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">现场实例工作者<br/><a class="ae lc" href="https://github.com/SEANDOUGHTY/learning-to-see-in-the-dark-worker" rel="noopener ugc nofollow" target="_blank">https://github . com/SEANDOUGHTY/learning-to-see-in-the-dark-Worker</a></li><li id="4c52" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">PyTorch推论<br/><a class="ae lc" href="https://github.com/frankgu968/learning-to-see-in-the-dark-pytorch" rel="noopener ugc nofollow" target="_blank">https://github . com/frankgu 968/learning-to-see-in-the-dark-py torch</a></li></ol></div><div class="ab cl mi mj go mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="ha hb hc hd he"><p id="583c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">[1]:陈晨，陈奇峰，贾旭，弗拉德伦·科尔敦，“学会在黑暗中看东西”，CVPR，2018年。</p></div></div>    
</body>
</html>