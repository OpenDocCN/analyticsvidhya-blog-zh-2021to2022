<html>
<head>
<title>Creating Apache Spark Standalone Cluster with on Windows</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在Windows上使用创建Apache Spark独立集群</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/creating-apache-spark-standalone-cluster-with-on-windows-95e66e00a2d8?source=collection_archive---------4-----------------------#2021-01-27">https://medium.com/analytics-vidhya/creating-apache-spark-standalone-cluster-with-on-windows-95e66e00a2d8?source=collection_archive---------4-----------------------#2021-01-27</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="a755" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">Apache Spark是一个强大、快速且经济高效的工具，用于解决大数据问题，具有Spark Streaming、Spark SQL和Spark MLlib等组件。因此，Spark就像大数据世界的瑞士军刀。</p><p id="5fde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">此外，Spark还有另一个非常重要的特性，即水平缩放。换句话说，Spark支持独立(部署)集群模式。单个Spark集群有一个主节点和任意数量的从节点或工作节点。工人可以在独立机器上的水平Spark集群上运行他们自己的单个流程，也可以在同一台机器上进行垂直扩展。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/faa06e6c6b907123164b713191c041dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UPM50fpnb4doVM2n37H7Lw.png"/></div></div></figure><p id="5e55" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们可以手动启动一个独立的集群，也可以使用Spark提供的启动脚本(sbin文件夹)。此外，我们还可以在一台机器上创建和运行集群，用于测试目的。</p><p id="249c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">今天，我将尝试向您展示如何创建一个包含1个主节点和2个从节点的single Spark独立集群。我将为此集群使用2台不同的机器。我将使用第一个创建我的主节点和1个从节点，第二个创建另一个从节点。因此我们将有一个独立的集群和一个单一的机器集群。</p><h1 id="9c87" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">先决条件</h1><p id="ef88" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">要创建Spark独立集群，我们必须在集群的每个节点上安装编译版本的Apache Spark和Python，还必须在每台机器上安装Java JDK。在每台机器上安装相同的版本也非常重要。</p><p id="f0b3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">安装完成后，我们需要在主机中编辑spark-env.sh.template和slaves.template文件。首先打开spark <em class="kt"> conf </em>文件夹，创建spark-env.sh.template的副本，重命名为“spark-env.sh”。然后编辑以下参数；</p><pre class="je jf jg jh fd ku kv kw kx aw ky bi"><span id="6fed" class="kz jq hi kv b fi la lb l lc ld"> export SPARK_MASTER_HOST=&lt;MASTER-IP&gt;<br/> export JAVA_HOME=&lt;Path_of_JAVA_installation&gt;<br/> export PYSPARK_PYTHON=python3</span></pre><p id="4a14" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">然后打开spark <em class="kt"> conf </em>文件夹，创建slaves.template的副本，重命名为“slaves”。然后编辑以下参数；</p><pre class="je jf jg jh fd ku kv kw kx aw ky bi"><span id="af29" class="kz jq hi kv b fi la lb l lc ld">&lt;SLAVE01-IP&gt;<br/>&lt;SLAVE02-IP&gt;</span></pre><p id="f469" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">最后，我们需要创建一个数据文件夹，我们将在Spark中使用它来保存我们的数据，在两台机器上使用相同的路径(例如C:\data)。如果我们的集群上没有Hadoop HDFS或者我们没有使用AWS实例，我们需要为每个节点创建一个数据文件夹。否则，群集将找不到数据，并会出错。通常情况下，像HDFS或S3这样的数据库将用于真实世界中的Spark集群，但由于我们创建它是为了了解Spark独立集群的基础，我们将通过在每台机器中创建一个数据文件夹来演示它。</p><h1 id="5ef1" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">启动集群</h1><p id="3037" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">完成安装和编辑步骤后，我们现在准备创建我们可爱的😀Spark独立集群。首先在主机中打开一个终端，移入Spark的bin文件夹中进行写入；</p><p id="7a47" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“spark-class org . Apache . spark . deploy . master . master”命令。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es le"><img src="../Images/eb241de63146caf95a5a271f375cada2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1092/format:webp/1*m9akUEWGzCV-_-WpXkUyQA.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lf"><img src="../Images/147d127a8a150b2fe914a23c51622c5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bqJmXWKltOqtH_efDdt4HQ.jpeg"/></div></div></figure><p id="b74e" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">从上面的截图可以看出，我们师傅在“spark:// <master-ip> :7077”成功启动。我们还可以在端口8080从Spark独立的基于web的用户界面监控我们的集群。</master-ip></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lg"><img src="../Images/722b74bdd3f2815c3d281217c27f186f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JV9G8yADFkjFYWI0F0DQdQ.jpeg"/></div></div></figure><p id="2e9a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">你可以很容易地看到，我们仍然没有任何工人，所以现在是时候通过在主机中打开另一个终端来提高我们的第一个工人节点，并写入；</p><p id="4bde" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">“spark-class org . Apache . spark . deploy . worker . worker spark://<master-ip>:7077”命令。</master-ip></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lh"><img src="../Images/16c471da470cb4206db16b5db1fc0cdf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*LZciL61DTAXTKdyungQc_w.jpeg"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es li"><img src="../Images/05c5fdceb52a78cd001a5f8198e826fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v9UtVxY0Q3cAJEuX1dMkrA.jpeg"/></div></div></figure><p id="b410" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">到目前为止，我们在同一台机器上启动了主节点和一个工作节点。现在让我们从第二台机器启动我们的第二个Worker节点。我们将再次打开一个终端，编写与第一个Worker相同的命令。</p><p id="2873" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在我们启动第二个Worker之后，我们可以从Spark Standalone集群的web ui监视我们集群的最后情况；</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lj"><img src="../Images/a76766abcb7b9504be302abffcdca7e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iriM2pIL5NT1dX_2oZKFKQ.png"/></div></div></figure><p id="b30d" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们设法创建了带有2个工作节点的Spark独立集群。如你所见，我们的员工有不同大小的内存(6.9和14.8 gib)。这是因为两台机器的配置不同。主机有16 gb内存，一台有8 gb内存。另外，Spark为每个Worker节点使用默认的1 gb内存，我们可以稍后在Pyspark脚本中更改这一内存。</p><h1 id="5806" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">在集群中运行应用程序</h1><p id="f0cc" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">我们的Spark独立集群已经可以使用了。让我们用一个带有Jupyter Notebook的示例Pyspark脚本来测试它。我将使用我在上一篇关于AWS的文章中使用的同一个例子。唯一的区别是关于创建Spark会话。这次我们将在master method中写“spark:// <master-ip> :7077”而不是“local”。正如我之前提到的，我将更改Workers的内存使用(每个Worker和驱动程序4gb ),并为它们分配核心数。您还可以使用其他选项调整配置，这些选项可以在<a class="ae ks" href="https://spark.apache.org/docs/latest/configuration.html" rel="noopener ugc nofollow" target="_blank"> Spark文档</a>中找到。</master-ip></p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lk"><img src="../Images/eb9904764e27c7164957a77e35ded02d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x2JmuLPQIKbfm1VGlonbnA.jpeg"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ll"><img src="../Images/4f6903940ad9242db813dc219b8cc226.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4754K69yFVxjDnTNGwy0Xg.png"/></div></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es lm"><img src="../Images/cc0df6227731ecd744de1b1cdc200b54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AtXQSxZIVIt2EuxEHc8Liw.png"/></div></div></figure><p id="6f98" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们成功地用新的集群运行了我们的查询。最后，我们可以从Spark UI网页查看我们的集群，以监控正在运行的应用程序。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es ln"><img src="../Images/646388efde35244e9faff362ba257763.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WNHpmr2Fr8U9X-PvyHSZKg.jpeg"/></div></div></figure><p id="7786" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我们的Spark应用程序(spark-standalone-cluster)在运行时没有任何问题，我们的两个Workers按照我们在SparkSession中指定的那样为每个Workers使用4 gb内存。</p><h1 id="9c96" class="jp jq hi bd jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km bi translated">结论</h1><p id="45ea" class="pw-post-body-paragraph if ig hi ih b ii kn ik il im ko io ip iq kp is it iu kq iw ix iy kr ja jb jc hb bi translated">在本文中，我尝试简要介绍了如何使用Jupyter Notebook创建和运行Apache Spark独立集群。在这个例子中，我们使用了两个工人，您可以使用我在文章中提到的相同方法将其增加到任意数量。您还可以借助<a class="ae ks" href="https://spark.apache.org/docs/latest/spark-standalone.html" rel="noopener ugc nofollow" target="_blank"> Spark文档</a>提高对Spark独立集群的了解。</p><p id="729a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我希望这篇文章对你有所帮助。在下一篇文章中，我将讲述如何将Spark应用程序与著名的NoSQL数据库“MongoDB”集成。</p><p id="0a1f" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">我将很高兴听到您的任何意见或问题。愿数据伴随你！</p></div></div>    
</body>
</html>