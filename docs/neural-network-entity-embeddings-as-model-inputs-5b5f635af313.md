# 作为模型输入的神经网络实体嵌入

> 原文：<https://medium.com/analytics-vidhya/neural-network-entity-embeddings-as-model-inputs-5b5f635af313?source=collection_archive---------8----------------------->

在学习杰瑞米·霍华德的 FastAI 课程时，我看到书中有一段引用了郭城和菲利克斯·伯克哈恩的论文 [*分类变量的实体嵌入*](https://arxiv.org/abs/1604.06737) *，“*从训练好的神经网络中获得的嵌入在用作输入特征时，大大提高了所有测试过的机器学习方法的性能。”本质上，作为他们研究的一部分，他们发现经过训练的嵌入矩阵可以用作其他模型的输入，以提高它们相对于输入本身的训练的性能。他们论文的结果如下图 1 所示，其中 MAPE 指的是平均误差百分比，EE 指的是实体嵌入方法。

![](img/bc45015d94998b985018326f0b063e32.png)

图一。使用神经网络嵌入作为其他机器学习算法的输入(分类变量的实体嵌入)。

对这个结果很感兴趣，我想尝试用一个不同的数据集来复制它，特别是杰瑞米·霍华德在课程中使用的推土机卡格尔比赛的蓝皮书数据集。训练嵌入矩阵的代码可以在书中找到，这个项目的完整代码可以在 [my GitHub](https://github.com/QuantumAbyss/EntityEmbeddings) 上找到。

# 背景——什么是实体嵌入？

在高层次上，对于我们的目的来说，嵌入是一种处理分类变量的方法。它类似于一键编码，在这种编码中，由“男性”和“女性”等类别组成的表格数据集列“性别”作为字符串将被转换为两个同名的列，如果行项目表示肯定，则转换为“1”，否则转换为“0”。另一方面，嵌入方法将每个类别表示为实值向量，该向量对单词的含义进行编码，使得相似的单词在向量空间中彼此更接近。这个定义让它听起来比实际更复杂；对我来说，这有助于理解它实际上是什么样子。您可以设想一个嵌入矩阵，它的行数等于不同类别的数量，列数几乎可以设置为您想要的任何数量(更多的列意味着更高的复杂性和学习您的单词空间的其他潜在因素的潜力)，这个矩阵的行构成了代表特定类别的向量。有关这方面的示例，请参见下面的图 2；它展示了如果我们用一键编码格式或作为嵌入来表达一个单独的列会是什么样子。

![](img/5093cfbafaf17cea7f881e614ebaa1dd.png)

图二。使用一键编码或嵌入方法表示分类列的示例。图片作者。

本例中嵌入矩阵的形状为 2 x N。对于本项目，我们使用 FastAI 软件包定义的经验法则选择 n，N = min(600，round(1.6 * categories^0.56).

# 构建嵌入矩阵

所以现在你可能想知道我们是如何为嵌入矩阵选择单元格中的值的。答案是我们没有。我们让随机梯度下降为我们做到这一点。在代码中，您会看到这非常简单，因为我们让 FastAI 的 tabular_learner 为我们构建和训练我们的神经网络:

```
learn = tabular_learner(dls, y_range=(8,12), layers=[500,250], n_out=1, loss_func=F.mse_loss)learn.fit_one_cycle(5, 1e-2)
```

然后，我们可以简单地访问来自学习者的嵌入矩阵，如下所示，其中 emb_idx 选择特定的分类变量嵌入，权重属性访问张量:

```
learn.model.embeds[emb_idx].weight
```

# 构建实体嵌入数据集

有了嵌入矩阵后，我们的挑战就变成了使用嵌入来重建数据集，而不是使用分类列本身。为此，我们使用图 3 所示的代码。它可以解释为:对于数据集中的每一行，对于每一项，检索值实体嵌入向量(如果值缺失，则对矩阵求平均，或者只返回非分类变量和因变量的原始数据)，将其添加到一行中，并重复，直到我们得到与原始数据行数相同的数据集。

![](img/1068f551118696f31e9571f80ac9ee97.png)

图 3。用于构建嵌入数据集的 Jupyter 笔记本 Python 摘录。图片作者。

我们的原始数据集包含 15 列，而新的嵌入数据集包含 483 列，这大大增加了内存中的数据量。

# 测试不同的模型

开发完数据集后，我运行了两个具有相同超参数的模型来比较这两个数据集，结果如图 4 所示。

![](img/6fb2e58ec07bae1b9de7b92fc8492e1b.png)

图 4。使用相同方法比较数据集。图片作者。

你可以看到，在每一个测试案例中，除了差异很小的神经网络，嵌入数据集的实体减少了误差。

# 结论

不幸的是，通过利用实体嵌入实现的误差减少伴随着需要处理的数据的大量增加。然而，这种情况下的嵌入特征空间是使用 FastAI 的经验法则选择的，因此有可能通过输入自定义大小来减少嵌入矩阵的大小。是否可以用更小的实体嵌入(也许是原始数据集的两倍或三倍，而不是 32 倍)实现类似的改进是一个潜在的进一步研究的领域。