<html>
<head>
<title>Discovering Customer Segments using Machine Learning — Part 2(Dimension Reduction and Clustering)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用机器学习发现客户群—第2部分(降维和聚类)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/discovering-customer-segments-using-machine-learning-part-2-dimension-reduction-and-clustering-36c6108599f9?source=collection_archive---------10-----------------------#2021-10-11">https://medium.com/analytics-vidhya/discovering-customer-segments-using-machine-learning-part-2-dimension-reduction-and-clustering-36c6108599f9?source=collection_archive---------10-----------------------#2021-10-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/667b770a1ab45eb9c24c7f87b1e28b63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5L46Ls-zrbgwQOwv.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated"><a class="ae it" href="https://data-flair.training/blogs/wp-content/uploads/sites/2/2019/07/R-project-customer-segmentation.png" rel="noopener ugc nofollow" target="_blank">https://data-flair . training/blogs/WP-content/uploads/sites/2/2019/07/R-project-customer-segmentation . png</a></figcaption></figure><p id="c520" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在前一部分中，我们清理了数据，并确定了可以使用哪个变量。在这一部分，我们将直接讨论如何为聚类准备数据。我们的数据由25个变量组成，上层管理人员和我们自己不方便同时直观地解释所有25个变量。这就是为什么我们在进行聚类之前先从降维开始。</p></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="dc41" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">主成分分析</h1><p id="3793" class="pw-post-body-paragraph iu iv hh iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr ha bi translated">在我们实现PCA之前，第一步实际上是只从数据中选择数字变量，因为PCA并不意味着处理分类变量。在我们选择了数值变量之后，我们可以实现PCA。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="de7a" class="ll ka hh lh b fi lm ln l lo lp">from sklearn.preprocessing import StandardScaler<br/>from sklearn.decomposition import PCA<br/>pcascale = StandardScaler()<br/>datanum = data.loc[:,data.dtypes != 'object']<br/>datacat = data.loc[:,data.dtypes == 'object']<br/>forpca = pd.DataFrame(pcascale.fit_transform(datanum),columns=datanum.columns)<br/>pca = PCA(svd_solver = 'full')<br/>pca.fit(forpca)</span></pre><p id="64e9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">主成分分析的目的，还是为了减少我们将要用到的变量的维数。PCA通过投影一对变量作为新的变量，即“分量”，来减少原始变量；因此，它被称为主成分分析。为了了解我们需要保留多少组分，我们需要查看PCA结果中组分的累积方差。我们将绘制预测变量的累积解释方差图，以确定我们应该保留多少分量。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="dc62" class="ll ka hh lh b fi lm ln l lo lp">def display_scree_plot(pca):<br/>    scree = pca.explained_variance_ratio_*100<br/>    plt.bar(np.arange(len(scree))+1, scree)<br/>    plt.plot(np.arange(len(scree))+1, scree.cumsum(),c="red",marker='o')<br/>    plt.xlabel("Number of Principal Components")<br/>    plt.ylabel("Percentage Explained Variance")<br/>    plt.title("Scree Plot")<br/>    plt.show(block=False)</span><span id="aa0f" class="ll ka hh lh b fi lq ln l lo lp">expvar = np.round(pca.explained_variance_ratio_,5) <br/>expvar<br/>print(pca.explained_variance_ratio_.cumsum())<br/>display_scree_plot(pca)</span></pre><figure class="lc ld le lf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lr"><img src="../Images/8e11000f891ff0d0fa5484789056b70b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HH1mG9a161dhXkCOuCcEiA.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">累积解释方差及其图</figcaption></figure><p id="660a" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">现在，保留成分的数量实际上取决于我们希望从原始数据中解释多少差异。通常，用户(像我们这样的人)希望解释的方差保持在80%-95%的范围内，这取决于具体情况。在这种情况下，我实际上要保留可以累计解释80%原始数据差异的组件。<br/>我们可以看到，我们实际上只需要7个分量来描述原始数据方差的80.19%。因此，现在我们将原始数据投影到7个新组件中。我们可以通过显示组件上每个变量的负载来解释7个新组件。通常，为了解释一个组件，我们只关注高于0.3或低于-0.3的载荷。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="b3f9" class="ll ka hh lh b fi lm ln l lo lp">pcanew = PCA(n_components = 7,svd_solver = 'full')<br/>pcanew.fit(forpca)<br/>loadings = pd.DataFrame(pcanew.components_.T, columns=['PC1','PC2','PC3','PC4','PC5','PC6','PC7'], index=forpca.columns)<br/>loadings[(loadings&gt;0.3)|(loadings&lt;-0.3)]</span></pre><figure class="lc ld le lf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ls"><img src="../Images/64a4f9403c338dc28e2f3e27ef19c6bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YrYY_f565O-UvrrbARWT5g.jpeg"/></div></div></figure><p id="e3c7" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">如果我们看一下每个组成部分，我们可以说在每个组成部分中，这些变量很重要:<br/> PC1 =收入，MntWines，MntMeatProducts，numcatalogpuses，numstoreepurchases<br/>PC2 = teen home，NumDealsPurchases，NumWebPurchases<br/>PC3 = teen home，NumWebVisitsMonth，days_since_join，Age <br/> PC4 = Kidhome，NumDealsPurchases，days_since_join，Age <br/> PC5 = MntWines，MntFruits</p><p id="b42c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过查看每个组件中的重要变量，我们可以尝试了解每个组件试图从数据中描述什么。经过长时间的思考，我是这样解释7个主成分的:<br/> PC1 =财富的衡量标准<br/> PC2 =使用交易的倾向<br/> PC3 =相对年龄<br/> PC4 =加入后的相对时间<br/> PC5 =相对商品购买量<br/> PC6 =活动衡量标准<br/> PC7 =黄金与糖果购买量的比较</p><blockquote class="lt lu lv"><p id="a13c" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated">这是我在解释每一个组成部分时对我的推理的解释。我加上这一点，以防你们想知道我为什么这样解释每一部分的原因。</p><p id="f9fc" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated">推理:<br/> PC1 =我们可以看到它所包含的大部分变量都可以用来衡量富裕程度比如:a)收入越高，PC1值越高。b)购买的葡萄酒量越高，PC1值越高。c)等。</p><p id="8769" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated">PC2 =我们可以看到，PC2可能表明NumDealsPurchases的增加也可能表明Teenhome和NumWebPurchases数量的增加。在PC2分量上具有最高负载的NumDealsPurchases意味着NumDealsPurchases对PC2的值的影响非常高。因此，我们可以说，这个组成部分可能代表了用户购买交易的倾向有多大。</p><p id="637a" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated">PC3 = PC3在days_since_join和Age上具有高负载，即使这两个原始变量实际上具有低相关性。这可能表明，PC3实际上试图描述我们的平均客户年龄，因此侧重于年龄或自加入以来的天数(自加入以来的客户年龄)。</p><p id="c54e" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated">PC4 = PC4在days_since_join上权重很大，但与PC3不同，在Age上的负载没有days_since_join高。这意味着PC4在其值中考虑年龄，但更关注days_since_join。PC4考虑的其他变量是NumDealsPurchases和Kidhome。这意味着PC4可能试图测量days_since_join数将如何根据NumDealsPurchases和/或Kidhome的大小而变化。</p><p id="a4f4" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated">PC5 = PC5显然是在试图描述顾客购买商品的相对量，因为它总共包含MntWines、MntFruits、MntFishProducts和MntSweetProducts。</p><p id="ee55" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated">PC6 = PC6包含了相当多的变数。我们可以看到，有3个关于购买次数的变量，其加载量&gt; 0.3或</p><p id="84e3" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated">PC7 = PC7仅包含MntGoldProds和MntSweetProducts。我们可以说，该组件试图描述购买的黄金与购买的甜食的相对数量(MntGoldPurchases与MntSweetProducts的比率)。</p></blockquote></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="b873" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">使用K原型的聚类</h1><p id="80cb" class="pw-post-body-paragraph iu iv hh iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr ha bi translated">在解释了主成分分析的每个成分想要表达的意思之后，我们可以尝试将主成分分析得分与我们之前分离的原始分类数据相结合。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="aeab" class="ll ka hh lh b fi lm ln l lo lp">reduced = pd.DataFrame(pcanew.transform(forpca), columns = ['wealthiness','usedeals','relative_age','relative_timesincejoin','relative_mntgoods','activitymeasurement','goldstosweets'])</span><span id="9e6d" class="ll ka hh lh b fi lq ln l lo lp">forclust=pd.concat([reduced.reset_index(drop=True),datacat.reset_index(drop=True)],axis = 1)</span></pre><p id="7098" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">然后，我们使用这个组合数据作为聚类的输入。</p><blockquote class="lt lu lv"><p id="f633" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated">在本文结束之前，我们必须记住，用于拟合聚类算法的输入是与原始分类数据相结合的PCA得分。</p></blockquote><p id="baf3" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我们将使用K-Prototype聚类，因为它处理数值和分类数据。由于K-Prototype实际上是K-Means和K-Modes(某种程度上)的组合，我们将需要声明我们想要从数据中获得的聚类数。我们将使用kmodes.kprototypes包中的成本方法生成的肘形曲线来评估最佳聚类数。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="34f9" class="ll ka hh lh b fi lm ln l lo lp">from kmodes.kprototypes import KPrototypes<br/>Poscatcol = [forclust.columns.get_loc(i) for i in forclust.loc[:, forclust.dtypes == 'object'].columns]<br/>cost = []<br/>for i in range(2,7):<br/>    clust = KPrototypes(n_clusters = i,init='Huang',random_state=42)<br/>    clust.fit_predict(forclust,categorical = Poscatcol)<br/>    cost.append(clust.cost_)<br/>    <br/>sns.lineplot(x = range(2,7),y = cost,marker = "+",dashes = True)<br/>plt.title('Elbow Curve')<br/>plt.xlabel('N of Clusters')<br/>plt.ylabel('Cost')<br/>plt.plot</span></pre><figure class="lc ld le lf fd ii er es paragraph-image"><div class="er es ma"><img src="../Images/ba3e1ca45c6132ec9e38f15db33e384c.png" data-original-src="https://miro.medium.com/v2/resize:fit:804/format:webp/1*T5IOcX559S2rmx3bMh-JCw.png"/></div></figure><p id="991c" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">通过肘形曲线，我们可以看到最佳的集群数量是3，因为我们希望显著降低成本，同时防止创建太多的集群。从2个集群到3个集群，成本下降相对显著。因此，我们运行聚类以从数据中获得3个聚类。</p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="3c99" class="ll ka hh lh b fi lm ln l lo lp">finalclust = KPrototypes(n_clusters = 3, init='Huang',random_state=42)<br/>finalclust.fit_predict(forclust,categorical = Poscatcol)<br/>full = forclust.loc[:]<br/>full['segments'] = finalclust.labels_<br/>full.segments.value_counts()</span></pre><p id="5049" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">使用从数据组合中获得的聚类，我们描述了数值变量和分类变量</p><div class="lc ld le lf fd ab cb"><figure class="mb ii mc md me mf mg paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/a660885641a1ebe6cd5f9f531e5d0aef.png" data-original-src="https://miro.medium.com/v2/resize:fit:750/format:webp/1*0kItWBsLPJQ97TI2PJup3Q.png"/></div></figure><figure class="mb ii mh md me mf mg paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><img src="../Images/f6d6563664fd75f242b88b03184099a8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/1*ZcS55gC4zGbxZNTQ815kuw.png"/></div><figcaption class="ip iq et er es ir is bd b be z dx mi di mj mk translated">左图:通过数值数据(PCA分数)进行的聚类比较，右图:通过分类数据进行的聚类比较</figcaption></figure></div><p id="0a01" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">从用于聚类输入和绘制的组合数据(PCA得分和原始分类数据)中，我们可以估计我们的市场是如何聚类和表现的。这些是我们细分市场中令人感兴趣的东西:</p><h2 id="615a" class="ll ka hh bd kb ml mm mn kf mo mp mq kj jf mr ms kn jj mt mu kr jn mv mw kv mx bi translated">第一个群集(群集0)</h2><p id="5862" class="pw-post-body-paragraph iu iv hh iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr ha bi translated">我们的大多数客户都属于这个集群，因此我们可以将这个集群作为参考来解释其他集群(一般客户/大多数客户)。与其他集群中的客户相比，该集群中的大多数客户不太可能拒绝我们活动的报价。与其他集群相比，该集群上的客户可以被认为更富有。</p><p id="00a9" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">该聚类的箱线图显示了自加入以来的相对时间、购买商品的相对数量、活动测量以及购买糖果的黄金数量，这些数据没有显示出聚类之间的任何差异，但是我们可以尝试关注异常值，以查看可能正确的一些想法。如果我们关注离群值，这个集群(集群0)上的客户可能由比其他集群上的客户加入我们的时间更长的客户组成。离群值也可能表明该集群上的客户比其他集群上的客户更活跃，购买了更多的产品。<strong class="iw hi">这只是一个想法，也许正确，也许不正确</strong>。稍后，我们将通过使用原始数据比较每个聚类来检查这一想法的有效性。</p><h2 id="fc81" class="ll ka hh bd kb ml mm mn kf mo mp mq kj jf mr ms kn jj mt mu kr jn mv mw kv mx bi translated">第二组(组1)</h2><p id="acd6" class="pw-post-body-paragraph iu iv hh iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr ha bi translated">这个集群中的客户没有第一个集群中的客户富有。该集群中的客户是最有可能购买特价商品的客户。</p><h2 id="be0f" class="ll ka hh bd kb ml mm mn kf mo mp mq kj jf mr ms kn jj mt mu kr jn mv mw kv mx bi translated">第三组(第二组)</h2><p id="da6a" class="pw-post-body-paragraph iu iv hh iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr ha bi translated">该集群中的客户是其他集群中所有客户中最不富裕的客户。与其他活动相比，该群中的客户更有可能接受我们第三次活动的报价。尽管很难被发现，也没有太大区别，但是这个集群上的客户比其他集群上的客户更有可能抱怨。</p><blockquote class="lt lu lv"><p id="243e" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated">我们可以忽略分类变量，因为我们可以从上面的图中看到，它们对区分每个聚类没有太大贡献。分类变量的模式在一个聚类和另一个聚类之间或多或少是相同的。</p></blockquote></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="0bea" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">用PCA分数+原始分类数据验证聚类</h1><p id="e477" class="pw-post-body-paragraph iu iv hh iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr ha bi translated">我们将尝试通过使用原始数据比较每个聚类的特征来验证使用组合数据(PCA得分和原始分类数据)进行的聚类的结果。<strong class="iw hi">这里的目的是查看从组合数据(PCA得分+分类数据)得出的每个聚类的结论特征与从原始数据得出的每个聚类的结论特征之间是否存在差异。</strong></p><pre class="lc ld le lf fd lg lh li lj aw lk bi"><span id="3d44" class="ll ka hh lh b fi lm ln l lo lp">data['segments'] = finalclust.labels_<br/>fig, ax = plt.subplots(nrows = 3, ncols = 5,figsize = (15,15))</span><span id="404e" class="ll ka hh lh b fi lq ln l lo lp">sns.boxplot(y='Age', x= 'segments', data=data, ax=ax[0,0])<br/>sns.boxplot(y='days_since_join', x= 'segments', data=data, ax=ax[0,1])<br/>sns.boxplot(y='Income', x= 'segments', data=data, ax=ax[0,2])<br/>sns.boxplot(y='MntWines', x= 'segments', data=data, ax=ax[0,3])<br/>sns.boxplot(y='MntFruits', x= 'segments', data=data, ax=ax[0,4])<br/>sns.boxplot(y='MntFishProducts', x= 'segments', data=data, ax=ax[1,0])<br/>sns.boxplot(y='MntMeatProducts',x= 'segments', data=data, ax=ax[1,1])<br/>sns.boxplot(y='MntGoldProds',x= 'segments', data=data, ax=ax[1,2])<br/>sns.boxplot(y='NumStorePurchases',x= 'segments', data=data, ax=ax[1,3])<br/>sns.boxplot(y='NumWebPurchases',x= 'segments', data=data, ax=ax[1,4])<br/>sns.boxplot(y='NumCatalogPurchases',x= 'segments', data=data, ax=ax[2,0])<br/>sns.boxplot(y='NumDealsPurchases',x= 'segments', data=data, ax=ax[2,1])<br/>fig.delaxes(ax[2,2])<br/>fig.delaxes(ax[2,3])<br/>fig.delaxes(ax[2,4])<br/>plt.tight_layout()<br/>plt.show()</span></pre><figure class="lc ld le lf fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es my"><img src="../Images/78e57433d1497c963987f7df8776aab1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5HNs9FXsIwqD_R-lvvoxCQ.png"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">用来自组合数据的聚类结果解释原始数据(PCA得分+原始分类数据)</figcaption></figure><p id="9808" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">选择在上面绘制的变量是在考虑了其与PCA结果成分的关系(由载荷解释)后选择的。上面的图试图用原始变量描述我们的原始数据，但是被我们的聚类结果分割。分类变量未绘制。根据上面的图，<strong class="iw hi">我们之前通过PCA得分做出的聚类解释与我们目前通过原始数据</strong>做出的聚类解释相差不远。我们可以看到，第一个聚类由比大多数客户更富有的客户组成。他们也更积极，也比其他顾客购买了更多的产品<strong class="iw hi">(就像之前PCA得分上的异常值所暗示的那样！)</strong>。同时，每个集群之间的年龄和加入天数似乎没有太大差异。我们还可以看到，与其他集群的客户相比，第二个集群更有可能购买特价商品。</p><blockquote class="lt lu lv"><p id="f7cc" class="iu iv lw iw b ix iy iz ja jb jc jd je lx jg jh ji ly jk jl jm lz jo jp jq jr ha bi translated"><strong class="iw hi">有趣的事实</strong>:如果你关注客户的交易购买和网络购买，你会发现这实际上与我们在PC2上的PCA加载密切相关。我们将PC2解释为客户通过交易进行购买的趋势。在PC2内部，我们可以看到web购买也有相对较大的加载量。这意味着我们可以通过网上购物的次数或者通过交易购物的次数来描述PC2。当我们解释PC2的聚类结果时，我们可以看到第二个聚类高于平均值。这意味着第二群集可能具有较高的网络购买量和/或较高的交易购买量。这个假设在上面的最后一个情节中得到了回答。</p></blockquote></div><div class="ab cl js jt go ju" role="separator"><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx jy"/><span class="jv bw bk jw jx"/></div><div class="ha hb hc hd he"><h1 id="1700" class="jz ka hh bd kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw bi translated">结论</h1><p id="766d" class="pw-post-body-paragraph iu iv hh iw b ix kx iz ja jb ky jd je jf kz jh ji jj la jl jm jn lb jp jq jr ha bi translated">根据这些数据，我们可以看出有三种类型的客户。简而言之，这三种类型的顾客在他们的收入和他们在网上购物和网上购物的行为上有所不同。如果我们考虑所有顾客的平均收入，我们可以说，平均收入的顾客更倾向于从网上购买和通过交易购买。高收入的顾客往往比低收入的顾客更活跃。</p><p id="6d65" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这部作品在过程和写作上都远非完美。我希望听到你们的一些评论和意见(是的，亲爱的读者)。最后，如果这篇文章以任何方式帮助你理解机器学习如何被用来做市场细分，请留下“掌声”。:)</p><p id="883f" class="pw-post-body-paragraph iu iv hh iw b ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">在我的下一部作品中再见！</p></div></div>    
</body>
</html>