<html>
<head>
<title>3- Time Series Forecasting Using LSTM</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于LSTM的3-时间序列预测</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/3-time-series-forecasting-using-lstm-e14b93f4ec7c?source=collection_archive---------1-----------------------#2021-06-20">https://medium.com/analytics-vidhya/3-time-series-forecasting-using-lstm-e14b93f4ec7c?source=collection_archive---------1-----------------------#2021-06-20</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es if"><img src="../Images/2c06e1961b737b60f800c4541fc9cbd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*f4byZw30VZa18ySF"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">克里斯·利维拉尼在<a class="ae iu" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</figcaption></figure><blockquote class="iv iw ix"><p id="3c73" class="iy iz ja jb b jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw hb bi translated"><strong class="jb hj"> <em class="hi">更新</em> </strong> <em class="hi">:本文是我探索时间序列的系列文章的一部分。查看完整系列:</em> <a class="ae iu" rel="noopener" href="/analytics-vidhya/1-introduction-to-time-series-5ae663c468f4"> <em class="hi">第一部分</em> </a> <em class="hi">，</em> <a class="ae iu" rel="noopener" href="/analytics-vidhya/2-econometric-statistical-models-in-time-series-7b69ae3ab1d8"> <em class="hi">第二部分</em> </a> <em class="hi">第三部分</em></p></blockquote></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h2 id="a254" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">介绍</h2><p id="3bd9" class="pw-post-body-paragraph iy iz hi jb b jc lc je jf jg ld ji jj kp le jm jn kt lf jq jr kx lg ju jv jw hb bi translated">这是自1743年以来佛罗里达的月平均气温，我在上一篇文章中讨论过。在本文中，我将首先演示在这个数据集上使用LSTM的基本操作。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="e9d5" class="lh kf hi bd kg li lj lk kk ll lm ln ko lo lp lq ks lr ls lt kw lu lv lw la lx bi translated">别跟我解释，出示代码</h1><p id="a05f" class="pw-post-body-paragraph iy iz hi jb b jc lc je jf jg ld ji jj kp le jm jn kt lf jq jr kx lg ju jv jw hb bi translated">你可以在这里访问GitHub repo。</p></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h2 id="9179" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">什么是LSTM，为什么它对时间序列很重要？</h2><p id="880a" class="pw-post-body-paragraph iy iz hi jb b jc lc je jf jg ld ji jj kp le jm jn kt lf jq jr kx lg ju jv jw hb bi translated"><strong class="jb hj">长短期记忆(LSTM) </strong>是一种用于深度学习领域的人工重复神经网络(RNN)架构。虽然它在工作逻辑方面与RNN没有什么不同，但它允许更长的序列工作。据RNN说，它可以在很大程度上解决梯度问题。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es ly"><img src="../Images/990056ac98d1be74b182d5021d21c1fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:500/0*V1xGkiCB3_kYtZ8N"/></div></figure><p id="06c6" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">简而言之，<strong class="jb hj"> LSTM模型可以在一定时间内存储信息</strong>。由于LSTM的这一特性，在处理时间序列或序列数据时，使用LSTM非常有用。当然，由于本文是时间序列文章系列的一部分，对LSTM的深入解释超出了本文的范围。但是它的使用可以给你一些思路。</p><h2 id="8a48" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">首选和可能的激活功能</h2><p id="2b33" class="pw-post-body-paragraph iy iz hi jb b jc lc je jf jg ld ji jj kp le jm jn kt lf jq jr kx lg ju jv jw hb bi translated">当我们知道预测的是什么时，我们偏好的激活函数其实是可以自发出现的。如果我们在这个阶段想在没有知识的情况下继续，它会以一种增加训练时间的方式返回给我们。例如，一个sigmoid很适合作为分类器，我们可以通过查看sigmoid的图形来最简单地理解它。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/e1e5772c5c074837e4efd2cc4570e87f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*KD-hSrlQAWJI4jRw.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">来自<a class="ae iu" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank">https://en.wikipedia.org/wiki/Sigmoid_function</a>的Sigmoid函数图</figcaption></figure><p id="cb1d" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">另一方面，如果我们想变得简单，ReLU在计算上比tanh和sigmoid更容易，因为它包括更简单的数学运算，并且需要更少的功率。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div role="button" tabindex="0" class="ik il di im bf in"><div class="er es md"><img src="../Images/f9a0c9cd122d7a615323b403b4b9b481.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*sR0hAReMWiG_Czp5.png"/></div></div><figcaption class="iq ir et er es is it bd b be z dx translated">ReLU函数图来自<a class="ae iu" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="noopener ugc nofollow" target="_blank">https://en . Wikipedia . org/wiki/Rectifier _(neural _ networks)</a></figcaption></figure></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="7dee" class="lh kf hi bd kg li lj lk kk ll lm ln ko lo lp lq ks lr ls lt kw lu lv lw la lx bi translated">所以让我们开始吧</h1><h2 id="afb4" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">0.加载和准备数据</h2><pre class="lz ma mb mc fd me mf mg mh aw mi bi"><span id="ee17" class="ke kf hi mf b fi mj mk l ml mm">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>import datetime as dt<br/><br/>from sklearn.preprocessing import MinMaxScaler<br/>from tensorflow.keras.models import Sequential<br/>from tensorflow.keras.layers import Dense, Dropout, LSTM<br/><br/># Load Data<br/>florida = pd.read_csv('github/florida_file_.csv')<br/>florida.head()<br/>florida.tail(5)<br/>florida["Date"] = pd.to_datetime(florida["Date"])<br/><br/>florida = florida[["Date", "Avg_Temp"]]<br/># florida = florida["Avg_Temp"].resample('MS').mean()<br/>florida = florida.fillna(florida.bfill())<br/>florida.columns = ['Date', 'Avg_Temp']<br/><br/>train = florida[:-225]<br/>len(train)<br/>test = florida[-225:]<br/>len(test)<br/>train_dates = pd.to_datetime(train['Date'])<br/>test_dates  = pd.to_datetime(test['Date'])</span></pre><p id="317a" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">在安装了所需的库并加载了数据之后，我执行了分离。在这里，测试数据集将是我保留在最后使用的数据，以使用我将通过模型预测的值。我以后会把训练数据集分成x_train和y_train，但在这之前，我会对数据进行缩放。(在处理神经网络时，缩放数据非常重要，这种模型大大缩短了训练时间。)</p><h2 id="cfbb" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">1.准备数据</h2><pre class="lz ma mb mc fd me mf mg mh aw mi bi"><span id="8f61" class="ke kf hi mf b fi mj mk l ml mm">scaler = MinMaxScaler(feature_range=(0,1))<br/>scaled_data = scaler.fit_transform(train['Avg_Temp'].values.reshape(-1,1))<br/><br/>prediction_days = 225<br/><br/>x_train = []<br/>y_train = []<br/><br/>for x in range(prediction_days, len(scaled_data)):<br/>    x_train.append(scaled_data[x-prediction_days:x, 0])<br/>    y_train.append(scaled_data[x, 0])<br/><br/><br/>x_train, y_train = np.array(x_train), np.array(y_train)<br/>x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))</span></pre><p id="0f42" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">在将数据集中的所有值调整到0到1之间之后，我指定了要预测的天数。在这个值之后，我将数据分离为x_train和y_train。对于我们给定的值225，该模型将以这样的方式工作，即它检查225个数据并预测下一个数据，然后再次检查225个数据并尝试预测下一个数据。</p><p id="523f" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">填充列表后，我们将它们转换成NumPy数组。然后我们重塑x_train，让x_train可以和神经网络一起工作。</p><h2 id="ee5a" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">3.建立模型</h2><pre class="lz ma mb mc fd me mf mg mh aw mi bi"><span id="3754" class="ke kf hi mf b fi mj mk l ml mm">model = Sequential()<br/><br/>model.add(LSTM(units =128, activation='relu', return_sequences=True, input_shape = (x_train.shape[1],1)))<br/>model.add(Dropout(0.2))<br/>model.add(LSTM(units =128, activation='relu', return_sequences=True))<br/>model.add(Dropout(0.2))<br/>model.add(LSTM(units =128, activation='relu', return_sequences=False))<br/>model.add(Dropout(0.2))<br/>model.add(Dense(units=1)) # Prediction of the next value</span></pre><p id="1738" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">在这一步，我们建立我们的模型，因为它是一个基本的神经网络，我们直接建立一个序列模型。在这里，在选择LSTM层后，我应用了Dropout来提高效率并消除无用的节点，这样在每个LSTM层后，我不会将性能最差的节点移到下一步。在这里，我已经消除了20%的节点总数。</p><p id="a64e" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">这里注意！！！我们必须将input_shape值赋予我们的第一个LSTM层，因为我们的模型不知道它将处理的数据的大小，我们不需要在接下来的步骤中输入该值。在最后一步中，我返回了具有密集层的单个值，因此这个估计值将是我们的模型预测的平均温度。</p><pre class="lz ma mb mc fd me mf mg mh aw mi bi"><span id="ed67" class="ke kf hi mf b fi mj mk l ml mm">model.compile(optimizer='adam', loss='mean_squared_error')<br/>model.summary()<br/><br/>history = model.fit(x_train, y_train, epochs = 25, batch_size=32, validation_split=0.1)</span></pre><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es mn"><img src="../Images/ff1023a5e6a1c5682400582015234d6f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1390/format:webp/1*_RRZzt0F3O44ST27vnRN5w.png"/></div></figure><p id="d152" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">然后，我们编译我们的模型，我们准备测试数据集，我们的模型将看到完整的模型。最后，我们重塑x_test，并将其转换为适合我们模型的格式。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/fb48776a1eeaabb2a8b1e46eed366423.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*wJHnta24jM-k--jYLVI5bA.png"/></div></figure><h2 id="29d2" class="ke kf hi bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb bi translated">4.预言；预测；预告</h2><pre class="lz ma mb mc fd me mf mg mh aw mi bi"><span id="2f66" class="ke kf hi mf b fi mj mk l ml mm">actual_temp = test['Avg_Temp'].values<br/>total_temp = pd.concat((train['Avg_Temp'], test['Avg_Temp']),axis=0)<br/><br/>model_inputs = total_temp[len(total_temp)-len(test)-prediction_days:].values<br/>model_inputs = model_inputs.reshape(-1,1)<br/>model_inputs = scaler.transform(model_inputs)<br/><br/><br/># Make Predictions on Test Data<br/>x_test = []<br/><br/>for x in range(prediction_days, len(model_inputs)):<br/>    x_test.append(model_inputs[x-prediction_days:x, 0])<br/><br/>x_test = np.array(x_test)<br/>x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))<br/><br/>pred = model.predict(x_test)<br/>pred = scaler.inverse_transform(pred)</span></pre><p id="59fa" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">然后，我们对模型执行预测操作。然后，我们用inverse_transform操作对这些估计值进行归一化，以便将这些预测值与我们拥有的实际值进行比较。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es mp"><img src="../Images/f7bec3a6856ac39d601e1635de5b2b69.png" data-original-src="https://miro.medium.com/v2/resize:fit:1314/format:webp/1*FalIdyuVeCYm_2CqCXZchQ.png"/></div></figure><p id="e195" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">考虑到我们的纪元值是一个低值，可以说我们的模型成功处于可接受的水平。</p><figure class="lz ma mb mc fd ij er es paragraph-image"><div class="er es mo"><img src="../Images/7e0fb83a043b2c766b6176bd910a0fb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*ERm0J8SnRHM5eLy2mhnhDQ.png"/></div></figure></div><div class="ab cl jx jy gp jz" role="separator"><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc kd"/><span class="ka bw bk kb kc"/></div><div class="hb hc hd he hf"><h1 id="3b38" class="lh kf hi bd kg li lj lk kk ll lm ln ko lo lp lq ks lr ls lt kw lu lv lw la lx bi translated">参考</h1><p id="8105" class="pw-post-body-paragraph iy iz hi jb b jc lc je jf jg ld ji jj kp le jm jn kt lf jq jr kx lg ju jv jw hb bi translated">[1]https://www.veribilimiokulu.com<a class="ae iu" href="https://www.veribilimiokulu.com/bootcamp-programlari/veri-bilimci-yetistirme-programi/" rel="noopener ugc nofollow" target="_blank"/></p><p id="089d" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">[2]<a class="ae iu" href="https://www.analyticsvidhya.com/blog/2020/10/how-to-create-an-arima-model-for-time-series-forecasting-in-python/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2020/10/how-to-create-an-ARIMA-model-for-time-series-forecasting-in-python/</a></p><p id="8147" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">[3]<a class="ae iu" href="https://www.statisticssolutions.com/time-series-analysis/" rel="noopener ugc nofollow" target="_blank">https://www.statisticssolutions.com/time-series-analysis/</a></p><p id="69ad" class="pw-post-body-paragraph iy iz hi jb b jc jd je jf jg jh ji jj kp jl jm jn kt jp jq jr kx jt ju jv jw hb bi translated">[4]<a class="ae iu" href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/keras/layers/LSTM</a></p></div></div>    
</body>
</html>