<html>
<head>
<title>Machine Learning Linear Regression project from scratch (without library)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从零开始的机器学习线性回归项目(无库)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-linear-regression-project-from-scratch-without-library-87294048020?source=collection_archive---------7-----------------------#2021-03-12">https://medium.com/analytics-vidhya/machine-learning-linear-regression-project-from-scratch-without-library-87294048020?source=collection_archive---------7-----------------------#2021-03-12</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="b177" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">线性回归是一种受监督的机器学习，用于预测一定范围内的值，而不是将它们分类。</p><blockquote class="jc jd je"><p id="e802" class="ie if jf ig b ih ii ij ik il im in io jg iq ir is jh iu iv iw ji iy iz ja jb ha bi translated">在本文中，您可以找到一元线性回归在Python中的实现，而无需使用任何机器学习库。代码将一步一步地用提供的数学背景解释。</p></blockquote><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es jj"><img src="../Images/da9c2fde47a56cecac80e46b8870ec90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OuM_T_KZ6OHOBXy8VvvjWQ.png"/></div></div></figure><h1 id="2f19" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">概要</strong></h1><ul class=""><li id="165c" class="kt ku hh ig b ih kv il kw ip kx it ky ix kz jb la lb lc ld bi translated">理论背景</li><li id="dc10" class="kt ku hh ig b ih le il lf ip lg it lh ix li jb la lb lc ld bi translated">Python代码</li><li id="508d" class="kt ku hh ig b ih le il lf ip lg it lh ix li jb la lb lc ld bi translated">摘要</li></ul><h1 id="2563" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak">背景</strong></h1><p id="7a6a" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">你可能认为，“我可以在不知道发动机如何工作的情况下驾驶汽车”。是的，你是对的。但是，如果你在高速公路上行驶时，发动机出现了简单的故障，该怎么办呢？等待服务几个小时还是自己在几分钟内解决问题？同样的事情也适用于机器学习算法。如果你了解背景，你会自己解决问题，甚至可能发明一个更好的引擎。</p><p id="3e02" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">了解任何算法背后的数学将会给你100%的控制权。在建立机器学习模型时，您可能需要修改算法，以便从提供给您的数据中获得最佳模型。在这种情况下，了解算法如何在后台工作以进行任何改进是至关重要的。</p><p id="2c23" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我已经发表了两篇关于线性回归背后的数学理论的论文。第一个是单变量线性回归，用简单的例子解释了算法的基础。从一元线性回归开始是一个好的做法，因为它是线性回归的最简单版本。在你获得了基本信息之后，你可以看看第二篇论文——多元线性回归。MLR的概念与ULR相同，但它用于更复杂的数据集(多个输入要素):</p><ol class=""><li id="6127" class="kt ku hh ig b ih ii il im ip lm it ln ix lo jb lp lb lc ld bi translated"><a class="ae lq" rel="noopener" href="/analytics-vidhya/machine-learning-univariate-linear-regression-1acddb85aa0b">一元线性回归</a>——需要开始的基本信息。</li></ol><p id="2b5f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.<a class="ae lq" rel="noopener" href="/analytics-vidhya/machine-learning-multivariate-linear-regression-8f9878c0f56f">多元线性回归</a> —线性回归的更复杂形式。</p><h1 id="efcf" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated"><strong class="ak"> Python代码</strong></h1><p id="7e00" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">代码将分为两部分。第一部分将是关于如何阅读和可视化数据集。在我们完成这一部分后，函数(成本函数，梯度下降等。)的算法将被编写。</p><blockquote class="jc jd je"><p id="3383" class="ie if jf ig b ih ii ij ik il im in io jg iq ir is jh iu iv iw ji iy iz ja jb ha bi translated">在一步步深入代码之前，我想提一下，你可以在<a class="ae lq" href="https://github.com/anarabiyev/Machine-Learning-Linear-Regression-from-scratch-without-library-" rel="noopener ugc nofollow" target="_blank">我的github账户</a>中找到所有的代码和数据集。</p></blockquote><h2 id="fd23" class="lr jw hh bd jx ls lt lu kb lv lw lx kf ip ly lz kj it ma mb kn ix mc md kr me bi translated"><strong class="ak">第一部分。读取和可视化数据集</strong></h2><p id="106d" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">要建立任何机器学习模型，你需要一个数据集，而要建立一个成功的模型，你需要可视化数据集，以便更好地进行分析。因为可视化将使您对数据有清晰的理解，并帮助您对使用哪种算法有初步的想法。</p><p id="f428" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据集提供为<strong class="ig hi"> csv </strong> <em class="jf"> </em>文件，<strong class="ig hi">熊猫</strong>库用于读取csv文件。read_csv函数将数据集写入名为“data”的变量中。</p><p id="95a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">head()函数返回数据集的前5行。</p><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="1acb" class="lr jw hh mg b fi mk ml l mm mn">import pandas as pd                       <br/>data = pd.read_csv("train.csv")      #reading csv<br/>print(data.head())                   #returns first 5 row of dataset</span><span id="4479" class="lr jw hh mg b fi mo ml l mm mn">Output:<br/>    x          y<br/>0  24  21.549452<br/>1  50  47.464463<br/>2  15  17.218656<br/>3  38  36.586398<br/>4  87  87.288984</span></pre><p id="9c8f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><em class="jf">注意:</em>请记住，py和csv文件应该在同一个目录中，以编写上述代码，否则您必须复制存储csv文件的完整路径:</p><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="67fb" class="lr jw hh mg b fi mk ml l mm mn">data = pd.read_csv(r"Full path\Filename.csv")</span></pre></div><div class="ab cl mp mq go mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ha hb hc hd he"><p id="4231" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">读取csv文件后，x和y值应该作为单独的变量存储，以便能够使用它们。这可以通过多种方式实现，例如，使用<strong class="ig hi"> iloc </strong>和<strong class="ig hi">loc</strong>(pandas的函数)，直接写入列名(我们将在本例中使用)等等。</p><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="d2e2" class="lr jw hh mg b fi mk ml l mm mn">X = data['x']<br/>Y = data['y']</span></pre><p id="26fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在上面这里，X和Y变量的类型是熊猫系列。Pandas系列是比numpy数组和python列表更复杂的数据结构。这就是为什么它需要更多的时间来操作熊猫系列。为此，我们将熊猫系列中的X和Y转换为python列表:</p><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="b2d3" class="lr jw hh mg b fi mk ml l mm mn">X = X.tolist()<br/>Y = Y.tolist()</span></pre></div><div class="ab cl mp mq go mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ha hb hc hd he"><p id="7e17" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了可视化，使用了matplotlib库。它有广泛的功能来定制一个情节。在这个例子中，我将使用其中的一些。有关matplotlib的更多信息，请查看参考资料中的链接。</p><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="0ba4" class="lr jw hh mg b fi mk ml l mm mn">import matplotlib.pyplot as plt<br/>plt.scatter(X, Y)<br/>plt.grid()<br/>plt.xlabel("x values")<br/>plt.ylabel("y values")<br/>plt.show()</span></pre><p id="2cd1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">输出:</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es mw"><img src="../Images/a33fe41ba654f84ed0992e50ca4c21fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*jxahG5cvnbSgEG3NmEq1kg.png"/></div></figure><p id="de32" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">图中的每个点代表数据集中的一个样本。从输出可以看出，线性回归算法非常适合这个数据集。</p></div><div class="ab cl mp mq go mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ha hb hc hd he"><h2 id="c861" class="lr jw hh bd jx ls lt lu kb lv lw lx kf ip ly lz kj it ma mb kn ix mc md kr me bi translated"><strong class="ak">第二部分。算法主体</strong></h2><p id="e061" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">注意:在这一节中，我将简要地谈论函数，对于每个函数的详细的数学解释，你可以看看我上面提到的文章或者你可以在参考文献中找到它们。</p><p id="bfae" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当我们开始编码算法的主体时，最好提一下变量代表什么。请记住，假设(直线方程)是:</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es mx"><img src="../Images/3adb097358b9377030509afeae2a5b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:476/format:webp/1*AtRJLsnG1SdXIt3HKVTnPQ.png"/></div></figure><p id="ad34" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">除此之外，alpha是学习速率，n_iter是迭代次数。</p></div><div class="ab cl mp mq go mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ha hb hc hd he"><p id="22e0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">成本函数</strong></p><p id="6f25" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">成本函数也叫损失函数。它用于计算直线与数据的拟合程度。成本函数值越小，解决方案越好-如果所有样本都在线上，成本函数值将为零，如果样本远离线，成本函数值将返回高值。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="er es my"><img src="../Images/febe02aea0cededeafb11943883c8789.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*SpO27LICEi79ru3F_VujXg.png"/></div></div></figure><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="1cf1" class="lr jw hh mg b fi mk ml l mm mn">def cost_function (X, Y, w, b):</span><span id="236c" class="lr jw hh mg b fi mo ml l mm mn">N = len(X)<br/>    total_error = 0.0<br/>    for i in range(N):<br/>        total_error += ((w*X[i] - b) - Y[i])**2</span><span id="e1eb" class="lr jw hh mg b fi mo ml l mm mn">    return total_error / (2*float(N))</span></pre><p id="d661" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">梯度下降</strong></p><p id="a510" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们以w和b的随机初始值(通常为零)开始算法，因此成本函数将返回一些高值。所以我们必须以某种方式优化w和b，以减少成本函数的回报。梯度下降是以这种方式使用的算法。在每次迭代中，梯度下降算法更新w和b的值，并且线更好地拟合数据。</p><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es mz"><img src="../Images/056906af58a193afad2d23ff156a8bf0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1040/format:webp/1*U7Z70U704IYASZF_ECRstA.png"/></div></figure><figure class="jk jl jm jn fd jo er es paragraph-image"><div class="er es na"><img src="../Images/86f0ed408c15fa00cc5b6615c19f4cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*wZ1BF-A3narHtaeeUU6w4Q.png"/></div></figure><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="a773" class="lr jw hh mg b fi mk ml l mm mn">#alpha - learning rate<br/>#N - number of samples in the dataset</span><span id="2f73" class="lr jw hh mg b fi mo ml l mm mn">def gradient_descent(X, Y, w, b, alpha):<br/> <br/>    dl_dw = 0.0       <br/>    dl_db = 0.0       <br/>    N = len(X)</span><span id="a435" class="lr jw hh mg b fi mo ml l mm mn">    for i in range(N):<br/>        dl_dw += -1*X[i] * (Y[i] - (w*X[i] + b))<br/>        dl_db += -1*(Y[i] - (w*X[i] + b))</span><span id="e7d6" class="lr jw hh mg b fi mo ml l mm mn">    w = w - (1/float(N)) * dl_dw * alpha<br/>    b = b - (1/float(N)) * dl_db * alpha</span><span id="2693" class="lr jw hh mg b fi mo ml l mm mn">    return w, b</span></pre><p id="833e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">列车功能</strong></p><p id="537b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在算法期间，梯度下降运行多次，准确地说，是在迭代次数上。在一些迭代之后，成本函数的值降低，并且看到成本函数的值是好的实践。因为在某一点之后，成本函数值不变或变化极小。这就是为什么，在那个点之后一遍又一遍地运行梯度下降是没有用的，并且你在下一次尝试中减少了迭代的次数。</p><p id="92f4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此，我们将所有这些操作结合起来，定义迭代次数，选择在多少次迭代后(在本例中，在每400次迭代中)您希望看到成本函数的返回，将梯度下降函数称为一个函数，该函数称为训练函数。</p><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="4075" class="lr jw hh mg b fi mk ml l mm mn">def train(X, Y, w, b, alpha, n_iter):</span><span id="4219" class="lr jw hh mg b fi mo ml l mm mn">    for i in range(n_iter):<br/>        w, b = gradient_descent(X, Y, w, b, alpha)</span><span id="32ba" class="lr jw hh mg b fi mo ml l mm mn">        if i % 400 == 0:<br/>            print("iteration:", i, "cost: ", cost_function(X,Y,w,b))</span><span id="0787" class="lr jw hh mg b fi mo ml l mm mn">    return w, b</span></pre><p id="fc52" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">预测功能</strong></p><p id="a193" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">预测函数是线性回归函数中最简单的一个。它只是在梯度下降找到w和b之后，计算并返回y和相应x的值。</p><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="d182" class="lr jw hh mg b fi mk ml l mm mn">def predict(x, w, b):<br/>    return x*w + b</span></pre><p id="f360" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">如何调用函数</strong></p><p id="769b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">由于训练函数本身包含梯度下降函数，只调用训练函数就足够了:</p><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="d17d" class="lr jw hh mg b fi mk ml l mm mn">w, b = train(X, Y, 0.0, 0.0, 0.0001, 7000)</span></pre><p id="ae05" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里，</p><ul class=""><li id="ccda" class="kt ku hh ig b ih ii il im ip lm it ln ix lo jb la lb lc ld bi translated">0.0s是w和b的初始值；</li><li id="3c9d" class="kt ku hh ig b ih le il lf ip lg it lh ix li jb la lb lc ld bi translated">0.0001是学习率(可以根据你的数据集增减学习率)；</li><li id="3a6c" class="kt ku hh ig b ih le il lf ip lg it lh ix li jb la lb lc ld bi translated">7000是迭代次数</li></ul></div><div class="ab cl mp mq go mr" role="separator"><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu mv"/><span class="ms bw bk mt mu"/></div><div class="ha hb hc hd he"><p id="466a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">训练函数返回w和b的值后，您可以借助预测函数检查您的结果:</p><pre class="jk jl jm jn fd mf mg mh mi aw mj bi"><span id="07a2" class="lr jw hh mg b fi mk ml l mm mn">x_new = 50.0<br/>y_new = predict(x_new, w, b)<br/>print(y_new)</span></pre><h1 id="b1e1" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">摘要</h1><p id="d1af" class="pw-post-body-paragraph ie if hh ig b ih kv ij ik il kw in io ip lj ir is it lk iv iw ix ll iz ja jb ha bi translated">综上所述，监督机器学习的算法范围很广。线性回归是主要使用的方法之一。在本文中，我们从头开始研究了如何使用Python代码实现它。代码的各个部分被逐一解释，背景参考资料来自我以前的文章。</p><p id="6c57" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">下一篇论文将讲述如何使用sklearn库实现线性回归。</p><h1 id="4551" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">参考</h1><ul class=""><li id="b2d4" class="kt ku hh ig b ih kv il kw ip kx it ky ix kz jb la lb lc ld bi translated"><a class="ae lq" rel="noopener" href="/analytics-vidhya/machine-learning-univariate-linear-regression-1acddb85aa0b">一元线性回归</a></li><li id="5ef1" class="kt ku hh ig b ih le il lf ip lg it lh ix li jb la lb lc ld bi translated"><a class="ae lq" rel="noopener" href="/analytics-vidhya/machine-learning-multivariate-linear-regression-8f9878c0f56f">多元线性回归</a></li><li id="147b" class="kt ku hh ig b ih le il lf ip lg it lh ix li jb la lb lc ld bi translated"><a class="ae lq" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html" rel="noopener ugc nofollow" target="_blank"> Matplotlib Pyplot文档</a></li><li id="808f" class="kt ku hh ig b ih le il lf ip lg it lh ix li jb la lb lc ld bi translated"><a class="ae lq" href="https://github.com/anarabiyev/Machine-Learning-Linear-Regression-from-scratch-without-library-" rel="noopener ugc nofollow" target="_blank"> GitHub </a></li></ul><h1 id="2e7f" class="jv jw hh bd jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks bi translated">谢谢你。</h1></div></div>    
</body>
</html>