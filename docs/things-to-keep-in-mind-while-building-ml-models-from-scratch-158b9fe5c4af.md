# 从头开始构建 ML 模型时要记住的事情

> 原文：<https://medium.com/analytics-vidhya/things-to-keep-in-mind-while-building-ml-models-from-scratch-158b9fe5c4af?source=collection_archive---------20----------------------->

许多机器学习的初学者喜欢从 scikit-learn 库开始，我也不例外。但是他们往往会忘记从头开始构建模型的重要性。从头开始给你真正的答案。权重和特征怎么相乘？偏见呢？事实上，什么是偏见？如何执行乙状结肠功能？损失怎么算？如何找到权重的优化值？如果你有这些问题，那么你就在正确的轨道上，芽！而且是时候从头开始了！

因此，在做这件事的时候，你将拥有的最重要的工具之一就是 NumPy 库。这是一个非常强大的库，可以在任何时间计算繁重的计算。你可以把它想象成“数学”库，但是对于巨大的矩阵来说，它更加强大和庞大。

在这里，我不会讨论 NumPy 的基础知识，而是讨论在使用 NumPy 从头构建模型时证明对我有用的解决问题的技术。

## **秩 1 数组**

在确定数组的形状时，您经常会遇到类似于'(5，) '的东西。这被称为“秩 1 数组”。这既不像行向量，也不像列向量。所以，使用**断言**函数总是一个好习惯。该函数用于确定内部所述的条件是否为真。如果不是，它将引发一个我们不想要的 **AssertionError，**。为了更好地理解，请考虑以下示例:

```
import numpy as np
a = np.array([12,3,4,55,6])
```

乍一看，vector **a** 的形状看起来像(5，1)或者可能是(1，5)(上帝，我希望这不会变成另一个 Yammy/Laurel 困境，或者更糟，蓝色/黑色连衣裙！).

因为编程中的模糊性是什么？对吗？

因此，我们使用**断言**函数来确保它看起来是这样的:

```
assert(a.shape==(5,1))
```

上面的代码抛出了一个 **AssertionError。**这是因为矢量 **a** 的形状不是(5，1)。

```
print(a.shape)(5,)
```

这个问题的解决方案是:

```
a = a.reshape((5,1))
print(a.shape)
assert(a.shape==(5,1))(5, 1)
```

显示的输出没有引发任何错误。请随时使用**重塑**方法，即使它看起来是多余的，因为这可以创造奇迹！

同样，如果你好奇的话，向量 **a** 最终看起来像这样。

```
print(a)[[12]
 [ 3]
 [ 4]
 [55]
 [ 6]]
```

所以，我猜是‘劳蕾尔’。嗯，不要看太多，可能会变成‘Yammy’！

## 广播

有一个非常简单的概念叫做广播。简单地说，它告诉 NumPy 如何处理不同形状的数组。所以，如果你遇到了一个错误，说“操作数不能和 shapes (4，2) (2，2)一起传播”，那么你很幸运在这里。当我尝试执行以下操作时，会出现此错误:

```
mat1 = np.array([[1,2],
        [9,8],
        [3,4],
        [5,6]])
mat2 = np.array([[3,5],
                [10,2]])
ans = mat1 + mat2
```

如果 **mat1** 和 **mat2** 不是 NumPy 数组，而只是嵌套的列表， **mat2** 会被连接到 **mat1** ，结果会是这样:

```
[[1, 2], [9, 8], [3, 4], [5, 6], [3, 5], [10, 2]]
```

但是，既然是 NumPy，重点就在计算上。因此，两个不同阶的矩阵，即 **(4，2)** 阶的 **mat1** 和 **(2，2)** 阶的 **mat2** 不能相加。除了，当我这样做的时候:

```
mat1 = np.array([[1,2],
        [9,8],
        [3,4],
        [5,6]])
mat2 = np.array([[3,5]])
ans = mat1 + mat2
print(ans)[[ 4  7]
 [12 13]
 [ 6  9]
 [ 8 11]]
```

注意现在 **mat2** 的顺序，是 **(1，2)** 。我们在**和**得到结果，没有因为广播而有任何误差。简单来说， **mat2** 不断重复自己，直到它的顺序变得和 **mat1** 一样，并把自己加到 **mat1** 上，给出了上面的结果。因此，在矩阵中传播的条件是，其中一项必须是 1D 阵列(不，不是一个方向的带)或整数的向量。以下是整数运算:

```
mat1 = np.array([[1,2],
        [9,8],
        [3,4],
        [5,6]])
b = 12
ans = mat1 + b
print(ans)[[13 14]
 [21 20]
 [15 16]
 [17 18]]
```

这一概念将被证明是有用的，同时将偏差添加到矩阵中，该矩阵是特征矩阵和权重矩阵的点积。

## 点积

如果你来自非数学背景，点积可能会让你有点困惑。为了简单起见，本文将只讨论它的编码部分。点积是矩阵的乘法，只有当第一个**矩阵的列数等于第二个**矩阵的行数时才会发生。这是必要的，因为乘法发生在第**第一**矩阵的行和第**第二**矩阵的相应列之间。因此，**结果**矩阵的行数与第**第一**矩阵的行数相同，**结果**矩阵的列数等于第**第二**矩阵的列数。例如:****

```
first = np.array([[2,2],[5,6],[4,3],[3,1]])
second = np.array([[3,7,1],[5,5,2]])
print(first.shape, second.shape)(4, 2) (2, 3)
    ------
```

注意，他们之间的共同点。

猜测**结果**矩阵的顺序。正确！是(4，3)。

```
import numpy
result = np.dot(first,second)
print(result)[[16 24  6]
 [45 65 17]
 [27 43 10]
 [14 26  5]]
```

> 我们使用了 **np.dot()** ，因为它是矩阵乘法。使用' *** '** 到乘法会导致我们之前讨论过的广播错误。

在解决问题时，可能会给你一个输入特征矩阵 **X** 的阶数，比如说(5，3)，以及一个权重矩阵 **w** 的阶数(1，3)。立刻，看起来他们的点积是不可能的，但是如果我们使用 **w** 的转置呢？这将使 **w** 的形状变为(3，1)。

让我举个例子:

```
X = np.array([[1,2,3], 
              [6,5,4], 
              [7,8,9],
              [12,11,10],
              [13,14,15]])w = np.array([[2,6,4]])
w_tp = w.T
output = np.dot(X,w_tp)
print(output)[[ 26]
 [ 58]
 [ 98]
 [130]
 [170]]
```

**w_tp** 存储 **w** 的转置，即:

```
print(w_tp)[[2]
 [6]
 [4]]
```

你也可以使用 **np.transpose(w)** 找到 **w.** 的转置

**最后**但绝对不是最不重要的，从零开始制作东西需要时间。但是，在你看到你的模型给出了 60%的准确率之后(*暗暗痛哭*)这一切都是值得的。

![](img/04e6a46d2ee6b3c2ed2fb602ec189aeb.png)

> 感谢您的阅读！希望你觉得有用:)