<html>
<head>
<title>NBA Machine Learning Position Predictor</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">NBA机器学习位置预测器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/nba-machine-learning-position-predictor-488fef42ac1c?source=collection_archive---------5-----------------------#2021-02-02">https://medium.com/analytics-vidhya/nba-machine-learning-position-predictor-488fef42ac1c?source=collection_archive---------5-----------------------#2021-02-02</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/74782c7974717f8db855c5329f19a354.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*viwJbrU57FvtSymiR0T_bA.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">NBA比以往任何时候都更加“无位置”:机器学习模型还能准确预测NBA球员的位置吗？</figcaption></figure><p id="a6aa" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这个用Python写的机器学习例子，使用了15个赛季(2005-2020)的NBA球员统计数据(特征)，来预测每个球员的位置(目标)。机器学习模型包括决策树、随机森林、支持向量机和梯度提升。还包括X数据的示例PCA变换。</p><p id="1d6b" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">从Basketball-Reference.com获得的CSV数据集</p><figure class="js jt ju jv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es jr"><img src="../Images/6d507474a16fc6979e0c8e263ab32476.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*W4_3BhgPNUsOuM_yslKOwg.gif"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">最终，你可以建立一个机器学习模型，在这个模型中，你可以输入你自己假设的NBA统计数据，并查看模型预测的位置。</figcaption></figure><h1 id="5bd0" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">数据预处理:</h1><p id="d08b" class="pw-post-body-paragraph it iu hh iv b iw ku iy iz ja kv jc jd je kw jg jh ji kx jk jl jm ky jo jp jq ha bi translated">预处理主要包括清理数据和过滤数据集，只显示符合特定标准的球员。每一季都作为一个单独的CSV文件读入，然后连接成一个我可以使用的单一数据帧。接下来，我过滤了数据框架，只包含了至少打了820分钟/赛季的球员(10分钟/场* 82场/赛季)。我这样做是因为包含少于这个可接受的比赛分钟数的行将会不公平地扭曲数据。例如，如果一个球员只为一个队打了1分钟，得了2分，那么他每36分钟的得分就是72分；显然这不是一个公平的代表。</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="6c65" class="le jx hh la b fi lf lg l lh li">original_df = original_df[original_df.MP &gt;= 820]</span></pre><p id="5565" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">然后，我将数据帧切片，只包含相关特征(删除姓名、年龄和团队等列；实际上不是玩家统计数据并且对玩家的位置没有影响的特征)。下一步是将混合位置，如“C-PF”和“PF-SF”转换为5种主要篮球位置之一:</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="49d9" class="le jx hh la b fi lf lg l lh li">df = df.replace("C-PF","C")</span></pre><p id="e314" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">对每个组合都这样做。最后要做的是将所有列四舍五入到两位小数:为了简单起见，这里只显示了一个转换:</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="045e" class="le jx hh la b fi lf lg l lh li">df = df.round({'PTS': 2})</span></pre><p id="27b5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">对每一列都这样做。我最初的数据帧由7089行和29列组成；在过滤掉玩家和不相关的列之后，我只剩下一个4051行21列的数据框架。这意味着我的模型要处理4051行玩家统计数据，以及模型要测试的20个特性(20个特性，1个目标列)。以下是数据帧的示例，仅显示了5行，但所有列都是:</p><figure class="js jt ju jv fd ii er es paragraph-image"><div class="er es lj"><img src="../Images/2f24c1a71527c81a32c1845fb54c11e6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/0*XeRw6PpAa6cERZYR"/></div></figure><p id="61ae" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">为了确认目标类是均匀分布的，并且不需要进行重新平衡，我检查了每个位置的唯一值的数量:</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="883c" class="le jx hh la b fi lf lg l lh li">df.loc[:, 'Pos'].value_counts()</span></pre><p id="52ea" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">SG:947<br/>PG:873<br/>PF:814<br/>SF:809<br/>C:608</p><p id="a41a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">位置分布均匀。我们现在已经完成了数据预处理，可以开始认真研究模型了。</p></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h1 id="5d4a" class="jw jx hh bd jy jz lr kb kc kd ls kf kg kh lt kj kk kl lu kn ko kp lv kr ks kt bi translated">模型前可视化:</h1><h1 id="87f5" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">按职位汇总统计数据:</h1><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="e8c7" class="le jx hh la b fi lf lg l lh li">summary_df = df.groupby('Pos').mean()</span></pre><figure class="js jt ju jv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lw"><img src="../Images/4d6490f449625d19b0b780832e3f1b2d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*nHV0hm3Lxq-cVSRZ"/></div></div></figure><p id="04e1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们可以从上面的图表中收集有用的信息。我们看到，就得分而言，每个位置都没有太大的差别:每个位置平均15分/36分钟。然而，我们在几个类别中看到了严重的差异，这是我们所期望的；最多的就是TRB(总篮板)和AST(助攻)。控球后卫带球上场并分配球，导致助攻(PGs平均6.2次助攻，Cs平均2.1次助攻)，中锋更高，承担更多的篮板责任(Cs平均10.1个篮板，PGs平均3.9个篮板)。这给出了一个很好的想法，关于在模型中期望什么，特别是在模型认为什么是帮助确定玩家位置的最重要的特征方面。</p><h1 id="86bb" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">条形图:</h1><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="eaf9" class="le jx hh la b fi lf lg l lh li">bar_chart_df = summary_df[['PTS', 'TRB', 'AST', 'STL', 'BLK']]<br/>bar_chart_df.plot(kind='bar', figsize = (12, 8), title='Bar Chart of Main Stats across all 5 Positions')</span></pre><figure class="js jt ju jv fd ii er es paragraph-image"><div class="er es lx"><img src="../Images/da109622eed3d8aabb1b50bf867e8710.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/0*GVXvrb1HAe3jhh6W"/></div></figure><p id="e8ab" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这个简单的条形图显示了五个主要的篮球统计数据——得分、篮板、助攻、抢断和盖帽——以及它们在五个位置上的分布情况。如上所述，每个位置的得分/36分钟没有太大的不同；但是，篮板和助攻的差异很大。我们还可以在黄色部分看到，中锋平均比其他位置多得多的盖帽，一般来说盖帽很难获得，所以中锋平均只有1.6个盖帽/36分钟，控球后卫平均只有0.26个盖帽/36分钟，这意味着在这个特定的数据集中，中锋平均比控球后卫多144%的盖帽/36分钟。这个特性可能被即将到来的模型认为是更重要的特性之一。</p><h1 id="ca19" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">Seaborn对图:</h1><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="648d" class="le jx hh la b fi lf lg l lh li">sns_df = df[['PTS', 'TRB', 'AST', 'STL', 'BLK', 'Pos']].head(300)<br/>sns_df = sns_df.reset_index()<br/>sns_df = sns_df.drop('index', axis=1)</span><span id="ff04" class="le jx hh la b fi ly lg l lh li">sns_plot = sns.pairplot(sns_df, hue='Pos', size=2)<br/>sns_plot</span></pre><figure class="js jt ju jv fd ii er es paragraph-image"><div class="er es lz"><img src="../Images/7f31620e2080511569da207f978c759a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*kXEyb3sJmoS5p_VjSOQ3Aw.png"/></div></figure><p id="17d0" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这里我们看到了所有可能的x/y轴组合的散点图。我注意到的第一件事是这些图表中的总体正相关，也就是说，随着x轴值的增加，y轴值也会增加。这对我来说很有意义，因为它告诉我，一个玩家在一个特定的类别上越好，他们在其他统计类别上也很好(好的玩家不只是做好一件事)。然而，对于TRB和AST来说，似乎相反:一般来说，一个球员的助攻越多，或者篮板越多，他的其他属性就越少。</p><p id="8a40" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">对角线让我们深入了解每个变量的分布，按位置细分，它有助于按位置直观显示值的范围。例如，看看TRB与TRB的交叉点，我们看到中锋比其他位置有更长的尾巴，而对于AST指标，控卫比其他位置有更长的尾巴-更长的尾巴表明更广泛的分布，更广泛的数值范围)。虽然大多数类别的分布各不相同，但PTS在所有五个职位中的分布保持相对稳定。</p></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h1 id="ddd8" class="jw jx hh bd jy jz lr kb kc kd ls kf kg kh lt kj kk kl lu kn ko kp lv kr ks kt bi translated">模型设置:</h1><p id="c929" class="pw-post-body-paragraph it iu hh iv b iw ku iy iz ja kv jc jd je kw jg jh ji kx jk jl jm ky jo jp jq ha bi translated">在运行模型之前，还需要执行一些特定于模型的步骤。这包括:</p><ol class=""><li id="686c" class="ma mb hh iv b iw ix ja jb je mc ji md jm me jq mf mg mh mi bi translated">将数据框拆分为一个仅包含要素(X变量)的数据框和一个仅包含目标列(y变量，模型将预测的内容)的数据框。按照惯例，X变量是大写的，而y变量是小写的。</li></ol><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="0275" class="le jx hh la b fi lf lg l lh li">X = df.drop('Pos', axis=1)<br/>y = df.loc[:, 'Pos']</span></pre><p id="b3c9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">2.手动编码y标签，使其在评估过程中对混淆矩阵更有意义:</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="8178" class="le jx hh la b fi lf lg l lh li">position_dictionary = {<br/>"PG": 1,<br/>"SG": 2,<br/>"SF": 3,<br/>"PF": 4,<br/>"C": 5}<br/>y = y.map(position_dictionary).values.reshape(-1,1)</span></pre><p id="ef30" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">3.将X和y分割成X_train、X_test、y_train、y_test，并检查每个的形状:</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="90b6" class="le jx hh la b fi lf lg l lh li">from sklearn.model_selection import train_test_split<br/>X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)</span></pre><p id="a135" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">将数据分成训练和测试数据集的目的是测试模型的准确性。您使用训练数据集(通常为数据的80%)来“训练”模型，然后使用测试数据集(通常为数据的20%)来“测试”模型的准确性。这为评估模型的性能提供了一种简单的方法。训练和测试数据帧的形状如下:</p><p id="cfbf" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">X_train: 3038行，20列<br/> y_train: 3038行，1列<br/> X_test: 1013行，20列<br/> y_test: 1013行，1列</p><p id="b23d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这意味着我们将使用包含20个特征/x变量的3038行数据来“训练”模型。我们将使用包含相同的20个特征/x变量的1013行数据来“测试”该模型。y数据集只包含一列(目标列，玩家的位置)，y_train比y_test包含更多的数据。</p><p id="4ace" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">4.缩放数据:</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="443f" class="le jx hh la b fi lf lg l lh li">from sklearn.preprocessing import StandardScaler<br/>scaler = StandardScaler()<br/>X_scaler = scaler.fit(X_train)</span><span id="5beb" class="le jx hh la b fi ly lg l lh li">X_train_scaled = X_scaler.transform(X_train)<br/>X_test_scaled = X_scaler.transform(X_test)</span></pre><p id="605a" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">缩放数据会改变数值的<em class="mj">范围</em>，而不会改变分布的形状。这样做是因为在我的数据集中，所有的列都不是相同的比例:例如，许多列是整数/浮点数(PTS、TRB、AST等。)而其他则用百分比表示(FG%、3P%、FT%等)。).缩放数据通常会使机器学习算法执行得更好/更快，因为要素的规模相对较小，并且呈正态分布。这最终会使模型更容易运行。</p><p id="1953" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">5.PCA变换X数据(不必要，例如，仅在模型中进行一次)</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="74bf" class="le jx hh la b fi lf lg l lh li">from sklearn.decomposition import PCA<br/>pca = PCA(n_components=3)<br/>X_pca = pca.fit(X_train_scaled)</span><span id="7940" class="le jx hh la b fi ly lg l lh li">X_train_pca = X_pca.transform(X_train_scaled)<br/>X_test_pca = X_pca.transform(X_test_scaled)</span><span id="9927" class="le jx hh la b fi ly lg l lh li">X_train_pca_df = pd.DataFrame(data = X_train_pca, columns = ["PC1", "PC2", "PC3"])<br/>X_test_pca_df = pd.DataFrame(data = X_test_pca, columns = ["PC1", "PC2", "PC3"])</span></pre><p id="4a4c" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">上面的代码生成了下面的数据集。</p><figure class="js jt ju jv fd ii er es paragraph-image"><div class="er es mk"><img src="../Images/05e81f4bd46bd77dfb7924009dffd7c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:426/0*MTP9b08ID8Iy--2W"/></div></figure><p id="dc35" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">X-data的PCA变换通常在大型数据集上执行，以便减少数据集中的维数，并使模型更容易运行。它会转换X数据集，这意味着您不再将原始要素作为列；它们现在被分成“主成分”，并且可以计算出一个解释的方差比率，它告诉你有多少解释的方差在数据集中被捕获——它有多大意义？对于这种大小的数据集，通常不使用X数据的PCA变换；这只是为了举例，并且只在一个数据集上执行。</p></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h1 id="0ddd" class="jw jx hh bd jy jz lr kb kc kd ls kf kg kh lt kj kk kl lu kn ko kp lv kr ks kt bi translated">创建、拟合和预测模型:</h1><h2 id="51be" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">测试了决策树、随机森林、支持向量机和梯度提升树。每个模型至少测试两次:一次使用所有20个特性，一次只使用模型本身认为最重要的5个特性。只有决策树被测试了三次(以显示PCA变换的例子以及它如何影响模型的性能)。</h2><h2 id="6d7a" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">请注意，模型是使用X_train_scaled和附带的y_train数据集“训练”的，而预测是基于X_test_scaled(模型尚未看到的数据)。</h2><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="5141" class="le jx hh la b fi lf lg l lh li"># Decision Trees:<br/>from sklearn import tree<br/>dt1_model = tree.DecisionTreeClassifier(random_state=1)<br/>dt1_model = dt1_model.fit(X_train_scaled, y_train)<br/>predictions = dt1_model.predict(X_test_scaled)</span><span id="15ed" class="le jx hh la b fi ly lg l lh li"># Random Forests:<br/>from sklearn.ensemble import RandomForestClassifier<br/>rf1_model = RandomForestClassifier(n_estimators=500, random_state=1)<br/>rf1_model = rf1_model.fit(X_train_scaled, y_train)<br/>predictions = rf1_model.predict(X_test_scaled)</span><span id="ecc3" class="le jx hh la b fi ly lg l lh li"># Support Vector Machines (SVMs):<br/>from sklearn import svm<br/>from sklearn.svm import SVC<br/>svm1_model = svm.SVC(kernel='linear', random_state=1)<br/>svm1_model = svm1_model.fit(X_train_scaled, y_train)<br/>predictions = svm1_model.predict(X_test_scaled)</span><span id="f995" class="le jx hh la b fi ly lg l lh li"># Gradient Boosted Trees (GBTs):<br/>from sklearn.ensemble import GradientBoostingClassifier<br/>gbt1_model = GradientBoostingClassifier(n_estimators=20, learning_rate=0.75, max_depth=3, random_state=1)<br/>gbt1_model = gbt1_model.fit(X_train_scaled, y_train)<br/>predictions = gbt1_model.predict(X_test_scaled)</span></pre><p id="e1e5" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">每个模型都是按照以下顺序依次运行的:首先，我测试了整个数据集，并确定了模型认为最重要/最相关的特性。然后我运行相同的模型，除了这一次，将我的特性限制在最重要的前5个(通过简单地删除dataframe中不需要的列并重新运行模型)。如上所述，对于决策树模型，包括了一个例子，其中I PCA变换X数据；其他型号不会这样做。</p><h1 id="8283" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">关于梯度增强树模型的注意事项:</h1><p id="9113" class="pw-post-body-paragraph it iu hh iv b iw ku iy iz ja kv jc jd je kw jg jh ji kx jk jl jm ky jo jp jq ha bi translated">梯度增强树模型中的一个关键参数是学习速率:模型学习的速度。一般来说，学习率越低，模型学习越慢，学习慢的模型表现更好。但这是有代价的——训练模型需要更多的时间，训练模型需要更多的树，这就产生了过度拟合的风险。为了确定哪个学习率是最好的，我创建了一个learning_rates列表，并运行了一个for循环来测试所有learning_rates的训练和测试数据集的准确性分数:</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="e96b" class="le jx hh la b fi lf lg l lh li">learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]<br/>for learning_rate in learning_rates:<br/>    gbt1_model = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=5, max_depth=3, random_state=0)</span><span id="55f5" class="le jx hh la b fi ly lg l lh li">    # Fit the model<br/>    gbt1_model.fit(X_train_scaled, y_train.ravel())<br/>    print("Learning rate: ", learning_rate)</span><span id="7105" class="le jx hh la b fi ly lg l lh li">    # Score the model<br/>    print("Accuracy score (training): {0:.3f}".format(<br/>        gbt1_model.score(<br/>            X_train_scaled,<br/>            y_train.ravel())))<br/>    print("Accuracy score (validation): {0:.3f}".format(<br/>        gbt1_model.score(<br/>            X_test_scaled,<br/>            y_test.ravel())))</span></pre><p id="bd41" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">运行它允许我为模型选择最佳的learning_rate。我选择learning_rate = 0.75，因为它具有训练准确性分数(84.7%)和测试准确性分数(68.3%)的最佳组合。</p></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h2 id="a62e" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">生成“特征重要性”表/图，以确定模型认为最重要/相关的5个特征，并在下一个模型中仅使用这5个特征与之前的模型(使用了所有20个特征)进行比较:</h2><h2 id="e0b0" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">决策树、随机森林和梯度提升树的特征重要性表可以通过使用简单的“model.feature_importances_”函数来生成:</h2><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="b826" class="le jx hh la b fi lf lg l lh li">model_importances = pd.DataFrame(model.feature_importances_, index = X_train.columns, columns=['Importance']).sort_values('Importance', ascending=False)</span></pre><p id="58a9" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">上面的代码生成以下特征重要性表，这是决策树1的表:</p><figure class="js jt ju jv fd ii er es paragraph-image"><div class="er es my"><img src="../Images/dfe8669609727408596d81613e1d28b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:256/0*mqRVpdbvbxb3jJ43"/></div></figure><p id="9890" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们可以在这个例子中看到，决策树1认为TRB、AST、BLK、PF和STL是帮助模型预测位置的最重要的特征。它认为FG、3P%、FGA、3P和FT是最不重要的特征。这是有意义的——模型认为不同位置的平均数据差异很大的类别(如TRB和AST)很重要，而平均数据差异很大的类别(如FG和FGA)则无助于预测。</p><h2 id="9642" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">然而，支持向量机的特征重要性表没有相同的“模型.特征_重要性_”函数。相反，必须构建一个情节，使其重要性可视化:</h2><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="c42b" class="le jx hh la b fi lf lg l lh li">def f_importances(coef, names, top=-1):<br/>    imp = coef<br/>    imp, names = zip(*sorted(list(zip(imp, names))))</span><span id="94d2" class="le jx hh la b fi ly lg l lh li">    # Show all features:<br/>    if top == -1:<br/>        top = len(names)</span><span id="9e27" class="le jx hh la b fi ly lg l lh li">    plt.barh(range(top), imp[::-1][0:top], align='center')<br/>    plt.yticks(range(top), names[::-1][0:top])<br/>    plt.show()</span><span id="7dda" class="le jx hh la b fi ly lg l lh li">feature_names = ['PTS', 'TRB', 'ORB', 'AST', 'STL', 'BLK', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%', 'PF', 'TOV']<br/>f_importances(abs(svm1_model.coef_[0]), feature_names)</span></pre><p id="4360" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">上面的代码为SVM协议1生成了以下功能重要性图表:</p><figure class="js jt ju jv fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es mz"><img src="../Images/92fdc09194f5fbb64cad36ccf4c42c69.png" data-original-src="https://miro.medium.com/v2/resize:fit:588/0*-xPpp_z9H5mdtLvT"/></div></div></figure><p id="be46" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我们可以在这个例子中看到，SVM 1认为AST、BLK、TRB、2P和FTA是帮助模型预测位置的最重要的特征。它认为PTS，FG%，FT%，2P%和STL是最不重要的特征。这是有意义的——模型认为不同位置的平均统计数据差异很大的类别(如TRB和AST)是重要的，而平均统计数据不<em class="mj">而</em>不同位置的类别(如PTS)被模型认为对做出预测没有帮助。</p></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h1 id="f600" class="jw jx hh bd jy jz lr kb kc kd ls kf kg kh lt kj kk kl lu kn ko kp lv kr ks kt bi translated">结果/评估:</h1><h1 id="562a" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">准确度分数:</h1><p id="addc" class="pw-post-body-paragraph it iu hh iv b iw ku iy iz ja kv jc jd je kw jg jh ji kx jk jl jm ky jo jp jq ha bi translated">对于以下所有指标，将变量名替换为正在运行的特定模型，以便进行比较。在每个模型后运行，而不是在最后一次运行，因为“y_test”和“predictions”数据集将在每次运行新模型后发生变化。</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="0308" class="le jx hh la b fi lf lg l lh li">from sklearn.metrics import accuracy_score<br/>model_accuracy_score = accuracy_score(y_test, predictions)</span></pre><p id="d67d" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">确保你的准确率分数是基于y_test，而不是y_train。真正的准确性分数应该基于模型尚未看到的数字，这就是测试数据集。</p><ol class=""><li id="0c29" class="ma mb hh iv b iw ix ja jb je mc ji md jm me jq mf mg mh mi bi translated">随机森林1准确度分数(所有20个特征):71.4%</li><li id="3c93" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq mf mg mh mi bi translated">SVM 1准确性得分(全部20个特征):70.6%</li><li id="e202" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq mf mg mh mi bi translated">支持向量机2准确率得分(前5个特征):67.2%</li><li id="3ecd" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq mf mg mh mi bi translated">随机森林2准确度分数(前5个特征):66.2%</li><li id="2f3c" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq mf mg mh mi bi translated">梯度增强的树1准确度分数(所有20个特征):66.2%</li><li id="37a5" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq mf mg mh mi bi translated">梯度增强的树2准确度分数(前5个特征):65.7%</li><li id="97e7" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq mf mg mh mi bi translated">决策树1准确度分数(全部20个特征):61.7%</li><li id="b1b4" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq mf mg mh mi bi translated">决策树3准确度分数(前5个特征):59.6%</li><li id="59b1" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq mf mg mh mi bi translated">决策树2准确度分数(所有20个特征，PCA变换):50.0%</li></ol><p id="70fc" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">使用所有20个特征的随机森林模型获得了71.4%的最高准确度分数；从使用所有20个特征<em class="mj">和</em>使用X数据的PCA变换的决策树模型中获得50.0%的最低准确度分数。一般来说，随机森林和支持向量机的表现最好，而梯度提升树和决策树的表现最差。</p><h1 id="a7ed" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">混淆矩阵:</h1><p id="ba9a" class="pw-post-body-paragraph it iu hh iv b iw ku iy iz ja kv jc jd je kw jg jh ji kx jk jl jm ky jo jp jq ha bi translated">混淆矩阵是一种可视化分类准确性的好方法，但是以一种更直观的方式。它们是分类器做出的正确和不正确预测数量的表格汇总。我定义了一个自定义函数来打印混淆矩阵热图，一旦定义了这个函数，所有未来的混淆矩阵都是通过简单地调用函数名来生成的。</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="b398" class="le jx hh la b fi lf lg l lh li">from sklearn.metrics import confusion_matrix</span><span id="f2a0" class="le jx hh la b fi ly lg l lh li"># Define Custom Confusion Matrix function that plots Heatmap of Actuals vs. Predictions:<br/>def confusion_matrix_heatmap(y_test, predictions):<br/>    """This plots the confusion matrix"""<br/>    warnings.filterwarnings('ignore')</span><span id="bd02" class="le jx hh la b fi ly lg l lh li">    cm = confusion_matrix(y_test, predictions)</span><span id="d610" class="le jx hh la b fi ly lg l lh li">    # Plot Heatmap:<br/>    f, ax = plt.subplots(figsize=(9, 7))<br/>    heat_map = sns.heatmap(cm, annot=True, fmt="d", linewidths=1, ax=ax, cmap=sns.cubehelix_palette(50), xticklabels=position_dictionary.keys(), yticklabels=position_dictionary.keys())</span><span id="63df" class="le jx hh la b fi ly lg l lh li">    # Set X and Y Labels:<br/>    heat_map.set_xlabel("# Predicted")<br/>    heat_map.set_ylabel("# Actual")</span><span id="eedf" class="le jx hh la b fi ly lg l lh li"># Print confusion matrix:<br/>cm1 = confusion_matrix_heatmap(y_test, predictions)</span></pre><p id="d9c6" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">上面的代码生成以下混淆矩阵，这是随机森林1的混淆矩阵:</p><figure class="js jt ju jv fd ii er es paragraph-image"><div class="er es nf"><img src="../Images/7208aea28b8472b4dfe8fbc3bb995181.png" data-original-src="https://miro.medium.com/v2/resize:fit:812/0*-L2wSe1ozq8OO59o"/></div></figure><p id="2518" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">混淆矩阵是一种可视化模型准确性的有用方法。例如，我们可以在上面看到，在测试数据集(181+34+3+0+0)中包含的218个控球后卫中，模型正确预测了“控球后卫”181次。34次它认为控卫是得分后卫，3次它认为控卫是小前锋，它从来不认为控卫是大前锋，它从来不认为控卫是中锋。这种分布是有意义的——随着不同位置职责的增加，模型不太可能预测控卫是那个位置。</p><h1 id="efe8" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">分类报告:</h1><p id="83f9" class="pw-post-body-paragraph it iu hh iv b iw ku iy iz ja kv jc jd je kw jg jh ji kx jk jl jm ky jo jp jq ha bi translated">分类报告显示模型的其他关键指标，这些指标与准确性相关，但不完全是准确性(精确度、召回率、F1和支持得分)。我们将会看到，这些分数即使不完全相同，也非常接近于准确性分数(考虑到目标列position的多类性质)。</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="2b5e" class="le jx hh la b fi lf lg l lh li">from sklearn.metrics import classification_report<br/>model_class_report = classification_report(y_test, predictions, target_names = ['PG', 'SG', 'SF', 'PF', 'C'])</span></pre><p id="3860" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">上面的代码生成以下分类报告，这是随机森林1的分类报告:</p><figure class="js jt ju jv fd ii er es paragraph-image"><div class="er es ng"><img src="../Images/2de8eac16c8cba38a108a3b2127fd507.png" data-original-src="https://miro.medium.com/v2/resize:fit:706/0*BgM7OFqb6uBK11fs"/></div></figure><h2 id="eab2" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">这些分数意味着什么？</h2><p id="1a52" class="pw-post-body-paragraph it iu hh iv b iw ku iy iz ja kv jc jd je kw jg jh ji kx jk jl jm ky jo jp jq ha bi translated">精度:正面预测的准确性:该模型以72%的比率正面预测了一个位置(意味着它说<em class="mj">是这个</em>位置，而不是<em class="mj">不是那个位置</em>)。</p><p id="2a15" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">回忆:被正确识别的阳性的比例:该模型捕获了71%的阳性病例。</p><p id="5607" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">F1得分:正确预测的正面预测的百分比:模型正确预测了72%的正面预测。</p><p id="2998" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">支持:数据集中出现的次数，也就是数据集中的行数。该数据集包含1013行数据，因此支持得分为1013。</p><h1 id="ce8b" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">最终结论:</h1><p id="5db2" class="pw-post-body-paragraph it iu hh iv b iw ku iy iz ja kv jc jd je kw jg jh ji kx jk jl jm ky jo jp jq ha bi translated">最佳准确率评分:随机森林1模型:71.4% <br/>最佳分类报告评分:随机森林1模型:72%精度、71%召回率、72% F1评分<br/>最佳整体模型:随机森林1模型</p></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h2 id="584b" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">让我们使用最好的模型(随机森林1，71.4%的准确性)并给它特定的预测，给它提供真实球员的真实数据，看看它如何对每个球员进行分类。</h2><h2 id="6c22" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">首先，我创建了两个数据框架:一个是定义好自己位置的球员，另一个是玩更“无位置”游戏的球员，他们的数据不局限于他们位置的传统职责。然后，我删除并重新排序了dataframe列，以模拟随机森林1的数据集，并缩放数据，因为随机森林模型数据已被缩放。</h2><h2 id="a88a" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">“位置”玩家:</h2><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="ed4e" class="le jx hh la b fi lf lg l lh li"># Select players who define their position well:<br/>pg_steph_row = original_df.loc[((original_df['Player'] == 'Stephen Curry') &amp; (original_df['Age'] == 26))]<br/>sg_beal_row = original_df.loc[((original_df['Player'] == 'Bradley Beal') &amp; (original_df['Age'] == 24))]<br/>sf_kawhi_row = original_df.loc[((original_df['Player'] == 'Kawhi Leonard') &amp; (original_df['Age'] == 25))]<br/>pf_love_row = original_df.loc[((original_df['Player'] == 'Kevin Love') &amp; (original_df['Age'] == 27))]<br/>c_embiid_row = original_df.loc[((original_df['Player'] == 'Joel Embiid') &amp; (original_df['Age'] == 24))]</span><span id="9aef" class="le jx hh la b fi ly lg l lh li"># Concatenate above into one dataframe:<br/>position_players_df = pd.concat([pg_steph_row, sg_beal_row, sf_kawhi_row, pf_love_row, c_embiid_row], axis='rows', join='inner')</span><span id="eb7b" class="le jx hh la b fi ly lg l lh li"># Drop/Re-order columns to mimic Random Forest 1's dataset:<br/>position_players_df = position_players_df[['PTS', 'TRB', 'ORB', 'AST', 'STL', 'BLK', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%', 'PF', 'TOV']]</span><span id="2afc" class="le jx hh la b fi ly lg l lh li"># Scale data (model data was scaled, so this data needs to be scaled as well):<br/>position_players_df_scaled = scaler.fit_transform(position_players_df)</span></pre><h2 id="c6f7" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">“无位置”玩家:</h2><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="cbec" class="le jx hh la b fi lf lg l lh li"># Select players who play a more "position-less" game, in which their stats are not confined to the traditional responsibilities of their position:<br/>pg_simmons_row = original_df.loc[((original_df['Player'] == 'Ben Simmons') &amp; (original_df['Age'] == 22))]<br/>pg_westbrook_row = original_df.loc[((original_df['Player'] == 'Russell Westbrook') &amp; (original_df['Age'] == 24))]<br/>sg_harden_row = original_df.loc[((original_df['Player'] == 'James Harden') &amp; (original_df['Age'] == 26))]<br/>pf_lebron_row = original_df.loc[((original_df['Player'] == 'LeBron James') &amp; (original_df['Age'] == 33))]<br/>pf_draymond_row = original_df.loc[((original_df['Player'] == 'Draymond Green') &amp; (original_df['Age'] == 27))]<br/>pf_giannis_row = original_df.loc[((original_df['Player'] == 'Giannis Antetokounmpo') &amp; (original_df['Age'] == 23))]<br/>c_gasol_row = original_df.loc[((original_df['Player'] == 'Marc Gasol') &amp; (original_df['Age'] == 33))]</span><span id="1ea9" class="le jx hh la b fi ly lg l lh li"># Concatenate above into one dataframe:<br/>positionless_players_df = pd.concat([pg_simmons_row, pg_westbrook_row, sg_harden_row, pf_lebron_row, pf_draymond_row, pf_giannis_row, c_gasol_row], axis='rows', join='inner')</span><span id="4379" class="le jx hh la b fi ly lg l lh li"># Drop/Re-order columns to mimic Random Forest 1's dataset:<br/>positionless_players_df = positionless_players_df[['PTS', 'TRB', 'ORB', 'AST', 'STL', 'BLK', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%', 'PF', 'TOV']]</span><span id="3896" class="le jx hh la b fi ly lg l lh li"># Scale data (model data was scaled, so this data needs to be scaled as well):<br/>positionless_players_df_scaled = scaler.fit_transform(positionless_players_df)</span></pre><h1 id="1f2a" class="jw jx hh bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt bi translated">然后，输入模型数据帧并预测:</h1><h2 id="cb24" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">请记住，我之前对y标签进行了编码:PG = 1，SG = 2，SF = 3，PF = 4，C = 5。</h2><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="3113" class="le jx hh la b fi lf lg l lh li"># Predict first dataframe, containing players who define their position well:<br/># A PG, SG, SF, PF, then C were loaded in.  Therefore, this output should be 1, 2, 3, 4, 5.<br/># Also keep in mind order of players: PG Curry, SG Beal, SF Leonard, PF Love, C Embiid.<br/>position_predictions = rf1_model.predict(position_players_df_scaled)</span><span id="ce22" class="le jx hh la b fi ly lg l lh li"># Output = array([1, 2, 3, 4, 5])</span><span id="c927" class="le jx hh la b fi ly lg l lh li"># Predict second dataframe, containing players who play a more "position-less" game:<br/># A PG, PG, SG, PF, PF, PF, and C were loaded in.  Therefore, this output should be 1, 1, 2, 4, 4, 4, 5.<br/># Also keep in mind order of players: PG Simmons, PG Westbrook, SG Harden, PF LeBron, PF Draymond, PF Giannis, C Gasol.<br/>positionless_predictions = rf1_model.predict(positionless_players_df_scaled)</span><span id="08b3" class="le jx hh la b fi ly lg l lh li"># Output = array([4, 2, 2, 3, 4, 4, 4])</span></pre><p id="b863" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">正如我们预期的那样，随机森林1模型正确预测了“位置”数据框中的所有5个位置。但是“无位置”数据框架呢？</p><p id="8899" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">随机森林1模型正确预测了“无位置”数据框架中7个位置中的3个:它正确预测了詹姆斯·哈登为SG，德雷蒙德·格林为PF，扬尼斯·阿德托昆博为PF。然而，它认为控卫本·西蒙斯是大前锋，控卫威斯布鲁克是得分后卫，大前锋勒布朗詹姆斯是小前锋，而马克加索尔是大前锋。一个中锋被误认为大前锋，反之亦然，或者一个控球后卫被误认为得分后卫，反之亦然，这并不是一个严重的错误。这些位置是相似的，分担着相似的责任，而且通常，这些球员实际上在一个赛季中扮演两个位置，甚至在同一场比赛的不同时间点。这里最有趣的发现是关于PG本·西蒙斯的:模特认为他是PF。本·西蒙斯身高6英尺10英寸，对于一个控球后卫来说已经很高了。就他的位置而言，他也是一个出了名的糟糕的射手，很少从外面投篮，而且当他投篮的时候，大多数时候都会投失。因此，他的统计数据更类似于大前锋，抢篮板和外线投篮不佳。这就是为什么模型认为他是一个大前锋。</p><h2 id="0ecb" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">让我们做同样的事情，但这一次，我们将使用我最喜欢的NBA球队纽约尼克斯队2020-2021赛季的统计数据。</h2><h2 id="ec14" class="le jx hh bd jy ml mm mn kc mo mp mq kg je mr ms kk ji mt mu ko jm mv mw ks mx bi translated">在这个时间点上，这个赛季只进行了15场比赛，所以对这个模型的预测要有所保留:</h2><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="c733" class="le jx hh la b fi lf lg l lh li"># Load in 2020-2021 Knicks dataframe:<br/>knicks_csv_path = Path('CSVs/knicks.csv')<br/>knicks_df = pd.read_csv(knicks_csv_path)</span><span id="6c80" class="le jx hh la b fi ly lg l lh li"># This particular dataset did not contain a "Position" column.  Let's add one ourselves:<br/>positions = {'Position': ['PF', 'SG', 'C', 'PG', 'SF', 'SF', 'SG', 'C', 'PG', 'SG', 'PF', 'PG', 'PG', 'SG', 'SF', 'PG']}<br/>df_positions = pd.DataFrame(positions)<br/>knicks_df['Pos'] = df_positions</span><span id="969f" class="le jx hh la b fi ly lg l lh li"># Filter dataframe to only include rows with at least 100 Minutes Played:<br/># We are only 15 games through the 2020-2021 season at the time of this writing,<br/># so a few players who have been injured have very few minutes: remove them<br/># from the dataset.</span><span id="7f64" class="le jx hh la b fi ly lg l lh li">knicks_df = knicks_df[knicks_df.MP &gt;= 100]</span><span id="603b" class="le jx hh la b fi ly lg l lh li"># Drop/Re-order columns to mimic Random Forest 1's dataset:<br/>knicks_df = knicks_df[['PTS', 'TRB', 'ORB', 'AST', 'STL', 'BLK', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%', '2P', '2PA', '2P%', 'FT', 'FTA', 'FT%', 'PF', 'TOV']]</span><span id="8432" class="le jx hh la b fi ly lg l lh li"># Replace "NaN" values with "0" instead of dropping null rows completely (helps preserve the data):<br/>knicks_df[np.isnan(knicks_df)] = 0.0</span><span id="717d" class="le jx hh la b fi ly lg l lh li"># Scale data (model data was scaled, so this data needs to be scaled as well):<br/>knicks_df_scaled = scaler.fit_transform(knicks_df)</span></pre><p id="2971" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">这给我留下了一个和《随机森林1》一模一样的数据框架。现在我所要做的就是把这个数据帧输入到随机森林1的模型中，看看它预测了什么:</p><pre class="js jt ju jv fd kz la lb lc aw ld bi"><span id="b19b" class="le jx hh la b fi lf lg l lh li">knicks_predictions = rf1_model.predict(knicks_df_scaled)</span><span id="fd00" class="le jx hh la b fi ly lg l lh li"># Output = array([4, 3, 5, 1, 3, 2, 2, 5, 1])</span></pre><ul class=""><li id="343a" class="ma mb hh iv b iw ix ja jb je mc ji md jm me jq nh mg mh mi bi translated">随机森林1模型正确预测了9个位置中的7个:它正确预测了朱利叶斯·兰德尔为PF，米切尔·罗宾逊为C，埃尔弗里德·佩顿为PG，雷吉·布洛克为SF，奥斯汀·里弗斯为SG，诺伦斯·诺埃尔为C，伊曼纽尔·奎克利为PG。</li><li id="1ef9" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq nh mg mh mi bi translated">然而，它认为SG RJ巴雷特是一个科幻小说，它认为科幻小说凯文诺克斯是一个SG。</li><li id="519d" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq nh mg mh mi bi translated">我期望看到的正是所发生的——事实上，SG RJ·巴勒特并没有被确定为SG，甚至没有被确定为PG。这是因为RJ·巴雷特，至少在他年轻职业生涯的这一点上，是一个不稳定的，糟糕的射手，他的大部分得分都在内线。</li><li id="8b82" class="ma mb hh iv b iw na ja nb je nc ji nd jm ne jq nh mg mh mi bi translated">这些信息很有用，因为它可以成为设置阵容的因素之一——哪些球员可以打多个位置，或者哪些球员可以在新角色中尝试成功。在巴雷特这个特殊的例子中，这可能是对尼克斯的一个警告信号，不要让他打SG，而是让他打模型预测的那个SF。也许尼克斯可以交换巴雷特和诺克斯的位置——像模型预测的那样，在SF打巴雷特，在SG打诺克斯。</li></ul></div><div class="ab cl lk ll go lm" role="separator"><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp lq"/><span class="ln bw bk lo lp"/></div><div class="ha hb hc hd he"><h1 id="4409" class="jw jx hh bd jy jz lr kb kc kd ls kf kg kh lt kj kk kl lu kn ko kp lv kr ks kt bi translated">改进模型的方法:</h1><p id="da39" class="pw-post-body-paragraph it iu hh iv b iw ku iy iz ja kv jc jd je kw jg jh ji kx jk jl jm ky jo jp jq ha bi translated">第一个，也是最明显的，改进模型的方法是使用更大的数据集；我的数据集包含15个赛季和4051行数据(过滤后)，这并不小，但具有更多训练/测试数据的更大数据集可能会受益。另一种提高模型准确性的方法是进一步过滤数据框架:我只包括在赛季中至少打了820分钟的球员(10分钟/场* 82场)，我觉得这是一个很好的数字，因为它过滤掉了很少使用的球员，同时仍然保留了大量的数据。使用更高的上场时间阈值将确保数据集中包含的球员真正代表该位置的产出。</p><p id="ab80" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">我还认为原始数据集中缺少了一个关键特征:球员的身高。这是确定一个人的位置的一个重要因素，我相信如果该特征包含在原始数据集中，它将被模型视为最重要的特征之一，并最终全面提高准确性得分。总体而言，更强大的特征工程将更好地服务于该数据集。</p><p id="dfe1" class="pw-post-body-paragraph it iu hh iv b iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq ha bi translated">此外，如今的NBA越来越“无位置”。球员的技能比过去更加全面和全面——过去，中锋通常不会投三分球，控球后卫也不会抢很多篮板。但在今天的游戏中，一个人在纸上的“位置”并不意味着一切；球员有各种各样的技能，就像我们在随机森林1的预测中看到的那样，预测NBA的位置不再那么容易了。使用许多年前的赛季，比15年前更早——当时游戏比现在更严格，玩家主要坚持各自位置的传统责任——将使模型更容易做出预测。下一步可能是使用另一个随机森林模型，使用同样的20个特征，但这一次，使用不同的数据集，一个包含1980-1995年的NBA数据的数据集，并查看该模型与使用更新的NBA数据的模型相比有多准确。</p></div></div>    
</body>
</html>