<html>
<head>
<title>Credit Card Fraud Detection — Part 2</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">信用卡欺诈检测—第2部分</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/credit-card-fraud-detection-part-2-3e75d0022b9b?source=collection_archive---------11-----------------------#2021-02-08">https://medium.com/analytics-vidhya/credit-card-fraud-detection-part-2-3e75d0022b9b?source=collection_archive---------11-----------------------#2021-02-08</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="cf93" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这一部分中，我们将更深入地研究我们将要使用的模型和数据不平衡技术。</p><p id="272d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们首先删除数据框中添加的所有其他数量(仅保留对数比例数量),并将所有要素放入“X”中。我们必须预测' Class ',所以我们将它从' X '中删除，并存储在标签' y '中。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><p id="eebe" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">正如我们在EDA部分<a class="ae jj" href="https://vasudhatapriya2.medium.com/credit-card-fraud-detection-part-i-1061d4c0bd68" rel="noopener"> (Part-1) </a>中看到的，这个数据集存在巨大的类不平衡。</p><h1 id="b89d" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated"><strong class="ak">为什么阶级不平衡是一个问题？</strong></h1><p id="1bc4" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">当在高度不平衡的数据集上训练统计分类器时，它倾向于挑选最流行的类中的模式，而忽略其余的。</p><p id="8b33" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如，在这个数据集中，99.9%的数据被标记为“非欺诈”，其余的为“欺诈”。因此，即使一个模型将它看到的一切都归类为“非欺诈”，准确率也将达到99.9%，这似乎非常好。</p><p id="6049" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">但是模式好吗？<strong class="ig hi">否</strong>，因为它没有将任何交易归类为‘欺诈’。所以，即使模型有99.9%的准确率，也完全没用！</p><p id="02d6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们需要一些<em class="kn">策略</em>来处理这样的数据集，或者我们需要在这样的场景中使用一些其他的<em class="kn">指标</em>(除了准确性)。</p><h1 id="e33c" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">处理阶级不平衡</h1><p id="ee66" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">在这篇博客中，我们将使用4种技巧来处理班级失衡问题。</p><h2 id="12c5" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated">1.欠样本多数类</h2><p id="5b78" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">在欠采样中，多数类中的样本数被下采样(通过随机消除它们)以使它们与少数类中的样本数对齐。</p><p id="f773" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这可能导致<em class="kn">数据低效</em>，因为有用数据的丢失可能使基于规则的分类器更难学习少数和多数样本之间的决策边界。</p><p id="d370" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">尽管受到严重不平衡的影响，这种技术仅在少数类具有足够的数据时有效。</p><h2 id="5b57" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated">2.过样本少数类</h2><p id="e956" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">这与欠采样正好相反。少数类中的样本数被随机复制，以使它们与多数类中的样本数一致。</p><p id="302a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这可能导致<em class="kn">过度拟合</em>，因为它制作了少数类样本的精确副本(它没有向模型添加任何新信息，而只是复制了数据样本)。</p><h2 id="9ccc" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated">3.合成少数过采样技术(SMOTE)</h2><p id="6e25" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">SMOTE是一种过采样技术，它在少数类中创建新的<em class="kn">合成</em>示例，这些示例与已经存在的<em class="kn"> </em>示例<em class="kn">相似</em>，而不是简单地复制它们。</p><blockquote class="lc ld le"><p id="c760" class="ie if kn ig b ih ii ij ik il im in io lf iq ir is lg iu iv iw lh iy iz ja jb ha bi translated">SMOTE首先随机选择一个少数类实例a，并找到其k个最近的少数类邻居。然后，通过随机选择k个最近邻居b中的一个并连接a和b以在特征空间中形成线段，来创建合成实例。合成实例被生成为两个所选实例a和b的凸组合。</p><p id="8c17" class="ie if kn ig b ih ii ij ik il im in io lf iq ir is lg iu iv iw lh iy iz ja jb ha bi translated"><em class="hh">第47页，</em> <a class="ae jj" href="https://amzn.to/32K9K6d" rel="noopener ugc nofollow" target="_blank"> <em class="hh">《不平衡学习:基础、算法、应用》</em> </a> <em class="hh">，2013年。</em></p></blockquote><p id="8496" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">SMOTE流程包括以下内容:</p><ol class=""><li id="2c32" class="li lj hh ig b ih ii il im ip lk it ll ix lm jb ln lo lp lq bi translated">识别特征向量及其最近邻。</li><li id="f4c4" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">取两者之差。</li><li id="5463" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">将差值乘以0到1之间的随机数。</li><li id="0e1e" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">通过将随机数添加到特征向量来识别线段上的新点。</li><li id="1c11" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">对识别的特征向量重复该过程。</li></ol><p id="bf9a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这种方法的局限性在于，当在不考虑多数类的情况下创建合成示例时，如果类之间有很强的重叠，则会导致创建不明确的样本。</p><h2 id="c7ed" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated">4.自适应合成样本(ADASYN)</h2><p id="ef5b" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">ADASYN背后的基本思想是根据不同少数类示例的学习难度级别对它们使用加权分布(为更容易学习的少数类示例生成更多合成数据)。</p><p id="2954" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">ADASYN方法以两种方式改进了关于数据分布的学习:</p><ol class=""><li id="787d" class="li lj hh ig b ih ii il im ip lk it ll ix lm jb ln lo lp lq bi translated">它减少了阶级不平衡带来的偏见。</li><li id="eb79" class="li lj hh ig b ih lr il ls ip lt it lu ix lv jb ln lo lp lq bi translated">它自适应地将分类决策边界移向困难的例子。</li></ol><p id="cb79" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">注:</strong>在应用 过采样技术之前，重要的是分成测试和训练集<strong class="ig hi"> <em class="kn">。分割数据之前的过采样会导致在测试和训练集中出现相同的观察结果，这只会让我们的模型记住这些数据点(并导致过拟合)。</em></strong></p><p id="b4e2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">导入依赖项:</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><p id="b7c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们为所有这些类不平衡方法准备数据集。</p><p id="374c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">随机下采样数据集</strong></p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es lw"><img src="../Images/98b200d7bad8249fac36d08c70cc6a21.png" data-original-src="https://miro.medium.com/v2/resize:fit:380/format:webp/1*FHFufR6JaFZqV5DzBuri7w.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">欠采样数据集的输出</figcaption></figure><p id="c80d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">随机过采样器数据集</strong></p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es md"><img src="../Images/f4f7935f9145b0a0cbfc2a59b9de37a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*PrqjE7AJuKdi1glOZl3M_A.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">过采样数据集的输出</figcaption></figure><p id="7990" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> SMOTE数据集</strong></p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es md"><img src="../Images/b97ce0069d0bb24b405af0404947a94c.png" data-original-src="https://miro.medium.com/v2/resize:fit:388/format:webp/1*xbAbMmf8L38y8_U9-csSRg.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">SMOTE数据集的输出</figcaption></figure><p id="08f0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> ADASYN数据集</strong></p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es me"><img src="../Images/d0d2b8df0e28dff40e92c45387a90864.png" data-original-src="https://miro.medium.com/v2/resize:fit:408/format:webp/1*sRCYT6lrE37q7e3uKKrSLQ.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">ADASYN数据集的输出</figcaption></figure><h1 id="aa90" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">韵律学</h1><p id="9026" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated"><strong class="ig hi">混淆矩阵</strong>(误差矩阵)，允许算法性能的可视化。</p><figure class="jc jd je jf fd jg er es paragraph-image"><div role="button" tabindex="0" class="mg mh di mi bf mj"><div class="er es mf"><img src="../Images/f9c2cb2084bc20b2f4ded9abf3c7dac1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GQ3iJtAjQeAoSaLUdiUzVw.png"/></div></div></figure><p id="fb00" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">真阳性(TP) : </strong>欺诈被正确识别为欺诈</p><p id="5364" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">真阴性(TN) : </strong>非欺诈被正确识别为非欺诈</p><p id="76d2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">误报(FP) : </strong>欺诈被错误地识别为非欺诈</p><p id="11ba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi">假阴性(FN) : </strong>非欺诈被错误地识别为欺诈</p><h2 id="3323" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated"><strong class="ak">精度</strong></h2><p id="4e5d" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated"><strong class="ig hi"> (TP +TN) / (TP + TN + FP +FN) </strong></p><p id="51b2" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">如前所述，我们需要一些其他的度量来评估我们的模型(除了准确性)。</p><h2 id="620a" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated"><strong class="ak">精度</strong></h2><p id="f50c" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated"><strong class="ig hi"> TP / (TP + FP) </strong></p><p id="56df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Precision告诉我们有多少正确预测的案例实际上变成了阳性(<em class="kn">阳性类别的预测正确的可能性有多大</em>)。</p><h2 id="ad26" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated"><strong class="ak">回忆</strong></h2><p id="1aef" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated"><strong class="ig hi"> TP / (TP + FN) </strong></p><p id="1492" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">回忆告诉我们有多少实际的阳性案例我们能够用我们的模型<em class="kn">正确预测(模型识别阳性类别的能力有多强)。</em></p><h2 id="f8b2" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated"><strong class="ak"> F1得分</strong></h2><p id="939b" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">当我们试图提高精确度时，召回率会下降，反之亦然。F1分数在一个值中捕捉了这两种趋势。这是回忆和精确的调和平均值。</p><p id="7e41" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><strong class="ig hi"> F1得分:2 x((精度x召回)/(精度+召回)</strong></p><p id="0a4a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">当精确度和召回率相等时，F1得分最高。</p><p id="43e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于这个数据集，我们将使用F1分数来比较各种模型的结果。</p><h2 id="8ff3" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated"><strong class="ak"> ROC曲线</strong></h2><p id="5e76" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">ROC曲线是在不同阈值设置下真阳性率(TPR)对假阳性率(FPR)的曲线图。</p><p id="5fbb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了计算每个分类模型的性能(使用所有五个数据集)，创建一个函数来评估上面提到的所有度量并存储它们，以便以后可以比较它们，这将是非常有益的。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><h1 id="755d" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">分类算法</h1><p id="d8a3" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">在这里，我们将在应用这些算法之前简要地讨论它们。</p><blockquote class="mk"><p id="d9c2" class="ml mm hh bd mn mo mp mq mr ms mt jb dx translated">对于这些分类算法中的每一个，我们将检查所有的类别不平衡技术(对于上面制作的数据集),并最终使用前面提到的度量来比较结果。所以，让我们开始吧！</p></blockquote><h2 id="8c98" class="ko jl hh bd jm kp mu kr jq ks mv ku ju ip mw kw jy it mx ky kc ix my la kg lb bi translated">1.逻辑回归分类器</h2><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><pre class="jc jd je jf fd mz na nb nc aw nd bi"><span id="f259" class="ko jl hh na b fi ne nf l ng nh">Model Name : LR IMBALANCED<br/>Test Accuracy :0.99826<br/>Test AUC : 0.50000<br/>Test Precision : 0.00000<br/>Test Recall : 0.00000<br/>Test F1 : 0.00000<br/>Confusion Matrix : <br/> [[84970     0]<br/> [  148     0]]<br/><br/><br/>Model Name : LR UNDERSAMPLE<br/>Test Accuracy :0.99826<br/>Test AUC : 0.50000<br/>Test Precision : 0.00000<br/>Test Recall : 0.00000<br/>Test F1 : 0.00000<br/>Confusion Matrix : <br/> [[84970     0]<br/> [  148     0]]<br/><br/><br/>Model Name : LR OVERSAMPLE<br/>Test Accuracy :0.99659<br/>Test AUC : 0.79594<br/>Test Precision : 0.27673<br/>Test Recall : 0.59459<br/>Test F1 : 0.37768<br/>Confusion Matrix : <br/> [[84740   230]<br/> [   60    88]]<br/><br/><br/>Model Name : LR SMOTE<br/>Test Accuracy :0.99659<br/>Test AUC : 0.79594<br/>Test Precision : 0.27673<br/>Test Recall : 0.59459<br/>Test F1 : 0.37768<br/>Confusion Matrix : <br/> [[84740   230]<br/> [   60    88]]<br/><br/><br/>Model Name : LR ADASYN <br/>Test Accuracy :0.99633<br/>Test AUC : 0.82279<br/>Test Precision : 0.26966<br/>Test Recall : 0.64865<br/>Test F1 : 0.38095<br/>Confusion Matrix : <br/> [[84710   260]<br/> [   52    96]]</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es ni"><img src="../Images/05b742989872911a79474d50d130171e.png" data-original-src="https://miro.medium.com/v2/resize:fit:688/format:webp/1*I2LCuwnomUW-pOGWf18uZQ.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">逻辑回归分类器的ROC曲线</figcaption></figure><h2 id="a15d" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated">2.随机森林分类器</h2><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><pre class="jc jd je jf fd mz na nb nc aw nd bi"><span id="79b4" class="ko jl hh na b fi ne nf l ng nh">Model Name : RF IMABALANCED<br/>Test Accuracy :0.99952<br/>Test AUC : 0.88847<br/>Test Precision : 0.93496<br/>Test Recall : 0.77703<br/>Test F1 : 0.84871<br/>Confusion Matrix : <br/> [[84962     8]<br/> [   33   115]]<br/><br/><br/>Model Name : RF UNDERSAMPLE<br/>Test Accuracy :0.96343<br/>Test AUC : 0.93784<br/>Test Precision : 0.04173<br/>Test Recall : 0.91216<br/>Test F1 : 0.07981<br/>Confusion Matrix : <br/> [[81870  3100]<br/> [   13   135]]<br/><br/><br/>Model Name : RF OVERSAMPLE<br/>Test Accuracy :0.99952<br/>Test AUC : 0.87835<br/>Test Precision : 0.95726<br/>Test Recall : 0.75676<br/>Test F1 : 0.84528<br/>Confusion Matrix : <br/> [[84965     5]<br/> [   36   112]]<br/><br/><br/>Model Name : RF SMOTE<br/>Test Accuracy :0.99947<br/>Test AUC : 0.91542<br/>Test Precision : 0.86014<br/>Test Recall : 0.83108<br/>Test F1 : 0.84536<br/>Confusion Matrix : <br/> [[84950    20]<br/> [   25   123]]<br/><br/><br/>Model Name : RF ADASYN<br/>Test Accuracy :0.99947<br/>Test AUC : 0.91542<br/>Test Precision : 0.86014<br/>Test Recall : 0.83108<br/>Test F1 : 0.84536<br/>Confusion Matrix : <br/> [[84950    20]<br/> [   25   123]]  </span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es nj"><img src="../Images/f87ba594952e36573479662ad4d25a7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:834/format:webp/1*r0MDot4HPds-sGebgitWhQ.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">随机森林分类器的ROC曲线</figcaption></figure><h2 id="b1dd" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated">3.高斯朴素贝叶斯分类器</h2><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><pre class="jc jd je jf fd mz na nb nc aw nd bi"><span id="62e5" class="ko jl hh na b fi ne nf l ng nh">Model Name : NB IMBALANCED<br/>Test Accuracy :0.99316<br/>Test AUC : 0.80097<br/>Test Precision : 0.14658<br/>Test Recall : 0.60811<br/>Test F1 : 0.23622<br/>Confusion Matrix : <br/> [[84446   524]<br/> [   58    90]]<br/><br/><br/>Model Name : NB UNDERSAMPLE<br/>Test Accuracy :0.99026<br/>Test AUC : 0.88046<br/>Test Precision : 0.12541<br/>Test Recall : 0.77027<br/>Test F1 : 0.21570<br/>Confusion Matrix : <br/> [[84175   795]<br/> [   34   114]]<br/><br/><br/>Model Name : NB OVERSAMPLE<br/>Test Accuracy :0.99119<br/>Test AUC : 0.87418<br/>Test Precision : 0.13559<br/>Test Recall : 0.75676<br/>Test F1 : 0.22998<br/>Confusion Matrix : <br/> [[84256   714]<br/> [   36   112]]<br/><br/><br/>Model Name : NB SMOTE<br/>Test Accuracy :0.99161<br/>Test AUC : 0.88113<br/>Test Precision : 0.14358<br/>Test Recall : 0.77027<br/>Test F1 : 0.24204<br/>Confusion Matrix : <br/> [[84290   680]<br/> [   34   114]]<br/><br/><br/>Model Name : NB ADASYN<br/>Test Accuracy :0.99118<br/>Test AUC : 0.89103<br/>Test Precision : 0.13978<br/>Test Recall : 0.79054<br/>Test F1 : 0.23756<br/>Confusion Matrix : <br/> [[84250   720]<br/> [   31   117]]</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es nk"><img src="../Images/f65c4a92ee667648853f6a0676572fb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*e8mumkD9F7k2xnUUxoYbNg.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">朴素贝叶斯分类器的ROC曲线</figcaption></figure><h2 id="a548" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated">4.决策树分类器</h2><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><pre class="jc jd je jf fd mz na nb nc aw nd bi"><span id="32d8" class="ko jl hh na b fi ne nf l ng nh">Model Name : DT IMBALANCED<br/>Test Accuracy :0.99915<br/>Test AUC : 0.86805<br/>Test Precision : 0.76761<br/>Test Recall : 0.73649<br/>Test F1 : 0.75172<br/>Confusion Matrix : <br/> [[84937    33]<br/> [   39   109]]<br/><br/><br/>Model Name : DT UNDERSAMPLE<br/>Test Accuracy :0.90412<br/>Test AUC : 0.91151<br/>Test Precision : 0.01642<br/>Test Recall : 0.91892<br/>Test F1 : 0.03225<br/>Confusion Matrix : <br/> [[76821  8149]<br/> [   12   136]]<br/><br/><br/>Model Name : DT OVERSAMPLE<br/>Test Accuracy :0.99887<br/>Test AUC : 0.84767<br/>Test Precision : 0.66883<br/>Test Recall : 0.69595<br/>Test F1 : 0.68212<br/>Confusion Matrix : <br/> [[84919    51]<br/> [   45   103]]<br/><br/><br/>Model Name : DT SMOTE<br/>Test Accuracy :0.99807<br/>Test AUC : 0.90461<br/>Test Precision : 0.46875<br/>Test Recall : 0.81081<br/>Test F1 : 0.59406<br/>Confusion Matrix : <br/> [[84834   136]<br/> [   28   120]]<br/><br/><br/>Model Name : DT ADASYN<br/>Test Accuracy :0.99769<br/>Test AUC : 0.89092<br/>Test Precision : 0.41281<br/>Test Recall : 0.78378Test F1 : 0.54079<br/>Confusion Matrix : <br/> [[84805   165]<br/> [   32   116]]</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es nl"><img src="../Images/926dd44fde5291efcb72dc12996ce8f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:838/format:webp/1*MNQyy3aQbJkS66dHuRocZw.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">决策树分类器的ROC曲线</figcaption></figure><h2 id="36c1" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated">5.k近邻分类器</h2><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><pre class="jc jd je jf fd mz na nb nc aw nd bi"><span id="7e58" class="ko jl hh na b fi ne nf l ng nh">Model Name : KNN IMBALANCE<br/>Test Accuracy :0.99834<br/>Test AUC : 0.52365<br/>Test Precision : 1.00000<br/>Test Recall : 0.04730<br/>Test F1 : 0.09032<br/>Confusion Matrix : <br/> [[84970     0]<br/> [  141     7]]<br/><br/><br/>Model Name : KNN UNDERSAMPLE<br/>Test Accuracy :0.64224<br/>Test AUC : 0.61171<br/>Test Precision : 0.00282<br/>Test Recall : 0.58108<br/>Test F1 : 0.00562<br/>Confusion Matrix : <br/> [[54580 30390]<br/> [   62    86]]<br/><br/><br/>Model Name : KNN OVERSAMPLE<br/>Test Accuracy :0.99823<br/>Test AUC : 0.61802<br/>Test Precision : 0.47945<br/>Test Recall : 0.23649<br/>Test F1 : 0.31674<br/>Confusion Matrix : <br/> [[84932    38]<br/> [  113    35]]<br/><br/><br/>Model Name : KNN SMOTE<br/>Test Accuracy :0.98089<br/>Test AUC : 0.82180<br/>Test Precision : 0.05851<br/>Test Recall : 0.66216<br/>Test F1 : 0.10752<br/>Confusion Matrix : <br/> [[83393  1577]<br/> [   50    98]]<br/><br/><br/>Model Name : KNN ADASYN<br/>Test Accuracy :0.98032<br/>Test AUC : 0.83164<br/>Test Precision : 0.05842<br/>Test Recall : 0.68243<br/>Test F1 : 0.10762<br/>Confusion Matrix : <br/> [[83342  1628]<br/> [   47   101]]</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es nm"><img src="../Images/5f17a601858af24a1a4b50f53bca7d72.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*jtuMz2MAyrx7YqNP90f4uw.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">KNNs分类器的ROC曲线</figcaption></figure><h2 id="64a2" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated">6.XG增强分类器</h2><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><pre class="jc jd je jf fd mz na nb nc aw nd bi"><span id="d21e" class="ko jl hh na b fi ne nf l ng nh">Model Name : XGBOOST IMBALANCED<br/>Test Accuracy :0.99954<br/>Test AUC : 0.90871<br/>Test Precision : 0.90977<br/>Test Recall : 0.81757<br/>Test F1 : 0.86121<br/>Confusion Matrix : <br/> [[84958    12]<br/> [   27   121]]<br/><br/><br/>Model Name : XGBOOST UNDERSAMPLE<br/>Test Accuracy :0.91485<br/>Test AUC : 0.92025<br/>Test Precision : 0.01858<br/>Test Recall : 0.92568<br/>Test F1 : 0.03643<br/>Confusion Matrix : <br/> [[77733  7237]<br/> [   11   137]]<br/><br/><br/>Model Name : XGBOOST OVERSAMPLE<br/>Test Accuracy :0.99948<br/>Test AUC : 0.91206<br/>Test Precision : 0.87143<br/>Test Recall : 0.82432<br/>Test F1 : 0.84722<br/>Confusion Matrix : <br/> [[84952    18]<br/> [   26   122]]<br/><br/><br/>Model Name : XGBOOST SMOTE<br/>Test Accuracy :0.99935<br/>Test AUC : 0.91874<br/>Test Precision : 0.80000<br/>Test Recall : 0.83784<br/>Test F1 : 0.81848<br/>Confusion Matrix : <br/> [[84939    31]<br/> [   24   124]]<br/><br/><br/>Model Name : XGBOOST ADASYN <br/>Test Accuracy :0.99928<br/>Test AUC : 0.91533<br/>Test Precision : 0.77358<br/>Test Recall : 0.83108<br/>Test F1 : 0.80130<br/>Confusion Matrix : <br/> [[84934    36]<br/> [   25   123]]</span></pre><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es nn"><img src="../Images/b09ea509c1d535ca9787f1bc5804f550.png" data-original-src="https://miro.medium.com/v2/resize:fit:686/format:webp/1*Bvcly1EFycwBhy_BvT0dBQ.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">XGBOOST分类器的ROC曲线</figcaption></figure><h2 id="7630" class="ko jl hh bd jm kp kq kr jq ks kt ku ju ip kv kw jy it kx ky kc ix kz la kg lb bi translated">7.MLP分类器</h2><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es no"><img src="../Images/aafe084576e0e73d5eeebc2b1fbbfb83.png" data-original-src="https://miro.medium.com/v2/resize:fit:1176/format:webp/1*XzW0iLAKvh4tRF8kJmTgSA.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">XGBOOST分类器的ROC曲线</figcaption></figure><p id="0c07" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们将比较测试数据集的所有F1分数(因为对于不平衡的数据集来说，准确性不是一个好的指标)，并将比较所有模型(和所有数据集)的F1分数。</p><p id="7236" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为此，我们将创建一个字典“comparision”，其中键是标签，值是包含我们之前添加的所有模型的分数的列表。</p><figure class="jc jd je jf fd jg"><div class="bz dy l di"><div class="jh ji l"/></div></figure><figure class="jc jd je jf fd jg er es paragraph-image"><div class="er es np"><img src="../Images/b26a146993a8823361ab9c0426651c24.png" data-original-src="https://miro.medium.com/v2/resize:fit:1124/format:webp/1*zGrRV8mOxPVxfscqWI-1zQ.png"/></div><figcaption class="lz ma et er es mb mc bd b be z dx translated">描述各种分类器比较的图像(应用了数据不平衡技术)</figcaption></figure><p id="cb4a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">XGBoost(超过样本)的F1值最高，与XGBoost(不平衡)的F1值相同。接下来是随机森林(过采样)。</p><h1 id="677b" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">结论</h1><p id="11cc" class="pw-post-body-paragraph ie if hh ig b ih ki ij ik il kj in io ip kk ir is it kl iv iw ix km iz ja jb ha bi translated">在这篇博客中，我们了解到在构建模型的过程中，数据不平衡是一个需要处理的主要挑战。我们比较了不同分类算法处理数据不平衡的不同技术。</p><h1 id="a96a" class="jk jl hh bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">参考</h1><div class="nq nr ez fb ns nt"><a href="https://ieeexplore.ieee.org/document/4633969" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab dw"><div class="nv ab nw cl cj nx"><h2 class="bd hi fi z dy ny ea eb nz ed ef hg bi translated">ADASYN:用于不平衡学习的自适应合成采样方法</h2><div class="oa l"><h3 class="bd b fi z dy ny ea eb nz ed ef dx translated">提出了一种新的自适应合成(ADASYN)采样方法，用于不平衡数据集的学习。的…</h3></div><div class="ob l"><p class="bd b fp z dy ny ea eb nz ed ef dx translated">ieeexplore.ieee.org</p></div></div><div class="oc l"><div class="od l oe of og oc oh lx nt"/></div></div></a></div><div class="nq nr ez fb ns nt"><a href="https://towardsdatascience.com/how-to-deal-with-imbalanced-data-34ab7db9b100" rel="noopener follow" target="_blank"><div class="nu ab dw"><div class="nv ab nw cl cj nx"><h2 class="bd hi fi z dy ny ea eb nz ed ef hg bi translated">如何处理不平衡数据</h2><div class="oa l"><h3 class="bd b fi z dy ny ea eb nz ed ef dx translated">Python中处理不平衡数据集的分步指南</h3></div><div class="ob l"><p class="bd b fp z dy ny ea eb nz ed ef dx translated">towardsdatascience.com</p></div></div><div class="oc l"><div class="oi l oe of og oc oh lx nt"/></div></div></a></div><div class="nq nr ez fb ns nt"><a href="https://www.guru99.com/confusion-matrix-machine-learning-example.html" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab dw"><div class="nv ab nw cl cj nx"><h2 class="bd hi fi z dy ny ea eb nz ed ef hg bi translated">机器学习中的混淆矩阵及实例</h2><div class="oa l"><h3 class="bd b fi z dy ny ea eb nz ed ef dx translated">什么是混淆矩阵？混淆矩阵是一种机器学习的性能测量技术…</h3></div><div class="ob l"><p class="bd b fp z dy ny ea eb nz ed ef dx translated">www.guru99.com</p></div></div><div class="oc l"><div class="oj l oe of og oc oh lx nt"/></div></div></a></div><div class="nq nr ez fb ns nt"><a href="https://www.kaggle.com/drscarlat/fraud-detection-under-oversampling-smote-adasyn" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab dw"><div class="nv ab nw cl cj nx"><h2 class="bd hi fi z dy ny ea eb nz ed ef hg bi translated">过采样、SMOTE、ADASYN下的欺诈检测</h2><div class="oa l"><h3 class="bd b fi z dy ny ea eb nz ed ef dx translated">使用Kaggle笔记本探索和运行机器学习代码|使用信用卡欺诈检测数据</h3></div><div class="ob l"><p class="bd b fp z dy ny ea eb nz ed ef dx translated">www.kaggle.com</p></div></div><div class="oc l"><div class="ok l oe of og oc oh lx nt"/></div></div></a></div><div class="nq nr ez fb ns nt"><a href="https://www.kaggle.com/mlg-ulb/creditcardfraud" rel="noopener  ugc nofollow" target="_blank"><div class="nu ab dw"><div class="nv ab nw cl cj nx"><h2 class="bd hi fi z dy ny ea eb nz ed ef hg bi translated">信用卡欺诈检测</h2><div class="oa l"><h3 class="bd b fi z dy ny ea eb nz ed ef dx translated">标记为欺诈或真实的匿名信用卡交易</h3></div><div class="ob l"><p class="bd b fp z dy ny ea eb nz ed ef dx translated">www.kaggle.com</p></div></div><div class="oc l"><div class="ol l oe of og oc oh lx nt"/></div></div></a></div></div></div>    
</body>
</html>