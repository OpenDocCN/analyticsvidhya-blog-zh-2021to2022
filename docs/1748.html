<html>
<head>
<title>ML24: Top 4% in Titanic on Kaggle</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">ML24:Kaggle上《泰坦尼克号》的前4%</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/ml24-7f32a79eb024?source=collection_archive---------23-----------------------#2021-03-15">https://medium.com/analytics-vidhya/ml24-7f32a79eb024?source=collection_archive---------23-----------------------#2021-03-15</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><div class=""><h2 id="fb62" class="pw-subtitle-paragraph ie hg hh bd b if ig ih ii ij ik il im in io ip iq ir is it iu iv dx translated">将交互添加到随机森林</h2></div><p id="3079" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">查看GitHub 上的库以获得完整的细节。</p><ul class=""><li id="b995" class="jt ju hh iy b iz ja jc jd jf jv jj jw jn jx jr jy jz ka kb bi translated">在2020/05年的<a class="ae js" href="https://www.kaggle.com/c/titanic" rel="noopener ugc nofollow" target="_blank">泰坦尼克号:机器从灾难中学习</a>中排名前4 % (833/22219)，这是Kaggle上一个标志性的入门级比赛。这个项目是<em class="kc">和R </em>一起进行的。</li><li id="b4bd" class="jt ju hh iy b iz kd jc ke jf kf jj kg jn kh jr jy jz ka kb bi translated">这实际上是NCCU CS系<em class="kc">研究生层次</em>课程<em class="kc">“数据科学】</em>的一个作业。另外我这门课考了<strong class="iy hi"> <em class="kc"> 96 (A+) </em> </strong>。</li></ul><div class="ki kj kk kl fd ab cb"><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/b7cd2e56c05336623322d987c76d24c6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*2GJRVhv_PaEdErZRmHD7kg.png"/></div></figure><figure class="km kn ko kp kq kr ks paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><img src="../Images/a2a5da5518dce794253fb256b7e52d5d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*8KZfk7S-ktTKFSI6k2vouw.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx ld di le lf translated">图1和2:在Kaggle上泰坦尼克号的公共排行榜上排名前4%。</figcaption></figure></div><p id="d02a" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我在三向分割下使用10倍随机森林得到了0.89的测试数据准确性。</p><figure class="ki kj kk kl fd kn er es paragraph-image"><div class="er es lg"><img src="../Images/7524b1ebd96f586247790b30b4ceef8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:752/format:webp/1*zwOlaZ54hPFDJstht5q52A.png"/></div><figcaption class="kz la et er es lb lc bd b be z dx translated">图Kaggle给出的整个数据集的分数。</figcaption></figure><blockquote class="lh li lj"><p id="cd82" class="iw ix kc iy b iz ja ii jb jc jd il je lk jg jh ji ll jk jl jm lm jo jp jq jr ha bi translated"><strong class="iy hi"> <em class="hh">概要</em> </strong> <em class="hh"> <br/> (1)特征简介<br/> (2)缺失值插补<br/> (3)特征工程<br/> (4)特征提取<br/> (5)模型选择</em></p></blockquote></div><div class="ab cl ln lo go lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ha hb hc hd he"><h1 id="0987" class="lu lv hh bd lw lx ly lz ma mb mc md me in mf io mg iq mh ir mi it mj iu mk ml bi translated">(1)特性介绍</h1><figure class="ki kj kk kl fd kn er es paragraph-image"><div role="button" tabindex="0" class="kt ku di kv bf kw"><div class="er es mm"><img src="../Images/cc12209d9539124f9e42b273a6f376a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MmPlqXuSVgib6uaEWykW9w.png"/></div></div><figcaption class="kz la et er es lb lc bd b be z dx translated">图4:特性的细节。</figcaption></figure><p id="8cfe" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这张快照拍摄于2021年3月。特征“名称”在这一点上已经被删除。在这10个变量中，“生存”显然是目标，其余9个变量都是特征。所以在我做这个项目的时候(2020/05 ),我有10个特点。</p></div><div class="ab cl ln lo go lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ha hb hc hd he"><h1 id="a2f6" class="lu lv hh bd lw lx ly lz ma mb mc md me in mf io mg iq mh ir mi it mj iu mk ml bi translated">(2)缺失值插补</h1><pre class="ki kj kk kl fd mn mo mp mq aw mr bi"><span id="f74b" class="ms lv hh mo b fi mt mu l mv mw">mice.data &lt;- mice(Raw,<br/>                  m = 1,            <br/>                  maxit = 50,      # max iteration<br/>                  method = "rf", <br/>                  seed = 188,<br/>                  print=FALSE)</span></pre><p id="2ce8" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">缺失值填补作为预处理中的一个重要步骤，却常常被搁置一旁。读者可以查看<a class="ae js" href="https://morton-kuo.medium.com/ml23-1b08fb0dd4b0" rel="noopener"> ML23:处理缺失值</a>，了解为什么正确处理缺失值会非常有帮助。</p><p id="e288" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">当然，我们可以用均值、中值或众数来估算缺失值；然而，有先进的ML算法插补方法可能会产生更好的结果。所以我用r中的<em class="kc">小鼠()</em>选择了<em class="kc">随机森林</em>。</p></div><div class="ab cl ln lo go lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ha hb hc hd he"><h1 id="caf9" class="lu lv hh bd lw lx ly lz ma mb mc md me in mf io mg iq mh ir mi it mj iu mk ml bi translated">(3)特征工程</h1><p id="b628" class="pw-post-body-paragraph iw ix hh iy b iz mx ii jb jc my il je jf mz jh ji jj na jl jm jn nb jp jq jr ha bi translated">读者可以在GitHub 上查看<a class="ae js" href="https://github.com/mortonkuo/Top_4_pct_Titanic_Kaggle" rel="noopener ugc nofollow" target="_blank">资源库，了解这里的完整细节。通过分别检查目标“survival”和每个特征的交叉表，我能够揭示如何将非数字数据分成可由“survival”区分的类别。</a></p><p id="94ab" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">至于数字数据，实际上，我已经尝试过对数转换和将数字数据转换成分类数据，但都不起作用。</p></div><div class="ab cl ln lo go lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ha hb hc hd he"><h1 id="acf0" class="lu lv hh bd lw lx ly lz ma mb mc md me in mf io mg iq mh ir mi it mj iu mk ml bi translated">(4)特征提取</h1><p id="8ffa" class="pw-post-body-paragraph iw ix hh iy b iz mx ii jb jc my il je jf mz jh ji jj na jl jm jn nb jp jq jr ha bi translated">利用高阶术语和交互的逐步线性回归(使用stepwise())，我能够选择一些有影响的特性。</p><p id="9f3f" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">我认为<strong class="iy hi"> <em class="kc">这一部分可能是我仅仅使用一个模型</em> </strong>(随机森林)而没有利用堆叠获得前4%排名的原因。<em class="kc">在随机森林</em>中加入互动，这是一个颇具创意的举动，可能会导致成功。</p></div><div class="ab cl ln lo go lp" role="separator"><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls lt"/><span class="lq bw bk lr ls"/></div><div class="ha hb hc hd he"><h1 id="db23" class="lu lv hh bd lw lx ly lz ma mb mc md me in mf io mg iq mh ir mi it mj iu mk ml bi translated">(5)型号选择</h1><p id="0e4d" class="pw-post-body-paragraph iw ix hh iy b iz mx ii jb jc my il je jf mz jh ji jj na jl jm jn nb jp jq jr ha bi translated">然后，我将这些有影响的特征输入到模型中，并在每个模型中尝试这些特征的组合。我尝试的模型从朴素贝叶斯、线性回归、SVM、随机森林、XGBoost到神经网络。最终，我发现随机森林产生了最好的结果。</p><p id="95f5" class="pw-post-body-paragraph iw ix hh iy b iz ja ii jb jc jd il je jf jg jh ji jj jk jl jm jn jo jp jq jr ha bi translated">这里有几个我见过的最好的模特。请注意，我<em class="kc">甚至没有采用堆叠</em>但已经获得了令人满意的前4% (833/22219)排名。</p><pre class="ki kj kk kl fd mn mo mp mq aw mr bi"><span id="efea" class="ms lv hh mo b fi mt mu l mv mw">fold1_rf   = randomForest( Survived ~ Title + Family_size:Sex_Survival + Fare + Embarked , data= Titanic_train , ntree = 1000, importance = F)</span><span id="5667" class="ms lv hh mo b fi nc mu l mv mw">fold1_rf01 = randomForest( Survived ~ Title + Family_size:Sex_Survival + Fare + Embarked , data=Titanic_train , ntree = 1000, importance = F)</span><span id="8b9d" class="ms lv hh mo b fi nc mu l mv mw">fold1_rf02 = randomForest( Survived ~ Title + Family_size:Sex_Survival + Fare:Age + Embarked + Ticket_02 , data=Titanic_train , ntree = 1000, importance = F)</span></pre></div></div>    
</body>
</html>