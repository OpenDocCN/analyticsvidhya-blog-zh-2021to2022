<html>
<head>
<title>VGGNet — Convolutional Network for Classification and Detection</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">VGGNet —用于分类和检测的卷积网络</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/vggnet-convolutional-network-for-classification-and-detection-3543aaf61699?source=collection_archive---------7-----------------------#2021-07-11">https://medium.com/analytics-vidhya/vggnet-convolutional-network-for-classification-and-detection-3543aaf61699?source=collection_archive---------7-----------------------#2021-07-11</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/dfb4f0a7a1491e5c6e486d438d98aa73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hs8Ud3X2LBzf5XMAFTmGGw.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">VGG16的架构——由<a class="ae it" href="https://www.researchgate.net/profile/Max-Ferguson" rel="noopener ugc nofollow" target="_blank"> Max Ferguson </a>在ResearchGate上传</figcaption></figure><h1 id="c45e" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">介绍</h1><p id="fa38" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated"><strong class="ju hi"> VGG16 </strong>是英国牛津大学的K. Simonyan和A. Zisserman在论文“<a class="ae it" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank">用于大规模图像识别的甚深卷积网络</a>”中提出的卷积神经网络模型。该模型在ImageNet中达到了92.7%的top-5测试准确率，ImageNet是一个包含1000个类的超过1400万个图像的数据集。它是提交给<a class="ae it" href="https://image-net.org/challenges/LSVRC/2014/" rel="noopener ugc nofollow" target="_blank"> ILSVRC-2014 </a>的著名模型之一。它通过用多个3×3内核大小的滤波器相继替换大内核大小的滤波器(第一和第二卷积层中分别为11和5个)来改进AlexNet。VGG16接受了数周的训练，使用的是NVIDIA Titan Black GPU。</p><h1 id="9383" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">ImageNet</h1><p id="8510" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated"><a class="ae it" href="http://www.image-net.org/" rel="noopener ugc nofollow" target="_blank"> ImageNet </a>是一个数据集，包含超过1500万张带有标签的高分辨率图像，属于大约22，000个类别。这些图片是从网上收集来的，由人类标签员用亚马逊的机械土耳其人众包工具贴上标签。从2010年开始，作为Pascal视觉对象挑战赛的一部分，每年都会举办一次名为ImageNet大规模视觉识别挑战赛(ILSVRC)的比赛。ILSVRC使用ImageNet的一个子集，在1000个类别中的每一个类别中大约有1000个图像。大约有120万幅训练图像、50，000幅验证图像和150，000幅测试图像。ImageNet由不同分辨率的图像组成。因此，图像被下采样到256×256的固定分辨率。给定一个矩形图像，该图像被重新缩放并从结果图像的中心256×256小块中裁剪出来。</p><h1 id="31c0" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">VGG16的架构</h1><p id="46f4" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">下图所示的架构是VGG16。</p><figure class="kq kr ks kt fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/dfb4f0a7a1491e5c6e486d438d98aa73.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hs8Ud3X2LBzf5XMAFTmGGw.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">VGG16架构</figcaption></figure><p id="fee1" class="pw-post-body-paragraph js jt hh ju b jv ku jx jy jz kv kb kc kd kw kf kg kh kx kj kk kl ky kn ko kp ha bi translated">cov1层的输入是固定大小的224 x 224 RGB图像。图像通过一叠卷积层，在卷积层中，过滤器与一个微小的感受域一起使用:3×3(这是捕捉左/右、上/下、中心概念的最小尺寸)。在其中一种配置中，它还利用1×1卷积滤波器，可视为输入通道的线性变换(后跟非线性)。卷积步距固定为1个像素；卷积层输入的空间填充使得在卷积后保持空间分辨率，即对于3×3卷积层，填充是1像素。空间池由五个最大池层执行，这五个最大池层跟随一些卷积层(并非所有卷积层都跟随最大池)。最大池化在2×2像素窗口上执行，步长为2。</p><p id="b1b0" class="pw-post-body-paragraph js jt hh ju b jv ku jx jy jz kv kb kc kd kw kf kg kh kx kj kk kl ky kn ko kp ha bi translated">三个全连接(FC)层跟随一个卷积层堆栈(在不同的架构中具有不同的深度):前两个各有4096个通道，第三个执行1000路ILSVRC分类，因此包含1000个通道(每个类别一个)。最后一层是最大柔化层。全连接层的配置在所有网络中都是相同的。</p><p id="ff06" class="pw-post-body-paragraph js jt hh ju b jv ku jx jy jz kv kb kc kd kw kf kg kh kx kj kk kl ky kn ko kp ha bi translated">所有隐藏层都配备了校正(ReLU)非线性。还注意到，没有一个网络(除了一个)包含本地响应标准化(LRN)。这种规范化不会提高ILSVRC数据集的性能，但会增加内存消耗和计算时间。</p><h1 id="5ec4" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">配置</h1><p id="f44a" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">ConvNet配置如图2所示。这些网被称为它们的名字(A-E)。所有配置都遵循架构中的通用设计，只是深度不同:从网络A中的11个权重层(8个卷积层和3个FC层)到网络E中的19个权重层(16个卷积层和3个FC层)。卷积层的宽度(通道数)相当小，从第一层的64开始，然后在每个最大池层之后增加2倍，直到达到512。</p><figure class="kq kr ks kt fd ii er es paragraph-image"><div class="er es kz"><img src="../Images/979a359043ad3f61702de96e4a010f21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1128/format:webp/1*onjub2RiHuwEyPWxZB01vA.jpeg"/></div><figcaption class="ip iq et er es ir is bd b be z dx translated">VGGNet的ConvNet配置</figcaption></figure><h1 id="edd9" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">用例及实现</h1><p id="b00f" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">VGGNet有两个主要缺点:</p><ol class=""><li id="50ce" class="la lb hh ju b jv ku jz kv kd lc kh ld kl le kp lf lg lh li bi translated">训练慢得令人痛苦。</li><li id="f8e8" class="la lb hh ju b jv lk jz ll kd lm kh ln kl lo kp lf lg lh li bi translated">网络架构权重本身相当大(关于磁盘/带宽)。</li></ol><p id="6c71" class="pw-post-body-paragraph js jt hh ju b jv ku jx jy jz kv kb kc kd kw kf kg kh kx kj kk kl ky kn ko kp ha bi translated">由于其深度和全连接节点的数量，VGG16超过533MB。这使得部署VGG成为一项令人厌倦的任务。VGG16用于很多深度学习图像分类问题；然而，更小的网络架构往往更可取(如SqueezeNet、GoogLeNet等。).但是对于学习来说，它是一个很好的构建模块，因为它很容易实现。</p><h1 id="5391" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">结果</h1><p id="48e5" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">VGG16在ILSVRC-2012和ILSVRC-2013比赛中明显优于上一代车型。VGG16的结果也在争夺分类任务的冠军(误差为6.7%的GoogLeNet)，并大大超过了ILSVRC-2013获奖提交的Clarifai，后者在有外部训练数据的情况下达到了11.2%，没有外部训练数据的情况下达到了11.7%。在单网性能方面，VGG16架构取得了最好的结果(7.0%的测试误差)，比单个GoogLeNet高出0.9%。</p><figure class="kq kr ks kt fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es lp"><img src="../Images/df160f83dc0492c8cbc47bcea64839f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9SUjCqRUg4SmRkh-CYCBug.jpeg"/></div></div><figcaption class="ip iq et er es ir is bd b be z dx translated">模型性能比较</figcaption></figure><h1 id="743a" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">参考</h1><ul class=""><li id="f1ec" class="la lb hh ju b jv jw jz ka kd lq kh lr kl ls kp lt lg lh li bi translated"><a class="ae it" href="https://neurohive.io/en/popular-networks/vgg16/" rel="noopener ugc nofollow" target="_blank">https://neurohive.io/en/popular-networks/vgg16/</a></li></ul><h1 id="a765" class="iu iv hh bd iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp jq jr bi translated">关于作者:</h1><p id="a980" class="pw-post-body-paragraph js jt hh ju b jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp ha bi translated">本文由马来西亚<a class="ae it" href="https://arkmind.com.my" rel="noopener ugc nofollow" target="_blank"> Arkmind </a>技术负责人韩胜撰写。他对软件设计/架构相关的东西、计算机视觉以及边缘设备充满热情。他开发了几个基于人工智能的网络/移动应用程序来帮助客户解决现实世界的问题。你可以通过他的<a class="ae it" href="https://github.com/hansheng0512" rel="noopener ugc nofollow" target="_blank"> Github简介</a>来了解他。</p></div></div>    
</body>
</html>