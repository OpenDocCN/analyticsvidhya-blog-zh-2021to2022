<html>
<head>
<title>Akira’s Machine Learning news — #issue 30</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Akira的机器学习新闻——第30期</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/akiras-machine-learning-news-issue-30-6364860348eb?source=collection_archive---------11-----------------------#2021-10-04">https://medium.com/analytics-vidhya/akiras-machine-learning-news-issue-30-6364860348eb?source=collection_archive---------11-----------------------#2021-10-04</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><h2 id="4111" class="il im hh bd in io ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji bi translated">本周特稿/新闻。</h2><ul class=""><li id="e21c" class="jj jk hh jl b jm jn jo jp iw jq ja jr je js jt ju jv jw jx bi translated"><a class="ae jy" href="https://arxiv.org/abs/2108.02774" rel="noopener ugc nofollow" target="_blank">有人提出了一项研究</a>，该研究使用一些草图来调整GAN的参数。然后，它将学习生成图像来匹配草图图像。</li><li id="d8a5" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ju jv jw jx bi translated"><a class="ae jy" href="https://arxiv.org/abs/2108.08810" rel="noopener ugc nofollow" target="_blank">关于ViT和CNN </a> s获得的特征差异的研究已经提出。与CNN不同，ViT似乎倾向于在浅层和深层获得相似的特征。这似乎与ViT的机制有关，它可以从初始层获取全局特征。</li></ul><p id="8450" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><p id="23bc" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">在下面的章节中，我将介绍各种文章和论文，不仅仅是关于上述内容，还包括以下五个主题。</p><ol class=""><li id="218e" class="jj jk hh jl b jm kg jo kj iw kv ja kw je kx jt ky jv jw jx bi translated">本周特稿/新闻</li><li id="5c89" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">机器学习用例</li><li id="1afe" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">报纸</li><li id="246b" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">机器学习技术相关文章</li><li id="54ad" class="jj jk hh jl b jm jz jo ka iw kb ja kc je kd jt ky jv jw jx bi translated">其他主题</li></ol><p id="aa48" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="c39c" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">1.本周特稿/新闻</h1><p id="83c1" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated">【arxiv.org】<strong class="jl hi">调整甘配图</strong><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2108.02774" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es lt"><img src="../Images/bb4151b947414931597e68e316778816.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8bbDkKZcqLlDb8J-7bspMQ.png"/></div></div></figure><p id="c4f6" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2108.02774]画出你自己的GAN图<br/>这是一项研究，利用一些插图对GAN图进行微调，以生成与插图相匹配的图像。生成的图像被返回到草图，并用鉴别器训练以确定其真实性。也可以修改自然图像以匹配草图。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="d914" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2108.08810?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">ViT和CNN在获得的表征上有什么不同？</strong></a><strong class="jl hi">——</strong>【arxiv.org】<strong class="jl hi"/></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mf"><img src="../Images/e7276120ac6f71a3eea0adaece186790.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2lNQt-oKzLRdUsX8lojiTg.png"/></div></div></figure><p id="1e18" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2108.08810]视觉变形器看起来像卷积神经网络吗？<br/>ViT与CNN的差异研究。上面写着:CNN在浅层和深层得到不同的表征，而ViT得到相对相似的表征；ViT从一开始就使用全局信息；ViT的跳跃连接在层表示的相似性等方面起着重要的作用。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="34e2" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="a361" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">2.机器学习用例</h1><p id="0dcf" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" rel="noopener" href="/predict/how-to-build-an-ai-unicorn-in-6-years-87b7967e1ac1?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter"> <strong class="jl hi">一个AI创业公司的创始故事</strong></a><strong class="jl hi">——</strong><a class="ae jy" rel="noopener" href="/predict/how-to-build-an-ai-unicorn-in-6-years-87b7967e1ac1"><strong class="jl hi">medium.com</strong></a></p><div class="mg mh ez fb mi mj"><a rel="noopener follow" target="_blank" href="/predict/how-to-build-an-ai-unicorn-in-6-years-87b7967e1ac1"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">如何在6年内打造一只AI独角兽</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">我是如何做到的(你也能做到)从对技术一无所知开始</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">medium.com</p></div></div><div class="ms l"><div class="mt l mu mv mw ms mx md mj"/></div></div></a></div><p id="2b12" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">Tractable是一家市值10亿美元的初创公司，其前六年的经历分为四个部分，最后一部分是关于日本Tokio Marine &amp; Nichido的挑战。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="561e" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="da3e" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">3.报纸</h1><p id="5c00" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2108.09084?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">极低计算复杂度变压器</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2108.09084" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es my"><img src="../Images/036c2c4be2172ab8fabd3ce0dc83e9c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tCm2mcJlDsHV1v_nBPmUvQ.png"/></div></div></figure><p id="ef97" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2108.09084]Fastformer:Additive Attention可以是你所需要的全部<br/>作者提出了fast former，这是一种计算复杂度为N-d的转换器。与传统的转换器不同，它不会为整个令牌构建N注意力图，而是使用查询的加权平均值作为全局特征，并将其元素乘积作为注意力。在5个数据集上的结果与其他方法相当。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="0622" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">【arxiv.org】<strong class="jl hi">注意，可以聚合本地信息</strong><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2106.13112" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es mz"><img src="../Images/569bf6bef4bd1f864e3bcf0db054ae08.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Cux-70M6Ja4p5V_Mg479uw.png"/></div></div></figure><p id="f5c8" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2106.13112]VOLO:Vision Outlook er for Visual Recognition<br/>作者提出了一种注意力机制Outlook Attention，它可以聚合大小为K的外围信息以获得局部信息，并在仅使用ImageNet学习的任务上实现SotA性能。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="0bd5" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2109.00024?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2109.00024" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es na"><img src="../Images/e771f49029ab36006a9d977f597a9ebb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IccD3LAwTfF__KJd9CBaeQ.png"/></div></div></figure><p id="108e" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2109.00024]机器学习媒体偏见<br/>这是一项可视化媒体偏见的研究。从报纸上出现的短语的频率来看，作者获得了接近人类感官的结果，使我们能够定量地可视化政治偏见和其他因素。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="0d72" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2109.04838?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">修剪模型中的一些参数</strong></a><strong class="jl hi">—</strong><a class="ae jy" href="https://arxiv.org/abs/2109.04838" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div class="ab fe cl nb"><img src="../Images/f3315b7eab21d18970b92254f65dffb6.png" data-original-src="https://miro.medium.com/v2/0*S6YcMazeLtRKdLtk"/></div></figure><p id="c816" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2109.04838]用于更快的变压器的块修剪<br/>作者提出了块修剪，该块修剪使用总结其一些参数的单元来修剪模型。与传统的剪枝不同，它可以很容易地应用于Transformer，并且不需要与知识提取相结合。它导致模型大小减少了74%，推理速度提高了2.4倍，F1分数仅下降了1%。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="c1be" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2109.04454?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">结合arxiv.org</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2109.04454" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi"/></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es nc"><img src="../Images/fcd4d5a11a444e3520b5b99079d6c8a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tu3n_r0nTnF9v4CMHd_XKw.png"/></div></div></figure><p id="3f28" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2109.04454] ConvMLP:用于视觉的分层卷积MLP<br/>尽管MLP混合器具有很高的精度，但将其应用于物体检测仍具有挑战性，因为它只能在固定维度上进行处理。因此，他们提出了ConvMLP，它结合了Conv和MLP，并采用分层结构来处理这个问题。因此，ConvMLP也可应用于物体检测，并以少量参数提供高度精确的结果。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="0e33" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://arxiv.org/abs/2109.01696?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">改进ResNet在动作识别上达到SotA水平。</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://arxiv.org/abs/2109.01696" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">arxiv.org</strong></a></p><figure class="lu lv lw lx fd ly er es paragraph-image"><div role="button" tabindex="0" class="lz ma di mb bf mc"><div class="er es nd"><img src="../Images/dce199d46c642f3fc22c1f873f9edd49.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6o2bZGzbuHWQb6E1PNpuAg.png"/></div></div></figure><p id="aeef" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">[2109.01696]重温3D ResNets进行视频识别<br/>这是一项在动作识别任务中将ResNet-3D提高到SotA水平的研究。通过引入dropbox、随机深度、RandAug等改进了网络结构。，作为正规化。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="04b0" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="7ffc" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">4.机器学习技术相关文章</h1><p id="d71a" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://bdtechtalks.com/2021/09/10/computer-vision-deep-learning-threat-detection/?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">把对付恶意软件当成“计算机视觉”问题</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://bdtechtalks.com/2021/09/10/computer-vision-deep-learning-threat-detection/" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">【bdtechtalks.com】</strong></a></p><div class="mg mh ez fb mi mj"><a href="https://bdtechtalks.com/2021/09/10/computer-vision-deep-learning-threat-detection/" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">计算机视觉和深度学习提供了检测网络威胁的新方法</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">本文是我们对人工智能研究论文的评论的一部分，这是一系列探索人工智能最新发现的文章</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">bdtechtalks.com</p></div></div><div class="ms l"><div class="ne l mu mv mw ms mx md mj"/></div></div></a></div><p id="74b7" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">本文介绍了一个将恶意软件检测作为计算机视觉问题来处理的案例研究。例如，恶意软件包含各种ASCII字符，可以将其可视化为一个计算机视觉问题。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="9fe5" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://thenextweb.com/news/researchers-created-new-technique-stop-adversarial-attacks-syndication?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">检测对抗性攻击</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://thenextweb.com/news/researchers-created-new-technique-stop-adversarial-attacks-syndication" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">thenextweb.com</strong></a></p><div class="mg mh ez fb mi mj"><a href="https://thenextweb.com/news/researchers-created-new-technique-stop-adversarial-attacks-syndication" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">研究人员创造了一种新技术来阻止恶意攻击</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">你知道Neural今年秋天会登台吗？与令人惊叹的专家阵容一起，我们将探索…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">thenextweb.com</p></div></div><div class="ms l"><div class="nf l mu mv mw ms mx md mj"/></div></div></a></div><p id="e72b" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">一篇文章是关于对抗性攻击的检测方法。本文解释了如何通过从GradCAM等显著图中重建图像来检测对抗性攻击。</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="8ced" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated"><a class="ae jy" href="https://www.deeplearningweekly.com/p/deep-learning-weekly-self-supervised?utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">自学入门</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://www.deeplearningweekly.com/p/deep-learning-weekly-self-supervised" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">www.deeplearningweekly.com</strong></a></p><div class="mg mh ez fb mi mj"><a href="https://www.deeplearningweekly.com/p/deep-learning-weekly-self-supervised" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">深度学习周刊:自我监督学习深度潜水</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">嘿伙计们，今天，我们向你们发送我们的第三次深潜！我们的目的是对给定的主题提供精确的检查。今天…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">www.deeplearningweekly.com</p></div></div><div class="ms l"><div class="ng l mu mv mw ms mx md mj"/></div></div></a></div><p id="8a1e" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">一篇关于自我监督学习的简介文章。它给出了概述，原则，应用和未来的前景。</p><p id="f6d4" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="cf64" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">5.其他主题</h1><p id="8a55" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated"><a class="ae jy" href="https://twitter.com/PyTorch/status/1437838231505096708?s=20&amp;utm_campaign=Akira%27s%20Machine%20Learning%20News%20%20%20&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" rel="noopener ugc nofollow" target="_blank"> <strong class="jl hi">在PyTorch中加速推理</strong></a><strong class="jl hi">——</strong><a class="ae jy" href="https://twitter.com/PyTorch/status/1437838231505096708?s=20" rel="noopener ugc nofollow" target="_blank"><strong class="jl hi">twitter.com</strong></a></p><figure class="lu lv lw lx fd ly"><div class="bz dy l di"><div class="nh ni l"/></div></figure><p id="2b58" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">Pytorch官方关于在Pytoch中加速推理的帖子，描述了torch.no_grad和torch.inference_mode的用法</p></div><div class="ab cl ie if go ig" role="separator"><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij ik"/><span class="ih bw bk ii ij"/></div><div class="ha hb hc hd he"><p id="86a1" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="778c" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">🌟我每周发布时事通讯！请订阅！🌟</h1><div class="mg mh ez fb mi mj"><a href="https://www.getrevue.co/profile/akiratosei" rel="noopener  ugc nofollow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">阿基拉的机器学习新闻- Revue</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">由Akira的机器学习新闻-由Akihiro FUJII:制造工程师/机器学习工程师/硕士…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">www.getrevue.co</p></div></div><div class="ms l"><div class="nj l mu mv mw ms mx md mj"/></div></div></a></div><p id="acd5" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="e185" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">其他博客</h1><div class="mg mh ez fb mi mj"><a href="https://towardsdatascience.com/machine-learning-2020-summary-84-interesting-papers-articles-45bd45c0d35b" rel="noopener follow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">机器学习2020摘要:84篇有趣的论文/文章</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">在这篇文章中，我总共展示了2020年发表的84篇我觉得特别有趣的论文和文章…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">towardsdatascience.com</p></div></div><div class="ms l"><div class="nk l mu mv mw ms mx md mj"/></div></div></a></div><div class="mg mh ez fb mi mj"><a href="https://towardsdatascience.com/recent-developments-and-views-on-computer-vision-x-transformer-ed32a2c72654" rel="noopener follow" target="_blank"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">计算机视觉x变形金刚的最新发展和看法</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">《变形金刚》和CNN的区别，为什么《变形金刚》很重要，它的弱点是什么。</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">towardsdatascience.com</p></div></div><div class="ms l"><div class="nl l mu mv mw ms mx md mj"/></div></div></a></div><div class="mg mh ez fb mi mj"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/reach-and-limits-of-the-supermassive-model-gpt-3-5012a6ddff00"><div class="mk ab dw"><div class="ml ab mm cl cj mn"><h2 class="bd hi fi z dy mo ea eb mp ed ef hg bi translated">超大质量模型GPT-3的到达和极限</h2><div class="mq l"><h3 class="bd b fi z dy mo ea eb mp ed ef dx translated">在这篇博文中，我将从技术上解释GPT 3号，GPT 3号取得了什么，GPT 3号没有取得什么…</h3></div><div class="mr l"><p class="bd b fp z dy mo ea eb mp ed ef dx translated">medium.com</p></div></div><div class="ms l"><div class="nm l mu mv mw ms mx md mj"/></div></div></a></div><p id="0dba" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi">— — — — — — — — — — — — — — — — — — –</p><h1 id="0e16" class="kz im hh bd in la lb lc ir ld le lf iv lg lh li iz lj lk ll jd lm ln lo jh lp bi translated">关于我</h1><p id="ff0b" class="pw-post-body-paragraph ke kf hh jl b jm jn kh ki jo jp kk kl iw lq kn ko ja lr kq kr je ls kt ku jt ha bi translated">制造工程师/机器学习工程师/数据科学家/物理学硕士/<a class="ae jy" href="https://t.co/hjHHbG24Ph?amp=1" rel="noopener ugc nofollow" target="_blank">http://github.com/AkiraTOSEI/</a></p><p id="6373" class="pw-post-body-paragraph ke kf hh jl b jm kg kh ki jo kj kk kl iw km kn ko ja kp kq kr je ks kt ku jt ha bi translated">推特，我贴一句纸评论。</p></div></div>    
</body>
</html>