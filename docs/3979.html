<html>
<head>
<title>Unsupervised Learning: Hierarchical Clustering and DBSCAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">无监督学习:层次聚类和DBSCAN</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/unsupervised-learning-hierarchical-clustering-and-dbscan-c38ffd8273d2?source=collection_archive---------1-----------------------#2021-08-15">https://medium.com/analytics-vidhya/unsupervised-learning-hierarchical-clustering-and-dbscan-c38ffd8273d2?source=collection_archive---------1-----------------------#2021-08-15</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><div class=""><h2 id="edc2" class="pw-subtitle-paragraph if hh hi bd b ig ih ii ij ik il im in io ip iq ir is it iu iv iw dx translated"><strong class="ak">在客户数据集中实施的温和介绍</strong></h2></div><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es ix"><img src="../Images/a13a6ad4d594bf70d93f64c5bac3ca50.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i0znaHgYtDIExyJz5jpgrw.jpeg"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:谷歌图片</figcaption></figure><p id="4273" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在机器学习中，有很多方法可以将我们的数据点分组，以便基于相似性进行进一步分析。作为数据科学家或数据分析师，我们知道这种方法叫做聚类。最常用的聚类算法是<strong class="jp hj"> K-means聚类算法</strong>。它如此受欢迎是因为这个算法如此简单和强大。它计算质心并迭代，直到我们找到一个最佳质心来分组数据点，组的数量由<strong class="jp hj"> K </strong>表示。</p><p id="3d3f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">然而，我不打算讨论K-means。我将解释其他聚类算法，如<strong class="jp hj">层次聚类</strong>和<strong class="jp hj"> DBSCAN </strong>。你们中的一些人可能已经知道这两种算法，但对我来说，这是新的东西，我对它很着迷。无论如何，让我们开始第一个！！</p><h1 id="aa62" class="kj kk hi bd kl km kn ko kp kq kr ks kt io ku ip kv ir kw is kx iu ky iv kz la bi translated"><strong class="ak">层次聚类</strong></h1><p id="d6bf" class="pw-post-body-paragraph jn jo hi jp b jq lb ij js jt lc im jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated">这种算法也像K-means算法一样流行。在K-means聚类中，我们需要在进行聚类之前定义聚类的数量或K，而在层次聚类中，是算法本身通过使用称为树状图的树形来自动找到潜在的聚类数量供我们决定。</p><p id="d3c1" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> <em class="lg">什么是树状图？</em>T15】</strong></p><p id="70d9" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><em class="lg">树状图</em>是显示对象之间层次关系的图表。通过使用它，我们可以看到我们将在接下来的步骤中使用的集群数量。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es lh"><img src="../Images/c52ea146fa28ad876aeae45fc3ee28f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1386/format:webp/1*cOWN0gp9wVuEgTh0d2KSHQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:走向数据科学</figcaption></figure><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es li"><img src="../Images/c83e6aeb78f846bea3b1df07b9a3cb77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/format:webp/0*ljJA-eJKqQZpdFea.jpg"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:谷歌图片</figcaption></figure><p id="23ea" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我们可以看到最后一张图中有两个变量。第一个是数据点本身(样本索引)，第二个是距离。这个图中的距离是欧几里德距离的表示。从图中，我们可以看到总体上有一个大的集群。然而，如果我们将距离缩短为60，那么将只有三个集群(绿色集群、红色集群(数字3、4和2)以及最后一个红色集群)。我们应该缩短距离，因为如果距离太大，聚类中的数据点可能没有一定的相似性。</p><p id="168b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">有两种层次聚类技术:</strong></p><p id="daf3" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 1。凝聚层次聚类</strong></p><p id="50da" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这是一种自下而上的方法，最初，每个数据点被认为是一个自己的聚类，相似的数据点或聚类合并为一个，在进一步迭代寻找聚类，直到一个聚类或K个聚类形成。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lj"><img src="../Images/5304a7e953319a16f17f9c26c5ab9741.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*TXU94D3J7Wy8qLBu.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:极客中的极客</figcaption></figure><p id="b39d" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 2。分裂层次聚类(DIANA) </strong></p><p id="5708" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">相比之下，DIANA是一种自上而下的方法，它将所有的数据点分配到一个聚类中，然后将该聚类分成两个最不相似的聚类。我们递归地处理每个聚类，直到每个观察都有一个聚类。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es lj"><img src="../Images/683d75578dd83e4daa78bb184ca1055e.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/0*0Snd55Fri3F9U0Up.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:极客为极客</figcaption></figure><p id="3a6b" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">实施</strong></p><ol class=""><li id="0e1b" class="lk ll hi jp b jq jr jt ju jw lm ka ln ke lo ki lp lq lr ls bi translated">可视化我们数据的树状图</li></ol><pre class="iy iz ja jb fd lt lu lv lw aw lx bi"><span id="b42b" class="ly kk hi lu b fi lz ma l mb mc">#Check the dendrogram <br/>plt.figure(figsize = (12, 8))<br/>dendogram = sch.dendrogram(sch.linkage(X_pc, method = 'ward'))<br/>plt.title('Dendrogram')<br/>plt.xlabel('Customers')<br/>plt.ylabel('Distance')<br/>plt.show()</span></pre><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es md"><img src="../Images/60d21ccf45fa99a46a2b0cb162d07c12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yJYQV1VKK4qLFYY-tbVfIQ.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">树状图</figcaption></figure><p id="e945" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">2.使用聚集聚类对数据进行聚类</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="831f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">3.将聚类结果追加到新数据集中</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="b632" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">结果:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mg"><img src="../Images/c36a6b1a459dcd75be189a20fbf15e02.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yFMIroF9KnkBklAkldS6xg.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">聚类可视化</figcaption></figure><p id="aa58" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">为什么要分层聚类？</strong></p><p id="e2f4" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">它的一个优点是不必预先定义聚类数，这使它比K-Means等算法更有优势。然而，当我们有大量的数据时，它并不能很好地工作。</p><h1 id="f4f2" class="kj kk hi bd kl km kn ko kp kq kr ks kt io ku ip kv ir kw is kx iu ky iv kz la bi translated"><strong class="ak"> DBSCAN(带噪声的应用程序的基于密度的空间聚类)</strong></h1><p id="0df1" class="pw-post-body-paragraph jn jo hi jp b jq lb ij js jt lc im jv jw ld jy jz ka le kc kd ke lf kg kh ki hb bi translated">现在，我们已经讨论了分区方法(K-means)和分层聚类，我们将讨论<strong class="jp hj">基于密度的带噪声应用空间聚类(DBSCAN)方法</strong>。大多数情况下，聚类算法的工作是寻找球形聚类，并受到数据中存在的噪声和异常值的严重影响。因此，对于包含大量噪声的真实生活数据，聚类的结果有时不是很好。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div role="button" tabindex="0" class="jd je di jf bf jg"><div class="er es mh"><img src="../Images/aa8d9eeae3274aeef0f2235804cb48ae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pdSAHvOx1MZhEYIr.png"/></div></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:瑞安·温盖特</figcaption></figure><p id="884c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">在这里，数据库可以解决这个问题。聚类是数据空间中的密集区域，由点密度较低的区域分隔开。DBSCAN基于“簇”和“噪声”的直观概念。关键思想是，对于一个聚类中的每个点，给定半径的邻域必须至少包含最小数量的点。</p><p id="39f8" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> DBSCAN参数</strong></p><p id="c5fe" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 1。Eps </strong></p><p id="858e" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">Eps是邻域的最大半径。它定义了数据点周围的邻域，即如果两点之间的距离小于或等于“eps ”,则它们被视为邻居。找到eps值的一种方法是基于<strong class="jp hj">k-距离图</strong>。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mi"><img src="../Images/648d340b9ff30f6d7f48519730af50fe.png" data-original-src="https://miro.medium.com/v2/resize:fit:1220/format:webp/1*ycfscUvgD--7RZyWWxaBIQ.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:谷歌图片，作者做了一些编辑</figcaption></figure><p id="b045" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">如果<strong class="jp hj"> eps值太小</strong>，那么<strong class="jp hj">数据的大部分将被视为</strong>异常值。如果<strong class="jp hj">非常大</strong>，那么聚类<strong class="jp hj">将合并</strong>，并且大多数数据点将<strong class="jp hj">在相同的聚类中。</strong></p><p id="3c55" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj"> 2。MinPts </strong></p><p id="7c24" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">MinPts是该点的eps邻域(Eps半径内)中的最小点数。数据集越大，必须选择越大的MinPts值。一个简单的方法是从数据集中的维数D中导出minPts。<strong class="jp hj"> minPts &gt; = D + 1 </strong>。对于2D数据，取minPts = 4。</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mj"><img src="../Images/0b5b29c2576730089f7cb0eebb9e9ea6.png" data-original-src="https://miro.medium.com/v2/resize:fit:696/format:webp/1*lS4MbK-tI7JqBFXh_FpeCA.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">来源:极客为极客</figcaption></figure><p id="3eb2" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">核心</strong>:距离自身<em class="lg"> n </em>以内至少有<em class="lg"> m </em>个点的点。</p><p id="ba43" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">边界</strong>:在距离<em class="lg"> n </em>处至少有一个核心点的点。</p><p id="d8af" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">噪点</strong>:既不是核心也不是边界的点。它就像一个离群值。它与自身的距离<em class="lg"> n </em>内少于<em class="lg"> m </em>个点。</p><p id="1a9f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">这就是我们在这个算法中的3种数据点。</p><p id="7753" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">实施</strong></p><ol class=""><li id="2a85" class="lk ll hi jp b jq jr jt ju jw lm ka ln ke lo ki lp lq lr ls bi translated">使数据符合DBSCAN算法</li></ol><pre class="iy iz ja jb fd lt lu lv lw aw lx bi"><span id="72a1" class="ly kk hi lu b fi lz ma l mb mc">#Use DBSCAN, -1 value means outliers<br/>dbscan = DBSCAN(eps = 10, min_samples = 5)<br/>y_pc_db = dbscan.fit_predict(X_pc)<br/>y_pc_db</span></pre><p id="e8ca" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">结果:</p><pre class="iy iz ja jb fd lt lu lv lw aw lx bi"><span id="e7c2" class="ly kk hi lu b fi lz ma l mb mc">array([-1,  0, -1,  0, -1,  0, -1, -1, -1,  0, -1, -1, -1,  0, -1,  0, -1,<br/>        0, -1, -1, -1,  0, -1,  0, -1,  0, -1, -1, -1,  0, -1,  0, -1, -1,<br/>       -1,  0, -1,  0, -1,  0, -1, -1,  1,  1, -1, -1,  1,  1,  1,  1,  1,<br/>        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,<br/>        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,<br/>        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,<br/>        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,<br/>        1,  1,  1, -1,  2, -1,  2,  1,  2, -1,  2, -1,  2, -1,  2, -1,  2,<br/>       -1,  2, -1,  2, -1,  2, -1,  2, -1,  2, -1,  2, -1,  2,  3,  2,  3,<br/>        2, -1,  2, -1,  2, -1,  2, -1,  2, -1,  2, -1,  2,  3,  2,  3, -1,<br/>        3,  2, -1,  2, -1,  2, -1,  2, -1,  2, -1,  2, -1,  2, -1,  2, -1,<br/>       -1, -1,  2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1])</span></pre><p id="66fe" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">您可以注意到聚类结果的值为-1。这些值是数据集中的噪声。</p><p id="cc23" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">2.将聚类结果追加到新数据集中</p><figure class="iy iz ja jb fd jc"><div class="bz dy l di"><div class="me mf l"/></div></figure><p id="d9c7" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">结果:</p><figure class="iy iz ja jb fd jc er es paragraph-image"><div class="er es mk"><img src="../Images/57e24b9dcaee0a04595ea19672245159.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*PWYXyaEhaB6dV1pQ7ZobEw.png"/></div><figcaption class="jj jk et er es jl jm bd b be z dx translated">3D聚类可视化</figcaption></figure><p id="152c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">记得以前，我们有-1值，那些蓝色点是-1值(噪声)。这里，我们有四个集群。我们可以使用下面的代码来检查这是不是真的。</p><pre class="iy iz ja jb fd lt lu lv lw aw lx bi"><span id="621b" class="ly kk hi lu b fi lz ma l mb mc">target = X_pc_db['cluster']<br/>print(target.nunique()) # number of clusters</span></pre><p id="f9ad" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">结果:</p><pre class="iy iz ja jb fd lt lu lv lw aw lx bi"><span id="abee" class="ly kk hi lu b fi lz ma l mb mc">4</span></pre><p id="a45c" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated"><strong class="jp hj">为什么选择DBSCAN？</strong></p><p id="bb4a" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">它可以根据您的输入数据<br/>和参数自动检测集群的数量。DBSCAN可以处理噪声和异常值。所有离群值将被识别和标记，而不被分类到任何聚类中。因此，DBSCAN也可以用于异常检测(异常值检测)。然而，这种算法对于大量杂乱的数据集仍然是困难的。</p></div><div class="ab cl ml mm gp mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hb hc hd he hf"><p id="e8c3" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">我打算解释另一种结合这两种方法的聚类算法，层次聚类和DBSCAN聚类。你能想象这些算法有多强大吗？</p><p id="d43f" class="pw-post-body-paragraph jn jo hi jp b jq jr ij js jt ju im jv jw jx jy jz ka kb kc kd ke kf kg kh ki hb bi translated">给你个提示，这个算法的名字是以H开头的，里面有DBSCAN这个词。h代表分级，DBSCAN代表DBSCAN算法。所以，它不会很快出版，因为我需要有心情来写它。但是希望在阅读了关于层次集群和DBSCAN的解释之后，您能有所收获。</p></div></div>    
</body>
</html>