<html>
<head>
<title>DISCRIMINANT ANALYSIS — A CONCEPTUAL UNDERSTANDING</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">判别分析——概念上的理解</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/discriminant-analysis-a-conceptual-understanding-c2ccc0dd2906?source=collection_archive---------7-----------------------#2021-01-28">https://medium.com/analytics-vidhya/discriminant-analysis-a-conceptual-understanding-c2ccc0dd2906?source=collection_archive---------7-----------------------#2021-01-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="c7b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi jc translated">判别分析是一种处理带有响应变量和预测变量的数据的分类技术。它主要用于根据数据的自变量将观察值分类到一个类或类别中。判别分析的两种类型:线性判别分析和二次判别分析。</p><h1 id="ae8e" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">线性判别分析(LDA): </strong></h1><p id="2bb2" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">它是一种监督技术，试图使用自变量的线性组合来预测因变量的类别。它假设独立变量是正态分布的(连续的和数字的),并且类的方差/协方差相等。这种技术既可以用于分类，也可以用于降维。当这些假设得到满足时，LDA创建一个线性决策边界。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es kp"><img src="../Images/2dd3d2e4dc1c863ac3cfd593ac1e716f.png" data-original-src="https://miro.medium.com/v2/resize:fit:544/format:webp/1*c-lDZS70K-HtLLS-lv6pLQ.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">线性判别分析</figcaption></figure><p id="0120" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这条线可以清楚地区分数据集中的0和1。因此，LDA的目标是论证区分0和1的最佳界限。然而，即使当这些假设被违反时，LDA也表现良好。</p><h1 id="1b8d" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak"> LDA技术:</strong></h1><p id="3efb" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">DS =β0+β1 * X1+β2 * X2+—+βk * Xk</p><p id="ff2e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在哪里</p><p id="b728" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">DS:判别分数</p><p id="7fba" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">β:判别权重/系数</p><p id="f66e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">x:独立变量</p><p id="cff4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">估计权重，以便尽可能清楚地根据判别函数将各组分开。LDA构建了一个等式，该等式最小化了将病例错误分类到其各自类别中的可能性。</p><h1 id="77b7" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">LDA的假设:</strong></h1><p id="3901" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">1.多元正态性-所有标签的独立变量应该是正态分布的。</p><p id="be20" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.所有类的方差和协方差相等。</p><p id="6044" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.没有多重共线性，如果存在，如果结果受到影响，需要进行处理。</p><p id="132d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.数据中的所有样本应该是相互独立的。</p><h1 id="4c96" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">LDA表现良好的标准:</strong></h1><p id="76e4" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">1.最大限度地减少将案例错误分类到各自类别的可能性。</p><p id="654d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.点离线的距离，即滞后点离分隔线有多远。</p><p id="d76a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.在LHS的概率和在RHS的概率。</p><h1 id="3cb6" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">标准化、非标准化和结构系数:</strong></h1><p id="4840" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">标准化变量的主要目的(其中均值变为0，标准差变为1，协方差变为相关)是为了引入数值稳定性。如果自变量有单位，那么βs将继承相应单位的倒数。从而使βs不含单位，对原始自变量进行标准化。βs的值越高，意味着相应的自变量在区分因变量类别时变得越重要。它还向我们展示了可变的重要性。与线性回归不同，LDA更倾向于自变量之间的相关性更强。</p><h1 id="d59b" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated">什么时候使用LDA？:</h1><p id="0445" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">1.当阶级划分得很清楚的时候。当类被很好地分开时，逻辑回归缺乏稳定性，也就是当LDA来拯救时。</p><p id="3014" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.当数据量很小时，LDA的效率更高。</p><p id="711f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.当我们有两个以上的班级时，LDA是更好的选择。在二元分类的情况下，逻辑回归和LDA都可以应用。</p><h1 id="d93d" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">执行LDA的步骤:</strong></h1><p id="483b" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">1.计算数据集不同类别的d维均值向量。</p><p id="bf6e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.计算类间方差，即不同类平均值之间的可分性。</p><p id="ee1e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.计算类内方差，即每个类的平均值和样本之间的可分性。</p><p id="0949" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.计算散射矩阵的特征向量和相应的特征值。对应于实非零特征值的特征向量指向被变换拉伸的方向，并且特征值是它被拉伸的因子。负特征值意味着方向相反。</p><p id="b0f8" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">5.通过降低特征值对特征向量进行排序，并选择具有最大特征值的k个特征向量来形成(n×k)维矩阵。</p><p id="91df" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">6.使用最大化类间方差和最小化类内方差的Fisher标准构建低维空间投影。</p><h1 id="711d" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">LDA是如何做预测的？:</strong></h1><p id="14aa" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">LDA模型使用贝叶斯定理来估计概率。它们根据新输入数据集属于每个类的概率进行预测。概率最高的类是输出类，然后LDA进行预测。简单地通过使用贝叶斯定理进行预测，该定理估计给定输入时输出的概率。它们还利用了每个类别的概率以及属于该类别的数据。</p><h1 id="70b6" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">LDA与其他技术的比较:</strong></h1><p id="829c" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">1.LDA、ANOVA和回归分析将因变量表示为自变量的线性组合。</p><p id="e0a7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.LDA中的因变量是分类变量，自变量是连续变量。方差分析使用分类自变量和连续因变量。</p><p id="490d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.LDA与PCA和因子分析密切相关，因为两者都是线性变换技术，即它们寻找最佳解释数据的变量的线性组合。</p><p id="23cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">4.LDA是一种监督技术，而PCA是一种非监督技术，因为它忽略了类别标签。</p><h1 id="d87e" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">LDA的应用:</strong></h1><p id="47e5" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">1.0和1的分离。</p><p id="4a10" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">2.物体的识别</p><p id="be28" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">3.模式识别任务</p><h1 id="2f9b" class="jm jn hh bd jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj bi translated"><strong class="ak">二次判别分析:</strong></h1><p id="8a7c" class="pw-post-body-paragraph ie if hh ig b ih kk ij ik il kl in io ip km ir is it kn iv iw ix ko iz ja jb ha bi translated">这是LDA的一种变体，使用自变量的二次组合来预测因变量的类别。它不假设类的协方差相等，但是正态分布的假设仍然成立。QDA创建了一个二次决策边界。</p><p id="fc73" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">DS =β1 * X1+β2 * X2+β3 * X12+β4 * X22+β5 * X1 * X2</p><p id="a4e5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">然而，QDA不能用于降维。</p><figure class="kq kr ks kt fd ku er es paragraph-image"><div class="er es lb"><img src="../Images/98746b7dfa38ca29240e4391eb708a22.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/format:webp/1*jDH8KpuMZIi12BrGWYyT-Q.png"/></div><figcaption class="kx ky et er es kz la bd b be z dx translated">二次判别分析</figcaption></figure></div></div>    
</body>
</html>