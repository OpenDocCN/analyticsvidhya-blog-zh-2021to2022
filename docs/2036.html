<html>
<head>
<title>What is StyleGAN? An overview of the key concepts of StyleGAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">StyleGAN是什么？StyleGAN关键概念概述</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/what-is-stylegan-an-overview-of-the-key-concepts-of-stylegan-3c1031775fb?source=collection_archive---------3-----------------------#2021-04-02">https://medium.com/analytics-vidhya/what-is-stylegan-an-overview-of-the-key-concepts-of-stylegan-3c1031775fb?source=collection_archive---------3-----------------------#2021-04-02</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><figure class="ev ex ig ih ii ij er es paragraph-image"><div class="er es if"><img src="../Images/a1a3f306d8832f1d3fe081953c3033cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:788/format:webp/1*SRmW3Vce3aN8TKAbuSq-hg.png"/></div></figure><p id="3f76" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">StyleGAN[1]最初于2019年提出，通过将姿势和面部表情等高级属性与头发和雀斑等图像的随机变化分离开来，在基于风格的生成器架构创建逼真图像方面表现出惊人的性能。此外，它旨在通过引入中间潜在空间W来扩展潜在空间，生成器从该中间潜在空间W而不是经典潜在向量进行推断。</p><h1 id="d065" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">关键概念</h1><ul class=""><li id="79a1" class="ki kj hi io b ip kk it kl ix km jb kn jf ko jj kp kq kr ks bi translated">学习的“风格”而不是潜在向量解开了复杂的图像空间，并实现了潜在空间中的平滑过渡。</li><li id="a390" class="ki kj hi io b ip kt it ku ix kv jb kw jf kx jj kp kq kr ks bi translated">使用AdaIN或条件批处理规范化，样式以各种比例应用于发生器的生成过程。</li><li id="eeb2" class="ki kj hi io b ip kt it ku ix kv jb kw jf kx jj kp kq kr ks bi translated">在每个尺度上添加随机噪声，以将随机变化添加到模型中。</li><li id="cf59" class="ki kj hi io b ip kt it ku ix kv jb kw jf kx jj kp kq kr ks bi translated">本文中应用的每种方法都通过各种指标进行了比较和评估。</li></ul><h1 id="9462" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">风格建筑</h1><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es ky"><img src="../Images/ae3ebfa92261b14a806e9938c318c4b4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*RhBcWCIyBkD5MZGKkngZoA.png"/></div></figure><p id="0554" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">StyleGAN基于渐进式GAN[2]发生器和鉴别器。不同之处在于，初始的4x4x512是一个恒定的学习向量，而潜在向量是通过样式映射生成的，并通过AdaIN层馈入生成器。鉴别器架构和损耗函数(WGAN-GP)与渐进式GAN并无不同。</p><h2 id="aab6" class="ld jl hi bd jm le lf lg jq lh li lj ju ix lk ll jy jb lm ln kc jf lo lp kg lq bi translated">样式映射和AdaIN</h2><p id="25a2" class="pw-post-body-paragraph im in hi io b ip kk ir is it kl iv iw ix lr iz ja jb ls jd je jf lt jh ji jj hb bi translated">总之，潜在的z通过非线性映射网络f: z -&gt; W映射到风格映射W。映射函数是全连接的非线性函数或具有泄漏ReLU激活的8层MLP。学习到的风格映射W被线性地转换成AdaIn层的多个向量“A”。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es lu"><img src="../Images/9164c846d87251ada2d717475052c907.png" data-original-src="https://miro.medium.com/v2/resize:fit:492/format:webp/1*n42Cn0g22elwOlNh2vWz7A.png"/></div></figure><p id="45f7" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">AdaIN操作定义如上，基本上是一个基于学习向量y进行缩放的通道式批量归一化层。在这种情况下，y是根据相应层的A向量计算的。因此，风格向量W可以在生成的不同阶段缩放网络的各种特征。</p><h2 id="0f6e" class="ld jl hi bd jm le lf lg jq lh li lj ju ix lk ll jy jb lm ln kc jf lo lp kg lq bi translated">随机变化的随机噪声</h2><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es lv"><img src="../Images/7761444a1e98eada785eaf41dc9c2518.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3QkJEkOCnftdNwnx0fmamQ.png"/></div></div></figure><p id="96a6" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">为了给图像提供随机变化，随机噪声B的矢量被添加到网络的多层中。结果如上所示。该模型可以生成不同的头发纹理和背景，同时保留面部的重要细节。这对于克服来自鉴别器的压力以通过简单地利用给定的噪声和模型来产生新的图像以集中于产生真实的图像是特别有用的。</p><h2 id="69de" class="ld jl hi bd jm le lf lg jq lh li lj ju ix lk ll jy jb lm ln kc jf lo lp kg lq bi translated">风格混合/混合正则化</h2><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es ma"><img src="../Images/4c440b1f9cc7b34b9aa381f2732ceb0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*C6atJ2Toyo32xPmIoJ6NQg.png"/></div></div></figure><p id="11bf" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">风格混合，就像上图中的结果一样，是通过混合图像不同尺度的风格向量来实现的。这证明了W空间捕捉图像“风格”的有效性。例如，4x4、8x8的粗糙样式会影响图像的姿势和发型，16x16、32x32的中等样式会带来较小比例的面部特征，而精细比例的样式会改变配色方案和细节。</p><p id="26be" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">使用混合正则化，在训练期间使用两个随机潜在码而不是一个来生成一定百分比的图像。这被应用来引导样式按照预期进行调整，并生成如上图所示的惊人的图像混合。</p><h2 id="69d9" class="ld jl hi bd jm le lf lg jq lh li lj ju ix lk ll jy jb lm ln kc jf lo lp kg lq bi translated">风格空间</h2><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es mb"><img src="../Images/f0acdd1807ecbc6fb4e0460313bcfede.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XNZfvHVlSLzgbyWDEbwHBA.png"/></div></div></figure><p id="6202" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">您可能想知道为什么在将z映射到W之后再输入到生成器中有助于提高性能。这是因为它解开了潜在空间和图像的空间。因为潜像空间和图像空间是连续的，并且生成器必须为每个潜像向量提供看似合理的图像。但是通过从z到W的非线性映射，W不必总是固定的形状，因此生成器在潜在空间中布置图像的压力较小。</p><h1 id="b761" class="jk jl hi bd jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh bi translated">实验</h1><figure class="kz la lb lc fd ij er es paragraph-image"><div class="er es mc"><img src="../Images/f7e14b0ac828fd0aa76b6b34622ad139.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*OZ2XT9YfWv5QuL5P-STP2g.png"/></div><figcaption class="md me et er es mf mg bd b be z dx translated">各种模型设置的结果</figcaption></figure><p id="ef3f" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">上表显示了本文中讨论的方法的有效性。B操作意味着在渐进增长阶段使用双线性上/下采样来放大图像。FFHQ数据集是与本文一起提出的一种新数据集，根据作者的说法，它比CelebA-HQ数据集具有更大的多样性，CelebA-HQ数据集最初是从名人的面部构建的。</p><figure class="kz la lb lc fd ij er es paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><div class="er es mh"><img src="../Images/a5d9a008fe43dae560e8596f03c2026d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ih1-R-3cTcqLP6Uj9p8sFw.png"/></div></div></figure><p id="74fb" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">上表比较了产生W空间的方法。路径长度通过从两幅图像之间的潜在向量生成的图像的VGG嵌入的差异来计算。</p><p id="ffc8" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">如果一个潜在空间被充分地解开，应该有可能找到与个体变异因素一致的方向向量。可分离性得分通过训练线性SVM来预测基于潜在空间的标签，从而衡量属性在整个潜在分布中的分离程度。这样我们可以测量潜在空间和人类理解的类之间的线性关系的强度。</p><p id="2c56" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">根据图表，通过增加潜在编码的复杂性，FID没有显著改变，但是可分离性似乎增加了，并且潜在空间中的翻译图像似乎变得更加平滑。这证明了所提出的StyleGAN成功地学习并分离了风格空间w中的各种风格。</p></div><div class="ab cl mi mj gp mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="hb hc hd he hf"><h1 id="8b4f" class="jk jl hi bd jm jn mp jp jq jr mq jt ju jv mr jx jy jz ms kb kc kd mt kf kg kh bi translated">参考</h1><p id="77e2" class="pw-post-body-paragraph im in hi io b ip kk ir is it kl iv iw ix lr iz ja jb ls jd je jf lt jh ji jj hb bi translated">[1]一种基于风格的生成式对抗网络生成器架构(<a class="ae mu" href="https://arxiv.org/abs/1812.04948" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1812.04948</a></p><p id="b146" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">[2]为了提高质量、稳定性和多样性而逐步种植甘蔗(【https://arxiv.org/abs/1710.10196】T2</p><p id="0dd5" class="pw-post-body-paragraph im in hi io b ip iq ir is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj hb bi translated">我们将通过在LSUN数据集上使用这种惊人的方法生成更多示例来结束本文。</p><div class="kz la lb lc fd ab cb"><figure class="mv ij mw mx my mz na paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/a5ee6a3ea2a02417239eeffe2a3f5419.png" data-original-src="https://miro.medium.com/v2/resize:fit:1348/format:webp/1*dWMNrXuKI299nhK_t3Hk4Q.png"/></div></figure><figure class="mv ij nb mx my mz na paragraph-image"><div role="button" tabindex="0" class="lw lx di ly bf lz"><img src="../Images/4dfab9ac0cb73d4fca22af49ee9685ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:654/format:webp/1*56A7ymaCAT7jqNvYa5MYRw.png"/></div></figure></div></div></div>    
</body>
</html>