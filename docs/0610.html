<html>
<head>
<title>Machine Learning Algorithms: Naïve Bayes Classifier and KNN Classifier</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习算法:朴素贝叶斯分类器和KNN分类器</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/machine-learning-algorithms-na%C3%AFve-bayes-classifier-and-knn-classifier-266537e9c2f2?source=collection_archive---------6-----------------------#2021-01-24">https://medium.com/analytics-vidhya/machine-learning-algorithms-na%C3%AFve-bayes-classifier-and-knn-classifier-266537e9c2f2?source=collection_archive---------6-----------------------#2021-01-24</a></blockquote><div><div class="ds gw gx gy gz ha"/><div class="hb hc hd he hf"><div class=""/><p id="f166" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">在机器学习算法系列的第二篇文章中，我将重点介绍朴素贝叶斯分类器和KNN分类器。它们都是使用的最简单的算法类型之一，并且更容易实现。朴素贝叶斯分类器基于概率概念，广泛用于垃圾邮件过滤。K-最近邻分类器基于特征相似性原理工作。让我们深入研究这些算法:)</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es jd"><img src="../Images/6796e21638e4ab674ce840d4b55855ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4BMbqkE_vep3-t0z"/></div></div><figcaption class="jp jq et er es jr js bd b be z dx translated">Anthony Intraversato 在<a class="ae jt" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</figcaption></figure><h1 id="9a21" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">朴素贝叶斯分类器</h1><p id="ce13" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">这种算法被称为nave，因为它基于一个简单的假设，即特征是独立的。朴素贝叶斯分类器的工作原理是贝叶斯定理。贝叶斯定理是分析领域中最基本的概念之一，有着广泛的应用。它通常在决策过程中起着至关重要的作用。让我们考虑两个事件A和b。相关的条件概率由下式给出:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es kx"><img src="../Images/5e90b2925b70ba54b1342cbb7c74c572.png" data-original-src="https://miro.medium.com/v2/resize:fit:726/format:webp/0*87jQ4ub1l53V7poe.png"/></div></div></figure><blockquote class="ky kz la"><p id="a195" class="if ig lb ih b ii ij ik il im in io ip lc ir is it ld iv iw ix le iz ja jb jc hb bi translated"><em class="hi">一个事件A给定B的条件概率(P(A|B))是给定B已经发生的概率。它通常被定义为A和B的联合概率(A和B一起发生的概率)与A的边际概率(事件A的概率)之比</em></p></blockquote><p id="ff4a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">使用以上两个等式，我们可以表明</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es lf"><img src="../Images/cf7b62ada5b866ae54459cd1e6edba22.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/format:webp/0*11WkgAOVgEN5u-Ig.png"/></div></figure><p id="84ed" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">上面的等式解释了贝叶斯定理。因此，对于事件B，我们可以在提供附加信息时更新关联的概率(这里A是附加信息)。</p><h2 id="edd3" class="lg jv hi bd jw lh li lj ka lk ll lm ke iq ln lo ki iu lp lq km iy lr ls kq lt bi translated">贝叶斯定理中的关键术语</h2><ol class=""><li id="d6fa" class="lu lv hi ih b ii ks im kt iq lw iu lx iy ly jc lz ma mb mc bi translated">先验概率(P(B)，P(A))-没有任何附加信息的概率值</li><li id="4bc8" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">后验概率(P(B|A))-在给定附加信息A的情况下，事件B的概率</li><li id="9e7c" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">P(A|B)-如果B为真，观察到A的可能性</li></ol><p id="404c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">有一个有趣的游戏和贝叶斯定理有关。对游戏感兴趣？继续阅读著名的蒙蒂霍尔问题。</p><div class="mi mj ez fb mk ml"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/the-math-behind-monty-hall-problem-ef7489ce7f20"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hj fi z dy mq ea eb mr ed ef hh bi translated">蒙蒂·霍尔问题背后的数学</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">当我们问统计学家概率如何改变了人类决策的视角时，第一个…</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">medium.com</p></div></div><div class="mu l"><div class="mv l mw mx my mu mz jn ml"/></div></div></a></div><p id="8e76" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当涉及到分类问题时，贝叶斯定理可以重新解释如下:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es na"><img src="../Images/a6bc4b38f71bba2097f07fe8fef1d20a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1026/format:webp/1*55y4OQsbIyzZsuePwBmCcw.png"/></div></figure><figure class="je jf jg jh fd ji er es paragraph-image"><div role="button" tabindex="0" class="jj jk di jl bf jm"><div class="er es nb"><img src="../Images/2c4fc67b7d3b190ef5252b6c69e2d286.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SzJ5ho6mHlxBFzRpz-jgDQ.png"/></div></div></figure><p id="7af4" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">其中c代表数据所属的类别，y1.y2…yn表示预测要素或标注。如果你看到分母项，可能会有证据概率为0的情况。这给组织制造了一个问题。为了解决这个问题，变量增加一个小值1，这样概率不会变为零。这种调整称为<strong class="ih hj">拉普拉斯校正。</strong></p><h2 id="e61f" class="lg jv hi bd jw lh li lj ka lk ll lm ke iq ln lo ki iu lp lq km iy lr ls kq lt bi translated">朴素贝叶斯分类的步骤</h2><ol class=""><li id="83ca" class="lu lv hi ih b ii ks im kt iq lw iu lx iy ly jc lz ma mb mc bi translated">计算所涉及类别的先验概率</li><li id="9e7b" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">计算每个类别的每个特征的证据的可能性</li><li id="1a8f" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">使用贝叶斯规则计算后验概率</li><li id="f9d5" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">为输入选择具有较高概率的类</li></ol><p id="c575" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当特征x本质上是分类的时，计算相关的概率就更容易了。当特征x连续时，我们假设变量x是正态分布(<strong class="ih hj">高斯朴素贝叶斯</strong>)。概率值由下式给出</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nc"><img src="../Images/4905565a79a1eda4dbc3798b40ceba50.png" data-original-src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*leekHjY93uCvk9BV80qRZQ.png"/></div></figure><p id="b1f1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优点</strong></p><ol class=""><li id="c5a4" class="lu lv hi ih b ii ij im in iq nd iu ne iy nf jc lz ma mb mc bi translated">易于实施</li><li id="3be0" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">在有噪声的数据中表现相当好</li></ol><p id="36ff" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">缺点</strong></p><ol class=""><li id="b006" class="lu lv hi ih b ii ij im in iq nd iu ne iy nf jc lz ma mb mc bi translated">连续功能的低性能</li><li id="ad32" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">假设特征是独立的是有风险的</li></ol><h1 id="3ed8" class="ju jv hi bd jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr bi translated">KNN分类器</h1><p id="a0b3" class="pw-post-body-paragraph if ig hi ih b ii ks ik il im kt io ip iq ku is it iu kv iw ix iy kw ja jb jc hb bi translated">k-最近邻算法可用于解决分类和回归问题。当朴素贝叶斯分类器等算法使用来自训练样本的概率进行预测时，KNN是一个懒惰的学习者，不会提前创建任何模型。只是根据特征相似性找到最近的。</p><p id="7994" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">相似性度量</strong></p><p id="ca0c" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">流行的相似性度量标准是距离度量。有几种距离测量方法可用。</p><p id="142a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">1.欧几里得距离</p><p id="5f27" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是最常用的距离测量方法。对于两点(x1，x2)和(y1，y2 ),欧几里得距离由下式给出:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ng"><img src="../Images/ddb43e97a72d3318939e51d5fec7ede1.png" data-original-src="https://miro.medium.com/v2/resize:fit:840/format:webp/1*NgW9CMEx66IeayVSvEfP1Q.png"/></div></figure><p id="fe57" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">2.曼哈顿距离</p><p id="6595" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">也被称为城市街区或绝对距离，它的灵感来自曼哈顿城的结构。对于两点(x1，x2)和(y1，y2 ),曼哈顿距离由下式给出:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nh"><img src="../Images/415a0709592400907838a96493db57b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:802/format:webp/1*T7gfh9lWa-DqbCgxNDnGwg.png"/></div></figure><p id="fe80" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">3.切比雪夫距离</p><p id="0644" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">也称为棋盘或最大值距离，对于两点(x1，x2)和(y1，y2)，切比雪夫距离由下式给出:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es ni"><img src="../Images/00a27042735e874358b4d2147f587cff.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*k4_Z2c08ufJ-NAihX4H8AA.png"/></div></figure><p id="f542" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">4.闵可夫斯基距离</p><p id="90e3" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这是一种广义的距离度量。所有上述距离都可以从通用公式中获得。</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nj"><img src="../Images/175b951f753da7d3b4ef0a2fb290d20a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*sbG0QIKEgDft120dhiAlEA.png"/></div></figure><p id="a68a" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当c =1时，闵可夫斯基=曼哈顿</p><p id="4680" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当c =2时，闵可夫斯基=欧几里得</p><p id="0a37" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">当c =3时，闵可夫斯基=切比雪夫</p><p id="1f82" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">5.马哈拉诺比斯距离</p><p id="ff10" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">为了计算多元空间中两品脱之间的距离，我们使用Mahalanobis距离。马氏距离由下式给出:</p><figure class="je jf jg jh fd ji er es paragraph-image"><div class="er es nk"><img src="../Images/d776d61efa04682d7b119d9772bed1f6.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*pNBTN6lQaWaNqb35qSsX5g.png"/></div></figure><p id="0b52" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">这里x和y是多元空间中相同分布的向量。c是协方差矩阵的逆矩阵。</p><p id="ae13" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">步骤</strong></p><ol class=""><li id="6539" class="lu lv hi ih b ii ij im in iq nd iu ne iy nf jc lz ma mb mc bi translated">根据所使用的相似性度量，查找靠近所选数据点的K个邻居。</li><li id="36ad" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">使用来自k个邻居的多数投票来识别数据点属于哪个类。</li></ol><p id="8388" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">选择K的最佳值</strong></p><p id="70aa" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">可能有两种情况:</p><ol class=""><li id="821c" class="lu lv hi ih b ii ij im in iq nd iu ne iy nf jc lz ma mb mc bi translated">K越小，噪声对结果的影响越大</li><li id="ac3c" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">高K，计算成本高</li></ol><p id="b902" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">因此，一些文章建议选择K作为sqrt(N)/2，其中N是数据点的数量。</p><p id="4982" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">优点</strong></p><ol class=""><li id="e117" class="lu lv hi ih b ii ij im in iq nd iu ne iy nf jc lz ma mb mc bi translated">易于实施</li><li id="4f02" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">不涉及假设</li></ol><p id="b755" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated"><strong class="ih hj">缺点</strong></p><ol class=""><li id="2e17" class="lu lv hi ih b ii ij im in iq nd iu ne iy nf jc lz ma mb mc bi translated">最佳K值总是一个挑战</li><li id="93d2" class="lu lv hi ih b ii md im me iq mf iu mg iy mh jc lz ma mb mc bi translated">懒惰的学习者——计算成本高</li></ol><p id="41ca" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">链接到本系列的第一篇文章:</p><div class="mi mj ez fb mk ml"><a rel="noopener follow" target="_blank" href="/analytics-vidhya/machine-learning-algorithms-logistics-regression-8ba38af531b3"><div class="mm ab dw"><div class="mn ab mo cl cj mp"><h2 class="bd hj fi z dy mq ea eb mr ed ef hh bi translated">机器学习算法:逻辑回归</h2><div class="ms l"><h3 class="bd b fi z dy mq ea eb mr ed ef dx translated">Tom Mitchell最著名的定义之一是将机器学习定义为“一个性能良好的计算机程序…</h3></div><div class="mt l"><p class="bd b fp z dy mq ea eb mr ed ef dx translated">medium.com</p></div></div><div class="mu l"><div class="nl l mw mx my mu mz jn ml"/></div></div></a></div><p id="4cf1" class="pw-post-body-paragraph if ig hi ih b ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb jc hb bi translated">希望你读得不错。请鼓掌以示支持，并关注我以获取更多文章☺</p></div></div>    
</body>
</html>