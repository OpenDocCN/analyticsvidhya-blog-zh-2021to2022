<html>
<head>
<title>How to build Spam classifier with Naive Bayes (Beginner guide)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何用朴素贝叶斯构建垃圾邮件分类器(初学者指南)</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/how-to-build-spam-classifier-with-naive-bayes-beginner-guide-6c40d2c0a559?source=collection_archive---------6-----------------------#2021-03-28">https://medium.com/analytics-vidhya/how-to-build-spam-classifier-with-naive-bayes-beginner-guide-6c40d2c0a559?source=collection_archive---------6-----------------------#2021-03-28</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><p id="05c4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在本文中，我想展示一个简单的算法，如朴素贝叶斯，实际上是如何产生有意义的结果的。我将在一个真实的数据集中介绍该算法，并向算法的利弊解释文本预处理中的每一步。</p><p id="0b97" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">朴素贝叶斯算法在分类任务中应用概率计算。这种算法属于监督机器学习算法，我们可以训练一组数据，并根据它们的类别对它们进行标记。</p><p id="f4ea" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">你也可以在我的博客上看到我的文章和代码！</p><h1 id="7a06" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">我们想要达到的目标</h1><p id="7cf6" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们将使用朴素贝叶斯创建一个模型，可以根据提供的数据集将短信分类为垃圾短信或非垃圾短信(ham)。作为人类，我们可能会发现一些垃圾邮件，我们也可以注意到一些垃圾邮件包含诸如“赢”、“赢家”、“现金”、“奖品”等词。基本上，他们想引起我们的注意，这样我们就可以点击他们。作为人类，我们也可以发现其他模式，如奇怪的字符，大量的大写字母等。</p><p id="9209" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的目标是通过使用朴素贝叶斯来模仿人类识别这些信息的能力。这是一个二元分类，这意味着它是垃圾邮件或不是垃圾邮件。</p><h1 id="ea61" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">概观</h1><p id="ec9a" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">以下项目由Udacity提供，该项目提供从市场营销到人工智能的在线课程(请注意，本文和博客都不是由Udacity赞助的)。</p><p id="8c57" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这篇博文中，我展示了该项目的一个概要版本，所以如果你想深入了解其中的解释和概念，请查阅jupyter笔记本。该项目分为以下几个步骤:</p><ul class=""><li id="e5da" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated">步骤0:朴素贝叶斯定理简介</li><li id="3117" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤1.1:了解我们的数据集</li><li id="cc8d" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤1.2:数据预处理</li><li id="01ee" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤2.1:单词袋(鞠躬)</li><li id="41ff" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤2.2:从头实现BoW(仅在Jupyter笔记本上可用，不在本文中)</li><li id="c262" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤2.3:在scikit-learn中实现单词包</li><li id="8358" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤3.1:训练和测试集</li><li id="e5c7" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤3.2:将单词包处理应用到我们的数据集。</li><li id="4a47" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤4.1:从零开始实现贝叶斯定理</li><li id="a148" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤4.2:从头开始实现朴素贝叶斯</li><li id="359e" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤5:使用scikit-learn实现朴素贝叶斯</li><li id="d19f" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">步骤6:评估我们的模型</li><li id="0c32" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">第七步:结论</li></ul><h1 id="da0b" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤0:朴素贝叶斯定理简介</h1><p id="63aa" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">定理中“幼稚”的一点，即认为每个特征都是相互独立的，这可能并不总是如此，因此会影响最终的判断。简而言之，贝叶斯定理基于某些其他事件的联合概率分布(在我们的例子中，某些单词在消息中的出现)来计算某个事件发生的概率(在我们的例子中，消息是垃圾邮件)。</p><h1 id="c002" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤1.1:了解我们的数据集</h1><p id="ffaa" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们将使用最初编译并发布在UCI机器学习知识库上的数据集，该知识库有非常好的用于实验研究目的的数据集集合。以下是数据预览:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ku"><img src="../Images/2ed40438fefa12e95a3619a3a7f26524.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*cxT1F4LaDcBRxEMr.png"/></div></div></figure><p id="8f14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">数据集中的列目前还没有命名，如您所见，有2列。第一列有两个值，“ham”表示该邮件不是垃圾邮件，“spam”表示该邮件是垃圾邮件。第二列是正在分类的SMS消息的文本内容。</p><h1 id="8e02" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤1.2:数据预处理</h1><p id="f6f6" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">现在我们对数据集有了基本的了解，为了便于计算，让我们将标签转换为二进制变量，0表示“ham”(即不是垃圾邮件)，1表示“spam”。如果我们将标签保留为字符串，我们的模型仍然能够进行预测，但是在计算性能指标时，例如在计算我们的精度和召回分数时，我们可能会遇到问题。因此，为了避免以后出现意想不到的“陷阱”，将我们的分类值作为整数输入到我们的模型中是一个很好的实践。</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="2621" class="ll je hh lh b fi lm ln l lo lp">df['label'] = df.label.map({'ham':0, 'spam':1})<br/>print(df.shape)<br/>df.head() # returns (rows, columns)</span></pre><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lq"><img src="../Images/dfb4e483835ab0d374974316510cfb1f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/0*Kv3tVhOBx1Aus8D1.png"/></div></figure><h1 id="70d8" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤2.1:单词袋</h1><p id="885d" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们的数据集中有大量的文本数据(5，572行数据)。大多数ML算法依赖于数字数据作为输入，而电子邮件/sms消息通常是大量的文本。</p><p id="5046" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">在这里，我们要介绍单词包(BoW)概念，这个术语用于指定需要处理的具有“单词包”或文本数据集合的问题。BoW的基本思想是获取一段文本，并计算该文本中单词的频率。值得注意的是，BoW概念单独处理每个单词，单词出现的顺序无关紧要。</p><p id="f837" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用我们现在将要经历的过程，我们可以将文档的集合转换成矩阵，其中每个文档是一行，每个单词(标记)是一列，相应的(行，列)值是每个单词或标记在该文档中出现的频率。</p><p id="2e2f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">例如:</p><p id="dd5d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设我们有4个文档，在我们的例子中是文本消息，如下所示:</p><p id="a14a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">['Hello, how are you!', 'Win money, win from home.', 'Call me now', 'Hello, Call you tomorrow?']</code></p><p id="cd89" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的目标是将这组文本转换为频率分布矩阵，如下所示:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es lu"><img src="../Images/c9dce7cc5954db6d6f353e200978d470.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zPiLHBVKcywYk0LD.png"/></div></div></figure><p id="600f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里我们可以看到，文档按行编号，每个单词是一个列名，对应的值是该单词在文档中的出现频率。</p><p id="f9a4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们分解一下，看看我们如何使用一小组文档来完成这种转换。</p><p id="b737" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了解决这个问题，我们将使用sklearn的<a class="ae jc" href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer" rel="noopener ugc nofollow" target="_blank">计数矢量器</a>方法，该方法执行以下操作:</p><ul class=""><li id="e817" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated">它将字符串标记化(将字符串分隔成单个单词)，并为每个标记提供一个整数ID。</li><li id="07d1" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">它计算这些标记的出现次数。</li></ul><h1 id="0d07" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤2.2:从头开始实现单词包</h1><p id="7194" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">(仅在我的存储库中的Jupyter笔记本<a class="ae jc" href="https://github.com/MLMarins/spam-classifier" rel="noopener ugc nofollow" target="_blank">上可用，不在本文中)</a></p><h1 id="9c83" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤2.3:在scikit-learn中实现单词包</h1><p id="ec76" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">这里，我们将在一个较小的文档集上创建一个频率矩阵，以确保我们理解文档术语矩阵是如何生成的。我们已经创建了一个示例文档集“文档”。</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="cc1d" class="ll je hh lh b fi lm ln l lo lp">documents = ['Hello, how are you!',<br/>                'Win money, win from home.',<br/>                'Call me now.',<br/>                'Hello, Call hello you tomorrow?']<br/>from sklearn.feature_extraction.text import CountVectorizer<br/>count_vector = CountVectorizer()</span></pre><p id="4214" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将使用CountVectorizer()提供的以下参数</p><ul class=""><li id="8473" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated"><code class="du lr ls lt lh b">lowercase = True</code></li><li id="2eae" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">lowercase</code>参数有一个默认值<code class="du lr ls lt lh b">True</code>，它将我们所有的文本转换成小写形式。</li><li id="caf1" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">token_pattern = (?u)\\b\\w\\w+\\b</code></li><li id="2b4e" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">token_pattern</code>参数有一个默认的正则表达式值<code class="du lr ls lt lh b">(?u)\\b\\w\\w+\\b</code>，它忽略所有标点符号并将其视为分隔符，同时接受长度大于或等于2的字母数字字符串作为单独的标记或单词。</li><li id="03ca" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">stop_words</code></li><li id="e3f7" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">stop_words</code>参数，如果设置为<code class="du lr ls lt lh b">english</code>，将从我们的文档集中删除所有匹配scikit-learn中定义的英语停用词列表的单词。考虑到我们的数据集很小，而且我们处理的是SMS消息，而不是像电子邮件这样较大的文本源，所以我们不会使用停用词，也不会设置这个参数值。</li></ul><p id="49d0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果:</p><p id="37c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">['are', 'call', 'from', 'hello', 'home', 'how', 'me', 'money', 'now', 'tomorrow', 'win', 'you']</code></p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="4fc8" class="ll je hh lh b fi lm ln l lo lp">doc_array = count_vector.transform(documents).toarray()<br/>frequency_matrix = pd.DataFrame(doc_array, <br/>                                columns = count_vector.get_feature_names())</span></pre><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es lv"><img src="../Images/fd49a52288117f1f2d4727e29bdf3b07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1266/format:webp/0*nYS4vMUhWp_sy4Pm.png"/></div></figure><p id="e0e3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用这种方法可能产生的一个潜在问题是，如果我们的文本数据集非常大(比方说，如果我们有大量的新闻文章或电子邮件数据)，由于语言本身的结构，某些值会比其他值更常见。例如，像“是”、“the”、“an”、代词、语法结构等词。会扭曲我们的矩阵并影响我们的分析。有几种方法可以减轻这种情况。一种方法是使用stop_words参数，并将其值设置为english。这将自动忽略我们输入文本中在scikit-learn的内置英语停用词列表中找到的所有单词。减轻这种情况的另一种方法是使用tfidf方法。</p><h1 id="abc6" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤3.1:训练和测试集</h1><p id="3576" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">既然我们已经了解了如何使用单词袋方法，我们可以返回到我们最初的、更大的UCI数据集，并继续我们的分析。我们的第一步是将数据集分为训练集和测试集，这样我们可以先训练，然后测试我们的模型。</p><p id="eaa9" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们将使用sklearn中的train_test_split方法将数据集拆分为一个训练和测试集，并打印出每个训练和测试数据中的行数。我们使用以下变量分割数据:</p><ul class=""><li id="9136" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated"><code class="du lr ls lt lh b">X_train</code>是我们为“sms_message”栏目提供的培训数据。</li><li id="f900" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">y_train</code>是我们用于“标签”列的训练数据</li><li id="f3f3" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">X_test</code>是我们对‘SMS _ message’栏目的测试数据。</li><li id="0cc8" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">y_test</code>是我们对“标签”栏的测试数据。</li></ul><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="b233" class="ll je hh lh b fi lm ln l lo lp">from sklearn.cross_validation import train_test_split</span><span id="88ee" class="ll je hh lh b fi lw ln l lo lp">X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], df['label'], random_state=1)</span></pre><h1 id="8084" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤3.2:将单词包处理应用到我们的数据集。</h1><ul class=""><li id="c195" class="kg kh hh ig b ih kb il kc ip lx it ly ix lz jb kl km kn ko bi translated">首先，我们必须将我们的训练数据(<code class="du lr ls lt lh b">X_train</code>)放入<code class="du lr ls lt lh b">CountVectorizer()</code>并返回矩阵。</li><li id="3de1" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">其次，我们必须转换我们的测试数据(<code class="du lr ls lt lh b">X_test</code>)来返回矩阵。</li></ul><p id="1cb3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，<code class="du lr ls lt lh b">X_train</code>是我们数据集中“sms_message”列的训练数据，我们将使用它来训练我们的模型。</p><p id="f032" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">X_test</code>是我们对“sms_message”列的测试数据，这是我们将使用的数据(转换为矩阵后)来进行预测。在后面的步骤中，我们将把这些预测与<code class="du lr ls lt lh b">y_test</code>进行比较。</p><p id="5190" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这个部分的代码分为两部分。首先，我们正在为训练数据学习词汇字典，然后将数据转换成文档-术语矩阵；其次，对于测试数据，我们只是将数据转换成文档术语矩阵。</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="e8ce" class="ll je hh lh b fi lm ln l lo lp"># Instantiate the CountVectorizer method<br/>count_vector = CountVectorizer()</span><span id="06df" class="ll je hh lh b fi lw ln l lo lp"># Fit the training data and then return the matrix<br/>training_data = count_vector.fit_transform(X_train)</span><span id="400f" class="ll je hh lh b fi lw ln l lo lp"># Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()<br/>testing_data = count_vector.transform(X_test)</span></pre><h1 id="b7bc" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤4.1:从零开始实现贝叶斯定理</h1><p id="432b" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">现在，我们已经有了我们需要的格式的数据集，我们可以进入我们任务的下一部分，即我们将用来进行预测以将邮件分类为垃圾邮件或非垃圾邮件的算法。请记住，在任务开始时，我们简要讨论了贝叶斯定理，但现在我们将进入更详细的讨论。通俗地说，贝叶斯定理是根据与正在讨论的事件相关的某些其他概率来计算事件发生的概率。它由“先验概率”——或者仅仅是“先验”组成。这些“先验”是我们意识到的或被赋予的可能性。贝叶斯定理也由“后验概率”组成，或者仅仅是“后验”，也就是我们希望使用“先验”来计算的概率。</p><p id="e013" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们用一个简单的例子从头开始实现贝叶斯定理。假设我们正试图找出一个人患糖尿病的几率，假设他或她接受了糖尿病测试并得到了阳性结果。在医学领域，这种概率起着非常重要的作用，因为它们经常处理生死情况。</p><p id="e7c5" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们假设如下:</p><p id="2e28" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">P(D)</code>是一个人患糖尿病的概率。它的值是<code class="du lr ls lt lh b">0.01</code>，或者换句话说，1%的普通人群患有糖尿病(免责声明:这些值是假设，并不反映任何实际的医学研究)。</p><p id="ff83" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">P(Pos)</code>是得到阳性检测结果的概率。</p><p id="d4fd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">P(Neg)</code>是得到阴性检测结果的概率。</p><p id="94f7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">P(Pos|D)</code>假设您患有糖尿病，在检测糖尿病的测试中获得阳性结果的概率。这有一个值<code class="du lr ls lt lh b">0.9</code>。换句话说，测试在90%的时候是正确的。这也被称为敏感度或真阳性率。</p><p id="0d7e" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">P(Neg|~D)</code>假设您没有糖尿病，在检测糖尿病的测试中获得阴性结果的概率。这也有一个值<code class="du lr ls lt lh b">0.9</code>，因此在90%的情况下都是正确的。这也被称为特异性或真阴性率。</p><p id="4a44" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">贝叶斯公式如下:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="er es ma"><img src="../Images/7c45a7f35f22bc449e0a2af159443940.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GWJoyf-BMN9lHKqS.png"/></div></div></figure><ul class=""><li id="96f9" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated"><code class="du lr ls lt lh b">P(A)</code>是A独立发生的先验概率。在我们的例子中，这是<code class="du lr ls lt lh b">P(D)</code>。这个值是给我们的。</li><li id="402c" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">P(B)</code>是B独立发生的先验概率。在我们的示例中，这是<code class="du lr ls lt lh b">P(Pos)</code>。</li><li id="0bd2" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">P(A|B)</code>是给定b时A出现的后验概率。在我们的示例中，这是<code class="du lr ls lt lh b">P(D|Pos)</code>。也就是说，假设一个人的测试结果为阳性，那么这个人患糖尿病的概率。这是我们要计算的价值。</li><li id="4b41" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">P(B|A)</code>是B发生的先验概率，给定a。在我们的例子中，这是<code class="du lr ls lt lh b">P(Pos|D)</code>。这个值是给我们的。</li></ul><p id="b683" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">将我们的值代入贝叶斯定理的公式，我们得到:</p><p id="b70b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">P(D|Pos) = P(D) * P(Pos|D) / P(Pos)</code></p><p id="4ab1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">获得阳性检测结果<code class="du lr ls lt lh b">P(Pos)</code>的概率可以使用灵敏度和特异性计算如下:</p><p id="53f1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">P(Pos) = [P(D) * Sensitivity] + [P(~D) * (1-Specificity))]</code></p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="394e" class="ll je hh lh b fi lm ln l lo lp"># P(D)<br/>p_diabetes = 0.01</span><span id="53ef" class="ll je hh lh b fi lw ln l lo lp"># P(~D)<br/>p_no_diabetes = 0.99</span><span id="39b0" class="ll je hh lh b fi lw ln l lo lp"># Sensitivity or P(Pos|D)<br/>p_pos_diabetes = 0.9</span><span id="6710" class="ll je hh lh b fi lw ln l lo lp"># Specificity or P(Neg|~D)<br/>p_neg_no_diabetes = 0.9</span><span id="7ba7" class="ll je hh lh b fi lw ln l lo lp"># P(Pos)<br/>p_pos = (p_diabetes * p_pos_diabetes) + (p_no_diabetes * (1 - p_neg_no_diabetes))<br/>print('The probability of getting a positive test result P(Pos) is: {}',format(p_pos))</span></pre><p id="4a14" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">得到一个肯定的测试结果P(Pos)的概率是:{} 0.107999999999</p><p id="364d" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">使用所有这些信息，我们可以计算我们的后验概率如下:</p><p id="3c6c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个人患糖尿病的概率，鉴于此，这个人得到阳性检测结果:</p><p id="b894" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">P(D|Pos) = (P(D) * Sensitivity)) / P(Pos)</code></p><p id="dcaf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">一个人没有糖尿病的概率，鉴于此，这个人得到了阳性检测结果:</p><p id="ee70" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">P(~D|Pos) = (P(~D) * (1-Specificity)) / P(Pos)</code></p><p id="bdb6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们的后验总和将永远等于<code class="du lr ls lt lh b">1</code>。</p><p id="eee6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">公式为:P(D|Pos) = (P(D) * P(Pos|D) / P(Pos)</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="96ae" class="ll je hh lh b fi lm ln l lo lp">p_diabetes_pos = (p_diabetes * p_pos_diabetes) / p_pos<br/>print('Probability of an individual having diabetes, given that that individual got a positive test result is:\<br/>',format(p_diabetes_pos))</span></pre><p id="dfbb" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">假设一个人的测试结果为阳性，那么这个人患糖尿病的概率是:0 . 46386 . 38638638661</p><p id="f808" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">计算一个人没有糖尿病的概率，假设这个人得到一个阳性的测试结果。换句话说，计算P(~D|Pos)。</p><p id="d76a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">公式为:P(~ D | Pos)= P(~ D)* P(Pos | ~ D)/P(Pos)</p><p id="2854" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">请注意，P(Pos|~D)可以计算为1 — P(Neg|~D)。</p><p id="9adf" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">因此:P(Pos | ~ D)= P _ Pos _ no _ diabetes = 1–0.9 = 0.1</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="9857" class="ll je hh lh b fi lm ln l lo lp"># P(Pos/~D)<br/>p_pos_no_diabetes = 0.1</span><span id="848d" class="ll je hh lh b fi lw ln l lo lp"># P(~D|Pos)<br/>p_no_diabetes_pos = (p_no_diabetes * p_pos_no_diabetes) / p_pos<br/>print('Probability of an individual not having diabetes, given that that individual got a positive test result is:'\<br/>,p_no_diabetes_pos)</span></pre><p id="2db4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">分析表明，即使你得到了阳性的测试结果，你实际上只有8.3%的可能性患有糖尿病，而你没有糖尿病的可能性为91.67%。当然，这是假设整个人口中只有1%的人患有糖尿病，这只是一个假设。</p><p id="65b4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">“朴素贝叶斯”中的“朴素”是什么意思？</p><p id="ebdc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Naive Bayes中的术语“Naive”来自于这样一个事实，即算法认为它用来进行预测的特征是相互独立的，但情况可能并不总是如此。因此，在我们的糖尿病例子中，我们只考虑一个特征，即测试结果。假设我们增加了另一个功能，“锻炼”。假设该特征具有二进制值<code class="du lr ls lt lh b">0</code>和<code class="du lr ls lt lh b">1</code>，其中前者表示个人每周锻炼少于或等于2天，后者表示个人每周锻炼大于或等于3天。如果我们必须使用这两个特征，即测试结果和“练习”特征的值，来计算我们的最终概率，贝叶斯定理将失败。“朴素贝叶斯”是贝叶斯定理的扩展，它假设所有的特征都是相互独立的。</p><h1 id="fdd3" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤4.2:从头开始实现朴素贝叶斯</h1><p id="5722" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">假设我们有两个政党的候选人，绿党的“吉尔·斯坦”和自由党的“加里·约翰逊”，我们有这些候选人在演讲时说出“自由”、“移民”和“环境”的概率:</p><ul class=""><li id="4588" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated">吉尔·斯坦说“自由”的概率:0.1——————&gt;<code class="du lr ls lt lh b">P(F|J)</code></li><li id="d0b8" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">吉尔·斯坦说“移民”的概率:0.1—--&gt;<code class="du lr ls lt lh b">P(I|J)</code></li><li id="03b2" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">吉尔·斯坦说“环境”的概率:0.8—--&gt;<code class="du lr ls lt lh b">P(E|J)</code></li><li id="9db9" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">加里·约翰逊说“自由”的概率:0.7—--&gt;<code class="du lr ls lt lh b">P(F|G)</code></li><li id="1867" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">加里·约翰逊说“移民”的概率:0.2 — -&gt; <code class="du lr ls lt lh b">P(I|G)</code></li><li id="1d9c" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">加里·约翰逊说“环境”的概率:0.1 — -&gt; <code class="du lr ls lt lh b">P(E|G)</code></li></ul><p id="068a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">让我们也假设吉尔·斯坦发表演讲的概率，<code class="du lr ls lt lh b">P(J)</code>是<code class="du lr ls lt lh b">0.5</code>，加里·约翰逊，<code class="du lr ls lt lh b">P(G) = 0.5</code>也是一样。</p><p id="4353" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">鉴于此，如果我们必须找出吉尔·斯坦说“自由”和“移民”这两个词的概率，会怎么样？这就是朴素贝叶斯定理发挥作用的地方，因为我们正在考虑两个特征，“自由”和“移民”。</p><p id="e445" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在我们可以定义朴素贝叶斯定理的公式了:</p><figure class="kv kw kx ky fd kz er es paragraph-image"><div class="er es mb"><img src="../Images/2ed1156fa0bd60a55bb0771807931541.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/0*iH1a6ZDbZfJ4IXVw.png"/></div></figure><p id="35cd" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">这里，<code class="du lr ls lt lh b">y</code>是类别变量(在我们的例子中是候选人的名字)，而<code class="du lr ls lt lh b">x1</code>到<code class="du lr ls lt lh b">xn</code>是特征向量(在我们的例子中是单个单词)。该定理假设每个特征向量或单词(<code class="du lr ls lt lh b">xi</code>)彼此独立。将这一点应用到我们将邮件分类为垃圾邮件的问题中，朴素贝叶斯算法会单独查看每个单词，而不是将它们视为相互之间有任何链接的关联实体。在垃圾邮件检测器的情况下，这通常是可行的，因为在电子邮件中有某些红色标记词，这些词非常可靠地将其分类为垃圾邮件。例如，带有“伟哥”字样的电子邮件通常被归类为垃圾邮件。</p><p id="801a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">为了分解它，我们必须计算以下后验概率:</p><ul class=""><li id="8d66" class="kg kh hh ig b ih ii il im ip ki it kj ix kk jb kl km kn ko bi translated">给定“自由”和“移民”这两个词，吉尔说出这两个词的概率有多大？</li><li id="434b" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">使用公式和我们的贝叶斯定理知识，我们可以如下计算:<code class="du lr ls lt lh b">P(J|F,I)</code> = <code class="du lr ls lt lh b">(P(J) * P(F|J) * P(I|J)) / P(F,I)</code>。这里的<code class="du lr ls lt lh b">P(F,I)</code>是‘自由’和‘移民’这两个词在演讲中出现的概率。</li><li id="cf99" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated"><code class="du lr ls lt lh b">P(G|F,I)</code>:鉴于“自由”和“移民”这两个词是由加里说出的，这两个词出现的概率有多大？</li><li id="26c8" class="kg kh hh ig b ih kp il kq ip kr it ks ix kt jb kl km kn ko bi translated">使用公式，我们可以计算如下:<code class="du lr ls lt lh b">P(G|F,I)</code> = <code class="du lr ls lt lh b">(P(G) * P(F|G) * P(I|G)) / P(F,I)</code></li></ul><p id="42c0" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在您已经了解了贝叶斯定理的来龙去脉，我们将扩展它来考虑我们有多个特征的情况。</p><h1 id="1327" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤5:使用scikit-learn实现朴素贝叶斯</h1><p id="66c6" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">我们将使用sklearn的sklearn.naive_bayes方法对我们的SMS消息数据集进行预测。</p><p id="052b" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">具体来说，我们将使用多项式朴素贝叶斯算法。这个特定的分类器适合于具有离散特征的分类(例如在我们的例子中，文本分类的字数)。它接受整数字数作为输入。另一方面，高斯朴素贝叶斯更适合于连续数据，因为它假设输入数据具有高斯(正态)分布。</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="5616" class="ll je hh lh b fi lm ln l lo lp">from sklearn.naive_bayes import MultinomialNB<br/>naive_bayes = MultinomialNB()<br/>naive_bayes.fit(training_data, y_train)</span></pre><p id="e8f6" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">结果</p><p id="62cc" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)</code></p><p id="98c7" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">现在，我们的算法已经使用训练数据集进行了训练，我们现在可以使用predict()对存储在“testing_data”中的测试数据进行一些预测</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="c14f" class="ll je hh lh b fi lm ln l lo lp">predictions = naive_bayes.predict(testing_data)</span></pre><h1 id="57f7" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">步骤6:评估我们的模型</h1><p id="55d2" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">既然我们已经对测试集进行了预测，我们的下一个目标是评估我们的模型做得有多好。这样做有各种各样的机制，所以首先让我们回顾一下。</p><p id="45c1" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">准确度衡量分类器做出正确预测的频率。它是正确预测的数量与预测总数(测试数据点的数量)的比率。</p><p id="5e32" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Precision告诉我们被我们归类为垃圾邮件的邮件中，实际上有多少是垃圾邮件。它是真阳性(分类为垃圾邮件的单词，实际上是垃圾邮件)与所有阳性(分类为垃圾邮件的所有单词，不管这是否是正确的分类)的比率。换句话说，精度是</p><p id="91a3" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">[True Positives/(True Positives + False Positives)]</code></p><p id="2903" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">Recall (sensitivity)告诉我们实际上是垃圾邮件的邮件中有多少被我们归类为垃圾邮件。它是真阳性词(被归类为垃圾邮件的词，以及实际上是垃圾邮件的词)与所有实际上是垃圾邮件的词的比率。换句话说，回忆是</p><p id="dc2f" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated"><code class="du lr ls lt lh b">[True Positives/(True Positives + False Negatives)]</code></p><p id="9840" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">对于像我们这样的分类分布不均匀的分类问题，例如，如果我们有100条短信，只有2条是垃圾邮件，其他98条不是垃圾邮件，准确性本身并不是一个很好的指标。我们可以将90封邮件归类为非垃圾邮件(包括2封垃圾邮件，但我们将其归类为非垃圾邮件，因此它们会是假阴性)，将10封邮件归类为垃圾邮件(所有10封邮件都是假阳性)，但仍然可以获得相当好的准确度分数。对于这种情况，精确和回忆非常方便。这两个指标可以结合起来得到F1值，F1值是精确值和召回值的加权平均值。该分数的范围从0到1，1是F1的最佳分数。</p><p id="977a" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我们将使用所有4个指标来确保我们的模型运行良好。对于数值范围从0到1的所有4个指标，分数尽可能接近1是我们的模型表现如何的良好指标。</p><pre class="kv kw kx ky fd lg lh li lj aw lk bi"><span id="b659" class="ll je hh lh b fi lm ln l lo lp">from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score<br/>print('Accuracy score: ', format(accuracy_score(y_test, predictions)))<br/>print('Precision score: ', format(precision_score(y_test, predictions)))<br/>print('Recall score: ', format(recall_score(y_test, predictions)))<br/>print('F1 score: ', format(f1_score(y_test, predictions)))</span><span id="3674" class="ll je hh lh b fi lw ln l lo lp">Accuracy score:  0.9885139985642498<br/>Precision score:  0.9720670391061452<br/>Recall score:  0.9405405405405406<br/>F1 score:  0.9560439560439562</span></pre><h1 id="45ff" class="jd je hh bd jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka bi translated">第七步:结论</h1><p id="e609" class="pw-post-body-paragraph ie if hh ig b ih kb ij ik il kc in io ip kd ir is it ke iv iw ix kf iz ja jb ha bi translated">与其他分类算法相比，朴素贝叶斯的一个主要优势是它能够处理大量的特征。在我们的例子中，每个单词都被视为一个特征，有成千上万个不同的单词。此外，即使存在不相关的特征，它也能很好地执行，并且相对不受它们的影响。它的另一个主要优点是相对简单。“朴素贝叶斯”开箱即用，很少需要调整其参数，除非通常在数据分布已知的情况下。它很少过拟合数据。另一个重要的优势是，对于它可以处理的数据量来说，它的模型训练和预测时间非常快。总而言之，朴素贝叶斯真的是算法中的瑰宝！</p><p id="e83c" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">我也相信朴素贝叶斯非常有用，即使你更高级。像这样的简单模型可以用作更高级模型的基线。为什么不呢？</p><p id="f5c4" class="pw-post-body-paragraph ie if hh ig b ih ii ij ik il im in io ip iq ir is it iu iv iw ix iy iz ja jb ha bi translated">编码快乐！</p></div></div>    
</body>
</html>