<html>
<head>
<title>License Plate Character Recognition: kNN &amp; CNN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">车牌字符识别:kNN &amp; CNN</h1>
<blockquote>原文：<a href="https://medium.com/analytics-vidhya/license-plate-character-recognition-knn-cnn-c6b4a3342515?source=collection_archive---------6-----------------------#2021-03-13">https://medium.com/analytics-vidhya/license-plate-character-recognition-knn-cnn-c6b4a3342515?source=collection_archive---------6-----------------------#2021-03-13</a></blockquote><div><div class="ds gv gw gx gy gz"/><div class="ha hb hc hd he"><div class=""/><figure class="ev ex if ig ih ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ie"><img src="../Images/913654a8ebb4a3b846b9be57798c9956.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oDnD6yRFXZffx2NFXaIANA.jpeg"/></div></div></figure><p id="31e4" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">本文基于两篇论文，重点关注人工智能的快速发展领域及其在实时世界中的实现。它讲述了使用机器学习(ML)和深度学习(DL)识别车牌字符的过程。使用的技术分别是k-最近邻(kNN)和卷积神经网络(CNN)。因此，性能，结果和方法进行了讨论。这36个角色中的每一个都是在不同的环境中使用这些算法来训练的。准确性是从训练和测试数据中提取的。该自主系统用于交通监控中的车辆牌照识别。副产品还包括在犯罪调查、监视系统、收费和停车场管理中的应用。因此，该系统可以帮助跟踪车主的身份，并根据违规情况对他们进行相应的收费。</p><p id="b7b0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">(图片提供:参考文献)</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es jn"><img src="../Images/26b9326e3832269b8c2710b3fe1cf4ef.png" data-original-src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*thAExSd37HGq0B3kpGy8fg.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">区域聚类</figcaption></figure></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><blockquote class="kd ke kf"><p id="8c74" class="ip iq kg ir b is it iu iv iw ix iy iz kh jb jc jd ki jf jg jh kj jj jk jl jm ha bi translated">C <strong class="ir hi"> <em class="hh">哈兰格斯</em>T3】</strong></p></blockquote><p id="af4b" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">近年来，这种车牌识别技术得到了快速发展。所有这些用例都隐含在用计算机视觉代替人眼的实时环境中。这引发了一些问题，例如</p><p id="ae44" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">a)由于快速行驶的车辆<br/>导致的运动模糊效果B)由于外部前灯/反射<br/>导致的过多光线C)由于夜间或破碎的街灯导致的照明不足<br/> d)由于街道/建筑灯故障导致的车牌污染<br/> e)由于灰尘/雨水/硬件导致的低分辨率<br/> f)由于摄像机角度导致的图像倾斜<br/> g)字符轮廓，如各种字体样式/大小<br/> h)由于车牌背景/纹理/自然光导致的分割级别<br/> i)类似字符，如D-0-Q-1</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es kk"><img src="../Images/924054f60980af247d2e8801ef95e05d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1006/format:webp/1*6rDVHGtjJUfUltc3dBSaAg.jpeg"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">捕捉车牌图像后的一些挑战</figcaption></figure><p id="9d4f" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">由于没有办法控制这些环境因素，我们必须确保算法预测足够准确和稳健。正如read所说，这两种技术产生了几乎相同的准确率，约为87%。但它有望尽可能地提高准确性，因为它可能会导致公民对他们没有犯下的行为的错误获取。因此，两篇论文都试图通过分别使用轮廓和线段提取方法来提高精确度。</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><blockquote class="kd ke kf"><p id="da5c" class="ip iq kg ir b is it iu iv iw ix iy iz kh jb jc jd ki jf jg jh kj jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="hh">算法</em> </strong></p></blockquote><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es kl"><img src="../Images/79a7b5b2cc44bc7e73510019c4a65170.png" data-original-src="https://miro.medium.com/v2/resize:fit:350/format:webp/1*hQiJRptZ-3AsUhEOtFLpHw.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">kNN流程图</figcaption></figure><p id="53b0" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">轮廓提取在[1]中使用ML的kNN技术用于分类。获得车牌图像后，计算出车牌的轮廓。如果根据它们的尺寸被发现有效，则这些板被分割成检测到的轮廓。使用kNN对这些轮廓进行分类。kNN是最简单和广泛使用的分类算法。在kNN中，训练数据集存储在数组/向量中。这些存储的属性由独立变量组成。每当需要分类时，就会产生这些属性的变化组合，形成因变量。这些因变量存储在不同的类别中。如果一个变量不属于任何类，那么使用kNN。因此，分类是通过提取k个已知类别的样本来完成的。通过在相似的参数上取距离，将这些样本与它们的邻居进行比较。这些距离可以是欧几里得距离、曼哈顿距离或闵可夫斯基距离，称为权重。在本文中，k = 1，其中仅识别一个邻居。“k”是分类时考虑的邻居数量。分类可以基于属于一类的样本的距离或数量来完成。但是当k = 1时，这种方法导致过拟合，因此易受噪声影响。而在k = T的情况下，观察到过度平滑或欠拟合，其中T是最大样本。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es km"><img src="../Images/bfc7e4ecc412a6eb6bfbec7b3c243341.png" data-original-src="https://miro.medium.com/v2/resize:fit:650/format:webp/1*Cilf5dXSqP4Eliv2k3pCIQ.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">CNN流程图</figcaption></figure><p id="5b3a" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在[2]中使用分割方法来执行DL的CNN中的字符识别。这是使用CNN和滑动窗口(SW)进行细化来检测的。SW将区域传送给CNN进行检测。而CNN区分字符和非字符区域。这创建了改进的固定大小的边界框，以提高分割的准确性。字符分割是一个关键特征，因为实时环境包含有缺陷的墨水、噪声、倾斜方向和照明。在CNN中，权重和偏差被分配给图像的各个方面。这有助于通过图层网络将图像与其他图像区分开来。采集图像后，获取该图像的灰度并将其提供给软件。这个固定的盒子从图像中检测出各个区域，转发给CNN进行预测。包围盒区域的分类由聚类算法完成。聚类包括对具有相似属性的数据进行分组。CNN是从多层感知器(MLP)中的二维数据发展而来的。CNN的学习过程有两个步骤，前馈和反向传播。有隐藏层使用校正线性单位(ReLU)卷积来过滤图像。</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><blockquote class="kd ke kf"><p id="e845" class="ip iq kg ir b is it iu iv iw ix iy iz kh jb jc jd ki jf jg jh kj jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="hh">方法论</em> </strong></p></blockquote><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es kn"><img src="../Images/0f51288df6096ea3aedacacbefca9d44.png" data-original-src="https://miro.medium.com/v2/resize:fit:446/format:webp/1*8I3vS3yqxdQ-b2Y0xuTEKQ.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">类别的二维kNN聚类</figcaption></figure><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es ko"><img src="../Images/de34829b30b8f0ad60333b59fc843b90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1206/format:webp/1*xn1-qcRs0FsW3d9BMfVn4w.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">基于轮廓的字符分离</figcaption></figure><p id="9350" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在[1]中，轮廓提取过程被用于车牌识别。在获得板图像之后，计算轮廓以验证来自图像的大小字符。然后将板分割成各自的轮廓。使用kNN算法，完成字符的分类。这是通过给由26个字母和10个数字组成的36个不同的字母数字字符分配一个类别来实现的。所有这些不同轮廓的字符被用作标准字体的训练集。每个轮廓被指定一个类别。分配多个训练数据以提高准确性，但限制训练量以减少计算时间。这是通过增加实例来实现的。利用定位板图像，进行测试和验证。通过检测轮廓，在调整车牌图像的大小后，字符被彼此分离。如果检测到的轮廓属于任何一个类别，那么就用kNN对其进行分类。通过使用欧几里德距离，对尺寸调整后的图像的尺寸进行逐像素的属性比较。角色分配的决定是由kNN的多数投票决定的。因此，流程的输出是一个字符串。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es kp"><img src="../Images/bf00d325240ca122777fda2905293827.png" data-original-src="https://miro.medium.com/v2/resize:fit:632/format:webp/1*IedmGeJZRJr3Y67XkQ1yLA.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">预测区域的分割</figcaption></figure><figure class="jo jp jq jr fd ii er es paragraph-image"><div class="er es kq"><img src="../Images/8c82c3b5e641909047892fe1ba499d7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:550/format:webp/1*Devwsms9HqxZgMFWBNegNQ.png"/></div><figcaption class="js jt et er es ju jv bd b be z dx translated">从每个聚类中获得单个有界盒</figcaption></figure><p id="62d5" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">CNN算法在[2]中使用，通过SW预测分割区域，以检测字符的存在。然后通过聚类技术对它们进行分类。SW是一种从图像矩阵中提取区域技术。本文采用25*60的窗口大小来提取94*300以上的图像。这3174个提取的区域被馈送到CNN用于字符或非字符区域的分类。这里设置了三个卷积层滤波器和具有128个神经元的ReLU激活函数。其中2个神经元具有Softmax功能。其中softmax函数是将多维数据归纳为概率总和为1的逻辑函数。由于多个质心，这导致许多区域被检测为字符。应用层次凝聚聚类(HAC)来分离这些质心。HAC是一种自下而上的方法，用于确定这些消除质心之间的距离。这种消除是基于为每个子聚类设置的最小距离来完成的。在字符的边界框固定后，通过设置框的平均限制进行细化。这样做是为了避免不良精度导致不良分割。并且为了细化，收缩和扩展概念被用在盒子的坐标上。</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><blockquote class="kd ke kf"><p id="c7ab" class="ip iq kg ir b is it iu iv iw ix iy iz kh jb jc jd ki jf jg jh kj jj jk jl jm ha bi translated">I <strong class="ir hi"> <em class="hh">发布会</em> </strong></p></blockquote><figure class="jo jp jq jr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es kr"><img src="../Images/1ce7d67d8a088702876b6decfe4aca55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NTGn2OfYCShIM-NyhCCgIw.png"/></div></div></figure><p id="3048" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">在[1]中，该技术在对包含183个字符的30个车牌进行实验后，达到了87.43%的准确率。观察到k值的增加降低了字符识别的准确性。结果在k = 1 (1NN)时最大。与人工神经网络相比，其准确率为86.34%。为了适合实时系统，要求最低30 fps的处理速度。因此，该系统以每帧0.034秒的速度运行，接近所需的速率。然而，少数帧超出了最大限制，但被其他帧的快速处理所补偿。因此，这里使用kNN作为分类器来计算提取的轮廓的分类。这是通过找到训练和验证数据集的属性之间的欧几里德距离来完成的。这个数据集只不过是通过相机输入算法的输入图像的像素矩阵。该过程从将车牌图像分割成单个字符开始。这些字符由边框分隔。在模板训练数据集的帮助下，在kNN算法中对这些盒子进行分类。此外，两个系统的精度实际上保持相同。所以，kNN相当于精确的现有技术。</p><figure class="jo jp jq jr fd ii er es paragraph-image"><div role="button" tabindex="0" class="ij ik di il bf im"><div class="er es ks"><img src="../Images/8c54626e05b68d27ba5b66f9dba5419e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VsYgQdnqLRfofPRgLyGiFw.png"/></div></div></figure><p id="80aa" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">我们在[2]技术中读出了87.06%的准确度。他们使用CNN和SW结合边界框细化来分割字符以检测车牌。该模型对包含982个字符的138个车牌进行了测试，其中855个字符被成功分割。因此，我们可以比kNN更依赖这种技术，因为它只对30幅图像进行了测试。CNN用于区分字符区域和非字符区域。具有2像素步幅的SW用于提取区域。这些提取的区域被馈送到CNN模型，其概率输出基于两个类别。字符值类的阈值设置为0.95。为了执行HAC，对潜在的基本事实进行了聚类。从包围盒的x和y坐标的平均值中取出单个盒子，并进行细化。如果并集上的交集(IoU)值超过0.75，则边界框被确定为真分割。IoU是交集面积与并集面积之比。对三个组合进行了SW和CNN测试，得到了44.29%的准确率。但通过添加边界框重定位(BBRep)，准确率提高到65.68%。最后，在添加细化(BBRef)后，准确率为87.06%，成功分割855个。因此，在增加重新定位和调整后，IoU值会变得更高。</p></div><div class="ab cl jw jx go jy" role="separator"><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb kc"/><span class="jz bw bk ka kb"/></div><div class="ha hb hc hd he"><blockquote class="kd ke kf"><p id="8997" class="ip iq kg ir b is it iu iv iw ix iy iz kh jb jc jd ki jf jg jh kj jj jk jl jm ha bi translated"><strong class="ir hi"> <em class="hh">参考文献</em> </strong></p></blockquote><p id="6f47" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[1] <br/> A. R. F. Quiros等人，“一种基于kNN的车牌号码字符识别机器视觉方法”，TENCON 2017–2017 IEEE第10区会议，槟城，2017，第1081–1086页，doi:10.1109/TENCON . 2017 . 2012828386</p><p id="bd41" class="pw-post-body-paragraph ip iq hh ir b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm ha bi translated">[2] <br/> A. T. Musaddid，A. Bejo和R. Hidayat，“使用CNN改进印度尼西亚车牌识别算法的字符分割”，2019年信息技术和智能系统研究国际研讨会(ISRITI)，印度尼西亚日惹，2019，第279–283页，doi:10.11109/ISRITI . 486863676</p></div></div>    
</body>
</html>